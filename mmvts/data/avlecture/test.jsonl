{"example_id": "mit049@@MIT8_701F20_04_300k", "text": ["MARKUS KLUTE: Welcome back to 8.701.  So we switch gears now and talk about quantum electrodynamics,  QED.  And we start the discussion by going back  to free wave equations. ", "Now could argue that we are interested in collisions  and we're interested in decays of particles.  So why do we discuss free wave equations?  But the theory we discussed last week,  which we used in order to get a hold on Feynman diagrams ", "and calculations, was very simplified.  And one of the aspects not considered in this theory  was the fact that particles carry spin.  So we had a theory which not only was applicable to scalars. ", "Now by walking through wave equations,  we can see how we can incorporate or make  use of the fact that particles actually do carry spin. ", "So let's do this one by one.  So we start off with our relativistic energy-momentum  relation--  e squared is equal to p squared plus m squared.  We express energy and momentum via ", "quantum mechanical operators.  And so immediately by putting this in,  we find this equation here, which  is the so-called Klein-Gordon wave equation. ", "So if you look at this equation, we  see that the second derivative here in time,  there's no derivative in space.  So there's an asymmetry between space and time.  And that is a not really useful feature of our wave equation ", "as we want them to be, Lorentz invariant, for example.  So what we want is a first-order equation in both derivatives. ", "So we'll just start writing this down in general terms,  and then make sure that this equation holds  to the relativistic information we just ", "saw on the previous slide.  We'll just write this down here.  We have a first derivative time and a first derivative space.  And we'll just say there's a constant between those two,  relating those two. ", "So the sigmas are just unknown constants.  So if you now try to find by squaring this, trying  to find the Klein-Gordon equation  and relates the coefficients, you  find this relationship here. ", "So the sigma squared are all the same and equal to 1.  But you also see that the sigmas,  they're anti-commutate-- sorry-- ", "which is not possible for numbers.  So sigmas need to be matrices.  You also see that this is only holding true here  for m equal to 0.  So this equation here is true for a massless particle. ", " All right, so if we then try to find solutions  for those relations, we find that they can be fulfilled  by the 2 by 2 Pauli matrices. ", "We might have seen this already hopefully  in the discussion of atomic physics.  And there, those Pauli matrices associate spin to electrons. ", "So this is exactly what we have in mind here also.  Now using this definition, we can rewrite the Weyl equations  to energy times the field is equal to minus ", "sigma times the momentum times the field.  And to find a second equation, we'll just design flips.  The chi here and the phi spinors, ", "they're two-dimensional vectors and the sigma  are our Pauli matrices.  Good.  So we have the relation of [INAUDIBLE]..  So we can go a step further. ", "Now we want to introduce mass term as well.  Those hold for massless particles,  so we're going introduce mass.  So we can rewrite this equation and introduce its mass term  here, again, with the coefficient. ", "And we find now this alpha here being--  sorry.  So this phi here is a core component spinor. ", "And it stands for the particle, its antiparticle, and the two  spin states.  So that's combining that two equations we had here.  So you'll see one is for particles  and one is for antiparticles, for the two spin states. ", "So we combine this in one equation  and we added this mass term.  So if you try to find the solutions here,  you find that alpha is a matrix-- ", "4 by 4 matrix which has the sigma, supporting matrices  on the off-diagonal elements.  And beta is a diagonal matrix-- a 4  by 4 matrix with identity on the upper two components, ", "and minus 1 in the lower two components.  So now with this, this is already the Dirac equation.  We can rewrite the Dirac equation in the covariant form ", "where you have just defined a new matrix here,  so-called gamma matrix which you build out  of this matrix beta and alpha.  Which are defined on the previous slide. ", "Good, so good.  So we have this new matrix, this new equation  here, which is the Dirac equation.  And it holds for particles with two spin states, examples  with spin half states.  And it holds for particles which have masses. ", "So that's great.  So this is now on starting point for the discussion.  So we'll continue the discussion on QED.  In the last video, we looked at wave equations  and we discussed Dirac equations. ", "Now we want to look at solutions to the Dirac equations.  All right, so remember that the overall goal now  is to find a description of spin-half particles, which ", "we can then use in our matrix element calculation  in order to get to cross sections or decay  rates of particles.  ", "If you just ad hoc or natural choice for a solution  would be a wave equation, which is  a product of a spinor, which depends on energy and momentum, ", "and an exponent.  So we have a free plane wave as a solution to our free particle  base waveform.  We have to show or we have to make sure ", "that this wave equation satisfies the Dirac equation  as shown here.  Since the spinor depends only on energy and momentum here, ", "it's rather simple to write down the derivatives,  because they only depend on the exponent.  So we can do this here.  And we find those solutions here for the four components. ", "We can rewrite this by putting those derivatives here back  into the Dirac equation.  What we find then here's this simplified form for the spinor. ", "Note that this does not depend on derivatives anymore.  So this is a rather simple form.  And then we can study--  what happens now if they have a particle at rest.  So it further simplifies the Dirac equation. ", "It further simplifies here to items E  times gamma 0, u-- that's our spinor-- equal m times u.  Since gamma 0 is a diagonal, or is diagonal, ", "we can immediately find the eigenstates to this equation.  So we find four different eigenstates,  and they are orthogonal. ", "And you find that they look very similar.  So n here is just the normalization factor,  which is the same for all four.  And we find those four different values here.  You can find two with a negative sign in the exponent and two ", "with a positive sign in the exponent.  Now this is for particles at rest, fine.  We can interpret those solutions as positive and negative energy  states of a spin-half particles or a particle with two spin ", "states.  But now we want to see what happens  if you have a particle which is not addressed.  So the way to approach this is, so once, we  can just apply Lorentz transformation  and see how the solutions transform. ", "But it is even easier to just look directly  at the Dirac equations for the spinor.  So we start again from our equation here.  We just write this down. ", "And then we rewrite the equation using the gamma  matrices until we find those factors p times gamma 1--  px times gamma 1, py gamma 2, p3 gamma 3. ", "Can we write this using the Pauli matrices in this form?  OK, so what this gives us is this coupled form of equations. ", "So here we revised our spinor as a two vector, uA and uB.  And you find the coupled form between those two ", "if we look at those set of equations.  Great.  But this is rather cumbersome and complicated.  However, now we can try to find the solutions ", "or try to find eigenstates to the equation.  We know that the solutions are of this form here.  That's how we started.  If you then try to find a specific [? state, ?] ", "you can start from the simplest alternate solution,  which is uA equal 1, 0.  And then just put this in here. ", "And you find for u1 those solutions here.  And then you turn this around.  For uB, you find 1 and 0 and you find the other solution.  So similarly as for the solutions at rest, ", "we find here for our spinors that there  is four different spinors, which are independent.  You can interpret them now as, again, ", "the positive and negative energy states.  So if you then, for example, say,  OK, let's make sure that this is all consistent,  we want to see that when the momentum is 0, ", "you come back to the previous solution.  If you look at the momentum, if they're 0,  those components are all here--  become 0, you find the very same solution  as we had on the previous page. ", "You can also ask yourself what happens now  if you don't use this idea of positive and negative energy  solutions.  If you want to do that and you define ", "that as all are either positive for energy solutions,  and not two positive and two negative,  you find that you can divide them  as linear combinations of the others,  so they're not independent solutions. ", "So in order to have four independent solution  of the Dirac equations, two have to be positive  and two have to be negative in energy.  All right, so I recommend just trying ", "the exercise of playing around with the Pauli matrices  and the gamma matrices.  If you have not seen this before,  it's not easy to follow the algebra.  But once you get a hang of it, it's ", "actually not that complicated.  So in the last two videos, we looked at the Dirac equation  and we looked at solutions Dirac equations.  And in the last lecture we found that,  along with positive energy states, ", "we had those negative energy states.  Since we cannot simply drop them or disregard them,  we do have to find physical interpretation for these  negative energy solutions. ", "The first one which was put forward,  is the one where you think about negative energy  states all being populated--  and that is the vacuum.  The vacuum is basically a sea full of negative energy states ", "which are all populated.  So if you have a positive energy state,  and there are electrons sitting in this energy state here,  the electron, because of the Pauli exclusion principle ", "cannot fall down into the negative energy state.  But you are able to kick them out, for example,  to excite them with a photon.  Very excited.  The negative energy state, you get an electron out. ", "This process is then will lend to the creation  of a positron and an electron pair with a photon.  [INAUDIBLE] pair production.  It can also explain undulation where ", "there's an empty and a negative energy  stage where the electron just folds into creating a photon.  So while the interpretation is useful  and it explains pair production and undulation processes, ", "they fail to explain what this vacuum,  the sea of negative energy state even is.  So a more useful interpretation is one part forward that ", "Feynman and St√ºckelberg, which came out of the discussion  of quantum field theory.  And we already discussed this interpretation  when we looked at Feynman [INAUDIBLE]..  So have a look at this Feynman diagram ", "here where you have an electron with a positive energy  and an electron with a negative energy,  building a photon, which is twice  the energy in the symmetric configuration of the electrons ", "before.  And you're interpreting the negative energy solution  here of the electron as the electron moving backward ", "in time.  This is an equivalent to a positron with a positive energy  and an electron with a positive energy  where the positron and the electron move forward in time. ", "Again, in both cases, you see the energy of the photon  is two times the energy of those two particles.  All right.  So this is a very short discussion. ", "And we will see later on how we use the spinodes  for antiparticles together with spinodes for particles order  to make relations that could have matrix element.  And so we move forward with our discussion of Feynman rules, ", "this time now, with spin-1/2 particles included.  MARKUS KLUTE: Welcome back to 8.701.  So we continue our discussion, our development of QED  as a discussion of the photon.  We have already seen how we can describe electrons ", "and positrons, anti-electrons.  And now it's time to actually look  at the quantum of electromagnetic fields.  A few general remarks first, quantum electrodynamic ", "is a quantum field theory--  the quantum field theory of electrodynamic  processes describing how light interacts with matter.  Specifically, all processes where ", "a photon is used as an exchange particle involving  electrically-charged particles can be described by QED.  The photon is in the limit theory particle. ", "And it's a quantum of the electromagnetic field.  But the real power in QED lies in the fact  that we can describe it as a perturbation theory. ", "We'll see that we can write down Feynman diagrams,  calculate them, and use those calculations to describe  processes we can observe in experiment. ", "And since we can do this with a very high precision,  we can use QED in order to make forecasts, in order  to understand, in order to understand inner dynamics  of processes we can measure. ", "Feynman called QED our pride and joy.  And it's in the really unmatched precision of this theory  where the pride and joy lies. ", "But stepping back one step.  Let's start with just local election dynamics.  And let's start from Maxwell's equations.  And I'm going to use this just to make a few points  and remarks. ", "This is really not in the direct path of our development,  but it connects the dots to something  you have already started, meaning  classical electrodynamics.  So you all have seen Maxwell equations. ", "They can be expressed in integral or differential form.  And you can write this even more compact than it's given here.  So you see Gauss's law. ", "And you see that electric charge generate electric fields  you can see that you can produce currents  by time changing electric fields or by spatially ", "changing magnetic fields.  Gauss's law for magnetic fields saying  that there is no magnetic charge, no magnetic monopole,  at least as far as we know. ", "We have not observed those.  And then there's Faraday's law as well.  You can express the magnetic field and the electric field  through vector potentials. ", "And if you go one step further, you  see this very nice form using four vectors  for the potential and the vector potential  and the charge and the current. ", "So what we're really doing here right now  is we're just rewriting the very same equations.  And so when we use this [INAUDIBLE] operator, ", "the form of this equation looks like this.  You can already see this form is very  similar to the Klein-Gordon equation we just looked at. ", "So let's go down this path a little bit more.  So this here is yet another form to write the Maxwell equations, ", "where f is our field strength tensor.  And the field strength tenor has all the physics involved.  You see that you're describing the electromagnetic field  and its components. ", "And then the simplification of the Maxwell equations  are sitting here.  So we have the Maxwell equation in this form.  We have the Maxwell equation in this form here.  So there's one interesting thing when ", "we use potential in order to describe  electromagnetic processes or properties,  is that we can actually choose the specifics of the gauge. ", "There's a degree of freedom which  we can choose, which doesn't have any impact on the physics,  on the reality of the physics.  And you can see this here. ", "If you do the choice that this component is 0,  this is called the Coulomb gauge.  We basically simplify again our Maxwell equations  to this point here. ", "Great.  So there's a number of things to be said.  So what we are basically doing here, if we fix a gauge,  so if you fix our potential, we tie the choice of the potential ", "to the inertial frame we're using here.  And you could say that's not nice.  That doesn't seem [INAUDIBLE] invariant.  It is actually OK to do this.  The issue with that is that you tie-- ", "if you go from one frame in the other,  you have to actually change the gauge  as you go along with changing the reference frame.  But there's nothing bad, it's just a little bit awkward. ", "All right, then moving back so we have this equation now.  And this equation, obviously simplifies.  If there's no current or no charge around for free photons. ", "So this one, and for this you can find the solution  is again the free rates.  This was the goal of this lecture,  finding this free weight.  So you could have probably written this down  before any of the discussion, but I just ", "want to makes some connection.  So now this in the QED, this a mu,  becomes our big function for the photon.  Again, we have to this is as a result of the we gauge made. ", "So we made specific choice in our reference frame.  And then we can describe the photon with our wave function.  That is epsilon here, epsilon is our polarization vector. ", "And is a normalization factor.  We always have to normalize our wave function  to a specific set of unit.  All right, that's good. ", "We can now analyze this.  We find that those conditions are fulfilled here,  basically saying that photon decays like a photon.  The energy of the photon is equal to the momentum times C. ", "That's great.  But it's also not a surprise because the form  of this equation here is exactly that  of the Klein-Gordon equation not for massless particles.  In the Klein-Gordon equation we got ", "from this very same relationship,  so I was not surprised that this works out.  All right, one more word on the polarization vector.  So the choice you just made-- ", "I'm resulting the choice here.  This is our Coulomb requires that the zeros  component of our polarization vector is a0.  And that the polarization vector is orthogonal to the momentum ", "vector.  So in principle, you have the three vector.  The three vector is perpendicular to the direction  of motion.  And that allows us to find two polarization states which ", "are independent of each other.  So different to our electrons before.  Now we don't have four states.  You only have two states with independent solutions ", "for a given momentum.  All right, so with this now, we have elections.  We can describe those.  We can describe photons.  The next step now is to look at the Feynman rules which ", "allows us to describe the interaction between those two.  So welcome back to 8.701.  So we have all ingredients now to prepare Feynman rules  for QED.  So that's the toolkit we need in order  to make calculations to calculate scattering processes ", "and decays.  And we've already seen Feynman rules for our toy theory.  Again, now the situation is a little bit more  complicated, because we can consider ", "the spin of particles in addition  to their energy and momentum.  The rules' sequence of things are very much the same.  There is, however, a few caveats to keep in mind, ", "and I'll point those out.  OK.  So the very first thing is to be very clear in our notation.  So this is an arbitrary or generic QED Feynman diagram. ", "We have only pointed out the incoming  and the outgoing lines.  There is internal lines which I didn't mention here.  Important to note the momentum and the directions. ", "The directions are arbitrary.  We just have to be clear on them and then  treat them consistently.  All right?  So this is not different in our previous discussion. ", "Then, here comes the difference.  Our external lines either electron,  positrons, or photons.  All right?  You can-- fermions and photons, charged fermions and photons. ", "So we discussed how the solutions look  like, our spinors u and v. And for outgoing electrons,  for outgoing particles, we have this adjunct vector here, which ", "is given by u dagger gamma 0.  And similarly for the incoming antiparticle--  v dagger gamma 0.  For the photon, we have the polarization vectors ", "for incoming and outgoing photons.  All right.  Then we have a vertex factor.  Here, now, g e is a constant and a dimensionless property. ", "But we do have to have a gamma mu here  as part of our vertex factor.  For the propagator, our internal lines, ", "we have a difference between electrons, positrons,  and photons.  And that comes from the fact that electrons and positrons  are massive particles.  So we have vertex vectors which now ", "have this 1 over q square behavior,  or 1 over q square minus m square behavior.  So here, you can already see that there's  going to be a complication later when we evaluate or integrate ", "over momentum--  simply the same discussion I had before.  And we already know how to solve this problem of infinities  by renormalizing-- by having a cut-off and renormalizing it. ", "Excellent.  So the next step, then, is very much the same.  There's no change.  We have to make sure that there's energy and momentum  conservation, and we enforce this  by introducing delta functions. ", "We have to integrate over each and every internal momenta,  and each internal line gets one of those integration factors. ", "And then after we integrate, we are left with a delta function,  and we have to cancel that delta function.  All right.  In our toy experiment, the order of things didn't matter. ", "Everything we had in there was scalar numbers, right?  Here we do have a little bit more complicated problem.  So there's an importance in the order ", "of which we execute things.  So what we want to do is form fermion lines.  We just follow a fermion as we go from the left to the right.  And then we find things which are always of the form ", "an adjoint spinor, a 4-times-4 matrix, and a spinor.  And the result of that is going to be a number.  All right?  Great.  There is one additional complication, ", "is accounting for duplications and making sure  that the sign is [INAUDIBLE].  I'm just mentioning this here.  This will become more clear as you work through examples. ", "So there is an antisymmetrization going on,  where we have to introduce a minus  sign between different diagrams that differ only  by the interchange or the exchange of two incoming or two ", "outgoing electrons or positrons and/or the incoming electron  with an outgoing positron.  So if you have a diagram which is exactly the same,  but the two incoming electrons are interchanged, ", "you have to add those two diagrams.  You have to add all matrix elements together  for recalculating amplitude.  But you have to introduce a minus sign when  you change those two particles. ", "So with that, we can now just basically calculate  whatever QED process we want.  All the tools are already here.  And what we want to do now next, in the next video, ", "and also in the recitation and homework,  is to go through a few examples to get  a little practice with this.  There's a number of tricks which will come in handy, ", "and I'll explain those in a separate video.  They are just mathematical tricks  which allow us to quickly evaluate  the multiplication of spinors and matrix elements and so on. ", "So in this lecture, we are going to start  looking at an example of the QED process,  for which we can now, with all the tools we have in hand,  calculate the matrix elements' transition amplitude. ", "All right.  In more general terms, we can look at all the examples.  And they are listed here--  second-order processes and one third-order process.  We are going to discuss them in more detail as we go along. ", "This is really just to give you some feedback  for the different kinds of processes  we're going to look at.  So the first one is elastic scattering.  And muon-electron scattering, that's ", "the one process we're going to look in more detail.  Why?  Because this is the simplest case.  For this process, there is only one leading-order diagram,  which is exactly the one shown here. ", "For other processes where have the same particle interacting,  we find that we do have to consider multiple diagrams--  for example, this one here, where we have electron ", "and electron scattering.  And so we have to calculate not just this leading diagram,  which looks exactly like the one for the muon scattering,  but we also have to include the [INAUDIBLE] ", "where we change the outgoing electron leg.  And so on.  And other processes are including  electron-positron scattering, which  is caused Bhabha scattering, Compton scattering, which ", "we discussed the kinematics for already,  but also inelastic processes like pair annihilation or pair  production.  There's a very interesting diagram here, ", "which is the third-order diagram, which  is responsible for the anomalous magnetic moment.  And we'll talk more about that when  we talk about higher-order interactions.  So let's have a look at this electron-muon scattering ", "process.  So only one diagram contributes at the second order.  And so you have an electron and a muon scattering  via the exchange of a photon.  This is after all of QED diagram. ", "So now, how do we calculate the matrix element?  We simply just follow the Feynman rules--  Feynman rules as we discussed them before.  And if you want to do this now, you draw your Feynman diagram. ", "It's always very good and useful to draw a Feynman diagram first  and label accordingly.  That's super-useful if you want to systematically evaluate  this process. ", "And then you start going backwards from an outgoing leg  back to the initial leg.  And you see this part here.  You have the u3, the third particle here, ", "the vertex vector, and the first particle.  Then you have a propagator here for your photon.  It's given by minus i g mu,nu divided by q square. ", "And then you analyze the second part here.  Here you find the first particle, vertex vector,  and the second particle.  For each of those lines, you have ", "to make sure that energy and momentum is  converted into those [INAUDIBLE] delta functions.  And then the last part you have to do,  integrate over your momentum. ", "All right.  That's already the end.  The next step in your list of rules  is carry out the integration.  Integrate over q.  That drops your delta function, but you ", "are left with one delta function which you are also  supposed to drop, which then gives you your matrix element.  Now, here we're already done.  If you now further want to evaluate this diagram, ", "you actually have to be more explicit about the spinors  involved.  What needs to be done now is have a discussion  on how to handle the spin of the particles,  meaning being explicit about the spinors. ", "And in order to do that, we'll discuss  how we treat spin, how we have to treat spin,  either in an experiment where the spin  of the initial particle is known or an experiment where  we have to average over all possible spin states. ", "MARKUS KLUTE: Welcome back to 8.701.  So the name of this plan is called Casimir's trick.  But what we're actually going to do  is we're going to evaluate or learn  how to deal with spin information  in the calculation of our matrix elements. ", "So now what is it we're trying to do?  So the first problem we might have  is that we have polarized particles.  So we have here again our example of electron muon  scattering. ", "And if you assume that the electron and the muons  are polarized, you will find as we discussed  in the previous lecture that our matrix element is ", "proportional to the adjoined vector of mu 1 times  some sort of gamma matrix times the spinor.  And we probably have a polarization ", "that is as well included here to give  the polarization of the photon involved at the propagating.  Good.  Now in order to now get a number for M, ", "we actually have to be explicit about the base function  of the external particles.  And you can do this-- you can just write this down.  However, in experiments, we are often ", "interested in the scattering of unpolarized particles.  Even if you have a way to polarize a beam,  your polarization is not going to be perfect.  So in your calculation, you might ", "want to average or some opposite available  spins of your particle.  So how are we going to do this? ", "So we're trying to calculate the spin average amplitude.  Why averaging?  We want to average over the polarization  of the incoming particles, again,  because we don't know what the polarization states are. ", "And we want to sum of the polarization of all final state  particles simply because each polarization  state is a possible outcome of the interaction.  And we have to sum over all possible outcomes. ", "Good.  So how do we calculate the spin average amplitude?  So again, we start from our matrix element  where we have the adjoined vectors and gamma ", "matrix or spinor.  If you then calculate the square of this matrix,  we find this solution here.  Great.  And now we're just doing a few tricks. ", "So first of all, we can write our adjoined mu 1 equal  to mu [INAUDIBLE] 1, gamma 0.  And then just continue this rewriting to refine ", "this part here of he solution, which  looks a little bit simpler where we  now the adjoined matrix instead of the adjoined matrix given  here. ", "So we want to evaluate what this adjoined u1 gamma u2 is times  adjoined u2 gamma adjoined u1. ", "Good.  So this was just matrix algebra and working with gamma so far.  Now we're using this completion relation  where I probably haven't told you yet ", "what this syntax here is.  So gamma flash is equal to gamma mu p mu. ", "And that's just the way to simplify it writing down  the equation.  So if you use this so-called Feynman's slash,  you can also rewrite that Dirac equation in the simple form phi ", "del flesh minus M y equal to 0.  That's now our direct [INAUDIBLE]..  Remember there was a gamma mu in here. ", "All right, let's just decide now again.  We have to sum over all spin states, or the spin  states of all those particles.  Now if you start with something over particle 2, ", "we can rewrite this here.  We use this equation, this completely-filled relation,  and just really find this q as equal to this part here.  ", "So now we have this equation here,  which looks a little bit simpler, because we just  have our incoming and outgoing spinors for particle 1 given ", "here.  All right, now we're looking at this part of the equation now.  And again, we're just doing a little bit of matrix algebra  here.  And you find that this is equal to q u 1 mu 1, i-i, ", "which is just simply something over the same indices, which  is the same as building the trace of this matrix.  All right, so if you just put all of us together, ", "you find that calculating the sum of matrix elements,  it's similar to building the trait of a matrix.  And then our final results then give you [INAUDIBLE].. ", "All right, so summarizing this part, we have a matrix element.  And we saw that the matrix elements of this form's  proportional to this form.  And then when we try to calculate the spin average ", "matrix element squared, that's equal to the traits  of the particles involved using the completion image.  There's an additional factor of 1/2  here, which comes from the averaging ", "over the initial spins.  So assuming exactly one of u1 and u2 corresponds  to the initial particles defined as vector 1/2,  if both initial particles are the same, ", "like in a parent relation, then vector is 1/4.  And if neither is in the initial state,  then the factor is 1, which you would have for fair production. ", " Good.  So now we simplified the calculation of our matrix  elements, putting the specific spin states ", "in there and the specific polarization vectors to what  the calculation of traces of matrices.  So now we can look at what does it mean. ", "So this is what Casimir's trick really is about.  So summing over spins reduces to summing over matrices.  If you have antiparticles, the completeness relation, ", "which uses two p/minus M, and then you we go ahead.  So all you need to know now is how to do this trace it.  So first, some general remarks on traces. ", "We have to matches, A and B. You want  to calculate the trace of A plus B. Set  equal to the trace of A plus the trace of B.  If you have a multiplicator here, a vector alpha, ", "you can just take this out of the calculation of the trace.  In the traces, two matrices commutate. ", "The trace of A times B is equal to the trace of B times A.  And then you can use this in order  to show a more complicated relationships.  ", "Good.  We have already started playing around with the gamma Here  are a few more identities which might be of use when  you calculate traces and calculate ", "matrix elements overall.  The first one is g mu nu times g mu nu is equal to 4.  The anti-commutator relations we already discussed ", "and have shown in one of our recitation.  And if you have three matrices you  can rewrite them as minus 2 times  the matrix, which is in the middle here. ", "So I'm not going through this in much detail here,  but I encourage you to just follow,  it's an additional exercise.  We didn't have the opportunity yet to play with the quantum. ", "And then you can use those tricks, for example.  And commutator relation to calculate the traces.  For example, the gamma mu, is 4 times g mu nu. ", "OK, so what you see here is basically  used this anti-commutator.  Put it in here, use this part here, ", "this is basically one trade-off, 1 is 4.  So we get g mu-mu times the trace the 1.  But 4 times 4 matrix is 4.  And so you get the trace of gamma mu gamma mu ", "is equal to 4 times g mu, and so on.  Later on, we haven't discussed gamma 5 so much,  gamma 5 is defined as 5 times gamma 0, gamma 1, gamma 2, ", "gamma 3.  We will see them and discuss the weak interaction.  That there's a prominent role will come up  this very special gamma matrix.  And here are just some pieces of information ", "for traces for gamma 5.  The trace of gamma 5 is at 0.  The trace of gamma 5 times--  sorry-- a different gamma matrix is zero. ", "And that's also true for the product of additional gamma  matrix that you can find when you just  try to calculate this relation and the relation of that. ", " One last piece of the traces, this gamma  matrices, it's shown here.  Only with four or more gamma matrices ", "can you define or find a non-zero trace  involved in gamma matrices.  And here's one example where you have  the product of five or four gamma matrices with gamma 5. ", "And that's equal in this case--  4 times 3i times the total asymmetric tensor.  The total asymmetric tensor is defined as minus 1,  or even for rotation of those numbers here plus 1 ", "for odd permutations and if there's  two instances of this state.  All right, again, I'm not showing you  this in too much detail. ", "But I encourage you to play around.  And you will be asked in the next homework  to play around with some of the compilations with that.  So again, we have now all tools in place ", "to do a next round of cross-section calculations.  We have seen how to set up a matrix element.  We have seen how to build spin average or to treat the spin, ", "and then specifically to calculate  spin average amplitudes using [INAUDIBLE]..  All right, I'm not saying that this is all easy now, ", "but you have seen all necessarily  elements to calculate a cross-section for QED process.  So let's summarize.  So we have seen that we can set up some matrix element using ", "Feynman rules for QED.  We have seen how to set up the spin average matrix element  squared using the traces. ", "Now we would have to evaluate the traces in order  to derive this formula here.  So I'll spare you a precise discussion of this step here,  but you can actually follow this quite straightforwardly. ", "Let me just step back a little bit before we proceed.  My goal for the class is not to have you calculate  all kinds of cross-section processes,  but to understand how you would do it, ", "for the purpose of really understanding  where dependencies come from and where this kind of calculation  has its limitations.  The first part is you want to see ", "what is the dependencies on the couplings involved.  You see this g squared, for example.  That's a rather important effect.  You also want to see, so Fermi's this golden rule, ", "how we get actually into the cross-section from the matrix  element calculation.  So if you ever had to calculate a matrix element,  am I going to ask you to do this once, maybe twice, ", "as part of the homework set.  I encourage you to open the book, follow the rules,  look up tricks, how to work with traces. ", "And then you should get to a reasonable solution  in a reasonable amount of time.   But here for the purpose of this discussion,  we want to just have a look at a few specific cases ", "where we make assumptions and simplifications  to the discussion.  So the first one is called Mott scattering.  So here, again, we are at this example of a spin-half particle ", "scattering with a spin-half particle--  a different spin-half particle, so an exchange of a photon.  So we used the example of an electron-muon scattering,  but this muon here could also be a proton or any other nuclei ", "we spin off.  The assumption for Mott scattering we are using  is that the mass of this particle, the muon,  is much heavier than the mass of the electron. ", "And that's true the muon 200 times heavier than an electron.  A proton is even heavier.  Any heavier nuclei of this feels even heavier than this. ", "In Mott scattering, we also make the assumption  that the momenta involved are lower  than the mass of the heavy particle  and that the recoil of the heavy nuclei, or the muon, ", "can be neglected.  If we do that, we can then write the differential cross-section  using Fermi's golden rule as a spin average matrix ", "element squared divided by 2 pi M squared.  OK.  If you then use this kinematic information, ", "you basically start from this matrix element here.  And then you use those vectors, those four vectors,  for your momentum of the first, second, third,  and fourth particle. ", "You find that many of the vectors are simplifying to ME.  So p2 times p3 is ME.  And so are many of the others.  And there is a few important factors.  For example, p1 minus p3 squared is minus 4p squared sine ", "squared theta half.  And similarly, p1 times p3.  So you put this all in--  again, starting from this very formula we ", "just had discussed before--  and you put all the simplifications  and you get this matrix element, which already that  looks much more manageable.  There's an M squared, there's a p squared, ", "there's a cosine squared theta half term,  and some factor which depends on the moment times the mass.  And if you then add this to Fermi's golden rule, ", "you find this equation for your Mott scattering.  Again, this is the scattering of two  different spin-half particles where one is much heavier.  The outgoing momenta are small. ", "And the recoil of the heavier particles can be neglected.  So this Mott's formula describes,  for example, the Coulomb scattering, so the scattering  this photon on the electric charge of a nuclei. ", "And the scattering particle is not too heavy and not too  energetic, like an electron.  We also assume that everything involved here is point-like.  We haven't had any discussion on the charge distribution ", "of the nuclei or anything.  We assume that this is a point-like particle.  OK, we can further discuss now the case  where the initial state particles are non-relativistic. ", "So here our momentum formulas simplify.  This is simply M squared, p amplitudes is 2ME.  And alpha is q1 times q2. ", " Those are the electric charges.  And so then our differential cross-section  further simplifies to something you've already seen. ", "The Lorentzian cross-section is equal to q1 times  q2 divided by 4 times the energy sine  squared theta half squared.  And we have seen that as already the Rutherford scattering ", "cross-section when we discussed cross-section measurements  in a geometrical kind of thing.  So this closes a loop here in our cross-section discussion  how we can think about those things. ", "The Rutherford cross-section is nothing else  but a big billiard ball being hit by a small billiard ball  and looking at how the cross-section differentially ", "kind of evolves out this setup.  All right, in this sequence we have a little bit more  of a discussion.  What happens now if we induce higher-order terms ", "and how can we think about those solutions?  And then have two extra lectures and where  we go back and discuss spin, and also  how we can actually understand this in a Lagrangian setup. ", "So in this short video, we'll talking  about the effects of renormalization  and higher-order QED diagrams.  And we have already seen that when  we perform the integration of a matrix element over q, ", "that there's infinities.  And those infinities can be gotten around  with by introducing a cut-off scale,  and then only integrating up to this cut-off scale, ", "and in effect renormalize or redefine  masses and couplings involved.  So the first of such an effect or effective higher ", "order is the so-called vacuum polarization.  So you have high-order contribution  which may look like this, an additional loop, which  you can think about in the photon is so energetic that it ", "can polarize the vacuum and produce  a particle-antiparticle pair.  And that particle and antiparticle pair  then provides kind of a screening of the charge ", "you want to probe.  So I mentioned this particle here emits a photon  and wants to probe the electric charge of this particle. ", "The fact that there is this vacuum polarization going on  screens the charge you actually want to probe.  So effectively, you see a charge which is either ", "reduced or increased, depending on the impact,  on the sort of impact.  So the fine structure constant, remember, alpha,  is 1/137 [INAUDIBLE] at 0. ", "We measure that the value of alpha slightly increases as we  go to higher and higher energies.  And so this has been measured in many places,  experimentally confirmed, for example, ", "at lab where, at the [INAUDIBLE] of the W  or the scale of the W mass, the value of alpha  has been measured to 1/128.  And you can do this analytically. ", "You can calculate what the scale of effect is and plot this.  So you see here the running of alpha QED as a function  of the energy scale.  And you see this increase here. ", "There's another interesting point.  As you open up new particles of higher masses, quark  and antiquark pairs, you find this kind ", "of stepping approach here--  the new particles, for example.  The muon, antimuon, and the quarks and antiquarks  are [INAUDIBLE]. ", "All right.  So this is the first effect, vacuum polarization.  The second effect is very interesting-- probably one  of the most famous higher-order processes in QED. ", "And it has to do with the anomalous magnetic moment.  The magnetic moment is defined as the factor  g times e over 2m times S, the spin of the particle. ", "Diagrams of this form here modify the vertex.  So instead of having a vertex like this,  you have higher orders which modify the [INAUDIBLE].. ", "This leads, then, to a modified magnetic moment  of the fermion involved-- in this case, an electron,  but it can also [INAUDIBLE] muon or tau or another form. ", "So this was shown by Schwinger already in 1948,  and then experimentally confirmed many times after.  This g minus [INAUDIBLE],, which is 2, leading order, ", "is modified to 2 plus pi over alpha in next leading order.  We can calculate this to many orders,  and with mind-blowing precision. ", "So the precision is better than 10 to the minus 12 pi now.  I think it's 1.7 [INAUDIBLE] at this stage.  And experiments have tried to measure  this to find new effects. ", "I mentioned you can have new particles which  make modifications to the magnetic moment here.  And you would have sensitivity by making  experimental measurements. ", "So the electrons [INAUDIBLE] muon g minus 2  has been measured with very high precision.  No new physics have been observed,  but some differences are small differences ", "that have caused quite some excitement  about further improvements in g minus 2 measurements  specifically for the muon.  So in this lecture, I'd like you to have ", "a first connection between particle physics  and the Lagrangian formalism.  In classical mechanics, you have seen  that you can write down the Lagrangian using  the kinetic and the potential energy of a particle, ", "and from that derive equations of motions.  In quantum field theory, you can translate this idea  and derive Lagrangian densities. ", "It's beyond the scope of this class  to do all the mechanics of this.  We'll visit this topic later in the class  when we introduce the Higgs mechanism, for example. ", "And we'll be a little bit more systematic then.  I'm introducing the topic now because it allows you to answer  one of the homework questions.  So you can just follow this lecture ", "and then you should be able to answer the first question  of the second p-set.  All right, so you just have to trust me at this point ", "that you can write the Lagrangian for a Dirac field,  or Lagrangian density for a Dirac field this way.  One exercise would be to use this and show ", "that from this Lagrangian you can derive the Dirac equation  for a spinor field.  But that's not what we're trying to do here.  You're trying to see what's the effect is ", "of having this Lagrange density being invariant or unchanged  under global symmetry.  So we are able to rotate our spinor ", "field with a global phase.  And we will see that the Lagrangian  doesn't change and the consequence of this,  which is if we can.  This is exercising Noether's theory. ", "There's an overarching global symmetry.  And out of the symmetry follows the conserved property--  in this case, the current.  All right, so we can express the symmetry ", "with infinitesimal phase transformation,  as shown here, for our fields and for our adjunct fields.  ", "For the field and the derivatives,  then, you just have to do the math  and we find those expressions, which we can then  put back into our Lagrangian. ", "First of all, we write the change  of our Lagrangian in this way.  And as we just have seen the Lagrangian,  its invariant under this transformation, ", "and therefore the change is going to be 0.  So then we use this information at this in the equations.  We find this very complicated-looking set  of equations. ", "OK, so now we get this.   And then we can rewrite the terms.  So this is already with a vision of what we would ", "like to actually find later.  So if we now look at the terms involving the derivative ", "with respect to du mu of our spinor,  we can express this equation as shown here.  And with that, we find the next equation. ", "I only show this for the spinor not for the adjunct spinor.  This looks exactly the same.  But you, however, find in this part here,  this looks like Euler-Lagrange equation. ", "And this part needs to be 0.  So we only have to worry about this part of the equation,  and the same for the adjunct field.  So this then leaves this equation here ", "where we have i epsilon, a derivative  of this part of the equation.  And something like this you have seen before in our continuity ", "equation, something like this.  It's our continuity equation.  We discussed this in one of the last recitation  session, which leads us then to conserve currents. ", "And let's go one step further.  If we now identify this part as our current,  we can then use the partial derivatives ", "of our initial Lagrangian.  Now we're just calculating those terms here.  And we find that our current, our conserved current  is given by the adjunct spinor, gamma mu spinor. ", "And so what we have just seen-- and this is conserved,  so the derivative is 0--  have seen that we have a Lagrangian density,  we have a global symmetry.  And out of that, we find that the current is conserved. ", "So this is all I wanted to show here in the homework set now.  We start from a different Lagrangian.  So this is our Lagrangian for a massive spin half  particle, which satisfies the Dirac equation. ", "In the homework, we are looking at a scalar particle,  a massive scalar particle.  And the exercise, however, is very much the same. "], "vid_duration": [11.25, 14.159, 12.556, 10.755, 12.9, 10.75, 13.48, 12.46, 10.0, 11.889, 11.731, 12.57, 12.915, 12.405, 15.13, 12.68, 11.07, 10.47, 11.77, 11.0, 11.18, 10.03, 13.51, 11.7, 11.93, 14.303, 10.653, 13.03, 12.75, 11.19, 10.44, 10.23, 10.95, 14.43, 11.54, 12.3, 11.699, 14.731, 13.71, 12.99, 10.71, 12.825, 10.185, 11.28, 10.18, 13.58, 10.33, 11.94, 10.38, 10.615, 11.555, 12.51, 11.68, 12.08, 11.55, 10.928, 11.631, 13.69, 10.47, 12.179, 13.101, 13.14, 10.86, 11.61, 13.588, 10.142, 12.15, 10.69, 14.61, 10.986, 13.88, 11.49, 12.9, 10.67, 10.57, 11.25, 13.58, 12.18, 11.82, 10.289, 13.861, 11.37, 12.52, 11.6, 11.04, 11.03, 11.02, 11.13, 12.1, 14.89, 10.37, 10.73, 15.06, 10.5, 13.03, 11.6, 10.41, 14.19, 12.54, 12.77, 14.33, 11.465, 11.615, 12.81, 10.18, 10.26, 12.93, 14.017, 10.2, 11.28, 12.47, 13.14, 10.05, 13.99, 12.92, 12.09, 15.55, 10.72, 13.63, 11.0, 12.53, 12.42, 10.95, 14.06, 11.58, 12.45, 12.3, 10.0, 12.62, 12.15, 13.27, 10.685, 10.965, 13.149, 11.29, 13.02, 10.11, 12.94, 10.95, 11.71, 14.04, 11.025, 12.235, 12.3, 12.06, 11.28, 13.79, 12.93, 11.07, 10.48, 11.215, 13.135, 12.58, 11.479, 12.21, 10.319, 10.141, 11.909, 11.391, 10.77, 11.099, 10.801, 13.12, 11.498, 10.551, 12.421, 11.92, 10.54, 11.079, 12.12, 10.351, 12.595, 14.145, 12.51, 11.83, 11.439, 15.75, 10.221, 12.76, 11.939, 12.031, 14.07, 11.11, 10.76, 10.9, 13.78, 12.51, 12.66, 11.65, 12.49, 11.6, 11.25, 12.72, 11.65, 14.359, 10.901, 12.059, 13.051, 12.58, 11.01, 10.292, 12.018, 10.86, 12.51, 11.1, 10.601, 10.06, 10.52, 15.11, 10.16, 15.84, 11.49, 10.44, 11.25, 11.73, 10.56, 12.38, 11.243, 12.337, 10.71, 10.275, 10.935, 11.19, 10.571, 11.399, 14.55, 10.111, 11.639, 10.531, 10.659, 13.35, 14.31, 11.07, 10.47, 10.05, 12.75, 12.52, 11.571, 11.889, 11.888, 14.58, 13.109, 11.192, 13.599, 11.16, 10.13, 11.33, 13.21, 11.6, 10.65, 11.34, 11.07, 10.101, 11.46, 11.399, 10.25, 13.88, 11.77, 12.951, 10.509, 10.44, 13.609, 10.185, 12.21, 12.931, 10.779, 11.241, 12.02, 11.19, 10.859, 10.061, 11.95, 13.42, 10.929, 10.841, 12.46, 10.049, 10.011, 13.13, 12.509, 12.64, 10.32, 10.951, 11.769, 13.59, 15.33, 14.465, 13.736, 8.76], "stet": [[0, 11.25], [11.25, 25.409], [25.409, 37.964999999999996], [37.964999999999996, 48.72], [48.72, 61.62], [61.62, 72.37], [72.37, 85.85000000000001], [85.85000000000001, 98.31], [98.31, 108.31], [108.31, 120.199], [120.199, 131.93], [131.93, 144.5], [144.5, 157.415], [157.415, 169.82], [169.82, 184.95], [184.95, 197.63], [197.63, 208.7], [208.7, 219.17], [219.17, 230.94], [230.94, 241.94], [241.94, 253.12], [253.12, 263.15], [263.15, 276.65999999999997], [276.65999999999997, 288.35999999999996], [288.35999999999996, 300.28999999999996], [300.28999999999996, 314.59299999999996], [314.59299999999996, 325.246], [325.246, 338.27599999999995], [338.27599999999995, 351.02599999999995], [351.02599999999995, 362.21599999999995], [362.21599999999995, 372.65599999999995], [372.65599999999995, 382.88599999999997], [382.88599999999997, 393.83599999999996], [393.83599999999996, 408.26599999999996], [408.26599999999996, 419.806], [419.806, 432.106], [432.106, 443.805], [443.805, 458.536], [458.536, 472.246], [472.246, 485.236], [485.236, 495.94599999999997], [495.94599999999997, 508.77099999999996], [508.77099999999996, 518.9559999999999], [518.9559999999999, 530.2359999999999], [530.2359999999999, 540.4159999999998], [540.4159999999998, 553.9959999999999], [553.9959999999999, 564.3259999999999], [564.3259999999999, 576.266], [576.266, 586.646], [586.646, 597.261], [597.261, 608.8159999999999], [608.8159999999999, 621.3259999999999], [621.3259999999999, 633.0059999999999], [633.0059999999999, 645.0859999999999], [645.0859999999999, 656.6359999999999], [656.6359999999999, 667.5639999999999], [667.5639999999999, 679.1949999999998], [679.1949999999998, 692.8849999999999], [692.8849999999999, 703.3549999999999], [703.3549999999999, 715.5339999999999], [715.5339999999999, 728.6349999999999], [728.6349999999999, 741.7749999999999], [741.7749999999999, 752.6349999999999], [752.6349999999999, 764.2449999999999], [764.2449999999999, 777.8329999999999], [777.8329999999999, 787.9749999999999], [787.9749999999999, 800.1249999999999], [800.1249999999999, 810.8149999999999], [810.8149999999999, 825.425], [825.425, 836.411], [836.411, 850.2909999999999], [850.2909999999999, 861.781], [861.781, 874.6809999999999], [874.6809999999999, 885.3509999999999], [885.3509999999999, 895.9209999999999], [895.9209999999999, 907.1709999999999], [907.1709999999999, 920.751], [920.751, 932.9309999999999], [932.9309999999999, 944.751], [944.751, 955.04], [955.04, 968.901], [968.901, 980.271], [980.271, 992.7909999999999], [992.7909999999999, 1004.391], [1004.391, 1015.4309999999999], [1015.4309999999999, 1026.461], [1026.461, 1037.481], [1037.481, 1048.611], [1048.611, 1060.711], [1060.711, 1075.601], [1075.601, 1085.971], [1085.971, 1096.701], [1096.701, 1111.761], [1111.761, 1122.261], [1122.261, 1135.291], [1135.291, 1146.8909999999998], [1146.8909999999998, 1157.301], [1157.301, 1171.491], [1171.491, 1184.031], [1184.031, 1196.801], [1196.801, 1211.1309999999999], [1211.1309999999999, 1222.5959999999998], [1222.5959999999998, 1234.2109999999998], [1234.2109999999998, 1247.0209999999997], [1247.0209999999997, 1257.2009999999998], [1257.2009999999998, 1267.4609999999998], [1267.4609999999998, 1280.3909999999998], [1280.3909999999998, 1294.408], [1294.408, 1304.608], [1304.608, 1315.888], [1315.888, 1328.358], [1328.358, 1341.498], [1341.498, 1351.548], [1351.548, 1365.538], [1365.538, 1378.458], [1378.458, 1390.548], [1390.548, 1406.098], [1406.098, 1416.818], [1416.818, 1430.448], [1430.448, 1441.448], [1441.448, 1453.978], [1453.978, 1466.3980000000001], [1466.3980000000001, 1477.3480000000002], [1477.3480000000002, 1491.4080000000001], [1491.4080000000001, 1502.988], [1502.988, 1515.438], [1515.438, 1527.738], [1527.738, 1537.738], [1537.738, 1550.358], [1550.358, 1562.508], [1562.508, 1575.778], [1575.778, 1586.463], [1586.463, 1597.4279999999999], [1597.4279999999999, 1610.5769999999998], [1610.5769999999998, 1621.8669999999997], [1621.8669999999997, 1634.8869999999997], [1634.8869999999997, 1644.9969999999996], [1644.9969999999996, 1657.9369999999997], [1657.9369999999997, 1668.8869999999997], [1668.8869999999997, 1680.5969999999998], [1680.5969999999998, 1694.6369999999997], [1694.6369999999997, 1705.6619999999998], [1705.6619999999998, 1717.8969999999997], [1717.8969999999997, 1730.1969999999997], [1730.1969999999997, 1742.2569999999996], [1742.2569999999996, 1753.5369999999996], [1753.5369999999996, 1767.3269999999995], [1767.3269999999995, 1780.2569999999996], [1780.2569999999996, 1791.3269999999995], [1791.3269999999995, 1801.8069999999996], [1801.8069999999996, 1813.0219999999995], [1813.0219999999995, 1826.1569999999995], [1826.1569999999995, 1838.7369999999994], [1838.7369999999994, 1850.2159999999994], [1850.2159999999994, 1862.4259999999995], [1862.4259999999995, 1872.7449999999994], [1872.7449999999994, 1882.8859999999995], [1882.8859999999995, 1894.7949999999996], [1894.7949999999996, 1906.1859999999997], [1906.1859999999997, 1916.9559999999997], [1916.9559999999997, 1928.0549999999996], [1928.0549999999996, 1938.8559999999995], [1938.8559999999995, 1951.9759999999994], [1951.9759999999994, 1963.4739999999995], [1963.4739999999995, 1974.0249999999994], [1974.0249999999994, 1986.4459999999995], [1986.4459999999995, 1998.3659999999995], [1998.3659999999995, 2008.9059999999995], [2008.9059999999995, 2019.9849999999994], [2019.9849999999994, 2032.1049999999993], [2032.1049999999993, 2042.4559999999994], [2042.4559999999994, 2055.0509999999995], [2055.0509999999995, 2069.1959999999995], [2069.1959999999995, 2081.7059999999997], [2081.7059999999997, 2093.5359999999996], [2093.5359999999996, 2104.9749999999995], [2104.9749999999995, 2120.7249999999995], [2120.7249999999995, 2130.9459999999995], [2130.9459999999995, 2143.7059999999997], [2143.7059999999997, 2155.6449999999995], [2155.6449999999995, 2167.6759999999995], [2167.6759999999995, 2181.7459999999996], [2181.7459999999996, 2192.8559999999998], [2192.8559999999998, 2203.616], [2203.616, 2214.516], [2214.516, 2228.2960000000003], [2228.2960000000003, 2240.8060000000005], [2240.8060000000005, 2253.4660000000003], [2253.4660000000003, 2265.1160000000004], [2265.1160000000004, 2277.606], [2277.606, 2289.206], [2289.206, 2300.456], [2300.456, 2313.176], [2313.176, 2324.826], [2324.826, 2339.185], [2339.185, 2350.086], [2350.086, 2362.145], [2362.145, 2375.196], [2375.196, 2387.776], [2387.776, 2398.786], [2398.786, 2409.078], [2409.078, 2421.096], [2421.096, 2431.956], [2431.956, 2444.4660000000003], [2444.4660000000003, 2455.5660000000003], [2455.5660000000003, 2466.1670000000004], [2466.1670000000004, 2476.2270000000003], [2476.2270000000003, 2486.7470000000003], [2486.7470000000003, 2501.8570000000004], [2501.8570000000004, 2512.0170000000003], [2512.0170000000003, 2527.8570000000004], [2527.8570000000004, 2539.347], [2539.347, 2549.7870000000003], [2549.7870000000003, 2561.0370000000003], [2561.0370000000003, 2572.7670000000003], [2572.7670000000003, 2583.327], [2583.327, 2595.7070000000003], [2595.7070000000003, 2606.9500000000003], [2606.9500000000003, 2619.2870000000003], [2619.2870000000003, 2629.9970000000003], [2629.9970000000003, 2640.2720000000004], [2640.2720000000004, 2651.2070000000003], [2651.2070000000003, 2662.3970000000004], [2662.3970000000004, 2672.9680000000003], [2672.9680000000003, 2684.367], [2684.367, 2698.9170000000004], [2698.9170000000004, 2709.0280000000002], [2709.0280000000002, 2720.6670000000004], [2720.6670000000004, 2731.1980000000003], [2731.1980000000003, 2741.8570000000004], [2741.8570000000004, 2755.2070000000003], [2755.2070000000003, 2769.5170000000003], [2769.5170000000003, 2780.5870000000004], [2780.5870000000004, 2791.0570000000002], [2791.0570000000002, 2801.1070000000004], [2801.1070000000004, 2813.8570000000004], [2813.8570000000004, 2826.3770000000004], [2826.3770000000004, 2837.9480000000003], [2837.9480000000003, 2849.8370000000004], [2849.8370000000004, 2861.7250000000004], [2861.7250000000004, 2876.3050000000003], [2876.3050000000003, 2889.414], [2889.414, 2900.606], [2900.606, 2914.2050000000004], [2914.2050000000004, 2925.3650000000002], [2925.3650000000002, 2935.4950000000003], [2935.4950000000003, 2946.8250000000003], [2946.8250000000003, 2960.0350000000003], [2960.0350000000003, 2971.635], [2971.635, 2982.2850000000003], [2982.2850000000003, 2993.6250000000005], [2993.6250000000005, 3004.6950000000006], [3004.6950000000006, 3014.7960000000007], [3014.7960000000007, 3026.2560000000008], [3026.2560000000008, 3037.6550000000007], [3037.6550000000007, 3047.9050000000007], [3047.9050000000007, 3061.7850000000008], [3061.7850000000008, 3073.5550000000007], [3073.5550000000007, 3086.5060000000008], [3086.5060000000008, 3097.015000000001], [3097.015000000001, 3107.455000000001], [3107.455000000001, 3121.0640000000008], [3121.0640000000008, 3131.2490000000007], [3131.2490000000007, 3143.4590000000007], [3143.4590000000007, 3156.390000000001], [3156.390000000001, 3167.169000000001], [3167.169000000001, 3178.4100000000008], [3178.4100000000008, 3190.4300000000007], [3190.4300000000007, 3201.620000000001], [3201.620000000001, 3212.4790000000007], [3212.4790000000007, 3222.540000000001], [3222.540000000001, 3234.4900000000007], [3234.4900000000007, 3247.9100000000008], [3247.9100000000008, 3258.839000000001], [3258.839000000001, 3269.6800000000007], [3269.6800000000007, 3282.140000000001], [3282.140000000001, 3292.1890000000008], [3292.1890000000008, 3302.2000000000007], [3302.2000000000007, 3315.330000000001], [3315.330000000001, 3327.839000000001], [3327.839000000001, 3340.4790000000007], [3340.4790000000007, 3350.799000000001], [3350.799000000001, 3361.750000000001], [3361.750000000001, 3373.5190000000007], [3373.5190000000007, 3387.109000000001], [3387.109000000001, 3402.4390000000008], [3402.4390000000008, 3416.904000000001], [3416.904000000001, 3430.640000000001], [3430.640000000001, 3439.400000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [316, 658, 827, 1281, 1610, 1850, 2463, 2862, 3130, 3440]}
{"example_id": "mit049@@MIT8_701F20_06_300k", "text": ["MARKUS KLUTE: Welcome back to 8.701.  So in this lecture, we open a new chapter  of weak interaction.  So we are one by one adding together  the components we need in order to describe  all elementary particles and their interactions. ", "And I'll be adding the third form of interaction.  After the QED and QCD, we enter into the discussion  of the weak interaction. ", "So let's have a look at the standard model.  So we discussed gluons and QCD.  And we saw that gluons couple to themselves and also ", "to all quarks.  Because they carry a charge under the--  on the QCD, a color charge.  We have also discussed the photon, ", "and seen that the photon, they do not couple to themselves,  but they couple to all charged elementary particles.  Those are the meta particles, the fermions.  The photon also couples to the W boson. ", "We call it the electrical charge.  So now what we want to do in this next chapter.  We want to fully understand the W and the Z boson.  And we will see that they couple to all meta particles. ", "And we'll also discuss how they might couple to themselves,  or the Z boson couples to the W boson.  Well, that's the story of this entire chapter,  and we'll take it one by one. ", "As an introduction, we start with the Feynman Rules.  So having the Feynman Rules in place, and the cookbooks,  the recipe, in order to calculate decays and scattering ", "processes.  That is all we need in order to get moving.  You can, for example, look at this vertex  here, of this component of the Feynman diagram. ", "And what we need to analyze this is  the propagator for the W and Z boson, and the vertex factor.  ", "This vertex factor now looks a little bit  more complicated than for QED and QCD,  because the W boson and the Z boson, they carry mass. ", "So we have some additional factors. q squared minus M  square.  And this q squared over M squared term as well.  ", "One interesting fact about this vertex factor  is what happens now, is q squared is much, much smaller  than M squared.  We have to get rid of those components here, ", "and we find a vertex factor which  looks similar to the one we have in QED.  However, that's not one over q squared term, but 1 over M  squared term, which is constant. ", "So we would see that we can describe  this in the context of the Fermi theory,  which is a lower energy approximation  of the full theory of heat conduction. ", "It's kind of an interesting concept,  and it extends to the entire understanding  of the standard model.  It might be that our standard model,  you know, that we have all the packages together, ", "describes the lower energy approximation  of a more complicated-- more holistic theory, which we then  can discuss under the concept of a grand unified theory. ", "Maybe there's a symmetry group which  is embedding the symmetry groups we need for QED, QCD,  and the weak interaction.  But that's a side remark. ", "So we will look at the Fermi Theory a little bit more later.  The vertex factor itself, describing the vertex here.  It's given here.  For the W boson, and also for the Z boson. ", "And it looks a little bit more complicated than the vertex  factors we have seen so far.   What you notice that there is the parameter,  which is associated to the strength of the interaction. ", "And the gamma matrix.  But there's also this term here, which has two components.  There's the one, and the gamma 5 matrix.  We have talked about gamma 5 matrix already. ", "And we can later identify those as individual currents  are coupling to vector current and an [INAUDIBLE] current. ", "So this looks even more complicated  now for the Z boson, because here we  have not just numbers of one, but an additional factor. ", "This factor cV is a vector coupling,  and it's specific for each fermion.  So each fermion has one of those constants.  And the second part of the package or set of constants, ", "for the axial current.  You have a second parameter here,  which is the strength of the coupling of the Z boson.  So at this point, you just take this axial, ", "and you can do all our calculation.  On our next slide, I'm going to explain  to you what the corresponding numbers and what d values are  for those parameters cV and cA. ", "Later, we will see how it comes to this more complicated  structure, and why there is a vector,  and why there is an actual axial current  in the weak interaction. ", "But for now, we just take this for granted,  and we just take this as a recipe.  So now for the neutral.  So we've just have seen that this is the vertex factor. ", "And here, for all fermions, we list what  these values are for cV and cA.  What you can see is for the neutrinos, ", "the factor is one half, both for cV and for cA.  And for the charge leptons and quarks,  there is an even more complicated term here, ", "which includes a new parameter.  Sine squared theta w.  The value of this is 28 degrees.  Sine squared theta w is 0.231. ", "As a little bit of a preview here already,  the fact that there is this new parameter and an angle involved  leads to, or can be explained later,  by the fact that the weak interaction is actually ", "a result of a mixing between an original weak interaction,  and QED.  So there's a mixed thing going on. ", "In other words, the Z boson itself  is a mixture between the thing which  couples to the weak part of the particle,  and the part, which couples to the electrically ", "charged part of the particle.  When you see that, that's why there  is a simple factor for the neutrinos who are electrically  neutral, and a more complicated term here for the electrically ", "charged particle.  And you see that this is the electric charge here.  Or two times the electric charge of the particles.  ", "But for now, those are all just constants and recipes  to be used.  One additional word on the history  of the neutral charge of the neutral weak current ", "is given here.  So in the '60s and '70s, the standard model  was slowly developed.  A little bit more slowly than we do in this class here. ", "And there was-- the hypothesis is  that there have to be something like a neutral current  in there.  But it has never been observed in nature.  And so this bubble chamber, specifically the one ", "Gargamelle at CERN, one was able to actually see those, see  virtual and really see, those interactions  for the first time.  And the first pictures that have been taken in the 1970s, 1973. ", "And this picture here illustrates--  I will expand it in a second--  illustrates the interaction of a neutrino  coming into the bubble chamber, making an interaction ", "with an electron, and then scattering off, kicking off  the electron.  So what you see here is this incoming--  this is an anti-neutrino kicking off an electron. ", "See the electron here.  The neutrino goes off undetected.  It just disappears.  You see here, the electron.  And then there's also two protons. ", "One proton here.  Let's use a different color.  And one photon here.  Causing electron positron pair, and the second photon  here doing the very same thing. ", "You can see those particles here.  See here and then going on here as well.  So this is a bubble chamber picture. ", "We'll talk about bubble chambers very briefly  later in the lecture as well.  But they're very extremely important and useful tools  in order to illustrate--  to visualize and measure particle interaction. ", "MARKUS KLUTE: Welcome back to 8.701.  So in this section, we look at electroweak unification.  So the aim is to combine the weak  and the electromagnetic interactions.  The issues we can see here are first, ", "the strength of the interactions are very different.  This can be mitigated by the fact  that we have heavy gauge bosons involved,  and we have seen our heavy particles  as being used as mediators to kind of change ", "the strength of the interaction.  So this might not be a big issue.  The second problem is that the structure of the coupling  is very different.  We have seen for QED that they are the vector coupling ", "and for weak interaction that they  are the vector-axial coupling.  This 1 minus gamma 5 is vector minus axial coupling.  So one way to mitigate this problem ", "is to simply absorb this 1 minus gamma 5 term in the definition  of the particle spinors.  And I have to warn you, this is a little misleading. ", "And I think that led also to some of the confusion we  had in the class before.  So what we are doing here simply is, we take our spinor, ", "and we project out with the 1 minus gamma 5 term  what the left-handed component of this spinor is.  This is just a projection and the definition of this. ", "And we can do this for antiparticles as well as  for the right-handed components as well.  Good.  So now we can look at the current again.  And we look at this weak current that you have seen you can ", "write as our antineutrino here, gamma mu times 1 minus gamma 5  1/2 times e.  Now, if we now define our particles which gamma matrices, ", "we find that this simplifies quite a bit,  because we now find the current, which can be simply written  as a vector current.  So we mitigated this quite nicely. ", "So what now happens to our electromagnetic interaction  here?  So we have an electron coupling to a photon.  We can project out a right-handed and left-handed  component, and then we have to add them together again. ", "When we do this, you find that this component  of the left-handed component, or the current  corresponding to the left-handed particle ", "and the current corresponding to the right-handed particle.  There's no mixed term here because  of the way gamma matrices or gamma 5 matrices multiply.  So that's nice. ", "This also explains why the helicity is not changed in QED.  You basically see this from the algebra  involved in those equations. ", "Good.  So far, we haven't done anything.  We have just changed the notation.  So we can go one step further.  And we use the concepts we introduced ", "when we talked about QCD or the strong isospin.  And since we can nicely describe those currents here  of those particles, we can maybe see  if we can write a neutrino and an electron ", "as part of a duplet.  And when we do this, we rewrite the currents,  the positively charged and the negatively charged current  as simply the left-handed components of those duplets. ", "We introduced a new matrix here, tau plus and tau minus.  And they're simply combinations of tau 1 and tau 2,  which are, in fact, the Pauli matrix.  This is just a relabelling as well. ", "So there's a lot of relabelling going on, not to confuse you.  But we have simply written this current  as positively charged weak current  and negatively charged current, where ", "we rotate a neutrino into an electron or an electron  into a neutrino using the weak interaction.  Great.  So now we can write this current here ", "as the third component of this current.  And we see when we write down the third component  of this current using tau 3 here,  we find that something looks--  something which looks like a neutral current. ", "So this is something like a neutral current, where  we have a neutrino coupling to a neutrino  and a left-handed electron coupling  to a left-handed electron, on a vertex vector ", "[?] where there's an interaction that was going on.  This is not quite the full story yet.  Let me remind you about the definition  we used also in isospin, which is ", "the Gell-Mann-Nishijima equation, which connected  the electric charge to the isospin and the strangeness  of the particle. ", "And we do the very same thing.  We have an isospin component and a so-called hypercharge  component.  It's similar to the strangeness we had before.  And Q is the electric charge of the particle involved. ", "And so with this, we can now define an iso--  a hyperspin current, which is given as 2 times  the electromagnetic current minus 2 times  the third component of the-- ", "third component of the weak current here.  And so now we find interesting effects here.  There's a new component which also couples  to right-handed particles. ", "So the missing part here--  some of you might have seen this already--  is this neutral current in the upper equation  didn't connect or didn't have a contribution  from right-handed particle. ", "And since there's right-handed electron which  coupled to Z boson, there needed to be  this kind of additional term.  So now we have a current which includes ", "the right-handed particles as well.  So that's great.  We can generalize this by writing those duplets  for all particles we know.  There's an additional kind of caveat here. ", "We haven't talked about this too much.  We have to consider the fact that mass eigenstates are not  really the same eigenstates which participate  in the weak interaction.  Right now we can ignore this. ", "We'll later come back to this question.  And then we can write the three components  of our isospin current and our hypercharge current as well. ", "Note that this EM current here is our electromagnetic current.  Good.  So now we rewrote this, and we find somehow very close ", "a consistent picture.  We find that there is a charged current,  and then there is a neutral current  in the weak interaction.  But what we actually wanted to do ", "is combine the weak interaction and  electromagnetic interaction.  Now, let's look at this again and start over again.  So we have an isospin current here,  which copies to the three components-- ", "the triplet, the isospin triplet.  So this is a W1, W2, W3 triplet.  And then we have the singlet here ", "which couples to the hypercharge.  Very good.  So now, if I try to identify now components which we already  know the first thing we can do, we ", "have to make sure that we find our W plus and W minus  bosons again.  And they're simply linear combinations  of the W1's and the W2's. ", "And then the next thing I have to do  is I have to find my electromagnetic interaction.  And we can do that by binding this A-- this is the photon-- ", "as a linear combination of the third component  of our triplet, isospin triplet, and our singlet.  And what you see here is that there's actually ", "mixing going on.  So we basically rotate those with this mixing angle, which  we already introduced, sine omega weak ", "mixing angle theta omega--  sorry, theta W.  So we find that the photon can be made out  of a mixing of the third component of the isospin ", "triplet and the singlet component B mu.  And similarly, we can find the Z boson  as the other component in this mixing, the other state we ", "find in this mixing.  The way we find those mixings here  is through the couplings we already know,  that we find this omega g times sine ", "theta W is equal to g prime cosine omega W.  And that's equal to the electromagnetic coupling. ", "And then similarly, we find a solution for gz.  So what we have seen now is that apparently we  are able to combine the weak and the electromagnetic interaction ", "by mixing--  by introducing the weak isospin and by mixing isospin triplet  components with a singlet component.  And so we find a picture which is ", "consistent with the W plus, a W minus photon, and the Z boson.  So that's very nice.  MARKUS KLUTE: Welcome back to 8.701.  So now after we introduced the weak interaction ", "and the Feynman rules for weak interaction,  we can now look at decays of muons, and in this case,  the decay of a pion.  Decay of the pion is specifically interesting.  And we discussed the decay of the pion ", "before when it came to the discussion of helicity states.  Now, let's look at this again with the information we have  and what we learned.  Now, if you look at the pion decay, ", "the two or three leading decay modes are given here.  The one is where the pion, in this case a negatively charged  pion, decays into an anti-electron neutrino ", "and an electron, or V or the W in a muon and an antimuon  neutrino.  If you look at this in the rest frame of the pion, ", "we can see that the neutrino and the lepton, charged lepton,  are produced back-to-back.  Now, the spin of the pion is 0, which  means that the opposite-direction outgoing ", "leptons have to have the same helicity states.  Since the neutrino is massless, the antineutrino is massless,  the antineutrino is produced right-handed. ", "It is always right-handed.  The chiral state of the neutrino and the helicity state  of the neutrino are essentially the same,  because they're massless.  Means the projection of the spinor ", "is basically the same as a projection  of the spin on the momentum [? direction. ?]  All right.  But the charged lepton is massive. ", "If the charged lepton would be massless,  the decay would not be allowed.  There would not be a right-handed helicity  state for a charged lepton. ", "Now, this causes quite some confusion.  And I've seen, even in this course, some students being  confused by this.  I can write the, let's say, right-handed charged lepton ", "and decompose its right-handed helicity state.  So this is, let's say, the right-handed helicity state.  ", "And I can decompose this through the chiral states,  the right-handed and the left-handed.  And you have seen in the previous lectures  that only the left-handed component participates. ", "Now, you can also see from this equation  here that if the momentum and energy would be the same,  as it is the case for massless particle, this would be 0,  this would be 1, this would be 1. ", "And therefore, this right-handed helicity state  would be the same as the chiral state,  and it wouldn't be coupling to the weak interaction. ", "Now let's erase this really quickly,  because you want to actually look at this decay.   And so now we have all the tools together-- almost all the tools  together to calculate this, the decay rates, ", "or the ratio of decay rates.  And you want to do this in the pion rest frame,  so the momenta are given here.  See that the pion momentum is 0. ", "And for momentum, the energy is equal to the mass  for the charged lepton.  And for the neutrino, just produce  in an opposite direction.  So neutrino in this case goes into negative d direction. ", "Then we can write the leptonic current,  as we have just seen in the previous lecture.  You see this 1 minus gamma 5 term here. ", "Good.  And I could have just called this left-handed here  and put this into the definition of the spinor.  Fine.  When we put a real spinor, this comes out immediately ", "[INAUDIBLE].  Immediately.  You have to keep this in mind.  The matrix element, then, is a little bit more complicated.  And here is an additional-- so you see the current here again. ", "You see the propagator, and I went  into the low-energy approximation here.  You see that instead of having a [? q ?] square minus m square,  I'm just keeping the m square component of this. ", "And then I have this part here for the current, for the pion  current here.  And I simply parameterize my missing understanding  or missing ability to calculate [? non-prohibitive ?] QCD with ", "a form factor.  So I introduce this form factor for a pion.  This is not an important part of the discussion,  we just keep track of this here.  All right.  Then we can calculate this matrix element fine. ", "We then have to be explicit about the spinors we are using,  and we use the momentum as defined above.  So this step here I'm not doing explicitly.  If you want, you can go to Thomson and read in chapter 11. ", "He gives quite some detail on this.  All right.  So moving on, there is one extra thing.  When we try to calculate the spin-averaged matrix element, ", "we find that we don't have to do any work because there's  a spin [? 0 set, ?] there's only one state contributing,  so we don't have to do any work.  We just have to square the matrix element. ", "We find this as a solution here, and there's  an additional factor we haven't introduced yet.  This is the Fermi coupling.  Again, this comes out in the low-energy approximation. ", "And G Fermi is simply defined over the coupling to the W  over the W mass squared, as shown here.  All right. ", "Again, this is just a factor which  is not relevant to the discussion at this point.  But we can then, using Fermi's golden rule,  calculate the partial decay width of the pion decay. ", "OK?  So we just put in the matrix element here,  and we replace the momentum with the energy,  being equal to the mass of the pion. ", "And voila-- we get this as an answer for the partial decay  width.  OK?  If you now want to know some experimental information,  like the partial decay width of the pion, ", "charged pion, to electrons over the muon,  you want to know what this factor is, we immediately  can do this.  We don't need to know any of the details F, G Fermi  as a structure function of the pion. ", "All of those factors cancel out.  And what is left here are the parameters  of the electron mass, the muon mass, and the pion mass.  And if you just use values like this, ", "the mass of the muon with 205 MeV  and the mass of the pion 240 MeV, you find 10 to the minus 4 ", "as a value for this ratio of part [? indicators. ?]  And you see where this comes from.  This basically comes from the fact  that the electron mass is much, much smaller ", "than the mass of the muon.  And factually, you can expand this by the fact  that a right-handed helicity state for a muon  can have a much larger contribution ", "of the left-handed chiral state of a muon, while this is not  possible-- or, that is, the component  is much smaller for the lighter electron.  And again, only the left-handed component of the charged lepton ", "contributes to the weak interaction.  So in this lecture, we look at the interaction of W bosons  with quarks, or the charged weak interaction of quarks.  Let's just make a number of observations. ", "Now, we observe that the weak interaction respects the lepton  generation, meaning that a W couples  to an electron and an electron neutrino,  but not an electron muon neutrino. ", "But in the case of the quarks, there is violation of this.  So there is a disrespect of the quark generation  when it comes to the interaction with Ws. ", "So when you investigate these two diagrams here,  you find that the W couples to the V quark and the U quark,  but it also couples to the S quark. ", "S quark and the U quark, all right?  In order to encapsulate this, we have to make a correction.  And the corrections are typically  called cosine theta C and sine theta C. Theta ", "C is the Cabibbo angle, so theta Cabibbo.  Turns out this is rather small, so it's a decrease.  So it is a correction, a small correction.  We studied the partial decay width ", "of the kaon in leptonic decays over the partial decays  to a pion of the pion in leptonic decays.  We found that there is a set of forms  that are the form factor for the pion decay ", "and a form factor for the kaon decay.  It turns out that the form factors are  due to this additional correction,  so you find the tangent-square of the Cabibbo angle ", "as part of this correction.  Good.  So far, so good.  Now we have made an observation.  We haven't explained anything yet.  We can make one more observation, or discuss one, ", "and that's the decay of neutral kaons to a pair of muons.  It turns out that those are not very likely.  Even so, you would expect that the amplitude has a factor here ", "of sine and cosine of Cabibbo, so the amplitude  should be on the order of sine theta Cabibbo times cosine  theta Cabibbo. ", "So when this was studied, the charm quark  hadn't been discovered.  And the explanation to why this decay is suppressed ", "comes from the fact that there is a second diagram here,  where we just replace the U quark in this rule with a C  quark.  This diagram contributes there's a minus sign to the amplitude. ", "And therefore, those two diagrams, they cancel.  Right?  They are the same magnitude, about the same magnitude,  and they have an opposite sign.  So this was the first indication that there ", "must be a force quark contributing  to this kind of process.  That's the charm quark.   Let me now try to understand what's going on here. ", "Why is the W coupling modified?  Or why is not the full down quark or charm  and strange quark participating in the weak interaction? ", "We can do the following here.  We can rewrite-- we note that the weak interaction  eigenstate, the eigenstate which participate in the [INAUDIBLE],, ", "is not the eigenstate of the particle  itself, the so-called mass eigenstate.  So we have to write the weak eigenstate  as the linear combination of the mass eigenstate or [INAUDIBLE].. ", "This can be done in this matrix form  here, where we simply multiply the weak eigenstates  with a matrix, and just basically rotate it ", "into the mass eigenstate.  So this was proposed by Cabibbo, and rather successful.  But it didn't incorporate the third-generation particle. ", "And this was done by Kobayashi and Maskawa,  who generalized the scheme and proposed the so-called CKM  matrix, the easier form Cabibbo-- ", "Cabibbo, Kobayashi, and Maskawa.  Because of constraints we'll discuss  in one of the recitations, this matrix ", "can be parameterized as only three independent angles  and one complex phase as independent parameters.  So you can choose different parameterization ", "to capture that there's only four parameters in this matrix,  which has nine components.  One is by thinking about this matrix ", "as three independent rotations and this complex phase here.  In terms of numerical values, you  see that the diagonal elements of this matrix ", "are very close to 1, meaning that this mixing is  on the block sector of the [INAUDIBLE] effect.  You find that those next-nearest off-diagonal elements are ", "on the order of 20%, and the next-to-next off-elements  are even smaller.  OK?  This leads us, then, to the discussion ", "that we can use different parameterization in order  to capture [INAUDIBLE].  We already discussed the standard parameterization,  which you can really think about three different rotation. ", "And the values of those angles are give here, together  with the value of this additional phase.  Another way to look at this is the so-called Wolfenstein ", "parameterization.  And this captures the fact that it  seems like that there's a correction being  applied to the actual particle.  So you find elements of the order of lambda. ", "Lambda is about 22%.  And you find elements which are in the order of 1  minus the lambda-square correction.  And then there is elements which are of lambda-square and lambda ", "3rd power.  So this captures the matrix, and then there's  higher-order corrections to that which are of order lambda  to the 4th power. ", "OK?   Because there's constraints on this matrix-- and specifically,  unitarity constraints, meaning that we have three generations ", "that will make a mixing of those three mass eigenstates  to weak eigenstate-- then unitarity, the total number  of particles in this discussion, is conserved. ", "This will change if there would be, for example, a force  generation particle.  So the study of weak-charged interaction with quarks  helps us to understand whether or not there  might be a force generation. ", "We'll not go into too much detail here,  but also, the complex phase explains  part of our understanding of CP violation.  And we might discuss this in a little bit of a later lecture. ", "But nevertheless, what we can achieve from here  is those unitarity constraints, just simply  summing over the matrix elements, ", "the scalar product of matrix elements.  And those where the contribution vanishes,  so those where j and k are not equal, ", "those can be represented as a triangle.  That's kind of interesting.  You can just rewrite this.  You just say that those three elements of the sum  are equal to 0. ", "Then you normalize by one element.  In this case here, normalize by Vcd, Vcb.  And so then this makes this point being 0, ", "and so we have this nice triangle  here, which has three angles, alpha, beta,  and gamma, and this point here, rho and eta. ", "And so this is a nice way to illustrate  actual measurements of the elements of the CKM  matrix [INAUDIBLE].  And without actually explaining how we do this experiment, ", "you can assume that all measurements have--  well, you can understand that all measurements  have to do with the weak interaction with quarks.  That's how we have access to the CKM matrix elements. ", "Sometimes this results in the modification of masses  or splitting of mass states, and sometimes  the direct measurement cause a recoupling. ", "When you put all of those measurements back together,  you can look at this.  So we see our triangle here.  We see this point, eta and rho, which is given here ", "in this right-angular plane.  And you see various number of measurements which correspond  to elements of this CKM matrix. ", "In this short section, you're going  to look at the weak interaction a little bit more,  and specifically discuss neutral currents.  We looked in some detail at charged currents--  specifically, the interaction with quarks. ", "So here, I'm going to look at the Z boson specifically,  and the weak interaction via the neutral current.  So studying those two processes here, ", "where there is an electron and a positron  through some process including a Z boson and a photon  and resulting in a muon and an anti-muon--  those processes have been studied in great detail ", "at SLAC and at CERN, at the SLC, and the Large Electron-Positron  Collider.  So if we want to calculate the cross-section ", "and study the cross-section of the center of mass energy,  we see a number of interesting effects.  At low energies, and at very large energies, ", "the cross-section runs with 1 over the energy squared.  But at the mass of the Z boson, we see this enormous resonance  here. ", "The cross-section at the resonance from the Z boson  is about 200 times that of just a photon exchange.  So this allows you to study the Z boson with great precision ", "at those colliders.  You have sizable cross-section when you are  in electron-positron colliders.  And then you can, with precision,  look at, what is the rate into a muon/anti-muon?  What is the rate into a quark/anti-quark? ", "And so on.  And you can study the mass, the width of the Z boson  with an enormous level of precision.  Again, so I will not go into too much detail here. ", "And please have a look at chapter 9.6 in Griffiths,  for example.  But there's many other resources where you can learn more  about [? neutral ?] currents. ", "Neutral currents, electroweak neutral currents  are specifically important in the study of neutrinos,  as we will discuss more in the lectures as well. "], "vid_duration": [12.645, 10.205, 10.32, 10.61, 11.31, 14.49, 11.34, 10.14, 14.47, 12.93, 10.38, 11.95, 11.49, 11.2, 12.57, 10.89, 14.67, 12.24, 13.233, 14.907, 12.36, 11.69, 11.35, 12.53, 10.777, 11.583, 10.718, 10.292, 10.47, 11.38, 14.08, 13.68, 10.28, 12.8, 12.33, 10.63, 10.5, 10.71, 12.09, 14.28, 10.8, 11.58, 11.649, 11.921, 10.16, 14.65, 11.61, 14.46, 10.65, 14.25, 10.209, 10.48, 10.431, 14.25, 16.93, 13.45, 11.839, 10.23, 11.25, 10.291, 11.12, 13.68, 15.675, 11.155, 10.849, 13.0, 11.861, 10.071, 10.639, 10.09, 13.13, 13.89, 10.47, 11.73, 10.02, 11.95, 10.44, 11.16, 10.02, 11.97, 11.145, 10.375, 11.69, 12.19, 10.47, 10.679, 10.35, 12.031, 11.07, 10.424, 10.426, 12.81, 10.86, 10.845, 11.671, 11.099, 10.711, 10.23, 13.32, 11.73, 12.84, 10.44, 11.16, 15.79, 11.63, 13.489, 11.971, 10.54, 13.86, 10.05, 12.14, 10.14, 11.88, 10.26, 12.72, 12.03, 11.84, 18.47, 13.8, 10.107, 12.633, 10.39, 15.12, 10.64, 11.76, 11.05, 14.099, 11.461, 12.21, 13.38, 15.57, 12.782, 11.52, 11.71, 12.349, 12.331, 12.3, 11.22, 10.5, 12.78, 14.73, 10.619, 10.53, 15.351, 11.49, 10.26, 11.899, 10.03, 13.21, 12.21, 11.611, 11.188, 12.152, 11.069, 10.02, 11.23, 10.395, 10.335, 10.711, 11.74, 10.97, 12.079, 11.171, 13.25, 12.359, 12.091, 13.631, 12.296, 10.002, 10.021, 12.04, 11.32, 11.089, 12.471, 11.68, 13.119, 12.876, 12.82, 10.529, 11.131, 10.139, 10.111, 10.77, 12.989, 10.951, 11.009, 10.591, 9.077], "stet": [[0, 12.645], [12.645, 22.85], [22.85, 33.17], [33.17, 43.78], [43.78, 55.09], [55.09, 69.58], [69.58, 80.92], [80.92, 91.06], [91.06, 105.53], [105.53, 118.46000000000001], [118.46000000000001, 128.84], [128.84, 140.79], [140.79, 152.28], [152.28, 163.48], [163.48, 176.04999999999998], [176.04999999999998, 186.94], [186.94, 201.60999999999999], [201.60999999999999, 213.85], [213.85, 227.083], [227.083, 241.99], [241.99, 254.35000000000002], [254.35000000000002, 266.04], [266.04, 277.39000000000004], [277.39000000000004, 289.92], [289.92, 300.697], [300.697, 312.28000000000003], [312.28000000000003, 322.99800000000005], [322.99800000000005, 333.29], [333.29, 343.76000000000005], [343.76000000000005, 355.14000000000004], [355.14000000000004, 369.22], [369.22, 382.90000000000003], [382.90000000000003, 393.18], [393.18, 405.98], [405.98, 418.31], [418.31, 428.94], [428.94, 439.44], [439.44, 450.15], [450.15, 462.23999999999995], [462.23999999999995, 476.5199999999999], [476.5199999999999, 487.31999999999994], [487.31999999999994, 498.8999999999999], [498.8999999999999, 510.5489999999999], [510.5489999999999, 522.4699999999999], [522.4699999999999, 532.6299999999999], [532.6299999999999, 547.2799999999999], [547.2799999999999, 558.8899999999999], [558.8899999999999, 573.3499999999999], [573.3499999999999, 583.9999999999999], [583.9999999999999, 598.2499999999999], [598.2499999999999, 608.4589999999998], [608.4589999999998, 618.9389999999999], [618.9389999999999, 629.3699999999999], [629.3699999999999, 643.6199999999999], [643.6199999999999, 660.5499999999998], [660.5499999999998, 673.9999999999999], [673.9999999999999, 685.8389999999999], [685.8389999999999, 696.069], [696.069, 707.319], [707.319, 717.61], [717.61, 728.73], [728.73, 742.41], [742.41, 758.0849999999999], [758.0849999999999, 769.2399999999999], [769.2399999999999, 780.0889999999999], [780.0889999999999, 793.0889999999999], [793.0889999999999, 804.9499999999999], [804.9499999999999, 815.021], [815.021, 825.66], [825.66, 835.75], [835.75, 848.88], [848.88, 862.77], [862.77, 873.24], [873.24, 884.97], [884.97, 894.99], [894.99, 906.94], [906.94, 917.3800000000001], [917.3800000000001, 928.5400000000001], [928.5400000000001, 938.5600000000001], [938.5600000000001, 950.5300000000001], [950.5300000000001, 961.6750000000001], [961.6750000000001, 972.0500000000001], [972.0500000000001, 983.7400000000001], [983.7400000000001, 995.9300000000002], [995.9300000000002, 1006.4000000000002], [1006.4000000000002, 1017.0790000000002], [1017.0790000000002, 1027.429], [1027.429, 1039.46], [1039.46, 1050.53], [1050.53, 1060.954], [1060.954, 1071.3799999999999], [1071.3799999999999, 1084.1899999999998], [1084.1899999999998, 1095.0499999999997], [1095.0499999999997, 1105.8949999999998], [1105.8949999999998, 1117.5659999999998], [1117.5659999999998, 1128.6649999999997], [1128.6649999999997, 1139.3759999999997], [1139.3759999999997, 1149.6059999999998], [1149.6059999999998, 1162.9259999999997], [1162.9259999999997, 1174.6559999999997], [1174.6559999999997, 1187.4959999999996], [1187.4959999999996, 1197.9359999999997], [1197.9359999999997, 1209.0959999999998], [1209.0959999999998, 1224.8859999999997], [1224.8859999999997, 1236.5159999999998], [1236.5159999999998, 1250.0049999999999], [1250.0049999999999, 1261.9759999999999], [1261.9759999999999, 1272.5159999999998], [1272.5159999999998, 1286.3759999999997], [1286.3759999999997, 1296.4259999999997], [1296.4259999999997, 1308.5659999999998], [1308.5659999999998, 1318.706], [1318.706, 1330.586], [1330.586, 1340.846], [1340.846, 1353.566], [1353.566, 1365.596], [1365.596, 1377.436], [1377.436, 1395.906], [1395.906, 1409.706], [1409.706, 1419.8129999999999], [1419.8129999999999, 1432.446], [1432.446, 1442.836], [1442.836, 1457.956], [1457.956, 1468.596], [1468.596, 1480.356], [1480.356, 1491.406], [1491.406, 1505.5049999999999], [1505.5049999999999, 1516.966], [1516.966, 1529.176], [1529.176, 1542.556], [1542.556, 1558.126], [1558.126, 1570.908], [1570.908, 1582.4279999999999], [1582.4279999999999, 1594.138], [1594.138, 1606.4869999999999], [1606.4869999999999, 1618.8179999999998], [1618.8179999999998, 1631.1179999999997], [1631.1179999999997, 1642.3379999999997], [1642.3379999999997, 1652.8379999999997], [1652.8379999999997, 1665.6179999999997], [1665.6179999999997, 1680.3479999999997], [1680.3479999999997, 1690.9669999999996], [1690.9669999999996, 1701.4969999999996], [1701.4969999999996, 1716.8479999999997], [1716.8479999999997, 1728.3379999999997], [1728.3379999999997, 1738.5979999999997], [1738.5979999999997, 1750.4969999999996], [1750.4969999999996, 1760.5269999999996], [1760.5269999999996, 1773.7369999999996], [1773.7369999999996, 1785.9469999999997], [1785.9469999999997, 1797.5579999999998], [1797.5579999999998, 1808.7459999999999], [1808.7459999999999, 1820.898], [1820.898, 1831.9669999999999], [1831.9669999999999, 1841.9869999999999], [1841.9869999999999, 1853.2169999999999], [1853.2169999999999, 1863.6119999999999], [1863.6119999999999, 1873.947], [1873.947, 1884.658], [1884.658, 1896.398], [1896.398, 1907.368], [1907.368, 1919.447], [1919.447, 1930.618], [1930.618, 1943.868], [1943.868, 1956.2269999999999], [1956.2269999999999, 1968.3179999999998], [1968.3179999999998, 1981.9489999999998], [1981.9489999999998, 1994.245], [1994.245, 2004.2469999999998], [2004.2469999999998, 2014.2679999999998], [2014.2679999999998, 2026.3079999999998], [2026.3079999999998, 2037.6279999999997], [2037.6279999999997, 2048.7169999999996], [2048.7169999999996, 2061.1879999999996], [2061.1879999999996, 2072.8679999999995], [2072.8679999999995, 2085.9869999999996], [2085.9869999999996, 2098.863], [2098.863, 2111.683], [2111.683, 2122.212], [2122.212, 2133.343], [2133.343, 2143.482], [2143.482, 2153.593], [2153.593, 2164.363], [2164.363, 2177.352], [2177.352, 2188.303], [2188.303, 2199.312], [2199.312, 2209.903], [2209.903, 2218.98]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [547, 1101, 1560, 2099, 2219]}
{"example_id": "mit049@@MIT8_701F20_08_300k", "text": [" MARKUS KLUTE: Welcome back to 8.701.  In this chapter, we will talk about neutrinos.  And we'll start the discussion with a relatively simple  introduction.  How does a neutrino look in the standard model, ", "and how does it interact?  We have discussed the neutrino already quite a bit.  So this is more or less a summary.  In the standard model, the neutrino is massless. ", "It's a massless particle.  And it interacts with a weak direction.  So it interacts with w bosons and with z bosons.  And specifically, it does not interact  with photons of gluons. ", "If we look at the Lagrangian or try to write down the current,  we find that there is a charged current via the w.  And there is a neutral current, we have the z boson.  It's quite interesting to think about those two currents ", "a little bit more.  So in case of a charged current, for example,  I have an incoming neutrino, we can determine the flavor, ", "the kind of neutrino we have.  We are detecting the flavor of the lepton.  So if, for example, identify an electron in this interaction ", "in the interaction, the initial neutrino  was an electron neutrino.  While for the neutral current, when we have some sort  of interaction happening, we cannot identify directly ", "the neutrino.  Hence, we cannot find the flavor of the neutrino.  You can just measure the sum of all flavors of neutrinos  in the neutral current. ", "On that story, neutrinos have three flavors.  They come in electron flavor, muon favor, or tau flavor.  Neutrinos are left-handed.  Anti-neutrinos are right-handed. ", "So that's the story.  That's how neutrinos are characterized  in the standard model.  In the standard model, in the framework we set up, ", "we can calculate cross-sections, scattering cross-sections.  And here, we are looking in the neutrino nuclei scattering.  Again, we can split this up in the charged current and neutral ", "current discussion.  But they go very much in parallel.  So we have elastic scattering.  Or in the case of the charged current,  we talk about quasi-elastic scattering. ", "Then we have an incoming neutrino,  let's say a muon neutrino, hitting a neutron,  producing a muon and a proton.  It's called quasi-elastic, because we do not  break up the target, but we change its kind. ", "So we change from a neutron to a proton, in this case.  While, for the elastic scattering,  the neutron just stays intact.  We can also have nuclear resonance production, ", "where we hits the nuclei.  And then inside the nuclei, we could use a [INAUDIBLE],,  like a neutral or a charged [? pion. ?]  And also, that's possible in the neutral current exchange. ", "And then we have deep-inelastic scattering,  where we hit a nuclei or nucleon that hard,  that we'd start breaking it up.  And in this case, we scatter off the quark, ", "and we produce a new quark in the charged current interaction  in the same quark in the neutral current interaction.  So this is no different from the stories we had before. ", "The intriguing part about studying neutrino scattering  is that we do know that we have weak interactions being--  we use a dominant force of being the process. ", "While, if we use photons to interact,  or we have electrons being [INAUDIBLE],,  then we can have a mixture of weak and electromagnetic ", "interaction.  Another important takeaway from this slide  is that, when we calculate cross-section,  we find that a linear increase in the cross-section  of the function of the energy.  So while cross-sections for neutrinos are small, ", "at higher energy source cross-sections scale linearly.  As we can discuss this for neutrino scattering with nuclei  and nucleons, we can also look at neutrino scattering ", "with electrons directly.  There's a lot of electrons in the metal around us.  And the neutrino [INAUDIBLE] with this metal that can  interact with electrons, too.  And they can live in the charged current interaction of muon ", "in an electron neutrino and in a neutral current interaction  in electron in the [INAUDIBLE].  Also, here, you see cross-section, total  cross-section scaled with [INAUDIBLE] energy. ", "Good.  It's the first introduction to neutrino physics.  In this section we want to look at how we can theoretically  describe masses of neutrinos. ", "There is not just one way to do this  and the judge is still out there which one is actually  realized in nature, or perhaps both are realized in nature.  So mass terms can be constructed by introducing ", "so-called sterile neutrinos.  The first way, and it's shown here in the Lagrangian,  is very familiar to you where you  have a left-handed component of a particle ", "coupling via the Higgs boson to a right-handed component.  Now, if we now have a right-handed component  or right-handed neutrino, that neutrino does not ", "interact with the weak interaction  and doesn't interact with any other interaction we know.  Hence, this neutrino, this right-handed particle  is a sterile neutrino. ", "It's not interacting in any of known ways other  than with the Higgs field with the rest of the standard model. ", "The second part, the second way the mechanism is using Majorana  particles, particles which are their own antiparticles,  and we'll look in how this is being implemented. ", "So again, the first, the Dirac term  is generated after electroweak symmetry breaking  from Yukawa interactions.  We have seen the very same thing for our charged leptons. ", "What we see here is that the lepton number is conserved.  Before and after the interaction we  have the same number of leptons, but the lepton flavor is not ", "conserved in this interaction.  We can rewrite this.  We identify the sterile neutrino as the right-handed component  of the spinor.  I mentioned this already, and we basically ", "couple the weak-doublet components  as you would just expect that to appear.   The second term, the Majorana mass term, ", "is interesting as we introduce another singlet  into the standard model.  So this then can appear as a bare mass  term with some consequences. ", "So here what we are trying to do is  we are involved two neutrinos, right-handed fields.  Those break the lepton number.  So if those neutrinos are realized in nature, ", "we have to observe lepton--  we should observe lepton number-violating processes.  And so the search for the specific kind of neutrino  is through searching for lepton number-violating processes. ", "So we can rewrite this part of the Lagrangian,  this part of the math term here using this matrix.  Let's see how this unfolds.  If the math term now is much, much larger, or larger ", "than the electroweak scale, you can  try to diagonalize the master and it  leads to three neutrinos, three light neutrinos,  three light neutrinos you would expect, ", "and one potentially-- one potential, or maybe  multiple potential heavy neutrinos.  If you then rewrite the math term  you find for the light ones, the term which goes ", "is 1 over the scale of this [? known ?] neutrino.  That is a nice motivation for this kind of physics  as it automatically reduces the amount of the neutrino ", "as we observe the math is to be very small in nature.  And then the mass of the heavy neutrino  is proportional to the mass.  This mechanism is called see-saw because it automatically moves ", "the scales of those two neutrinos,  the heavy ones and the light one apart so you happen to observe  the heavy one, maybe because they're very, very heavy, ", "and the light ones have light mass because of this mechanism  of being proportional to 1 over the mass scale--  the mass eigenstate of those neutrinos. ", "However, if the mass scale of those eigenvalues is much--  not higher than the electroweak scale,  the low energy spectrum contains these additional light states. ", "So you have not just the three light neutrinos but you  have additional light scales--  states which mix with these three light neutrinos.  And that is kind of an interesting area ", "to look for these particles as they would lead  to small deviations in observed electroweak  efficient properties, and they might ", "yield to some interesting decays in nuclear physics,  and we'll come to those specifics later.  We have seen in this lecture two different ways  to generate masses.  One's to recover interactions, same ", "as the interaction with the Higgs field, and one,  we have the see-saw mechanism introducing Majorana neutrinos.  We have seen in the previous video  how neutrinos can acquire mass. ", "When they have mask, [\"mass\"?] their weak eigenstate is not  equal to their mass eigenstate.  So we observe the same mixing as we  have seen in the quark sector.  So let's review this a little bit. ", "So just starting from two neutrino generations,  we can write the flavoring states.  We are mixing of mass eigenstate.  If we do this, it's a simple matrix. ", "You find that there is one angle used  for the rotation of the mass eigenstate  into the flavor eigenstate.  All right. ", "So we can add some time to 0, write our neutrino  or our muon neutrino as a combination of the 1 and 2  mass eigenstates.  If we then have this neutrino evolve as time, ", "we see that the relative contribution of the 1 and 2  mass eigenstate actually changes.  So if we do that, so obviously you find some time evolution. ", "If we then ask ourselves, what is the probability  that we start from a muon neutrino  that we actually find in an interaction electron neutrinos. ", "Through this mixing of mass eigenstates,  we can calculate this probability  just by squaring the amplitudes.  If you do this, you just use this part here. ", "We find that there is a cosine E2 minus E1 term.  All right.  Good.  So let's analyze this a little bit further.  We know that the masses need to be small. ", "So one thing we can also do here is  do a Taylor expansion of our energy and then  just revise the term.  If you then analyze it some more, ", "you find that the oscillation probability simply  depends on the mass difference squared, the length of distance ", "the neutrino had time from 0 to oscillate,  and the energy of the neutrino.  So this is fantastic, because now  by studying the probability for a neutrino ", "to change its flavor, we can infer the mass differences  of two states.  This is fantastic.  I should add here that in this case, in this formula, ", "the length is given in meters, the energy is given--  unit of the energy MeV and the mass difference ", "is in eV, otherwise the equation doesn't make sense.  So again, we have seen, if you start from two neutrino ", "kind of model, two neutrino flavor model,  that the experimental parameters of interest  here are the length of distance from the neutrino source ", "to the detector on the place where we generate  a specific neutrino of a specific flavor,  to where we actually observe the flavor of the neutrino  and the energy of the neutrino. ", "And then, the appearance or disappearance  of a muon neutrino, for example, if we  start from a beam of muon neutrinos,  is a function of the length of the source. ", "And this is shown here for neutrinos of a specific energy.  So you can observe or can try to measure  the disappearance of muon neutrinos  or you can try to find the appearance of electron ", "neutrinos in the specific two-neutrino model.  All right.  So all we find later is that we want  to look for disappearance and appearance of neutrinos ", "of specific flavors in order to probe mass differences.   Instead of doing this for two generations,  you already know how to do this in three generations, ", "you can find that the unitary matrix  has three angles, three rotations and one  complex phase.  And this looks very much the same  here as in the quark sector. ", "The big difference is that the values of those parameters  are quite different.  For the quarks, we have seen it's dominated by the diagonal.  And then we have seen, for example,  in the Wolfenstein parameterization ", "that we can do an expansion of the matrix  and see terms which are all of this lambda, which would all  point to two and number square and number acute. ", "Here, on the leptons sector, the situation  seems to be quite different.  We have a later lecture where we look at the extra parameters  and the numerical values.  But what you see here is that it's ", "more like democracy between the individual values.  Question is, do we have sensitivity  to the complex phase?  We can only have that sensitivity ", "if the value of this matrix element is non-zero.  And this has been observed already.  So that's good news in order to allow further neutrino studies. ", "So in general, you can write the oscillation from one flavor  to another flavor state using this rotation of matrices  we have seen, and with that measure ", "the individual components of the matrix.  So in this video, we want to look at experimental studies  of neutrino oscillations.  The first question is, where do we get the neutrinos?  How do we produce the neutrinos? ", "The answer is, there's numerous sources for neutrinos.  You might be lucky and find them in supernova explosions.  Or if we're really trying hard, we  can observe them as relics of the Big Bang. ", "There is a lot of neutrinos as a relic of the Big  Bang around us.  Problem is that they have very low energies  and are difficult to observe. ", "Easier-- so is the use of neutrinos in the-- generated  in cosmic ray showers.  There's a lot of neutrinos coming from the sun. ", "Beams, beamlines-- accelerators can  be used to smash particles into a material,  and then in the decay product, produce also neutrinos. ", "And also, reactors.  Nuclear reactors can be used as neutrino sources.  By the way, neutrinos can also be  used in order to monitor the nuclear activity ", "around the globe.  OK.  Studies of neutrino oscillations.  So we can make this table here and ask ourselves, what kind  of-- the experimental parameters are ", "the length, the energy, and the sensitivity to a specific mass  range.  So for the solar neutrinos, you know  the distance between the Earth and the sun  is pretty much fixed to first order. ", "The energy of the neutrinos coming out  is in the order of 1 meV.  We are going to look at the table.  And so the mass range you can probe is 10 to the minus 10  in delta m squared. ", "For atmospheric neutrinos, they're  produced in the upper atmosphere, 10  to the 4, 10 to 7 meters.  Energies can range-- have a large range,  let's say 10 to the 2 to 10 to the 5 meV. ", "And then reactors, typically meV range.  It's kind of the nuclear range for the neutrino energies.  And the range is given by how much  space do you have around or away from a nuclear reactor. ", "Similarly for accelerators.  You build an accelerator or use an existing accelerator,  and then you build your detectors, maybe close to it,  and maybe another one far away. ", "And that's limited by the size of our planet  or wherever you want to build your detectors.  Energy ranges there depends on the energy  range of the accelerator. ", "And that is in the order of 10 to the 3, 10 to the 4 meV.  So you see that it's actually rather a straightforward study.  Also, it's interesting to see-- and we'll ", "see this next-- what kind of flavor of neutrinos,  and whether or not we can study neutrinos  or antineutrinos with other experiment is important. ", "Let's go through this.  So it's been a little bit of a history in how this all  occurred.  So the first question is, what happens to the solar neutrinos?  So solar neutrinos are basically produced ", "in the core of the sun, together with light.  It turns out that the light of the sun  takes about 10,000 years to come out of the sun,  while the neutrinos come out immediately. ", "So when first experiments tried to observe solar neutrinos,  they had to theoretically estimate how many neutrinos  to expect, and they saw less. ", "And so one explanation would have been, or could have been,  or was, maybe something happened at the core of the sun  and we just haven't seen it yet, because the light which  come out of the sun has a delay of up to 10,000 years. ", "That didn't turn out to be the case.  So here is the spectrum of the neutrino energies  and the specific sources of neutrinos from the sun. ", "In our nuclear physics discussion,  we'll get to the point that we understand how the neutrino--  how the sun produces energy, and then some of this  becomes more clear. ", "The story to take away at this point  is that there are certain--  there's several processes in the sun producing neutrinos.  And they all come with their characteristic energy  distribution. ", "But the bottom line is you find meV scale neutrinos  from the sun.  There's a soup of electron neutrinos. ", "They start interacting with the sun.  And there's a little bit of a flavor evolution within--  when they go through the material of the sun.   But, you know, what you want to really do ", "is look for disappearance in detectors  which are sensitive to electron neutrinos.  And that has been done in a number of experiments.  Most famous may be the Davis experiments which ", "had a big tank of chlorine.  And in the interaction, you were looking  for finding argon in your detector,  and you just every now and then went in there  and saw how much argon was actually produced. ", "And it turned out that those experiments, all of them,  found a reduced number of neutrinos, reduced with respect  to the theoretical expectation. ", "So far so good.  The assumption was that--  or there was no knowledge of neutrino oscillations or mixing  at this time.  So that needed to be explained. ", "And one way to explain--  it's not just using the charge interaction, which  allows you to probe the flavor of the neutrino,  but also lose a neutral--  ", "the neutral scattering, which then  allows you to measure the total number of neutrinos.  And if you do this-- this was done by the SNO experiment--  you find that the total number of neutrinos ", "is in good agreement with the theoretical expectation.  Hence, those neutrinos are not really lost,  they're just more from one flavor into the next. ", "So this was the first evidence for solar neutrinos  to be oscillating. ", "By now there's-- this first experiment was Homestake.  By now, there is a larger number of solar neutrino experiments,  and you see the long time of neutrino studies. ", "Different materials are being used, different energy  thresholds being tested, different scale  of the experiments, and experiments become more  sensitive the larger they are.  And so this you can--  something you can see from this table. ", "The next sort of neutrinos is the ones which  are produced in the atmosphere.  So they are produced in decays of pions and kaons  and by the cosmic rays interact with the atmosphere, ", "or the Earth's atmosphere.  And so you find, for example, a pi  plus decaying into a muon and a muon neutrino.  And then the muon itself can decay  into an electron, an electron neutrino, and a muon ", "antineutrino.  So if you, for example, build a ratio of muon/antimuon over  electron/anti-electron neutrinos,  you find it should be around 2. ", "You have two neutrinos-- muon neutrinos here,  and an electron neutrino.  And also, this wasn't really observed.  And you can see here, as a function ", "of the column of the zenith, of looking up  upwards towards the atmosphere or downwards,  you find that there is an effect of this kind of oscillation. ", "So the actual measurement depends on the energy range.  And you can see that the muon neutrinos,  the muon-like neutrinos, they disappear. ", "You see here in this very clear plot the prediction  without oscillation compared to the experimental results,  so you see the muon neutrinos actually disappear.  ", "Moving on, accelerators can be used.  And the big accelerator on the Earth at CERN or at Fermilab.  The beamline at Fermilab is called NuMI, Fermilab National ", "Accelerator Laboratory, FNAL.  Or CERN, or in Japan.  ", "Those are the big sources of accelerator-driven neutrinos.   And with those, there's big detectors, typically a detector  very close to the accelerator and one further away. ", "The close one probes the total flux  of the neutrino at the experiment, and then the one  which is away in order to probe the effect of the neutrino  oscillation in order to study appearance or disappearance. ", "And again here, you see this is a long program.  But it basically took off quite a bit in the 2000s and after.  So a lot of neutrino physics happened in those years.  A lot of information about the neutrino ", "was gathered in those years.  And again here-- this is from the T2K experiment--  you see the comparison between unoscillated predictions ", "and oscillated using some additional constraints  about expectation of the total flux of the neutrinos,  and that compared to the data.  And you see very clearly that the-- ", "that the neutrinos oscillate, that there  is evidence of oscillation.   All right.  The last source are reactor neutrinos.  We'll talk about nuclear physics starting from next week. ", "Here neutrinos are produced in nuclear fission  of heavy isotopes, mainly uranium and polonium.  The flux can be calculated in various ways, ", "for example by knowing the nuclear processes  and the thermal power produced in the reactor,  or by just looking at how much fuel is being-- ", "nuclear fuel is being used by the reactor itself.  What's being studied here is the anti-electron neutrino  disappearance.  And what you do here is you use this inverse beta decay, where ", "you have a collision or scattering  of a anti-electron neutrino with a proton,  creating an electron-- a positron and a neutron. ", "And again, there's a number of experiments.  Basically, whenever you have a large neutrino experiment,  it can probe surrounding nuclear reactors. ", "There's many of them in France and Japan, also in China.  And they're being used in those experiments.  Again, you see that this topic became really hot in the 2000s. ", "And again, a lot of-- a lot has been learned.  So this part here shows you as a function of the energy--  the length over the energy--  so kilometer over meV-- ", "the oscillation, the survival probability,  meaning that you can actually see directly the oscillation  we'll look at some of the experimental findings  of neutrinos.  Given the sheer number of experiments ", "and the long history in which we are  trying to understand neutrinos and neutrinos' behavior,  this can be rather confusing.  So I'm trying to condense this a little bit ", "and just give you the highlights, or the basic pieces  of information.  So this one here shows a summary of what we  know from neutrino oscillation.  So if we look at atmospheric neutrinos, ", "we find that mirror neutrinos and anti-mirror neutrinos  disappear, and they're most likely  converting into tau neutrinos and anti-tau neutrinos.  We look at accelerating neutrinos-- here ", "we are using mirror neutrinos and anti-mirror  ones-- we can show that they disappear over distances  of 200 to 800 kilometers.  ", "From accelerators, we also know that they appear or reappear  as electron or anti-electron neutrinos  over those same distances. ", "From the solar neutrinos, we know  that electron neutrinos convert into mirror neutrinos  and/or tau neutrinos.  There is more detail to this story ", "than I'm giving you here, where we  would have to discuss the interaction of the matter  effects of neutrinos.  That is for a different lecture.  That goes beyond the scope of what I want to discuss here. ", "From reactor neutrinos, we also know  that anti-electron neutrinos disappear as well.  So the name of the game now is to take  all of those pieces of information ", "and extract information about the neutrinos' property.  And in order to do that, one has to make assumption  about the number of available neutrino generations, ", "and in some part of the interpretation,  also about the nature of the neutrinos.   As you can simply figure out of the exercise we had before, ", "it matters to the neutrino oscillation probabilities  whether one assumes two or three or four neutrinos in the mix.  But if you just focus here on three neutrinos, ", "you still have the problem that we have  degeneracies in the discussion.  And they can be boiled down to two major kind of trends. ", "One is where the spectrum of the neutrino mass  follows a normal ordering, meaning  that the mass of the first is smaller  than the mass of the second is smaller  than the mass of the third, or that the spectrum is inverted, ", "meaning that the mass of the third might be smaller  than the mass of the second and the mass of--  the first and the second.  Data suggests that the difference squared ", "in mass splittings between those states  is such that delta m12 squared is  much smaller than delta m31 squared, which ", "is approximately the same size as delta m32 squared.  So if you look now at the numbers  for the normal hierarchy spectrum, ", "we find that the mass of the first is much, much smaller  than the mass of the second, which is a little bit smaller  than the mass of the third.  Numerically, we find the mass of the second  is in the order of 8 times 10 to the minus 3 electron-volt, ", "and the mass of the third in the order of 0.05 electron-volts,  so really, really small masses.  The inverted spectrum-- here the story is slightly different. ", "Here we find that m1 is about 0.05 election-volts, which  is similar to the square root of the mass splitting between 3 ", "and 2, which is also 0.05 electron-volts.  The information of the neutrino oscillation experiment,  and then how to map into the individual parameters ", "of our neutrino CKM matrix is summarized here, and also  in the mass information.  And I don't want to read the entire table.  I'll just leave this here for you. ", "So in order to understand this, one  has to go back to the first slide  and understand what kind of information  we extract from various neutrino experiments-- for example, ", "the solar neutrino experiments-- and then think about,  is this sensitive to oscillations  between the first and the second generation,  or the first and the third generation? ", "So that's kind of the mapping you have to do in order  to understand this table fully.  There are some experiment where the information just  dominates the position of a certain measurement.  In others, there is combinations of results coming out. ", "The other reason why I put this table here in this lecture  is to just illustrate how diverse the landscape  of experiments is and why that's needed. ", "In order to get a full picture of neutrinos  and their properties, one has to identify  the individual properties in the experiments  and then put the picture back together in a global fit ", "or in a general analysis of the data.  So this is our last video in the chapter on neutrino physics.  And we'll talk about mass scales and the nature of the neutrino  particle very briefly. ", "When we think about how we can measure the neutrino masses,  there's a number of methods which come to mind.  The first one is to just look out into the universe ", "and try to understand how much matter in total  could come from as a source of neutrinos.  And one has to make assumptions about the model, ", "the cosmological models at hand.  But if I accept those potential biases or model dependencies,  one finds that there's a potential reach ", "of this kind of measurements of 20 to 50 MeV, millielectron  volts.  And the current best limits are in the order  of 0.1 to 1 electron volt. ", "A second source, and I'll talk more about this later,  is the study of neutrinoless beta decay--  double beta decays.  Here, the current best limits are on the order of 0.2 ", "to 0.4 electron volts.  And there's a chance to reach 20 to 50 millielectron volts.  This kind of measurement will also answer the question ", "whether or not the neutrino is a direct particle or a Majorana  particle as we discussed in earlier lectures.  And then there is the more classical approach ", "of measuring the mass of an neutrino  from the end point spectrum of beta decays.  And so here the current best limit  is from the Kartrin experiment. ", "And I talk about it in the next slide.  And it's in the order of one electron volt.  And there's a potential reach to go down to 40 millielectron  volt. So currently the range of limits ", "is in the order of 1 electron volt or a bit better,  and when we'll be able to go down  to limits in the order of 20 to 50 millielectron volts. ", "So here is a cartoon of how those measurements are  being conducted.  One starts with tritium.  And it uses beta decay. ", "And this lecture overall is a good first entry  into the nuclear physics program where we discuss beta decays  and other nuclear decays in more detail. ", "What we find here is that you find an electron  and the neutrino-- antineutrino in this case--  being emitted.  And so the name of the game is now  to measure the electron energy as precisely as possible, ", "and then find a sensitivity off the neutrino mass in the end  point spectrum.  And those small differences here in the end point spectrum then ", "that leads to understanding of the mass of the neutrino  because the total energy in the collision  needs to be preserved. ", "And so the entire story here is about how precisely can we  measure the energy of the electron  in order to infer the neutrino mass in that. ", "And so the latest results came out last year  from the Kartrin experiment and shows  that the result is consistent with a neutrino mass of 0, ", "and that we can set an upper limit at 90% confidence level.  That electron neutrino is of mass of 1.1 electron ", "volt. Just as a reminder, we measure the mass  of the electron neutrino in this decay, which  is the sum of the individual components, mass ", "eigenstate, which make up the electron neutrino.  To just have historical context in this discussion here,  we find that this latest result is ", "an improvement of the order of factor of 2  compared to previous result by other experiments, which  had a very similar job to measure the electron ", "energy in beta decays, in the end point  spectrum of beta decays.  There's a new approach, which has  been proposed by Joe Formaggio here from MIT, ", "which changes the way the electron energy is  being measured.  So the idea is to have the decay happen in magnetic fields,  and use the cyclotron radiation of single electrons. ", "So the advantage here is that one  doesn't have to move the electrons somehow  into a spectrometer, but can immediately measure  the energy of the electron. ", " And the measurement of the energy  then turns into a measurement of the frequency  and basically measures the cyclotron frequency ", "of the electron circling around in a magnetic field.  And so it turns out that one moves the measurement  of the energy of the electron into a measurement  of a frequency. ", "And thus frequency can be measured  with very, very high precision.  So there's some hope that this kind of measurement  lead to very, very precise results ", "of the energy of the electron and with that the mass  of the neutrino.  So the last slide here is now how can we  figure out whether or not the neutrino has ", "Dirac or Majorana nature.  And this can be done, or the high sensitivity  comes from so-called neutrinoless double  beta decays.  So one starts with nuclear decays ", "where two electrons are emitted, but no neutrino.  And so this requires that in this process  there's a transition which includes ", "the neutrino where the neutrino has to be its own antiparticle.  And that just means that the neutrino is of Majorana nature.  This is being done by measuring, again, the energy spectrum. ", "You typically have all kinds of background contributions,  but also backgrounds from double beta decays with two neutrinos.  So you see this spectrum here. ", "And then you look at the end point of this part  here and find that there is this peak, a precise sharp peak  of the energies of the two electrons. ", "The issue is that forecasting where this peak is  requires proper knowledge of the dynamics inside the nuclei  here. ", "And those measurements are being conducted.  There's many of them conducted in various nuclear transitions  or decays.  And they haven't yielded a positive result yet. ", "Research is still going on on this end. "], "vid_duration": [11.54, 10.649, 12.811, 12.54, 10.26, 11.46, 12.45, 11.43, 12.97, 11.089, 12.481, 10.32, 15.33, 11.04, 12.96, 12.48, 12.75, 10.62, 11.52, 13.17, 14.01, 12.18, 12.72, 10.717, 13.681, 12.14, 11.19, 11.11, 11.25, 13.21, 10.82, 10.68, 15.05, 12.14, 11.141, 12.469, 14.07, 13.41, 10.95, 13.26, 11.16, 13.05, 11.069, 12.1, 12.481, 12.65, 10.289, 12.571, 10.259, 12.151, 14.64, 10.04, 12.9, 12.509, 12.121, 11.79, 11.43, 10.74, 11.76, 12.24, 12.45, 12.625, 11.365, 10.23, 12.03, 10.679, 13.76, 10.081, 11.95, 11.52, 12.0, 11.5, 12.179, 11.451, 10.16, 11.899, 10.393, 13.05, 10.171, 10.23, 10.42, 11.31, 11.62, 12.42, 11.66, 12.48, 14.399, 10.201, 10.98, 11.25, 10.26, 12.97, 10.98, 10.22, 13.98, 10.58, 11.07, 12.36, 10.25, 11.12, 11.79, 10.77, 11.41, 11.3, 11.1, 10.59, 11.45, 11.28, 12.723, 12.897, 13.31, 11.85, 12.36, 11.54, 10.23, 10.35, 11.78, 13.66, 10.28, 13.169, 13.591, 10.949, 10.781, 12.0, 13.36, 10.635, 11.485, 12.57, 10.2, 14.28, 10.41, 10.14, 12.207, 11.01, 12.53, 11.52, 10.75, 10.169, 12.331, 11.58, 11.46, 13.2, 11.64, 11.34, 13.0, 14.54, 11.55, 12.6, 10.4, 14.7, 11.48, 11.4, 13.08, 11.02, 10.429, 13.151, 14.27, 12.12, 11.31, 10.13, 10.592, 11.039, 10.231, 12.21, 12.284, 10.436, 10.07, 11.49, 15.75, 11.77, 12.849, 10.051, 13.26, 10.83, 10.889, 11.821, 10.82, 11.89, 12.81, 11.34, 12.0, 12.97, 13.97, 10.53, 11.79, 10.74, 12.75, 11.6, 11.13, 10.59, 13.43, 10.361, 11.079, 10.769, 13.901, 2.4], "stet": [[0, 11.54], [11.54, 22.189], [22.189, 35.0], [35.0, 47.54], [47.54, 57.8], [57.8, 69.25999999999999], [69.25999999999999, 81.71], [81.71, 93.13999999999999], [93.13999999999999, 106.10999999999999], [106.10999999999999, 117.19899999999998], [117.19899999999998, 129.67999999999998], [129.67999999999998, 139.99999999999997], [139.99999999999997, 155.32999999999998], [155.32999999999998, 166.36999999999998], [166.36999999999998, 179.32999999999998], [179.32999999999998, 191.80999999999997], [191.80999999999997, 204.55999999999997], [204.55999999999997, 215.17999999999998], [215.17999999999998, 226.7], [226.7, 239.86999999999998], [239.86999999999998, 253.87999999999997], [253.87999999999997, 266.05999999999995], [266.05999999999995, 278.78], [278.78, 289.49699999999996], [289.49699999999996, 303.17799999999994], [303.17799999999994, 315.3179999999999], [315.3179999999999, 326.5079999999999], [326.5079999999999, 337.61799999999994], [337.61799999999994, 348.86799999999994], [348.86799999999994, 362.0779999999999], [362.0779999999999, 372.8979999999999], [372.8979999999999, 383.5779999999999], [383.5779999999999, 398.62799999999993], [398.62799999999993, 410.7679999999999], [410.7679999999999, 421.90899999999993], [421.90899999999993, 434.37799999999993], [434.37799999999993, 448.4479999999999], [448.4479999999999, 461.85799999999995], [461.85799999999995, 472.80799999999994], [472.80799999999994, 486.0679999999999], [486.0679999999999, 497.22799999999995], [497.22799999999995, 510.27799999999996], [510.27799999999996, 521.347], [521.347, 533.447], [533.447, 545.928], [545.928, 558.578], [558.578, 568.867], [568.867, 581.438], [581.438, 591.697], [591.697, 603.848], [603.848, 618.4879999999999], [618.4879999999999, 628.5279999999999], [628.5279999999999, 641.4279999999999], [641.4279999999999, 653.9369999999999], [653.9369999999999, 666.0579999999999], [666.0579999999999, 677.8479999999998], [677.8479999999998, 689.2779999999998], [689.2779999999998, 700.0179999999998], [700.0179999999998, 711.7779999999998], [711.7779999999998, 724.0179999999998], [724.0179999999998, 736.4679999999998], [736.4679999999998, 749.0929999999998], [749.0929999999998, 760.4579999999999], [760.4579999999999, 770.6879999999999], [770.6879999999999, 782.7179999999998], [782.7179999999998, 793.3969999999998], [793.3969999999998, 807.1569999999998], [807.1569999999998, 817.2379999999998], [817.2379999999998, 829.1879999999999], [829.1879999999999, 840.7079999999999], [840.7079999999999, 852.7079999999999], [852.7079999999999, 864.2079999999999], [864.2079999999999, 876.3869999999998], [876.3869999999998, 887.8379999999999], [887.8379999999999, 897.9979999999998], [897.9979999999998, 909.8969999999998], [909.8969999999998, 920.2899999999998], [920.2899999999998, 933.3399999999998], [933.3399999999998, 943.5109999999999], [943.5109999999999, 953.7409999999999], [953.7409999999999, 964.1609999999998], [964.1609999999998, 975.4709999999998], [975.4709999999998, 987.0909999999998], [987.0909999999998, 999.5109999999997], [999.5109999999997, 1011.1709999999997], [1011.1709999999997, 1023.6509999999997], [1023.6509999999997, 1038.0499999999997], [1038.0499999999997, 1048.2509999999997], [1048.2509999999997, 1059.2309999999998], [1059.2309999999998, 1070.4809999999998], [1070.4809999999998, 1080.7409999999998], [1080.7409999999998, 1093.7109999999998], [1093.7109999999998, 1104.6909999999998], [1104.6909999999998, 1114.9109999999998], [1114.9109999999998, 1128.8909999999998], [1128.8909999999998, 1139.4709999999998], [1139.4709999999998, 1150.5409999999997], [1150.5409999999997, 1162.9009999999996], [1162.9009999999996, 1173.1509999999996], [1173.1509999999996, 1184.2709999999995], [1184.2709999999995, 1196.0609999999995], [1196.0609999999995, 1206.8309999999994], [1206.8309999999994, 1218.2409999999995], [1218.2409999999995, 1229.5409999999995], [1229.5409999999995, 1240.6409999999994], [1240.6409999999994, 1251.2309999999993], [1251.2309999999993, 1262.6809999999994], [1262.6809999999994, 1273.9609999999993], [1273.9609999999993, 1286.6839999999993], [1286.6839999999993, 1299.5809999999992], [1299.5809999999992, 1312.8909999999992], [1312.8909999999992, 1324.740999999999], [1324.740999999999, 1337.100999999999], [1337.100999999999, 1348.640999999999], [1348.640999999999, 1358.870999999999], [1358.870999999999, 1369.2209999999989], [1369.2209999999989, 1381.0009999999988], [1381.0009999999988, 1394.660999999999], [1394.660999999999, 1404.940999999999], [1404.940999999999, 1418.109999999999], [1418.109999999999, 1431.7009999999989], [1431.7009999999989, 1442.649999999999], [1442.649999999999, 1453.430999999999], [1453.430999999999, 1465.430999999999], [1465.430999999999, 1478.7909999999988], [1478.7909999999988, 1489.4259999999988], [1489.4259999999988, 1500.9109999999987], [1500.9109999999987, 1513.4809999999986], [1513.4809999999986, 1523.6809999999987], [1523.6809999999987, 1537.9609999999986], [1537.9609999999986, 1548.3709999999987], [1548.3709999999987, 1558.5109999999988], [1558.5109999999988, 1570.717999999999], [1570.717999999999, 1581.727999999999], [1581.727999999999, 1594.257999999999], [1594.257999999999, 1605.7779999999989], [1605.7779999999989, 1616.5279999999989], [1616.5279999999989, 1626.696999999999], [1626.696999999999, 1639.0279999999989], [1639.0279999999989, 1650.6079999999988], [1650.6079999999988, 1662.0679999999988], [1662.0679999999988, 1675.267999999999], [1675.267999999999, 1686.907999999999], [1686.907999999999, 1698.247999999999], [1698.247999999999, 1711.247999999999], [1711.247999999999, 1725.7879999999989], [1725.7879999999989, 1737.3379999999988], [1737.3379999999988, 1749.9379999999987], [1749.9379999999987, 1760.3379999999988], [1760.3379999999988, 1775.0379999999989], [1775.0379999999989, 1786.517999999999], [1786.517999999999, 1797.917999999999], [1797.917999999999, 1810.997999999999], [1810.997999999999, 1822.017999999999], [1822.017999999999, 1832.446999999999], [1832.446999999999, 1845.597999999999], [1845.597999999999, 1859.867999999999], [1859.867999999999, 1871.987999999999], [1871.987999999999, 1883.2979999999989], [1883.2979999999989, 1893.427999999999], [1893.427999999999, 1904.019999999999], [1904.019999999999, 1915.058999999999], [1915.058999999999, 1925.289999999999], [1925.289999999999, 1937.499999999999], [1937.499999999999, 1949.7839999999992], [1949.7839999999992, 1960.2199999999991], [1960.2199999999991, 1970.289999999999], [1970.289999999999, 1981.779999999999], [1981.779999999999, 1997.529999999999], [1997.529999999999, 2009.299999999999], [2009.299999999999, 2022.148999999999], [2022.148999999999, 2032.199999999999], [2032.199999999999, 2045.459999999999], [2045.459999999999, 2056.289999999999], [2056.289999999999, 2067.178999999999], [2067.178999999999, 2078.999999999999], [2078.999999999999, 2089.8199999999993], [2089.8199999999993, 2101.709999999999], [2101.709999999999, 2114.519999999999], [2114.519999999999, 2125.859999999999], [2125.859999999999, 2137.859999999999], [2137.859999999999, 2150.829999999999], [2150.829999999999, 2164.799999999999], [2164.799999999999, 2175.329999999999], [2175.329999999999, 2187.119999999999], [2187.119999999999, 2197.8599999999988], [2197.8599999999988, 2210.6099999999988], [2210.6099999999988, 2222.2099999999987], [2222.2099999999987, 2233.339999999999], [2233.339999999999, 2243.929999999999], [2243.929999999999, 2257.3599999999988], [2257.3599999999988, 2267.7209999999986], [2267.7209999999986, 2278.799999999999], [2278.799999999999, 2289.5689999999986], [2289.5689999999986, 2303.4699999999984], [2303.4699999999984, 2305.8699999999985]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [282, 589, 913, 1564, 1886, 2306]}
{"example_id": "mit159@@MITRES18-009F15_0_300k", "text": [" GILBERT STRANG: OK.  Well, the idea of this first video  is to tell you what's coming, to give a kind of outline  of what is reasonable to learn about ordinary differential ", "equations.  And a big part of the series will  be videos on first order equations and videos ", "on second order equations.  Those are the ones you see most in applications.  And those are the ones you can understand and solve, ", "when you're fortunate.  So first order equations means first derivatives  come into the equation.  So that's a nice equation that we will solve, ", "we'll spend a lot of time on.  The derivative is-- that's the rate of change of y--  the changes in the unknown y-- as time goes forward ", "are partly from depending on the solution itself.  That's the idea of a differential equation,  that it connects the changes with the function y as it is. ", "And then you have inputs called q of t,  which produce their own change.  They go into the system. ", "They become part of y.  And they grow, decay, oscillate, whatever y of t does.  So that is a linear equation with a right-hand side, ", "with an input, a forcing term.  And here is a nonlinear equation.  The derivative of y. ", "The slope depends on y.  So it's a differential equation.  But f of y could be y squared over y cubed or the sine of y ", "or the exponential of y.  So it could be not linear.  Linear means that we see y by itself.  Here we won't. ", "Well, we'll come pretty close to getting  a solution, because it's a first order equation.  And the most general first order equation, the function ", "would depend on t and y.  The input would change with time.  Here, the input depends only on the current value of y. ", "I might think of y as money in a bank,  growing, decaying, oscillating.  Or I might think of y as the distance on a spring. ", "Lots of applications coming.  OK.  So those are first order equations.  And second order have second derivatives.  The second derivative is the acceleration. ", " It tells you about the bending of the curve.  If I have a graph, the first derivative we know ", "gives the slope of the graph.  Is it going up?  Is it going down?  Is it a maximum?  The second derivative tells you the bending of the graph.  How it goes away from a straight line. ", "So and that's acceleration.  So Newton's law-- the physics we all live with--  would be acceleration is some force.  And there is a force that depends, again, linearly-- ", "that's a keyword-- on y.  Just y to the first power.  And here is a little bit more general equation.  ", "In Newton's law, the acceleration  is multiplied by the mass.  So this includes a physical constant here, the mass. ", "Then there could be some damping.  If I have motion, there may be friction slowing it down.  That depends on the first derivative, the velocity. ", "And then there could be the same kind of forced term  that depends on y itself.  And there could be some outside force, some person or machine ", "that's creating movement.  An external forcing term.  So that's a big equation.  And let me just say, at this point, ", "we let things be nonlinear.  And we had a pretty good chance.  If we get these to be non-linear,  the chance at second order has dropped. ", "And the further we go, the more we  need linearity and maybe even constant coefficients. ", "m, b, and k.  So that's really the problem that we  can solve as we get good at it is a linear equation-- ", "second order, let's say-- with constant coefficients.  But that's pretty much pushing what  we can hope to do explicitly and really ", "understand the solution, because so  linear with constant coefficients.  Say it again.  That's the good equations. ", "And I think of solutions in two ways.  If I have a really nice function like a exponential. ", "Exponentials are the great functions  of differential equations, the great functions in this series.  You'll see them over and over.  Exponentials.  Say f of t equals-- e to the t. ", "Or e to the omega t.  Or e to the i omega t.  That i is the square root of minus 1.  In those cases, we will get a similarly nice function ", "for the solution.  Those are the best.  We get a function that we know like exponentials.  And we get solutions that we know.  Second best are we get some function we don't especially ", "know.  In that case, the solution probably  involves an integral of f, or two integrals of f. ", "We have a formula for it.  That formula includes an integration  that we would have to do, either look it up ", "or do it numerically.  And then when we get to completely non-linear  functions, or we have varying coefficients, ", "then we're going to go numerically.  So really, the wide, wide part of the subject  ends up as numerical solutions. ", "But you've got a whole bunch of videos  coming that have nice functions and nice solutions.  OK.  So that's first order and second order. ", "Now there's more, because a system doesn't usually  consist of just a single resistor or a single spring. ", "In reality, we have many equations.  And we need to deal with those. ", "So y is now a vector.  y1, y2, to yn.  n different unknowns.  n different equations.  That's n equation.  So here that is an n by n matrix. ", " So it's first order.  Constant coefficient.  So we'll be able to get somewhere.  But it's a system of n coupled equations. ", "And so is this one with a second derivative.  Second derivative of the solution.  But again, y1 to yn.  And we have a matrix, usually a symmetric matrix ", "there, we hope, multiplying y.  So again, linear.  Constant coefficients.  But several equations at once. ", "And that will bring in the idea of eigenvalues  and eigenvectors.  Eigenvalues and eigenvectors is a key bit of linear algebra ", "that makes these problems simple,  because it turns this coupled problem  into n uncoupled problems. ", "n first order equations that we can solve separately.  Or n second order equations that we can solve separately.  That's the goal with matrices is to uncouple them. ", "OK.  And then really the big reality of this subject  is that solutions are found numerically ", "and very efficiently.  And there's a lot to learn about that, a lot to learn.  And MATLAB is a first-class package ", "that gives you numerical solutions with many options.  One of the options may be the favorite.  ODE for ordinary differential equations 4 5. ", "And that is numbers 4, 5.  Well, Cleve Moler, who wrote the package MATLAB, ", "is going to create a series of parallel videos  explaining the steps toward numerical solution. ", "Those steps begin with a very simple method.  Maybe I'll put the creator's name down.  Euler.  So you can know that because Euler was centuries ago, ", "he didn't have a computer.  But he had a simple way of approximating.  So Euler might be ODE 1. ", "And now we've left Euler behind.  Euler is fine, but not sufficiently accurate.  ODE 45, that 4 and 5 indicate a much higher accuracy, much more ", "flexibility in that package.  So starting with Euler, Cleve Moler  will explain several steps that reach ", "a really workhorse package.  So that's a parallel series where you'll see the codes.  This will be a chalk and blackboard ", "series, where I'll find solutions in exponential form.  And if I can, I would like to conclude the series by reaching ", "partial differential equations.  So I'll just write some partial differential equations here,  so you know what they mean.  And that's a goal which I hope to reach.  So one partial differential equation ", "would be du dt-- you see partial derivatives-- is  second derivative.  So I have two variables now. ", "Time, which I always have.  And here is x in the space direction.  That's called the heat equation.  That's a very important constant coefficient, ", "partial differential equation.  So PDE, as distinct from ODE.  And so I write down one more. ", "The second derivative of u is the same right-hand side  second derivative in the x direction. ", "That would be called the wave equation.  So this is like the first order equation in time.  It's like a big system.  In fact, it's like an infinite size system of equations. ", "First order in time.  Or second order in time.  Heat equation.  Wave equation.  And I would like to also include a the Laplace equation. ", "Well, if we get there.  So those are goals for the end of the series that  go beyond some courses in ODEs. ", "But the main goal here is to give you  the standard clear picture of the basic differential ", "equations that we can solve and understand.  Well, I hope it goes well.  GILBERT STRANG: OK well, here we're at the beginning. ", "And that I think it's worth thinking about what we know.  Calculus.  Differential equations is the big application of calculus, ", "so it's kind of interesting to see what part of calculus, what  information and what ideas from calculus,  actually get used in differential equations. ", "And I'm going to show you what I see,  and it's not everything by any means,  it's some basic ideas, but not all the details you learned. ", "So I'm not saying forget all those,  but just focus on what matters.  OK.  So the calculus you need is my topic. ", "And the first thing is, you really do  need to know basic derivatives.  The derivative of x to the n, the derivative  of sine and cosine. ", "Above all, the derivative of e to the x, which is e to the x.  The derivative of e to the x is e to the x.  That's the wonderful equation that is solved by e to the x. ", "Dy dt equals y.  We'll have to do more with that.  And then the inverse function related to the exponential  is the logarithm. ", "With that special derivative of 1/x.  OK.  But you know those.  Secondly, out of those few specific facts, ", "you can create the derivatives of an enormous array  of functions using the key rules.  The derivative of f plus g is the derivative ", "of f plus the derivative of g.  Derivative is a linear operation.  The product rule fg prime plus gf prime. ", "The quotient rule.  Who can remember that?  And above all, the chain rule.  The derivative of this-- of that chain of functions, ", "that composite function is the derivative of f with respect  to g times the derivative of g with respect to x. ", "That's really-- that it's chains of functions  that really blow open the functions or we can deal with.  OK. ", "And then the fundamental theorem.  So the fundamental theorem involves the derivative  and the integral.  And it says that one is the inverse operation to the other. ", "The derivative of the integral of a function is this. ", "Here is y and the integral goes from 0  to x I don't care what that dummy variable is.  I can-- I'll change that dummy variable to t. ", "Whatever.  I don't care.  [? ET ?] to show the dummy variable.  The x is the limit of integration. ", "I won't discuss that fundamental theorem,  but it certainly is fundamental and I'll use it.  Maybe that's better.  I'll use the fundamental theorem right away. ", "So-- but remember what it says.  It says that if you take a function, you integrate it,  you take the derivative, you get the function back again. ", "OK can I apply that to a really--  I see this as a key example in differential equations. ", "And let me show you the function I have in mind.  The function I have in mind, I'll call it y,  is the interval from 0 to t. ", "So it's a function of t then, time, It's  the integral of this, e to the t minus s.  Some function. ", " That's a remarkable formula for the solution ", "to a basic differential equation.  So with this, that solves the equation dy  dt equals y plus q of t. ", "So when I see that equation and we'll see it again  and we'll derive this formula, but now I  want to just use the fundamental theorem of calculus ", "to check the formula.  What as we created-- as we derive the formula-- well  it won't be wrong because our derivation will be good. ", "But also, it would be nice, I just  think if you plug that in, to that differential equation  it's solved.  OK so I want to take the derivative of that. ", "That's my job.  And that's why I do it here because it uses all the rules.  OK to take that derivative, I notice  the t is appearing there in the usual place, ", "and it's also inside the integral.  But this is a simple function.  I can take e to the t-- I'm going to take e  to the t out of the-- outside the integral. ", "e to the t.  So I have a function t times another function of t.  I'm going to use the product rule ", "and show that the derivative of that product  is one term will be y and the other term will be q.  Can I just apply the product rule to this function ", "that I've pulled out of a hat, but you'll see it again.  OK so it's a product of this times this.  So the derivative dy dt is-- the product rule ", "says take the derivative of [INAUDIBLE] that  is e to the [INAUDIBLE].   Plus, the first thing times the derivative of the second. ", "Now I'm using the product rule.  It just-- you have to notice that e to the t came twice  because it is there and its derivative is the same. ", "OK now, what's the derivative of that?  Fundamental theorem of calculus.  We've integrated something, I want to take its derivative, ", "so I get that something.  I get e to the minus tq of t.  That's the fundamental theorem.  Are you good with that? ", "So let's just look and see what we have.  First term was exactly y.  Exactly what is above because when ", "I took the derivative of the first guy,  the f it didn't change it, so I still have y.  What have I-- what do I have here?  E to the t times e to the minus t is one. ", "So e to the t cancels e to the minus t  and I'm left with q of t Just what I want.  So the two terms from the product rule  are the two terms in the differential equation. ", "I just think as you saw the fundamental theorem was needed  right there to find the derivative of what's  in that box, is what's in those parentheses. ", "I just like that the use of the fundamental theorem.  OK one more topic of calculus we need.  And here we go. ", "So it involves the tangent line to the graph.  This tangent to the graph. ", "So it's a straight line and what we need is y of t plus delta t.  That's taking any function, maybe ", "you'd rather I just called the function f.   A function at a point a little beyond t,  is approximately the function at t ", "plus the correction because it-- plus a delta f, right?  A delta f.  And what's the delta f approximately?  It's approximately delta t times the derivative at t. ", "That-- there's a lot of symbols on that line,  but it expresses the most basic fact of differential calculus. ", "If I put that f of t on this side with a minus sign,  then I have delta f.  If I divide by that delta t, then the same rule ", "is saying that this is approximately df dt.  That's a fundamental idea of calculus,  that the derivative is quite close. ", "At the point t-- the derivative at the point t  is close to delta f divided by delta t.  It changes over a short time interval. ", "OK so that's the tangent line because it starts with that's  the constant term.  It's a function of delta t and that's the slope. ", "Just draw a picture.  So I'm drawing a picture here.  So let me draw a graph of-- oh there's  the graph of e to the t. ", "So it starts up with slope 1.  Let me give it a little slope here.   OK the tangent line, and of course it  comes down here Not below. ", "So the tangent line is that line.   That's the tangent line.  That's this approximation to f. ", "And you see as I-- here is t equals 0 let's say.  And here's t equal delta t.  And you see if I take a big step,  my line is far from the curve. ", "And we want to get closer.  So the way to get closer is we have  to take into account the bending.  The curve is bending.  What derivative tells us about bending? ", "That is delta t squared times the second derivative.  ", "One half.  It turns out a one half shows in there.  So this is the term that changes the tangent line,  to a tangent parabola. ", "It notices the bending at that point.  The second derivative at that point.  So it curves up.  It doesn't follow it perfectly, but as well-- much better ", "than the other.  So this is the line.  Here is the parabola.   And here is the function.  ", "The real one.  OK.  I won't review the theory there that it pulls out that one  half, but you could check it. ", "Now finally, what if we want to do even better?  Well we need to take into account the third derivative  and then the fourth derivative and so on,  and if we get all those derivatives then, ", "all of them that means, we will be at the function  because that's a nice function, e to the t.  We can recreate that function from knowing ", "its height, its slope, its bending  and all the rest of the terms.  So there's a whole lot more-- Infinitely many terms. ", "That one over two-- the good way to think of one  over two, one half, is one over two factorial, two times one.  Because this is one over n factorial, ", "times t to the nth, pretty small,  times the nth derivative of the function.  ", "And keep going.  That's called the Taylor series named after Taylor.  Kind of frightening at first. ", "It's frightening because it's got infinitely many terms.  And the terms are getting a little more comp--  For most functions, you really don't want  to compute the nth derivative. ", "For e to the t, I don't mind computing the nth derivative  because it's still e to the t, but usually that's-- this  isn't so practical. ", "[INAUDIBLE] very practical.  Tangent parabola, quite practical.  Higher order terms, less-- much less practical.  But the formula is beautiful because you ", "see the pattern, that's really what mathematics  is about patterns, and here you're  seeing the pattern in the higher, higher terms.  They all fit that pattern and when you add up all the terms, ", "if you have a nice function, then the approximation  becomes perfect and you would have equality.  So to end this lecture, approximate to equal provided ", "we have a nice function.  And those are the best functions of mathematics and exponential  is of course one of them.  OK that's calculus. ", "Well, part of calculus. "], "vid_duration": [13.35, 14.26, 11.34, 13.35, 14.68, 14.48, 10.87, 11.94, 10.47, 10.75, 10.25, 10.06, 11.2, 15.92, 10.13, 12.486, 12.484, 13.6, 10.05, 10.78, 11.62, 12.65, 12.49, 10.53, 12.26, 11.91, 11.57, 13.12, 12.43, 13.28, 13.44, 16.11, 10.27, 10.41, 11.74, 10.33, 11.95, 12.54, 11.46, 14.5, 12.78, 12.18, 11.279, 10.181, 11.14, 13.49, 14.49, 15.82, 12.23, 13.38, 13.51, 14.11, 10.22, 14.92, 12.44, 12.86, 19.11, 12.07, 11.68, 14.13, 10.44, 10.9, 13.68, 21.15, 11.57, 13.94, 10.979, 10.58, 10.24, 14.23, 13.08, 11.62, 12.233, 11.087, 12.0, 12.66, 11.2, 10.58, 12.48, 10.25, 13.73, 11.26, 13.43, 10.709, 12.061, 10.3, 12.04, 11.53, 10.345, 11.635, 16.45, 10.77, 12.14, 10.7, 13.28, 12.82, 11.8, 14.455, 15.415, 17.436, 11.354, 11.64, 11.33, 10.34, 14.07, 11.81, 11.15, 11.64, 10.539, 12.621, 14.45, 19.06, 10.47, 12.85, 10.83, 10.03, 11.61, 10.38, 12.29, 11.7, 11.99, 13.99, 10.26, 11.5, 10.58, 12.92, 10.03, 12.62, 12.14, 11.02, 11.52, 10.52, 15.379, 10.131, 11.27, 12.26, 14.839, 13.75, 11.231, 1.951], "stet": [[0, 13.35], [13.35, 27.61], [27.61, 38.95], [38.95, 52.300000000000004], [52.300000000000004, 66.98], [66.98, 81.46000000000001], [81.46000000000001, 92.33000000000001], [92.33000000000001, 104.27000000000001], [104.27000000000001, 114.74000000000001], [114.74000000000001, 125.49000000000001], [125.49000000000001, 135.74], [135.74, 145.8], [145.8, 157.0], [157.0, 172.92], [172.92, 183.04999999999998], [183.04999999999998, 195.53599999999997], [195.53599999999997, 208.01999999999998], [208.01999999999998, 221.61999999999998], [221.61999999999998, 231.67], [231.67, 242.45], [242.45, 254.07], [254.07, 266.71999999999997], [266.71999999999997, 279.21], [279.21, 289.73999999999995], [289.73999999999995, 301.99999999999994], [301.99999999999994, 313.90999999999997], [313.90999999999997, 325.47999999999996], [325.47999999999996, 338.59999999999997], [338.59999999999997, 351.03], [351.03, 364.30999999999995], [364.30999999999995, 377.74999999999994], [377.74999999999994, 393.85999999999996], [393.85999999999996, 404.12999999999994], [404.12999999999994, 414.53999999999996], [414.53999999999996, 426.28], [426.28, 436.60999999999996], [436.60999999999996, 448.55999999999995], [448.55999999999995, 461.09999999999997], [461.09999999999997, 472.55999999999995], [472.55999999999995, 487.05999999999995], [487.05999999999995, 499.8399999999999], [499.8399999999999, 512.0199999999999], [512.0199999999999, 523.2989999999999], [523.2989999999999, 533.4799999999999], [533.4799999999999, 544.6199999999999], [544.6199999999999, 558.1099999999999], [558.1099999999999, 572.5999999999999], [572.5999999999999, 588.42], [588.42, 600.65], [600.65, 614.03], [614.03, 627.54], [627.54, 641.65], [641.65, 651.87], [651.87, 666.79], [666.79, 679.23], [679.23, 692.09], [692.09, 711.2], [711.2, 723.2700000000001], [723.2700000000001, 734.95], [734.95, 749.08], [749.08, 759.5200000000001], [759.5200000000001, 770.4200000000001], [770.4200000000001, 784.1], [784.1, 805.25], [805.25, 816.82], [816.82, 830.7600000000001], [830.7600000000001, 841.7390000000001], [841.7390000000001, 852.3190000000002], [852.3190000000002, 862.5590000000002], [862.5590000000002, 876.7890000000002], [876.7890000000002, 889.8690000000003], [889.8690000000003, 901.4890000000003], [901.4890000000003, 913.7220000000002], [913.7220000000002, 924.8090000000002], [924.8090000000002, 936.8090000000002], [936.8090000000002, 949.4690000000002], [949.4690000000002, 960.6690000000002], [960.6690000000002, 971.2490000000003], [971.2490000000003, 983.7290000000003], [983.7290000000003, 993.9790000000003], [993.9790000000003, 1007.7090000000003], [1007.7090000000003, 1018.9690000000003], [1018.9690000000003, 1032.3990000000003], [1032.3990000000003, 1043.1080000000004], [1043.1080000000004, 1055.1690000000003], [1055.1690000000003, 1065.4690000000003], [1065.4690000000003, 1077.5090000000002], [1077.5090000000002, 1089.0390000000002], [1089.0390000000002, 1099.3840000000002], [1099.3840000000002, 1111.0190000000002], [1111.0190000000002, 1127.4690000000003], [1127.4690000000003, 1138.2390000000003], [1138.2390000000003, 1150.3790000000004], [1150.3790000000004, 1161.0790000000004], [1161.0790000000004, 1174.3590000000004], [1174.3590000000004, 1187.1790000000003], [1187.1790000000003, 1198.9790000000003], [1198.9790000000003, 1213.4340000000002], [1213.4340000000002, 1228.8490000000002], [1228.8490000000002, 1246.285], [1246.285, 1257.6390000000001], [1257.6390000000001, 1269.2790000000002], [1269.2790000000002, 1280.6090000000002], [1280.6090000000002, 1290.949], [1290.949, 1305.019], [1305.019, 1316.829], [1316.829, 1327.979], [1327.979, 1339.6190000000001], [1339.6190000000001, 1350.1580000000001], [1350.1580000000001, 1362.7790000000002], [1362.7790000000002, 1377.2290000000003], [1377.2290000000003, 1396.2890000000002], [1396.2890000000002, 1406.7590000000002], [1406.7590000000002, 1419.6090000000002], [1419.6090000000002, 1430.439], [1430.439, 1440.469], [1440.469, 1452.079], [1452.079, 1462.459], [1462.459, 1474.749], [1474.749, 1486.449], [1486.449, 1498.439], [1498.439, 1512.429], [1512.429, 1522.689], [1522.689, 1534.189], [1534.189, 1544.769], [1544.769, 1557.689], [1557.689, 1567.719], [1567.719, 1580.339], [1580.339, 1592.479], [1592.479, 1603.499], [1603.499, 1615.019], [1615.019, 1625.539], [1625.539, 1640.918], [1640.918, 1651.049], [1651.049, 1662.319], [1662.319, 1674.579], [1674.579, 1689.418], [1689.418, 1703.168], [1703.168, 1714.399], [1714.399, 1716.35]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [836, 1716]}
{"example_id": "mit126@@MIT2_003SCF11_lec17_300k", "text": ["PROFESSOR: And I have put on the second board  just a quick review of the key equations that we  use to do the direct method. ", "So straight from Newton's second law, the first one,  second one-- the summarization of torques about some point a. ", "a may be g, in which case things get much simplified, g  being the center of mass.  And if point a is moving, then you have this extra term. ", "And this is a new equation over here,  which I got frustrated with this equation a few days ago  and derive something, which I think is easier to use. ", "So I'll do a problem today using that expression.  So I won't talk more about it now-- show it to you  in a minute.  And then finally, it's convenient at times ", "to express angular momentum with respect  to a point a as angular momentum about g  plus the position vector from a to g times the linear momentum. ", "So that's kind of the covered on the quiz.  And we're going to use these equations.  Today, what I'm going to do is look at a few problems ", "from the point of view both equations of motion,  by the direct method and the Lagrange method,  and kind of talk about and which one's easier, when should ", "you choose this one, when to choose that one.  That's the nature of today's lecture to sort of get  you prepped for the quiz.  ", "And a little bit more on generalized forces.  ", "You have questions about what's going to be on the quiz?   AUDIENCE: What is that last word-- balancing of?  PROFESSOR: Balancing of rotors.  ", "There's a rotor-- any thing that we spin about an axis.  A rigid body spinning about an axis,  you can call a rotor of some kind.  And balancing is usually-- the axes are fixed. ", "And so is this one-- this axis passes  through the center of mass-- so is  this rotor statically balanced? ", "Right.  Is this rotor dynamically balance?  Would you expect to when this is spinning,  it's direction of spin is vertical, right. ", " Is the direction of the angular momentum of this  object in the same direction as the angle of rotation? ", "No.  And so that's an indication of dynamic imbalance.  Angular momentum is not in the same direction  as angular rotation, right.  All right. ", "And, well, while we're on that subject,  we'll just hit it briefly here.   One other prop I need.  ", "So another rigid body, and I don't know  where g is on this rigid body.  ", "So does-- this is rotating about an axis.   Is this object statically balanced,  just doing this experiment? ", "We're doing an experiment.  We're sticking this on an axis, and we're  letting it do it's thing.  And I'm asking you is it statically balance.  How do you know?  AUDIENCE: Because if you were to flip it upside down and do it, ", "it would still come to a stop.  PROFESSOR: So it goes to a low point, right.  And that tells you what about the position of this axis?  AUDIENCE: [INAUDIBLE]  PROFESSOR: The center of mass has ", "got gravity, puts a force at the center of mass,  creates a torque which brings it to the low point.  Does this object have any symmetries ", "that you could point out?  Or in other words, can you without doing any math tell me  one principal axis of this object?  ", "AUDIENCE: Where the dotted line is, that's a plane [INAUDIBLE].  PROFESSOR: So you say I've got a dotted line around here  and that's a plane of what?  AUDIENCE: Plane of symmetry.  PROFESSOR: So there's a plane of symmetry cutting  this thing through here. ", "So if you can identify one plane of symmetry,  then where can you tell me that for sure you  know that you can make a principal axis? ", "He says perpendicular to that plane.  Any place on that plane perpendicular to it?  What do you think? ", "For now, we've identified it has a plane of symmetry  and that an axis perpendicular to it-- a principle axis should ", "be perpendicular to that plane.  But the question is where do I put it?  Where, perpendicular to that plane  can this axis be and be a principal axis?  ", "She says through g.  Do you agree with that?  So certainly through g.  Let's say that that really is g and I put it through here.  And if it was exactly through g, it ", "wouldn't rotate to the low spot.  This is pretty close.  It struggles to get there.  That's definitely a principal axis, but are there more?  This is kind of the real point of the question.  Are there other allowable principal axes ", "in this direction?   So we haven't talked about this very much.  Any axis-- if this is a principal axis,  any axis parallel to it is a principal axis. ", "It's no longer through g.  It's no longer statically balanced about that point.  But it's still a principal axis.  And one measure of whether or not something ", "is a principal axis-- if you know the principal axes  of an object and you write the mass moment of inertia  matrix of it with respect to g, what ", "does that matrix look like?  Where does it have 0s and non-0s?  It's a diagonal matrix.  So if i about g is diagonal, that ", "means you're computed the moment, mass moment  properties with respect to three principal axes.  If it's diagonal, and those axes all pass through g, ", "if I now take one of those axes and say,  I want to move it over here, and you've  re-computed the inertia matrix, would it still be diagonal? ", " So you've moved just one axis to another spot, parallel  to its original one.  You know this one is a principal axis. ", "I'm going to move it just parallel.  Only that one axis-- the other two are saying where they are.  I've just moved it parallel.  Is that also a principal axis, or another way of saying it, ", "does that mass matrix, mass moment of inertia matrix stay  diagonal?  Do any of the terms in it change? ", "Let's say this is the z principal axis and I move away.  So now you have this new mass moment inertia matrix.  Does the Izz term change? ", " Yeah, by how much?  AUDIENCE: [INAUDIBLE] ", "PROFESSOR: He said ml squared, l being what?  AUDIENCE: The length you moved.  PROFESSOR: Here.  And that's this thing though as parallel axis there, right?  If you move one axis, any axis parallel to one of those axes ", "is also a principal axis.  So that's a subtle point.  We don't often talking about it.  Any axis parallel to a principal axis is also principal axis.  ", "Well, let's think about a problem.  We've done this problem before.  But now we have all the full tools.  We have Lagrange, we have direct method.  So that's this problem of the wheel on a horizontal plane. ", " Kind of a complicated distribution of mass ", "for which we know Izz about g is some mass radius and gyration  squared.  ", "Maybe we measured it rather than computed it.  So this thing is sliding on ice, and it has cord  wrapped around it. ", "I'm pulling with a force F, call it F1.   I'll provide the inertial frame. ", " And it's got some radius R. And we'll ", "say the surface is frictionless.  ", "So I don't have a string wrapped around.  But we're really talking about this problem.  I'm pulling on the string and this thing  can slide and rotate.  ", "Take a second.  Think about how many different ways  can you think of solving for the equations of motion of this?  So if this on a quiz, I want you to find ", "the equations of motion.  What method would you use?   And what's this?  And then you're confronted with, well,  I know more than one method. ", "What's the simplest method?   And before that, you need to decide  how many coordinates you're going to need,  how many equations you're going-- so let's start there. ", "How many independent coordinates do you need to do this problem?   We'll back up one more question, then. ", "Is this a planar motion problem?  So it's confined to one plane.  I see a lot of heads nodding.  And it rotates only with one degree of freedom of rotation, ", "axis perpendicular to the plane.  So this is a planar motion problem.  So in general, planar motion problems  have found many degrees of freedom per rigid body?  So I see a bunch of 3's. ", "Does this one have any constraints on those three  degrees of freedom?  So this has three degrees of freedom.  You conceivably need three equations of motion.  ", "What are the choices for getting them?  I want you to think about this for a minute.  You decide what way you would do, and let's  take a poll in a minute.  You think about it, and then let's take  a poll for how people would do this problem. ", "", "So what's your favorite?  How would you do it?  He'd use the direct method.  Do you need a torque equation? ", "About what point?  He'd use center of mass.  So he'd say, direct method and for the torque equation,  do it about the center of mass.  Anybody have a different way they would do this problem? ", "Is there another way to do it?  He wants to do Lagrange.  Everybody agree it could be done that way?  So I agree, and let's quickly do this problem. ", "And so direct method-- I'm going to make it easier on myself  here.  ", "So the three coordinates, you're going to need an x, a y,  and a theta is what I've chosen for the three coordinates  to do this direct method.  And to make it easy on myself, I'm ", "going to align the force with my coordinates.  So I'm going to essentially make theta 0.  ", "Essentially aligning F1, my force F1 with the x-axis.  And if I do that, then I can say the sum of the forces in the y, ", "the external forces in the y direction are nonexistent, 0.  So that must be my double dot, so y double dot is 0. ", "So that simplifies the problem.  Summation of forces in the x direction, external forces  are F1I.  ", "And they must equal to the mass times the acceleration  in the x direction.  And I'm basically done with that equation.  AUDIENCE: Is that a rotating [INAUDIBLE]  ", "PROFESSOR: Well, I'm doing this.  I'm saying this is my inertia frame.  ", "You add an inertial frame?  Sure.  Now I can-- I don't have to break this force  into components, F1 cosine theta in the x direction ", "and F1 sine theta in the y direction  and get two-- get a finite amount, a nonzero amount  for y double dot and non-0 amount for x double dot. ", "I end up with three equations I have to work with.  Just by realigning it, I can make this problem even simpler.  So just to do it quickly, that's what I did.  ", "So I've got two of the three equations done.  And finally, the sum of the torques about g.  ", "And we know the angular momentum of this  would be some izz g times omega z  would be the angular momentum. ", "And it's d by dt of that izz about g, omega z dot,  which is theta double dot, right? ", "And what are the external torques?   So figure it out.  What's the external torque in this problem? ", "What is its size and what's its direction?  ", "So, somebody give me-- what's the external torque  with respect to where, to start with?  So we're summing torques about g, the center of mass. ", "R cross F, right, which comes out in what direction?   k direction, right? ", "And minus or plus?  Do your right hand rule.  And notice I've drawn x and y such  that positive z is into the board.  ", "So this is positive.  I put a positive z into the board on purpose  so that this would just work out R F1 in the k direction. ", "And that's equal to Izz about g theta double dot.  And since it's all with respect to k, ", "you can drop the unit vectors here.  And so we have one equation.  We have two equations. ", "And we have three equations.  And that's all we need to complete this,  is three degrees of freedom to completely define the motion.  Yes?  AUDIENCE: Do you want us to have a trivial case? ", "PROFESSOR: Do you mean the my double dot equals 0?  Well, in general-- when I started this one, when ", "I didn't align them, then you're forced to use the three, right?  So the only difference between what  I did and this probe making a problem slightly more messy, ", "is if I had let theta, this angle, be other than 0, I  would have had to have come up with three  non-zero acceleration equations. ", "So I'd say technically, or I'd just say I think it's prudent.  If you're ever not sure, if you can  look at it and by inspection write down, my double dot is 0, ", "you've essentially just written an equation of motion.  Rather than say let's just ignore it,  I'd keep it in your-- I'd just put it on the paper,  my double dot equals 0. ", "And that's your first trivial equation of motion.  But it is an equation of motion, because this body  has a true degree of freedom in that direction.  ", "That's really the point.  Don't confuse trivial results because there's  no external forces with constraints.  It's unconstrained in the x direction, ", "or in the y direction the way I've set it up.  So I think you're safer if you do just--  say the torques or the forces in that direction are 0 ", "and you write it down.  Let's look at this problem from the point of view of Lagrange.  It's also equally simple, the Lagrange,  except for the generalized forces. ", "Actually, Lagrange is harder because you  have to think your way through the generalized forces  in this problem.  And I got myself in a pickle with this problem  and I spent hours trying to figure out ", "a good explanation of a conundrum I  ran into with the generalized forces.  So let's look.  I'll tell you what that was in a second.  Let's look at Lagrange.  ", "So you need T. And we're pretty good at this now,  I with respect to g zz, theta dot squared. ", "That's your rotational kinetic energy.  1/2 mx dot squared plus y dot squared.  ", "Translational kinetic energy associated  with the center of mass.  Notice this is with respect to the center  of mass.  How about v?  ", "Potential energy in this problem?   Any?  It's all 0's, right?  There's no springs.  There's no gravity in this plane, operating in this plane. ", "So this is 0.  This problem's going to be particularly simple.  ", "So in the theta direction here, this derivative  with respect to Q dot gives us Iz theta dot ", "and the time derivative of that zz theta double dot.  T with respect to theta-- nothing. ", "V with respect to theta?  Nothing.  And on the right hand side, we need to get Q theta here.  And the other equation, it's the x equation. ", "Well, actually, we can have x and y.  So what about the x equation?  Derivative with respect to x dot?  I get an mx dot, time derivative, mx double dot.  ", "And with respect to y.  The thing about Lagrange, if you can do Lagrange, just write  down the total expression and just crank it out,  because if you say, oh, well, I know this is trivial, ", "then you're actually employing some information  from the direct method.  If you're saying, I know the sum of the forces in this direction  is 0.  So when you straight out in applying Lagrange, ", "you can do it without any reference at all to Newton.  So in this case, we just blindly clunk along and we say, well,  what's the derivative now with respect to y dot? ", "Will I get an my dot time derivative y double dot.  This derivative would be 0.  This derivative is 0.  And over here I get Q1. ", "Now I'm left-- so the left hand side of Lagrange equations--  remember, you just add these terms together.  ", "And these are going to be our three equations of motion  that result. And now the remaining work  is to get these three generalized forces.  ", "Let's go back to our picture.  If we had lined it up like this, and now we  give it a general little virtual displacement delta ", "y, how much work gets done?  None.  And so you suddenly realize, oh, I went to a lot of work  for nothing here.  This equation is trivial. ", "Nothing happens there.  And so now it's reduced to doing the Qx and Qy.   So just to give us some practice, ", "let's do Q theta and Qx the rigorous kinematic way.  ", "I'm going to draw the general picture here,  because this is where I got myself into trouble.  You're working along on a problem  and then something doesn't quite work for you.  I had set this problem to do generalized-- to compute ", "the generalized forces.  And I set it up looking like set it up like this so theta is 0. ", "It's lined up like that.  And I started thinking about, then generalized,  my little virtual displacements, and I  got into a conceptual problem that I couldn't sort out ", "for a while.  And I'll work it into the explanation here.  So I'm going to set this up more generally.  I have an angle theta here, and this is my F1. ", "So to do this by this kinematic way,  I need to find the position vector.  Here's a point-- I'm going to call it D,  and this is my point G, and here's O. ", "So I have a position vector going to here--  it's RG; and a position vector going to here-- that's  R of D with respect to G; and a position vector from here, ", "and that's RD in O. And RD in O is RG in O plus RD with respect ", "to G. I can write that.  They're vectors.   So I'm going to need those.  So what is RG in O? ", "Well, I have this coordinate system.  It's going to be some XI plus YJ in the inertial frame.  And then RD with respect to G-- I ", "need to have some kind of a coordinate system that  rotates with the body.  So I'll call this y1, and this x1-- how ", "it's rotating with the body.  So now, this one down here is minus R in the j1 direction. ", " So that's the position of this point D with respect to O,  written as the sum of two vectors. ", "", "And I'm eventually going to need to be able to express  this j1 in an inertial frame.  So here's just this little vector j1, ", "and I need its components in the J and I directions.  So it's made up of a piece like that, a piece like this, ", "and this angle here is theta.  So little j1-- so I can converge. ", "I can move from this unit vector system to that one  by this transformation.  I'm going to need that in a minute.  ", "Actually, I'll invoke it right now.  So my position vector here is-- the x component is x.  ", "Can't read my plus.  I crossed out a plus and minus, so I got to sort this out  carefully here.  ", "Is this right?  ", "What do you think?  Laura, what have I done wrong?   So this is the plus I direction. ", "This piece here is-- so minus sine  theta in the I plus cosine theta in the J are the components. ", "So I'm missing a minus sign there.  OK.   So I want to collect the I pieces together.  So I have an X in the I, and I have ", "a minus R minus sine theta.  So, plus R sine theta-- this is the I contribution. ", "And then over here I have a Y and a minus R cosine  theta in the J. Then I have this vector all worked out ", "in my inertial frame.   So now I can say that-- remember, Qj dot ", "dR-- it's a sort of virtual deflection for the jth  contribution. ", "So in this case, I'm interested in, say, the 1 in the-- which  one should we do first-- The x direction.  ", "So this is the F1 in the I dot derivative of RD with respect ", "to x delta x.  But now I have an-- I can work this out.  I can figure this one out directly now, ", "because I have an expression for R--  that vector-- in terms of one set of unit vectors,  and I can take the derivative with respect to x. ", "And the only x that shows up in here  is this, so the derivative is pretty simple.  It's just 1.  So this is F1I dot I delta x. ", "So this tells us that Qx equals F1.  No great surprise.  We knew the answer to that from before. ", "And I-- oh, I made a mistake.  ", "What didn't I-- I was mixing the two.  I did a simplification when I did the direct one.  Is F1 in the I direction?  ", "So F1 has components.  Vector F1 has a magnitude F1 times cosine theta I plus sine ", "theta J. And so down here, I need  to put those in and take the dot product.  So the only dot product that will matter is the I component. ", "This is going to be F1 cosine theta I  dot this, which we know this gives us just and I.  So I'm leaving out the J piece. ", "So I end up here with F1 cosine theta.  Does that look right?  So here is your theta. ", "Here is your-- this is F1 cosine theta.   So for our coordinate system that's squared up like this, ", "it's only that term that's in the F1 direction,  and this would come out correctly.  Now  And if we let-- if we now reorient our coordinate system ", "so that theta is 0, then this would just turn out to be F1.  If you can see that this is F1 cosine theta without going  through all the work, what's Qy for this system? ", " Sure.  F1 sine theta.  We won't go through all the work,  but you go through the same taking ", "the derivative-- in this case, the derivative of R  with respect to y, and then dot it with F,  and you get F1 sine theta in the J direction. ", "So there's Qy.  Now, the problem I ran into, conceptually, ", "is around this other piece.  So Q theta, the virtual work done in the theta direction,  we know has to do with rotation. ", "And that is going to be sum F1 dot-- now  this is the derivative of RD with respect to theta delta ", "theta.   So RD is here, and it's indeed a function of theta, right? ", "And so I can take a derivative with respect to theta,  and I'll get derivative of that R sine theta term,  and I'll get a derivative of the R cosine theta term.  But here's how I got myself in trouble.  It took me-- and this is the sort of thing ", "that happens to all of us.  You're working a problem, throw in a simplification,  and then something doesn't work.  Well, what if you had oriented the axis, initially, ", "so that the force is aligned with x and perpendicular to y?  Then this theta angle is 0, right? ", "And you know, when you set it up,  you don't end up with-- the cosine of 0 is 1, and sine of 0  is 0.  You don't end up with the cosine and sines in there ", "to take derivatives of.  You just jump to the simplification,  and you just find out that you just have R in the J. ", "There's no R sine theta term.  It's just vanished on you.  And now you need to take that derivative to do this step.  ", "And I do count with it as huh?  What have I done wrong?  In order to do this method, you need  to leave it in the sort of general formulation, ", "and then let theta be 0 at the end, if you want to do that.  So if I had then finished it, I can  do this for this general problem, ", "and then let theta go to 0, and the answer  will come out all right.  So should we do this?  So this is F1 dot this.  So, F1 dotted with the derivative of R ", "with respect to theta.  So I get an R cosine theta in the I, ", "and the derivative of this term will be-- well,  the cosine theta is minus sine theta  times a minus is a plus R sine theta in the J delta theta. ", "And I do this dot product, so I get  the I times the I's, and the J terms times the J terms. ", "", "And it all works out nicely.  Sine squared plus cosine squared-- you get 1.  And you find out that the torque doesn't care about the angle.  And does that make sense?  AUDIENCE: [INAUDIBLE]?  ", "PROFESSOR: Absolutely.  I did this on purpose to give us a little more practice using  this kinematic grind it out method.  But, for sure, the intuitive method ", "would have yielded result a lot faster here, right?  We would've said, let's have a little deflection delta x.  What's the virtual work, then? ", "Well, would have been F1 cosine theta delta x.  It would be Qx delta x.  Qy delta y would be F1 delta y sine theta, and we're done. ", "And the rotation one-- we would have looked at this  and said, how much-- in a little motion delta theta-- how  much does this move?  It moves R delta theta crossed with the F ", "that it moves through, or dot product with that distance,  would have given you F1 R delta theta equals  Q theta delta theta.  So we could have done it in a minute. ", " And sometimes, doing it the hard way  is what will get you in trouble.  I didn't have the cosine theta and sine thetas  working out in this and I couldn't take the derivative. ", "What did I do wrong?  And I finally realized, I made the problem too simple,  simplified it too soon.  So I wanted to use this as a stepping stone ", "to something I meant to cover perhaps weeks ago.  And there's a general little lesson  that we can learn from this, which you've probably  been taught before, but I'm going to remind you. ", "Here's a rigid body.  Got some center of mass.  And I've got a force acting on it here, ", "just some arbitrary position and angle.   So that force has a line of action,  and perpendicular to that line of action ", "is a distance, which I'll call d here.   And we know that in R cross F, we  can-- this force exerts a moment about G that would be R cross ", "F, where R goes from here to here,  but it's only the component perpendicular to it.  So we know that this is going to create a moment.  And I won't draw pictures yet here for a moment. ", "This diagram is the same as-- well,  I could draw the same peanut here.  It's the same as the following-- a force here, that's F, ", "and another force at G, that's F. Equal and opposite,  so it's like adding 0 to the problem.  So I can do that with impunity, and I still  have my force F down here. ", "So this problem's equal to that problem.   But now, this force and this force, equal and opposite, ", "cancel one another, but create what's  called a couple-- a moment that we can compute about my point G  here.  So these two forces create just a pure torque, ", "leaving this as a force.  They're equal and opposite, so no net force.  But they create a torque in this direction,  and there's a remaining force on the center of mass. ", "So this whole thing is also, then,  equal to the equivalent of a torque ", "around the center of mass and a force  applied at the center of mass.  And in this case, the torque would be dF. ", " This problem is easier to do if you're  trying to compute generalized forces than the one we started ", "with, because now, the position vector that we need  goes only to the center of mass.  ", "And the general rule for this-- you have a body,  you have several forces-- F1, F2, F3. ", " That's equal to the body with G, with a F total on it, ", "and a moment-- a torque-- total.  And F total-- it's a vector-- is a summation of the Fi's. ", "And T, the torque total, is the summation  of each of these guys.  Here's G. This has an R1.  ", "Here is an R2.   Here's an Ri to the ith force.  So this is a summation of the Ri cross Fi's. ", "So if you sum all the forces and compute the equivalent torque  about the center of mass, sum all the forces  and apply it at the center of mass,  then this problem is equal to that problem. ", "So this can come in handy when you're  trying to simplify problems.  ", "And for this particular problem, let's draw our hockey puck. ", " Going to put my force in the simplest direction here. ", "But there's my force.  This problem is equal, doing the same thing here.  It's the same thing as if I had drew forces like this. ", " And that gives me an equivalent problem, ", "where I have-- this couple here produces a torque,  and there is a net force acting on the center of mass. ", "So this problem is equal to this problem now.  A torque and a force both acting at the center of mass,  and the torque is RF1 in the k. ", "And the force is just F1 in the positive I direction.  ", "And R-- but now, what is the little R vector?  If we're going to do this the kinematic way?  From here to G, this is R1, I'll call it. ", "And that's it.  I only-- now I have everything acting here.  And Qx delta x is F1 dot derivative of R ", "with respect to x delta x.  But what is R?  ", "It's XI plus YJ.  The derivative of R1 with respect to x is just 1 ", "in the I, and the derivative of R with respect to Y  is just J. So this becomes a trivial calculation.  F1I dot I-- I get Qx equals F1 delta x. ", "Then I get Qy is F1, which is in the I direction dot J is 0.  And I get Q theta-- ah, Q theta. ", "Now, do I use this expression?  So, I'm not dealing with little changes in distance anymore.  When you can put rotation-- when you put moments  about the centers of mass, it's just easier. ", "This one-- you call intuitive, but this is just  going to be the sum delta theta is  equal to the total torques acting ", "at the center of mass dot delta theta.  And in this case, the torque is in the k direction, ", "delta theta's in the k direction,  and this is RF1k dot k delta theta, which just gives us ", "RF1 equals Q theta.  So the torque equations you can derive straight out.  You don't have to take derivatives.  It doesn't have anything to do with change in position. ", "It's just a little rotation, delta theta.   So it simplifies this problem and, actually, totally avoids  the conundrum I got into. ", "If I work everything about the center of mass  of that rigid body, the R gets easier,  the derivatives get easier, and the torque  becomes obvious how it applies.  ", "We'll talk about-- I have a pendulum in kind  of a weird shape.  ", "But the pendulum has the following properties.  So that weird shape-- that may be this.  It's got one plane of symmetry like this does. ", "And I'm going to put-- what did I do with my axle?  I'm going to put the axis of rotation perpendicular  to that plane of symmetry, somewhere not at G, ", "not at the center of mass-- so, just what I've done here.  I can make any object that has a plane of symmetry-- ", "if I have it rotate about an axis that's  perpendicular to that plane of symmetry,  it becomes a simple pendulum. ", "And you can write down with my inspection  what the equation of motion is.  So, how many degrees of freedom does this system have? ", " So first of all, then, is it planar motion?  So it has, at most, 3, and how many-- ", "and it has a pin through it that doesn't allow it  to move in x or y.  How many constraints is that?  AUDIENCE: 2.  PROFESSOR: 2.  So how many you got left?  AUDIENCE: 1.  PROFESSOR: 1. ", "So this is a single degree of freedom problem,  and I've chosen to have it move about an axis that  is-- is this axis a principal axis of this body? ", "Absolutely.  And so, if I ask you, what's the mass moment of inertia of this?  If I gave you Izz about G for this thing, and this distance,  what would you tell me the mass moment ", "of inertia about the pivot is?   I'll give you this.  ", "What's the rest of it?   Not a G. You've got some distance here,  which you're given-- L, we'll call it. ", "Correct.  So, parallel axis-- remember, ML squared.  So we know that that's true, and the G is over here someplace,  and this is this distance L. And what's the equation of motion ", "for this?  And gravity acts.  No damping for now.  What's the equation of motion?  Right off the top your head.  You've done enough of these. ", " I'll give you one minute think about it.  We'll figure out the equation of motion for this problem.  ", "I highly recommend you don't do the Lagrange.  ", "Somebody give me their equation of motion.  ", "So, what method would you choose to use?  Simplest one you could think of.  Direct?  About what point?  AUDIENCE: Around A. ", "PROFESSOR: About A. And what do you  say is-- what equation do you apply?  General equation.  AUDIENCE: [INAUDIBLE] It's just AIzz [INAUDIBLE]. ", "PROFESSOR: Yeah, that would be part of the answer.  And the equation-- remember, I wrote a list of them-- 1, 2,  3 over there.  Which one do you use?  ", "AUDIENCE: You just use the second one.  PROFESSOR: Just a second one, right.  And do the nuisance terms go away?  Point A's not moving.  So some of the torque is equal to dHdt,  and it's H with respect to A, right? ", "", "So that's H, right?   d by dt Izz with respect to A theta double dot k ", "equals the sum of the external torques.  And the rest of the problem is finding the external torques.  What's the free body diagram look like?  ", "So, here's the object, possibly A and Rx, and an Ry, and an Mg. ", "Those are your possible-- that will set your free body  diagram, right?  So here's the Mg down.  What's the torque that gravitational force ", "puts on this object with respect to point A?   R cross F, right?  ", "R cross F into the board.  Is that positive or negative?   And what's the link to this R?  ", "Well, from here to here is, I guess-- oh, that  is L. So the length of this side and that triangle?   L sine theta? ", "L sine theta cross Mg.  And it is positive or negative-- what did we decide?  Looks like it's-- this is positive theta xy system. ", "It gets negative minus MgL sine theta, and we're done.  So, generically-- and this is also in the k direction, ", "so we can drop the k's now.  We have our equation of motion Izz theta double dot plus MgL  sine theta. ", " Is there any then single degree of freedom pendulum made out ", "of a rigid body, and rotating about an axis  that is a principal axis that has that equation of motion? ", " Any of them, no matter what the shape.  If you can rotate it about a principal axis, ", "and not through G, because if you put--  what's the natural frequency if you run the axis through G?  What's the torque?  0.  Nothing happens, right? ", "It doesn't want to do anything.  But as soon as it's not through G, then the things oscillates.  And that's because this is now a differential equation.  And I need to say this equals 0 here. ", "There's no other forces.  If you've got a damping force, then it would show up.  But this is a generic, undamped equation  of motion for any single degree of freedom pendulum ", "rotating about one of its principal axes.  And if the body you're shown or given  has a single plane of symmetry, then you ", "can figure out one way, immediately,  that you know this will-- that equation applies.  An axis perpendicular to that plane of symmetry is a pendulum  and it is that equation. ", "And the i respect to A you can get from simple parallel axis,  if you're told what i with respect to G is.  ", "Questions?  ", "I'm going to put up two additional problems.  And I'm not going to solve them.  We're going to talk about them.  You're going to tell me how you would go about doing them.  And they wouldn't be bad problems for you ", "to practice on.  ", "And you've actually seen both of them before.  So, the first one-- pulley rotating about that fixed axis. ", " And this is that thing we call Atwood's Machine.  ", "How did I draw my coordinates?   So I have my Izz about G. It's sum M3 kappa squared. ", "You're given the radius of gyration of this pulley.  So that's its mass moment of inertia about the center.  And you know R. You could specify a theta. ", " And we have a pair of masses-- start off like this, M1, M2. ", "And this, now-- so I've going to say, no slip.   And this rope goes over the pulley, no slip, initially ", "stationary.  I let go.  I want an equation of motion for this system.  So how many is it-- first of all,  is it a planar motion problem? ", "OK.  How many rigid bodies?   How many potential degrees of freedom?  AUDIENCE: None.  PROFESSOR: None.  How many do you think they really ", "are going to end up with here?   How many do you expect to find?  How many necessary coordinates are you ", "going to need to completely describe the motion?  I see some 1's going up.  Everybody believe that?  Lots of constraints.  We're not going to let this-- we're  constraining this to move in-- only allowing ", "it to move up and down.  These can't rotate, so there's one for each.  These can't go in this direction, so two more. ", "This can only rotate, no translations.  So you end up with 1.  And finally, there's this no slip condition,  which means that R theta equals x, ", "and that's one final one that you'd need to write down.  So if you had that, gotten this far--  find the equation of motion.  What method would you use? ", "So, your choices are here-- direct method, Lagrange. ", "Think about it.  How would you-- what's the easiest way for you to  do this problem?  ", "Maybe an ancillary question is, how many ways can you  think of that you could do this problem?  How many different approaches could you use?  ", "So, how many ways can you think of doing this problem, Kristen?  ", "I'm just picking on her, but--  AUDIENCE: I'm not Kristen.   PROFESSOR: Give me an answer anyway.  AUDIENCE: OK.  ", "I think you could do two, but I would choose Lagrange.  PROFESSOR: You would want to do it by Lagrange.  Helen, how else could you do it?  If you did it by Lagrange, got the answer, and said, ", "I want to check it, what would you do next?  AUDIENCE: The direct method.  PROFESSOR: Direct.  But where would do apply?  Would you use torques?  Would you use forces? ", "How would you go about doing this?  AUDIENCE: I would use torques about the center of the pulley.  PROFESSOR: Torques about the center.  We did that.  I mean, I worked that-- I actually  did this problem by that method earlier in the term. ", "Torques about A. Let's have the pivot.  Works fine.  Actually, it's pretty efficient.  So, Lagrange or torques about A. You only ", "need-- there's one degree of freedom, right?  How many equations do you need to write to do this problem?  Just one.  So the sum of the torques about A will give you the answer. ", "Lagrange equation will give you the answer.  That's a good problem to practice on.  Another problem-- this is not very big. ", " It's basically this problem.  This is just-- you've seen this.  I'm sure you've been shown this in physics and stuff before.  This is the falling stick problem. ", "You can't set this up without having some friction.  So there's definitely friction on the table.  But until it hits, it's doing some things.  And so, there's two problems that you ", "could set up and try to do.  One is the problem with no friction-- frictionless table.  And then, you could allow friction. ", "Tricky thing about allowing friction  is-- you think there's a normal force.  So let's say our usual friction model is-- the friction force  is mu times the normal force. ", "Does the normal force change with time in this problem?   So, standing up, what's the normal force? ", " Mg, right?  And the sum of the forces in the vertical direction  is mass times acceleration in the vertical direction. ", "And what are the-- if you draw a free body  diagram of this problem-- so let's draw it now.  Here's my-- if there's no friction force,  I still-- without friction force, ", "I still have a normal force, and I still  have Mg pulling down here.  So the sum of the forces in the y  certainly have a minus Mg plus N equals ", "the mass times the acceleration in the y direction.  And if you solve for N, do you-- then the issue-- ", "my question is, does this remain constant?  Depends on whether or not ay remains constant, right?  Do you think the acceleration in the y direction of this thing ", "will change as it goes more and more horizontal?  There's some nods, up and down, and left and rights.  I think it's going to change.  For sure, you can't assume that it won't change. ", "So you have to assume it'll change.  And that means N-- this normal force becomes  a function of time, which makes certain ways of doing  this problem a little harder. ", "So how many ways?  Let's say the friction-- let's do a, no friction, and b, ", "with friction.  No friction-- first of all, is it a planar motion problem?  Yeah, we can do that.  So, at most three degrees of freedom. ", "How many does this one have?  Work this one out.  Figure out how many degrees of freedom this problem has.  How many separate equations do you need to come up with?  ", "So, you decide what your-- let's say  we're going to use Lagrange.  What would your generalized coordinates  be to do this problem?  ", "So, problem a-- no friction.  How many generalized coordinates?  How many degrees of freedom?  How many generalized coordinates do you need?  ", "I heard a three.   I hear one.  Somebody give me two.  I got a two.  All right.  Obviously a good question. ", "So, at most there can be three, because we've  agreed that it's planar motion.  Does this problem have any constraints?  ", "Where?   AUDIENCE: The bottom of the line can't move the y.  PROFESSOR: So it can't move in the y direction. ", "So if any part of a body can't move in-- translate,  then there's no translation in that direction,  pure translation of the body in that direction. ", "So there's a constraint in the y,  if we draw a coordinate system here.  ", "Constraint in the y.  True.  So we're down to two.  Are there any other constraints?  AUDIENCE: I would say that, yes, because the upper line--  PROFESSOR: No, no, it's not leaning against the wall. ", "This is just a skip.  This is the problem.  ", "So it definitely can't move through the table.  So it's constrained in y.  We've got that so now that leaves us, at most, two.   Are there any other constraints? ", " How many say no?  How many say yes?  If you say yes, you've got to tell me what it is, ", "but I don't see any others.  So we're left with two.  We need two coordinates.  What might we pick here?  ", "What would you pick?  You're now confronted with this problem.  Do you have rotational-- if you're  going to use Lagrange do you have rotational kinetic energy  in this problem?  You're probably going to need an angle. ", "What else would you need?  So we're going to need an angle for sure.  Say it again?  AUDIENCE: The height of the center of mass.  PROFESSOR: You're going to need the height  of the center of mass.  Yeah, you're going to need a potential energy expression, ", "but we've decided that y is constrained.  So you can't have a theta and a y.  Let's make this our theta.  ", "What else is there?  AUDIENCE: x.  PROFESSOR: x.  You're going to need an x.  So our generalized coordinates are  going to be an x and a theta. ", "But you do need to be able to write down a potential energy  expression, and it involves motion in the y.  So what do you do?  ", "Right.  So what's the height of this thing  is-- above the ground-- is sum L over 2 cosine theta equals y. ", "Something like that, right?  And I might have a-- depending on whether you make--  I haven't thought this through.  Whether or not it's xy this way or xy that way,  theta might be plus or minus.  This could be-- there might be a sine in there. ", "But basically, this is-- theta and y are constrained.  If you know one, you know the other.  So you do your potential energy expression this way.  ", "Now we've gotten that far.  We know we need two coordinates.  We're going to use x and theta.  But now you have to decide what method to use.  Direct method using one of these, or Lagrange? ", "What would you do?  How would you go about it?  It's a quiz.  You got 20 minutes to finish, and you  want to do this in the safest, quickest possible way. ", " What would you try?  And this is the realistic situation, right?  Next Tuesday. ", "What do you trust yourself to do the most?  It's probably what you ought to do in a quiz situation.  ", "Anne, how many ways can you think of doing this?  How many ways could you do this, Rob?  AUDIENCE: Two.  PROFESSOR: Two.  Any way.  Direct, indirect, what would you use?  Where would you choose to-- you're ", "going to need a torque equation to do this problem,  if you use direct.  Where would you take your torques about?  ", "Think about that.  For this problem, if you're doing the direct method,  where are you going to compute the torques?  About what point?  ", "So you can do it about that-- you  could call this point A here.  And what equation would you-- now  you've got to use that equation that's got ", "the problematic terms in it, right?  But it's all right.  You can punch those through and do it.  That will work.  And if you use Lagrange?  You've got to be able to figure out ", "the potential and kinetic energy, and so forth.  ", "So could all of you do this by Lagrange?  This is a good one to go practice on.  It's not that hard.  Do it.  It's a good practice problem. ", "Now add friction.  So, the b problem.  It now has friction.  ", "Can you-- I don't think-- is Lagrange a good choice  if it now has friction?  ", "I think it's got a problem, and I'd be careful using Lagrange  if it had friction.  Not that-- Lagrange is perfectly--  it is certainly valid. ", "It's just hard.  Why is it hard?   Well, yeah, it might be hard to find. ", "What do you need to know to-- so,  are there any external non-conservative forces  in the problem with friction?  AUDIENCE: Friction.  PROFESSOR: Friction. ", "You're going to have to figure out the friction force.  And to figure out the friction force,  you're going to have to apply direct method.  No other way. ", "You are going to have to apply some direct method to do  this problem, no matter what.  So you can't just say-- Lagrange is not ", "going to bail you out and not have  to solve some of the F equals ma,  and torque, and those sort of things  to figure out what friction is. ", "So there are problems that Lagrange-- isn't all as simple  as we sometimes make it out to be.  All right, I've run a couple minutes over.  Thank you.  We'll see you in class on Tuesday. ", "We'll do some more review. "], "vid_duration": [12.689, 11.161, 13.36, 10.96, 12.28, 14.13, 10.67, 11.9, 10.249, 14.068, 13.603, 12.98, 14.721, 10.564, 12.665, 10.09, 12.09, 14.08, 10.986, 12.49, 11.324, 15.04, 17.724, 10.486, 10.78, 10.15, 13.86, 16.22, 11.327, 13.253, 13.3, 10.63, 12.58, 12.39, 10.0, 10.68, 11.56, 10.37, 10.5, 11.77, 10.378, 15.861, 18.541, 15.375, 10.245, 12.51, 10.6, 10.625, 13.785, 14.93, 14.83, 10.82, 10.61, 11.9, 11.53, 11.03, 11.33, 12.48, 11.805, 43.155, 11.76, 10.56, 14.28, 18.99, 10.2, 19.783, 10.177, 10.05, 11.11, 15.358, 12.402, 13.565, 11.455, 10.94, 18.1, 10.44, 10.6, 11.649, 22.971, 12.459, 10.301, 12.29, 10.2, 10.72, 10.72, 11.865, 10.635, 11.79, 13.01, 14.23, 11.04, 10.241, 11.349, 10.935, 13.175, 10.74, 16.37, 10.42, 11.04, 13.156, 11.724, 30.73, 11.21, 12.17, 18.01, 16.16, 12.28, 10.06, 11.75, 13.57, 11.03, 14.66, 11.02, 11.43, 12.8, 33.35, 12.597, 10.383, 11.396, 11.864, 12.51, 18.2, 13.0, 10.83, 15.55, 13.86, 10.93, 10.87, 16.11, 12.35, 13.72, 22.145, 13.533, 21.292, 16.7, 10.187, 10.403, 11.535, 11.235, 12.41, 15.06, 14.09, 10.11, 12.34, 10.27, 10.62, 13.01, 12.55, 11.21, 11.82, 15.35, 16.33, 11.56, 11.85, 10.16, 11.168, 10.632, 13.699, 12.811, 10.6, 16.64, 11.82, 12.061, 16.211, 11.558, 17.1, 14.49, 12.48, 14.8, 13.24, 10.74, 10.65, 22.23, 12.037, 14.593, 10.165, 25.265, 13.454, 11.436, 10.0, 13.27, 15.425, 10.65, 11.945, 12.65, 12.18, 10.85, 11.84, 18.61, 12.28, 13.17, 14.23, 12.29, 11.85, 11.8, 12.31, 11.3, 10.68, 11.43, 13.96, 16.21, 11.63, 12.13, 15.82, 12.06, 14.89, 16.47, 12.6, 13.525, 10.135, 13.14, 15.05, 10.37, 14.59, 18.53, 11.95, 10.62, 17.75, 12.54, 11.9, 14.57, 10.04, 16.8, 11.23, 11.04, 41.77, 12.31, 15.84, 12.41, 10.28, 11.65, 14.28, 12.04, 10.521, 12.169, 11.35, 14.734, 12.326, 13.26, 10.482, 19.448, 65.37, 18.67, 10.3, 12.537, 10.15, 11.813, 18.85, 15.14, 11.85, 14.67, 12.4, 10.54, 14.49, 11.99, 13.97, 16.99, 10.75, 13.99, 10.641, 10.929, 12.909, 12.321, 10.93, 11.03, 11.93, 15.011, 13.269, 11.44, 10.66, 16.345, 10.89, 18.425, 13.505, 13.745, 10.89, 11.41, 11.01, 12.52, 12.565, 10.975, 13.145, 10.095, 10.225, 11.065, 33.11, 12.15, 10.598, 10.012, 10.44, 13.12, 10.55, 10.49, 13.945, 12.355, 10.85, 12.92, 11.0, 12.06, 12.7, 10.745, 16.715, 17.86, 11.29, 12.53, 10.57, 19.9, 10.419, 53.651, 38.76, 12.25, 12.17, 10.17, 10.35, 11.58, 10.59, 12.12, 10.604, 11.096, 11.14, 13.82, 12.479, 12.031, 11.83, 13.37, 10.031, 10.984, 13.005, 14.92, 12.7, 11.773, 11.527, 10.12, 10.41, 10.58, 10.41, 11.59, 10.36, 11.56, 11.15, 10.04, 15.23, 10.73, 12.01, 10.14, 10.4, 10.34, 10.07, 12.0, 3.46], "stet": [[0, 12.689], [12.689, 23.85], [23.85, 37.21], [37.21, 48.17], [48.17, 60.45], [60.45, 74.58], [74.58, 85.25], [85.25, 97.15], [97.15, 107.399], [107.399, 121.467], [121.467, 135.07], [135.07, 148.04999999999998], [148.04999999999998, 162.771], [162.771, 173.33499999999998], [173.33499999999998, 185.99999999999997], [185.99999999999997, 196.08999999999997], [196.08999999999997, 208.17999999999998], [208.17999999999998, 222.26], [222.26, 233.24599999999998], [233.24599999999998, 245.736], [245.736, 257.06], [257.06, 272.1], [272.1, 289.824], [289.824, 300.31], [300.31, 311.09], [311.09, 321.23999999999995], [321.23999999999995, 335.09999999999997], [335.09999999999997, 351.31999999999994], [351.31999999999994, 362.64699999999993], [362.64699999999993, 375.8999999999999], [375.8999999999999, 389.19999999999993], [389.19999999999993, 399.8299999999999], [399.8299999999999, 412.4099999999999], [412.4099999999999, 424.7999999999999], [424.7999999999999, 434.7999999999999], [434.7999999999999, 445.4799999999999], [445.4799999999999, 457.0399999999999], [457.0399999999999, 467.4099999999999], [467.4099999999999, 477.9099999999999], [477.9099999999999, 489.6799999999999], [489.6799999999999, 500.0579999999999], [500.0579999999999, 515.9189999999999], [515.9189999999999, 534.4599999999999], [534.4599999999999, 549.8349999999999], [549.8349999999999, 560.0799999999999], [560.0799999999999, 572.5899999999999], [572.5899999999999, 583.1899999999999], [583.1899999999999, 593.8149999999999], [593.8149999999999, 607.5999999999999], [607.5999999999999, 622.5299999999999], [622.5299999999999, 637.3599999999999], [637.3599999999999, 648.18], [648.18, 658.79], [658.79, 670.6899999999999], [670.6899999999999, 682.2199999999999], [682.2199999999999, 693.2499999999999], [693.2499999999999, 704.5799999999999], [704.5799999999999, 717.06], [717.06, 728.8649999999999], [728.8649999999999, 772.0199999999999], [772.0199999999999, 783.7799999999999], [783.7799999999999, 794.3399999999998], [794.3399999999998, 808.6199999999998], [808.6199999999998, 827.6099999999998], [827.6099999999998, 837.8099999999998], [837.8099999999998, 857.5929999999998], [857.5929999999998, 867.7699999999999], [867.7699999999999, 877.8199999999998], [877.8199999999998, 888.9299999999998], [888.9299999999998, 904.2879999999998], [904.2879999999998, 916.6899999999998], [916.6899999999998, 930.2549999999999], [930.2549999999999, 941.7099999999999], [941.7099999999999, 952.65], [952.65, 970.75], [970.75, 981.19], [981.19, 991.7900000000001], [991.7900000000001, 1003.4390000000001], [1003.4390000000001, 1026.41], [1026.41, 1038.8690000000001], [1038.8690000000001, 1049.17], [1049.17, 1061.46], [1061.46, 1071.66], [1071.66, 1082.38], [1082.38, 1093.1000000000001], [1093.1000000000001, 1104.9650000000001], [1104.9650000000001, 1115.6000000000001], [1115.6000000000001, 1127.39], [1127.39, 1140.4], [1140.4, 1154.63], [1154.63, 1165.67], [1165.67, 1175.911], [1175.911, 1187.26], [1187.26, 1198.195], [1198.195, 1211.37], [1211.37, 1222.11], [1222.11, 1238.4799999999998], [1238.4799999999998, 1248.8999999999999], [1248.8999999999999, 1259.9399999999998], [1259.9399999999998, 1273.0959999999998], [1273.0959999999998, 1284.8199999999997], [1284.8199999999997, 1315.5499999999997], [1315.5499999999997, 1326.7599999999998], [1326.7599999999998, 1338.9299999999998], [1338.9299999999998, 1356.9399999999998], [1356.9399999999998, 1373.1], [1373.1, 1385.3799999999999], [1385.3799999999999, 1395.4399999999998], [1395.4399999999998, 1407.1899999999998], [1407.1899999999998, 1420.7599999999998], [1420.7599999999998, 1431.7899999999997], [1431.7899999999997, 1446.4499999999998], [1446.4499999999998, 1457.4699999999998], [1457.4699999999998, 1468.8999999999999], [1468.8999999999999, 1481.6999999999998], [1481.6999999999998, 1515.0499999999997], [1515.0499999999997, 1527.6469999999997], [1527.6469999999997, 1538.0299999999997], [1538.0299999999997, 1549.4259999999997], [1549.4259999999997, 1561.2899999999997], [1561.2899999999997, 1573.7999999999997], [1573.7999999999997, 1591.9999999999998], [1591.9999999999998, 1604.9999999999998], [1604.9999999999998, 1615.8299999999997], [1615.8299999999997, 1631.3799999999997], [1631.3799999999997, 1645.2399999999996], [1645.2399999999996, 1656.1699999999996], [1656.1699999999996, 1667.0399999999995], [1667.0399999999995, 1683.1499999999994], [1683.1499999999994, 1695.4999999999993], [1695.4999999999993, 1709.2199999999993], [1709.2199999999993, 1731.3649999999993], [1731.3649999999993, 1744.8979999999992], [1744.8979999999992, 1766.1899999999991], [1766.1899999999991, 1782.8899999999992], [1782.8899999999992, 1793.076999999999], [1793.076999999999, 1803.479999999999], [1803.479999999999, 1815.0149999999992], [1815.0149999999992, 1826.249999999999], [1826.249999999999, 1838.6599999999992], [1838.6599999999992, 1853.7199999999991], [1853.7199999999991, 1867.809999999999], [1867.809999999999, 1877.919999999999], [1877.919999999999, 1890.2599999999989], [1890.2599999999989, 1900.5299999999988], [1900.5299999999988, 1911.1499999999987], [1911.1499999999987, 1924.1599999999987], [1924.1599999999987, 1936.7099999999987], [1936.7099999999987, 1947.9199999999987], [1947.9199999999987, 1959.7399999999986], [1959.7399999999986, 1975.0899999999986], [1975.0899999999986, 1991.4199999999985], [1991.4199999999985, 2002.9799999999984], [2002.9799999999984, 2014.8299999999983], [2014.8299999999983, 2024.9899999999984], [2024.9899999999984, 2036.1579999999983], [2036.1579999999983, 2046.7899999999984], [2046.7899999999984, 2060.488999999998], [2060.488999999998, 2073.2999999999984], [2073.2999999999984, 2083.8999999999983], [2083.8999999999983, 2100.539999999998], [2100.539999999998, 2112.3599999999983], [2112.3599999999983, 2124.4209999999985], [2124.4209999999985, 2140.6319999999982], [2140.6319999999982, 2152.1899999999982], [2152.1899999999982, 2169.289999999998], [2169.289999999998, 2183.779999999998], [2183.779999999998, 2196.259999999998], [2196.259999999998, 2211.059999999998], [2211.059999999998, 2224.299999999998], [2224.299999999998, 2235.0399999999977], [2235.0399999999977, 2245.689999999998], [2245.689999999998, 2267.919999999998], [2267.919999999998, 2279.9569999999976], [2279.9569999999976, 2294.5499999999975], [2294.5499999999975, 2304.7149999999974], [2304.7149999999974, 2329.9799999999973], [2329.9799999999973, 2343.4339999999975], [2343.4339999999975, 2354.8699999999976], [2354.8699999999976, 2364.8699999999976], [2364.8699999999976, 2378.1399999999976], [2378.1399999999976, 2393.564999999998], [2393.564999999998, 2404.214999999998], [2404.214999999998, 2416.159999999998], [2416.159999999998, 2428.809999999998], [2428.809999999998, 2440.989999999998], [2440.989999999998, 2451.839999999998], [2451.839999999998, 2463.679999999998], [2463.679999999998, 2482.289999999998], [2482.289999999998, 2494.5699999999983], [2494.5699999999983, 2507.7399999999984], [2507.7399999999984, 2521.9699999999984], [2521.9699999999984, 2534.2599999999984], [2534.2599999999984, 2546.1099999999983], [2546.1099999999983, 2557.9099999999985], [2557.9099999999985, 2570.2199999999984], [2570.2199999999984, 2581.5199999999986], [2581.5199999999986, 2592.1999999999985], [2592.1999999999985, 2603.6299999999983], [2603.6299999999983, 2617.5899999999983], [2617.5899999999983, 2633.7999999999984], [2633.7999999999984, 2645.4299999999985], [2645.4299999999985, 2657.5599999999986], [2657.5599999999986, 2673.3799999999987], [2673.3799999999987, 2685.4399999999987], [2685.4399999999987, 2700.3299999999986], [2700.3299999999986, 2716.7999999999984], [2716.7999999999984, 2729.3999999999983], [2729.3999999999983, 2742.9249999999984], [2742.9249999999984, 2753.0599999999986], [2753.0599999999986, 2766.1999999999985], [2766.1999999999985, 2781.2499999999986], [2781.2499999999986, 2791.6199999999985], [2791.6199999999985, 2806.2099999999987], [2806.2099999999987, 2824.739999999999], [2824.739999999999, 2836.6899999999987], [2836.6899999999987, 2847.3099999999986], [2847.3099999999986, 2865.0599999999986], [2865.0599999999986, 2877.5999999999985], [2877.5999999999985, 2889.4999999999986], [2889.4999999999986, 2904.069999999999], [2904.069999999999, 2914.1099999999988], [2914.1099999999988, 2930.909999999999], [2930.909999999999, 2942.139999999999], [2942.139999999999, 2953.179999999999], [2953.179999999999, 2994.949999999999], [2994.949999999999, 3007.259999999999], [3007.259999999999, 3023.099999999999], [3023.099999999999, 3035.509999999999], [3035.509999999999, 3045.789999999999], [3045.789999999999, 3057.439999999999], [3057.439999999999, 3071.7199999999993], [3071.7199999999993, 3083.7599999999993], [3083.7599999999993, 3094.2809999999995], [3094.2809999999995, 3106.4499999999994], [3106.4499999999994, 3117.7999999999993], [3117.7999999999993, 3132.533999999999], [3132.533999999999, 3144.859999999999], [3144.859999999999, 3158.1199999999994], [3158.1199999999994, 3168.6019999999994], [3168.6019999999994, 3188.0499999999993], [3188.0499999999993, 3253.419999999999], [3253.419999999999, 3272.0899999999992], [3272.0899999999992, 3282.3899999999994], [3282.3899999999994, 3294.926999999999], [3294.926999999999, 3305.0769999999993], [3305.0769999999993, 3316.8899999999994], [3316.8899999999994, 3335.7399999999993], [3335.7399999999993, 3350.879999999999], [3350.879999999999, 3362.729999999999], [3362.729999999999, 3377.399999999999], [3377.399999999999, 3389.7999999999993], [3389.7999999999993, 3400.3399999999992], [3400.3399999999992, 3414.829999999999], [3414.829999999999, 3426.819999999999], [3426.819999999999, 3440.7899999999986], [3440.7899999999986, 3457.7799999999984], [3457.7799999999984, 3468.5299999999984], [3468.5299999999984, 3482.519999999998], [3482.519999999998, 3493.1609999999982], [3493.1609999999982, 3504.0899999999983], [3504.0899999999983, 3516.9989999999984], [3516.9989999999984, 3529.3199999999983], [3529.3199999999983, 3540.249999999998], [3540.249999999998, 3551.2799999999984], [3551.2799999999984, 3563.209999999998], [3563.209999999998, 3578.220999999998], [3578.220999999998, 3591.489999999998], [3591.489999999998, 3602.929999999998], [3602.929999999998, 3613.589999999998], [3613.589999999998, 3629.9349999999977], [3629.9349999999977, 3640.8249999999975], [3640.8249999999975, 3659.2499999999977], [3659.2499999999977, 3672.754999999998], [3672.754999999998, 3686.4999999999977], [3686.4999999999977, 3697.3899999999976], [3697.3899999999976, 3708.7999999999975], [3708.7999999999975, 3719.8099999999977], [3719.8099999999977, 3732.3299999999977], [3732.3299999999977, 3744.8949999999977], [3744.8949999999977, 3755.8699999999976], [3755.8699999999976, 3769.0149999999976], [3769.0149999999976, 3779.1099999999974], [3779.1099999999974, 3789.3349999999973], [3789.3349999999973, 3800.3999999999974], [3800.3999999999974, 3833.5099999999975], [3833.5099999999975, 3845.6599999999976], [3845.6599999999976, 3856.2579999999975], [3856.2579999999975, 3866.2699999999977], [3866.2699999999977, 3876.7099999999978], [3876.7099999999978, 3889.8299999999977], [3889.8299999999977, 3900.379999999998], [3900.379999999998, 3910.8699999999976], [3910.8699999999976, 3924.814999999998], [3924.814999999998, 3937.169999999998], [3937.169999999998, 3948.0199999999977], [3948.0199999999977, 3960.939999999998], [3960.939999999998, 3971.939999999998], [3971.939999999998, 3983.9999999999977], [3983.9999999999977, 3996.6999999999975], [3996.6999999999975, 4007.4449999999974], [4007.4449999999974, 4024.1599999999976], [4024.1599999999976, 4042.0199999999977], [4042.0199999999977, 4053.3099999999977], [4053.3099999999977, 4065.839999999998], [4065.839999999998, 4076.409999999998], [4076.409999999998, 4096.309999999998], [4096.309999999998, 4106.7289999999975], [4106.7289999999975, 4160.379999999997], [4160.379999999997, 4199.139999999998], [4199.139999999998, 4211.389999999998], [4211.389999999998, 4223.559999999998], [4223.559999999998, 4233.729999999998], [4233.729999999998, 4244.079999999998], [4244.079999999998, 4255.659999999998], [4255.659999999998, 4266.249999999998], [4266.249999999998, 4278.369999999998], [4278.369999999998, 4288.973999999998], [4288.973999999998, 4300.069999999998], [4300.069999999998, 4311.209999999998], [4311.209999999998, 4325.029999999998], [4325.029999999998, 4337.508999999998], [4337.508999999998, 4349.539999999998], [4349.539999999998, 4361.369999999998], [4361.369999999998, 4374.739999999998], [4374.739999999998, 4384.770999999998], [4384.770999999998, 4395.754999999998], [4395.754999999998, 4408.759999999998], [4408.759999999998, 4423.6799999999985], [4423.6799999999985, 4436.379999999998], [4436.379999999998, 4448.152999999998], [4448.152999999998, 4459.6799999999985], [4459.6799999999985, 4469.799999999998], [4469.799999999998, 4480.209999999998], [4480.209999999998, 4490.789999999998], [4490.789999999998, 4501.199999999998], [4501.199999999998, 4512.789999999998], [4512.789999999998, 4523.149999999998], [4523.149999999998, 4534.709999999998], [4534.709999999998, 4545.859999999998], [4545.859999999998, 4555.899999999998], [4555.899999999998, 4571.129999999997], [4571.129999999997, 4581.859999999997], [4581.859999999997, 4593.869999999997], [4593.869999999997, 4604.0099999999975], [4604.0099999999975, 4614.409999999997], [4614.409999999997, 4624.749999999997], [4624.749999999997, 4634.819999999997], [4634.819999999997, 4646.819999999997], [4646.819999999997, 4650.279999999997]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [543, 1199, 2424, 2993, 3591, 4651]}
{"example_id": "mit126@@MIT2_003SCF11_lec18_300k", "text": ["PROFESSOR: OK, what I thought I would do  is I'm going to go quickly through the problems that ", "were assigned for practice.  There's seven or eight of them.  I'm not going to do all of them.  I'm going to go through and kind of  talk about what some of the key issues are with each problem ", "and maybe make some points about identifying  how you do problems, not necessarily specifically focus ", "on the exact question that was asked here.  So here was this first-- this was a quiz from last year.  And you were asked to find an equation of motion ", "for this thing.  And it can be a bit of a puzzling problem,  so how many degrees of freedom, what are the constraints, what  equation should you use.  ", "So first of all, I look at a problem like this.  Is it planar motion or not?  OK, so maximum three degrees of freedom.  What are the constraints, though?  ", "STUDENT: So G is [INAUDIBLE].  PROFESSOR: So G is R/2 from the center.  So that's true.  And so what you're really saying is it's fixed in radial motion, ", "right?  And you're right.  So that's one constraint.  What's another constraint in this problem?   How many degrees of freedom do you expect to end up with? ", "How many equations do you need?  How many coordinates?  One, right?  So how do we articulate the other constraint?   So it can't move radially. ", "We figured that out.  ", "So this is actually kind of an important point  in this problem.  Because if you can get this down,  then the problem becomes very simple.  ", "So talk to a neighbor.  How would you describe the other constraint here?  I'm going to hold it a second.  STUDENT: [INAUDIBLE]  PROFESSOR: Pardon?  STUDENT: Gravity is just [INAUDIBLE]. ", "PROFESSOR: Well, there is gravity, yes.  But gravity is not a constraint.  So this is a pendulum, actually, of sorts.   So talk to a neighbor.  How would you describe the other constraint? ", "", "OK, how would you describe it?  What's the other constraint here?  ", "So sometimes if something is pinned,  we say, well, then it's fixed in x and y.  And that's two constraints.  It's only left to rotate.  But this one doesn't seem to-- it's kind of hard ", "to understand where this one is pinned.  You know this thing is constrained in x and y.  Because you want to use theta for the coordinate, right?  But how do you say that it's constrained  in that other thing? ", "Yeah.  STUDENT: [INAUDIBLE]  ", "PROFESSOR: OK, so he's saying that you can define x  and y in terms of r and theta.  And that's true.  And I'm going to say it slightly differently.  So the way I think about this problem  is we've said that it's constrained ", "in the radial direction.  So that's one.  It can move in the tangential direction, right?  This problem is really exactly the same  as the skateboard problem in a bowl. ", "You shorten that thing a little bit,  and it looks like a skateboard.  And we're ignoring the inertia of the wheels.  So it's just a stick sliding up and down.  So what's the relationship between the tangential motion ", "and theta?  Is it a fixed relationship?  So how far does it move in the theta?  If you have a little motion, delta theta, ", "how far does it move tangentially?  R delta theta is the delta r tangential, ", "the distance it moves.  So this is the way to say the other constraint,  is if you know theta, you know how far it's  moved in the radial, in the tangential direction. ", "So that's a way of saying that other constraint.  OK, then we can say we completely describe  this problem by one coordinate.  And that's theta. ", "And the second you can do that, this problem then  has a center of rotation right in the center of the circle.  And anytime you have a body which ", "rotates around a central point, then  you know that you can describe the angular  momentum of the body as some I with respect  to A times-- and it's planar motion. ", "So then it's just omega z, as long as this is a principal,  as long as you have the mass moments of inertia in terms ", "of principal axes here.  And it's nice when you can write it that simply.  The second you can identify a fixed point about which ", "something rotates, then the angular momentum  simplifies to that.  OK, and then this problem, of course ", "the sum of the torques with respect to the center  here has got to be d H with respect to A dt plus vAO ", "cross PGO.  But this is-- what's the velocity at point A?   0, so you don't have to worry about this term. ", "And it's just that.  And you know that the sum of the external torques  in this problem comes from gravity. ", "So you put in the gravity term and compute the torques  about the center.   So our object really looks like that.  And here's G. And in the problem, the way it was posed, ", "the theta is drawn from this line.  So this is theta.  So what's the moment arm? ", "It looks like whatever this distance is, which is R/2.  It's given.  R/2 cosine theta is the length of this side. ", "So the moment that gravity makes is some Mg.  ", "And that's going to be equal to some Izz  about A theta double dot.  OK, good.  Let's take a look at the next problem. ", "And now so my intention here, I'm  going to go kind of quickly one by another.  And I'm just trying to hit the important concepts.  So if you have a question about the concepts, ask.  If I've left you wondering, I really ", "want this to be kind of a conversation here.  So that's the whole point.  I've given you the essence of what makes these problems work.  OK, this one, we just find a location of the center of mass. ", "I think you're pretty good at that sort of thing.  Well, remember just a couple points about center of mass.  This one it says, find it.  And you're given the two objects. ", "The important point is that you can  pick any coordinate at all in order  to use it to compute the center of mass.  So I pick S here, the M1. ", "And some distance down here is where the center of mass  is that we're looking for.  And so this is the G we're looking for.  So M1 plus M2 is the total mass times the position of G. ", "I guess that ought to be a capital-- SG here  must be equal to the sum of the parts times their positions, M1 ", "SG1 plus M2 SG2.  And you can solve for SG.  And that tells you where you're at.  So you can pick any coordinate at all to calculate it. ", "And once you find it, you know where it is.  So you just solve here for SG.  It's that divided by the total mass, obviously. ", "OK, the next question was, draw principal axes.  So does this object have some planes of symmetry? ", "Tell me one.  STUDENT: This one.  PROFESSOR: Slice down through it this way, OK.  And that means you have a principal axis where?  Perpendicular to every plane of symmetry.  So you have a principal axis coming out of the board. ", "That's one.  And give me another plane of symmetry.  STUDENT: [INAUDIBLE]  PROFESSOR: Yeah, this one.  So that means you've got a plane of axis,  principal axis going that way.  And so then the third one has to be perpendicular to that. ", "So you have one this way, this way, and this way.  ", "So I'd asked for-- so if this is G, then principal axes  with respect to G, one there, one coming out of the board, ", "and one going up like that.   So what is it? ", "Let's remind ourselves what it means to be a principal axis.  So if you know the principal axes of an object, ", "if you rotate, and you've chosen them to go through G,  do they have to go through G?  Do all principal axes have to go through G?  No, not at all. ", "The principal axes just have to give you, when you work it out,  a diagonal inertia matrix.  ", "But what does it mean to have body  coordinates that we know are principal axes?  Well, one of the things we know, that if you rotate about G, ", "rotate about a principal axis passing through G,  if you rotate about any one of them,  is it dynamically balanced?  ", "Guaranteed.  You must rotate about the principal axis, though.  Now, I'll ask you a second question.  If you rotate about any axis passing through G, ", "is it statically balanced?  Right, if you rotate about any axis passing through G,  is it dynamically balanced?  Maybe, right?  Not necessarily. ", "It might be dynamically balanced if you pass through G,  and it is a principal axis, right?  OK, can you have a principal axis not going through G ", "and rotate about that axis and have  it be dynamically balanced?  Yeah, OK, so we'll talk about an example in a second. ", "OK, so I think the second question here said,  OK, we want to rotate this about this point G2. ", "Now, G2 is right in the middle at this body.  That's where its center of mass is.  And there's a G1 up here that's the center of mass  of the upper body.  And there's a composite center of mass right ", "here, which we just computed what it was.  And we want-- there's going to be an axis of rotation passing  through G2. ", "And we're rotating this body around it.  So first question is, this axis coming through G2,  is it a principal axis?  Yes.  If we rotate about that axis only, ", "do you expect it to be dynamically balanced?  Right.  Do you expect it to be statically balanced?  No.  ", "So we're spinning it around this G2, going like that around G2 ", "at some omega z.  We know that this is G2.  We know that G for the object is here.  That's the center of mass of the whole thing. ", "So there's some distance between those two, which I don't know.  But we could figure it out.  We'll call it e.  So what's the force required at this pin ", "that its axle is going around?  What's the force required to allow this thing  to spin around, to hold it, essentially, the force required  to hold it in place? ", "And you ought to intuitively have an idea of what it is.  Why is there a force?  That thing will spin around this central axle.  And there's a force required to keep  that thing from moving away. ", "What is it?  STUDENT: Centrifugal force.  PROFESSOR: I hear centrifugal.  So you're accelerating the center of mass of that thing. ", "You're making it go in a circle.  Mass times acceleration is a force.  And that's the tension in the string when you're  swinging the ball around.  This is no different from swinging the ball on a string. ", "And you're essentially calculating  the tension required to keep that thing from flying off.  And we could probably just guess.  We can almost guess what it is, minus the total mass times ", "the acceleration, which is inward.  That's where the minus comes from.  And what is it?   STUDENT: [INAUDIBLE]  PROFESSOR: Louder. ", "STUDENT: [INAUDIBLE]  PROFESSOR: Omega squared.  I hear an omega z squared.  We need something else.  Pardon?  STUDENT: [INAUDIBLE]  PROFESSOR: Yeah, the r.  And the r is this little e here. ", "It's called the eccentricity, when  you have something unbalanced. e omega squared,  and it's in the r hat direction.  We'll call it inwards.  And the inwards is the minus. ", "So that's the acceleration.  Mass times acceleration is the force.  Also, you could compute this by computing d by dt of P of G ", "with respect to O. And that's then  M1 plus M2 times v of G. You have to take the d by dt of it. ", "And that gives you that, which is the acceleration.  So the forces you get directly from computing dP/dt,  if you need to remember a way to do that. ", "All right, so conceptually, if I don't know what e is,  then I don't want to have to figure it out. ", " So I'm going to describe to you a way in which you could  get directly at this answer, which  reminds us something about angular ", "momentum and these bodies.  This object is made up of two objects.  ", "And we're spinning it about the center of one of them.  So let's take them one at a time.  How much force is required to keep this spinning ", "about that axle that goes right through its center of mass?  None, right?  Because there's no r omega squared.  There's no acceleration. ", "You're not making the center of mass of this object  go in a circle.  So this piece doesn't enter into the solution.  The actual force, the mass, this mass here, ", "is M2 in the problem.  M2 doesn't actually have anything to do with the answer.  Because it's perfectly statically  balanced around that point. ", "All of this force making the thing go in a circle  is making this piece go in a circle.  So in fact, this force up here is minus M1. ", " And now we need the distance from the axis of rotation  to its center of mass. ", "Well, that's some r.  We need to know what that r is.  And I think that's basically-- this was L/2.  And this was b, so plus b/2. ", "So the distance from this rotation point  to that center of mass is L/2 plus b/2, omega z squared. ", "Mass-- this is acceleration, and it's inwards.  And that's the total force.   All right, let's look at the next problem.  ", "Vicente, can you pull up the next one?  ", "OK, this problem-- this problem and the next  are rather similar.  This is the elevator problem with the pendulum  in the elevator.  ", "There's a couple subtleties here.  The elevator, you're told that it's moving upwards  at some particular rate of acceleration,  some y double dot. ", "That's given.  So how many degrees of freedom does this problem have?   OK, two or one?  I hear one. ", "I see a two.  How many coordinates is it going to take  to completely describe the motion,  or how many equations of motion do  you think you're going to need? ", " I see ones and twos.  So there's a little not-- two, OK.   If we know the acceleration of the thing-- we start ", "with some initial conditions, at time 0,  it's sitting on the ground, and y equals 0,  and now it takes off from the first floor-- we  know for all time its position. ", "So that's actually a given.  It's a specified thing.  And we don't have to write a separate equation of motion  for that that we then will have to solve. ", "So it's actually given.  So the actually only dynamic equation  of motion we have to write is about the pendulum.  Now, will it involve y double dot?  Absolutely.  But it's a given number. ", "It's just a number you're given.  You don't have to write a separate equation of motion.  So actually you've got just one degree of freedom.  Yeah.  STUDENT: [INAUDIBLE]  PROFESSOR: OK, so put up the next problem-- that one. ", "So this problem has how many degrees of freedom?  This is definitely two.  Because you don't know.  The motion in the up and down of the mass  and the slider with a spring on it is unknown. ", "You're going to have to write an equation of motion, which  would have to be solved to get it, so a distinction,  a subtlety that can trip you up.  When the motion is actually specified, ", "and you know what it is for all time,  you don't need a separate equation for that.  So this problem requires two.  The behavior of the pendulum part  is essentially the same in both. ", "When you write the equation-- well, let's talk about it.  How will we go about solving this problem?  We need two equations, two coordinates.  What would you pick for your coordinates?  STUDENT: [INAUDIBLE] ", " PROFESSOR: Theta, and then a coordinate.  This one I guess is called y, so y  for the square block sliding up and down, ", "and a theta for the pendulum, two equations of motion.  And to get the y equation of motion,  you would use-- we're not using Lagrange here.  We're going to do a little review of direct method. ", "How would you write the equation of motion using-- up there  I kind of wrote the key to everything  that we do with the direct method, some of the forces, ", "some of the torques.  Every rigid body has at max how many degrees of freedom?  Six for rigid body.  In planar motion, this is reduced to three. ", "But every rigid body in 3D space has  six degrees of freedom-- three positions, three rotations.  So you write some of the forces on the body. ", "That is equal to the mass times acceleration.  That gives you three equations, one in each vector, component  direction.  You write the sum of the torques.  That's also a vector equation. ", "You can get as many as three equations out of it  if you need it.  Then we keep reducing down how many  equations we need to get by figuring out the constraints  until we get down to the number of actual degrees of freedom. ", "And that's the remaining equations, the number  of equations you actually need.  So this one requires two.  And if you're going to write an equation of motion ", "about the main mass that slides up and down, what law would  you use?  STUDENT: [INAUDIBLE]  PROFESSOR: Yeah, sum of the forces  equal to the mass times acceleration. ", "Then we need to get another question.  What law would you use for the second one?  STUDENT: Torque.  PROFESSOR: Torque about where?  STUDENT: A.  PROFESSOR: Torque about A. So let's look at that. ", "So that's the second equation up there.  Torque about A is the time derivative  of the angular momentum with respect to A plus  that vA cross momentum term, which is ", "a little annoying to work out.  So the simpler version is the third equation.  It's a pretty quick derivation to go from that second equation  to the third. ", "And it's much less work, generally,  to get that mass times acceleration  term, a lot less work actually.  And if I've got time, I'll go back ", "and we'll work out a problem like this.  And we'll do that part.  But let's go on to the other questions.  OK, this problem-- two rigid bodies. ", "Is it planar motion?  STUDENT: Yes.  PROFESSOR: Right?  How many possible degrees of freedom for each rigid body?  Times 2, 6, now how many constraints? ", "So let's take them one rigid body at a time.  It's a big roller.  Pardon?  STUDENT: No y.  PROFESSOR: No y, she says.  OK, that's one constraint in it-- two left,  two possible things left. ", "STUDENT: No slip.  PROFESSOR: Ahh, so I think this one's no slip.  So how does a no slip then give you a constraint?  STUDENT: So x dot equals r omega of the wheel turning. ", "PROFESSOR: So r, there's an r.  X equals r theta, or minus r theta  depending on how you define the theta, right?  So x is not independent of theta. ", "And that's a second constraint.  So you only need one equation, one generalized coordinate,  to describe the motion of the wheel.  And what would you use?  ", "STUDENT: Theta?  PROFESSOR: OK, theta.  You could use theta.  Or you could use x.  All right, and now the other object, how many constraints  does it have? ", "And what are they?  What are the constraints on the T bar?   STUDENT: Can't translate the y.  PROFESSOR: OK, that's true. ", "Let me give you a little hint about how I process  this when I'm looking at it.  Remember when you're picking generalized coordinates, ", "they need to be independent.  And independent means if you freeze all but one,  that last one can still move.  OK, so we've picked one.  You said theta or x. ", "Let's freeze it.  What motion is left of that T bar?  STUDENT: [INAUDIBLE]  PROFESSOR: It can only rotate, right?  And that means it has a pin, a point ", "about at which it rotates, which you have just fixed.  So it's constrained.  That pin constrains it in how many directions?  STUDENT: Two.  PROFESSOR: Two, right off the bat. ", "You have the two constraints right at the pin.  But it's not so obvious until you say, let's freeze  at other coordinates.  And then we see that, ahh, there's  only one possible motion left, the rotation. ", "OK, so we have a rotation and a translation, or two rotations.  That's the way we could write equations of motion.  If we did translation of the main disk, ", "what equation would you use to write the equation of motion  for the main disk?  STUDENT: Force.  PROFESSOR: Force, yeah. ", "Newton's second law, sum of the forces in what direction?   It can only move in--  STUDENT: [INAUDIBLE]  PROFESSOR: Horizontal, yeah.  So sum of the forces in the x direction, ", "sum of external forces in the x direction,  equals mass times acceleration.  Now this, though, has some problematic external forces,  right?  What are they, the difficult ones? ", "STUDENT: [INAUDIBLE]  PROFESSOR: Well, friction.  There's a friction force.  And there's also the internal forces at the pin.  So you're going to have to sort out how ", "to work your way through that.  If you don't want to mess with external forces at the pin,  you have to sum rotations at the--  STUDENT: [INAUDIBLE]  ", "PROFESSOR: Yeah, so this problem,  there's no escaping something messy.   So let's say one equation will be ", "the sum of the forces on that main roller  in the horizontal direction.  And that's going to force us to deal with a friction  force and an internal, two reaction forces at the pin. ", "Well, you just write them down.  Then go and write the same expression, sum of the forces  on the other object.  And it'll also show up with those two internal forces. ", "You add those two equations together.  Those forces cancel.   And that gives you the first equation.  And it'll involve acceleration of both masses. ", "And you'll have to figure out the acceleration  of that second mass around its own.  But you know how to do that.  That's just kinematics.  ", "And then you've got to do the torque equation.  And you'd probably do it about A.  And does this involve-- what about the velocity of A ", "in this problem?  Is it 0?  No, so you may have to deal with that second term.  And again, I would go use the third expression.  Because you need to find the accelerations anyway. ", "And I would use that.  Yeah.  STUDENT: Could you also take the sum of the torques about d?  PROFESSOR: Some of the torques about?  STUDENT: d?  PROFESSOR: Then d is the point of contact.  ", "Yeah, and that would give you a way of getting at,  I think, an equation of motion that mostly  describes the big roller.  ", "I don't know.  In terms of the other one, I'm not--  summing it, then talking about the second rigid body?  I don't think I would do it. ", "It gets a little complicated.  But it's interesting.  It might be worth a try.  I'd probably do it about A, is the point I would choose,  and deal with the fact that you need ", "to know the acceleration of A. But in this problem,  that's pretty straightforward.  What's the acceleration of point A?  And let's say our horizontal coordinate is x. ", "What's the acceleration of point A?  x double dot in the I direction-- pretty easy  to stick that in this third expression up here.  And you know Rg with respect to A ", "is just the length of the distance down  to the center of mass of that T. So that term's  pretty easy to figure out.  And then the lead term is just everything with respect to g. ", "And that's pretty straightforward.  OK, good, how are we doing on time?  Not a lot left.  And is that the last problem?  Yeah.  STUDENT: Quick question. ", "The previous problem, we don't need to worry about friction,  do we?  STUDENT: If it was slipping, we would.  PROFESSOR: Yeah, will friction ultimately  end up in the answer to this one? ", "No.   STUDENT: [INAUDIBLE]   PROFESSOR: Well, speaking in Lagrange terms, ", "does it do any work?  STUDENT: [INAUDIBLE]  PROFESSOR: I know, but you know about it now, right?  Constraints that do no work usually  don't end up in the final answer. ", " I don't have a simple way of explaining why it doesn't. ", "But if in the first case, instead of doing Newton's law  on the first one, we had done torques about d,  it would have given us an equation of motion  for the roller. ", "And then you could have done torques  about A, a different equation.  And we'd have got an equation of motion largely dealing  with T. You still have some internal forces  and torques that you're going to have to eliminate. ", "So this is not a simple problem, but straightforward if you  know what laws to apply to some of the forces, some  of the torques. ", "And be careful with the extra term.  If this object were just given an initial deflection,  like the T bar is picked up and let go, and it's just there,  and it's just doing its thing, what ", "can you say about the center of mass of the system?   STUDENT: [INAUDIBLE]  PROFESSOR: Well, it's not that it doesn't necessarily move. ", " Well, let's put it this way.  What if I gave this thing a push to start with,  and now it's going to roll along? ", "Huh?  STUDENT: [INAUDIBLE]  PROFESSOR: OK, in that case, you're  saying that the center of mass moves with constant velocity.  And Newton would agree with you. ", "Why?  STUDENT: [INAUDIBLE]   PROFESSOR: Because once it gets rolling, is there  any friction force?  STUDENT: No.  PROFESSOR: So you've got to draw the free body diagram ", "and decide whether or not there are any forces on the system.  If there are no external forces on the system,  Newton says no acceleration, no change in momentum. ", "So once you get it rolling, there's  actually no friction force.  Because it isn't trying to either speed up or slow down  the rolling.  So it goes actually to 0.  Is there slip? ", "No, it still isn't slipping.  But it's just happily rolling along.  There are no external forces acting on it.  It means the mass times the acceleration of the center  of mass of the system is zero.  So the center of mass does not accelerate. ", "That means it has constant velocity.  Now, if I contrive to have the initial velocity of the center  of mass be 0, just cause that thing to swing back and forth, ", "what would you see the center of mass do?  It has no linear momentum.  The linear momentum of the system is 0.  So the center of mass sits still. ", "Its velocity now is 0.  There's still no acceleration.  It's just this T bar is rocking back and forth.  So what must the roller be doing?  STUDENT: [INAUDIBLE]  PROFESSOR: So the roller has to move to the left ", "when the T bar is going to the right.  So the two things are going like this.  In the center of mass, wherever it is, it's just sitting still.  All right, is there a last problem? ", " This forces you to go back to the fundamental definition  of angular momentum.  It's R cross, this little summation of each RI cross PI. ", "And add them up, and you get the angular momentum with respect  to the rotational point, 1 degree of freedom,  has a center of mass.  Where is the center of mass of the system? ", "Can you describe it?   STUDENT: Right in between--  PROFESSOR: Somewhere in between the two masses.  There are two point masses, center mass  has to be someplace in between. ", "So once you figure out where that is, then  you can concentrate all the mass there and go from there.  Does this have mass moment of inertia?  ", "Can you write the equation of motion?  This is a pendulum.  Can you write I about A theta double dot equals minus Mg ", "something sine theta?  This is a pendulum.  The restoring torque on it comes from gravity.  And you'll end up with an expression ", "that looks like some I with respect  to the point of rotation.  So basically, you just need to figure out  what is I with respect to A. And they're particles. ", "So each particle has an I with respect to its center of mass.  It's equal to, for a particle, concentrated point mass? ", "STUDENT: Mr squared?  PROFESSOR: Yeah, but there's no r.  So I for a particle about its center mass is 0.  So this only has parallel axis theorem components. ", "It has M1 times this distance squared  from the center plus M2 times this distance squared  from the center.  And that's the total Izz.  So then you can write it out. ", "OK, so I think we've run out of time. "], "vid_duration": [10.549, 11.021, 11.84, 11.88, 12.22, 14.9, 15.11, 11.53, 11.23, 14.5, 11.15, 10.63, 11.715, 41.595, 15.9, 10.52, 10.613, 10.957, 12.18, 12.05, 12.28, 10.98, 10.05, 12.12, 12.14, 11.78, 12.81, 10.51, 10.31, 11.3, 11.62, 12.39, 10.55, 15.955, 10.817, 15.208, 11.95, 16.51, 11.24, 13.319, 12.526, 11.595, 16.376, 10.184, 12.71, 11.28, 14.8, 11.96, 13.32, 16.689, 11.481, 10.2, 10.32, 11.43, 11.93, 13.0, 10.15, 10.96, 11.04, 17.47, 11.64, 11.54, 11.82, 10.775, 12.13, 20.565, 21.08, 11.82, 12.01, 11.89, 11.1, 11.41, 10.42, 15.44, 10.658, 10.929, 10.273, 11.1, 13.32, 11.46, 10.349, 12.24, 10.161, 17.87, 10.17, 12.8, 10.31, 11.75, 11.86, 11.01, 17.03, 13.3, 18.8, 10.224, 12.616, 10.31, 10.151, 14.609, 11.01, 11.24, 10.117, 15.023, 12.424, 11.286, 14.0, 10.736, 10.394, 10.205, 11.015, 12.17, 11.16, 10.42, 12.68, 10.83, 11.219, 10.091, 13.44, 10.54, 13.05, 11.88, 12.75, 10.97, 11.63, 13.669, 11.381, 10.455, 11.415, 11.74, 10.18, 12.39, 11.14, 10.53, 10.44, 10.04, 11.79, 11.759, 11.811, 13.316, 13.224, 11.87, 11.089, 11.071, 10.46, 12.412, 11.708, 14.02, 14.36, 10.62, 10.52, 10.4, 12.33, 12.1, 10.708, 14.047, 11.315, 10.165, 12.005, 11.99, 11.43, 10.35, 11.98, 13.415, 11.536, 10.799, 10.712, 10.448, 11.375, 11.54, 10.135, 14.709, 12.341, 10.43, 15.2, 11.0, 10.17, 13.2, 11.77, 11.57, 11.14, 10.73, 11.68, 10.26, 5.36], "stet": [[0, 10.549], [10.549, 21.57], [21.57, 33.41], [33.41, 45.29], [45.29, 57.51], [57.51, 72.41], [72.41, 87.52], [87.52, 99.05], [99.05, 110.28], [110.28, 124.78], [124.78, 135.93], [135.93, 146.56], [146.56, 158.275], [158.275, 199.87], [199.87, 215.77], [215.77, 226.29000000000002], [226.29000000000002, 236.90300000000002], [236.90300000000002, 247.86], [247.86, 260.04], [260.04, 272.09000000000003], [272.09000000000003, 284.37], [284.37, 295.35], [295.35, 305.40000000000003], [305.40000000000003, 317.52000000000004], [317.52000000000004, 329.66], [329.66, 341.44], [341.44, 354.25], [354.25, 364.76], [364.76, 375.07], [375.07, 386.37], [386.37, 397.99], [397.99, 410.38], [410.38, 420.93], [420.93, 436.885], [436.885, 447.702], [447.702, 462.91], [462.91, 474.86], [474.86, 491.37], [491.37, 502.61], [502.61, 515.929], [515.929, 528.4549999999999], [528.4549999999999, 540.05], [540.05, 556.4259999999999], [556.4259999999999, 566.6099999999999], [566.6099999999999, 579.3199999999999], [579.3199999999999, 590.5999999999999], [590.5999999999999, 605.3999999999999], [605.3999999999999, 617.3599999999999], [617.3599999999999, 630.68], [630.68, 647.3689999999999], [647.3689999999999, 658.8499999999999], [658.8499999999999, 669.05], [669.05, 679.37], [679.37, 690.8], [690.8, 702.7299999999999], [702.7299999999999, 715.7299999999999], [715.7299999999999, 725.8799999999999], [725.8799999999999, 736.8399999999999], [736.8399999999999, 747.8799999999999], [747.8799999999999, 765.3499999999999], [765.3499999999999, 776.9899999999999], [776.9899999999999, 788.5299999999999], [788.5299999999999, 800.3499999999999], [800.3499999999999, 811.1249999999999], [811.1249999999999, 823.2549999999999], [823.2549999999999, 843.8199999999999], [843.8199999999999, 864.9], [864.9, 876.72], [876.72, 888.73], [888.73, 900.62], [900.62, 911.72], [911.72, 923.13], [923.13, 933.55], [933.55, 948.99], [948.99, 959.648], [959.648, 970.577], [970.577, 980.85], [980.85, 991.95], [991.95, 1005.2700000000001], [1005.2700000000001, 1016.7300000000001], [1016.7300000000001, 1027.0790000000002], [1027.0790000000002, 1039.3190000000002], [1039.3190000000002, 1049.4800000000002], [1049.4800000000002, 1067.3500000000001], [1067.3500000000001, 1077.5200000000002], [1077.5200000000002, 1090.3200000000002], [1090.3200000000002, 1100.63], [1100.63, 1112.38], [1112.38, 1124.24], [1124.24, 1135.25], [1135.25, 1152.28], [1152.28, 1165.58], [1165.58, 1184.3799999999999], [1184.3799999999999, 1194.6039999999998], [1194.6039999999998, 1207.2199999999998], [1207.2199999999998, 1217.5299999999997], [1217.5299999999997, 1227.6809999999998], [1227.6809999999998, 1242.2899999999997], [1242.2899999999997, 1253.2999999999997], [1253.2999999999997, 1264.5399999999997], [1264.5399999999997, 1274.6569999999997], [1274.6569999999997, 1289.6799999999996], [1289.6799999999996, 1302.1039999999996], [1302.1039999999996, 1313.3899999999996], [1313.3899999999996, 1327.3899999999996], [1327.3899999999996, 1338.1259999999997], [1338.1259999999997, 1348.5199999999998], [1348.5199999999998, 1358.7249999999997], [1358.7249999999997, 1369.7399999999998], [1369.7399999999998, 1381.9099999999999], [1381.9099999999999, 1393.07], [1393.07, 1403.49], [1403.49, 1416.17], [1416.17, 1427.0], [1427.0, 1438.219], [1438.219, 1448.31], [1448.31, 1461.75], [1461.75, 1472.29], [1472.29, 1485.34], [1485.34, 1497.22], [1497.22, 1509.97], [1509.97, 1520.94], [1520.94, 1532.5700000000002], [1532.5700000000002, 1546.2390000000003], [1546.2390000000003, 1557.6200000000003], [1557.6200000000003, 1568.0750000000003], [1568.0750000000003, 1579.4900000000002], [1579.4900000000002, 1591.2300000000002], [1591.2300000000002, 1601.4100000000003], [1601.4100000000003, 1613.8000000000004], [1613.8000000000004, 1624.9400000000005], [1624.9400000000005, 1635.4700000000005], [1635.4700000000005, 1645.9100000000005], [1645.9100000000005, 1655.9500000000005], [1655.9500000000005, 1667.7400000000005], [1667.7400000000005, 1679.4990000000005], [1679.4990000000005, 1691.3100000000004], [1691.3100000000004, 1704.6260000000004], [1704.6260000000004, 1717.8500000000004], [1717.8500000000004, 1729.7200000000003], [1729.7200000000003, 1740.8090000000002], [1740.8090000000002, 1751.88], [1751.88, 1762.3400000000001], [1762.3400000000001, 1774.7520000000002], [1774.7520000000002, 1786.4600000000003], [1786.4600000000003, 1800.4800000000002], [1800.4800000000002, 1814.8400000000001], [1814.8400000000001, 1825.46], [1825.46, 1835.98], [1835.98, 1846.38], [1846.38, 1858.71], [1858.71, 1870.81], [1870.81, 1881.518], [1881.518, 1895.565], [1895.565, 1906.88], [1906.88, 1917.045], [1917.045, 1929.0500000000002], [1929.0500000000002, 1941.0400000000002], [1941.0400000000002, 1952.4700000000003], [1952.4700000000003, 1962.8200000000002], [1962.8200000000002, 1974.8000000000002], [1974.8000000000002, 1988.2150000000001], [1988.2150000000001, 1999.7510000000002], [1999.7510000000002, 2010.5500000000002], [2010.5500000000002, 2021.2620000000002], [2021.2620000000002, 2031.7100000000003], [2031.7100000000003, 2043.0850000000003], [2043.0850000000003, 2054.6250000000005], [2054.6250000000005, 2064.7600000000007], [2064.7600000000007, 2079.4690000000005], [2079.4690000000005, 2091.8100000000004], [2091.8100000000004, 2102.2400000000002], [2102.2400000000002, 2117.44], [2117.44, 2128.44], [2128.44, 2138.61], [2138.61, 2151.81], [2151.81, 2163.58], [2163.58, 2175.15], [2175.15, 2186.29], [2186.29, 2197.02], [2197.02, 2208.7], [2208.7, 2218.96], [2218.96, 2224.32]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [483, 1159, 1489, 2225]}
{"example_id": "mit126@@MIT2_003SCF11_lec27_300k", "text": ["PROFESSOR: Today we are going to talk about the vibration  of continuous systems.  Not covered on the quiz, but it's ", "a really important part of real-world vibration  and the most-- one of the easiest ones to demonstrate, ", "I've shown you this one before, is the taut string.  But I want to show you something unusual about-- something  you may not know about strings. ", "Wait until it calms down here a little bit.   OK, so this is your guitar string or a piano string. ", "It's under tension.  We've already seen that it exhibits  natural frequencies in mode shape,  so there's the first mode.  Looks like half a sine wave. ", "Has a particular frequency associated with it.  Get it to stop doing that-- but if I excite it  at twice the frequency-- I don't know if I can do this. ", "There we go.   That turns out to be exactly twice  the frequency of the first.  The mode shaped one full sine wave. ", "The mode shapes for a taut string are sine n pi x over L.  But strings can do something else kind of neat.  ", "And that is if I hit this thing--  I'm going to wait till it calms down here.   If I give this thing just a pulse, ", "what do you expect to see?  Are you going to see vibration?  Tell me what you see.  ", "What do you see happening?  Something running back and forth.  Right?  What you're seeing is wave propagation.  It's not really vibration.  Vibration we see of its modes and standing waves and things ", "like that.  Right?  So the taut string satisfies an equation of motion that's  called the wave equation.  We're going to talk quite a bit about that this morning. ", "And the wave equation has its name give something away.  The wave equation describes continuous systems  of a particular kind that support travelling waves. ", "And so the string will both support--  I can give it a little pluck.  I'll try to just place it in a particular shape and let go.  There it is. ", "And that little pluck just goes back and forth back and forth  at a particular speed.  So is there a relationship between the speed  at which things can travel in a string  and the natural frequencies of the string? ", "Well, we'll get into that today.   And I'm going to start by just showing you  a little something that comes from my research ", "and-- let's see.  Let me do this.  I think this will work.  ", "Hear that?  As I go slower, does frequency go up or down?  It's kind of slow, and I'm going to speed up.  ", "Right?  Goes up as the speed goes up.  So that's the result of the phenomenon  called flow-induced vibration.  And I'll give you a very brief intro ", "to flow-induced vibration.  You have a cylinder sitting still, flow coming by it--  water or air.  The cylinder is diameter D, velocity U, for the flow. ", "What happens in the wake of that cylinder, vortices are formed.  And just like if you're paddling a canoe or something  and stick a paddle in the water, you'll  see vortices shed off the side. ", "First you get one that's positive  and then one that's negative And so one full cycle of this  is from here to here.  There's a frequency to this shedding. ", "And the shedding frequency, FS, in hertz,  can be predicted by a simple dimensionless parameter called  the Strouhal number, St U over D. And that's approximately 0.2 ", "U/D for stationary cylinders.  You can predict the frequency at which these vortices are shed.  Now, associated with the shedding of vortices  is a lift force. ", "I'll call it some FL cosine omega  t, which is 2 pi FS, times t.  So at this frequency of vortex shedding ", "there is a transverse force.  There's actually an inline force also,  which I'll call FD for drag.  And it goes like cosine 2 omega s times t. ", "It's twice the frequency of that.  And so you'll get some inline oscillatory excitation  and what we call cross-flow oscillatory excitation. ", "And this is the cause of lots of things  that the people who work on it call flow-induced vibration. ", "Now, an amazing thing happens is if this cylinder is elastically  mounted or is flexible, and that force starts to act on it, ", "it will begin to vibrate.  And the amazing thing, as it begins to vibrate,  it correlates the shedding of these vortices ", "all along the cylinder.  So it's like soldiers marching in step  going across the bridge.  If everybody's walking randomly, then the bridge  doesn't respond too much. ", "But if everybody marches together,  you can put a pretty good excitation into it.  Well, the motion of the cylinder itself  organizes these vortex shedding all along the cylinder, ", "so they're all marching in step.  And that means the force is all correlated on the length.  And you can get some pretty substantial response.  So that's the subject called flow-induced vibration. ", "And with that, I'm going to show you a few slides.  Let's dim the lights a little bit, if you could, to see this.  There's some pictures I just want you to see better. ", "All right.  So I do flow-induced vibration.  I've been doing this-- working on this  for all my professional career.  And it's applied, primarily, to big, flexible cylinders ", "in the ocean.  Particularly associated with the things that the US Navy does.  Long cables and things and also the offshore oil industry.  Next slide.  Can we dim the lights? ", " Can we dim the lights?   I want you to be able to see. ", "This is a tension leg platform.  It's one of the structures that's  used in the offshore industry to produce oil.  And one of these might be moored in 3,000 feet of water, ", "1,000 meters of water.  Might weigh 20,000 tons.  And what's connecting it-- what holds in place--  are steel cylinders a half a meter  in diameter, 3,000 feet long, going vertically ", "down from each of those three pontoon legs sticking out.  And they're under a lot of tension.  And in fact, it pulls the thing down into the water  so the buoyancy of the whole thing ", "puts tension on these cylinders.  But now, what happens if an ocean current  comes by those cylinders?  Vortex shedding, and the cylinders vibrate.  And if they vibrate, over time they will fatigue and fail. ", "OK.  Next slide.  There's a picture of a real one.  That's a bigger one called Marco Polo.  It's on a launch ship that'll take it out to the site  that it is.  And the ship will lower and it will slide off. ", "So these are big.  Next slide.  This is a diagram of the Gulf of Mexico.  South America is at the bottom.  The Yucatan Peninsula is sticking up there right  in the middle of the bottom. ", "This is a picture of satellite imagery of currents  in the Gulf of Mexico.  And there's a current that flows up off of South America  into the Gulf of Mexico, goes around in a loop, ", "and then comes out.  You can see Florida sticking down in there on the right.  That current comes out of the Gulf,  goes around the tip of Florida, and goes up the Atlantic Coast,  and is known as the Gulf Stream. ", "But it starts as a big current that  comes into the Gulf of Mexic.  And, every now and then, that current pinches off an eddy.  And that's what that red circle is in the middle.  And it's an eddy that's many, many kilometers in diameter ", "with surface currents on the order of a meter per second  or more.  And those are the biggest threat for causing ", "flow-induced vibration failures of long members  from hanging off of offshore structures.  Next.  So I've been doing research in this area for a long time. ", "This is a picture taken in the summer of 1981.  It is a piece of steel pipe about 2 inches  in diameter and 75 feet long.  It's under 750 pounds of tension, ", "and it's pinned at each end.  It behaves almost exactly like my rubber cord here.  It has natural frequencies, and it will vibrate ", "if a current comes by it.  So this is actually a sandbar.  And at low tide, we'd do all the work putting it up.  Then, as the tide comes in, the flow  is perpendicular to the cylinder, ", "and vortices start shedding.  And as the pipe begins to move, they  get organized all along the length.  And a typical response mode was when ", "the vortex shedding frequency, therefore the lift force  frequency, coincided with the natural frequency.  Then you'd expect it to give quite a bit of response. ", "The diagram on the left is if you cut the cylinder  and looked down its axis, this is the trajectory  that you'd see the cylinder make.  It would sit there and just make big figure eights. ", "So up and down vertical is its vertical motion.  Flow's coming from, say, left to right.  Its vertical motion is up and down.  In-line motion's like this.  And exactly such a phase it just makes big beautiful figure ", "eights.  That's the kind of motion you'd see.  OK?  So then, very much what I was talking about a minute ago,  very much behavior dominated by vibration. ", "Vibration in the third mode, cross flow, was a typical one.  And fifth mode, inline, was typical.  But as cylinders go in the ocean, ", "that one's kind of short.  Third mode vibration is sort of low.  So as years have gone by and oil is  being produced in deeper and deeper and deeper water, ", "the cylinders we're putting out there  get longer and longer and longer and longer.  And the modes that are excited by currents coming by  get quite high.  So this is an experiment we did.  It was roughly a 1/10 scale model. ", "Model is almost 2 inches in diameter, 500 feet long.  Scale that up by a factor of 10, you're  up around 20 inches in diameter and 5,000 feet  long, which is exactly the size of the drilling riser ", "that BP had hung off the drilling  ship when the blowout occurred.  It's a piece of steel pipe, 21 inches in diameter, ", "3/4 of an inch wall thickness, 5,000 feet long,  under a lot of tension.  And when ocean currents come by, it  behaves just like this string.  And so we're out-- this is a 1/10 scale model. ", "So we put a big weight on the bottom of the cylinder,  put it behind a boat, and towed it in the Gulf Stream.  Next picture.  So there's the boat.  It's an oceanographic vessel.  It's actually a catamaran. ", "Next.  This is a spool that had our test cylinder on it.  There's a reddish object down on the bottom which  is-- that's a 750-pound piece of railroad wheel, ", "and it's the weight on the bottom.  And so you'd spool this thing off, lower it down,  and then do your tests.  Next.  Top, we measured tension inclination.  ", "And then we also had-- it's a pin joint at the top,  so it would vibrate freely.  Inside, though, was fiber optics.  Next. ", "We had eight optical fibers.  And in those optical fibers were what  we call optical strain gauges.  So we had 280 optical strain gauges instrumented up and down ", "that pipe so we could measure its vibration.  And so you're looking at a cross section of the pipe.  There were two optical fibers in each quadrant,  and each one of those fibers had 35 sensors on it. ", "Next.  This is typical experimental case.  This is the surface.  This is 500 feet down.  This is the current profile.  So the flow velocity is about 2 feet ", "per second near the surface, up to 4 feet  per second down on the bottom.  And this is the region where most of the excitation  was coming from that would drive the flow-induced vibration. ", "This is measured RMS strain caused by the bending vibration  in the cylinders.  And peak-- the maximum strain-- is about right there. ", "Next.  Typical response spectrum.  Basically, the frequency content at three different locations.  Down deep, in the middle, near the top.  This is frequency.  So this would be the peak that describes ", "the principal cross-flow vibration at the vortex  shedding frequency.  Next.   This is position, bottom to top. ", "This is time, and these are strain records from all  of those strain sensors.  There's a strain sensor about every 2 meters along here. ", "But what you're seeing is-- this is evidence.  The red is the amplitude and red--  let's say red is positive strain and blue is negative strain. ", "And so at any location on the pipe where it's vibrating,  it's going to go from red to blue, red to blue, red to blue.  But it's showing you that they're highly correlated  all along the length, that there's ", "a red streak all lined up, but it's not parallel to the pipe.  It's inclined.  This is showing you wave propagation.  The behavior of the pipe is completely  dominated by wave propagation, not by standing wave vibration. ", "So totally different than that short pipe in 1981.  The wave equation.  ", "Let's imagine we have a long pipe or a string like that,  and it can carry waves traveling along it. ", "The position at any location on here-- here's a coordinate x.  We describe the motion at a point  by a coordinate w of x and t. ", "So it's a function of where it is and time.  What describes the motion of something  which obeys the wave equation is the following equation. ", "Partial squared w with respect to x squared  equals 1/c squared partial squared w with respect ", "to t squared.  That's what's known as the one-dimensional wave equation.  And the one-dimensional wave equation  governs an incredibly broad category of physical phenomena. ", "Light behaves according to the wave equation.  Sound propagating across the room to you  is governed by the wave equation.  Longitudinal vibration of rods, torsional vibration of rods-- ", "all governed by the wave equation.  So it's worthwhile to know a little bit about the wave  equation.  And what I showed you this morning,  it has this kind of duality to it.  You can have things that vibrate with standing waves and mode ", "shapes, but the same system can support  waves that travel along it.  So let's figure out why that is.  ", "So I'm going to do the derivation for you of the wave  equation for a string, just so you  know where it comes from because then  that general derivation applies to all these different things. ", "So imagine you've got now-- we're interested in eventually  getting to vibration.  So I'm going to make this a finite length string. ", "And it has this position we'll describe as a w of x and t. ", "It has a tension, T, a mass per unit length, m.  So this is like kilograms per meter ", "is the mass per unit length of this thing which can vibrate.  So tension.  Mass per unit length.  L, the length of it. ", "What other parameters do we need?  That'll do for the moment.  Now-- so let's draw it again without.  ", "In some displaced position and what's exciting  it may be my vortex shedding, and so I'm going  to draw that excitation here. ", "And that we'll describe as F of x and t,  some force per unit length.  So this has units of newtons per meter. ", " Now, in that little-- there may also  be drag forces, the fluid damping.  ", "So I'm going to cut out a little piece of this cylinder  and do a force balance on that piece of cylinder. ", "So basically, F equals ma.  We're just applying Newton to this piece of cylinder.  And I'll draw it right here.  A little section of it is curved. ", "Here's horizontal.  There's horizontal.  We need to evaluate all the forces on it.  So the tension on this end-- so like that. ", "And the tension on this end is some different angle.   This we'll call theta 1.  This we'll call theta 2. ", "And along here are my excitation forces, F of x and t.  There may be some resistance-- drag forces, damping. ", "That'll be a damping constant, R of x,  which is force per unit length per unit velocity,  times-- the force on this would have ", "to be multiplied by the velocity, so  the derivative of this displacement with respect  to time.  That's the force along here, and it can vary with position. ", "Have we accounted for everything?  Ah, well, this is position x, and this is at x plus dx.  So this little element is dx in length. ", " And this is all for small motions.  ", "And if you assume small motions, then you  can say theta 1 is approximately equal to sine theta 1. ", "That's also approximately equal to tan theta 1.  And that's equal to the derivative of w with respect  to x, just the slope. ", "We're going to take advantage of that.  Theta 2, same thing.  It's approximately equal to tan theta 2 here, and sin ", "and all those things.  But that, then-- the slope has changed a little bit  when you go through dx.  And this is equal to the slope on the left-hand side ", "plus the rate of change of the slope times dx.  ", "So the slope on the left, this is now the slope  on the right-hand side.  And so now, all that's left to do  is to write a force balance for that little piece ", "on the element dx.   So if positive, upward.  We have a T sine theta. ", "But because sine theta is approximately tan  theta is equal to dw dx, then there's  an upward force on the right-hand side, which is T. ", "And this turns into partial squared w with respect  to x squared dx.  So on the right-hand side-- positive  upwards-- you have T times the partial ", "of w with respect to x, plus partial square w with respect  to x squared dx. ", "That's the upward force on the right-hand side.  On the left-hand side, we have a downward force, minus T partial  of w with respect to x. ", "And you notice that this one's going to cancel that one.  We have minus R of x partial w with respect to t-- ", "that's the velocity-- dx long.  Because that's force per unit length.  And have we missed anything?  So that's the sum of the external forces ", "on this little slice.  And that has to be equal to-- what did Newton say?  The mass, which is the mass per unit length, times dx, ", "is the total mass, times the acceleration,  partial squared w with respect to t squared.  ", "So this cancels this term.  And then you notice I'm left with everything  as just something dx, something dx, something dx. ", "Get rid of the dx's, and I can write-- oh, I  left out something. ", "I left out my distributed force, F of x and t dx.  It's positive as it's drawn. ", "It's over here also.  So this, and I cancel out that dx.  So I put them all together now and assemble them.  I can write down the equation that governs this motion. ", "So T partial square w with respect  to x squared minus r of x times velocity plus f of x and t ", "equals m partial square w with respect to t squared.  And that just says that the sum of the forces on the object  equals its mass times its acceleration. ", " Now, if we're interested in natural frequencies and mode  shapes, when we've been doing one and two degree of freedom ", "systems, and we want to get the natural frequencies in mode  shapes, we temporarily let the damping be 0 and the force  be 0, right?  So we want to do the same thing now.  We're interested in how do you find the omega n's and what I ", "call the psi n's.  Because now the mode shapes are functions.  And so this is a natural frequency  and the mode shape for mode n.  We know there's lots of modes. ", "So we let r of x and f of x and t be 0.  And when we do that, this term goes away. ", "This term goes away.  I'm just left with T partial squared w with respect  to x squared equals this.  And I'm going to divide through by t.  So I get partial squared w with respect to x squared equals 1 ", "over T over m partial squared w with respect to t squared. ", "And this T/m quantity turns out to be  the speed of wave propagation in the medium. ", " And that is the wave equation. ", " So we've just found the wave equation for the string  just by applying Newton's law to a little section of string. ", "You can do that for the vibrate.  You're going to do the same thing,  cut out a little section of a beam,  do the force balance on it, set it equal to the mass times  acceleration.  And for a beam, you'll get a fourth order differential ", "equation.  And it's not the wave equation.  It still vibrates, but it's not governed by what  we call the wave equation. ", "OK, so this is the one dimensional wave equation.  This quantity T/m is the phase velocity. ", "It's called phase velocity.  ", "You know, that's a good one to remember.  For a simple string, the speed of phenomena running down  the string is the square root of the tension divided  by the mass per unit length.  ", "And if you had a long string, I put that little pluck in it,  and you can see that pluck running back and forth on it.  That's the speed it's going at.  ", "Basically, it's called-- well, so if I have my string,  and I put a little bump on it, and that bump  goes zipping along, your eye will see  this thing propagating at c.  ", "So to get natural frequencies in mode shapes,  we basically need to solve this equation.  And it's quite straightforward to do. ", " And a technique known as separation  of variables works, which means that all you're doing ", "is saying, I believe that I'm going  to be able to write the solution as some function of x  only times some function of time only, product of two terms. ", "And that in fact-- because we're interested in vibration. ", "You can tell me what the function of time is.   You're going to tell me half the solution just from observation.  What is it? ", "Just the time dependent part.  It's the same as anything else that vibrates.  So a single degree of freedom system,  what is the time dependent function that we substitute in ", "to find the natural frequency?  AUDIENCE: [INAUDIBLE]   PROFESSOR: Say again?  AUDIENCE: e to the i omega t.  PROFESSOR: e to the i omega t would be just fine. ", "Cosine omega t works.  Sine omega t works.  But e to the i omega t is pretty easy to use.  Because it's so simple to take the derivatives.  So we can guess that this is going ", "to be some W of x times Ae to the i omega t.  And plug it in. ", " Plug it into our wave equation over here.  So I'll make sure I write it consistently. ", " So we plug this into the first term.  It's two derivatives with respect to x. ", "So this is just-- and the time-dependent part just  stays outside. ", " And on the right-hand side, when we plug it in here, 1 over c  squared, two derivatives with respect to time, ", "it's going to give me minus omega squared,  so minus omega squared over c squared.  And then it gives me back W of x Ae to the i omega t. ", "And now I can get rid of the Ae to the i omega t's.  And I'm left with just an equation involving x only.  And it's an ordinary differential equation ", "in w of x.   So it turns into d2W dx squared plus omega squared ", "over c squared W equals 0.  And you've seen this equation before.  Does this not look like, have some similarity to, ", "Mx double dot plus kx equals 0?  They're basically the same equation.  This one's a function of x.  That one's a function of time. ", "And we know the solution to this one is some x of t  is some amplitude e to the i omega t. ", "So therefore, we can guess that the solution to this one  is W of x is going to be-- I'll write it as some B. ", "Now I need a function of x.  But it can be just like this-- e to the i, and I'll say kx.  I know that's going to be a solution.  ", "So let's plug it in.  If I plug that in, I get minus k squared ", "Be to the ikx plus omega squared over c squared Be to the ikx ", "equals 0.  Well, now I get rid of these.  And what I found out is that k squared is  omega squared over c squared. ", "And this has a name-- k.   It's called the wave number. ", "And it also happens to be 2 pi over lambda.  We'll come back to that.  Lambda is the wavelength.  You have sinusoidal waves running through the medium. ", "2 pi over lambda is the same as omega over c.  And this is called the wave number-- ", "really important quantity if you're  trying to understand wave propagation in systems.  And actually, this one, this definition  applies to all wave bearing systems, ", "whether or not they obey the wave equation.  It'll apply to waves traveling down a beam as well.  So the definition of wave number is frequency divided by speed, ", "or 2 pi over the wavelength.  Well, let's see.  We can't go much further with just the wave equation itself. ", "In order to get the natural frequencies,  we have to invoke other information  that we know in the problem.  In particular, we know that in order  to get natural frequencies, we had to create conditions ", "where this could vibrate.  In particular, I fix that end, and I fix this end,  and I put some tension on it.  And now it'll vibrate.  But it clearly has something to do  with its ends and its length. ", "And so this is a boundary value problem.  And we have to invoke the boundary conditions to actually  finish finding the natural frequencies and mode shapes. ", " Apply the boundary conditions-- so I assumed here ", "that my W of x is going to look something like that.  In order to get a little more information out of this,  I'm going to write now W of x in an alternative form that's ", "equally valid.  And I'll call it B1 cosine kx plus a B2 sine kx. ", "And I could relate that to e to the ikx, B to the ikx,  by real and imaginary parts, and so forth.  This is a real part.  I'm saying in general it could have a cosine part and also ", "a sine part.  But now I know my boundary conditions are W at x equals 0.  W of 0 is what?  What's the displacement at x equals 0? ", "AUDIENCE: [INAUDIBLE]   PROFESSOR: 0.  That's the pin.  That's the end where it's fixed at.  And we started out here with a second order ", "partial differential equation.  And a second order equation requires two boundary  conditions.  A fourth order equation for the beam  will require four boundary conditions.  We only have to find two.  One of them is it has no motion on the left. ", "So you plug in 0 for x.  Cosine of 0 is 1.  Sine of 0 is 0.  So we find out that this is B1 times 1. ", "But it has to be 0 as the boundary condition.  So that implies B1 is 0.  There's no cosines in this answer.  And W at L is 0. ", "And so that says B2 sine kL equals 0. ", "And that's true.  That's only true if kL equals n pi. ", "So now I've found out that there's,  just for vibration of a finite length string,  only particular values of k that work.  So that says that there are special values of k which ", "I'll call k sub n which are equal to n pi over L. ", "And from that, we now have our mode shapes.  Because we can say, ah, well, there's  special solution for this W of x that ", "applies only when we satisfy the boundary conditions.  And that will be some undetermined amplitude.   B2 came from the sine term. ", " And those are our mode shapes.  And now the natural frequencies-- once ", "you know mode shapes, natural frequencies actually  become pretty trivial to find.  In this case, if we know that's the mode shape,  then how do we get the natural frequencies? ", "Well, we know that-- what's the definition of k?  ", "Therefore, the particular values of k  that were allowed solutions here are  going to correspond to particular values of omega n. ", "And therefore, omega n squared is just kn squared c squared.  And that's n pi over L squared T/m. ", " That's omega n squared.  So the natural frequencies of a string ", "are n pi over L root T/m.  ", "And this is in radians per second.  And I like to work in hertz sometimes.  So the natural frequencies in hertz-- omega n over 2 pi. ", "And that becomes n over 2L root T/m.   So the first natural frequency, f1, is 1 over 2L root T/m. ", " Now, let's draw.  What's the mode shape for the first mode? ", "Well, it's half a sine wave, vibrates like that.  It's full wavelength.  I didn't leave myself quite enough room. ", "That's half a wavelength of a sine wave.  So the full wavelength would be like that.  This is of length L. And so is this piece over here. ", "So the lambda is 2L for this particular problem.   Let's see, how do I want to pose this question? ", " So how long does it take for a wave or disturbance ", "to travel the length of this finite string?  ", "How long does it take it to go down there and back?  How would you calculate that?   Distance equals rate times time. ", "What's the distance?  2L.  What's the speed?  c.  So the length of time ought to be 2L over c, right? ", " So the time required-- and 2L divided by T over m. ", "But f1 is T/m divided by 2L.  Hmm.  ", "So the period-- so there's a direct connection  between propagation speed, frequencies, wavelengths. ", "They're very closely related.  So the natural frequency of the first mode of this string, ", "that frequency, is exactly 1 over the length of time  it takes for a disturbance to travel down and back.  ", "So with that depth of understanding  of how the wave equation behaves,  you can guess the behavior of lots of other things ", "that behave like that, like my rod here.  I'll do a little demo with it in a second.  ", "So for example, the longitudinal vibration,  stress waves running up and down this thing,  obey the wave equation. ", "So if I take this thing and drop it on the floor,  it'll bounce off the floor.  How long does it take to bounce off the floor?  ", "So what do you think actually-- what physics has to happen?  What's required to make this thing bounce off the floor?  So we're going to consider the floor infinitely rigid. ", "It hits the floor.  It actually stays there for some finite length of time,  and then it leaves.  So physically, when I was holding up my string, if I  smacked the end, what happened? ", "A pulse took off, ran down the end, reflected, came back.  And that was one round trip.  What do you suppose happens here? ", "I put a pulse into the end.  Is it a tension or compression, the strain that's felt?  AUDIENCE: Compression  PROFESSOR: Compression.  So a little compression pulse is put into the end.  That compression pulse then, when it first hits, ", "the compression and the speed of propagation is finite.  So that compression wave starts traveling up here.  Behind the compression wave, this rod has come to a stop. ", "In front of the compression wave,  the rod doesn't know it hit the ground yet.  It's still moving down.  So that compression wave travels up,  and it is decelerating each little slice of mass ", "as it passes through.  It brings it to a stop.  And so the compression reaches the top end.  The cylinder has come to a stop.  The end is free.  It can't take any strain. ", "So an equal and opposite tension wave  has to start to make the sum of them go to 0 at the end.  The boundary condition at the end is no strain.  So it reflects as a tension wave.  Now you have a tension wave going down. ", "And what it does is it accelerates every atom as it  goes by, as it goes past it.  So everything is stopped now.  Now it starts down, and this thing ", "starts rebounding from-- the top rebounds from the floor  before the bottom does.  The top starts going up.  All of it-- more and more goes up.  And one hits the bottom.  The tension wave hits the floor, and it jumps off. ", "So how long does it take?  ", "Right?  And what do you guess the natural frequency  of a free-free rod is?  Now, it has a funny mode shape.  The mode shape is not half a sine wave like this. ", "The displacement of the rod, it has free ends.  The ends are moving a lot.  But I'll give you a clue.  [ROD RINGING] ", "I can hold it in the center and not damp it.  What do you think the mode shape looks like?   Half a wavelength long, ends are free-- cosine, ", "maximum displacement, goes to zero,  maximum negative displacement.  So it's half a wavelength long, but it's  a cosine half a wavelength. ", "And the full wavelength is 2L.   So this has mode shapes.  The mode shapes-- I've applied different boundary conditions. ", "These are free-free boundary conditions.  The mode shapes are cosine n pi x over L.  But they have to obey a certain other law  that we know about, conservation of momentum. ", "Because I've got gravity to deal with,  I have to hang on to this thing.  But I've picked a place to hang onto it that you can hear it.  I'm not affecting the motion.  There's no motion where I'm holding it. ", "So if I were out in space, I could do this--  [ROD RINGING]  --and just let it hang there in space, right?  And it would sit there and ring.  What is happening to the center of mass of this system ", "as it vibrates?  AUDIENCE: [INAUDIBLE]  PROFESSOR: Stationary.  So half of the mass of this thing's  got to be moving that way.  And half of the mass has to be moving ", "that way so that the total center of mass doesn't move.  Well, cosine mode shape, positive here,  negative there, perfectly symmetric, center of mass  doesn't move.  So there's all sorts of neat little problems ", "that you can solve just by knowing the wave equation  and figuring out boundary conditions.  How many of you stand in the shower at home ", "and sing, and every now and then,  you hit a note, man, you just sound great, right?  And it's just all this reverberation.  How many of you have done that?  OK, right, what's going on? ", "AUDIENCE: [INAUDIBLE] Natural frequency?  PROFESSOR: You've hit a-- somebody said  natural frequency.  Of what?  AUDIENCE: [INAUDIBLE]  PROFESSOR: Huh?  AUDIENCE: [INAUDIBLE] ", " PROFESSOR: You've hit the natural frequency of the shower  stall itself. ", "If the shower stall is a meter across,  pressure waves-- and you plot pressure  inside of the shower, the lowest mode ", "if you're plotting pressure.  Well, let's plot actually molecular movement.  What's the boundary condition at the wall,  the molecules at the wall?  They can't move, right?  0. ", "So the molecular motion at resonance  in the shower stall, the molecules, the pressures making  them move back and forth, looks like back to the string again.  This is L. The first natural frequency ", "of sound waves bouncing off the walls in the stall  is 1 over 2L root times c, whatever c is. ", "And c is the speed of sound in air,  which is 340 meters per second.  So 340 meters per second divided by 2L--  so if it's 1 meter across here, it's ", "340 divided by 2, 170 hertz.  So that first note you can hit in the 1 meter  across shower stall is about 170 hertz-- pretty low. ", "But you can hit second mode.  It'd be twice that, and so forth.  OK, what about an organ pipe?  This is an organ pipe, wood. ", "It's got a stoppered end.  Actually, let's do it without the stopper.  Now it's an open organ pipe.  [ORGAN NOTE]  ", "Basic wave equation-- how would you  model its boundary conditions?   So you can talk about maybe particle molecular motion. ", "This is, now again, just sound waves, so air particles.  And this is now longitudinal.  Things are moving inside.  So what's the boundary condition at this end, free or fixed? ", "Free.  And here it's quite open, so the boundary condition on here  is free.  So for the molecular motion in a free-free organ pipe, ", "you have to get back to that half a wavelength cosine thing.  And if you wanted to plot pressure instead,  you can write the wave equation in terms of pressure.  Pressure is-- this is pressure relief here ", "and pressure relief there.  So in fact, if is displacement of the molecules, ", "pressure would plot like that.  You'd have what's called a pressure relief boundary  condition.  But again, it's a half wavelength long.  What do you think the first natural frequency ", "of this organ pipe is?  ", "The period would be 2L over c.  The frequency would be c over 2L.   So the frequency for the organ pipe open end f1 is c over 2L. ", " [ORGAN NOTE]  Check your intuition.  I'm going to close the end-- still an organ pipe. ", "Is the frequency now going to be higher or lower?  Take a vote.  How many think the frequency is going to go up?  Raise your hands, commit. ", "All right, down.  We've got a lot of uncertainty.  All right, let's do the experiment.  [ORGAN NOTE]  ", "[LOWER ORGAN NOTE]   How come?  I find that actually kind of counterintuitive.  Until I learned this, I would have guessed the opposite way.  What's going on with pressure in a closed pipe? ", " Well, here at the orifice where the sound is actually  generated, it's the pressure. ", "If we wanted to plot pressure at the opening,  that's a pressure relief place.  So it's 0.  But at the other end where the stopper is, it's maximum. ", " How many wavelengths is that?  A quarter.   And so the length of time it takes for the thing ", "to go through one complete period  is going to be 4L over c, half the frequency of the open pipe. ", "OK, so the wave equation is really quite powerful,  governs lots of things.   I've got 10, 15 minutes left here. ", "I don't want you to go away thinking that the whole world  behaves like the wave equation.  Because there are some important other physical systems ", "that we care about.  And I'm going to show you just one.  And that's the vibration of the beam. ", "So here's the cantilever beam.   The whole table is moving.  And you can see it up on the screen. ", "OK, so its first mode vibration, tip moves maximum.  It kind of looks like a quarter wavelength.  It roughly is, but not exactly.  ", "So let's draw a cantilever.   And most of you have had 2.001. ", "So if you put a load P out here-- bends,  goes through a displacement delta.  So you know that delta equals Pl cubed over 3EI, right? ", "And what's this I?  AUDIENCE: [INAUDIBLE]  PROFESSOR: Area moment of inertia.  Now that you've been doing dynamics all term,  we talk about mass moments of inertia. ", "There's also area moments of inertia.  So this is the area moment of inertia of a beam.  In this case, our beam is a little rectangular cross  section.  And the neutral axis is here, a little variable y ", "at displacement.  I is the integral of y squared dA.  And dA is just a little slice of area here, dA. ", "And the integral of y squared dA is your cross sectional area  moment of inertia in the direction of bending.  So that is I. You can also write it as a kappa squared A. ", "And we ran into this in dynamics.  We called it the radius of gyration.  You had the same thing with area moments of inertia,  the radius of gyration.  This is going to be really helpful in a second. ", "So if you solve the force balance for a beam  like I did for the string, take a little slice, ", "do force balance for transverse motions--  I'm not going to grind it out.  And temporarily neglect external forces and damping.  I want to get to the natural frequencies and mode shapes. ", "So the free vibration, no damping, equation  looks like EI partial 4 w with respect ", "to x to the fourth plus rho A partial squared w with respect ", "to t squared equals 0.  And now this is density, mass density.   And the A, this A, is the area of the cross section. ", " So it's just some bh with thickness times the width. ", "So rho times A is a mass per unit length.   And so mass per unit length times  dx would be the little mass associated ", "with the element times the acceleration should  be the forces on the element.  So that's the fourth order partial differential  equation that describes the vibration of a beam. ", "And you have to apply the boundary conditions.  And for the string, it was just B1 cosine B2 sine. ", "For the beam, it's B1 cosine plus B2 sine plus C2 cosh  plus D2 sinh x. ", "And then you have to apply four boundary conditions  and solve for B1, B2, and so forth, all four of those.  I won't do it.  But that's how you do it.  Separation-- and separation of variables works again. ", "So we solve this, apply the boundary conditions.   What are the boundary conditions?  Just so you understand what I mean by the boundary ", "conditions, what are they for a free-free beam,  zero motion at the wall?   No strain at the end, no bending moment at the end, ", "no sheer force at the end-- so there's  no second derivative, no third derivative.   And at the wall, the slope is 0, the first derivative. ", "No slope comes into the wall, but the slope is 0 there.  So those are the different kind of boundaries.  So if you have a free-free beam, you  have no bending at either end and no strain at either end. ", "Fixed-fixed beam-- no displacement,  zero slopes at both at ends, and all different combinations.  And every different combination gives you  different natural frequencies.  So you apply the boundary conditions, and for a beam, ", "you find out that for all beams omega  n can be written as some beta n, a parameter, squared, ", "I'll call it, times the square root of EI over rho A.  And this thing varies according to the boundary conditions. ", " Now that's what you get shown in every textbook in the world.  And I have a very hard time visualizing this, ", "getting physical intuition by that.  So something you never see in a textbook  but I often do is let's replace I with kappa squared A. ", "And you get a square root of E over rho and a square root of I  over A. But I is kappa squared A. The A's cancel. ", "It's the square root of kappa squared.  So this, you know what E over rho is?  E over rho, square root of E over rho, ", "is the sound speed in a solid material.  So the speed of stress waves traveling up and down ", "this thing is the square root of E over rho.  [ROD RINGING]  This is aluminum.  It's about 4,000 meters a second.  So if you know just the properties of the material, ", "you have that.  And that says then omega n for beams  is some beta n squared a parameter times kappa CL. ", "And this thing, this is often written CL.  It's the longitudinal sound speed.   This is sound speed for waves traveling through the medium. ", "So this tells you if you make the beam twice as thick,  what do you do to its natural frequencies?  Doubles-- instantly you know that.  So bending properties depend a lot on the radius of gyration. ", "And I'll give you a few natural frequencies  for different boundary conditions  just so you see what they behave like.  ", "So a pin-pin beam looks like that. ", "So you put a plank across the stream, rocks on both sides,  you've got a pin-pin beam, basically.  It's set there in rock. ", "So some length L has properties EI.  So the natural frequencies for a pin-pin beam,  the beta n's, are just n pi over L. ", "And so your natural frequencies-- omega n  looks like n pi over L quantity squared kappa CL.  ", "And for the cantilever, the natural frequencies ", "look like omega n pi squared over 4L squared, is the beta n. ", " And I'll write it this way again-- EI over  rho A. You can always go back and do that.  Or you can call it kappa CL. ", "This is also kappa CL.  But then there are some numbers you've got  to use here-- 1.194 squared. ", "That's the first mode.  Second mode-- 2.988 squared.  And then after that-- 5 squared, 7 squared, 9 squared. ", "So this is the natural frequency of a cantilever.  Pi squared over 4L squared times 1.194  squared kappa CL, that's this natural frequency. ", " And one final case, because I can show it  to you-- the free-free case. ", "So that's a beam bending that vibrates like that.   And I happen to know on a beam for the first mode-- this ", "is the first mode of a beam.  Where these nodes are, where there's no motion,  I should be able to hold it there and not damp it.  And that turns out to be at about the quarter points.  ", "So whack it like that.  [ROD RINGING]  And do it again.  [ROD RINGING] ", "All right, so I want you to hold it about right there.  Nope, you can't hold it like that, though-- just  got to balance it.  Because you've got to be right where the node is. ", "[ROD RINGING]  You can hear that little bit lower tone.  That's that free-free bending mode.  And it's just sitting.  You can feel it vibrating a little bit but not much.  When you're right in the right spot, ", "you're right on the mode shape.  You can almost see it if you hit it hard enough.  So that's the free-free beam.  And the free-free beam has natural frequencies omega n, ", "again, pi squared over 4L squared kappa CL 3.0112 ", "squared, 5 squared, 7 squared, 9 squared, so as you go up in n.  So those are the natural frequencies  of a free-free beam. ", " Oh, one last fact about beams-- so this is now ", "a steel beam under no tension.  It can support its own weight, long though.  So can a beam support waves traveling down ", "the beam, transverse waves traveling down the beam?  What do you think?   Well, if it can support this, it can probably  support waves, right?  So waves will propagate in a beam ", "even though this is fourth order partial differential equation.  But how fast do they go?  That's the question.  So this is a beam.  And I want to know about waves traveling down it. ", "And I'm not going to go through-- this  would take another hour or so to show you where this comes from.  But here's my beam. ", "Here's a disturbance traveling along it  with some speed that I'm going to call CT.  It's transverse wave speed. ", "It's the speed you'd see a crest of a wave moving  at running down that beam.  CT for a beam-- square root of omega kappa CL. ", "And CL, again, is the square root of E over rho.  That's the speed of sound in the material.  That just turns up in here. ", "So what does this tell you about the frequency dependence  of the speed? ", "Does the speed change with frequency?   Omega kappa CL-- it's proportional to frequency.  High frequency waves go faster than low frequency waves ", "in a beam.  I didn't emphasize it when we were talking about it.  But the wave equation, what was c for the string? ", "For the wave equation, the speed of wave propagation  was square root of T/m.  Was it frequency dependent?  Always traveled at the same speed.  And so there's an important consequence. ", " So for anything that obeys the wave equation,  the speed of propagation is a constant and independent ", "to frequency.  So I can make any initial shape that I make in this thing  and let it go.  Its initial disturbance, that little shape ", "will stay that shape and run up and down the thing forever.  And that shape-- you could imagine a little pluck  like this to start with.  You could imagine doing a Fourier ", "series to approximate that.  It would be made up of a bunch of different Fourier  components.  And yet for something that bears the wave equation,  that little pluck will just stay the shape of that pluck ", "and run around forever.  But not so in a beam.  If you did that in a beam, if you come up and put  an impulse into a beam, all that energy ", "would start out together.  But in very brief time, the high frequency information  would get out in front of the low frequency information.  And if you were way down this beam, and somebody up a mile ", "away whacks one end, and you're down further along,  you'll see high frequency waves past you,  and then lower frequency, and finally really slow  ones coming by, the really long waves. ", "So that's called dispersion.  So beam waves are dispersive.  ", "Things that obey the wave equation are non-dispersive.  The energy all travels at the same speed independent  of frequency.  All right, so that's it for the term. ", "I'll see you guys on next Wednesday. "], "vid_duration": [12.59, 13.49, 10.75, 10.1, 11.38, 11.73, 10.78, 10.48, 13.22, 16.1, 12.511, 10.909, 11.65, 10.269, 14.081, 12.9, 15.37, 12.37, 14.558, 14.832, 13.66, 12.035, 14.835, 11.04, 11.779, 12.941, 10.22, 11.09, 10.09, 11.01, 10.62, 10.43, 10.9, 12.041, 11.299, 10.03, 10.87, 13.26, 12.49, 12.35, 12.229, 12.491, 11.23, 10.52, 10.66, 12.32, 10.85, 11.14, 12.63, 10.31, 11.23, 11.63, 10.91, 11.82, 12.47, 12.2, 10.04, 11.26, 11.58, 11.94, 10.26, 11.56, 11.49, 17.67, 12.64, 10.95, 10.76, 12.45, 12.33, 10.94, 10.38, 13.71, 12.33, 10.78, 10.02, 10.91, 13.65, 17.15, 11.26, 11.49, 12.55, 11.84, 12.6, 14.618, 13.081, 11.311, 12.25, 12.65, 10.19, 11.29, 12.85, 11.25, 10.83, 10.105, 12.215, 13.93, 11.77, 13.44, 11.27, 13.07, 12.76, 12.92, 12.645, 31.785, 10.16, 10.24, 11.79, 13.29, 12.98, 22.58, 12.73, 22.66, 11.81, 11.59, 10.94, 11.36, 11.06, 12.37, 12.811, 13.119, 11.32, 11.73, 16.4, 18.29, 10.855, 15.415, 17.36, 10.54, 17.1, 15.36, 13.93, 10.58, 12.495, 12.692, 13.593, 10.93, 13.695, 12.059, 12.696, 14.01, 17.52, 10.425, 10.485, 11.87, 14.94, 10.34, 11.86, 11.4, 10.29, 10.1, 12.736, 11.814, 10.176, 11.554, 16.09, 12.64, 17.48, 12.27, 13.25, 10.67, 11.685, 13.813, 14.432, 18.619, 13.131, 12.32, 10.16, 10.73, 10.34, 10.11, 13.59, 17.5, 11.68, 10.52, 17.75, 11.99, 13.76, 11.32, 10.075, 11.665, 12.61, 12.95, 12.32, 10.17, 10.51, 13.96, 19.93, 10.15, 11.4, 11.79, 12.79, 10.02, 12.68, 19.33, 10.27, 11.22, 12.68, 16.95, 11.64, 11.64, 11.64, 12.65, 14.37, 18.211, 11.199, 12.63, 26.89, 10.01, 10.62, 11.6, 16.01, 15.04, 19.97, 10.19, 14.91, 10.59, 11.05, 11.69, 13.88, 12.63, 13.49, 11.39, 11.12, 10.28, 12.48, 10.77, 12.12, 12.15, 13.86, 11.0, 11.639, 14.041, 10.2, 11.38, 10.3, 11.91, 10.22, 12.44, 10.16, 10.17, 14.11, 10.32, 12.52, 14.06, 12.21, 10.544, 10.366, 10.87, 10.06, 11.77, 12.566, 10.319, 10.775, 10.03, 10.2, 21.465, 10.095, 10.24, 10.048, 13.127, 10.055, 10.82, 14.88, 19.04, 14.3, 12.28, 12.41, 13.27, 11.64, 12.7, 17.06, 11.079, 12.301, 12.025, 15.405, 12.93, 18.05, 11.13, 10.59, 10.29, 11.96, 11.16, 11.11, 11.49, 10.46, 10.58, 12.38, 11.533, 13.567, 13.58, 12.95, 11.27, 10.78, 10.935, 12.085, 17.24, 10.69, 16.22, 12.83, 12.18, 12.05, 12.4, 12.55, 15.05, 10.66, 10.679, 11.891, 13.75, 14.59, 12.205, 11.005, 12.27, 12.83, 11.34, 11.4, 14.17, 11.2, 10.599, 11.649, 11.802, 15.412, 15.688, 10.805, 15.394, 10.821, 11.32, 12.149, 11.21, 10.021, 18.019, 10.021, 11.332, 11.658, 10.26, 13.285, 12.875, 10.93, 12.11, 11.92, 11.35, 11.93, 10.73, 12.56, 13.84, 8.77], "stet": [[0, 12.59], [12.59, 26.08], [26.08, 36.83], [36.83, 46.93], [46.93, 58.31], [58.31, 70.04], [70.04, 80.82000000000001], [80.82000000000001, 91.30000000000001], [91.30000000000001, 104.52000000000001], [104.52000000000001, 120.62], [120.62, 133.131], [133.131, 144.04], [144.04, 155.69], [155.69, 165.959], [165.959, 180.04], [180.04, 192.94], [192.94, 208.31], [208.31, 220.68], [220.68, 235.238], [235.238, 250.07], [250.07, 263.73], [263.73, 275.76500000000004], [275.76500000000004, 290.6], [290.6, 301.64000000000004], [301.64000000000004, 313.41900000000004], [313.41900000000004, 326.36], [326.36, 336.58000000000004], [336.58000000000004, 347.67], [347.67, 357.76], [357.76, 368.77], [368.77, 379.39], [379.39, 389.82], [389.82, 400.71999999999997], [400.71999999999997, 412.76099999999997], [412.76099999999997, 424.05999999999995], [424.05999999999995, 434.0899999999999], [434.0899999999999, 444.9599999999999], [444.9599999999999, 458.2199999999999], [458.2199999999999, 470.7099999999999], [470.7099999999999, 483.05999999999995], [483.05999999999995, 495.28899999999993], [495.28899999999993, 507.7799999999999], [507.7799999999999, 519.0099999999999], [519.0099999999999, 529.5299999999999], [529.5299999999999, 540.1899999999998], [540.1899999999998, 552.5099999999999], [552.5099999999999, 563.3599999999999], [563.3599999999999, 574.4999999999999], [574.4999999999999, 587.1299999999999], [587.1299999999999, 597.4399999999998], [597.4399999999998, 608.6699999999998], [608.6699999999998, 620.2999999999998], [620.2999999999998, 631.2099999999998], [631.2099999999998, 643.0299999999999], [643.0299999999999, 655.4999999999999], [655.4999999999999, 667.6999999999999], [667.6999999999999, 677.7399999999999], [677.7399999999999, 688.9999999999999], [688.9999999999999, 700.5799999999999], [700.5799999999999, 712.52], [712.52, 722.78], [722.78, 734.3399999999999], [734.3399999999999, 745.8299999999999], [745.8299999999999, 763.4999999999999], [763.4999999999999, 776.1399999999999], [776.1399999999999, 787.0899999999999], [787.0899999999999, 797.8499999999999], [797.8499999999999, 810.3], [810.3, 822.63], [822.63, 833.57], [833.57, 843.95], [843.95, 857.6600000000001], [857.6600000000001, 869.9900000000001], [869.9900000000001, 880.7700000000001], [880.7700000000001, 890.7900000000001], [890.7900000000001, 901.7], [901.7, 915.35], [915.35, 932.5], [932.5, 943.76], [943.76, 955.25], [955.25, 967.8], [967.8, 979.64], [979.64, 992.24], [992.24, 1006.8580000000001], [1006.8580000000001, 1019.9390000000001], [1019.9390000000001, 1031.25], [1031.25, 1043.5], [1043.5, 1056.15], [1056.15, 1066.3400000000001], [1066.3400000000001, 1077.63], [1077.63, 1090.48], [1090.48, 1101.73], [1101.73, 1112.56], [1112.56, 1122.665], [1122.665, 1134.8799999999999], [1134.8799999999999, 1148.81], [1148.81, 1160.58], [1160.58, 1174.02], [1174.02, 1185.29], [1185.29, 1198.36], [1198.36, 1211.12], [1211.12, 1224.04], [1224.04, 1236.685], [1236.685, 1268.47], [1268.47, 1278.63], [1278.63, 1288.8700000000001], [1288.8700000000001, 1300.66], [1300.66, 1313.95], [1313.95, 1326.93], [1326.93, 1349.51], [1349.51, 1362.24], [1362.24, 1384.9], [1384.9, 1396.71], [1396.71, 1408.3], [1408.3, 1419.24], [1419.24, 1430.6], [1430.6, 1441.6599999999999], [1441.6599999999999, 1454.0299999999997], [1454.0299999999997, 1466.8409999999997], [1466.8409999999997, 1479.9599999999996], [1479.9599999999996, 1491.2799999999995], [1491.2799999999995, 1503.0099999999995], [1503.0099999999995, 1519.4099999999996], [1519.4099999999996, 1537.6999999999996], [1537.6999999999996, 1548.5549999999996], [1548.5549999999996, 1563.9699999999996], [1563.9699999999996, 1581.3299999999995], [1581.3299999999995, 1591.8699999999994], [1591.8699999999994, 1608.9699999999993], [1608.9699999999993, 1624.3299999999992], [1624.3299999999992, 1638.2599999999993], [1638.2599999999993, 1648.8399999999992], [1648.8399999999992, 1661.3349999999991], [1661.3349999999991, 1674.0269999999991], [1674.0269999999991, 1687.6199999999992], [1687.6199999999992, 1698.5499999999993], [1698.5499999999993, 1712.2449999999992], [1712.2449999999992, 1724.3039999999992], [1724.3039999999992, 1736.999999999999], [1736.999999999999, 1751.009999999999], [1751.009999999999, 1768.529999999999], [1768.529999999999, 1778.954999999999], [1778.954999999999, 1789.439999999999], [1789.439999999999, 1801.3099999999988], [1801.3099999999988, 1816.2499999999989], [1816.2499999999989, 1826.5899999999988], [1826.5899999999988, 1838.4499999999987], [1838.4499999999987, 1849.8499999999988], [1849.8499999999988, 1860.1399999999987], [1860.1399999999987, 1870.2399999999986], [1870.2399999999986, 1882.9759999999987], [1882.9759999999987, 1894.7899999999988], [1894.7899999999988, 1904.9659999999988], [1904.9659999999988, 1916.5199999999988], [1916.5199999999988, 1932.6099999999988], [1932.6099999999988, 1945.2499999999989], [1945.2499999999989, 1962.7299999999989], [1962.7299999999989, 1974.9999999999989], [1974.9999999999989, 1988.2499999999989], [1988.2499999999989, 1998.919999999999], [1998.919999999999, 2010.6049999999989], [2010.6049999999989, 2024.417999999999], [2024.417999999999, 2038.849999999999], [2038.849999999999, 2057.468999999999], [2057.468999999999, 2070.599999999999], [2070.599999999999, 2082.919999999999], [2082.919999999999, 2093.079999999999], [2093.079999999999, 2103.809999999999], [2103.809999999999, 2114.149999999999], [2114.149999999999, 2124.2599999999993], [2124.2599999999993, 2137.8499999999995], [2137.8499999999995, 2155.3499999999995], [2155.3499999999995, 2167.0299999999993], [2167.0299999999993, 2177.5499999999993], [2177.5499999999993, 2195.2999999999993], [2195.2999999999993, 2207.289999999999], [2207.289999999999, 2221.0499999999993], [2221.0499999999993, 2232.3699999999994], [2232.3699999999994, 2242.4449999999993], [2242.4449999999993, 2254.109999999999], [2254.109999999999, 2266.7199999999993], [2266.7199999999993, 2279.669999999999], [2279.669999999999, 2291.9899999999993], [2291.9899999999993, 2302.1599999999994], [2302.1599999999994, 2312.6699999999996], [2312.6699999999996, 2326.6299999999997], [2326.6299999999997, 2346.5599999999995], [2346.5599999999995, 2356.7099999999996], [2356.7099999999996, 2368.1099999999997], [2368.1099999999997, 2379.8999999999996], [2379.8999999999996, 2392.6899999999996], [2392.6899999999996, 2402.7099999999996], [2402.7099999999996, 2415.3899999999994], [2415.3899999999994, 2434.7199999999993], [2434.7199999999993, 2444.9899999999993], [2444.9899999999993, 2456.209999999999], [2456.209999999999, 2468.889999999999], [2468.889999999999, 2485.839999999999], [2485.839999999999, 2497.4799999999987], [2497.4799999999987, 2509.1199999999985], [2509.1199999999985, 2520.7599999999984], [2520.7599999999984, 2533.4099999999985], [2533.4099999999985, 2547.7799999999984], [2547.7799999999984, 2565.990999999998], [2565.990999999998, 2577.1899999999982], [2577.1899999999982, 2589.8199999999983], [2589.8199999999983, 2616.709999999998], [2616.709999999998, 2626.7199999999984], [2626.7199999999984, 2637.3399999999983], [2637.3399999999983, 2648.9399999999982], [2648.9399999999982, 2664.9499999999985], [2664.9499999999985, 2679.9899999999984], [2679.9899999999984, 2699.959999999998], [2699.959999999998, 2710.1499999999983], [2710.1499999999983, 2725.059999999998], [2725.059999999998, 2735.6499999999983], [2735.6499999999983, 2746.6999999999985], [2746.6999999999985, 2758.3899999999985], [2758.3899999999985, 2772.2699999999986], [2772.2699999999986, 2784.8999999999987], [2784.8999999999987, 2798.3899999999985], [2798.3899999999985, 2809.7799999999984], [2809.7799999999984, 2820.8999999999983], [2820.8999999999983, 2831.1799999999985], [2831.1799999999985, 2843.6599999999985], [2843.6599999999985, 2854.4299999999985], [2854.4299999999985, 2866.5499999999984], [2866.5499999999984, 2878.6999999999985], [2878.6999999999985, 2892.5599999999986], [2892.5599999999986, 2903.5599999999986], [2903.5599999999986, 2915.1989999999987], [2915.1989999999987, 2929.239999999999], [2929.239999999999, 2939.4399999999987], [2939.4399999999987, 2950.819999999999], [2950.819999999999, 2961.119999999999], [2961.119999999999, 2973.029999999999], [2973.029999999999, 2983.2499999999986], [2983.2499999999986, 2995.6899999999987], [2995.6899999999987, 3005.8499999999985], [3005.8499999999985, 3016.0199999999986], [3016.0199999999986, 3030.1299999999987], [3030.1299999999987, 3040.449999999999], [3040.449999999999, 3052.969999999999], [3052.969999999999, 3067.029999999999], [3067.029999999999, 3079.239999999999], [3079.239999999999, 3089.7839999999987], [3089.7839999999987, 3100.1499999999987], [3100.1499999999987, 3111.0199999999986], [3111.0199999999986, 3121.0799999999986], [3121.0799999999986, 3132.8499999999985], [3132.8499999999985, 3145.4159999999983], [3145.4159999999983, 3155.7349999999983], [3155.7349999999983, 3166.5099999999984], [3166.5099999999984, 3176.5399999999986], [3176.5399999999986, 3186.7399999999984], [3186.7399999999984, 3208.2049999999986], [3208.2049999999986, 3218.2999999999984], [3218.2999999999984, 3228.539999999998], [3228.539999999998, 3238.587999999998], [3238.587999999998, 3251.714999999998], [3251.714999999998, 3261.7699999999977], [3261.7699999999977, 3272.589999999998], [3272.589999999998, 3287.469999999998], [3287.469999999998, 3306.509999999998], [3306.509999999998, 3320.809999999998], [3320.809999999998, 3333.0899999999983], [3333.0899999999983, 3345.499999999998], [3345.499999999998, 3358.769999999998], [3358.769999999998, 3370.409999999998], [3370.409999999998, 3383.109999999998], [3383.109999999998, 3400.169999999998], [3400.169999999998, 3411.248999999998], [3411.248999999998, 3423.549999999998], [3423.549999999998, 3435.574999999998], [3435.574999999998, 3450.979999999998], [3450.979999999998, 3463.909999999998], [3463.909999999998, 3481.959999999998], [3481.959999999998, 3493.0899999999983], [3493.0899999999983, 3503.6799999999985], [3503.6799999999985, 3513.9699999999984], [3513.9699999999984, 3525.9299999999985], [3525.9299999999985, 3537.0899999999983], [3537.0899999999983, 3548.1999999999985], [3548.1999999999985, 3559.6899999999982], [3559.6899999999982, 3570.1499999999983], [3570.1499999999983, 3580.729999999998], [3580.729999999998, 3593.1099999999983], [3593.1099999999983, 3604.642999999998], [3604.642999999998, 3618.209999999998], [3618.209999999998, 3631.789999999998], [3631.789999999998, 3644.739999999998], [3644.739999999998, 3656.009999999998], [3656.009999999998, 3666.789999999998], [3666.789999999998, 3677.724999999998], [3677.724999999998, 3689.809999999998], [3689.809999999998, 3707.049999999998], [3707.049999999998, 3717.739999999998], [3717.739999999998, 3733.9599999999978], [3733.9599999999978, 3746.7899999999977], [3746.7899999999977, 3758.9699999999975], [3758.9699999999975, 3771.0199999999977], [3771.0199999999977, 3783.419999999998], [3783.419999999998, 3795.969999999998], [3795.969999999998, 3811.019999999998], [3811.019999999998, 3821.679999999998], [3821.679999999998, 3832.358999999998], [3832.358999999998, 3844.249999999998], [3844.249999999998, 3857.999999999998], [3857.999999999998, 3872.5899999999983], [3872.5899999999983, 3884.7949999999983], [3884.7949999999983, 3895.7999999999984], [3895.7999999999984, 3908.0699999999983], [3908.0699999999983, 3920.8999999999983], [3920.8999999999983, 3932.2399999999984], [3932.2399999999984, 3943.6399999999985], [3943.6399999999985, 3957.8099999999986], [3957.8099999999986, 3969.0099999999984], [3969.0099999999984, 3979.6089999999986], [3979.6089999999986, 3991.2579999999984], [3991.2579999999984, 4003.0599999999986], [4003.0599999999986, 4018.4719999999984], [4018.4719999999984, 4034.1599999999985], [4034.1599999999985, 4044.9649999999983], [4044.9649999999983, 4060.358999999998], [4060.358999999998, 4071.179999999998], [4071.179999999998, 4082.499999999998], [4082.499999999998, 4094.648999999998], [4094.648999999998, 4105.858999999998], [4105.858999999998, 4115.879999999997], [4115.879999999997, 4133.898999999998], [4133.898999999998, 4143.919999999997], [4143.919999999997, 4155.251999999998], [4155.251999999998, 4166.909999999998], [4166.909999999998, 4177.169999999998], [4177.169999999998, 4190.454999999998], [4190.454999999998, 4203.329999999998], [4203.329999999998, 4214.259999999998], [4214.259999999998, 4226.369999999998], [4226.369999999998, 4238.289999999998], [4238.289999999998, 4249.6399999999985], [4249.6399999999985, 4261.569999999999], [4261.569999999999, 4272.299999999998], [4272.299999999998, 4284.859999999999], [4284.859999999999, 4298.699999999999], [4298.699999999999, 4307.469999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [185, 920, 1552, 2698, 3320, 4308]}
{"example_id": "mit126@@MIT2_003SCF11_lec24_300k", "text": ["PROFESSOR: All right.  I'm a little slow getting started today,  better get going.  ", "What we're going to talk about today is a technique--  you guys done?  OK, thanks.  We're going to talk about today a technique known ", "as modal analysis, and it's a way  of analyzing things that vibrate, essentially thinking  about them one mode and a time. ", "Though you might not make a lot of use  of the actual calculations, doing the math,  throughout your careers, I think if you understand it ", "conceptually it'll help you just have a better  understanding of what vibration is all about,  just give you some insight to it that you otherwise  wouldn't have. ", "So the basic concept is that you can model just  about any structural vibration as the summation  of the individual contributions of each  what we call natural mode. ", "So what we mean by that is, let's  start by thinking-- actually, let  me say that this applies to both continuous systems  like vibrating strings or beams or buildings as it ", "does to finite degree of freedom rigid body systems.  We haven't talked about continuous systems.  I'll do a lecture on it as the last lecture ", "of the term, just kind of an enrichment sort of lecture.  But everything I say about finite degree of freedom  systems can be extended to continuous systems. ", "But since we've been studying rigid bodies and systems  with finite numbers of degrees of freedom,  I'll explain-- I'll go through this analysis  in the context of rigid body finite degree of freedom ", "systems.  So in general, we can write the equations of motion  for finite degree of freedom systems as a mass matrix. ", "And to keep the kind of writing down,  I'm just going to underline matrices and a squiggle  under vectors so we have them.  In general, we can write the equations of motion ", "as a mass matrix times an acceleration vector  plus a damping matrix times a velocity vector, ", "stiffness matrix times a displacement vector,  all equal to some external vector of excitations. ", "And I'm writing these as if these are translations,  but you know, like from doing the pendulum on the cart  problem, that the equations of motion  might involve rotations and displacements. ", "And we let them-- they mix together here however they  fall out.  But just to write them symbolically,  I'm just going to refer to all of those coordinates ", "with an x vector.  OK, now the basic premise of modal analysis  is a thing called the modal expansion theorem. ", " It's basically the assertion that you  can represent any motion set of vectors-- ", "I'll write them kind of as a vector here for a moment-- x,  as the superposition of each contributing mode. ", "Now each mode has a mode shape to it,  which I'm going to call u, and up here I'll  put a superscript for what mode it ", "is, the first mode, times its time-dependent behavior.  And this is called, what they call in textbooks,  the natural coordinates. ", "And we'll see what those are in a second.  So mode shape one.  This is the time-dependent and amplitude part  that says how much the contribution of mode one ", "is to this motion and what its time dependence is, this is.  And then you'd have mode two's contribution, q2. ", " And this goes out to the nth mode's contribution, qn of t. ", "And that's the proposition, that you  can represent the total response of the system  as a superposition of the response of each  of the natural modes of the system. ", "And if it's an n degree of freedom system,  there will be n natural modes, so.  ", "Now something I didn't say here.  This all assumes that the system vibrates.  So this is all in the discussion of things  that exhibit vibratory motion. ", "So this is all, it should say here, of vibrating systems, OK? ", " So this kind of a long and cumbersome way  of writing this out. ", "So if you notice, each one of these is the mode shape vector.  And if I put them together in a matrix just side by side, ", "here's a u1 over to un and multiply it by this vector, ", "q1 of t down to qn.   That's the same statement but said  in a much more compact way. ", "So this statement, this modal expansion theorem,  basically says the vector of-- these  are your generalized coordinates, which ", "we've been using all term long.  These are the generalized coordinates  that you choose to derive the equations of motion around.  The vector of generalized coordinates  can be written as uq. ", " And these are often called the modal coordinates ", "or sometimes called the natural coordinates, OK?  ", "So if we can say that x is uq, then x dot,  you take the derivative of each one of those expressions. ", "You'll find that's going to be uq dot.  And x double dot equals uq double ", "dot because these are just constants.  The mode shape vectors are just a fixed set of numbers  that represent the mode shape to the system.  Now just to-- I think maybe this is a good time to do this. ", "You grab one end.   So this is a-- and it's hard to see black against black.  My apologies for that.  So this is a guitar string or any stringed instrument. ", "In fact, any long, slender thing under tension will vibrate.  And it has, if I do this carefully,  that's called the first mode of vibration. ", "And that's when you pluck your guitar string or violin  in the middle.  You mostly hear that.   But at twice the frequency, if I can get it going here, ", "there's a second mode of vibration.  And for a taut string, it happens  to be at twice the frequency of the first.  And if my hand is well calibrated-- ", "it may be easier if it's a little longer-- if I  get this going right, there's a third mode, OK? ", "So that's what we're calling-- oh,  what I meant to say when I was doing  this is these shapes for the vibrating string, ", "that second mode shape happens to be one full sine wave.  And the mode shape has the form sine n pi x over l, ", "where l's the length of the string.  n's the mode number.  So first mode.  Second mode is this, when n is 2.  First mode, n is 1. ", "nth mode or something high, you get higher modes like that.  So these are the mode shapes for a vibrating string.  ", "That's good for now.   This two degree of freedom system with the two lump  masses-- and it's going to show up  there, yeah-- this is basically two lump masses. ", "And we idealize the springs as being massless,  but it's a pretty good approximation.  This has two modes of vibration.  And Professor Gossard made these neat little things that ", "can make it so-- and I'm going to come back to this,  but there's mode one.  And the mode shape is as this goes down  one unit, that goes down about two times as much. ", "I'll give you the exact numbers in a minute.  And the other mode shape of the system-- ", "we're going to talk about this today and why this happens.  But if I give it the right initial conditions,  I can make it vibrate only in the second mode shape.  And so it's now deflected with the right conditions ", "so that it'll respond only in second mode.   This mass goes up and down a lot.  That mass goes up in that little, opposite to it,  actually.  The frequency is different from the first. ", "But if this is moving one unit, then this down here  is moving minus 0.3 or something like that.  And that ratio is constant.  And that's called the mode shape. ", "So if you just pick one of them and say, let its motion be one,  then all of the other masses in the system  will move in a particular ratio to the motion of that one ", "that you arbitrarily set to one.  So this is what we mean by mode shapes  and their natural frequencies.  There's the natural frequency associated  with that first mode. ", "And we can solve these things mathematically,  and we've been doing that a little bit  in the last couple of lectures.   All right.  ", "So this is the relationship between these things,  the generalized coordinates and the modal coordinates.  And we now need to see how we're going to use these. ", " So in general, we have our equations of motion.  ", "And I'm going to substitute for x, x dot,  and x double dot, these and pre multiply by u transpose. ", "Remember the transpose of a matrix.  You just take the first column, make it the first row.  Second column, make it the second row.  So if I plug in these up here, I get ", "muq-- I'm going to leave some space here  because I'm going to pre multiply in a second-- plus cuq ", "dot plus kuq equals the external exciting forces. ", "Now I'm going to pre multiply by u transpose, OK? ", "Now a remarkable thing happens.  It happens that when you do this calculation, when you multiply ", "this matrix times that, one row at a time-- so this  has vectors in it, 1 through n.  I'm going to pick vector r, the rth one.  If I take that rth vector and multiply it one ", "at a time by row by row by row, then I  get a new vector that results, which ", "I'm going to multiply by this.  And so if I'm going to pick out one of the vectors,  multiply it through times one of the rows ", "here-- when you transpose them, the rows are now the vectors.  So I'm going to pick.  If I do the calculation-- lost my right piece of paper here. ", "", "So I'm going to just pull out one of the calculations  that you end up doing if you do this whole triple matrix  multiplication, you need to know the following fact. ", "So for the mode s transpose-- that's one  of the rows out of here-- times m times  one of the columns, the rth one from here, ", "and I do this calculation, this is 0 for r not equal to s.  ", "What that statement says is, the only non-zero result from this  is when you multiply-- when you take the rth column from here  and you use the rth from here. ", "All the other combinations of this thing go to 0.  And the net result of that is that this  implies that u transpose mu always ", "equals to a diagonal vector, which I'll call this like that.  Sometimes a mass matrix is diagonal to start with.  But even if it isn't, you do this calculation, ", "it will produce a diagonal matrix.  And that's because these multiplications are always  0 unless r is the same as s. ", "And the same is true for u transpose Ku will give you  a K matrix that is diagonal. ", "And you know, normally the stiffness  matrix we've come up with, they've  generally been full matrices oftentimes.  But you do uKu, you will get a diagonal stiffness matrix. ", " And there the little problem comes  because u transpose cu, well, sometimes, this one is diagonal ", "only for ideal conditions of damping.  So that's something you just have to address. ", "", "So only for ideal conditions, and that's  just something you have to deal with.  ", "So why is this?  Why is there this special, wonderful thing?  The natural modes of a system-- this one is  a two degree of freedom system-- form a complete and independent ", "set of vectors.  And in this case of this two degree of freedom system,  I can pick any kinematically allowable position, ", "like this-- stationary, static is one of the solutions,  right, to this two degree of freedom system--  so any possible allowable position of these two things, ", "static or moving, can be described  by a linear combination of the mode shapes of the system,  a weighted sum of the mode shapes of the system. ", "And that's all it takes.  So this one has two mode shapes, one  that looks like that, one that looks  like this one's going down, this one's going up,  their particular ratios. ", "And I can take a weighted amount of that first mode, so much  of it, and a weighted amount of the second mode  and add them together and describe any possible position ", "of the system.  The same thing is true of that string.  It has mode shapes that are sine waves,  but they're sine 1 pi x, sine pi 2x, over and so forth. ", "Any possible allowable shape of that guitar string  can be made up of a weighted sum of the mode  shapes of the system.  And moreover, the mode shapes, the reason ", "this works is because the mode shapes ", "are orthogonal to one another.  ", "Now, you know that if you take 2 sine waves like that string  and you take first mode sine pi x over l,  and second mode say sine 2 pi x over l ", "and you multiply them together and integrate from 0  to l, what do you get?   You'll always get 0 if the two sines are-- ", "if they're full wavelengths, they go to nodes at the end,  you will always get 0 if the wavelengths are different,  always, right?  That's a statement of orthogonality ", "of sine functions.  All right.  The same thing is true of these simple vectors.  They are orthogonal to one another such  that if you do this multiplication, ", "you transpose mu, you only get contributions  when you are using mode r transpose m mode r.  You only get a contribution of each of those. ", "That gives you the diagonals.  The same is true when you do u transpose ku.  Because of orthogonality, you only get a diagonal matrix  at the end.  And under the right conditions, u transpose cu ", "gives you a diagonal matrix.  So what's that good for?  ", "Well, here was the set of equations  that we get when we make that substitution.  This is going to give us a diagonal mass ", "matrix times q double dot plus, when conditions are right,  a diagonal damping matrix times q dot, ", "plus a diagonal stiffness matrix times q  equals u transpose F, which as a vector times a matrix ", "gives you back a vector, which we call capital  Q. It's a function of time.  And this is called the modal force.  ", "But if you look carefully at these,  if I pick the rth one, mode r out of this whole thing-- ", "if I just pick any mode out of this, any part of this vector,  and complete this multiplication,  I will find that I get an Mr, which is the rth entry here.  And now I'm going to refer to these as the modal masses, ", "and I'll write them with capitals  and I'll give a subscript to tell you what the mode is.  This is a number.  This is the modal mass for mode r.  This gives me an equation that looks ", "like Mrqr double dot plus crqr dot plus Krqr equals Qr of t. ", "And what does that remind you of that we've done a lot of work  with?  AUDIENCE: [INAUDIBLE]  PROFESSOR: How many degree of freedom system?  ", "That's the equation of motion, the generic equation of motion,  of a single degree of freedom oscillator.  And you know how to calculate the response  to initial conditions for that.  You know how to calculate the steady state ", "response for that when you have a harmonic input, right?  What I said at the beginning of the discussion about vibration  is it's really important to understand ", "the single degree of freedom oscillator  because it'll give you insight as to the behavior  of complicated multiple degree of freedom systems.  And here's the proof of this. ", " This is now n uncoupled single degree of freedom systems. ", "This is n independent single, one degree of freedom systems ", "which you can solve one at a time.  ", "Now, lots of times a vibrating system, a complicated one,  might be this thing.  If I hit this, it's vibrating. ", "And actually, it's pretty much vibrating  at a single frequency.   And once I've hit it, are there any external forces driving it? ", "So what kind of response are you seeing?   Response to?  AUDIENCE: Initial conditions.  PROFESSOR: Initial conditions, right?  Now in general, each one of the natural modes of a system ", "has a different natural frequency, right?  So if I hit this thing and I look at it,  really, I can just see it wiggling back and forth  basically at one frequency So if you ", "wanted to come up with a simple model of this system,  how many natural modes you think you'd  have to include to describe the motion of this system?  AUDIENCE: One. ", "PROFESSOR: One.  Now is that a lot easier than having  to do the full general equation of motion  for all the possible modes that this thing has?  And it turns out a lot, right, you ", "have to deal with the equation of motion  of a single degree of freedom system to describe this.  And that's the real point.  You know they built the Hancock building  across the river 35 years ago. ", "It was losing windows like crazy.  It was a brand new building.  And when the wind would get above 40 miles an hour,  the windows started falling out.  60 stories high, 60, 61 stories high, and the wind was blowing. ", "Where do you suppose the windows fall out?  What part of the building?  AUDIENCE: [INAUDIBLE]  PROFESSOR: Huh?  I mean, you'd think that when the wind is blowing  it get stronger as it goes up.  It was probably blowing out the windows at the top, right? ", "But the windows were breaking-- as time went by,  every time a window would break, they replaced this five foot  by nine foot sheet of glass with a piece of plywood.  And so you get this statistical sampling ", "after a while of where the breakage was.  So you had no windows broken at the top and a few  as you got further down and more and lots of them broken out  at the bottom. ", "It turns out that that building was vibrating mostly  in its first bending mode.  It was going back and forth like this.  Also happened to have a torsional mode. ", "Its first torsional mode was kind of twisting around  the base like that.  So in fact the moment when the wind  would get about 40 miles an hour,  this building would start rocking and rolling,  mostly like this with a little of this thrown in, OK? ", "But you can basically model that complicated building that  has millions of possible natural modes in it by one  or possibly two single degree of freedom oscillators. ", "So that's the power of modal analysis.  But I think the real power of understanding  that you can do this is that it gives you  this immediate insight as to what  might be going on in something.  So I look at this. ", "I don't see a complicated thing that I  have to model with a big finite element model.  I see something that's vibrating at one frequency.  And I know it has a little decay. ", "It'll have damping.  It'll have a natural frequency.  And I get immediate insight as to its behavior  by knowing this, OK.  And that's the real reason why I wanted to show this to you. ", "So today we'll do-- there are sort of two directions we  can go with this.  One is to talk about response to initial conditions, ", "and the other is to talk about the response  to force excitation.  So we're going to begin by doing response to ICs, OK? ", "And then we'll move on probably next time  and talk about response to harmonic excitations.   And we're going to use that as the example. ", "Before I go there, once we have broken the system down  and analyzed this way, how do we get back  to the motion of the system in our generalized coordinates, ", "which are the ones we're comfortable with?  Because I don't know where to take a ruler and go  measure this natural coordinate. ", "So somehow I have to get back to putting  in the real physical measurements  that I can relate to.  Well, that's easy because where did we start with this?  We started by saying this whole thing began right here. ", " And so at the end we just come back and say, oh, well, ", "x here, our generalized coordinates,  is this summation of the mode shapes ui here, summed ", "over i of qi of t.  Now the reason I wrote it here as a summation ", "is to remind you that you do this.  ", "That's the beauty of this thing, is  you only have to do it over the modes that matter.  So if you've decided to approximate the motion  of this complicated system, by just a couple  of motile contributions because you ", "know they're the important ones, this  is a pretty short summation.  This is how you get back to your original modal coordinates.  Just take the modal amplitude, multiply it by the mode shape. ", "And when you do that, it says, if this turns out  to be, say, sum a sine omega t, when you multiply by the mode  shape it basically tells you how much  each generalized coordinate gets of the motion. ", "The mode shape distributes thing answer  out proportionally in the correct amount.  So this is how you get back to the original.  So let's think about that system and we'll ", "do an initial conditions kind of problem.  So I think Professor Gossard-- I think  in class you sort of figured out what the approximate ks  and ms and things were for that system.  So I actually took it apart, weighed it, ", "measured some natural frequencies,  and have come up with a pretty good model,  or at least pretty good set of numbers, ", "characterizing this two degree of freedom system.  ", "So c1, k1, m1, k2, c2, x1, x2. ", "So these are my generalized coordinates, measured probably  from what position?   Static equilibrium, right? ", "So I don't have to mess with gravity in this.  Measured from static equilibrium.  And to try to help keep things understandable, ", "I tried to write the parameters of the system  as lowercase k1s, k2s, k3s because I  want to write modal stiffness for mode one as a capital K1, ", "so I try to be consistent about that.  And notice where I put the dampers in the system.  That's because most of the damping in this thing  comes from the upper mass rubs against a stationary object, ", "which is the bar here.  The lower mass rubs against a stationary object.  So I'm going to model that as a dashpot between each mass  and the fixed reference frame because the bar doesn't move. ", "So it's an approximate model of the damping.  And so if we do our sum of forces on each of these masses,  just do Newton's laws on the mass,  we can come up with our two equations of motion. ", "We get two equations of motion.   And let's see.  ", "I think I'll give you some information here first.  m1.  ", "And I really don't know the damping,  but we can get that by just counting how many cycles it  takes to decay and so forth.  So that's basically what I come into this problem knowing. ", " And I'm going to write my equations of motion  in matrix form.  So it's going to end up looking like m1. ", "", "Now notice the damping in this one, the damping force,  is only proportion-- it'll be c1 x1.  Doesn't involve the motion of the other object.  In this one, the damping force only ", "involves the second motion.  So this one happens to look like a c1, 0, c2.  ", "And the stiffness matrix, well, that's k1 plus k2, minus k2,  minus k2, and k2, x1, x2. ", "And for no external forces, this starts off this one  has nothing on the right hand side. it's equal to 0.  So those are my equations of motion. ", "And you know if you multiply these out  you'd get two equations.  And each one would be this result  that you get by apply Newton's law to mass one  and Newton's law to mass two. ", "But you we've done that enough times.  I'm not going to go through that part of it.   OK.  ", "And putting it in real numbers, that's our mass matrix. ", " I don't know this.  My stiffness matrix.  ", "So this is my K matrix here.  And stiffness matrices, they're always symmetric.  ", "Although this one happened to be diagonal,  you'll find that mass matrices and even the damping matrices  for our linear systems are symmetric.  So here's my stiffness matrix.  Here's my mass matrix, OK? ", " And also in this case here's my damping matrix,  but I'm going to leave that because it's the one that's  a little bit troublesome.  So what do I need to do to this to carry out my modal analysis? ", "So I need to go find the results of computing u transpose m  and u and transpose Ku. ", "And let's see what we get.   So we need to know a couple things about this system. ", " We need to know natural frequencies and mode shapes.  So if we have this mass matrix and we  have the stiffness matrix, then we know we can cast this. ", "We want the undamped natural frequencies and our mode  shapes.  ", "And we know that we can transform  the equations of motion into an algebraic problem where  we solve for the natural frequencies and mode shapes.  So we have, just to remind you really quickly of that, ", "remember our equations look like this undamped.   And you assume that x is some form u in fact e to the i omega ", "t.  Plug it in, you get minus omega squared m plus K u e ", "to the i omega t equals 0.   And this now is your algebraic problem.  e to this unknown set of amplitudes is 0. ", "These are going to turn out to be the mode shapes.  And they're not generally 0 so that means this has to be 0.  That means we know the determinant of this matrix.  ", "And that'll give you in this case the two  natural frequencies.  This gives of you the omega ns of the system.  Omega n squareds is what you solve for, OK?  And then you go back and you get the mode shapes out of it. ", "But this you can do on the computer too.  You can either crank out-- for a two degree of freedom system,  this gives you a quadratic omega squared.  You solve it.  You plug it back in and get the mode shapes. ", "I'm not going to take the time to do  that today because I want to emphasize the modal analysis  part.  So I'll give you the answers.  ", "Where are we here?   So you get omega 1 is 5.6546. ", "And I seem to be keeping a lot of significant digits,  and there's a reason for that.  ", "In both mode shapes and natural frequencies  you need to carry a lot of significant digits  or modal analysis doesn't work, or at least you  don't get the clean results you expect.  If you're sloppy about the number of significant digits ", "and you compute u transpose mu, then the  [? off ?] diagonal terms won't quite go to 0.  And it's just because you're not carrying enough precision. ", "OK, now that's the two natural frequencies.  Now the u matrix, the mode shapes for this system  that goes with that. ", "u comes out to be 1.0 and 2.2667. ", "And that's mode.  I'll do this to help you.  The columns are the mode shapes.  That's the first mode shape.  And the second mode shape is 1 and minus 0.2236. ", "So those are the mode shapes for the first and second mode  that go with these two natural frequencies.  So that's for this system.  The top one moves one unit.  The bottom one moves 2.27 times that, same direction, ", "positive, positive.  So the upper one moves one unit.  The bottom one moves the opposite direction--  that's the minus signs-- equivalent to a phase  angle of 180 degrees minus 22% of the amount ", "that the upper one moves.  So first one moves one unit.  The bottom one moves 2.2 times that.  And then the second mode, which is much harder to get going. ", " Guess the only way I can do it is  to do it the way Professor Gossard intended here.  ", "One unit up and down, minus 0.2236, going the opposite way.  So those are our mode shapes.  These are the natural frequencies.  I calculated this one and measured it with a stopwatch. ", "This one I can do watching it with a stopwatch.  And I came within better than 1% of getting the same number.  OK.  ", "So I want my model mass matrix.  I carry out this calculation.  And for this system, remember, it's  going to give me back a diagonal matrix looking like this. ", "And in fact, the numbers are 3.5562, 0, 0, and 0.3508. ", "And when I calculate u transpose Ku,  gives me a diagonal stiffness matrix.  ", "And I get the numbers 113.71 and 0, 0, 109.839. ", "And that's my diagonalized stiffness matrix.  Now something had better be true.  I'm saying that this is now going  to give me my two independent single degree of freedom ", "equations of motion, right?  ", "So what I'm seeking here, I want to get two equations,  one that looks like m1q1 double dot plus c1q1 dot plus K1q1 ", "equals 0 for no external force.  That's one of the equations I'm after.  And the other one will look like m2q2 double dot plus c2q2 dot ", "K2q2.   Now one way to check that you've gotten the right thing  is now these are two independent single degree of freedom  systems.  What's the natural frequency of this system? ", "", "Yeah?  Actually, I heard somebody say square root of K1 over m1.  That had better be true.  But numerically what's the number?  What had it better be?  It better be the omega 1 of the system, right? ", "And so a check that you can perform  is to check to see if the omega 1 squared equals K1/m1. ", "You found two numbers.  You've got, up here, K1 is 113.7.  m1 is 3.55. ", "Take K1/m1, and take its square root.  So K1/m1, that's about 30 something.  Square root of 30 something is a little less than 6. ", "Omega 1 is 5.65.  And same thing, omega 2 had better  be equal to the square root of K2/m2. ", "So one of the things you can always  do when you do your modal analysis,  you do your calculations, u transpose mu, u transpose Ku.  If you calculate the ratios of each one of these things, ", "you can go back and check that you  can see that the natural frequencies are  the ones that you started with.  If they are not, then you've messed up in your arithmetic.  So now we've got our two independent equations. ", "And the natural frequencies check out.  But we still have a couple of things to deal with.  We have to figure out how to calculate  the initial conditions, and we have to figure out ", "how to deal with damping.   Let's do ICs first.  ", "So those of you who were here last time,  I ended kind of right at the end.  We kind of worked our way through figuring out  the initial conditions for a two degree of freedom system ", "doing it the hard way.  You end up with four equations and four unknowns  for the a1, a2, phi 1, phi two.  Remember that?  I mean, it's really painful.  This is incredibly easier. ", "We're going to do the same thing, but extremely easily.  So I would never go myself given the choice of grinding out  all those phase angles and amplitudes ", "in simultaneous equations.  I'd do the following.  Generally now I know the initial conditions are  going to be specified not in q coordinates  but in what coordinate system? ", " In your original generalized coordinates, right?  You know, your x, this one.  If I'm going to set initial conditions here, ", "I'm not going to say q1 is equal to something.  I'm going to put this one down one unit and this one  down two units and let go.  This is in x1 and x2 coordinates.  But the beautiful thing here is that we know that x equals uq. ", " So if I know the initial conditions on I'll  call it x0 here, if I know the initial deflections ", "of the system, they're going to be u  times the initial values of q.  And if I know a vector of initial velocities at time 0, ", "they're going to be uq0 dot.   So if I told you values of x0 and you ", "know that this equation's true, what we need is the q0s.  We need the initial conditions in the modal  coordinates in order to finish this problem.  If I told you this, how would you solve for that? ", " Just a little linear algebra here.   AUDIENCE: Inverse matrix of u? ", "PROFESSOR: Yeah, do what with it?  AUDIENCE: Then you multiply x by it.  PROFESSOR: Multiply it by u inverse, right?  OK, so this implies that q0-- well, ", "I'll write it out a little more fully here.  So if I do u inverse x0, that's going ", "to be equal to u inverse uq0.   u inverse times u gives you? ", "1, basically, right?  And so if I do u inverse x0, I get q0.  That's all there is to it. ", "Yeah?  AUDIENCE: [INAUDIBLE] initial conditions, what about c?  PROFESSOR: All right, c's a problem, OK,  and I'm leaving it to the end.  We're going to deal with it as the last step. ", "And if I have initial velocities u inverse times x  initial velocities vector, I get the initial velocities vector ", "in the natural coordinates.  So that's how simple it is to get the initial conditions  in modal coordinates.  Boom, OK?  ", "And we'll do a numerical example in a second here.   We're seeking a solution of the form to do response ", "to initial conditions.   We seek equations that we know are ", "right for a single degree of freedom system response  to initial conditions.  So we know that for a single degree of freedom system, x ", "of t-- this is for SDOF system here-- ", "we worked out before is equal to some e to the minus zeta  omega nt.  This is just a transient decay problem of x0 cosine omega dt ", "plus v0 plus zeta omega n x0 all over omega d sine omega dt. ", "We know that that's what the response of a single degree  of freedom system looks like to initial conditions x0 and v0.  And for light damping, for small damping, ", "you can usually even ignore this term.  So it's just even simpler.  This term is small compared to that, all right?  This term, contribution from x0, is small compared to this term. ", "So it's basically dominated by an x0 cosine and a v0  over omega d sine.  But we know that's the exact response  for a single degree of freedom system to initial conditions. ", "So just by analogy to that, we're  looking for mode one in modal coordinates.  It's going to look exactly the same way.  e to the minus zeta omega nt, q0 cosine omega 1 ", "d-- this is omega dt-- plus q0 dot plus zeta 1 omega 1 q0. ", "I guess I need to do q10 like that.  This is the first mode's equation, zeta 1.  And I'll call this omega 1. ", "But now that you get multiple degree of freedom systems,  you got to keep track of what mode you're talking about.  Mode one, damping ratio mode one,  natural frequency mode one, initial displacement mode one, ", "initial velocity mode one, omega 1 d like that.  And mode two is going to be exactly analogous. ", "q2 equals, and it's exactly similar,  except you update it with a 2 instead of a 1.  ", "And if you plug in the initial-- you over here  have found the initial values for q10 and q20 and q1 dot 0 ", "and so forth.  You found the initial values that plug into that equation  by just doing this.   And once we have this, then we can go back to saying, ", "how do you get to the final answer?  Well, you just multiply the result  for q times the mode shape and add them up.  And you have the answer.  But we still have to deal with the damping problem. ", " We're going to do that one next.  But I see a bunch of hands and some puzzled looks,  so it means it's a good time to stop and talk for a second. ", "Yeah?  AUDIENCE: [INAUDIBLE]  PROFESSOR: Pardon?  AUDIENCE: What if you [INAUDIBLE]  PROFESSOR: I can't quite hear.  AUDIENCE: The sine theta and the sine rate of g.  PROFESSOR: Yeah, what about it? ", "AUDIENCE: Why do we lose it?  PROFESSOR: Why do we use it?  AUDIENCE: Lose it.  PROFESSOR: Oh, you don't lose it.  I was saying, you see this bit, it's like that.  These are two pieces that behave like sine. ", "And see, this one depends on initial displacement  but is multiplied by the damping ratio.  And the damping ratio for things that are interesting  is usually pretty small.  So here you have a term that's x0 cosine omega 1 damped, ", "and here you have a contribution that's x0 small times  x0 sine omega 1 damped. ", "So you multiply the same.  They're operating on the same frequency.  Two terms at the same frequency, you add them together,  it's like a cosine omega t minus some phase angle. ", "If this little term is small, that phase angle's almost 0.   x0 cosine plus something x0 sine, ", "it gives you a cosine term that is shifted a little bit  and its magnitude is different by this little amount.  I'm just saying oftentimes this is small.  But if you don't want to make that approximation, ", "just carry it along.  Just do it.  AUDIENCE: [INAUDIBLE]   PROFESSOR: Mm-hmm.  AUDIENCE: [INAUDIBLE]  PROFESSOR: Oh, no.  I'm just saying you can throw out this piece usually. ", "And it makes-- I keep in my mind-- let me see.  OK, now.  Vibration engineering is full of lots of approximations ", "because it's very hard oftentimes  to get detailed quantitative numbers on exactly  everything you need to know.  So I carry around little approximations ", "that I know is the way the world mostly behaves.  And the way the world mostly behaves  for a single degree of freedom system  is the response to initial conditions looks like this.  ", "And this initial value here is always approximately x0.  And this initial slope here is always approximately v0. ", " That's the slope.   Now, it turns out that this thing is shifted just slightly. ", "Why?  Because of this term, OK?  But honest, to tell you the truth,  it really rarely matters.  So as a vibration engineer, I just ", "remember I have an x0 cosine.  I have a v0 over omega d sine.  And the whole thing decays like that.  But if you like to be mathematically precise,  you carry along that a little bit. ", "Yeah?  AUDIENCE: Don't you lose [INAUDIBLE] sine wave?  PROFESSOR: You're not going to lose the sine.  AUDIENCE: [INAUDIBLE]  PROFESSOR: Oh, oh, oh.  Wait a minute.  I just left it out.  ", "You guys are-- well, I'm glad you're awake.  This is good.   Now how's that?  Ah, good.  Now I know why I had so many puzzled looks. ", "Anybody have a different question?  Just anything now about this whole modal analysis thing?  Because then we have to deal with this awkward part that  has to do with the damping.  And I've got to finish on time, OK? ", " All right.   So damping.  I've gotten this far. ", "What I need is I need estimates for the damping for mode one  and damping for mode two, right?  ", "So the problem is that utcu does not always ", "equal some nice diagonalized matrix.  You sometimes get these are not always 0, OK? ", "The orthogonality principle just doesn't  apply to the damping terms.  Just doesn't.   But this actually doesn't hurt you a lot. ", "You just got to know that this is going to be a problem.  And when the systems are lightly damped,  the approximation, even if your true damping in the system  gives you some non-zero elements here, ", "the first order behavior of the system  is basically going to be-- you can just ignore  the off-diagonal elements.  What practical consequence do you  think it has if you have some actual non-zero numbers here? ", "Go back and look at the equations  that you're trying to derive.  These were the equations that we were trying to come up with.  And we wanted them to be n individual single degree ", "of freedom systems.  But if this has non-zero off-diagonal terms,  you're going to find popping up in this single degree  of freedom equation another term that couples it through damping ", "to the other modes.  It provides a little bit of coupling to other modes.  They can talk to one another, all right?  And what that means is if I-- this may be a good time ", "to do the demonstration.  ", "How do I want to say this?  ", "If the initial displacement of the system  is in the shape of one of the natural modes-- ", "so if this is some u, this is exactly shaped like mode r.  So this looks like the ur vector.  ", "When I carry out this multiplication,  what do you think will happen?  ", "If this is shaped like mode r, because  of orthogonality when I do u inverse, which  is all about the mode shapes information and the mode  shapes are these orthogonal set of independent orthogonal ", "vectors, if this is exactly one mode  and I do u inverse times that, I will get 0 over here  on the right hand side for every mode except the mode ", "that that's shaped like.  So if this is shaped like a particular mode,  then over here all the modal initial conditions  are 0 except that mode. ", "That means if I set this, give its initial conditions are  equal to the shape exactly of mode one, ", "it only responds in mode one.  And if I give it initial conditions that are exactly ", "shaped like that of mode two, then it only  responds in mode two.  And if I give it anything else, like I move just the top one ", "but not the bottom and let it go,  then there's-- maybe I better do the other one.  That one had too much of one and not the other.  If I hold this one, here's its reference. ", "I'm going to hold it right there and I'm  going to give this one a unit deflection and let go.  Now you see a get some of both, all right?  So if when I do this first one, say first mode, ", "I could sit here and measure how many cycles  it takes to decay halfway and estimate the damping ratio  for that mode.  If it's only moving in this mode,  I can estimate its damping directly for that mode ", "and get zeta 1.  You agree?  OK.  And I did the same thing with mode two, it's too fast for me  to catch it with a stopwatch, but I  could measure its damping. ", "And as it decays, I could get an estimate for zeta 2,  for the damping ratio for mode two, all right?  All right.  But somehow I have to get damping  ratio for mode one, zeta 1, and damping ratio ", "for mode two, zeta 2.  I have to somehow get it out of this.  I have to model it somehow with these damping coefficients that  come from computing this u transpose cu, OK. ", " So I'm going to show you kind of damping  called Rayleigh damping, OK? ", "Lord Rayleigh, who did lots of things in science  that you've probably run into, proposed  that if you model your damping, the c matrix as-- this ", "is just now the system damping matrix  that you start with-- some alpha times the mass matrix ", "plus beta times the stiffness matrix-- these are now  the original ones in your generalized coordinates,  just your mass and stiffness matrices. ", "If you say, I'm going to approximate my damping model  like this, then I want to compute u transpose cu. ", " I'm going to get alpha u transpose  mu plus beta u transpose Ku. ", " But we know that this gives you the diagonalized mass matrix,  known as the modal mass matrix.  This gives you the diagonalized stiffness matrix. ", "And so this damping model, this is  guaranteed to give you a diagonalized damping matrix  which we'll call, somehow, some capital C2, 0, ", "0, C2, all right?  And it's going to be alpha times the modal mass matrix ", "plus a beta times the modal stiffness matrix.  And those alphas and betas you adjust.  They're just parameters you adjust  to get the amount of damping you need, OK? ", "So for a two degree of freedom system, ", "C1 here is alpha m1 plus beta K1. ", "Modal mass, alpha times the modal mass  plus beta times the modal stiffness.  That's what you get for the first one.  And C2 is alpha m2 plus beta K2, OK? ", " And the alphas and betas give you two free parameters  you can play with. ", "And for a two degree of freedom system,  I can manipulate alpha and beta to get the damping  that I measure.  And I forced my equations of motion a couple. ", "Now, Mother Nature may say, you know, Vandiver,  they don't uncouple, and there's going  to be a little crosstalk between them.  But I say, yeah, but to first order  I'm going to get a pretty good model of the system. ", "So let's do that in this case.  Let's maybe just to keep it-- I've got numbers here,  so let my notes so I don't get completely lost here. ", "So I'm going to just pick one for now.  I'm going to model my damping with just  beta K, beta times my diagonal, my stiffness matrix. ", "And let's see what happens here.   So that says my modal damping is going to be some, ", "for mode one, beta K1.  Now what's damping ratio?  Zeta 1 for a single degree of freedom system ", "is the damping constant for the system over 2 omega 1 m1.  But that's going to be beta K1 over 2 omega 1 m1. ", "But m1/K1 is omega 1 squared.  So I get an omega 1 squared in the numerator.  Beta omega 1 squared over 2 omega 1. ", "Remember, the K over the m gave me the omega one squared,  so the ms are gone.  You can cancel one of these.  This gives me beta omega 1 over 2.  ", "So this now gives me a way I can fit one of the dampings.  I can get exactly what I want, say, for mode one ", "if I pick beta to be the right number.  OK, so in this case, I actually did some numbers. ", " Pardon?  Can't hear you.  AUDIENCE: [INAUDIBLE] ", "PROFESSOR: No.  K1/m1 is omega 1 squared.  Omega 1 squared takes care of the m1.  I get rid of one of the omega 1s.  I'm left with this, OK? ", "OK.   So let's just let beta equal 0.01.  And if you let beta equal to 0.01, ", "then zeta 1 equals 0.01 omega 1 over 2.  We know omega 1 is 5.65. ", "This when you work it out then gives you  a number of 0.0283, about 3%. ", "And that would say that this system when it vibrates  in mode one is going to damp out up to 50%  in about three cycles.  Not bad approximations. ", "I'm just guessing about what it is.  That's a reasonable amount of damping for mode one.  Now the problem is when I only use just beta K as my model. ", "Now I'm stuck with whatever happens for mode two  once I pick beta because zeta 2 is going  to be beta omega 2 over 2. ", "And omega 2 is quite a bit larger,  so now I'm stuck with a greater value for the second mode.  In this case, it's 0.0885. ", "So if I just pick a one parameter model for my damping,  I can make one perfect.  I can match it perfectly, but then I'm  stuck with whatever the other one is. ", "So I did this because I could do it simply with one.  But if I'd kept the full two-parameter model,  with manipulating both alpha and beta ", "I could actually get both of the two measured dampings  exactly right.  But if I have an n degree-- if I have  three degree of freedom system, I only have two parameters.  I can fit two of the damping ratios, ", "but then I'm going to be stuck with whatever it gives me  for the third.  But oftentimes it's just one mode you really care about.  It's the problem mode.  You're at its natural frequency.  It's going like crazy. ", "Initial conditions make it vibrate a lot in that mode.  But this is what Rayleigh damping allows you to do.  It guarantees you that you will have a diagonalized set ", "of equations of motion.  And it gives you two parameters that you  can play with to fit the damping model however you want.  Once you have damping, now you have the complete solution ", "for decay from initial conditions.   And there's your two models.  You can solve for q1, transient decay given initial conditions. ", "You can solve for q2, transient K of the second mode.  And then to get back to the initial  to the response in terms of your modal coordinates, ", "you just add the two together, OK?   I got some numbers here which are just instructive. ", " u Inverse.  In order to get these initial conditions,  you've got to know u inverse.  Do we know u?  I gave us u.  Here's our set of mode shape vectors. ", "And I've run out of boards.  ", "So we have the u matrix.  We need u inverse, so u inverse for this problem.  ", "And we're going to quickly do some examples.  Let's let the v0s be 0.  No initial conditions on velocities. ", "And let's do x0, the initial displacements, be 1 and 0. ", "So the 1 and 0, what we're saying  is the bottom one doesn't move, unit deflection here, let  it go.  What are you're going to get for the initial conditions? ", "x0 equals 1 and 0, well, that implies that the qs are ", "going to be u inverse x0.  So by the way, if this is true, this  implies that all q dot initial conditions equal 0, right? ", "No initial velocities in generalized  coordinates, no initial velocities in modal  coordinates.  But we are going to have an initial deflection.  ", "I want to then compute u inverse x0 and see what I get.  And what I get back when I do this one is 0.0898 and 0.9102. ", "Remember, this is q10, q20.   So for that case, it says I'm going to get 0.08 or 0.09 ", "equal to q1 and 0.9 of q2.  And I go back over here to my transient decay.  There's no velocity.  So it's basically going to look like q10 cosine omega ", "dt, e the minus zeta omega t, decaying, cosine.  But for mode one, its initial amplitude's less than 0.1. ", "And mode two, it's got a lot of mode two.  So what happens?  So unit deflection here, in fact it's mostly mode two. ", "And just quickly I'll do one other.  x0 is 0, 1.  That implies that q0 that you get from that ", "is 0.4016 and minus 0.4016. ", "Says you get about equal amounts.  So that's this one.  I don't move this one, but I give this one  a unit deflection, let go. ", "I get about equal amounts of each one.  And of course I've told you the answer to this one.  If I let x equal mode one's mode shape, ", "1 and 2.266, that implies that q1 equals 1 and q2, when ", "you multiply it out, is zero 0.  If I deflect it in the shape of mode one and I do u inverse x0,  I will get back 0 and 1.  And if I make this the shape of mode two, ", "I will get back 0 for mode one and 1 for mode two.   I've out of time, but that's your intro to modal analysis. ", "So I think it's conceptually powerful.  Yes.  AUDIENCE: How did you get from the 0.898 value  to the 0.0898 value? ", "AUDIENCE: The inverse should be 0.0898.  PROFESSOR: Oh, is this 0.08?  Yeah, OK.  I may have written that down.  ", "Yeah.  I'll double check that.  But yeah, question?  AUDIENCE: Why is it for here that we picked c  to be only a function of--  PROFESSOR: Beta?  AUDIENCE: A.  PROFESSOR: Because I want to get done by the end of the-- ", "AUDIENCE: OK.  PROFESSOR: --60 minutes, 80 minutes.  I could have put both of them in,  manipulated both parameters as two equation with [? two ?]  modes, two target values of dampings.  I'd find an alpha and a beta that would ", "make both work exactly right.  Actually, just this one model is pretty good for this case.  The damping for second mode is greater  than the first mode just happens to be.  This model's not bad. ", "AUDIENCE: All right, so you try the three  and see what gets you the best results?  PROFESSOR: Yeah. "], "vid_duration": [11.029, 11.73, 11.101, 10.099, 11.52, 11.891, 12.639, 10.051, 10.3, 12.97, 14.05, 10.92, 10.73, 10.94, 11.73, 11.29, 19.835, 12.634, 13.811, 11.045, 12.385, 11.93, 11.57, 12.8, 10.25, 22.6, 12.31, 13.083, 10.587, 12.18, 10.909, 11.75, 16.051, 10.6, 11.87, 19.5, 10.57, 10.54, 14.332, 15.638, 13.519, 13.011, 10.23, 13.05, 11.49, 10.09, 10.37, 10.37, 13.67, 17.49, 12.25, 12.194, 11.276, 12.64, 11.24, 11.1, 10.27, 11.8, 15.31, 23.81, 29.92, 10.67, 17.44, 14.76, 14.41, 10.2, 13.81, 11.19, 13.5, 12.79, 15.05, 18.92, 16.73, 10.33, 11.71, 14.44, 12.23, 11.11, 13.929, 11.551, 21.87, 11.695, 12.905, 11.07, 14.33, 12.93, 12.28, 12.321, 12.949, 10.51, 12.6, 11.84, 14.56, 11.312, 11.748, 11.39, 11.56, 10.43, 10.662, 10.848, 18.68, 12.6, 10.788, 15.452, 12.17, 11.01, 12.975, 10.945, 13.091, 13.329, 11.43, 10.62, 11.183, 10.707, 13.57, 18.1, 11.01, 11.21, 13.4, 11.42, 10.08, 11.434, 12.696, 13.55, 12.96, 11.39, 11.61, 11.08, 13.65, 10.93, 10.57, 10.17, 11.8, 13.28, 17.47, 12.5, 13.501, 10.279, 11.87, 12.22, 15.0, 11.57, 14.522, 11.278, 14.08, 13.52, 14.56, 13.12, 11.97, 13.45, 13.96, 10.48, 12.09, 10.71, 13.91, 12.83, 12.3, 10.48, 44.408, 10.432, 10.71, 14.23, 11.48, 15.68, 19.57, 10.61, 11.109, 36.341, 13.535, 29.965, 11.11, 11.58, 15.04, 10.102, 10.718, 15.08, 27.8, 14.83, 14.9, 13.97, 11.93, 17.6, 16.09, 11.51, 13.59, 15.32, 15.54, 12.36, 10.89, 10.23, 12.819, 21.011, 14.28, 11.36, 12.36, 12.81, 12.33, 32.12, 12.18, 16.58, 11.82, 21.73, 11.56, 12.989, 14.331, 12.946, 11.677, 10.577, 11.76, 14.05, 11.43, 13.956, 10.184, 10.196, 10.224, 11.919, 27.221, 12.524, 12.296, 11.34, 10.2, 11.47, 15.565, 11.755, 14.23, 11.0, 11.22, 10.67, 18.48, 13.15, 10.8, 11.03, 10.11, 10.91, 13.84, 16.809, 14.005, 11.336, 17.51, 16.7, 17.22, 11.12, 14.06, 10.86, 19.22, 14.84, 11.547, 11.293, 10.87, 10.88, 12.44, 10.96, 11.61, 11.5, 10.72, 12.08, 17.62, 10.12, 10.02, 14.32, 10.88, 11.13, 10.04, 11.13, 11.2, 11.6, 10.67, 10.0, 11.04, 13.03, 12.73, 11.936, 11.134, 23.57, 18.08, 17.24, 11.43, 10.92, 14.82, 14.45, 13.23, 13.14, 16.145, 15.385, 13.39, 11.71, 12.29, 12.63, 13.31, 12.94, 10.23, 10.81, 14.11, 11.3, 24.93, 11.78, 10.68, 12.32, 13.91, 18.62, 14.11, 12.21, 10.59, 19.525, 12.125, 12.57, 12.939, 12.911, 13.57, 15.07, 13.79, 16.047, 10.663, 11.949, 11.681, 11.26, 29.8, 12.6, 11.61, 18.76, 16.734, 12.416, 10.69, 10.37, 11.16, 12.551, 11.719, 10.0, 10.98, 11.052, 10.018, 12.54, 13.96, 10.64, 10.82, 10.54, 10.87, 10.59, 12.64, 10.81, 11.19, 10.444, 12.736, 27.33, 20.62, 11.23, 10.19, 11.08, 11.76, 12.53, 11.54, 20.96, 13.32, 18.079, 11.791, 12.14, 14.75, 10.43, 11.56, 11.86, 12.0, 11.71, 13.82, 14.836, 14.103, 11.486, 10.865, 10.962, 7.888], "stet": [[0, 11.029], [11.029, 22.759], [22.759, 33.86], [33.86, 43.959], [43.959, 55.479], [55.479, 67.37], [67.37, 80.009], [80.009, 90.06], [90.06, 100.36], [100.36, 113.33], [113.33, 127.38], [127.38, 138.29999999999998], [138.29999999999998, 149.02999999999997], [149.02999999999997, 159.96999999999997], [159.96999999999997, 171.69999999999996], [171.69999999999996, 182.98999999999995], [182.98999999999995, 202.82499999999996], [202.82499999999996, 215.45899999999995], [215.45899999999995, 229.26999999999995], [229.26999999999995, 240.31499999999994], [240.31499999999994, 252.69999999999993], [252.69999999999993, 264.62999999999994], [264.62999999999994, 276.19999999999993], [276.19999999999993, 288.99999999999994], [288.99999999999994, 299.24999999999994], [299.24999999999994, 321.84999999999997], [321.84999999999997, 334.15999999999997], [334.15999999999997, 347.243], [347.243, 357.83], [357.83, 370.01], [370.01, 380.919], [380.919, 392.669], [392.669, 408.71999999999997], [408.71999999999997, 419.32], [419.32, 431.19], [431.19, 450.69], [450.69, 461.26], [461.26, 471.8], [471.8, 486.132], [486.132, 501.77], [501.77, 515.289], [515.289, 528.3], [528.3, 538.53], [538.53, 551.5799999999999], [551.5799999999999, 563.0699999999999], [563.0699999999999, 573.16], [573.16, 583.53], [583.53, 593.9], [593.9, 607.5699999999999], [607.5699999999999, 625.06], [625.06, 637.31], [637.31, 649.5039999999999], [649.5039999999999, 660.7799999999999], [660.7799999999999, 673.4199999999998], [673.4199999999998, 684.6599999999999], [684.6599999999999, 695.7599999999999], [695.7599999999999, 706.0299999999999], [706.0299999999999, 717.8299999999998], [717.8299999999998, 733.1399999999998], [733.1399999999998, 756.9499999999997], [756.9499999999997, 786.8699999999997], [786.8699999999997, 797.5399999999996], [797.5399999999996, 814.9799999999997], [814.9799999999997, 829.7399999999997], [829.7399999999997, 844.1499999999996], [844.1499999999996, 854.3499999999997], [854.3499999999997, 868.1599999999996], [868.1599999999996, 879.3499999999997], [879.3499999999997, 892.8499999999997], [892.8499999999997, 905.6399999999996], [905.6399999999996, 920.6899999999996], [920.6899999999996, 939.6099999999996], [939.6099999999996, 956.3399999999996], [956.3399999999996, 966.6699999999996], [966.6699999999996, 978.3799999999997], [978.3799999999997, 992.8199999999997], [992.8199999999997, 1005.0499999999997], [1005.0499999999997, 1016.1599999999997], [1016.1599999999997, 1030.0889999999997], [1030.0889999999997, 1041.6399999999996], [1041.6399999999996, 1063.5099999999995], [1063.5099999999995, 1075.2049999999995], [1075.2049999999995, 1088.1099999999994], [1088.1099999999994, 1099.1799999999994], [1099.1799999999994, 1113.5099999999993], [1113.5099999999993, 1126.4399999999994], [1126.4399999999994, 1138.7199999999993], [1138.7199999999993, 1151.0409999999993], [1151.0409999999993, 1163.9899999999993], [1163.9899999999993, 1174.4999999999993], [1174.4999999999993, 1187.0999999999992], [1187.0999999999992, 1198.9399999999991], [1198.9399999999991, 1213.499999999999], [1213.499999999999, 1224.811999999999], [1224.811999999999, 1236.559999999999], [1236.559999999999, 1247.9499999999991], [1247.9499999999991, 1259.509999999999], [1259.509999999999, 1269.9399999999991], [1269.9399999999991, 1280.6019999999992], [1280.6019999999992, 1291.4499999999991], [1291.4499999999991, 1310.1299999999992], [1310.1299999999992, 1322.729999999999], [1322.729999999999, 1333.5179999999991], [1333.5179999999991, 1348.9699999999991], [1348.9699999999991, 1361.1399999999992], [1361.1399999999992, 1372.1499999999992], [1372.1499999999992, 1385.124999999999], [1385.124999999999, 1396.069999999999], [1396.069999999999, 1409.160999999999], [1409.160999999999, 1422.4899999999989], [1422.4899999999989, 1433.919999999999], [1433.919999999999, 1444.5399999999988], [1444.5399999999988, 1455.7229999999988], [1455.7229999999988, 1466.429999999999], [1466.429999999999, 1479.9999999999989], [1479.9999999999989, 1498.0999999999988], [1498.0999999999988, 1509.1099999999988], [1509.1099999999988, 1520.3199999999988], [1520.3199999999988, 1533.719999999999], [1533.719999999999, 1545.139999999999], [1545.139999999999, 1555.219999999999], [1555.219999999999, 1566.6539999999989], [1566.6539999999989, 1579.3499999999988], [1579.3499999999988, 1592.8999999999987], [1592.8999999999987, 1605.8599999999988], [1605.8599999999988, 1617.2499999999989], [1617.2499999999989, 1628.8599999999988], [1628.8599999999988, 1639.9399999999987], [1639.9399999999987, 1653.5899999999988], [1653.5899999999988, 1664.5199999999988], [1664.5199999999988, 1675.0899999999988], [1675.0899999999988, 1685.2599999999989], [1685.2599999999989, 1697.0599999999988], [1697.0599999999988, 1710.3399999999988], [1710.3399999999988, 1727.8099999999988], [1727.8099999999988, 1740.3099999999988], [1740.3099999999988, 1753.8109999999988], [1753.8109999999988, 1764.0899999999988], [1764.0899999999988, 1775.9599999999987], [1775.9599999999987, 1788.1799999999987], [1788.1799999999987, 1803.1799999999987], [1803.1799999999987, 1814.7499999999986], [1814.7499999999986, 1829.2719999999986], [1829.2719999999986, 1840.5499999999986], [1840.5499999999986, 1854.6299999999985], [1854.6299999999985, 1868.1499999999985], [1868.1499999999985, 1882.7099999999984], [1882.7099999999984, 1895.8299999999983], [1895.8299999999983, 1907.7999999999984], [1907.7999999999984, 1921.2499999999984], [1921.2499999999984, 1935.2099999999984], [1935.2099999999984, 1945.6899999999985], [1945.6899999999985, 1957.7799999999984], [1957.7799999999984, 1968.4899999999984], [1968.4899999999984, 1982.3999999999985], [1982.3999999999985, 1995.2299999999984], [1995.2299999999984, 2007.5299999999984], [2007.5299999999984, 2018.0099999999984], [2018.0099999999984, 2062.4179999999983], [2062.4179999999983, 2072.849999999998], [2072.849999999998, 2083.559999999998], [2083.559999999998, 2097.789999999998], [2097.789999999998, 2109.269999999998], [2109.269999999998, 2124.949999999998], [2124.949999999998, 2144.519999999998], [2144.519999999998, 2155.1299999999983], [2155.1299999999983, 2166.238999999998], [2166.238999999998, 2202.579999999998], [2202.579999999998, 2216.114999999998], [2216.114999999998, 2246.079999999998], [2246.079999999998, 2257.1899999999982], [2257.1899999999982, 2268.769999999998], [2268.769999999998, 2283.809999999998], [2283.809999999998, 2293.911999999998], [2293.911999999998, 2304.629999999998], [2304.629999999998, 2319.7099999999978], [2319.7099999999978, 2347.509999999998], [2347.509999999998, 2362.339999999998], [2362.339999999998, 2377.239999999998], [2377.239999999998, 2391.2099999999978], [2391.2099999999978, 2403.1399999999976], [2403.1399999999976, 2420.7399999999975], [2420.7399999999975, 2436.8299999999977], [2436.8299999999977, 2448.339999999998], [2448.339999999998, 2461.929999999998], [2461.929999999998, 2477.249999999998], [2477.249999999998, 2492.789999999998], [2492.789999999998, 2505.1499999999983], [2505.1499999999983, 2516.039999999998], [2516.039999999998, 2526.269999999998], [2526.269999999998, 2539.088999999998], [2539.088999999998, 2560.099999999998], [2560.099999999998, 2574.3799999999983], [2574.3799999999983, 2585.7399999999984], [2585.7399999999984, 2598.0999999999985], [2598.0999999999985, 2610.9099999999985], [2610.9099999999985, 2623.2399999999984], [2623.2399999999984, 2655.3599999999983], [2655.3599999999983, 2667.539999999998], [2667.539999999998, 2684.119999999998], [2684.119999999998, 2695.9399999999982], [2695.9399999999982, 2717.6699999999983], [2717.6699999999983, 2729.229999999998], [2729.229999999998, 2742.2189999999982], [2742.2189999999982, 2756.5499999999984], [2756.5499999999984, 2769.4959999999983], [2769.4959999999983, 2781.1729999999984], [2781.1729999999984, 2791.7499999999986], [2791.7499999999986, 2803.509999999999], [2803.509999999999, 2817.559999999999], [2817.559999999999, 2828.989999999999], [2828.989999999999, 2842.945999999999], [2842.945999999999, 2853.129999999999], [2853.129999999999, 2863.325999999999], [2863.325999999999, 2873.5499999999993], [2873.5499999999993, 2885.468999999999], [2885.468999999999, 2912.689999999999], [2912.689999999999, 2925.213999999999], [2925.213999999999, 2937.509999999999], [2937.509999999999, 2948.849999999999], [2948.849999999999, 2959.049999999999], [2959.049999999999, 2970.5199999999986], [2970.5199999999986, 2986.0849999999987], [2986.0849999999987, 2997.839999999999], [2997.839999999999, 3012.069999999999], [3012.069999999999, 3023.069999999999], [3023.069999999999, 3034.2899999999986], [3034.2899999999986, 3044.9599999999987], [3044.9599999999987, 3063.4399999999987], [3063.4399999999987, 3076.589999999999], [3076.589999999999, 3087.389999999999], [3087.389999999999, 3098.419999999999], [3098.419999999999, 3108.5299999999993], [3108.5299999999993, 3119.439999999999], [3119.439999999999, 3133.2799999999993], [3133.2799999999993, 3150.0889999999995], [3150.0889999999995, 3164.0939999999996], [3164.0939999999996, 3175.4299999999994], [3175.4299999999994, 3192.9399999999996], [3192.9399999999996, 3209.6399999999994], [3209.6399999999994, 3226.859999999999], [3226.859999999999, 3237.979999999999], [3237.979999999999, 3252.039999999999], [3252.039999999999, 3262.899999999999], [3262.899999999999, 3282.119999999999], [3282.119999999999, 3296.959999999999], [3296.959999999999, 3308.506999999999], [3308.506999999999, 3319.7999999999993], [3319.7999999999993, 3330.669999999999], [3330.669999999999, 3341.5499999999993], [3341.5499999999993, 3353.9899999999993], [3353.9899999999993, 3364.9499999999994], [3364.9499999999994, 3376.5599999999995], [3376.5599999999995, 3388.0599999999995], [3388.0599999999995, 3398.7799999999993], [3398.7799999999993, 3410.859999999999], [3410.859999999999, 3428.479999999999], [3428.479999999999, 3438.599999999999], [3438.599999999999, 3448.619999999999], [3448.619999999999, 3462.939999999999], [3462.939999999999, 3473.8199999999993], [3473.8199999999993, 3484.9499999999994], [3484.9499999999994, 3494.9899999999993], [3494.9899999999993, 3506.1199999999994], [3506.1199999999994, 3517.3199999999993], [3517.3199999999993, 3528.919999999999], [3528.919999999999, 3539.5899999999992], [3539.5899999999992, 3549.5899999999992], [3549.5899999999992, 3560.629999999999], [3560.629999999999, 3573.6599999999994], [3573.6599999999994, 3586.3899999999994], [3586.3899999999994, 3598.3259999999996], [3598.3259999999996, 3609.4599999999996], [3609.4599999999996, 3633.0299999999997], [3633.0299999999997, 3651.1099999999997], [3651.1099999999997, 3668.3499999999995], [3668.3499999999995, 3679.7799999999993], [3679.7799999999993, 3690.6999999999994], [3690.6999999999994, 3705.5199999999995], [3705.5199999999995, 3719.9699999999993], [3719.9699999999993, 3733.1999999999994], [3733.1999999999994, 3746.3399999999992], [3746.3399999999992, 3762.484999999999], [3762.484999999999, 3777.8699999999994], [3777.8699999999994, 3791.2599999999993], [3791.2599999999993, 3802.9699999999993], [3802.9699999999993, 3815.2599999999993], [3815.2599999999993, 3827.8899999999994], [3827.8899999999994, 3841.1999999999994], [3841.1999999999994, 3854.1399999999994], [3854.1399999999994, 3864.3699999999994], [3864.3699999999994, 3875.1799999999994], [3875.1799999999994, 3889.2899999999995], [3889.2899999999995, 3900.5899999999997], [3900.5899999999997, 3925.5199999999995], [3925.5199999999995, 3937.2999999999997], [3937.2999999999997, 3947.9799999999996], [3947.9799999999996, 3960.2999999999997], [3960.2999999999997, 3974.2099999999996], [3974.2099999999996, 3992.8299999999995], [3992.8299999999995, 4006.9399999999996], [4006.9399999999996, 4019.1499999999996], [4019.1499999999996, 4029.74], [4029.74, 4049.265], [4049.265, 4061.39], [4061.39, 4073.96], [4073.96, 4086.899], [4086.899, 4099.8099999999995], [4099.8099999999995, 4113.379999999999], [4113.379999999999, 4128.449999999999], [4128.449999999999, 4142.239999999999], [4142.239999999999, 4158.286999999998], [4158.286999999998, 4168.949999999998], [4168.949999999998, 4180.898999999998], [4180.898999999998, 4192.579999999997], [4192.579999999997, 4203.839999999997], [4203.839999999997, 4233.639999999998], [4233.639999999998, 4246.239999999998], [4246.239999999998, 4257.849999999998], [4257.849999999998, 4276.609999999998], [4276.609999999998, 4293.343999999998], [4293.343999999998, 4305.759999999998], [4305.759999999998, 4316.449999999998], [4316.449999999998, 4326.819999999998], [4326.819999999998, 4337.979999999998], [4337.979999999998, 4350.530999999998], [4350.530999999998, 4362.249999999998], [4362.249999999998, 4372.249999999998], [4372.249999999998, 4383.229999999998], [4383.229999999998, 4394.281999999997], [4394.281999999997, 4404.299999999997], [4404.299999999997, 4416.839999999997], [4416.839999999997, 4430.799999999997], [4430.799999999997, 4441.439999999998], [4441.439999999998, 4452.2599999999975], [4452.2599999999975, 4462.799999999997], [4462.799999999997, 4473.669999999997], [4473.669999999997, 4484.2599999999975], [4484.2599999999975, 4496.899999999998], [4496.899999999998, 4507.709999999998], [4507.709999999998, 4518.899999999998], [4518.899999999998, 4529.343999999998], [4529.343999999998, 4542.079999999998], [4542.079999999998, 4569.409999999998], [4569.409999999998, 4590.029999999998], [4590.029999999998, 4601.2599999999975], [4601.2599999999975, 4611.449999999997], [4611.449999999997, 4622.529999999997], [4622.529999999997, 4634.289999999997], [4634.289999999997, 4646.819999999997], [4646.819999999997, 4658.359999999997], [4658.359999999997, 4679.319999999997], [4679.319999999997, 4692.639999999997], [4692.639999999997, 4710.718999999996], [4710.718999999996, 4722.509999999997], [4722.509999999997, 4734.649999999997], [4734.649999999997, 4749.399999999997], [4749.399999999997, 4759.829999999997], [4759.829999999997, 4771.389999999998], [4771.389999999998, 4783.249999999997], [4783.249999999997, 4795.249999999997], [4795.249999999997, 4806.959999999997], [4806.959999999997, 4820.779999999997], [4820.779999999997, 4835.615999999997], [4835.615999999997, 4849.718999999997], [4849.718999999997, 4861.204999999997], [4861.204999999997, 4872.069999999997], [4872.069999999997, 4883.031999999997], [4883.031999999997, 4890.919999999997]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [489, 598, 714, 1875, 2651, 3625, 3976, 4892]}
{"example_id": "mit126@@MIT2_003SCF11_lec11_300k", "text": ["PROFESSOR: Today we're going to talk all about moments  of inertia, and the last time we did [? muddy ?] cards, there ", "were a lot of questions.  The most common question-- where did all those terms come from?  And I'm going to do a brief kind of intro ", "around that so as to facilitate the rest of the discussions.  ", "Some basic assumptions here today.  We're going to consider bodies that ", "rotate about their center of mass, or fixed points. ", " That's the kind of problems we're doing.  And secondly-- all through this lecture ", "today, there's four or five significant assumptions  or conditions that are really important  to the whole discussion.  I'm going to really try to highlight them. ", "And starting with two here.  The other one is we're going to use reference frames attached ", "to the bodies.   That's why we did all that work in kinematics figuring out  how to do velocities of things that are in translating ", "and rotating references frame, it's  so that we can do these problems.   So this said, here's a inertial frame. ", " Here's some rigid body.  Here's a point on it, that's my origin. ", "And here is a set of coordinates attached to the rigid body--  an xyz system-- the body rotates and translates, ", "it goes with it.  And if we consider a little piece of this body,  a little part-- I'll call it little mass element ", "mi-- from here to here is some distance y with respect to A, ", "then the angular momentum of that little mass particle  is by definition of angular momentum Ri cross Pi. ", " And the P is always the linear momentum  defined in an inertial frame.  That's the definition of angular momentum. ", "", "So you have seen this little demo before.  So this is now my rigid body that I'm talking about.  In this case, the axis of rotation is this one. ", "And I'm just going to define my rigid body  as essentially rotating about this fixed point,  this is A now.  And my coordinate system is xyz, so the rotation is omega z. ", "And this rigid body-- this is massless,  consists of a single point mass.  So we've done this before, but we  tended to do this kind of problem ", "using polar coordinates.  And now I really wanted to strictly think in terms of XYZ.  The answers come out exactly the same.  Polar coordinates also moved.  You could do this in rhat, thetahat, z. ", "We're going to do it in xyz attached to the body.  ", "And y is going into the board, and we'll  have no values in the y direction for this problem.  Here's our little mass, we'll call it m1. ", "It's at a position out here x1, z1 are its coordinates,  and y is zero.  And we want to compute its angular momentum, ", "h1 with respect to A. That's our R1A cross P1 and 0. ", "And for this problem that's x1 in the i hat  plus z1 in the k hat, that's the R-- cross ", "P and P is mass times velocity, m1.  And the velocity is just omega cross R. ", "We've done this before.  So we need a length on this thing.  ", "We've done this enough times before I'm assuming  you can make this leap with me.  The momentum is into the board, in the y direction. ", "The linear momentum is R cross with that.  And that will give us-- let me write it-- omega z. ", "So that's the linear momentum.  It's in the j direction, its velocity is x1 omega z.  The radius times the rotation rate is the velocity, ", "the direction is that direction.  So this is your momentum.  You multiply out this cross product,  you get two terms-- m1 x1 squared omega z k, minus m1 x1 ", "z1 omega z i.   And these two terms then we would identify.  This is the angular momentum in the k direction, angular ", "momentum in the i direction.  There doesn't happen to be any in the z direction,  in general there could be.  But this is h for this particle, particle one.  ", "I want to particularly emphasize this one--  oops, this is-- excuse me-- z.  And this is the piece we call hx.  ", "So there's a complement of the angular momentum  that's in the z direction, there's  a component in the x direction.  ", "We know that if we compute-- just  to tie it back to previous work a little further-- d ", "by dt of h1A gives us the external torques  in the system, a vector of torques ", "when we compute that out.  I'm not going to calculate it, I don't need it  for the purposes of the rest of the discussion.  This one gives you omega z dot term.  This one gets two terms because you have ", "to take the derivative of i.  So you get three terms which are torque  in the x, torque in the y, torque in the z directions.  Two of them are static, because it's  trying to bend this thing back and out, and one of them, ", "the z direction one, is the one that makes it spin faster.   So we've seen that, that's a review.  And to make the leap from that to rigid bodies-- Capital ", "H, now, a collection of particles with respect  to its the origin attached to the rigid body ", "is going to be the summation over all  the little mass particles.   Their position vector crossed with the linear momentum of all ", "those little mass particles.  Sum all that out.  Because it's a rigid body, this is always  something of the form that looks like omega cross R,  m omega cross R. And I can then write this ", "as the summation of [? oper ?] i of the mi,  RiA cross omega with respect to 0, cross RiA. ", " That gives you the velocity, m gives you the linear momentum,  crossed with this one again makes it ", "into an angular momentum.  So the angular momentum of every particle-- the bits of this  come out looking like an R squared omega. ", "Or at least has dimensions of R squared omega.  These can be like x1 squared, but these can also  end up being terms like x1 z1, those cross product terms. ", "But in general, these things all add up.  And this is a vector, this is a vector,  so this is a vector-- these are all vectors, ", "the result's a vector.   And therefore we would break this down, this whole thing.  Once you write all that out and sum it all up, ", "you're going to get a piece of it  that we would say that is in the i hat direction  and we call that Hx.  Another piece that's in the j hat direction, which ", "we call Hy and Hz in the k hat.  That's just how that all shakes out.  In general you get three parts.  ", "Yeah?  AUDIENCE: Why do you have mass multiplied by displacement  and the momentum?  PROFESSOR: Why do we have the mass multiplied by a position ", "vector times the momentum?  Because that is the definition of angular momentum.  ", "It's R cross P, all right?  [INTERPOSING VOICES]  ", "PROFESSOR: Ah, I see what I've done.  Yeah you're right.  This m doesn't belong-- I got ahead of myself--  it doesn't belong here.  It pops out of this to here. ", "Thanks for catching that.  Absolutely right.  ", "So every term here is made up of things that  look like x1, z1, m1 omega x. ", "Or omega y, or omega z, because this is a vector,  and it can have three components-- a piece in the i,  a piece in the j, a piece in the k direction.  So there's a lot of possible terms, ", "and we're in the practice of writing this out.   This H vector can be written then ", "as a-- I'm going to run out of room here.  ", "So the Hx term-- the piece that comes out  with all little bits in the i direction--  when you just break it apart, we would write it Ixx omega ", "x, plus Ixy omega y, plus Ixz omega z. ", " All the i terms that float out of this,  we just collect them together-- all the ones that ", "are multiplied by omega x ends up being some terms that  look like sums of mi-- x, mi z squared terms, ", "and there's some y squared terms.  But we collect them all together and we  call this constant in front of it Ixx.  Just what floats out of this stuff.  We break it into three pieces, the part of the angular ", "momentum due to the rotation in the x,  the part due to the rotation in the y,  the part due to the rotation in the z.  And you do the same thing for Hy,  and you get in Iyz omega x plus an Iyy omega ", "y plus an Iyz omega z, and you're finally get and Hz term.  Izx omega x, Izy omega y, Izz omega z. ", " That's everything that falls out of just doing this calculation.  ", "And where in the habit of writing that in a matrix  notation as the product of this thing ", "called the inertia matrix.   And so forth, with this bottom term ", "being Izz multiplied by omega x, omega y, omega z.  You multiply that times the top row, you get Hx, middle row, ", "you get Hy, bottom row, you get the Hz.  So where this stuff comes from is just  from carrying out the summation over all the mass bits. ", "So it basically starts with the definition of angular momentum.  And this is just a convenient way to write it.   So for example, the Ixz term-- the one in the upper right ", "there that's part of Hx, the Ixz term--  is minus the summation of all the little mass bits ", "times their location xi zi.  And this, the xz, always matches xz.  And when you want to do this over a continuous object, ", "you integrate that.  And for Izz, this is the summation over i, ", "all the bits of mi xi squared plus yi squared. ", "So in general this, by summations, that's  where these terms come from.  They just come.  They've started with this calculation.  ", "And in general, from that calculation.   So for our one particle system, for this thing.  So where this is x and z, it's one single particle. ", "So for our one particle system.  ", "And there's no y1 in here because it's  a zero in this problem.  The coordinate of that little mass particle is x1, 0, y1. ", "So in general, this is x1 squared plus yi squared,  but that's 0.  So it's just mx1 squared.  ", "So that's where all these things come from.  Now let's kind of look at-- the units of these things  are always mass times length squared. ", "The diagonal terms the Ixx, Iyy, Izz terms will all  be of the form of something squared. ", "And what it is is it's always just the distance  of the mass particles from the axis of rotation, call that r. ", "It's just a summation of this perpendicular distance  from the axis of rotation.  For Izz, the axis of rotation is z.  And this piece here is always the distance ", "squared that the mass particle is from the axis of rotation.  Now that's the set up for today. ", "And when we want to get onto the real meat of the discussion,  talking about things like what principal axes are  and so forth.  ", "Now we're going to move on to the part of this conversation  about principal axes.  ", "So a really important point.   For every rigid body, even weird ones. ", "For every rigid body, there is a coordinate system  that you can attach to this body, an xyz set of orthogonal  coordinates that you can fix in this body such ", "that you can make this inertia matrix be diagonal.   Any weird body at all, there is a set ", "of coordinates that if you use that set,  this matrix turns out to be diagonal.  And what that means in dynamics terms is if you then ", "rotate the object about one of those axes,  it will be dynamically balanced.  ", "And so when you rotate a shaft-- this is an object for which I  know-- it's a circular uniform disk, ", "one of the axes through the center is a principal axis.  And if I rotate the object about that-- this one the hole's kind  of out around so it wobbles a bit  but if I rotate it about that it will ", "make no torques about this axis that are because it's  unbalanced.  It's essentially the dynamic meaning of principal axis-- ", "an axis about which you can rotate the thing and it'll just  be smooth, no away-from-the-axis torques.  So that's so those are pretty important. ", "We want to know what those are for rigid bodies  and how to find them.  So there's a mathematical way to find them  and you can just read about in the textbook. ", "It's sort of a-- I'm trying to think of the mathematical term.  I forgot it. ", "But what I want to teach you today  is for many, many objects, if you just  look at their symmetries, you can figure out by common sense  where their principal axes are.  So that's what we're going to do next. ", "", "We started off saying that we're talking about bodies that  are either rotating about their centers of mass  or about some other fixed point.  So we're going to define our principal axes ", "assuming we are rotating about the center of mass.  There is an easy method known as the parallel axis theorem  to get to any other point. ", "So why do we care about doing it about the center of mass?   Why is that useful to know about the properties ", "around the center for dynamics purposes?  What kind of dynamics problems do you  care about the center of mass?  Rotation about the center of mass.  AUDIENCE: [INAUDIBLE].  ", "PROFESSOR: So when I throw this thing in the air, it's  rotating, it's translating, and when it rotates,  what's it's rotating about?  AUDIENCE: Center of mass.  PROFESSOR: Center of mass.  So there's just lots and lots of problem ", "in which in fact the rotation is going to occur around  the center of mass.  Any time the thing is off there and there's nothing  constraining its rotational motion, ", "the rotation will be about the center of mass.  So that's a good enough reason, and a very practical reason  then for computing these things or knowing ", "how to find these things about the center of mass.  All right so we're now going to do principal axes,  and we're going to teach you some symmetry rules. ", " Maybe first a little common sense.  This thing-- is this a principal axis? ", "No way, right?  And we know for a fact that it has off-diagonal terms  because I've defined my coordinates as being  an x, y, z, like this, and this is often at some strange angle. ", "So as a practical matter, how could I  alter this object so that this is a principal axis?  Essentially, how would you balance this? ", "AUDIENCE: [INAUDIBLE].   PROFESSOR: Take the mass off, fix it.  [LAUGHTER]  Or? ", "All right.  Where do I put it?  Down here?  Ah, you want it like this.  ", "This is steel going into aluminum,  I have to be careful that I don't strip the threads.  ", "There we go.   And now test one, this is axis of rotation,  is it dynamically in balance? ", "Smooth as silk.  This now is a principal axis.  Its mass distribution is symmetric.  ", "Where is there a plane of symmetry for this problem,  for this object?  That's what we're going to talk about now, planes of symmetry  and axis of symmetry. ", "Ah, you're saying one like back?  You're right, that's a plane of symmetry.  Is there another one for this one?   Like this.  So there's two planes of symmetry. ", "So let's say come up with some symmetry rules.   So this first one is there exists-- ", "by this I mean diagonal, it's a diagonal matrix.  You can find a set of orthogonal axes  such that this matrix is diagonal.  That's what we mean when we go to find principal axes. ", " And pick a board here-- rules.  ", "And we're going to have three of them,  so just leave room on your paper.  We're going to build these up.  And I'm going to talk about it, and then you add another one  and so forth.  ", "So rule one.   AUDIENCE: [INAUDIBLE] the inertia matrix [INAUDIBLE]. ", "PROFESSOR: What is the inertia matrix--  AUDIENCE: No, I mean the second one.  PROFESSOR: This thing with the diagonals?  This is going to have all the off-diagonal terms are zeroes.  ", "That's what I mean.  It's a diagonal matrix, the mass moments of inertia and products  of inertia-- you only have Ixx, Iyy, Izz if you properly ", "pick this set of orthogonal coordinates attached  to the body-- if you pick them right.  What it means if then you spin that object about one  of those axes, it's in balance. ", "So rule one, if there it is an axis of symmetry-- Remember ", "the caveat here is we're talking about uniform density objects  or at least objects in which the density is symmetrically  distributed.  ", "So the geometric symmetry and mass symmetry  mean the same thing.  What does that mean?  So axis of symmetry.  ", "Does this have an axis of symmetry?   Where?  AUDIENCE: It has multiple ones down the middle ", "and it's also symmetric [INAUDIBLE].  PROFESSOR: That's a plane of symmetry,  the [? other ones you think, ?] axis of symmetry.  AUDIENCE: Well I mean the line right through it.  PROFESSOR: Which way?  AUDIENCE: Well any. ", "PROFESSOR: Nope.  AUDIENCE: Perpendicular to it.  PROFESSOR: Axis of symmetry means  that there is a mirror image from that point--  that point mirror image over here is always identical. ", "But you think any from angle, it doesn't matter where you start,  it's reflected through the axis.  So things that are circularly shaped  tend to have axes of symmetry. ", "So this has an axis of symmetry.  Everything is reflected exactly just across the axes,  you don't have to pick any particular line. ", "So what it's saying if it's an axis of symmetry,  then it is a principal axis, and rotation about that  axis-- the things will be nice perfectly in balance. ", "If you go through all the hairy details of calculating  the hard way, the Ixx, Iyy, et cetera terms--  all of the off diagonal terms will come out zero. ", "And the reason is that for every mass particle over here,  let's say there's a little bit right here in the corner,  there is one exactly like it on the other side. ", "So if this one we're trying to bend this thing up as it  spins around, this one over here is telling it to come back.  Yeah?  AUDIENCE: How come this is not an axis, if you hold it-- ", "yeah--  [INTERPOSING VOICES]  PROFESSOR: So if you do this.  So I think it's kind of just the definition we're getting to  of an axis of symmetry.  Because in simple terms, what the object looks ", "like this way is it's a narrow object,  it is in fact a mirror image reflection.  But it looks different when you go to this angle.  And it looks different when you go to this angle ", "so it's not an axis of symmetry, that's a plane of symmetry.  We're going talk about that next.  So axes of symmetry-- the thing essentially  looks the same at all orientations about that axis. ", "But it is certainly dynamically balanced.  Every mass bit here balances one over there, it doesn't wobble.  All right.  So that's for sure true. ", "Now keep in mind that exists a set of orthogonal axes.  So that means once you find one, you ", "know that the other two are perpendicular to it  and perpendicular to each other.  So for this system, when I got the x and y here,  there has to be an x and y perpendicular ", "that that are the other two.  And because it's actually symmetric,  it doesn't matter where you out them, you just  could say it's these two, these two, it doesn't matter. ", "You just have to decide where you're  going to put them on the object, they're all the same.  So for this axis symmetry, they're just two more. ", "They're going to be in the body perpendicular to the first.  Now we're going to do about g so the book uses g  to talk about the center of mass, so I'll use g. ", "So the center of mass of this thing  is right in the middle of this and in the middle here.  So it's inside this body.  Right in the dead center of it. ", "So the three principal axes are an orthogonal set, one of which  goes through it and the other two  are embedded in it right angles.  So this is the simplest rule.  If you have an axis of symmetry, you know right way just ", "about everything you need to know about the principal axes  of the body.  ", "Shoot.  AUDIENCE: It seems like then there would only  be axis of symmetry in objects that are either round  or spherical, is that correct?  PROFESSOR: Pretty much. ", "AUDIENCE: So it's a very limited special case.  PROFESSOR: Yeah but there sure appear an awful lot in machines  because they have this beautiful property of just being balanced  in all directions. ", "So everything rotating in the world  tends to have an almost perfect axial symmetry.  ", "Just thinking about order here.  Let's do this and then I'm going to go do a couple of examples.  The second rule-- if you have one plane of symmetry, ", "a plane of symmetry.  So this is kind of the opposite direction,  in this you have the least information.  Here's an object, does it have a plane of symmetry?  AUDIENCE: Yes. ", "PROFESSOR: Where?  AUDIENCE: Straight through [INAUDIBLE].  PROFESSOR: Show me.  That cut.  All right.  So I've got these little dotted marks on this thing.  So if I slice through that, I create ", "two pieces that are identical.  So that's a plane of symmetry.  There is image match across that plane at every point.  So if I have a plane of symmetry, ", "what do you think you can say about a principal axis?  One of the principal axis?  AUDIENCE: It'll be on that plane.  PROFESSOR: It'll be on that plane.  That turns out to be true, but that's the second point  I want to make. ", "AUDIENCE: It might be perpendicular.  PROFESSOR: She says there might be one perpendicular to it.  And that's the one I was searching for,  you're right too.  There's going to be a principal axis ", "that's perpendicular to that plane of symmetry,  and since we want to define our moments of inertia  for this to get started with with respect  to g, where will it pass through?  AUDIENCE: Through g.  PROFESSOR: G, kind of by definition. ", "So we're going to have it pass through g.  If there's a plane of symmetry, then there ", "is a principal axis perpendicular to it. ", " And we'll0 define it, for the purposes of our discussion, ", "we'll just let it pass through g.   It doesn't have to, but that's how we're  going about this discussion.  Let it pass through the center of mass, this point we call g. ", "All right, so that means that there's  a center of mass in this thing.  And I'm just guessing roughly where it is. ", "But in fact if I hung this thing up here like this,  and let gravity find it's natural hanging angle,  and I drew a plumb line down here, ", "just drew a line that the string would take with a plumb bob.  Then I went to some other point and did it again  and hung a plumb bob on it drew the line-- where they intersect ", "is the center of mass.  And then you know since it's got symmetry this way  that's in the middle.  So I guesses that that's about where it is.  And there then is a principal axis ", "of this object that's perpendicular to it,  passing through the plane-- perpendicular to the plane.  And that means now there's two more.  But this gets a little more difficult, and I have no clue. ", "There are two more, because the principal axes always  come in an orthogonal set.  So now that I know one, I know that there's  two more somewhere around oriented ", "this way, someplace in this plane.  Maybe one like that, maybe one like this,  such that if you spun it about one of those axes,  it'd be in balance.  You can see that gets a little messy, ", "I can't guess where it is.  And so there are ways to find it, one of them  would be doing an experiment, seeing which  axis it spins nicely around.  So that's the second rule.  ", "But even just with that one plane of symmetry,  you get some pretty good insight.  Now what if there are two planes of symmetry? ", "Yeah?  AUDIENCE: You said that the principal axis does not  have to pass through the center of mass?  PROFESSOR: No, I'm saying it doesn't have to pass ", "through the center of mass.  The question is?  AUDIENCE: How could it not because it  becomes stable [INAUDIBLE].  PROFESSOR: So she's saying it'd be unstable if it's not ", "passing through there.  Like if I put an axle through this wheel,  and I spun it about some point out here,  you don't know because I had that shaker in here,  that thing is going to shake like crazy. ", "But does it produce unbalanced torques  about my rotation point?   It produces centrifugal force that you'll feel like crazy, ", "but does it produce a torque that you'd  have to resist with some static torque?  What do you think?  ", "It won't.  So there's a nuance to this unbalanced thing,  and I was going to get to it, probably next lecture,  but that is the when we say an object is dynamically balanced, ", "we mean that it doesn't have any unbalanced torques.  If it is statically balanced, it's ", "rotating about its center of mass.  But you can be statically unbalanced  and let it go around this axis, but it'll produce no torques. ", "It's still dynamically balanced.  And the angular momentum of an object which is rotating-- ", "And this we know has a principal axis here,  I just moved it off to the side.  It's rotating about this.  It is dynamically balanced, and if you computed ", "about this point now the Ixy, Ixz off-diagonal entries  in that moment of inertia matrix, they're all 0.  You'd get no unbalanced torques, but you ", "do have an unbalanced centrifugal force  as this thing goes around.  And we'll talk a bit more about that.  AUDIENCE: Is that sort of analogous  to the homework problem we had a few weeks back ", "with the motorcycle wheel and you just had mass on one side  and not on the other?  PROFESSOR: Right.  So she's asking about the motorcycle wheel problem  where we had that little mass that got there.  I think in the next lecture I'm going to come back ", "to that problem just so we could tie  a bow around this whole thing and understand why it's  unbalanced, how you can balance it,  and the difference between static unbalance ", "and dynamic unbalance.  But today, we're talking about symmetry rules.   Finally, so I was saying, let's talk about something  that has two planes of symmetry. ", "This actually has three planes of symmetry,  but we'll settle for two.   Pick a plane of symmetry for this object. ", "If I pick-- OK, so she picked the one-- slice it this way.  What about the second?   Like that. ", "Then a third, right?  There's even one like that.  So this has three planes of symmetry.  But if you have two planes of symmetry that intersect, ", "that are orthogonal to one another,  what do you think you can say about that line  of intersection?  AUDIENCE: It's the principal axis. ", "PROFESSOR: It sure is.  And it's probably right through g.  So if you have two planes of symmetry-- ", "Now make them orthogonal.  You can make all sorts of symmetry rules,  and I'm just picking these three to help you out.  This just to help you see principal axes.  If you have two orthogonal planes ", "of symmetry their intersection-- and once you know that, ", "then you go back to rule two.  And it tells you everything else you need to know.  Because you have one plane of symmetry,  you know there is a principal axis perpendicular to it. ", "Well if you have two planes of symmetry, the rule still holds.  There's one perpendicular to each one.  The intersection, let's say, of this plane of symmetry  and this plane of symmetry is a line ", "which goes right through the center of this thing that way.  So there's a principal axis this way.  But since there is a plane of symmetry here,  there must also be a principal axis perpendicular to it. ", "So sure enough, three principal axes for this thing  are through the center, perpendicular this way,  perpendicular that way. ", "You instantly know.  Two planes of symmetry-- you instantly  know where the three orthogonal principal axes are that past  through the center of mass.  Yeah? ", "[?  AUDIENCE: Does this all apply ?] just like a constant mass  throughout?  PROFESSOR: Not constant, symmetrically  distributed density. ", "Right so I'm choosing my words carefully so  that I succeed in the following--  that the planes defining mass symmetry  will be the same as the planes defining geometric similarity. ", "But you actually don't have to have a constant density,  it just has to be distributed so that what I just said is true.  So that the geometric symmetries are  the same as the mass distribution symmetries. ", "All right so those are my three rules of symmetry.  You could make up others.  Those are the three that I've made up  to help you see objects.  ", "That object, it's a circular disk  put on top of another object such that their centers ", "of mass line up.  Where are the principal axes of this object using those rules?  ", "If you think you know one, tell me.   AUDIENCE: Through the middle. ", "PROFESSOR: Through the middle of both of them.  Probably, good guess.  How about another one?   Where does this thing have planes of symmetry? ", "AUDIENCE: So there's a plane of symmetry if you cut it in half.  [INAUDIBLE] cut it in half, [INAUDIBLE].  PROFESSOR: OK, and?  AUDIENCE: The other way. ", "PROFESSOR: One like that, we've got all three.  And if we're going to want it to go through the center of mass,  then we're going to have to find where the center of mass  is this way, but it's about there. ", "So just using the symmetry ideas,  you can right away figure out where these principal axes be.  And that means from a dynamic point of view,  if you spin it about one of those axes, ", "it's nice and dynamically balanced.  If you spin it off in some other weird direction  is it necessarily dynamically balanced  about that axis of spin? ", " So let me restate that question.  ", "We know that this thing has an axis of symmetry principal  axis through the center, and another one this way,  and another one this way. ", "And if I spin it about any one of those,  it's dynamically balanced.  But if I pick some other strange direction for the spin,  and I spin it about that axis, will I feel unbalanced torques ", "on this axle, on the bearings having  to hold this thing in place?  Yeah, you better believe it, this thing wobbles like crazy.  So the principal axes are a property of the object, ", "they're not a property of the angular momentum.  The angular momentum comes then from multiplying  the mass moment of inertia that you've ", "determined times the actual rotation vector.  And you'll find out then you get angular components of angular  momentum that are not in the direction of spin, ", "and as soon as that happens, you have unbalanced terms.   I've got to get on to something else to help you do homework. ", "", "So for my disk, with z coming out of the board, the Izz--  so let's say here's x, y, z coming out of the board-- Izz, ", "the mass moment of inertia about this z axis  is, from the basic definition, the summation of the mis, ", "xi squared plus yi squared.  It's just that for every little mass particle  it's the radius squared away from the center of rotation. ", "That's what the x squared plus y squared is.  And we can turn this into an integral.  It's the integral of r squared, that distance,  times the little mass bit that's there. ", "And that's the same.  If you wanted to do the integral as x squared plus y squared dm.  ", "But to do this integral for a nice circular, symmetric disk,  you can pick a little mass bit that has thickness dr and width ", "rd theta.  And this angle here is d theta.   And that's a little bit of area.  That's a little dA which has area r dr d theta. ", " It's just length times width.  When it's small enough, it's a little rectangle,  and it has that area. ", "And it has a volume, dV-- the volume of that thing  is just the area times the thickness of it.  So here's our disk here, but it has some thickness, ", "and I'll call that h.  So the volume is just h r dr d theta. ", "And the mass, dm, is a density times dV.  ", "So I want to integrate this, all I  have to integrate the integral then of r  squared dm is the integral from 0 to 2pi, 0 to r of rho dV. ", "Rho h-- oh, and I need an r squared-- r squared  dV is rho h r dr d theta. ", "So this is 1802 integrals, right?  So is any of this a function of theta?  No, so it's a trivial integral, you  integrate that over theta, you just get theta, ", "evaluate it 0 to 2pi.  So this is 2pi rho h, can all come to the outside, integral 0  to R of r cubed dr. And that ends up-- ", "the r cubed goes to r to the 4th over 4.  And the final result of this one is 2pi r to the 4th over 4 ", "rho h, and when new account for h times pi r squared  is the volume times rho is the mass.  This all works out to be m r squared over 2. ", "So Izz-- so I needed to do this once for you.  For simple things integrate, Izz in this case,  you just integrate it out, account ", "for all little mass bits, that is the mass moment of inertia  with respect to the axis passing through the center like this.  Pardon? ", "AUDIENCE: [INAUDIBLE]  PROFESSOR: It's this, this is what I'm talking about.  ", "Moving on to the last bit.  ", "So we need to know how to be able rotate things  about places other than their centers of mass.  So this is a stick, I can rotate about the center of mass, ", "but it's more interesting if I rotate it  about some other point.  It makes it a pendulum when I do it around here.  So I need to be able to calculate  mass moments of inertia about a point that's  not through the center of mass. ", "I know you've seen this before in [? 8.01, ?]  so this is going to be a quick reminder.   But I'll show you where it comes from. ", "So here's my stick.  ", "And it has a center of mass, and that's where G is located here.  It has a total length l. ", " I'm going to give it a thickness b, a width a. ", "So it's a stick.  a wide, b thick, l long.  Uniform has a center gravity right in the middle. ", "And I'm going to attach to this stick--  and this point is kind of hard to draw.  This point is at the center of the stick, OK? ", "I'm going to put my coordinate system attached  at the center of gravity, center of mass,  and I'm going to make it the-- that's x prime downward, ", "z prime, and y prime is then going off that way.  So this is a body set of coordinates  at the center of mass.  x prime, y prime, z prime. ", "And x happens to be down.  And I want to calculate my mass moment of inertia  with respect to a point up here that is d, this distance. ", "I've moved up the x-axis an amount d.  I'm going to set a new coordinate system up here.  So if this was z prime, my new z is here. ", "It's getting a little messy.  Maybe I'll do just a face view.   If my previously y prime and x prime ", "were like that, z coming out of the board,  now I have a new system that is y  and x like this, z still coming out of the board.  ", "Now the coordinate.   So how do I calculate mass moment of inertia?  Well I want Izz. ", " I probably know Iz'z'.  Iz'z' is the mass moment of inertia about this point. ", "I know it's a principal axis from all the things we  just-- that square block is the same as this.  That's a principal axis in the z prime direction.  I know the Izz' with respect to G, ", "I want to know what with respect to this point.  So well Izz, which is my new location  up here, and we'll call it A. So Izz here with respect to A ", "is the integral of r squared dm.  We've got to do the same integral now.   But that's the integral of x squared plus y squared dm. ", " Now I can look at this and I can say oh, well, these  are d-- this is separated by d.  I only moved it in the x. ", "The ys haven't moved and the zs didn't change.  I just moved my point only in the x direction.  So I can now say that in terms of my new coordinate, ", "it's the same as x prime plus d, the distance from here  to a point down her, some arbitrary mass point ", "xi is going to be xi' plus d.  So to do this integral in the new coordinates, ", "this is going to be the integral of x prime plus d squared  plus y. ", "Now y prime equals y and z prime equals z.  Those haven't changed.  I didn't move my new coordinate system ", "in the y direction or the z direction.  So the coordinate in the new system in y  is the same as before.  So this is just y prime squared.  And this whole thing times d, integrated times ", "every little mass bit.  If I square this, I get x prime squared, 2x'd, d squared,  plus y squared.  So this integral, Izz with respect ", "to A, when you rearrange it, looks  like x prime squared plus y prime squared dm ", "and the integral of a sum is the sum of the integrals.  So I break it into bits here, there's  a d squared, which is a constant, dm.  And then the last term is plus 2d and it's x prime dm. ", " Just multiply this out, rewrite it, break it apart.   Well let's do this one. ", "Integral of x prime squared plus y prime squared dm.  That's something that we already have a name for.  This is IGzz.  ", "It's the original mass moment of inertia  with respect to the original coordinate system at G  in the z direction.  So it's [? IzzG, ?] we already know that. ", "That's given for the object.  Plus, this is the integral of dm over the whole extent  of the object?  Just the mass of the object.  ", "This integral, this is the integral  in terms of the x-coordinate.  And every mass bit from here, if I go out here and find one, ", "there's an equal and opposite one up here.  This is the definition of the center of mass.  This integral, if I'm at the center of mass  integrating out from it, this is zero because of the definition ", "the center of mass.  And I've just proven the parallel axis theorem.  Izz about this new point is I about G plus Md Squared, ", "where d squared is the distance I've  moved this z-axis to a new place parallel to it.  ", "So Izz with respect to G, the original mass moment  of inertia for Izz is m L squared plus a squared over 12. ", " And Ixx m L squared plus b squared over 12. ", "And Izz-- oh, we already know that one.  ", "Wait a minute.  I haven't told you what that is.  That's Izz, Ixx, Iyy.  Just a little messy here.  Iyy for this problem is-- I have made a mistake. ", "Ixx is a squared plus b squared.  Iyy is m L squared plus b squared. ", "So those are the three-- all with respect  to G-- for this stick stick.  And I'm going to--   AUDIENCE: [INAUDIBLE]? ", "Is that also divided by 12?  PROFESSOR: Yeah.   That kind of sets us up where I can pick up next time. ", "So let's finish by asking ourselves the question, what  do we think about-- if I've moved to this new put ", "new position, and I'm not rotating about the center,  is this new axis-- this one around the center before, ", "that one we know is a principal axis.  If I rotate about this new place which  I've defined the mass moment of inertia about that place? ", "Is this a principal axis?  AUDIENCE: Yes.  AUDIENCE: Yes.  PROFESSOR: How many think yes?  How many think no?  OK, so lots of people not sure. ", "So my dynamic definition of principal axis  is if you can rotate the object about that axis  and produce no unbalanced torques, it's a principal axis. ", "And I can do that and this thing will just spin all day long.  Now there is a force, you could think of a fictitious force.  There's a center of mass out here.  As it spins around, there's a centripetal acceleration ", "making it go in the circle, that means that fictitious force is  like there is a centrifugal force pulling out on it.  Do I feel that?  Do I have to this resist that force ", "as it goes round and round?  Yes.  So that is an unbalance of a kind  we know as a static imbalance, but it doesn't produce torques  about my axis right lined up on the center. ", "AUDIENCE: Doesn't gravity pull on the center of mass  [INAUDIBLE].  PROFESSOR: Sure, gravity does, but that's now  a different problem.  That's what makes this thing act like an oscillator. ", "The torques of the kind I'm talking about  is if I compute the angular momentum of this thing  and compute dh/dt-- the time rate of change of the angular ", "momentum is a torque on the system, right?  I will get the term that makes it spin faster,  and I will get, if they exist, terms  that make it want to bend this way or bend back. ", "It only happens if-- if I hold this thing over here, and spin  it, get it spinning, and I compute the angle momentum ", "with respect to this point, will I get torques?  Yeah, but that's not how I-- that's a different problem.  The IG is as if I were computing the angular momentum. ", "Remember I started defining mass moment of inertia matrix  based on an angular momentum computation at G.  So it's right there in the center of this object, ", "there's no moment arm that is causing  torques that's trying to twist this thing about that point.  So the answer to the question is this is a principal axis. ", "Yeah?  AUDIENCE: So if you take the derivative of the angular  momentum would you get torques that are not in that direction?  PROFESSOR: If you get torques that aren't in that direction, ", "either you made a mistake doing the math,  or you were in error in identifying  the mass moment of inertia matrix to begin with.  Because if you get torques, there ", "must be non-zero off-diagonal terms and in mass moment  of inertia matrix.  They are what account for the torques.  So by this parallel axis theorem, any other axis ", "you go to-- if you started at a principal axis,  any other axis you create is also a principal axis.  That's the movement of just one axis. ", "If you do two, if you move this way and this way,  all bets are off.  You get a difference answer.  And if you're interested in that more complicated problem,  read that Williams thing because he ", "does the complete parallel axis, parallel planes  and comes up with a super compact little way  of calculating them.  See you on Thursday. "], "vid_duration": [10.76, 11.28, 16.02, 15.13, 17.266, 12.154, 10.02, 17.405, 11.525, 16.94, 10.33, 11.51, 12.68, 10.09, 14.65, 10.905, 10.645, 15.02, 18.499, 10.881, 10.76, 27.98, 10.7, 11.56, 12.795, 11.575, 10.9, 13.43, 13.1, 15.75, 11.86, 20.29, 11.684, 13.276, 10.68, 11.3, 11.369, 11.651, 11.54, 12.41, 31.61, 11.94, 15.384, 13.036, 18.935, 11.495, 16.68, 14.31, 11.8, 12.24, 12.71, 13.29, 12.42, 10.28, 11.86, 11.37, 17.74, 14.89, 14.88, 15.06, 18.97, 16.312, 11.193, 11.335, 13.51, 13.46, 18.9, 21.005, 14.955, 12.98, 10.37, 14.07, 13.46, 22.77, 12.309, 11.731, 12.83, 11.51, 12.11, 15.67, 29.61, 11.1, 16.81, 13.82, 11.15, 12.17, 11.83, 10.86, 23.49, 19.28, 14.02, 12.37, 11.2, 13.23, 11.22, 12.1, 14.49, 10.14, 11.2, 10.84, 10.06, 10.345, 10.375, 17.06, 11.45, 10.28, 12.62, 10.365, 11.755, 11.53, 13.8, 12.61, 10.96, 10.849, 10.077, 12.351, 13.053, 10.67, 11.95, 10.64, 12.22, 40.64, 11.255, 23.015, 21.98, 12.286, 12.484, 10.85, 12.4, 40.52, 10.12, 12.24, 11.161, 10.4, 11.539, 11.22, 10.33, 10.35, 10.16, 11.53, 12.163, 16.197, 10.53, 14.03, 10.94, 10.9, 11.92, 10.99, 10.099, 11.382, 12.089, 12.11, 15.58, 10.41, 12.33, 12.43, 24.94, 10.28, 12.87, 13.03, 10.918, 10.732, 11.91, 14.62, 14.29, 10.21, 16.69, 10.27, 11.11, 10.04, 12.61, 13.79, 11.79, 11.02, 12.47, 10.924, 10.862, 11.028, 11.886, 12.25, 10.26, 12.11, 11.76, 10.68, 12.85, 13.01, 13.2, 10.392, 11.478, 10.66, 10.72, 10.81, 10.357, 12.453, 10.8, 21.18, 15.5, 33.06, 11.03, 10.83, 11.44, 10.2, 10.219, 11.381, 14.329, 12.048, 13.703, 11.2, 13.5, 10.744, 13.606, 10.08, 10.11, 10.49, 10.79, 14.87, 10.27, 13.29, 15.85, 10.12, 12.07, 10.015, 41.495, 14.95, 10.39, 13.72, 12.78, 11.31, 17.626, 14.467, 11.307, 14.22, 10.0, 10.83, 19.37, 14.13, 11.42, 17.3, 14.94, 14.77, 12.39, 11.012, 15.948, 10.4, 12.2, 11.52, 12.36, 10.89, 10.175, 14.065, 11.5, 12.42, 11.92, 11.64, 14.35, 11.96, 15.39, 13.95, 15.32, 10.81, 11.235, 15.985, 16.815, 11.225, 12.08, 11.93, 10.64, 10.17, 12.16, 13.19, 12.96, 11.91, 18.472, 10.638, 14.75, 12.17, 13.51, 13.89, 11.68, 13.85, 68.3, 20.59, 18.94, 12.41, 24.01, 11.67, 10.354, 14.176, 12.58, 12.23, 10.65, 13.76, 13.87, 13.329, 10.567, 16.942, 11.122, 10.35, 13.05, 11.15, 15.778, 10.46, 10.924, 12.498, 10.98, 11.99, 11.45, 10.38, 20.33], "stet": [[0, 10.76], [10.76, 22.04], [22.04, 38.06], [38.06, 53.190000000000005], [53.190000000000005, 70.456], [70.456, 82.61], [82.61, 92.63], [92.63, 110.035], [110.035, 121.56], [121.56, 138.5], [138.5, 148.83], [148.83, 160.34], [160.34, 173.02], [173.02, 183.11], [183.11, 197.76000000000002], [197.76000000000002, 208.66500000000002], [208.66500000000002, 219.31000000000003], [219.31000000000003, 234.33000000000004], [234.33000000000004, 252.82900000000004], [252.82900000000004, 263.71000000000004], [263.71000000000004, 274.47], [274.47, 302.45000000000005], [302.45000000000005, 313.15000000000003], [313.15000000000003, 324.71000000000004], [324.71000000000004, 337.50500000000005], [337.50500000000005, 349.08000000000004], [349.08000000000004, 359.98], [359.98, 373.41], [373.41, 386.51000000000005], [386.51000000000005, 402.26000000000005], [402.26000000000005, 414.12000000000006], [414.12000000000006, 434.4100000000001], [434.4100000000001, 446.0940000000001], [446.0940000000001, 459.3700000000001], [459.3700000000001, 470.0500000000001], [470.0500000000001, 481.35000000000014], [481.35000000000014, 492.71900000000016], [492.71900000000016, 504.3700000000002], [504.3700000000002, 515.9100000000002], [515.9100000000002, 528.3200000000002], [528.3200000000002, 559.9300000000002], [559.9300000000002, 571.8700000000002], [571.8700000000002, 587.2540000000002], [587.2540000000002, 600.2900000000002], [600.2900000000002, 619.2250000000001], [619.2250000000001, 630.7200000000001], [630.7200000000001, 647.4000000000001], [647.4000000000001, 661.71], [661.71, 673.51], [673.51, 685.75], [685.75, 698.46], [698.46, 711.75], [711.75, 724.17], [724.17, 734.4499999999999], [734.4499999999999, 746.31], [746.31, 757.68], [757.68, 775.42], [775.42, 790.31], [790.31, 805.1899999999999], [805.1899999999999, 820.2499999999999], [820.2499999999999, 839.2199999999999], [839.2199999999999, 855.5319999999999], [855.5319999999999, 866.7249999999999], [866.7249999999999, 878.06], [878.06, 891.5699999999999], [891.5699999999999, 905.03], [905.03, 923.93], [923.93, 944.935], [944.935, 959.89], [959.89, 972.87], [972.87, 983.24], [983.24, 997.3100000000001], [997.3100000000001, 1010.7700000000001], [1010.7700000000001, 1033.5400000000002], [1033.5400000000002, 1045.8490000000002], [1045.8490000000002, 1057.5800000000002], [1057.5800000000002, 1070.41], [1070.41, 1081.92], [1081.92, 1094.03], [1094.03, 1109.7], [1109.7, 1139.31], [1139.31, 1150.4099999999999], [1150.4099999999999, 1167.2199999999998], [1167.2199999999998, 1181.0399999999997], [1181.0399999999997, 1192.1899999999998], [1192.1899999999998, 1204.36], [1204.36, 1216.1899999999998], [1216.1899999999998, 1227.0499999999997], [1227.0499999999997, 1250.5399999999997], [1250.5399999999997, 1269.8199999999997], [1269.8199999999997, 1283.8399999999997], [1283.8399999999997, 1296.2099999999996], [1296.2099999999996, 1307.4099999999996], [1307.4099999999996, 1320.6399999999996], [1320.6399999999996, 1331.8599999999997], [1331.8599999999997, 1343.9599999999996], [1343.9599999999996, 1358.4499999999996], [1358.4499999999996, 1368.5899999999997], [1368.5899999999997, 1379.7899999999997], [1379.7899999999997, 1390.6299999999997], [1390.6299999999997, 1400.6899999999996], [1400.6899999999996, 1411.0349999999996], [1411.0349999999996, 1421.4099999999996], [1421.4099999999996, 1438.4699999999996], [1438.4699999999996, 1449.9199999999996], [1449.9199999999996, 1460.1999999999996], [1460.1999999999996, 1472.8199999999995], [1472.8199999999995, 1483.1849999999995], [1483.1849999999995, 1494.9399999999996], [1494.9399999999996, 1506.4699999999996], [1506.4699999999996, 1520.2699999999995], [1520.2699999999995, 1532.8799999999994], [1532.8799999999994, 1543.8399999999995], [1543.8399999999995, 1554.6889999999994], [1554.6889999999994, 1564.7659999999994], [1564.7659999999994, 1577.1169999999995], [1577.1169999999995, 1590.1699999999996], [1590.1699999999996, 1600.8399999999997], [1600.8399999999997, 1612.7899999999997], [1612.7899999999997, 1623.4299999999998], [1623.4299999999998, 1635.6499999999999], [1635.6499999999999, 1676.29], [1676.29, 1687.545], [1687.545, 1710.5600000000002], [1710.5600000000002, 1732.5400000000002], [1732.5400000000002, 1744.8260000000002], [1744.8260000000002, 1757.3100000000002], [1757.3100000000002, 1768.16], [1768.16, 1780.5600000000002], [1780.5600000000002, 1821.0800000000002], [1821.0800000000002, 1831.2], [1831.2, 1843.44], [1843.44, 1854.601], [1854.601, 1865.0010000000002], [1865.0010000000002, 1876.5400000000002], [1876.5400000000002, 1887.7600000000002], [1887.7600000000002, 1898.0900000000001], [1898.0900000000001, 1908.44], [1908.44, 1918.6000000000001], [1918.6000000000001, 1930.13], [1930.13, 1942.2930000000001], [1942.2930000000001, 1958.49], [1958.49, 1969.02], [1969.02, 1983.05], [1983.05, 1993.99], [1993.99, 2004.89], [2004.89, 2016.8100000000002], [2016.8100000000002, 2027.8000000000002], [2027.8000000000002, 2037.8990000000001], [2037.8990000000001, 2049.281], [2049.281, 2061.37], [2061.37, 2073.48], [2073.48, 2089.06], [2089.06, 2099.47], [2099.47, 2111.7999999999997], [2111.7999999999997, 2124.2299999999996], [2124.2299999999996, 2149.1699999999996], [2149.1699999999996, 2159.45], [2159.45, 2172.3199999999997], [2172.3199999999997, 2185.35], [2185.35, 2196.268], [2196.268, 2207.0], [2207.0, 2218.91], [2218.91, 2233.5299999999997], [2233.5299999999997, 2247.8199999999997], [2247.8199999999997, 2258.0299999999997], [2258.0299999999997, 2274.72], [2274.72, 2284.99], [2284.99, 2296.1], [2296.1, 2306.14], [2306.14, 2318.75], [2318.75, 2332.54], [2332.54, 2344.33], [2344.33, 2355.35], [2355.35, 2367.8199999999997], [2367.8199999999997, 2378.7439999999997], [2378.7439999999997, 2389.6059999999998], [2389.6059999999998, 2400.6339999999996], [2400.6339999999996, 2412.5199999999995], [2412.5199999999995, 2424.7699999999995], [2424.7699999999995, 2435.0299999999997], [2435.0299999999997, 2447.14], [2447.14, 2458.9], [2458.9, 2469.58], [2469.58, 2482.43], [2482.43, 2495.44], [2495.44, 2508.64], [2508.64, 2519.0319999999997], [2519.0319999999997, 2530.5099999999998], [2530.5099999999998, 2541.1699999999996], [2541.1699999999996, 2551.8899999999994], [2551.8899999999994, 2562.6999999999994], [2562.6999999999994, 2573.0569999999993], [2573.0569999999993, 2585.5099999999993], [2585.5099999999993, 2596.3099999999995], [2596.3099999999995, 2617.4899999999993], [2617.4899999999993, 2632.9899999999993], [2632.9899999999993, 2666.0499999999993], [2666.0499999999993, 2677.0799999999995], [2677.0799999999995, 2687.9099999999994], [2687.9099999999994, 2699.3499999999995], [2699.3499999999995, 2709.5499999999993], [2709.5499999999993, 2719.7689999999993], [2719.7689999999993, 2731.149999999999], [2731.149999999999, 2745.4789999999994], [2745.4789999999994, 2757.526999999999], [2757.526999999999, 2771.229999999999], [2771.229999999999, 2782.429999999999], [2782.429999999999, 2795.929999999999], [2795.929999999999, 2806.673999999999], [2806.673999999999, 2820.2799999999993], [2820.2799999999993, 2830.359999999999], [2830.359999999999, 2840.4699999999993], [2840.4699999999993, 2850.959999999999], [2850.959999999999, 2861.749999999999], [2861.749999999999, 2876.619999999999], [2876.619999999999, 2886.889999999999], [2886.889999999999, 2900.179999999999], [2900.179999999999, 2916.029999999999], [2916.029999999999, 2926.1499999999987], [2926.1499999999987, 2938.219999999999], [2938.219999999999, 2948.2349999999988], [2948.2349999999988, 2989.7299999999987], [2989.7299999999987, 3004.6799999999985], [3004.6799999999985, 3015.0699999999983], [3015.0699999999983, 3028.789999999998], [3028.789999999998, 3041.5699999999983], [3041.5699999999983, 3052.8799999999983], [3052.8799999999983, 3070.5059999999985], [3070.5059999999985, 3084.9729999999986], [3084.9729999999986, 3096.2799999999984], [3096.2799999999984, 3110.499999999998], [3110.499999999998, 3120.499999999998], [3120.499999999998, 3131.329999999998], [3131.329999999998, 3150.699999999998], [3150.699999999998, 3164.829999999998], [3164.829999999998, 3176.249999999998], [3176.249999999998, 3193.5499999999984], [3193.5499999999984, 3208.4899999999984], [3208.4899999999984, 3223.2599999999984], [3223.2599999999984, 3235.6499999999983], [3235.6499999999983, 3246.6619999999984], [3246.6619999999984, 3262.6099999999983], [3262.6099999999983, 3273.0099999999984], [3273.0099999999984, 3285.209999999998], [3285.209999999998, 3296.729999999998], [3296.729999999998, 3309.0899999999983], [3309.0899999999983, 3319.979999999998], [3319.979999999998, 3330.1549999999984], [3330.1549999999984, 3344.2199999999984], [3344.2199999999984, 3355.7199999999984], [3355.7199999999984, 3368.1399999999985], [3368.1399999999985, 3380.0599999999986], [3380.0599999999986, 3391.6999999999985], [3391.6999999999985, 3406.0499999999984], [3406.0499999999984, 3418.0099999999984], [3418.0099999999984, 3433.3999999999983], [3433.3999999999983, 3447.349999999998], [3447.349999999998, 3462.6699999999983], [3462.6699999999983, 3473.479999999998], [3473.479999999998, 3484.7149999999983], [3484.7149999999983, 3500.6999999999985], [3500.6999999999985, 3517.5149999999985], [3517.5149999999985, 3528.7399999999984], [3528.7399999999984, 3540.8199999999983], [3540.8199999999983, 3552.749999999998], [3552.749999999998, 3563.389999999998], [3563.389999999998, 3573.559999999998], [3573.559999999998, 3585.719999999998], [3585.719999999998, 3598.909999999998], [3598.909999999998, 3611.869999999998], [3611.869999999998, 3623.779999999998], [3623.779999999998, 3642.251999999998], [3642.251999999998, 3652.889999999998], [3652.889999999998, 3667.639999999998], [3667.639999999998, 3679.809999999998], [3679.809999999998, 3693.3199999999983], [3693.3199999999983, 3707.209999999998], [3707.209999999998, 3718.889999999998], [3718.889999999998, 3732.739999999998], [3732.739999999998, 3801.039999999998], [3801.039999999998, 3821.6299999999983], [3821.6299999999983, 3840.5699999999983], [3840.5699999999983, 3852.979999999998], [3852.979999999998, 3876.9899999999984], [3876.9899999999984, 3888.6599999999985], [3888.6599999999985, 3899.0139999999983], [3899.0139999999983, 3913.1899999999982], [3913.1899999999982, 3925.769999999998], [3925.769999999998, 3937.999999999998], [3937.999999999998, 3948.6499999999983], [3948.6499999999983, 3962.4099999999985], [3962.4099999999985, 3976.2799999999984], [3976.2799999999984, 3989.6089999999986], [3989.6089999999986, 4000.1759999999986], [4000.1759999999986, 4017.1179999999986], [4017.1179999999986, 4028.2399999999984], [4028.2399999999984, 4038.5899999999983], [4038.5899999999983, 4051.6399999999985], [4051.6399999999985, 4062.7899999999986], [4062.7899999999986, 4078.5679999999984], [4078.5679999999984, 4089.0279999999984], [4089.0279999999984, 4099.951999999998], [4099.951999999998, 4112.449999999998], [4112.449999999998, 4123.429999999998], [4123.429999999998, 4135.419999999997], [4135.419999999997, 4146.869999999997], [4146.869999999997, 4157.249999999997], [4157.249999999997, 4177.579999999997]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1249, 2989, 3259, 4178]}
{"example_id": "mit126@@MIT2_003SCF11_lec03_300k", "text": ["PROFESSOR: So I'm going to give you  a quick example of what I think is a good way to do solutions.  Our approach to solutions. ", "", "State the problem.   I'm going to give you a little formulaic here.  Draw figures.  ", "On the first day I said I like to think of dynamics problem.  I break them down into three categories.  One is to describe the motion.  ", "What does describing the motion mean?  Well how many-- the number of degrees of  freedom in the problem.  That implies the number of equations of motion ", "that you're going to need to solve that problem.  So you got to identify the number of degrees of freedom.  It also then tells you the number of coordinates you need. ", " So this is all part of describing the motion.  It's figuring out how many coordinates, assigning them.  ", "So assigning the coordinates.  And then finally, essentially all underneath this you  essentially do the kinematics.  ", "And that's the velocities, accelerations, so forth.  So once you have-- you've explained the motion.  ", "And this I guess is four.  Explain the correct physical laws.  ", "You know how they apply.  f equals ma.  Newton's first, second, third law of conservation of momentum  or whatever you want-- you think is the appropriate thing.  So explain what the physical laws are and apply them. ", " And finally, do the math.  ", "So if you could break problems down that way  it'll give you a nice, logical flow.  So I'm going to give you a bit of an example problem.  ", "And I'm also going to kind of pose a brain teaser to you  at the end of this problem today.  I want to give you something to think about.  So I'm going to draw my problem. ", "This is a block on an incline.   It's got some scales to measure your weight. ", "And you're standing on this thing.  Riding it down the incline.   And the first question about this ", "is to find the position as a function of time.  ", "So that's the problem.  That's part a.   So state the problem, find the position.  ", "So how-- well what do we do?  Well draw figures, I've started with that.  Next, describe the motion.  I need a free-- We have to figure out ", "how many degrees of freedom this problem has.  I'm going to just declare no rotation.  Going to treat it as a particle.  So a particle has how many, generally how many degrees of ", "freedom?  How many coordinates to completely describe  where it's at?  AUDIENCE: Three.  PROFESSOR: Three.  So I may need as many as three coordinates  to describe the motion of this thing. ", "And if I really doing complete equations of motion  I need three equations of motion.  So this is two, three-- describing the motion I  have three degrees of freedom. ", "I'm going to need three coordinates.   So in this case here's my picture ", "I'm going just to set up a Cartesian coordinate system  aligned in a helpful way.  X, y, z coming out. ", "And this is my fixed inertial reference frame.  And here's my center of mass.  And basically my coordinates are describing the position  of the center of mass.  ", "So that's pretty much the describing the motion,  what I need for now.  We'll get to the velocities and accelerations  when we get to the math part.  Apply the physics.  ", "I'm going to use Newton's second law.  ", "Sum of the external forces, mass times the acceleration.  That's the physical law I'm going to apply. ", "Draw a free body diagram.  ", "And I'm just going to consider the block  and the person this is the whole collection, it's one thing.  I'm just not keep drawing the person on it,  but-- so here's my object, including ", "the weight of the person.  And it's going to have-- here's its center of mass.  Obviously in mg, gravitational force, ", "it's going to have a normal force.  Going to have a friction force and how do I  figure out what the friction-- which direction the friction  is?  I assume motion down the hill. ", "Friction will oppose it.  I draw in the arrows in the direction  I expect the forces to act.  Then I'll use the sign convention  that the arrows tell me what signs. ", "So since my x-coordinate is down the hill.  This is y.  This is x, friction x, in the minus x direction.  ", "And I haven't-- I've left out a key piece of information.  Got to have the angle of the slope.  And once you have the angle of the slope that's theta, ", "this is theta.  And I'm going to need to-- this is in a direction of one  of my coordinates and so is this,  but I need to break the gravitational piece  into components lined up with my coordinates. ", "And so you have a theta here as well.  And now I can write my equation to motion.  ", "And the nice thing about vectors is  that when you have three equations of motion,  three coordinates, each that are components of vectors ", "in the x, y and z direction, it gives us  three equations immediately.  So for example, the summation of the forces  in this problem in the z-direction,  the external forces are sums to? ", "AUDIENCE: 0.  PROFESSOR: 0.  OK so we get a trivial solution out of that.  And we don't have to go much further.  Summation of the forces in the y-direction ", "gives us some useful information.   And then the y-directed forces I have an n and a minus mg ", "and I think it's cosine theta.   Which tells me immediately what n is. ", "So from statics I get to-- and from what we know about models  of friction then we know that we can model the friction as mu ", "times n for mu mg cosine theta.  So from the statics I learn a bunch of things ", "that I need to know for the problem.   So now I get to the real heart of the problem, ", "writing my equation of motion in the x-direction.  ", "And the forces in the x-direction mg  sine theta down the hill.  So it's positive.  Minus the friction is up the hill. ", "So I get mg.   I'm mixing up my m's here but there's no other m so-- this ", "basically says, that x double dot, the m's all cancel out.  That x double dot is g sine theta minus mu g cosine theta. ", "And that just happens to be a pretty simple to solve,  ordinary differential equation.  This is an equation in which the acceleration in the problem  is constant.  The data's not changing. ", "None of these things are changing  and so you can just solve this one.  Now we're to the third part, do the math.  ", "This one you can just integrate.  And so you find out that well, x dot then  and I'm just going to call this c some constant.  So x dot ct plus an initial velocity, if it had one. ", "And x of t, what you're looking for.  ", "And now so v0 and x0 are just your initial conditions.  More than likely 0 if you set it up cleverly.  So that's just modeling quickly what  I think a good way to lay out a problem is. ", "Describing the motion, explaining the physics,  doing the math, drawing good pictures, stating the problem.  All right so now the brain teaser ", "that I want you to think about.  ", "So here's the mass of the block plus the scales.   And here's the-- here you're standing on it.  ", "So mass of the person.   You're riding this down the hill.  ", "So this is part b.  ", "Think about that when in the shower.   If you've got a really simple way to do it,  great write it up.  It's not terribly hard and it's mostly-- I'll give you a hint. ", "Thinking in terms of free body diagram helps a lot.  And we'll come back to this kind of fun problem.  ", "OK, want to go-- that was part one.  I want to go onto this recapping the center of mass quickly.  We learned a couple of important things. ", "We got-- we talked about the center of mass  because we were just talking about Newton's three laws.  From looking at the first law, found  that it's useful in determining whether or not  you're in a inertial frame, we used it. ", "Second law we've just applied it.  We used to do-- get equations of motion.  Third law was about-- we used it when we're  thinking about center of mass. ", "We used it to define what the center of mass was.  So we said the total mass of a system,  I better draw my picture.  Here's my system of particles. ", " M1 with position vectors.  So a whole mess of particles with their position vectors. ", "This is ri with respect to O for example.  This is my O x, y, z frame.  We said that this total mass of the particles ", "somewhere out here there's a center of mass with a position  vector rg with respect to O. So the definition of my center ", "of mass is this is equal to the summation of the m, i, r, i, o  and these are position vectors. ", "So that's the definition of my center of mass.  If I take two time derivatives of that we arrived at mt rg ", "with the respect to O double dot.  Summation over i of my m, i, r, i, o double dots. ", " And then importantly that's the summation  of all of the external forces on each ", "of these-- each one of these by itself  satisfies Newton's law, second law, which  he wrote about particles.  Each one has a summation.  I've summed these and I'm going to sum these, ", "but each one has a summation of internal forces acting on it.  These I call the f, i, j's.  And we learn-- something about the third law ", "tells us about that summation.  The third law tells us what?  That goes to 0 and that was that's the really powerful  piece of the third law that we make great use of. ", "Because this now essentially allows us to say,  that the summation of the external  forces on an assembly of particles, ", "on a system of particles, is equal to the total mass ", "times the acceleration of the center of mass.  And that-- what that does in one stroke ", "takes you from Newton, who's laws applied to particles  and allows you to apply Newton's second law to rigid bodies. ", "Because rigid bodies can be thought up  a bunch of particles, which are represented  in that simple equation.  And that gets you from particles to rigid bodies. ", "And we all know from physics that a summation  of the external force on this thing  is the mass times the acceleration  of the center of mass.  ", "So that's actually quite an important powerful law.  It provides this for us.  Now I said I wanted to give you a quick, very ", "useful application of thinking about center of mass.  I showed you the other day, I had my carbon fiber tube here.  Showed you that trick for finding the center of mass  just by sliding your fingers along it. ", "And you end up at the center of mass.  Well as a practical matter other things--  you really want to be able find center of mass.  This is a glider, a sailplane called an LS8. ", "I happen-- I'm a glider flight instructor.  Been flying gliders for 35 years or something like that.  And I flew a glider of this type just recently. ", "That machine has a 49 to one let's call it 50 to one  to make it easy, glide ratio.  Means if you're a mile above the ground in still air, ", "you will go 50 miles before you touch the ground.  So they're really amazing high performance machines.  One of the things about all aircraft that you actually  need to know is, you really need to know where ", "the center of mass of it is.  And if the center of mass is in the wrong place  the plane will not fly properly.  And so you can't just go throw on 50 pounds of lead ", "in the tail of that plane and expect  to survive the next flight.  So you have to know where the center of mass  is, and in fact, you want the center of mass  about 25% of the-- if the wing is this wide from front ", "to back it's called the cord.  About 25% back from the leading edge  is about where the center of lift of a wing is.  And you want your center of mass also ", "called the center of gravity in these situations,  you want it to be pretty close to the center of lift  so that their balance in the plane flies nicely.  So is there a simple way to find the center of mass of something ", "like a sailplane?  So I'm going to drew-- this is exactly how you do it.  So I'll draw a quick picture of my sailplane here.  ", "You usually have a little skid or a tail wheel on the back.  And to find the center of mass you just set them on scales.   You weigh it. ", "You pick a coordinate system.  Doesn't matter where it is, as long as it's fixed.  The easiest place is right at the nose of the sailplane.  So we'll make this x, make this y. ", "You take it and you can take a tape measure  and measure the distance from your reference point  to the position where the wheel sits on the scales. ", "We'll call that L1 here.  And that's typically about five feet.  And back here you have another position ", "to where you have your second set of scales, that's L2.  And a typical sailplane that's about 15 feet.  ", "Apply Newton's law.  This thing's not going anywhere.  Sum of the forces in the vertical direction  is equal to 0.  Free body diagram. ", "Well you have somewhere about here, where the wing is,  this is your center of mass.  And you have m total times g downwards there. ", "You have two weights pushing on the sailplane.  A W2 pushing up, holding up the tail.  And a W1 holding up the main gear. ", "And so from the sum of the forces in the y-direction,  that had better be 0.  So you know that W1 plus W2 minus mtg is 0. ", "And so you find out that the total weight of the sailplane  is no surprise, the sum of the two weights on the scales.  AUDIENCE: [INAUDIBLE]. ", " PROFESSOR: Yeah.  Let's do this, m, t, g.  So the total weight times gravity ", "is just the sum of the two readings on the scales.  And the second piece that you need to do to do this problem  is, you can have an equation that says,  the sum of the external torques with respect ", "to you're-- through a fixed point O,  is equal to the mass moment of inertia times the angular  acceleration, oftentimes written as alpha. ", "In this case, that's going to be 0, it's going nowhere.  So what are the external torques with respect to this point?  Well we have a right-handed coordinate system.  You have W1 up, times L1. ", " W2 up, times L2 minus W1 plus W2, ", "which is the total weight of the sailplane times  rg, the location of the center of mass. ", "That's this distance that we're looking for.  ", "So we know everything here, except rg.  So we can solve for rg with respect to O  and it's simply W1 L1 plus W2 L2 over W1 plus W2. ", "And if you run the numbers, typically W1 600 pounds, ", "W2 the numbers I've done here is-- might be 40 pounds.  ", "And I've already said five feet and 15 feet.  And you work the answer and you come up  with 5.62 feet, which puts this-- here is the wheel ", "and you're a little bit aft of the main gear.  And that's where you, basically where you want to be.  That's a real practical use of knowing about centers of mass ", "and how to calculate them.   So that's the second item I wanted to talk about today. ", "Essentially a recap of the center of mass.  And now I want to move on to talking  about a serious introduction to-- we've ", "had the introduction, velocities and accelerations.  We have to have a way of writing down  the acceleration of a mass, a point, a dog in a rotating, ", "translating, reference frame with the possibility  that in addition to that, the dog's moving.  So we want to have equations-- we want to have the ability  to write down expressions for the velocity ", "and acceleration of a mass moving in a translating,  rotating, reference frame. ", "So we've started this.  We did pretty much did velocities to begin with.  ", "So here's my inertial frame.   Call it O or O x, y, z. ", "Here's my rigid body out there.   It has a point a something else, b might be the dog. ", "And we've described the position of this  as the position of this point a, with respect to O.  And at this point we're going to locate a reference frame ", "attached to the rigid body.  And so it's going to be called a,  and I'll call it x prime, y prime, z prime.  It's attached to the rigid body, it ", "rotates with the rigid body and its attached  at some fixed point.  Now what would oftentimes would be  a smart choice for that fixed point at point A?  ", "AUDIENCE: [INAUDIBLE].  PROFESSOR: If you're going to write an equation expressing  the motion of this.  Where would you make point a?  [INTERPOSING VOICES]  AUDIENCE: Center of mass.  PROFESSOR: Center of mass. ", "So very, very often, especially when objects are free  floating around out there you're going to make smart choices  and you're going to put this coordinate system  right on the center of mass.  But it doesn't have to be, but it can be. ", " So we were interested in knowing things  about the motion of this point in our inertial reference ", "frame, in terms of positions of our coordinate system.  And then also this vector here rd, with respect to a. ", "Now last time we came up with expressions for the velocity  of b with respect to O. ", "We said in general it's the velocity of your-- where  your coordinate system's located.  The translating-- the velocity of the translating frame ", "plus the derivative of rba, time derivative  of the position as seen from, if you were sitting at a. ", " And another way to say that, or this  is a derivative taken with the rotation rate momentarily set ", "equal to 0.  Another way to think of it.  Plus a piece that comes from rotation.  So the rotation with respect to the fixed frame, these ", "are all vectors, the rotation with respect  to the fixed frame, cross product with r, b, a. ", "And this-- and we said this is actually  a general formula for the derivative of-- this piece is  the derivative of a vector in a frame, in a fixed frame. ", "You have two pieces, the derivative as  seen without rotation plus the contribution that  comes from rotation.  ", "When I did this center of mass thing a second ago,  I just kind of quickly wrote down two time derivatives  of the position vector.  There's no omega cross O's in there right? ", "Why could I do that?  This is actually kind of an important distinct point.  I could do that they didn't say very specifically when I did it ", "was an assumption I was making.  Except for perhaps they drew it.  This was done in a Cartesian coordinate system.  And my coordinates were x, y and z ", "and the unit vectors were i, j, k and do they move?  No.  What's their time derivative?  [INTERPOSING VOICES]  PROFESSOR: When you don't-- when the inner vectors don't have ", "time derivatives you don't get these terms.  This is the only term that contributes so I could just  write that equation.  But we now have a reference frame attached to a body  and this reference frame is rotating. ", "And that means that the direction of the unit vectors  attach-- the unit vector attached to x-prime here  is moving, it's rotating.  And it's going to have a time derivative. ", "So we have to-- and that is given  and you take those time derivatives you  get this second piece.   I'm going to give you the answer in advance. ", "The acceleration of b with respect to O I'm  going to give you the full 3D equation. ", "Then we'll go back and see a bit where it comes from.  So here's-- it's the time derivative of that velocity  expression with respect to time taken in the inertial frame O, ", "x, y, z.   And am I going to have enough room to get this on?  It'll be close. ", "", "All right this has several pieces.  It's got a contribution of the acceleration of a with respect  to O. That's just the acceleration of this point. ", "Has nothing to do with rotation, so it's just a straight out  acceleration of my translating frame with respect to O.  That's the first piece.  The second piece is related-- is the derivative of this guy that ", "comes from the derivative of this.  It's the acceleration of b with respect to a as seen  in this a frame. ", " If you read the Williams book, it's  called the relative acceleration.  It's relative to the-- if you were sitting at point A, ", "it's what you would see as the acceleration.   Plus 2 omega cross velocity of b with respect ", "to a as seen from a plus omega dot, the derivative ", "of the rotation rate, cross rba plus omega cross, ", "omega cross r, b, a.  ", "Kind of daunting right?  A little messy.  Basically one, two, three, four, five different terms. ", "And you're going to-- and they all have names and meanings.  And one of the things that will really help you  is to get familiar, you really need ", "to be familiar with the meaning of each one of the terms.  And it's not terribly difficult.  This one, just the acceleration of the translating frame. ", "So if it's a merry-go-round sitting  on a train and the train's heading down the track,  its acceleration of the train.  Rotating frame is attached to the merry-go-round.  ", "And if you've got the dog on the merry-go-round  this is then the acceleration of the dog relative to this,  the merry-go-round.  This position of the coordinate system ", "attached to the merry-go-round has no rotation in it.  This is the velocity of that point, the dog, ", "as seen from the A frame.  Again, you have no sense of rotation.  Rotation is not a part of this.  Cross product with the rotation rate.  ", "This is the accelerate.  This is the angular acceleration cross product with rba.  Now that's a term-- what does that mean?  I'm swinging a baseball bat and I'm accelerating this thing. ", "Idealize it as just something on a radius accelerating.  The acceleration of a point out here  is the radius times the angular acceleration. ", "So that's all this term is.  And it's called the Euler acceleration.  But it's just simply r theta double dot.   This, if you multiply it out and just think about units, ", "this ends up looking like r omega squared.  Have you run into that before?  What's that?  Common language.  AUDIENCE: [INAUDIBLE]. ", "PROFESSOR: That's as a centrifugal-- centripetal,  this is centripetal acceleration.  So this is the centripetal acceleration term,  that's the Euler acceleration term,  this is the local acceleration. ", "This is the acceleration of your frame.  This is the strange one.  This is the Coriolis acceleration.  ", "And we'll get familiar with it too.  So that's the full blown 3D acceleration equation.  And by the way the vector-- the velocity one ", "is also perfect 3D.  Now in this course we won't do much in the way of 3D dynamics ", "problems.  Yes.  AUDIENCE: Does the point b on the rigid plane move?  PROFESSOR: Does the-- it may.  It could be this is the-- an asteroid out there in space ", "and you've got-- this is home base  and that's a guy out there in a space suit running.  ", "So we want to be able to describe  the acceleration of that guy as seen from a fixed reference  frame. ", "Now why would we want to know that acceleration?  Why do we want to know it in a fixed frame?  Well if you want to calculate the forces on the person. ", "Well how much-- what's he have to do with his feet  to brace himself or whatever?  What are the actual forces?  You have to know the acceleration on the person. ", "But Newton's laws, in order to say f equals ma,  Newton's laws have to be applied in inertial reference frames.  Is this thing out there doing this an a inertial reference ", "frame?  No.  So you can't calculate the forces  without having some idea of this inertial frame.  So this is the way of getting the acceleration ", "on-- at a location on a moving, rotating body with respect  to an inertial frame.  And with all the terms present. ", "Now most discourse has generally has addressed problems  which are in most textbooks address only planar motion  problems. ", "Planar motion basically means that we can find  the translations to a plane.  So imagine an x, and a y, and a z upwards coordinate system ", "attached to the top this table.  And I only allow motions that are around the table.  And I only allow motions that have a single axis rotation.  And that's lined up with z.  Those are essentially planar motion problems. ", "And most courses in dynamics, it lists [INAUDIBLE].  That's as far as they get.  And the most of the problems that you'll do  will be planar motion problems. ", "But that equation reduces to the planar motion problem as well.  We will do a little bit of 3D, because there's  a class of problems that I really ", "think it's important for you to understand that just come up  all the time that require a little 3D.  And as you want to have some things going on  out of the plane, but we'll still  confine the axis of rotation to a single direction. ", "Yeah.  AUDIENCE: [INAUDIBLE] in a planar,  but then would you have three to view the freedom? [INAUDIBLE].  PROFESSOR: That's a great question ", "she said if you had a dog running  on the merry-go-round how many degrees of freedom do you have?  So in general rigid bodies, each rigid body,  each independent rigid body has-- ", "you have to describe its location of its center of mass  and that takes how many coordinates?  How many coordinates I'll call them.  AUDIENCE: [INAUDIBLE].  PROFESSOR: Well in general three. ", "And it can now rotate around three different axes.  And that takes three more.  So rigid bodies have six degrees of freedom. ", "And any problem when you go to address the problem you  essentially for a rigid body you start with six.  And you start applying constraints  to reduce it down to the number of remaining ", "degrees of freedom.  So if it's confined to a plane and no z-motion  is allowed one constraint.  If it is on a plane and it's only ", "allowed to rotate about the z-axis that  means you've constrained its rotation in around y and x.  So that's two more.  And so now you're down to three degrees of freedom left, xy ", "and a rotation about the z-axis.  So planar motion problems generally  have three degrees of freedom.  But instant-- let's just say we're ", "just interested in just something that  rotates and doesn't translate.  How many degrees of freedom does that have then?  Just one.  x and y are forced not to-- no motion, two more ", "constraints you're down to one.  So lots of problems we do are in fact single degree  of freedom problems.  ", "So to do planar motion problems we oftentimes  use polar coordinates.  So I'm going to introduce r theta. ", "And I'm actually going to call it cylindrical coordinates.  ", "And cylindrical coordinates then you have an r, a theta and z.  ", "And let's think about well let's see, I have a demo,  a little demo here.  So here's a problem with a single axis of rotation. ", " And it's a-- there is a mass out here and just this is a rhyme.  And so think of this think of this mass ", "out here as being a bug walking out this rod.  And the rod, this thing goes round and round.  It's not a merry-go-round but it's ", "a merry-go-round with a gang plank on it.  It's going up at an angle and you  can walk the gang plank while the merry-go-round's  going around.  So that's what we got here.  So this is actually allowed to change position of this mass. ", "So how would I describe that with cylindrical coordinates?  Let me so it's going to take-- one would be a side view. ", " So you see your vertical axis here  and have to have a bearing to hold it in place.  ", "Here's the arm, here's the bug walking out the arm,  has some rotation rate.  ", "Theta dot this is the z-axis and the position of this point ", "is described by a r vector, in the r hat  direction, which I think is the unit ", "vectors you're used to using.  And then this is the z-component in the k hat direction.   And this vector here would be r of v with respect to what shall ", "I call it?  I'll make this a and over here someplace ", "I have a fixed inertial let's see I got to be careful here. ", "I want that to be z then I have a y going out here x, y, z  pointing upwards.  And my-- this fixed inertial system the unit ", "vectors here this would be i hat, j hat and k hat.  But these-- this rotating system with its unit ", "vector little k and this vector they're the same,  they're parallel.  But looking down on this, this is my polar coordinate system. ", "Now I'm going to look at my top view.  I will see a projection.   I'll just see the r, this is rr hat, ", "this is my point B. This is theta.   And I have a unit vector.  So the unit vector r hat is something-- the unit long ", "pointing in this direction.  And the unit vector in this direction is theta hat.  And it's perpendicular to that radius. ", "So now I have my three unit vectors.  One pointing in the direction of r, here's  also my unit vector is just to make sure there's no confusion. ", "This unit vector is in this direction.   K is in that direction.  Theta is in that direction.  ", "And over here you still have your-- now here's  my x, y, z out of the board inertial frame. ", "And this-- my inertial frame this might be r, b, o.   So in my inertial frame.  I want to know what's going on here. ", "I want to be able to calculate the velocities  and the accelerations.   So the notation here gets-- can get a little confusing. ", "The rbo notation that I've been using all along,  that's the motion-- that's the position vector describing  that point in my inertial frame. ", "And my-- just lowercase r here, no scrub scripts or anything,  that's just going to-- that's my polar coordinate r theta ", "and z that happened to be in this case,  this is a rotating frame.  This is a rotating frame.  It's the center of this coordinate system's at a. ", "But this thing rotates.  So this is a pretty simplified version  of this general problem.  Now because it's simplified, you can actually-- ", "it's a lot easier to use.  Also has some real limitations.  You can only going just-- there's limited things  that you can describe with it.  ", "So let's start by describing velocities in cylindrical  coordinates.  ", "Remember this rba is the length of this guy here.  And it's made up of rr hat zk hat.  ", "So to express the velocity we have  to take a time derivative of this r, b, a  and I'm going to express it in terms of r theta nz.  And to get acceleration I have to take two time  derivatives of this, but this is going to be expressed ", "in my cylindrical coordinates.  This is where I'm going.  And lots of problems-- many, many of these problems ", "have fixed axes of rotations and this velocity  and this acceleration are zero.  You just drop it out.  I'm going to do that just to keep this-- make  this problem a little simpler. ", "So we can just focus on these terms.  So let's just let the there be no translational of this frame. ", "And that says that Va with respect  to O the acceleration of A with respect to O over zero.  So I want you to just focus on these terms.  I don't lose anything, I can put these back in ", "later if I need them.  I just don't want to keep carrying them along.  ", "So I have my-- remember my side view.   This is r, r hat zk hat that's my point. ", "And my top view.  ", "This is my projection just looking down on it  what I see is the length r.  And what I see in my unit vector going that way r direction ", "and theta that direction.   And this is x and the i and a y with a j hat ", "vector looking down on it.  My rotation rate mega with respect to my inertial frame,  is sum theta dot k hat. ", " All right so now let's find the velocity of b with respect  to O. Well it's 0, no translation, plus-- ", "and now I need a time derivative of rb with respect to a.  But this is then r, b, a is r, r hat plus z k hat. ", "And I need the time derivative of that.   So I get an r dot r hat plus an r r hat dot plus a z dot k. ", "So this is the product of two things.  They're both time dependent.  So I have to get two pieces, k does not change in direction.  So it has no time derivative. ", "So I only have a z dot k.  So this is a result of doing this,  but I now have to figure out what  is the time derivative of the unit vector in the r direction.  ", "So when I told-- when we worked out this formula the other day  for the time derivative of a rotating vector,  I mostly did it, it was kind of an intuitive argument.  So on this one occasion I'm going ", "to give you an example of actually figuring out  what the derivative of this rotating vector is.  And if you go read that kinematics handout ", "and it does this in kind of full blown form for-- in general.  So I'm just going to do it as one example.  So here's our looking down on this, the projection on the xy ", "plane, here's our r-vector.  And here's this unit vector and it  starts from-- I have a unit vector starting from a it's ", "unit-- it's one long.  And this is r hat.  And it's of unit length and it's in this particular direction. ", "Now in a little bit it time delta t, it moves.  It moves to here.  So this is delta r hat and what direction does it move? ", "AUDIENCE: [INAUDIBLE].  PROFESSOR: Yeah, it moves in the-- moves in the theta hat  direction.  And the amount that it moves is the rotation rate, ", "theta dot, delta t.   So delta r hat, if I solve for this, delta t. ", "And this is in the theta hat direction,  is theta dot theta hat.  ", "So this is the limit as t, delta t  goes to 0 you get the derivative of r hat with respect to time. ", "Its direction is in the theta hat direction  and its magnitude is theta dot.  So that's the time derivative of the unit vector r hat. ", " Yeah.  AUDIENCE: How does that work with units?  PROFESSOR: How does it work with units? ", "What's left out of here is that this is unit length  and has dimensions.  It's unit length, one whatever unit system you're working. ", "So that is implicitly in here.  It's one meter theta dot and that theta dot, the delta t,  the times go away. ", "You're left with one meter times the magnitude of theta dot.  So the distance it actually moves  is r theta, the r delta theta, delta theta is theta dot delta ", "t and the radius happens to be 1.   So whatever unit system you're working in it's a unit vector.  Has unit length. ", "So its units are buried right there.  Good question.  OK so now we know what this is.  So now we can come back finish our description of the velocity ", "of b with respect to a then is r dot r hat  plus z dot k hat plus theta dot times ", "so r times the derivative of the unit vector r, which we just  figured out is theta dot theta hat times r. ", "R theta dot theta hat.  So that's my velocity of b with respect to a.  My velocity of B with respect to O all you have to add in ", "is the velocity of A with perspective to O,  which we've let be 0 for now.  So for the moment this is also d with respect to O.  But this is the general piece of the velocity ", "of b with respect to a in polar cylindrical coordinates.   Now we could have-- so I've actually worked it out, just ", "shown you, just drew the picture and figured out the derivative.  We could have used that magic formula.  The formula for the derivative of a vector in a rotating  frame. ", "", "So I'll just do that quickly to remind you  how we could have done this.  rba with respect to time as seen in the O frame. ", " Is the partial derivative of rba with respect  to time as seen in the rotating frame, plus omega cross r, b, ", "a.   This term is that and that. ", " The derivative of this rba as seen  from inside of the rotating frame,  is just the change in length, this is rba here from the side. ", "So the change in length of that vector, the derivative  of-- the time derivative of it.  It's the vector sum of the r dot plus z dot. ", "So this piece comes from this and this.  And this piece should-- this one here, it better be this. ", "Well this is-- let's figure it out.  This is omega in the k hat direction,  cross and rba is r r hat plus z k hat. ", "k cross k is 0.  k cross r theta hat.  K cross-- k hat cross r hat is theta hat positive. ", "r omega theta hat, same thing as r theta dot theta hat.  So we could have just applied this formula for the derivative  of a rotating vector and we would ", "have gotten the same thing.  ", "OK just ran out of boards.  ", "Now a quick little exercise you could do on your own  is, we're going to need to be able to calculate  the derivative of theta hat.  Well just plug it in that little formula.  ", "And the first term you'll find out the derivative of the theta  hat, the length doesn't change in time, it's a unit vector. ", "So you only have the second piece.  So it's sum omega cross theta and you're going  to get minus theta dot r hat.  ", "So I really want to get here.  The acceleration of b and O. That's  the real-- that's the single piece we really ", "need to finish the kinematics.  So we can do most any problems.  Got to be able to describe the acceleration of a point  and translating rotating frame.  And that's going to be the acceleration of a with respect ", "to O, plus a time derivative of the velocity of b with respect ", "to O.  We've calculated the velocity, we  need to be able to essentially carry out this derivative. ", "Two time derivatives of the r, b, a, or a single time  derivative of bva.  Well we just computed the velocity ", "in this-- of this rotating frame and this  is our final expression.  So we need to compute the time derivative of that.  I just-- so it's going to look like r ", "dot r hat plus over here a term r theta dot theta hat ", "and pardon me for doing this I think  it'll be cleaner in the end.  I'm going to start with my z dot k, keep it over here, ", "plus r dot r hat plus this term.   And this is going to take up a lot room. ", "Just spread out this way so it--  ", "So let's just-- I'm going to write down where this comes  out, this is a little tedious, but then you'll  have seen it once hopefully believe that it really works.  ", "So these terms, this first term here just  gives you z double dot.  So let's write her down.  So just z double dot k hat time derivative of this, ", "plus an r double dot r hat, but now I  have to take-- do it, flip it and do the other side of it.  So I get my-- how do I want to do this? ", "", "Yeah, I like this.  ", "So this term kept-- leads to this.  This term brings you to here.  This term, you get r dot times theta dot theta hat plus an r ", "and now you need to take a time derivative of theta dot theta  hat.  So that's going to expand.  So this brings you to here. ", "", "Now we've done this derivative, so we can put it in.  So this gives us this term over here, ", "so let's keep adding these up.  ", "Notice this gives me an r dot theta dot theta hat.  This gives me an r dot theta dot theta hat.  ", "Two identical terms.   Now this term gives me an r theta double dot theta hat. ", "And now this-- now we need to take  the derivative of theta hat and that gives you  minus theta dot r hat.  So you get a minus r but multiplied by theta dot again ", "squared r hat.  So I think we're about there.  We're going to start collecting things together.  ", "Now we have a two r dot theta dot  theta hat plus an r theta double dot theta hat, minus r theta ", "dot squared r half.  So these things, these derivatives,  just all kind of flowed down and led to more terms.  ", "But now if we compare-- that we get one, two, three, four,  five, I clump these together. ", "This is the change in length of the r vector.  Stretch in the position has a z component and a r component. ", "This is the movement of the coordinate system if it moves.  This is the Coriolis term.  This is the Euler acceleration and this is ", "the centripetal acceleration.  So this is the-- what happens when  you start with that messy vector thing ", "and apply it, restrict it to a cylindrical coordinate problem,  which is basically planar motion.  But you allow some things in the z direction only. ", "So polar coordinates is a more limited form of that,  but it's-- every term comes back,  every term is still in it.  So acceleration of the moving coordinate ", "system, change of the length of the position  vector in the moving coordinate system,  the Coriolis term the Euler acceleration term that angular ", "acceleration speedup and finally the centripetal term.  Now the way you go about solving problems,  usins-- doing problems in polar coordinates. ", "So now you're asked to find an equation of motion.  This is an expression for the acceleration  of whatever it is you're trying to describe ", "in an inertial frame.  So that when you say-- you can now say f equals ma.  If you know the-- sometimes you're ", "given the forces in problems and your asked  to find the accelerations.  But what if you're given the acceleration  and you're asked to find the force?  All right, I give you the simplest problem of this kind. ", " What's the tension in the string?  Well if I know that-- so I just say, ", "the way you do these problems is how many things can you  eliminate?  Well I wasn't moving, this term goes away.  That's zero.  Z wasn't involved, it's not changing,  it's just constant angular rotation, that term is 0. ", "What's the change in length of the string while I  was doing it?  Now if that term's 0 we're getting easier all time.  How far-- how fast was the length getting longer? ", "That terms gone away.  Was I speeding up, or slowing down, or constant speed?  Well we'll say it's constant speed,  ooh this problem's getting easier all the time.  I'm down to one term. ", "f equals ma.  ", "Minus r theta dot squared r hat.  So the force that I must have been applying to the string ", "was in the minus r hat direction and had  magnitude mr omega squared.   So that's actually all there is to it. ", "We're using polar coordinates and cylindrical coordinates  to do second law problems.  So there's a couple of problems that you're  doing these kind of things on the homework ", "set that's being put out today.  So give them a try.  Have a good weekend. "], "vid_duration": [10.405, 13.685, 15.78, 13.25, 16.33, 10.919, 17.031, 22.84, 13.18, 12.64, 12.78, 10.447, 16.853, 10.569, 13.111, 12.05, 23.664, 18.49, 11.116, 10.731, 10.309, 11.396, 13.624, 11.19, 25.75, 17.43, 12.0, 11.014, 17.216, 10.04, 12.2, 12.27, 10.03, 16.48, 19.45, 14.25, 10.93, 10.5, 12.82, 10.99, 14.1, 10.72, 15.29, 10.856, 15.663, 12.981, 12.17, 25.74, 18.19, 11.53, 12.11, 15.23, 13.78, 11.37, 11.319, 25.551, 12.44, 24.83, 12.076, 12.214, 21.52, 15.079, 11.011, 10.62, 10.095, 10.175, 10.26, 18.62, 10.87, 10.045, 10.285, 14.383, 10.097, 11.92, 12.63, 10.58, 13.03, 10.94, 10.407, 11.943, 10.57, 11.9, 10.803, 10.587, 10.99, 10.75, 11.78, 10.665, 13.565, 12.07, 19.67, 18.522, 13.108, 12.77, 11.02, 10.03, 16.19, 10.97, 13.49, 12.16, 23.35, 10.478, 10.612, 12.88, 10.17, 11.955, 12.725, 12.55, 10.81, 17.11, 12.04, 11.22, 13.89, 12.417, 12.833, 12.21, 16.88, 12.14, 10.38, 34.05, 12.06, 13.4, 13.44, 10.71, 13.794, 10.206, 10.69, 13.55, 13.6, 12.095, 10.975, 14.17, 11.99, 11.73, 12.57, 12.12, 16.59, 12.88, 11.22, 11.72, 11.511, 11.779, 11.16, 10.63, 11.13, 17.916, 10.159, 13.555, 11.461, 14.139, 10.205, 11.837, 18.507, 11.611, 20.22, 10.466, 12.204, 10.68, 12.82, 11.75, 12.05, 10.07, 13.32, 13.97, 11.12, 12.67, 10.44, 11.395, 10.365, 10.31, 10.47, 18.28, 10.2, 11.06, 12.77, 11.49, 11.62, 10.16, 13.41, 11.11, 13.59, 12.35, 10.46, 10.271, 15.479, 11.01, 11.67, 12.56, 11.08, 11.11, 10.62, 15.09, 11.67, 12.029, 16.931, 11.23, 12.88, 13.61, 10.54, 12.81, 11.32, 13.96, 11.36, 11.89, 11.41, 15.24, 10.36, 21.93, 10.07, 11.6, 10.08, 13.44, 11.7, 11.72, 13.85, 10.24, 11.49, 14.53, 10.12, 12.515, 14.645, 12.92, 10.2, 14.02, 12.38, 31.72, 40.32, 36.61, 12.31, 12.45, 10.59, 10.72, 11.19, 33.37, 16.61, 19.83, 13.959, 11.941, 13.23, 13.54, 20.762, 21.578, 11.35, 24.58, 10.91, 10.3, 12.76, 11.02, 13.0, 17.58, 11.99, 14.17, 13.64, 11.49, 10.97, 11.96, 14.57, 10.61, 12.49, 10.76, 14.54, 20.125, 10.497, 10.348, 11.27, 11.14, 10.37, 11.3, 11.9, 19.957, 14.453, 15.06, 11.2, 14.55, 16.68, 16.01, 14.2, 11.5, 38.95, 16.47, 12.15, 29.14, 10.48, 13.54, 12.01, 11.33, 12.85, 14.5, 10.87, 11.66, 11.32, 10.5, 14.41, 13.46, 20.59, 10.449, 10.821, 23.68, 11.67, 26.6, 31.25, 11.59, 11.529, 15.6, 21.33, 23.24, 23.531, 12.01, 10.2, 10.54, 10.969, 11.231, 11.769, 14.481, 11.66, 12.88, 10.28, 10.93, 12.866, 10.951, 12.742, 11.601, 10.07, 11.8, 12.02, 11.26, 10.76, 8.56], "stet": [[0, 10.405], [10.405, 24.09], [24.09, 39.87], [39.87, 53.12], [53.12, 69.44999999999999], [69.44999999999999, 80.36899999999999], [80.36899999999999, 97.39999999999998], [97.39999999999998, 120.23999999999998], [120.23999999999998, 133.42], [133.42, 146.06], [146.06, 158.84], [158.84, 169.287], [169.287, 186.14000000000001], [186.14000000000001, 196.709], [196.709, 209.82], [209.82, 221.87], [221.87, 245.534], [245.534, 264.024], [264.024, 275.14], [275.14, 285.871], [285.871, 296.18], [296.18, 307.576], [307.576, 321.20000000000005], [321.20000000000005, 332.39000000000004], [332.39000000000004, 358.14000000000004], [358.14000000000004, 375.57000000000005], [375.57000000000005, 387.57000000000005], [387.57000000000005, 398.58400000000006], [398.58400000000006, 415.80000000000007], [415.80000000000007, 425.8400000000001], [425.8400000000001, 438.0400000000001], [438.0400000000001, 450.31000000000006], [450.31000000000006, 460.34000000000003], [460.34000000000003, 476.82000000000005], [476.82000000000005, 496.27000000000004], [496.27000000000004, 510.52000000000004], [510.52000000000004, 521.45], [521.45, 531.95], [531.95, 544.7700000000001], [544.7700000000001, 555.7600000000001], [555.7600000000001, 569.8600000000001], [569.8600000000001, 580.5800000000002], [580.5800000000002, 595.8700000000001], [595.8700000000001, 606.7260000000001], [606.7260000000001, 622.3890000000001], [622.3890000000001, 635.3700000000001], [635.3700000000001, 647.5400000000001], [647.5400000000001, 673.2800000000001], [673.2800000000001, 691.4700000000001], [691.4700000000001, 703.0000000000001], [703.0000000000001, 715.1100000000001], [715.1100000000001, 730.3400000000001], [730.3400000000001, 744.1200000000001], [744.1200000000001, 755.4900000000001], [755.4900000000001, 766.8090000000001], [766.8090000000001, 792.3600000000001], [792.3600000000001, 804.8000000000002], [804.8000000000002, 829.6300000000002], [829.6300000000002, 841.7060000000002], [841.7060000000002, 853.9200000000003], [853.9200000000003, 875.4400000000003], [875.4400000000003, 890.5190000000002], [890.5190000000002, 901.5300000000002], [901.5300000000002, 912.1500000000002], [912.1500000000002, 922.2450000000002], [922.2450000000002, 932.4200000000002], [932.4200000000002, 942.6800000000002], [942.6800000000002, 961.3000000000002], [961.3000000000002, 972.1700000000002], [972.1700000000002, 982.2150000000001], [982.2150000000001, 992.5000000000001], [992.5000000000001, 1006.8830000000002], [1006.8830000000002, 1016.9800000000001], [1016.9800000000001, 1028.9], [1028.9, 1041.5300000000002], [1041.5300000000002, 1052.1100000000001], [1052.1100000000001, 1065.14], [1065.14, 1076.0800000000002], [1076.0800000000002, 1086.487], [1086.487, 1098.43], [1098.43, 1109.0], [1109.0, 1120.9], [1120.9, 1131.7030000000002], [1131.7030000000002, 1142.2900000000002], [1142.2900000000002, 1153.2800000000002], [1153.2800000000002, 1164.0300000000002], [1164.0300000000002, 1175.8100000000002], [1175.8100000000002, 1186.4750000000001], [1186.4750000000001, 1200.0400000000002], [1200.0400000000002, 1212.1100000000001], [1212.1100000000001, 1231.7800000000002], [1231.7800000000002, 1250.3020000000001], [1250.3020000000001, 1263.41], [1263.41, 1276.18], [1276.18, 1287.2], [1287.2, 1297.23], [1297.23, 1313.42], [1313.42, 1324.39], [1324.39, 1337.88], [1337.88, 1350.0400000000002], [1350.0400000000002, 1373.39], [1373.39, 1383.8680000000002], [1383.8680000000002, 1394.4800000000002], [1394.4800000000002, 1407.3600000000004], [1407.3600000000004, 1417.5300000000004], [1417.5300000000004, 1429.4850000000004], [1429.4850000000004, 1442.2100000000003], [1442.2100000000003, 1454.7600000000002], [1454.7600000000002, 1465.5700000000002], [1465.5700000000002, 1482.68], [1482.68, 1494.72], [1494.72, 1505.94], [1505.94, 1519.8300000000002], [1519.8300000000002, 1532.247], [1532.247, 1545.0800000000002], [1545.0800000000002, 1557.2900000000002], [1557.2900000000002, 1574.1700000000003], [1574.1700000000003, 1586.3100000000004], [1586.3100000000004, 1596.6900000000005], [1596.6900000000005, 1630.7400000000005], [1630.7400000000005, 1642.8000000000004], [1642.8000000000004, 1656.2000000000005], [1656.2000000000005, 1669.6400000000006], [1669.6400000000006, 1680.3500000000006], [1680.3500000000006, 1694.1440000000007], [1694.1440000000007, 1704.3500000000006], [1704.3500000000006, 1715.0400000000006], [1715.0400000000006, 1728.5900000000006], [1728.5900000000006, 1742.1900000000005], [1742.1900000000005, 1754.2850000000005], [1754.2850000000005, 1765.2600000000004], [1765.2600000000004, 1779.4300000000005], [1779.4300000000005, 1791.4200000000005], [1791.4200000000005, 1803.1500000000005], [1803.1500000000005, 1815.7200000000005], [1815.7200000000005, 1827.8400000000004], [1827.8400000000004, 1844.4300000000003], [1844.4300000000003, 1857.3100000000004], [1857.3100000000004, 1868.5300000000004], [1868.5300000000004, 1880.2500000000005], [1880.2500000000005, 1891.7610000000004], [1891.7610000000004, 1903.5400000000004], [1903.5400000000004, 1914.7000000000005], [1914.7000000000005, 1925.3300000000006], [1925.3300000000006, 1936.4600000000007], [1936.4600000000007, 1954.3760000000007], [1954.3760000000007, 1964.5350000000008], [1964.5350000000008, 1978.0900000000008], [1978.0900000000008, 1989.5510000000008], [1989.5510000000008, 2003.6900000000007], [2003.6900000000007, 2013.8950000000007], [2013.8950000000007, 2025.7320000000007], [2025.7320000000007, 2044.2390000000007], [2044.2390000000007, 2055.850000000001], [2055.850000000001, 2076.0700000000006], [2076.0700000000006, 2086.5360000000005], [2086.5360000000005, 2098.7400000000007], [2098.7400000000007, 2109.4200000000005], [2109.4200000000005, 2122.2400000000007], [2122.2400000000007, 2133.9900000000007], [2133.9900000000007, 2146.040000000001], [2146.040000000001, 2156.110000000001], [2156.110000000001, 2169.430000000001], [2169.430000000001, 2183.400000000001], [2183.400000000001, 2194.520000000001], [2194.520000000001, 2207.190000000001], [2207.190000000001, 2217.630000000001], [2217.630000000001, 2229.025000000001], [2229.025000000001, 2239.390000000001], [2239.390000000001, 2249.7000000000007], [2249.7000000000007, 2260.1700000000005], [2260.1700000000005, 2278.4500000000007], [2278.4500000000007, 2288.6500000000005], [2288.6500000000005, 2299.7100000000005], [2299.7100000000005, 2312.4800000000005], [2312.4800000000005, 2323.9700000000003], [2323.9700000000003, 2335.59], [2335.59, 2345.75], [2345.75, 2359.16], [2359.16, 2370.27], [2370.27, 2383.86], [2383.86, 2396.21], [2396.21, 2406.67], [2406.67, 2416.9410000000003], [2416.9410000000003, 2432.42], [2432.42, 2443.4300000000003], [2443.4300000000003, 2455.1000000000004], [2455.1000000000004, 2467.6600000000003], [2467.6600000000003, 2478.7400000000002], [2478.7400000000002, 2489.8500000000004], [2489.8500000000004, 2500.4700000000003], [2500.4700000000003, 2515.5600000000004], [2515.5600000000004, 2527.2300000000005], [2527.2300000000005, 2539.2590000000005], [2539.2590000000005, 2556.1900000000005], [2556.1900000000005, 2567.4200000000005], [2567.4200000000005, 2580.3000000000006], [2580.3000000000006, 2593.9100000000008], [2593.9100000000008, 2604.4500000000007], [2604.4500000000007, 2617.2600000000007], [2617.2600000000007, 2628.580000000001], [2628.580000000001, 2642.540000000001], [2642.540000000001, 2653.900000000001], [2653.900000000001, 2665.790000000001], [2665.790000000001, 2677.2000000000007], [2677.2000000000007, 2692.4400000000005], [2692.4400000000005, 2702.8000000000006], [2702.8000000000006, 2724.7300000000005], [2724.7300000000005, 2734.8000000000006], [2734.8000000000006, 2746.4000000000005], [2746.4000000000005, 2756.4800000000005], [2756.4800000000005, 2769.9200000000005], [2769.9200000000005, 2781.6200000000003], [2781.6200000000003, 2793.34], [2793.34, 2807.19], [2807.19, 2817.43], [2817.43, 2828.9199999999996], [2828.9199999999996, 2843.45], [2843.45, 2853.5699999999997], [2853.5699999999997, 2866.0849999999996], [2866.0849999999996, 2880.7299999999996], [2880.7299999999996, 2893.6499999999996], [2893.6499999999996, 2903.8499999999995], [2903.8499999999995, 2917.8699999999994], [2917.8699999999994, 2930.2499999999995], [2930.2499999999995, 2961.9699999999993], [2961.9699999999993, 3002.2899999999995], [3002.2899999999995, 3038.8999999999996], [3038.8999999999996, 3051.2099999999996], [3051.2099999999996, 3063.6599999999994], [3063.6599999999994, 3074.2499999999995], [3074.2499999999995, 3084.9699999999993], [3084.9699999999993, 3096.1599999999994], [3096.1599999999994, 3129.5299999999993], [3129.5299999999993, 3146.1399999999994], [3146.1399999999994, 3165.9699999999993], [3165.9699999999993, 3179.928999999999], [3179.928999999999, 3191.869999999999], [3191.869999999999, 3205.099999999999], [3205.099999999999, 3218.639999999999], [3218.639999999999, 3239.401999999999], [3239.401999999999, 3260.979999999999], [3260.979999999999, 3272.329999999999], [3272.329999999999, 3296.909999999999], [3296.909999999999, 3307.819999999999], [3307.819999999999, 3318.119999999999], [3318.119999999999, 3330.879999999999], [3330.879999999999, 3341.899999999999], [3341.899999999999, 3354.899999999999], [3354.899999999999, 3372.479999999999], [3372.479999999999, 3384.469999999999], [3384.469999999999, 3398.639999999999], [3398.639999999999, 3412.279999999999], [3412.279999999999, 3423.7699999999986], [3423.7699999999986, 3434.7399999999984], [3434.7399999999984, 3446.6999999999985], [3446.6999999999985, 3461.2699999999986], [3461.2699999999986, 3471.8799999999987], [3471.8799999999987, 3484.3699999999985], [3484.3699999999985, 3495.1299999999987], [3495.1299999999987, 3509.6699999999987], [3509.6699999999987, 3529.7949999999987], [3529.7949999999987, 3540.2919999999986], [3540.2919999999986, 3550.6399999999985], [3550.6399999999985, 3561.9099999999985], [3561.9099999999985, 3573.0499999999984], [3573.0499999999984, 3583.4199999999983], [3583.4199999999983, 3594.7199999999984], [3594.7199999999984, 3606.6199999999985], [3606.6199999999985, 3626.5769999999984], [3626.5769999999984, 3641.0299999999984], [3641.0299999999984, 3656.0899999999983], [3656.0899999999983, 3667.289999999998], [3667.289999999998, 3681.8399999999983], [3681.8399999999983, 3698.519999999998], [3698.519999999998, 3714.5299999999984], [3714.5299999999984, 3728.729999999998], [3728.729999999998, 3740.229999999998], [3740.229999999998, 3779.179999999998], [3779.179999999998, 3795.649999999998], [3795.649999999998, 3807.799999999998], [3807.799999999998, 3836.939999999998], [3836.939999999998, 3847.419999999998], [3847.419999999998, 3860.9599999999978], [3860.9599999999978, 3872.969999999998], [3872.969999999998, 3884.299999999998], [3884.299999999998, 3897.149999999998], [3897.149999999998, 3911.649999999998], [3911.649999999998, 3922.5199999999977], [3922.5199999999977, 3934.1799999999976], [3934.1799999999976, 3945.4999999999977], [3945.4999999999977, 3955.9999999999977], [3955.9999999999977, 3970.4099999999976], [3970.4099999999976, 3983.8699999999976], [3983.8699999999976, 4004.4599999999978], [4004.4599999999978, 4014.908999999998], [4014.908999999998, 4025.7299999999977], [4025.7299999999977, 4049.4099999999976], [4049.4099999999976, 4061.0799999999977], [4061.0799999999977, 4087.6799999999976], [4087.6799999999976, 4118.929999999998], [4118.929999999998, 4130.519999999998], [4130.519999999998, 4142.048999999998], [4142.048999999998, 4157.6489999999985], [4157.6489999999985, 4178.978999999998], [4178.978999999998, 4202.218999999998], [4202.218999999998, 4225.749999999998], [4225.749999999998, 4237.759999999998], [4237.759999999998, 4247.959999999998], [4247.959999999998, 4258.499999999998], [4258.499999999998, 4269.468999999998], [4269.468999999998, 4280.699999999998], [4280.699999999998, 4292.468999999998], [4292.468999999998, 4306.949999999998], [4306.949999999998, 4318.609999999998], [4318.609999999998, 4331.489999999998], [4331.489999999998, 4341.769999999998], [4341.769999999998, 4352.699999999998], [4352.699999999998, 4365.565999999998], [4365.565999999998, 4376.516999999998], [4376.516999999998, 4389.258999999998], [4389.258999999998, 4400.859999999998], [4400.859999999998, 4410.929999999998], [4410.929999999998, 4422.729999999998], [4422.729999999998, 4434.749999999998], [4434.749999999998, 4446.009999999998], [4446.009999999998, 4456.769999999999], [4456.769999999999, 4465.329999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [875, 1547, 3296, 4466]}
{"example_id": "mit097@@MIT6_042JS15_30_ipod", "text": ["PROFESSOR: Independent events are events that have nothing  to do with each other.  And needless to say, it's a lot easier to work with them  because you don't have to figure out  some weird interaction between two events that ", "do have something to do with each other.  Typical case where independent events come up  is, for example, you toss a coin five times,  and then you're about to toss a coin the sixth time.  Is there any reason to think that ", "what the coins did the first five times is going  to have any influence on the flip  of the coin for the sixth time?  Well, it's reasonable to assume not, ", "which is to say that the outcome of the sixth toss  is arguably independent of the outcome of all  the previous tosses.  OK. ", "Let's look at a formal definition  now in this short video of just what  is the technical definition of independent events.  So what we said is that they are independent if they have ", "nothing to do with each other.  What that means is that if I tell you that B happened,  it doesn't have any effect on the probability of A. That is,  the probability of A, given that B happened, ", "doesn't change the probability of A at all.  That's it.  Now this is one definition.  Maybe this is the more intuitive definition.  But another definition that's equivalent and is standard ", "is that two events are equivalent if the product  of their probabilities is equal to the probability  that they both happen, that is, the probability  of their intersection.  Now definition one and definition two ", "are trivial equivalent, just using the definition  of conditional probability.  And if you don't see that, this would be a moment  to stop, get a pencil and paper, and write down ", "the three-line proof of the equivalence of these two  equalities.  In fact, the three-line proof has this as the first line  and that as the second line.  So you could argue it's really just the middle line ", "that you're adding.  OK.  Definition two has the slight advantage that it always works,  whereas definition one implicitly  requires that the divisor-- remember probability of A given ", "B is defined as the probability of the intersection divided  by the probability B. It's only defined if the probability of B  is positive.  Whereas the second definition always works,  so we don't have to put a proviso ", "in about the probability of B being non-zero.  So that's the definition of independence.   Looking at this definition, what you can see immediately  is that it's completely symmetric in A and B. ", "Since multiplication is commutative  and intersection is commutative, which is A  and which is B doesn't matter.  And what that implies then is that A is independent of B  if and only if B is independent of A. ", "Now another fact that holds is that if the probability of B  happens to be zero, then vacuously B  is independent of everything-- even itself. ", "Which isn't important, but is a small technicality that's worth  remembering by that definition.  Now again, the intuitive idea that A and B have nothing ", "to do with each other is that A is independent of B means  that A is independent of whether or not B occurs.  That is to say, if A is independent of B, ", "it ought to be independent of the complement of B.  And that's a lemma that's also easily proved.  A is independent of B if and only  if A is independent of the complement of B. ", "It's a simple proof using the difference rule.  And again, I encourage you to stop  with a piece of paper and a pencil  and convince yourself that that follows with a one-line proof.  ", "ALBERT MEYER: We've looked at independence for two events.  What about when we have a bunch of events?  Well, in that case we want to look  at the idea of mutual independence.  So let's check that out. ", "I'll say that if I have n different events,  I'll say that they're mutually independent, intuitively.  If the probability that one of them occurs  is unchanged by which other ones happen to have occurred. ", "So expressed in conditional probability, which  is the way to make it precise, what we're really saying  is that events A1 through An are mutually independent when  the probability of Ai is equal to the probability of Ai, ", "given the intersection of any of the other  As as long as i is not one of them.  So take A1, A2, or A1, A2, A3, and so on. ", "And A5 is going to be independent of all  of those other intersections.  If we shift over to the other definition of independence ", "that we used for two sets, in terms of products,  you could say that n sets are mutually independent when  the probability of the intersection of any bunch ", "of them is equal to the product of the individual probabilities  of the events in the intersection.   Let's look at an example of mutual independence. ", "Maybe the simplest one is the one  of independent coin flips, which by definition are independent.  So the idea is that I will flip a coin a bunch of times. ", "And I will let Hi be the event that the ith  time I flip I get a heads.  So if you think about what's going on,  what happens on the fifth flip has ", "nothing to do with what happens on the first, fourth or seventh  flip.  There's no causal relationship between the flips  before or after flip five.  Flip five is an isolated event by itself. ", "And the fact that there were a bunch of heads before  or there will be a bunch of heads  afterward doesn't have any impact on the probability  that the fifth flip comes up with a head.  At least that's what we believe and that's the way ", "that we would model them.  So what that means, for example, is  that the probability of a head on the fifth toss  is equal to the probability of a head on the fifth toss given  that the first toss was a head and the fourth toss was a head ", "and the seventh toss was not a head.  This is the complement of H7.  So that would just be an example of one  of the many different conditional equations that ", "hold when you have mutual independence.  Let's look at an example.  Suppose that I flip a fair coin twice.  Now, the previous definition didn't require fairness at all ", "in the coin flipping.  But now I'm going to need it.  So that means that heads and tails are equally likely.  And suppose I flip the coin twice.  Well, let H1 be as before, the event that a head comes up ", "on the first flip.  And H2, the event that a head comes up on the second flip.  And let O be the event that there were an odd number  of heads in the two flips. ", "Now, I claim that O is independent of whether or not  there's a head on the first flip.  That may seem a little weird because O  depends on both the first flip and the second flip. ", "It's whether or not there are an odd number of heads there,  but nevertheless, I claim that whether or not  there are an odd number of heads is  independent of whether or not the first toss was a head. ", "Let's just check it using the official definition.  First of all, O is the event HT TH.  If I write out Hs and Ts, a pair of them ", "for what the results of the first and second flips were,  you get an odd number of heads exactly when there's first  a head and then a tail or first a tail and then a head, which ", "means that the probability of O is exactly a half.  Because the other two outcomes are  TT and HH, which is when you have an even number of heads. ", "Now, O into section H1 is saying that you  have an odd number of heads and the first toss is a head.  The only outcome that fits that description ", "is HT, which means that-- and the probability of HT  is a quarter-- so the probability of O intersection  H1 is a quarter.  O into section H1 is just a peculiar way ", "of saying you got a head and then you got a tail.  So that means that the probability of O intersection  H1 is a quarter.  And of course, that's equal to the probability of O, ", "which we decided was a half, and the probability of H1,  which of course is a half, because we  said the coin was fair.  So I've verified the condition for the independence of O ", "and H1, and therefore, I'm done.  But the weird thing to notice now  is that if you look at O, H1, and H2, the three of them, ", "they are not mutually independent.  Because in fact, if you know any two of them  you can figure out what the third one was.  But just explicitly in terms of conditional probabilities, ", "the probability of there being an odd number of heads,  given that the first toss was a head  and the second toss was a head, is 0,  because once you know H1 and H2 you ", "know exactly how many heads there were.  There were two.  And that's not odd.  So the probability of odd given H1 intersection H2  is 0, which is not equal to the probability of odd by itself, ", "which was a half.  So the three of them are not independent.  They're not mutually independent,  even though any two of them are because O and H1 are.  And obviously O and H2 are by symmetry. ", "And H1 and H2 to are coin tosses,  and they're independent.  So that leads us to the general idea of k-way independence.  And an example would be if you flip a fair coin k times, ", "let Hi be whether or not there's a head on the ith flip.  And you let O, again, be whether or not  there are an odd number of heads.  And by the same argument, you can  verify that any set of k of these events ", "are mutually independent.  But if you give me all k plus 1, then they are not independent.  In fact, any k of them will determine the k plus first one. ", "But any k among themselves will be mutually independent.  So that's why this notion of how independent a bunch of sets are  comes up, and this is how to count it. ", "So in general, events A1 through an arbitrary set of events  are k-way independent if any k of them  are mutually independent.  Pairwise, then, is just the case of two way independence. ", "And what we saw was the example that with k coin  flips the events odd and the outcomes  of head or not on H1 through Hk are k-way independent, ", "but not k plus one way independent.   By the way, now that we understand  what k-way independence is, mutual independence of n sets ", "is simply n-way independence.  But I just wanted to close with the remark  that checking with n events are mutually independent ", "means that you actually have to check  all the intersections equaling the products  of the individual events in the intersection. ", "So that there are two to the n possible collections  of subsets of A1 through An and you  have to check for each of them, that the intersection  of those ones that you chose is equal to the product ", "of their probabilities.  But of course, you don't need to check the empty selection.  And you don't need to check the single [? set ?],  so you just have to check the 2 to the n  equations corresponding to all the subsets of size ", "more than one.  So it's 2 to the n minus n plus 1 equations to check.  So in general, it's not going to be  easy to verify mutual independence by doing ", "this kind of a calculation.  And you usually arrive at it really  by assumption most of the time. "], "vid_duration": [11.81, 11.26, 10.03, 10.07, 11.571, 11.609, 10.09, 11.45, 10.21, 11.7, 13.59, 12.06, 11.637, 14.283, 11.18, 10.92, 10.16, 10.26, 10.599, 12.171, 13.31, 14.809, 10.951, 12.55, 10.769, 10.691, 12.7, 12.87, 12.104, 11.616, 13.34, 10.08, 11.44, 13.1, 10.842, 10.779, 10.649, 10.539, 11.011, 10.349, 12.38, 10.961, 11.3, 10.359, 12.041, 11.28, 10.2, 11.38, 11.73, 14.0, 14.1, 11.61, 12.28, 13.22, 10.839, 11.111, 10.24, 10.37, 12.922, 11.048, 10.72, 5.25], "stet": [[0, 11.81], [11.81, 23.07], [23.07, 33.1], [33.1, 43.17], [43.17, 54.741], [54.741, 66.35], [66.35, 76.44], [76.44, 87.89], [87.89, 98.1], [98.1, 109.8], [109.8, 123.39], [123.39, 135.45], [135.45, 147.087], [147.087, 161.36999999999998], [161.36999999999998, 172.54999999999998], [172.54999999999998, 183.46999999999997], [183.46999999999997, 193.62999999999997], [193.62999999999997, 203.88999999999996], [203.88999999999996, 214.48899999999995], [214.48899999999995, 226.65999999999994], [226.65999999999994, 239.96999999999994], [239.96999999999994, 254.77899999999994], [254.77899999999994, 265.72999999999996], [265.72999999999996, 278.28], [278.28, 289.049], [289.049, 299.73999999999995], [299.73999999999995, 312.43999999999994], [312.43999999999994, 325.30999999999995], [325.30999999999995, 337.41399999999993], [337.41399999999993, 349.0299999999999], [349.0299999999999, 362.3699999999999], [362.3699999999999, 372.4499999999999], [372.4499999999999, 383.8899999999999], [383.8899999999999, 396.9899999999999], [396.9899999999999, 407.8319999999999], [407.8319999999999, 418.6109999999999], [418.6109999999999, 429.2599999999999], [429.2599999999999, 439.79899999999986], [439.79899999999986, 450.8099999999999], [450.8099999999999, 461.1589999999999], [461.1589999999999, 473.5389999999999], [473.5389999999999, 484.4999999999999], [484.4999999999999, 495.7999999999999], [495.7999999999999, 506.1589999999999], [506.1589999999999, 518.1999999999999], [518.1999999999999, 529.4799999999999], [529.4799999999999, 539.68], [539.68, 551.06], [551.06, 562.79], [562.79, 576.79], [576.79, 590.89], [590.89, 602.5], [602.5, 614.78], [614.78, 628.0], [628.0, 638.839], [638.839, 649.95], [649.95, 660.19], [660.19, 670.5600000000001], [670.5600000000001, 683.4820000000001], [683.4820000000001, 694.5300000000001], [694.5300000000001, 705.2500000000001], [705.2500000000001, 710.5000000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [214, 711]}
{"example_id": "mit097@@MIT6_042JS15_09_ipod", "text": ["PROFESSOR: So we're going to talk  about state machines, which is a topic  that you're going to see in many further courses,  because state machines model step by step processes. ", "And of course, if you think about a computation, normally  the way you think about it is that it's doing instructions,  step by step, one after another, until it finally  reaches termination. ", "Likewise, various digital circuits  move through stages or states until they  produce a final answer.  So state machines come up in at least those circumstances ", "and in many others.  And the general model of state machine  involves the idea that you can give it input  and it responds to them, but we don't really  need that for our purposes.  So let's look at our example of a state machine. ", "Here's maybe a particular simple one.  This is a description of a state machine that counts to 99.  So the circles are indicating what its states are, and we've ", "named them from 0 through 99.  And then there's a final state called overflow,  and that funny arc is an indication  that if you're in overflow mode and you ", "make another step by following the arc,  you get back to overflow mode.  But if you're in 0, you can make a step to 1.  And if you're in 1, you can make a step to 2, and so on.  So starting off at the start state, which is generally ", "indicated by that double mark.  So to indicate where to start.  Then the description of this machine, ", "consistent in complete description is a set of states  which are pictured as 0 through 99 plus overflow,  a set of transitions which are indicated  by the arrows, which is how one state can ", "move to another state.  And the transitions can be summarised  by saying that there of the form of i  to i plus 1 for i between 0 and 99. ", "And then there's a 99 transition to overflow,  and once you're in overflow, you stay in overflow.  So the picture at the top is saying exactly the same thing  as we've said here in mathematical notation, ", "explicitly describing what the transitions are.  So this is a machine that if you really build something  to behave this way, it wouldn't be much use,  because once it's overflowed, it's dead,  because it stays there. ", "Real machine to be useful would have a reset transition, which  took overflow back to zero.  But this illustrates the basic idea.  So let's look at a fun example from a Die Hard movie. ", "I've forgotten which one it was.  But there was one with Bruce Willis and Samuel Jackson  playing a detective and a friend that he  meets who helps him deal with a bad man, ", "as is the case in all these movies.  This time, the bad man's name is Simon.  And what Simon says to them as they  stand behind the fountain in the park shown  on the previous slide is that on the foundation, ", "there should be two jugs, do you see them?  A five gallon and a three gallon.  Fill one of these jugs with exactly four gallons of water  and place it on the scale, and the timer will stop. ", "The timer and the scale are not shown in that picture,  but there's a scale and a timer nearby.  You must be precise, one ounce more or less  will result in detonation.  If you're still alive in five minutes, we'll speak. ", "OK.  So let's think about formalizing this as a state machine  to see what's going on.  So but first of all, to understand the specification ", "informally.  What there is a three gallon jug and a five gallon jug  that's capable of holding water, and an unlimited supply  of water that you can get from the fountain. ", "And the basic moves that you can make--  So with this set up, the kind of moves that you can make  would be, say you fill up the three gallon jug with water, ", "and then you could pour the three gallon jug  into the five gallon jugs.  And the three gallon jug was empty  and the five gallon jug you knew had exactly three gallons  in it.  ", "And then you can do other things like empty a jug and fill a jug  and empty them into each other.  So let's model this as a state machine.  And the first decision we need to make ", "is what's the state going to be.  Well, the state-- the obvious model for the state  is the amount of water in each of the jugs.  So b is the amount in the big jug  and l is the amount the little jug. ", "And what we know about b and l is  that they're going to be some amount between 0 and 5 for b,  and 0 and 3 for l.  We're going to quickly realize that we ", "need them to be integers, but off hand we  can allow them to be real numbers.  Because after all, you could just  pour some arbitrary amount of water  into the big jug, any amount that it'll ", "hold between 0 and 5.  Although, that'll be dangerous, because as soon as  you do that, you're going to lose track of exactly how  much is in there and you won't know when  you have four gallons or not. ", "So let's formalize the possible moves that we can have.  So first of all, the start state is 0,0,  because we start with both jugs empty.  And then what are the possible transitions ", "of how b and l moves?  Well, let's see.  The fill the little jug move amounts  to saying that if you have an amount of b in big  and l in little, then you can make a transition called ", "fill the little jug into b, and big is still unchanged,  and 3 in little for l less than 3.  I'm going to forbid the vacuous move where ", "the little jug is already full and you try to fill it.  That doesn't count, so l has to be less than 3,  you can make it 3 by filling the little jug.  Similarly, you could fill the big jug if b is less than 5. ", "Then you can turn it into 5 by filling it.  And then you can empty the little jug, which is easy.  If you go from b, l you go to b, 0.  And likewise, you can empty the big jug. ", "Those are the easy moves.  A slightly more complicated move is pour the big jug  into the little jug.  Well if there's no overflow, what that means  is that there's l in the little jug and b in the big job. ", "And after you've poured the big jug into the little jug,  there's b plus l in the little one,  and nothing in the big one.  But let's be careful here about what exactly--  we're doing math, we're not sort of-- we're ", "trying to get away from the metaphor.  So what is no overflow means?  It simply means that b plus l will fit.  b plus l is less than or equal to 3.  All right.  What's the other case of pouring the big jug ", "into the little jug?  Well that's when b plus l won't fit, in which case,  you pour into the little jug.  It's got l, so you pour in 3 minus l to fill it up. ", "And then what's left in b is b minus the 3 minus little l  that you poured.  So that the other wise case, when there is overflow.  And similarly, there are moves for pouring the little jug ", "into the big jug.  So that then is a formal specification  of the Die Hard machine and the moves  that we're going to allow.  Now, you could allow other moves like randomly ", "pouring out a little water, or randomly filling  up a little water.  But if you did that, again, you lose  track of how much water is in the jug.  So these are the only safe moves.  And they're the only ones we're going to model. ", "All right.  So let's go back to Simon's challenge.  He wants to disarm the bomb by getting exactly four  gallons of water in the jug and measure it on the scale, ", "or things will blow up.  And how do you do it?  Well, why don't you take a moment  to think about it before I proceed ", "to the next set of slides or before you let me proceed.  But just to understand the rules again,  watch the work here's how.  We're going to start off with both jugs empty. ", "So we start off in state 0,0, and the first move  is going to be to fill the big jug, which  takes us to state 5, 0.  Where the big jug has 5 and the little jug is still empty. ", "Then we're going to pour from the big into the little.  So now, the little jug has 3.  We're filling up the little one.  That leaves two in the big jug. ", "Now we're going to empty the little one,  we still have 2 left in the big one.  And now we're going to pour from the big one  into the little one, so the little one has 2 gallons ", "and the big one is empty.  Now, we fill the big jug, and there's still  2 gallons in the little one and 5 gallons of the big one.  Now we pour off from the five gallon jug until the one gallon ", "jug is full, that's removing the 1 gallon that the 3 gallon jug  still has capacity for.  We reduced to full 2 gallons in the little jug,  and four gallons, our target in the big jug. ", "So we've accomplished it.  And we're done.  So the bomb doesn't go off.  All right.  So the point of this exercise is really just  to practice how the moves work and what the states are, ", "but the questions I want to raise  is suppose that we want to have a Die Hard once  and for all scenario, in which we're  tired of the remakes of these movies. ", "And we proposed that in the next movie,  that Simon, if he's still around,  offers an alternative challenge, where  instead of a three gallon and a five gallon jug, ", "there's a three gallon jug and a nine gallon jug.  And now the question is, can you get four gallons  into the big jug by pouring back and forth with rules ", "like these, or can't you?  And can you prove it?  Well my guess is that you probably  can figure out what's going on, because what's happening ", "is if you start off with nothing in either jug,  and you do these moves of filling up a jug  and pouring one jug into another,  you'll discover that the amount of water in any jug ", "is always divisible by 3.  This is a preserved invariant.  Any state that you can get to, starting off from 0,0,  3 will divide the number of gallons in each jug. ", "We could state it this way.  There's a property of states, property of b and l,  which is the state, which is that 3 divides  b-- that vertical line is a shorthand ", "for the symbol divides.  So three divides b, or b is a multiple of 3.  3 divides l.  Synonym, l is a multiple of 3.  And the claim is that that's always going to be true. ", "So in case that's not obvious, you  might not have all the rules in your head.  Let's just take a look at one of the more complicated rules.  This was the rule where you're pouring  the big jug into the little jug up ", "until the little jug is full.  And that transition is that if you're in state b,  l, you move to b minus 3 minus l, and 3. ", "And if you look at this now, clearly if 3 divides both b  and l, both components of the state  you're at, then in the new state,  well 3 obviously divides the contents ", "of the little jug, which is 3.  But three also divides the contents  of the big jug, which is a multiple of 3, namely b  minus 3, which is a multiple of 3 minus w, ", "which is a multiple of 3.  When you take a linear combination of multiples of 3,  you get a multiple of 3.  And you look at all the other transitions,  and they check equally well.  If you're in a state b, l, and you ", "move to a new state b prime, l prime, if 3 divides b and l,  then 3 divides b prime and l prime.  So this is what's called a preserved invariant. ", " And of course the corollary is that in the Die Hard once  and for all game with the 3 gallon jug and the 9  gallon jug, you can't get to any state of the form 4, x, ", "because 4 is not divisible by 3, and therefore Bruce  is going to die.  Now what we've illustrated here is an argument  that's known as Floyd's Invariant Principle, ", "and it's really nothing but induction reformulated  for state machines.  The statement of what is invariant principle  is that we're going to define a preserved invariant ", "as a property of states.  And a preserved invariants means it  has the property that if you're in a state that has property p,  and it's possible to make a single transition to state r, ", "then r will also have property p.  This is just like the induction step.  We have to prove that p n implies p of n plus 1.  So if you have a preserved invariant, ", "then if the property holds at the start state,  then it's obvious that the property  will hold for all of the states that you can possibly get to. ", "That p of r will hold for all reachable states.  And you can prove this by induction  on the number of states, but I think  it's clear that if you have a property that you begin with,  and it doesn't change making a step,  it's never going to change. ", "And that's all that Floyd's invariant principle states.  So in particular, since the property p  holds in all reachable states, if there  is any final state which the machine reaches, ", "then p is going to hold in that state.  And what we saw was-- we're using the word preserved  invariant to distinguish the definition here ", "from another usage that's co-opted the word  invariant to mean a property that's true in all states.  And while it's nice to know that some property is ", "true in all states, the way you prove  that is by having a preserved invariance.  You want to distinguish the two.  Technically if you look at this, the predicate  that's always false is a preserved invariant. ", "Because of the condition, as usual the way implication  works.  If the antecedent is false, then the entire implication is true.  So if you're always false, then it's always the case ", "that if false held in a state, which it never does, then  it has to hold in any state you can get to,  so that implication is true.  So just remember that preserved invariants that are constantly ", "false exist, they are good preserved in variance.  But they're not what other people would call an invariant.  We use preserved invariance to prove that a property is ", "true in all states.  It's a methodology.   So let's do one more example to wrap this up.  Suppose I have a robot on a grid, the integer grid, ", "and we can think then of the coordinates  of the integer as a pair of-- the coordinates of the robot  as the coordinates of the square that it's in,  a pair of non-negative integers. ", "Now the way that this robot can move  is we can make a diagonal move in one step.  So it could move one step to the northeast or southeast  or northwest or southwest and that's it. ", "And the question I want to ask is,  suppose you start the robot off at the origin, at 0,0.  Is there some way that it can wander around,  following its moves, and get to a next state ", "where it's moved 1 square over?  That is, it gets to the square 0,1.  The answer to that is settled again by a preserved invariant. ", "I don't know whether it's obvious to you yet,  but it will be in a moment.  I'm claiming you can't get to the square 0,1,  and the reason is that there's are preserved invariant ", "of that set of robot moves, namely  the sum of the coordinates is even is an invariant.  If the sum of the coordinates is even, it stays even. ", "And why is that?  Well, any move adds plus or minus 1  to the coordinates of both x and y. ", "Maybe x and y both go up by 1, in which  case, the sum of x and y increases by 2.  So if it was even, it stays even,  or they both go down by 1, or maybe one goes up ", "and the other goes down, in which case, the sum  doesn't change in every case.  If x plus y was even, it stays even.  As a matter of fact, if it was odd, it stays odd. ", "Moves actually preserve the parity of x plus y.  But the invariant is that x plus y is even.  Now, what else is the case.  Well 0,0-- 0 plus 0 is 0, which is even. ", "And so we're in Floyd invariant principal case,  where all the positions you can get to from the origin 0,0,  which has an even sum, have to have an even sum. ", "And since 1 plus 0 is odd, you can't get to that square, 1,0.  It's not reachable. ", " So the parity invariant of the diagonally moving robot  will set us up for an analysis of the 15 puzzle game. ", "That's this logo that we've had on every slide in 6042  so far with 6 blank, 4, 2, on the diagonal.  This is a game where there are these little numbered ", "tiles that slide into the blank square,  and the question is how to permute--  how to get from one permutations of the numbers to another.  It turns out that the analysis of that game ", "depends on a parity invariant reminiscent  of a slightly more sophisticated than the diagonally  moving robot.  Let's look at one more example of using the invariant ", "to verify a little algorithm that actually will be quite  important as the course progresses,  and that is fast exponentiation.  So in this set up, a is a real number  and b is a non-negative integer. ", "I want to compute the b power of a.  Let's say b was 128, and I want to compute the 128th power  of some real number a. ", "Well, I can multiply a by itself 127 times, that would work  fine.  But you think about it, suppose I square a and then I square it  again, and I square it again, then in about eight squarings, ", "instead of 99 multiplications, I'm  going to get to 8 of the 128th.  Now if b is not a power of two, you adjust it slightly, ", "and using that idea, you can compute the bth power of a much  more rapidly than if you just naively  multiplied out b minus 1 times. ", "So let's look at the pseudocode for this algorithm.  Here, XYZ in our temporary registers y and z, hold-- y, z, ", "and r all hold integers.  And x holds this real number a.  And you can read the code if you wish  but in fact, I'm going to immediately jump  to the slightly more abstract and easier ", "to understand version of it as a state machine.  So what matters about this fast exponentiation algorithm  as a state machine is that first of all,  there are three states to real numbers, ", "and a non-negative integer.  And the start state is going to be that the number a is  in the first register, or in the first location, ", "first coordinate of the states.  1 is the real number in the second coordinate,  and b the target exponent, is the non-negative integer  in the third component. ", "The transitions are going to be as follows.  Here's a simple one.  If I have an amount x in the first location, y  in the second location, z in the third, then if z is positive ", "and even, then I'm going to square x, leave y  alone, and divide z by 2.  And that's the new state that I get. ", "On the other hand, if z is odd and positive,  then I'm going to square x, multiply y by x,  and again take the quotient of z, divide z by 2. ", "OK.  Why does this state machine do fast exponentiation,  why is it correct?  And the insight is that there's a preserved invariant  of this machine.  And the preserved invariant is that y times x to the z ", "is always a to the b.  SO let's see how to verify that, that yx to the z  is equal to a to the b. ", "Let's just look at maybe the slightly more interesting  of the two transition rules, which  is when z is positive and odd, the xyz state ", "moves to a new state, indicated in green.  Where the new value of x is x squared, the new value of y  is xy, and the new value of z is z minus 1 over 2. ", "Remember, you went to the quotient of z divided by 2,  and when z is odd, that means z minus-- it's literally  z minus 1 over 2.  Well, do the new values satisfy the invariant ", "if I plug-in the green values of x squared for y and xy  for x-- I'm sorry, x squared for x, xy for y, ", "and z minus 1 over 2 for z?  Well let's see what happens.  If I take the new value of y, which is xy, ", "and I multiply it by the new value of x, which is x squared,  raised to the new value of z, which is z minus 1 over 2.  Let's do a little algebraic simplification of that. ", "Well, the x squared to the z minus 1 over 2  becomes x to the z minus 1.  And I'm just carrying over the xy.  And then that simplifies to simply y times x times x ", "to the z minus 1, or yz to the z, which we assumed  was equal to a to the b, so sure enough, the new values of x, y,  and z satisfy the invariant. ", "It's a preserved invariant, and an even simpler argument  applies to the other transition, when z is positive and even.  So we verified that this is a preserved invariant. ", "Now at the start, remember, we start off with the real number  a in register x, the real number b in z, and the real number ", "1 in y, which is the accumulator.  And 1 times a to b is equal to a to b.  So this is a-- this preserved invariant  is true of the start state. ", "That means by Floyd's Invariant Principle,  that it is true at this the final state,  if and when the thing stops.  Well, when does this machine stop? ", "As long as z is positive, it can keep moving.  So it gets stuck when z is 0?  What happens if it ever gets to z is 0?  If it gets stuck, then the invariant says that yx to the 0 ", "has to equal a to the b.  But of course, yx to the 0 is nothing but y.  And what we conclude is, that sure enough,  this machine leaves the desired exponential value ", "in the register y, which is where we get the answer.  And that's why this algorithm is correct.  Now another aspect of what's going on here ", "is proving that the algorithm does terminate.  So let me just say a word that Floyd distinguished  sort of these two aspects of program correctness  that typically come up. ", "One is showing that if you get an answer, it's correct,  and that's what we just did.  If this machine stops, if it ever gets to the case  where z is 0, then y has the right answer. ", "But we haven't proved that it stops.  So we've shown that it's partially  correct like a partial function.  It might not be defined everywhere,  we haven't shown that yet, but when it is defined, ", "if gives the right answer.  The other aspect of correctness is termination,  showing in effect, that the function is total,  that the program always does stop.  Well in this case, there's an easy way ", "to see why it always stops.  Because at every transition, z is being halved or more.  z is a non-negative integer valued variable. ", "And since we're halving it, or making  it even smaller than half of it at every step,  it means that since it starts with the value z, ", "it can't get smaller, more than log to the base 2 of b times,  because by then, it would have hit 0.  And so we can be sure that this machine  makes it most log to the base 2 of b transitions. ", "And then it has to get stuck at the only place it  can get stuck, which is when z equals 0.  And there is a picture of my friend, an early colleague, ", "Bob Floyd, whom I met at the very beginning of my career  at Carnegie Mellon University.  We worked together for about one year  before he went off to Stanford. ", "And you can read much more about his life  in a warm and detailed eulogy written  by his best friend, Don Knuth. ", "Floyd won the Turing Award for his major contributions,  both to program correctness and to programming language  parsing. ", "  The technique of derived variables  comes up in analyzing state machines. ", "So let's just take a quick look at it together.  So a derived variable is simply a function  on the states of a state machine that assigns some value ", "to the states.  So it's just that kind of a function mapping.  If the values happen to be, say, the non-negative integers,  it's called non-negative integer value, ", "but it could be real value, complex value,  and even take on other kinds of odd kinds of values,  not necessarily numerical.  No pun there-- not odd numbers, but unusual values. ", "So let's look at the example of the robot on the grid.  The states were pairs of non-negative integers giving  the coordinates of where the robot was.  And one of the derived variables that we ", "found was real useful was the sum  value, sigma, of a state, which is defined to be x plus y.  And this would be a non-negative integer ", "valued derived variable.  So the word \"derived\" comes because we're making it up.  It's not part of the specification  of the state machine or part of the program that ", "defines the state machine.  So in the robot example, the actual states  were composed of the two coordinates x and y,  but the derived variable that we made up ", "was their sum of signal.  Another useful derived variable for that robot example  was the parity of sigma, whether or not ", "the number was even or odd.  So sigma is a 0, 1 valued variable,  which takes the value 0 if the sum is even ", "and 1 if the sum is odd.  So in the case of fast exponentiation,  we looked at the actual variable z, ", "which was part of the invariant and a crucial part  of the program.  And what we noticed about z was that z  was a strictly decreasing and natural number valued variable. ", "As a matter of fact, we noticed that it halved at each step.  But its values were non-negative integers,  and it's strictly decreasing at every step. ", "So that implies by the Well Ordering Principle  that it will take a minimum value.  And what we know about the minimum value of a strictly ", "decreasing variable is that the algorithm is stuck,  because once z has reached its minimum value,  if the machine took another step, ", "then it would get smaller.  So it means that the algorithm has to terminate.  So this gives you a general methodology  for proving termination-- find a non-negative integer valued ", "strictly decreasing variable guarantees the program stops.  As a matter of fact, we can say sometimes  how long it will take for the program to stop.  As we saw with fast exponentiation, ", "it took not z, which was the obvious bound,  but in fact, log of z, because z not only went down  at every step, it got halved at every step.  So in general, the concept of a strictly decreasing variable ", "is one-- as shown here-- that at every step of the state  machine, at each transition, it gets strictly smaller.  A related idea is a weakly decreasing variable. ", "These are not necessarily useful for proving termination,  but they are often useful, as you'll  see as we progress through the term-- examples ", "where it helps you analyze the behavior of the algorithm.  So a weakly decreasing variable is one which goes down  or stays constant.  It never gets larger. ", "So if we looked at the example of sigma,  the sum of the coordinates, that's  up and down all over the place.  It's neither increasing nor decreasing.  The other extreme is the parity variable ", "pi, which was the 0 or 1 according to whether  or not the sum of the coordinates was even or odd.  And pi is a constant, and that means  that it's both weakly increasing and weakly ", "decreasing in the degenerate sense  that weakly increasing is allowed to stay the same.  In fact, something is weakly increasing and weakly  decreasing if and only if it's a constant. ", "By the way, we used to call weakly decreasing variables  \"non-increasing,\" which is the standard terminology  in the field.  In calculus, you talk about non-increasing functions. ", "And we just found that it caused a lot of confusion,  because you have to remember that non-increasing is not  the same as not increasing. ", "So there's an example of a function that  is not increasing, but it's certainly not non-increasing.  And if that didn't register, I'll let you think about it. ", "By the way, this method of proving termination  by finding a strictly decreasing natural number  valued variable generalizes straightforwardly  to a variable which takes on values from a well-ordered set ", "of real numbers.  Remember, a well-ordered set of real numbers,  one of the definitions of it is that it's  a set of numbers where it's impossible to find  an infinite decreasing sequence of values-- ", "w0 less than w1 less than w2 less than w1 going on forever.  If that can't happen, then the set is called well ordered. ", "Of course, the non-negative integers  are the most obvious basic case, but there  are a bunch of others described in the notes.  And in general, the termination principle ", "is that if you can find a strictly decreasing  variable of derived variable whose values always come  from a well-ordered set, that also ", "is a way to prove termination.  That's going to guarantee termination for the same reason  that the variable will have to take a minimum value.  That's the other definition of well ordered. ", "And when it does, the machine can't move anymore. "], "vid_duration": [11.53, 10.13, 11.73, 12.46, 11.81, 13.32, 14.7, 10.12, 12.1, 10.36, 12.93, 11.83, 13.6, 13.06, 11.225, 10.335, 13.55, 10.57, 12.34, 11.36, 10.9, 10.869, 11.381, 10.91, 10.91, 11.97, 11.96, 12.06, 10.72, 11.87, 10.09, 12.11, 11.849, 11.551, 11.67, 13.16, 10.84, 11.69, 10.68, 11.55, 12.0, 12.05, 11.254, 10.435, 14.701, 13.76, 11.69, 11.27, 10.74, 12.64, 12.11, 13.2, 12.876, 11.014, 11.85, 11.98, 11.18, 11.05, 10.52, 11.55, 11.625, 13.085, 12.64, 10.38, 12.34, 12.34, 13.02, 11.57, 12.32, 10.27, 10.75, 11.14, 11.6, 12.22, 10.66, 12.55, 10.77, 11.415, 12.015, 11.7, 11.57, 10.26, 10.5, 10.96, 11.18, 15.19, 12.62, 10.37, 11.637, 10.293, 11.49, 12.33, 11.54, 10.33, 13.58, 10.11, 10.45, 10.93, 11.43, 12.82, 12.63, 12.3, 13.83, 10.5, 14.08, 13.49, 10.4, 10.16, 10.5, 10.92, 10.17, 10.41, 11.36, 13.6, 10.15, 11.57, 10.32, 11.36, 10.25, 14.82, 11.82, 13.41, 10.67, 11.31, 10.613, 10.607, 13.16, 11.02, 12.9, 11.95, 10.38, 11.7, 10.62, 11.79, 10.219, 11.051, 13.35, 11.13, 11.58, 11.05, 10.77, 12.47, 10.46, 11.287, 12.438, 10.115, 10.87, 11.8, 14.129, 11.601, 12.1, 12.59, 10.88, 12.62, 12.86, 12.31, 10.769, 10.171, 11.81, 10.8, 13.8, 12.26, 10.59, 10.88, 12.26, 10.79, 2.74], "stet": [[0, 11.53], [11.53, 21.66], [21.66, 33.39], [33.39, 45.85], [45.85, 57.660000000000004], [57.660000000000004, 70.98], [70.98, 85.68], [85.68, 95.80000000000001], [95.80000000000001, 107.9], [107.9, 118.26], [118.26, 131.19], [131.19, 143.02], [143.02, 156.62], [156.62, 169.68], [169.68, 180.905], [180.905, 191.24], [191.24, 204.79000000000002], [204.79000000000002, 215.36], [215.36, 227.70000000000002], [227.70000000000002, 239.06], [239.06, 249.96], [249.96, 260.829], [260.829, 272.21000000000004], [272.21000000000004, 283.12000000000006], [283.12000000000006, 294.0300000000001], [294.0300000000001, 306.0000000000001], [306.0000000000001, 317.9600000000001], [317.9600000000001, 330.0200000000001], [330.0200000000001, 340.7400000000001], [340.7400000000001, 352.6100000000001], [352.6100000000001, 362.7000000000001], [362.7000000000001, 374.8100000000001], [374.8100000000001, 386.6590000000001], [386.6590000000001, 398.2100000000001], [398.2100000000001, 409.8800000000001], [409.8800000000001, 423.04000000000013], [423.04000000000013, 433.8800000000001], [433.8800000000001, 445.5700000000001], [445.5700000000001, 456.2500000000001], [456.2500000000001, 467.8000000000001], [467.8000000000001, 479.8000000000001], [479.8000000000001, 491.85000000000014], [491.85000000000014, 503.10400000000016], [503.10400000000016, 513.5390000000001], [513.5390000000001, 528.2400000000001], [528.2400000000001, 542.0000000000001], [542.0000000000001, 553.6900000000002], [553.6900000000002, 564.9600000000002], [564.9600000000002, 575.7000000000002], [575.7000000000002, 588.3400000000001], [588.3400000000001, 600.4500000000002], [600.4500000000002, 613.6500000000002], [613.6500000000002, 626.5260000000002], [626.5260000000002, 637.5400000000002], [637.5400000000002, 649.3900000000002], [649.3900000000002, 661.3700000000002], [661.3700000000002, 672.5500000000002], [672.5500000000002, 683.6000000000001], [683.6000000000001, 694.1200000000001], [694.1200000000001, 705.6700000000001], [705.6700000000001, 717.2950000000001], [717.2950000000001, 730.3800000000001], [730.3800000000001, 743.0200000000001], [743.0200000000001, 753.4000000000001], [753.4000000000001, 765.7400000000001], [765.7400000000001, 778.0800000000002], [778.0800000000002, 791.1000000000001], [791.1000000000001, 802.6700000000002], [802.6700000000002, 814.9900000000002], [814.9900000000002, 825.2600000000002], [825.2600000000002, 836.0100000000002], [836.0100000000002, 847.1500000000002], [847.1500000000002, 858.7500000000002], [858.7500000000002, 870.9700000000003], [870.9700000000003, 881.6300000000002], [881.6300000000002, 894.1800000000002], [894.1800000000002, 904.9500000000002], [904.9500000000002, 916.3650000000001], [916.3650000000001, 928.3800000000001], [928.3800000000001, 940.0800000000002], [940.0800000000002, 951.6500000000002], [951.6500000000002, 961.9100000000002], [961.9100000000002, 972.4100000000002], [972.4100000000002, 983.3700000000002], [983.3700000000002, 994.5500000000002], [994.5500000000002, 1009.7400000000002], [1009.7400000000002, 1022.3600000000002], [1022.3600000000002, 1032.7300000000002], [1032.7300000000002, 1044.3670000000002], [1044.3670000000002, 1054.66], [1054.66, 1066.15], [1066.15, 1078.48], [1078.48, 1090.02], [1090.02, 1100.35], [1100.35, 1113.9299999999998], [1113.9299999999998, 1124.0399999999997], [1124.0399999999997, 1134.4899999999998], [1134.4899999999998, 1145.4199999999998], [1145.4199999999998, 1156.85], [1156.85, 1169.6699999999998], [1169.6699999999998, 1182.3], [1182.3, 1194.6], [1194.6, 1208.4299999999998], [1208.4299999999998, 1218.9299999999998], [1218.9299999999998, 1233.0099999999998], [1233.0099999999998, 1246.4999999999998], [1246.4999999999998, 1256.8999999999999], [1256.8999999999999, 1267.06], [1267.06, 1277.56], [1277.56, 1288.48], [1288.48, 1298.65], [1298.65, 1309.0600000000002], [1309.0600000000002, 1320.42], [1320.42, 1334.02], [1334.02, 1344.17], [1344.17, 1355.74], [1355.74, 1366.06], [1366.06, 1377.4199999999998], [1377.4199999999998, 1387.6699999999998], [1387.6699999999998, 1402.4899999999998], [1402.4899999999998, 1414.3099999999997], [1414.3099999999997, 1427.7199999999998], [1427.7199999999998, 1438.3899999999999], [1438.3899999999999, 1449.6999999999998], [1449.6999999999998, 1460.3129999999999], [1460.3129999999999, 1470.9199999999998], [1470.9199999999998, 1484.08], [1484.08, 1495.1], [1495.1, 1508.0], [1508.0, 1519.95], [1519.95, 1530.3300000000002], [1530.3300000000002, 1542.0300000000002], [1542.0300000000002, 1552.65], [1552.65, 1564.44], [1564.44, 1574.659], [1574.659, 1585.71], [1585.71, 1599.06], [1599.06, 1610.19], [1610.19, 1621.77], [1621.77, 1632.82], [1632.82, 1643.59], [1643.59, 1656.06], [1656.06, 1666.52], [1666.52, 1677.807], [1677.807, 1690.2450000000001], [1690.2450000000001, 1700.3600000000001], [1700.3600000000001, 1711.23], [1711.23, 1723.03], [1723.03, 1737.1589999999999], [1737.1589999999999, 1748.76], [1748.76, 1760.86], [1760.86, 1773.4499999999998], [1773.4499999999998, 1784.33], [1784.33, 1796.9499999999998], [1796.9499999999998, 1809.8099999999997], [1809.8099999999997, 1822.1199999999997], [1822.1199999999997, 1832.8889999999997], [1832.8889999999997, 1843.0599999999997], [1843.0599999999997, 1854.8699999999997], [1854.8699999999997, 1865.6699999999996], [1865.6699999999996, 1879.4699999999996], [1879.4699999999996, 1891.7299999999996], [1891.7299999999996, 1902.3199999999995], [1902.3199999999995, 1913.1999999999996], [1913.1999999999996, 1925.4599999999996], [1925.4599999999996, 1936.2499999999995], [1936.2499999999995, 1938.9899999999996]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1558, 1939]}
{"example_id": "mit097@@MIT6_042JS15_33_ipod", "text": [" ALBERT MEYER: In the last lecture,  we spent time talking about the mean, or expectation,  and its properties, most important one being linearity.  But let's step back now and think about, ", "what is it that the mean means?  Why we care about it?  We have this intuitive idea that if you do things long enough,  if you keep experimenting with the same random variable ", "collecting its values, its long run average will  be about the same as its mean.  Now, we're going to try to make that more precise.  So we're going to talk about the topic of deviation  from the mean, or as I like to say, ", "what does the mean really mean?  Why do we care about it?  Well, let's look at an example that's  familiar to get a grip on the specific ideas  that we're interested in. ", "So suppose I toss a fair coin 101 times.  Then, I know that the expected number, since all the values  from zero through 101 are possible, and the middle value ", "is the expectation, it's 50 and 1/2 heads.  Now, I'm never going to get exactly 50 and 1/2 heads.  The probability in 101 flips of getting 50 and 1/2 heads ", "is zero because there's no way to flip 1/2 a head.  So you don't expect the expectation in that sense.  No given measurement, no given experiment  is going to yield the expectation. ", "The expectation is this thing that we expect  to come out on the average.  Well, we can ask, what's the probability  of getting as close as you could hope to get to the expectation? ", "Namely, what's the probability of getting exactly 50 heads?  And it's about 1/13.  Or if you ask, what's the probability  of getting either 50 or 51 heads, ", "being within plus or minus one of the expectation?  It's about 1/7.  OK, let's flip more coins and see what happens.  This time I'm going to flip 1001 coins. ", "And again, the expected number of heads is 500 and 1/2,  which I'll never get exactly.  The probability of getting exactly 500 heads is 1/39, ", "and the probability of getting within one of the expectation,  that is either 500 or 501 heads, is about 1/19.  Now, these numbers have gone down from the previous numbers. ", "Remember, it was about 1/7 and we've gone down to 1/19.  So it's actually we're less likely to be  within a fixed distance, within one of the expectation when ", "we flip more coins.  So as the number of tosses grows, the number of heads  gets less likely to be within any given fixed  distance of the mean.  But things get better when we start looking at percentages. ", "So what's the probability of being  within 1% of the mean if I toss 1,001 coins?  Well, 1% of 1,001 is about 10, so we're talking about 1% ", "of the 1,001.  And the probability of being within 10 of 500.5,  that is to say the probability of being within 510 and 490, ", "is about 0.49.  It's almost 50-50, which is not really so bad.  So we have a 50/50 chance of actually  being within 1% of the expected number when I flip 1,001 coins. ", "So what we can start to say is that when  we're trying to give the meaning to the mean,  if I let u be the standard abbreviation for expectation  of R-- I'm doing that just so it'll fit on the slide  nicely in formulas, so mu is the expectation of R-- ", "the basic question we're asking is two basic questions.  One is, what's the probability that the random variable is far  from its mean, mu?  You could phrase that as, what's the probability ", "that the distance from R to mu, the absolute value of R  minus mu is greater than some amount, x.  And the second question that we want to ask  is, what's the average deviation? ", "What's the expectation of the distance between R minus mu?  What's the expected value of r minus mu?  Now, of course, we're trying to make ", "sense of the meaning of the expectation,  in terms of the expectation of the distance between R  and this expectation.  So there's a little bit of circularity there,  but let's live with it and proceed. ", "Let's look at example to crystallize the ideas a little.  Let's look at two dice with the same mean.  The green die is going to be a standard fair die, in which ", "each of the numbers one through six  has an equal probability of showing up,  and its expected value is exactly  going to be the midpoint between one and six, or 3 and 1/2. ", "Now, suppose I look at a loaded die,  die two, which only throws a one or a six,  but with equal probability.  Then, it's expectation is also 3 and 1/2, by the same reasoning. ", "So here are these two different die.  One takes the values one through six equally likely,  and the other takes only the two values one and six,  but they have the same expectation. ", "So how do I capture the difference?  Well, if I look at the expected distance of the fair die  to its mean, I claim it's one and a half. ", "But the expected distance of the loaded die  from its mean-- same mean remember, 3 and 1/2--  is actually 2 and 1/2.  In fact, the second die is always exactly 2 and 1/2  from its expected value. ", "Let's look at the PDFs to get a grip on understanding  what's going on.  So here's the PDF for the fair die.   Over one through six the probability is 1/6, ", "so each of those green spikes, columns, is 1/6 high.  And their total is the probability ", "that the fair die takes one of those values one through six  with equal likelihood.  Now, the expected value is exactly  in the middle at 3 and 1/2. ", "And the average distance of these points--  well, you can see that a third of the time, you're  at distance 1/2, a third of the time, that  is when you take the values 2 and 5, ", "you are a distance exactly 1 and 1/2.  And another third of the time, you're at distance 2 and 1/2  when you take one and six.  And that averages out to the middle value of 1 and 1/2. ", "So the expected deviation, the expected distance,  of the fair die from its mean is 1 and 1/2.  On the other hand, for the loaded die, as we said,  it's always exactly 2 and 1/2 from its expected ", "value, which means its expected value is also 2 and 1/2.  So we can start to see the difference between these two  distributions and these two kinds of die. ", "Even though they have the same expectation, one of them  is more likely and has a greater expected distance  from its mean.  And the moral of this short piece ", "is that the mean alone is not a good predictor  of a random variable's behavior, as you might suppose.  One parameter, one number is not going  to capture the shape of a PDF, which gives you ", "more full information about the distribution of values  of a random variable.  And we need some more information  than just the expectation.  An especially, valuable extra piece of information ", "that's still well less than the overall shape  of the PDF of the random variable,  is knowing its probable deviation from its mean.   PROFESSOR: The simplest bound that a random variable differs ", "by much from its expectation is due to a guy named Markov,  a Russian probability theorist.  And this is Markov's bound that we're going to talk about.  Let's illustrate it with a memorable example of IQ. ", "In the MIT context, it may be a radical idea.  But IQ was this thing that was invented  for intelligence quotient in the late 19th century, I believe. ", "Might have been early 20th.  It was meant as an effort to break  the mold at Harvard of hiring the children of wealthy alumni. ", "And the idea was to have merit-based admissions.  And it was going to be some objective measure that  did not depend on social class of the ability that people had.  And Harvard was going to admit students ", "based on merit and their intelligence quotient.  So the original design of the intelligent quotient  by a bunch of psychologists was that the average was supposed  to be 100 over the whole population, which, ", "of course, is-- around here, there just  aren't very many people with an IQ of just 100.  Anyway, let's ask this extreme question. ", "Yes, around the elite universities,  there are a lot of people with IQs much higher than 100.  But what fraction of the population  could possibly have an IQ as high as 300? ", "Now, I'm not sure that an IQ of as high as 300  has ever been recorded.  But we're talking logically here.  Is it possible for a lot of people  to have an IQ of greater than or equal to 100?  And the answer is no. ", "You can't possibly have more than 1/3 of the population  have an IQ of 300, because if more than 1/3 had an IQ of 300,  then that third alone would contribute 1/3 of 300 ", "to the average, which would be greater than 100.  So you can't have more than 1/3 of the population  have an IQ of triple the expected value of the IQ. ", "So that's the basic bound.  So we can restate it this way.  The probability that a randomly chosen person  has an IQ greater than or equal to 100 we can say ", "is absolutely less than or equal to the expected value of IQ,  namely 100 divided by 300.  And just parameterizing it, if we ask, ", "what's the probability that the IQ is  greater than or equal to some amount x,  it's less than or equal to 100/x by exactly that reasoning.  And this is basically Markov's bound, ", "except there's one implicit fact that we're  using in deriving the previous identity, or inequality,  that IQ is bounded by 100.  Our logic was that you can't have more than population x ", "with an IQ of more than 100x, because that  would contribute x times 100/x, or more than 100  to the average.  And the average is only 100.  That's only a problem if there are no negative terms, ", "negative IQs, to offset the excess contribution  of the fraction of the population that  has this high IQ.  But we're implicitly using the fact that IQ is never negative. ", "IQ runs from zero up to unlimited amount.  But it's never negative.  And that means that that contribution  from the 1/3 of the population that has an IQ of over 300 ", "can't be offset by negative values.  It's there, and it messes up the average.  It forces the average up.  So we were using the fact that IQ is always non-negative.  And by this very same reasoning, I'm  not going to belabor you with a more formal proof. ", "There's a trivial one in the text.  It's easy.  The theorem, Markov's bound, says that if R is non-negative,  then the probability that R is greater than  or equal to x is less than or equal to the expectation of R ", "divided by x.  And this holds for any x greater than 0.  Of course, it's silly to state if this bound  is greater than or equal to 1.  It's not an interesting bound, since probability is never ", "greater than or equal to 1.  So we might as well just restrict ourselves  to x's that are greater than the expectation of R,  because those are the only x's that  are going to give us a nontrivial bound that's ", "less than 1.  Again, if R is non-negative, then the probability  that R exceeds an amount x is less than  or equal to the expectation of R over x. ", "And that's the Markov bound.  If you restate it in terms of deviation from the mean,  you could formulate it this way--  the probability that R is greater ", "than or equal to a constant times its mean-- mu is  an abbreviation for the expectation of R-- is less than  or equal to 1/c.  So now, we can understand that as a bound ", "on the deviation from the mean-- above the mean, in this case--  that R, as the factor of the expectation increases,  the probability decreases proportionally. ", "So the probability that R is greater equal to 3 times  the expected amount is less than or equal to 1/3, which was what  we saw with the IQ example. ", "So look, this Markov bound, in general, is very weak.  As I said, I don't think there's ever been an IQ recorded  that was as high as 300. ", "And in almost all the examples that you come across,  there'll be other information that  allows you to deduce tighter bounds on the probability  that a random variable is significantly ", "bigger than its expectation.  But if you don't have any information  about the random variable, other than that it's non-negative,  then as a matter of fact, Markov bound is tight.  You can't possibly reach a stronger contribution, ", "because there are non-negative random variables where  the probability that they are greater  than or equal to a given amount x  is, in fact, equal to their expectation divided by x. ", "So the Markov bound is weak in application,  but it's the strongest condition you  can make on the very limited hypotheses  that it makes about properties of the random variable. ", "And it's also pretty obvious, I hope from this example  that we've talked about, but the amazing thing  is how useful it is.  We will get mileage out of it by using it in clever ways. ", "So let's talk about the first clever way.  And suppose that we're thinking about IQ  is greater than or equal to 100.  But I bring into the story another fact  that we haven't mentioned before, which is, ", "let's suppose that as a matter of fact, IQs of less than 50  just don't occur.  I think they might actually, but there's  a certain point where you just are not functioning at all. ", "And it's not clear that it makes sense  to ever talk about somebody who's in a coma  as having an IQ.  Maybe they have an IQ of 0.  But let's assume that pragmatically IQ is never ", "less than or equal to 50.  Now, if I tell you that I know that IQ  is greater than or equal to 50, then I  can actually get a better bound out of Markov. ", "Because now, knowing that IQ is greater than or equal to 50,  IQ minus 50 becomes a non-negative random variable,  which I couldn't be sure it was before, ", "because IQ might have gone below 50.  Now that I know that it's always above 50, IQ minus 50  is non-negative.  And Markov's bound will apply to IQ minus 50.  And applying it to IQ minus 50 will give you a better bound. ", "Because now, looking at the probability  that the IQ is greater than or equal to 100, of course, that's  the same as saying that IQ minus 50  is greater than or equal to 300 minus 50, ", "which 50-- the average expected value of IQ minus 50 ", "is 100 minus 50.  So we're asking whether this is non-negative random variable is  greater than or equal to 250. ", "And the answer is, that's less than  or equal to its expectation over 250, which is 1/5, 50/250. ", "And that's a tighter bound than the 1/3 we had previously.  This is a general phenomenon that you get  and that helps you get slightly stronger bounds out of Markov's  bound, namely if you have a non-negative variable, ", "you get a better bound on it by shifting it  so that its mean is 0.  As a matter of fact, even if it goes negative,  if you shift it up, if you can force  it to become above 0 as a minimum, ", "then you can apply Markov's bound to it.   PROFESSOR: Our topic is deviation from the mean,  meaning the probability that a random variable returns  a value that differs significantly from its mean. ", "Now, the Markov bound gave you a course bound on the probability  that R was overly large using very little information  about R. Not surprisingly, if you know a little bit more ", "about the distribution of R, simply that it's not negative,  you can state tighter bounds.  And this was noticed by a mathematician named Chebyshev. ", "And he has a bound called the Chebyshev bound.  Now, it's interesting that the Markov bound, even though it's  very weak and seems not very useful, ", "the Chebyshev bound, which generally  gives you a significantly stronger, invaluably stronger  bound on the probability that a random variable differs much  from its mean is actually a trivial corollary ", "of Markov theorem.  So that's just a very simple ingenious way  to use Markov's bound to derive Chebyshev bound.  And let's look at how.  So we're interested in the probability ", "that a random variable R differs from its mean by an amount x.  The distance between R and its mean,  the absolute value of R minus mu,  is greater than or equal to x.  We're trying to get a grip on that probability ", "as a function of x.  Now, the point is that the event that the distance between R  and its mean is greater than or equal to x, another way  to say that is to square both sides of this inequality. ", "It says that the event that R minus mu squared is greater  or equal to x squared happens.  These two events are just different ways  of saying the same set. ", "So therefore, their probabilities  are equal trivially.  Now, what's nice about this is, of course, that R minus mu  squared is a non-negative random variable to which Markov's ", "theorem applies.  The square of a real number is always  going to be non-negative.  So let's just apply Markov's theorem  to this new random variable, R minus mu squared. ", "And what does Markov's bound tell us about this probability,  that the square variable is greater  than or equal to an amount x squared.  Well, just plug in Markov. ", "And it tells you that this probability  that the square variable, that it's as big as x squared, ", "is simply the expectation of that squared variable  divided by x squared.  This is just applying Markov's bound to this variable, R  minus u squared. ", "Now, this numerator is a weird thing to stare at,  expectation of R minus mu squared, and may not  seem very memorable.  But you should remember, because it's so important ", "that it has name all it's own.  It's called the variance of R. And this  is an extra bit of information about the shape  of the distribution of R that turns out  to allow you to state much more powerful theorems in general ", "about the probability that R deviates from its mean  by a given amount.  So we could just restate the Chebyshev bound.  Just replacing that expectation formula ", "in terms of its name, variance of R,  this is what the Chebyshev bound says.  The probability that the distance between R and its mean  is greater than or equal to x is the variance of R divided ", "by x squared, where variance of R  is the expectation of the square of R minus u.  Now, the very important technical aspect  of the Chebyshev bound is that we're ", "getting an inverse square reduction in the probability.  Remember, with Markov, the denominator  was behaving linearly. ", "And here, it behaves quite quadratically.  So these bounds get smaller, much more  rapidly as we ask about the probability of differing  by a larger amount. ", "The variance of R, maybe in a way that will help you  remember it is to remember another name that it has.  It's called the mean square error.  If you think of R minus mu as the error ", "that R is making in how much it differs  from what it ought to be, and we square it,  and then we take the average, so we're taking  the mean of the squared errors. ", "And here, we're back to restating Markov  bound in terms of the variance.  The variance has one difficulty with it.  And that leads us to want to look at another object, which ", "is just the square root of the variance,  called the standard deviation.  So you wonder why-- I mean, if you understand variance,  what's the point of taking the square root  and working with that?  And the answer is simply that if you ", "think of R as a random variable whose values have  some dimension, like seconds or dollars, then the variance of R  is the expectation of a square variable of R minus mu ", "squared, which means its units are second squared  or dollar squared or whatever.  And the variance of R itself is a squared value,  which is not reflecting the magnitude of the distance ", "that you expect-- of the kind of errors  that you expect R to make, the distance that you expect  part R to be from its mean.  So we can get the units of this quantity ", "back into matching the units of R  and also get a number that's closer to the kind of variance  that you'd expect to observe by just taking the square root.  And it's called the standard deviation of R. ", "If it helps you any, the standard deviation is also  called the root mean square error.  And you might have heard that phrase.  It comes up all the time in discussions  of experimental error. ", "So again, we're taking the error--  means the distance between the random variable and its mean.  We're squaring it.  We're taking the expectation of that squared error. ", "And then we're taking the square root of it.  It's the standard deviation.  So going back to understand what the standard deviation means  intuitively in terms of a familiar shaped distribution ", "function for a random variable R,  suppose that R is a random variable that  has this fairly standard kind of bell  curved shape or Gaussian shape, that it's got one hump. ", "It's unimodal.  And it kind of trails off with some moderate rate,  as you get further and further away from the mean.  Well, the mean of a distribution that's shaped like this, ", "it's symmetric around that high point, that's going  to be the mean by symmetry.  It's equally likely to be-- well,  the values average out to this middle value. ", "A standard deviation for a curve like this  is going to be an interval that you can interpret  as an interval around the mean.  And the probability that you're within that interval ", "is fairly high for standard distributions.  Now, we'll see that the Chebyshev bound is not  going to tell us much about for arbitrary unknown distribution.  But in general, for the typical distributions, ", "you expect to find that the standard deviation tells you  that that's where you're most likely to be when you take  a random value of the variable.  So let's return to the Chebyshev bound, as we've stated it. ", "And I'm just replacing here, I'm restating the Chebyshev bound,  just replacing the variance of R in the numerator  by the square of its square root,  by sigma squared R. It's a useful way to restate it. ", "Because by restating it this way,  it motivates another reformulation  of the Chebyshev bound as we reformulated  the Markov bound previously in terms  of a multiple of something. ", "I'm going to replace x by a constant times  the standard deviation.  So I'm going to see the probability that the error is  greater than or equal to a constant times  the standard deviation. ", "And this term is going to simplify.  Once x is a constant times the standard deviation,  the standard deviations are going to cancel out.  And I'm just going to wind up with 1 over x squared. ", "So let's just do that.  And there's the formula-- the probability  that the distance of R from its mean ", "is greater than or equal to a multiple c  of its standard deviation is less than or equal to 1  over c squared.  So it's getting much more rapidly smaller as c grows. ", "Let's look at what that means for just some numbers,  to make the thing a little bit more real.  What this assertion is telling us  is that R is probably not going to return ", "a value that's a significant multiple  of its standard deviation.  For example, what does this formula  tell us about the probability that R ", "is going to be greater than or equal to one standard deviation  away from its mean?  Well, it actually tells us nothing.  That's the case in which it's no good.  Because c is 1, it's just telling us  that the probability is at most 1, which we always know, ", "because probabilities are at most 1.  But if I ask, what's the probability that the error of R  is greater than or equal to twice the standard deviation, ", "then this theorem is telling me something nontrivial.  It's telling me that the probability that it's twice  the deviation is 1 over 2 squared or 1/4.  An arbitrary random variable with standard deviation sigma ", "is going to exceed twice-- the error  is going to exceed twice the standard deviation at most 1/4  of the time, three times at most 1/9 of the time, four times  at most the 1/16 of the time. ", "So the qualitative message to take away  is that, for any random variable whatsoever, as long  as it has a standard deviation sigma,  then you can say some definite things about the probability ", "that the random variable is going  to take a value that differs by a large multiple  of the standard deviation from its mean. ", "That probability is going to be small  and get smaller and rapidly smaller  as the multiple of the standard deviation continues.   PROFESSOR: If we're going to make use of Chebyshev's Bound ", "and other results that depend on the variance,  we'll need some methods for calculating variance  in various circumstances.  So let's develop that here. ", "A basic place to begin is to ask about the indicator  variables and their variance.  Remember, i is an indicator variable that  means that it's zero one value. ", "It's also called the Bernoulli variable.  And if the probability that it equals 1 is p,  that's also its expectations.  So we have an indicator variable with expectation  of the indicator is p, and we're asking ", "what's its variance, which by definition is the expectation  of i minus p squared.  Well, this is one of the sort of almost mechanical proofs that  follows simply by algebra and linearity of expectation. ", "But let's walk through it step by step,  just to reassure you that that's all that's involved.  I would recommend against really trying to memorize this,  because it's-- I can remember it anyway,  I just reprove it every time I need it. ", "And so, let's see how the proof would go.  So step one would be to expand this i minus  p squared algebraically.  So we're talking about the expectation of i squared ", "minus 2pi plus p squared.  Now we can just apply linearity of expectation,  and I get the expectation of i squared minus 2p times  the expectation of i plus p squared. ", "Of course, the expectation of a constant is the constant.  So when I take expectation of p squared, I get p squared.  But now look at this.  i squared is zero one value.  So in fact, i squared is equal to i and the expectation of i ", "has now appeared here, that's p.  So this term simplifies to expectation of i,  and this term becomes 2p times p plus p squared.  Of course that expectation of i is a p. ", "So I've got p minus 2p squared plus p squared.  The p squareds cancel, and I get p minus p squared.  If you factor out p, that's p times 1 minus p, ", "or pq, which is the standard way that you  write the variance of an indicator variable.  It's p times 1 minus p.  OK, that was easy, and again, completely mechanical. ", "There's a couple of other rules for calculating  variance of new variables from old ones that are basic.  Like [? additivity ?] of expectation,  but it doesn't quite work so simply for variance. ", "So the first rule is that if you ask  about the variance of a constant times r  plus b, that turns out to be the same as a squared  times the variance of b-- of r. ", "The b doesn't-- the additive of be doesn't matter,  and the-- because the variance is really the expectation  of something squared, when you get rid of that constant ", "a, you're factoring out an squared.  And this is the rule you get here.  OK.  Another basic rule that's often convenient, instead ", "of working with variance in the form of the expectation of r  minus mu squared, is to say that it's  the expectation of r squared minus the square ", "of the expectation of r.  Now, this expression-- the square of the expectation of r  comes up so often that there's a shorthand for it.  Where instead of writing [? parends ?] ", "you write e squared of r, just means the same  as expectation of r squared.  And so much for the second rule, which we'll use all the time,  because it's a convenient rule to have. ", "I'm going to prove the second one, just again,  just to show you have nothing to worry about.  You don't even have to remember how the proof goes, of course,  you can reconstruct it every time.  So it's again simple proofs just by linearity of expectation ", "and doing the algebra.  So the variance of r is by definition the expectation  of r minus mu squared.  Let's expand our minus mu squared. ", "It's the expectation of r squared  minus 2mu r plus mu squared.  Now we apply linearity to that.  I get the expectation of r squared  minus 2mu expectation of r, plus the expectation of mu squared, ", "if I'm really being completely mechanical  about linearity of expectation.  Now expectation of a constant mu squared is simply mu squared.  And here, I've get the expectation  of r, that's mu again. ", "So I wind up with the expectation of r squared  minus 2mu mu plus r squared.  This is 2mu squared-- minus 2mu squared plus mu squared.  It winds up with minus mu squared. ", "And of course, mu squared is the expectation squared of r,  I've proved the formula.  Again, as claimed, there's nothing interesting here,  just algebra and linearity of expectation. ", "And the first result about factoring out an a  and squaring it follows from a similar proof, which  I'm not going to include here.  So let's look at the space station Mir ", "again, which we used as an example of calculating  mean time to failure.  So the hypothesis that we're making  is that with probability p, the Mir space station ", "will run into some huge space garbage that will clobber it.  And the probability of that happening in any given hour  is probability p. ", "So we know that that means the expected number of hours  for the Mir to fail is 1 over p, that's  the mean time to failure.  And what we're asking is what's the variance of f, if f is ", "the number of hours to failure?  What's the variance of f?  Well, one way we can do is just plug-in  the definition of expectation and this will work. ", "The probability that it takes k hours to fail  is-- we know the geometric distribution.  The probability of not failing for k minus 1 hours, ", "and failing after that, q to the k minus 1 times p.  So the variance of f, using our previous formula  about the expectation of f squared  minus the expectation squared of f, this becomes a minus 1 ", "over p squared.  We can forget about that, we want  to focus on calculating the expectation of f squared.  So f is 1, 2, 3, and so on. ", "That means f squared is 1, 4, 9, k squared.  The point being that the only values that f squared  can take our squares, so we don't  have to worry about counting them in to sum ", "that defines the expectation.  So let's go look at that.  So the expectation of f squared is the sum  over the possible values that f squared can take,  namely the sum from k equals 1 to infinity of k squared, ", "times the probability that f squared is equal to k squared.  Well of course, the probability that f  squared is equal to k squared is the same as the probability  that f equals k.  ", "And we know what the probability of f  equals k is, it's a geometric distribution, so  the probability that f equals k is q to the k minus 1 times p. ", "If I factor out a p over q, this simplifies to the sum from k  equals 0 to infinity of k squared, q to the k.  And this is a kind of sum that we've ", "seen before that has a closed form  and we could perfectly well calculate then  the expectation of f squared by appealing to our generating  function information to get a closed form for this, ", "and then remember to subtract 1 minus p squared  because the variance is this term minus the square  of the expectation of f.  But let's go another way and use the same technique ", "of total expectation that we used before.  That is, the expectation of f squared, of the failure  of time squared, is equal, by the law of total probability, ", "to the expectation of f squared, given that f is one.  That is, we fail f on the first step,  times the probability that we fail on the first step.  Plus, the expectation of f squared, ", "given that we don't fail on the first step,  that f is greater than 1, times the probability that f  is greater than 1.  Now, what's going to make this manageable  is that this expression, the expectation of f squared when ", "f is greater than 1, will turn out  to be something that we can easily  convert into a nonconditional probability,  and find a value for. ", "So the limit that we're using here is the following.  What I'm thinking about in mean time  to failure-- if I think of any function whatsoever,  g of the mean time to failure. ", "And I'm interested in the expectation of g of f,  And I'm interested in the expectation of g of f,  given that f is greater than n.  That is, it's already taken n steps to get where I am. ", "Then the thing about the mean time to failure  is that at any moment that you haven't failed,  you're starting off in essentially the same situation  you were at the beginning in waiting for the next failure ", "to occur.  And the probability of failing in one more step  is the same probability-- is the same p.  And the probability of you're failing  in two more steps is qp, and three more steps is qqp. ", "The only difference is that the value of f  has been shifted by n.  In the ordinary case, we start off  with f equals 0 and look at the probability ", "that we fail in one more step, two more steps.  Now we're starting off with f having the value f plus n,  and asking about the probability that it  fails in the next step or the next step, or the next step. ", "So the punchline is that the expectation of g of f,  given that f is greater than n, is simply the expectation  of g of f plus n. ", "And I'm going to let you meditate that  and not say anymore about it.  But the punchline is the corollary  that the expectation of f squared,  given that f is greater than 1, is simply the expectation ", "of f plus 1 squared.  And that lets us go back and simplify this expression.  That we've had from total expectation,  we now have-- here's the expectation of f squared, ", "given that f is greater than 1.  And let's look at these other terms.  This is the expectation of f squared, given that f equals 1.  Well, the expectation of f squared given that f equals 1  is 1 squared, because we know what f is ", "and that's the end of the story.  Times the probability that f equals 1,  that's p, the probability of failure on a given step.  This is the probability that f is greater than 1, which is q, ", "that we didn't fail on the first step.  And we just figured out that this term is the expectation  of the square of f plus 1.  So there's the 1 and the p. ", "And that becomes a q, and this is the expectation  of f plus 1 squared.  Now again, I apply limit linearity.  I'm going to expand f plus 1 squared  into f squared plus 2f plus 1, and then ", "apply linearity of expectation.  And I'm going to wind up with the expectation of f squared  plus twice the expectation of f, which remember,  is twice over-- 2 over p, plus 1, times the q. ", "And now what I've got is a simple arithmetic equation  between the expectation of f squared  and some other arithmetic and the expectation of f squared. ", "It's easy to solve for the expectation of f squared.  And I'll spare you that elementary simplification.  But the punchline is, when-- we also  remember to subtract one over p squared, ", "because that was the expectation of the square of f  of the expectation of f.  We came up with this punchline formula.  The variance of mean time to failure  is 1 over the probability of failure on a given step, ", "times 1 minus 1 over-- times the probability-- 1  over the probability of the failure in the first step,  minus 1.  That's just for practice and fun,  let's look at the space station Mir again. ", "Suppose that I tell you that there is a 1 in [? 10,000ths ?]  chance that in any given hour, the Mir is going to crash  into some debris that's out there in orbit. ", "So the expectation of f is 10 to the fourth, about 10,000 hours.  And the sigma is going to be the variance of f, which is about 1 ", "over ten thousandths, that is 10,000 times 10,000 minus 1,  which is pretty close to 10,000 squared for the variance. ", "And when I take the square root, I get back to 10,000.  So sigma is just a tad less than 10,000, is 10 to the fourth.  So with those numbers, I can apply the Chebyshev's Theorem  and conclude that the probability that the Mir lasts ", "more than 4 times 10 to the fourth hours  is less than 1 chance in four.  If we translate that into years-- if it was really  the case that there was a 1 in 10,000 chance of the Mir being ", "destroyed in any given hour, then the probability  that it lasts more than 4.6 years before destructing  is less than 1/4.  ", "So another rule for calculating variance,  and maybe the most important general one,  is that variance is additive.  That is, the variance of a sum is the sum of the variances. ", "But unlike expectation, where there's no other side  condition, and it does not in any way depend on independence,  it turns out that variance is additive  only if the variables being added our pairwise independent. ", "Now you might wonder where the pairwise came from,  and it's because variance is the square of an expectation.  So when you wind up multiplying out and doing the algebra, ", "you're just getting quadratic terms  for variances of-- for expectations of ri times rj.  And so you need to factor those into expectation of r times ", "expect-- ri times expectation of rj,  which you only need pairwise independence for.  So that's a fast talking through the algebra  that I'm going to leave to you.  It's in the text, and it's again one of these easy proofs. ", ""], "vid_duration": [11.66, 11.43, 11.97, 10.42, 13.75, 11.51, 11.4, 11.16, 10.12, 11.83, 10.66, 12.49, 11.11, 12.73, 13.38, 14.97, 16.87, 12.99, 12.08, 10.03, 10.84, 11.08, 10.85, 14.01, 13.88, 11.35, 10.75, 13.55, 11.86, 10.02, 12.13, 10.21, 12.78, 11.51, 12.91, 10.485, 11.545, 13.43, 11.463, 13.78, 12.25, 10.7, 11.38, 13.19, 10.99, 13.37, 11.68, 13.13, 12.44, 11.49, 11.34, 11.78, 12.08, 15.7, 11.38, 10.75, 12.52, 12.74, 11.37, 10.376, 12.264, 10.225, 11.265, 13.57, 11.36, 10.451, 11.809, 11.33, 10.9, 12.71, 10.53, 12.14, 11.497, 10.003, 10.15, 11.51, 12.94, 11.59, 10.42, 11.3, 11.15, 11.83, 13.96, 12.61, 12.27, 10.57, 10.05, 11.66, 12.81, 12.46, 12.97, 10.336, 11.994, 12.98, 10.576, 12.834, 11.14, 10.96, 14.59, 11.46, 10.96, 11.19, 10.5, 11.75, 11.53, 13.9, 11.804, 12.336, 12.49, 16.12, 10.67, 11.605, 10.535, 10.43, 13.72, 10.97, 11.63, 11.74, 13.53, 11.0, 13.655, 11.505, 10.48, 10.82, 11.1, 11.61, 13.769, 10.891, 10.29, 12.23, 10.852, 11.588, 11.19, 13.26, 10.36, 11.779, 10.361, 10.53, 12.119, 13.19, 12.33, 11.771, 11.226, 13.654, 10.96, 10.099, 13.72, 12.111, 12.399, 12.561, 10.66, 11.9, 10.659, 10.821, 12.57, 10.879, 14.371, 11.16, 12.179, 13.931, 11.099, 11.611, 10.81, 12.94, 11.899, 10.46, 12.25, 10.871, 10.54, 13.099, 11.8, 10.261, 10.709, 10.711, 11.299, 11.46, 11.861, 12.96, 10.27, 10.08, 11.84, 12.339, 12.921, 11.01, 11.22, 10.25, 11.739, 11.161, 12.88, 12.6, 10.18, 16.24, 12.58, 11.02, 12.81, 13.0, 12.07, 10.37, 15.23, 10.029, 13.451, 11.52, 11.9, 12.839, 13.381, 11.0, 12.22, 11.76, 16.547], "stet": [[0, 11.66], [11.66, 23.09], [23.09, 35.06], [35.06, 45.480000000000004], [45.480000000000004, 59.230000000000004], [59.230000000000004, 70.74000000000001], [70.74000000000001, 82.14000000000001], [82.14000000000001, 93.30000000000001], [93.30000000000001, 103.42000000000002], [103.42000000000002, 115.25000000000001], [115.25000000000001, 125.91000000000001], [125.91000000000001, 138.4], [138.4, 149.51], [149.51, 162.23999999999998], [162.23999999999998, 175.61999999999998], [175.61999999999998, 190.58999999999997], [190.58999999999997, 207.45999999999998], [207.45999999999998, 220.45], [220.45, 232.53], [232.53, 242.56], [242.56, 253.4], [253.4, 264.48], [264.48, 275.33000000000004], [275.33000000000004, 289.34000000000003], [289.34000000000003, 303.22], [303.22, 314.57000000000005], [314.57000000000005, 325.32000000000005], [325.32000000000005, 338.87000000000006], [338.87000000000006, 350.7300000000001], [350.7300000000001, 360.75000000000006], [360.75000000000006, 372.88000000000005], [372.88000000000005, 383.09000000000003], [383.09000000000003, 395.87], [395.87, 407.38], [407.38, 420.29], [420.29, 430.77500000000003], [430.77500000000003, 442.32000000000005], [442.32000000000005, 455.75000000000006], [455.75000000000006, 467.2130000000001], [467.2130000000001, 480.99300000000005], [480.99300000000005, 493.24300000000005], [493.24300000000005, 503.94300000000004], [503.94300000000004, 515.3230000000001], [515.3230000000001, 528.5130000000001], [528.5130000000001, 539.5030000000002], [539.5030000000002, 552.8730000000002], [552.8730000000002, 564.5530000000001], [564.5530000000001, 577.6830000000001], [577.6830000000001, 590.1230000000002], [590.1230000000002, 601.6130000000002], [601.6130000000002, 612.9530000000002], [612.9530000000002, 624.7330000000002], [624.7330000000002, 636.8130000000002], [636.8130000000002, 652.5130000000003], [652.5130000000003, 663.8930000000003], [663.8930000000003, 674.6430000000003], [674.6430000000003, 687.1630000000002], [687.1630000000002, 699.9030000000002], [699.9030000000002, 711.2730000000003], [711.2730000000003, 721.6490000000002], [721.6490000000002, 733.9130000000002], [733.9130000000002, 744.1380000000003], [744.1380000000003, 755.4030000000002], [755.4030000000002, 768.9730000000003], [768.9730000000003, 780.3330000000003], [780.3330000000003, 790.7840000000003], [790.7840000000003, 802.5930000000003], [802.5930000000003, 813.9230000000003], [813.9230000000003, 824.8230000000003], [824.8230000000003, 837.5330000000004], [837.5330000000004, 848.0630000000003], [848.0630000000003, 860.2030000000003], [860.2030000000003, 871.7000000000003], [871.7000000000003, 881.7030000000003], [881.7030000000003, 891.8530000000003], [891.8530000000003, 903.3630000000003], [903.3630000000003, 916.3030000000003], [916.3030000000003, 927.8930000000004], [927.8930000000004, 938.3130000000003], [938.3130000000003, 949.6130000000003], [949.6130000000003, 960.7630000000003], [960.7630000000003, 972.5930000000003], [972.5930000000003, 986.5530000000003], [986.5530000000003, 999.1630000000004], [999.1630000000004, 1011.4330000000003], [1011.4330000000003, 1022.0030000000004], [1022.0030000000004, 1032.0530000000003], [1032.0530000000003, 1043.7130000000004], [1043.7130000000004, 1056.5230000000004], [1056.5230000000004, 1068.9830000000004], [1068.9830000000004, 1081.9530000000004], [1081.9530000000004, 1092.2890000000004], [1092.2890000000004, 1104.2830000000004], [1104.2830000000004, 1117.2630000000004], [1117.2630000000004, 1127.8390000000004], [1127.8390000000004, 1140.6730000000005], [1140.6730000000005, 1151.8130000000006], [1151.8130000000006, 1162.7730000000006], [1162.7730000000006, 1177.3630000000005], [1177.3630000000005, 1188.8230000000005], [1188.8230000000005, 1199.7830000000006], [1199.7830000000006, 1210.9730000000006], [1210.9730000000006, 1221.4730000000006], [1221.4730000000006, 1233.2230000000006], [1233.2230000000006, 1244.7530000000006], [1244.7530000000006, 1258.6530000000007], [1258.6530000000007, 1270.4570000000008], [1270.4570000000008, 1282.7930000000008], [1282.7930000000008, 1295.2830000000008], [1295.2830000000008, 1311.4030000000007], [1311.4030000000007, 1322.0730000000008], [1322.0730000000008, 1333.6780000000008], [1333.6780000000008, 1344.2130000000009], [1344.2130000000009, 1354.643000000001], [1354.643000000001, 1368.363000000001], [1368.363000000001, 1379.333000000001], [1379.333000000001, 1390.963000000001], [1390.963000000001, 1402.703000000001], [1402.703000000001, 1416.233000000001], [1416.233000000001, 1427.233000000001], [1427.233000000001, 1440.888000000001], [1440.888000000001, 1452.3930000000012], [1452.3930000000012, 1462.8730000000012], [1462.8730000000012, 1473.6930000000011], [1473.6930000000011, 1484.793000000001], [1484.793000000001, 1496.403000000001], [1496.403000000001, 1510.172000000001], [1510.172000000001, 1521.063000000001], [1521.063000000001, 1531.353000000001], [1531.353000000001, 1543.583000000001], [1543.583000000001, 1554.435000000001], [1554.435000000001, 1566.023000000001], [1566.023000000001, 1577.213000000001], [1577.213000000001, 1590.473000000001], [1590.473000000001, 1600.833000000001], [1600.833000000001, 1612.612000000001], [1612.612000000001, 1622.973000000001], [1622.973000000001, 1633.503000000001], [1633.503000000001, 1645.622000000001], [1645.622000000001, 1658.812000000001], [1658.812000000001, 1671.142000000001], [1671.142000000001, 1682.913000000001], [1682.913000000001, 1694.139000000001], [1694.139000000001, 1707.793000000001], [1707.793000000001, 1718.753000000001], [1718.753000000001, 1728.852000000001], [1728.852000000001, 1742.572000000001], [1742.572000000001, 1754.6830000000011], [1754.6830000000011, 1767.082000000001], [1767.082000000001, 1779.643000000001], [1779.643000000001, 1790.303000000001], [1790.303000000001, 1802.203000000001], [1802.203000000001, 1812.8620000000012], [1812.8620000000012, 1823.6830000000011], [1823.6830000000011, 1836.253000000001], [1836.253000000001, 1847.132000000001], [1847.132000000001, 1861.503000000001], [1861.503000000001, 1872.6630000000011], [1872.6630000000011, 1884.8420000000012], [1884.8420000000012, 1898.7730000000013], [1898.7730000000013, 1909.8720000000012], [1909.8720000000012, 1921.4830000000013], [1921.4830000000013, 1932.2930000000013], [1932.2930000000013, 1945.2330000000013], [1945.2330000000013, 1957.1320000000012], [1957.1320000000012, 1967.5920000000012], [1967.5920000000012, 1979.8420000000012], [1979.8420000000012, 1990.7130000000013], [1990.7130000000013, 2001.2530000000013], [2001.2530000000013, 2014.3520000000012], [2014.3520000000012, 2026.1520000000012], [2026.1520000000012, 2036.4130000000011], [2036.4130000000011, 2047.1220000000012], [2047.1220000000012, 2057.833000000001], [2057.833000000001, 2069.132000000001], [2069.132000000001, 2080.592000000001], [2080.592000000001, 2092.453000000001], [2092.453000000001, 2105.413000000001], [2105.413000000001, 2115.683000000001], [2115.683000000001, 2125.763000000001], [2125.763000000001, 2137.603000000001], [2137.603000000001, 2149.942000000001], [2149.942000000001, 2162.8630000000007], [2162.8630000000007, 2173.873000000001], [2173.873000000001, 2185.0930000000008], [2185.0930000000008, 2195.3430000000008], [2195.3430000000008, 2207.082000000001], [2207.082000000001, 2218.243000000001], [2218.243000000001, 2231.123000000001], [2231.123000000001, 2243.723000000001], [2243.723000000001, 2253.9030000000007], [2253.9030000000007, 2270.1430000000005], [2270.1430000000005, 2282.7230000000004], [2282.7230000000004, 2293.7430000000004], [2293.7430000000004, 2306.5530000000003], [2306.5530000000003, 2319.5530000000003], [2319.5530000000003, 2331.6230000000005], [2331.6230000000005, 2341.9930000000004], [2341.9930000000004, 2357.2230000000004], [2357.2230000000004, 2367.2520000000004], [2367.2520000000004, 2380.7030000000004], [2380.7030000000004, 2392.2230000000004], [2392.2230000000004, 2404.1230000000005], [2404.1230000000005, 2416.9620000000004], [2416.9620000000004, 2430.3430000000003], [2430.3430000000003, 2441.3430000000003], [2441.3430000000003, 2453.563], [2453.563, 2465.3230000000003], [2465.3230000000003, 2481.8700000000003]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [464, 989, 1609, 2482]}
{"example_id": "mit097@@MIT6_042JS15_25_ipod", "text": [" PROFESSOR: The topic of counting, or combinatorics,  is an important one in a number of different disciplines,  and notably in computer science. ", "So the origins of the combinatorics and counting  are a little bit disreputable.  They come, historically, out of people studying gambling ", "and trying to calculate odds and the fraction of times  that various events occur to know what kind of bets  to make on them.  So a typical kind of question would ", "be-- if you know how poker works,  there are various classifications  of five-card hands in poker.  And you might ask, what fraction of all possible five-card poker  hands translate into being a pair of jacks? ", "And basically, this fraction of total poker hands  which fit into the category \"a pair of jacks\"  is the probability of a pair of jacks. ", "So counting in gambling is one fundamental place  where it really comes up.  And historically, that's where a lot of combinatorics begins.  Related to that is counting in games. ", "When you're trying to write, for example, a computer program  to play chess or checkers or so on, one of the aspects of it  is getting a sense of how much searching you ", "have to do in order to look ahead to find good moves.  And you wind up counting, from a given chess position,  how many possible further positions can you  get to a given number of moves. ", "A puzzle kind of question, in solving the Rubik's Cube toy,  is how many different positions are there,  and how many different positions can you  get to from a given position? ", "Concretely, in computer science, it comes up in algorithms.  It's often the case that an essential question  is, how many operations does it take  to do a manipulation on a data structure ", "and to update it from one to another?  For example, how many comparisons  does it take to sort n numerical items?  And typically, the count is n log n, ", "proved as a number of operations that are both achievable  and a lower bound.  One that we've seen when we looked at fast exponentiation  is a question like, if you're trying ", "to compute the nth power of a number d,  how many multiplications does it take?  It's roughly log n by using the iterated squaring method.  And we want to be able to count that number of multiplications ", "that a particular program uses to compute d to the n  in the smallest number of multiplications  you can get away with.  And a place where, again, counting and combinatorics ", "becomes critical is for security and the issue of cryptography.  If you're going to have security from passwords,  there needs to be too large a space of passwords ", "for an adversary to search through exhaustively  and check them likewise.  If you're doing encryption with some kind of secret key  that enables you to read messages, ", "you want to be sure that the space of possible keys  is also way too large to search exhaustively  to see what keys work.  So let's talk briefly now about the very basic counting ", "methods, and two rules for counting things--  the most rudimentary of them, but in fact we'll  get some mileage out of them.  So the first rule is called the Sum Rule,  and it's completely straightforward and obvious, ", "which is that if I have two sets, A and B, that do not  overlap, then the number of elements in A union B  is simply the number of elements in A  plus the number of elements in B. ", "And there's no issue proving that-- it's self-evident--  but let's do an example.  Suppose a class has 43 women and 54 men.  How many people are in it? ", "43 plus 54 equals 97.  This is implicitly assuming that there's  no one whose sex is ambiguous and that there's  no third sex, so that men and women are disjoint. ", "The total number of students is the sum  of the number of men and women.  Another one is there are 26 lowercase Roman  letters and 26 uppercase Roman letters and 10 digits. ", "And so there are 26 plus 26 plus 10 equals 62 characters  in that repertoire of symbols. ", "The second rule is called the Product Rule,  and just about as obvious.  Suppose I have four boys and three girls.  How many boy-girl couples can I assemble out ", "of four boys and three girls?  And the answer is, there are four ways to choose a boy,  and for each of them, there are three ways to choose a girl. ", "So there's 4 times 3, or 12, possible boy-girl girl  couples in this setting.  More generally, if I have a set A of size m  and a set B of size n, then A cross B-- remember, that's ", "the set of ordered pairs where the first element is from A  and the second element is from B-- the size of A cross B  is-- the vertical bars, remember,  mean size-- is equal to m times n. ", "So let's just do an example that illustrates it.  Suppose that A is the set of four elements-- little a,  b, c, and d-- and B is the set of three numbers, 1, 2, and 3. ", "Then I can list A cross B in a nice orderly way,  as a 4-by-3 matrix.  But this is really meant to be just a list of elements, ", "but I'm organizing this way so the pattern is more apparent.  And for each element little a, I can pair it  with each of the three elements in B. ", "And for the second element, little b, in A,  I can pair it with this three digits [? in A. ?]  And c I can pair with three, and d I can pair with three.  And that's where the 4 times 3 comes from, and more generally, ", "the m times n comes from.   A useful immediate application of this  is, how many binary strings are there? ", "How many strings of zeros and ones are there of length 4?  Well, the length for binary strings,  it can be explained as well as the product of B times B ", "times B times B. We're not writing parentheses here.  It's B times B-- cross B.  So I'm thinking of a quadruple like this  as being a pair whose first element is a triple. ", "And a triple is a pair whose first element is a pair.  And given that it doesn't really matter how you break it up,  we just typically write it as B cross  B cross B, and even abbreviate that as B to the fourth, ", "where b is 0, 1.  And the Product Rule says that the size of this  is the size of B times the size of B  times the size of B times the size of B, or 2 to the fourth. ", "So in general, if I look at strings  of length n, whose elements are from an alphabet of size m,  the total number of such strings is m to the n. ", " PROFESSOR: An elementary idea that  gets you a long way in counting things  is this idea of counting with bijections, which is counting ", "one thing by counting another.  And we can illustrate that by example.  Let's begin with looking at some stuff that  is easy to count using just the simple sum and product rules. ", "So suppose that I'm trying to count passwords.  This is a contrived, over-simplified example,  but it gives you the idea.  And this is what I mean by a password.  A password is a sequence of characters that are either ", "letters or digits subject to the constraints  that they are supposed to be between six  and eight characters long.  They're supposed to start with a letter,  and they're case sensitive.  So you can tell the difference between uppercase and lowercase ", "letters.  So let's define the set L of all the letters-- uppercase  and lowercase together.  And let D be the set of digits from 0 through 9. ", "Then we said that passwords are supposed  to be between six and eight words long,  but it's a little bit easier actually to just use links  as a parameter.  So let's think about words of length n ", "that satisfy the password conditions.  So Pn is going to be the length n  words starting with a letter, which is one of the password ", "constraints.  So we can express that has a length n  word can be broken up into the first character, which  is an L, paired with the rest of the word-- ", "the remaining n minus 1 characters.  And the remaining n minus 1 characters can be either  L's or D's.  So though length n passwords can be expressed ", "as the product of L with the n-th power of L union D-- that  is, L union D cross L union D cross  L union D, n minus 1 times.  Well, now we have an easy way to count this, ", "because the size of this product by the product rule  is the size of L times the size of L union  D to the n minus first power. ", "And of course, L union D, since letters and digits  don't overlap by the sum rule, the size of them  is just L plus D. And so I get this nice formula  that is 52 letters times 52 letters ", "plus 10 digits raised to the n minus first power.  What about the passwords?  Well, the passwords were then P6 union P7 union P8. ", "And since words of length six don't  overlap with words of length seven or eight,  this is a disjoint union.  And therefore, the total number of passwords as specified  is simply the size of P6 plus the size P7 ", "plus the size of P8.  There's the formula when I plug in.  And it turns out to be a good size number, 19 times 10  to the 14th.  That's one simple example where I'm ", "translating a spec into because something that I can express  easily as a products and disjoint sums of stuff  that I already know the size of. ", "Let's just do another example.  Suppose that I want to count the number of 4-digit numbers.  So the elements of these 4-digit numbers  are 0 through 9-- there are 10 possibilities-- with at least ", "one 7-- the number of 4-digit sequences of digits that  have at least one 7 in them.  And one way to count is I can make ", "it a sum of different 4-digit numbers containing  one 7, depending on where the first 7 is.  If there's at least one 7, there's a first 7.  That's the well-ordering principle applied. ", "So if we let x abbreviate any digit--  there are 10 possible values of x-- and o  represent any digit other than 7-- so there's  nine possible values of o-- then the words that start with 7 ", "can then be followed with any three digits.  So 7xxx is one possible pattern when the first occurrence of 7  is first.  Another possible pattern is when you have a digit that's ", "not 7 followed by a 7.  This is when 7 occurs second followed by anything at all.  Likewise, here 7 occurs third, and here, 7 occurs forth.  Now, these individual patterns are easy enough ", "to count using the product rule, because here, I  have to count how many triples of any digits are there.  Well, there's 10 digits, so it's 10 cubed.  Here, how many sequences of where ", "the first choice is 9 and the second two choices are 10.  And it's 9 times 10 squared.  Here, it's 9 squared times 10.  And here it's 9 cubed. ", "These are disjoint, because they're  distinguished by where the first 7 occurs.  And so I just add them up.  And I get this number.  It's not especially interesting, but it's 3,439. ", "So that's an exercise in counting something  by somewhat ingeniously breaking it up  into a sum of disjoint things that  are themselves easier to count. ", "There's another way that's another standard trick that  comes up in combinatorics of how do  you count the sequence of 4-digit numbers  with at least one 7, by counting the complement. ", "Count the numbers of 4-digit numbers  that don't have any 7's and simply  subtract that number, the number of 4-digit numbers with no 7's, ", "from the total number of 4-digit numbers.  And that's going to be the numbers that  are left over that have one 7.  Now, the number of 4-digit numbers is easy to count.  And it will turn out that the number of 4-digit numbers ", "with no 7's is also really easy to count,  because the number of 4-digit numbers is 10 to the fourth  and the number of 4-digit numbers with no 7's,  there's nine possible choices for each of the remaining ", "digits.  So it's just the digits 0 through 9,  leaving out 7, to the fourth power, or 9 to the fourth.  And you can double check that 10 to the fourth minus 9 ", "to the fourth is 3,4,39.  So now, with that practice using the basic sum and product  rules, we can start applying and thinking ", "about the bijection rule.  So the bijection rule simply says  that if I have a bijection between two sets A and B,  then they have the same size, at least  assuming that they are finite sets. ", "And the only kind of things we're counting are finite sets.  Let's use an example of that, where  I'm going to count the number of subsets of a set A ", "by finding a bijection between the subsets of a set A  and something that I do know how to count.  In fact, we've already counted them,  the binary strings of a given length. ", "What's the bijection?  Well, suppose that A is a set of n elements,  call them a1 through an.  And I have some arbitrary subset of A. Say, it's got a1, ", "and it doesn't have a2, and it has a3, and it has a4,  and it doesn't have a5.  And then it's got some selection of the other numbers.  And it turns out it has a n in it.  Well, if I think of a subset laid out ", "this way up against the corresponding elements in A,  I can code this in an obvious way  by putting a 1 where the element is in the subset and a 0 ", "where the element is not in the subset.  In effect, this is the so-called characteristic function  of the subset where 1 means that that index element-- a 1  in the i-th position means that ai is there. ", "And a 0 in the i-th position means that ai is not there.  So the second coordinate here is a 0.  That means a2 is not there. ", "And this is easily seen to be a bijection.  That is, given the string, you could figure out  what the subset is.  Given the subset, you can figure out what the unique string is.  So we have a bijection.  And what we conclude then is that the number ", "of n-bit strings is equal to the size of power set of A.  It's equal to the number of subsets of A.  And of course, we know how to count  the number of n-bit strings.  It's 2 to the n. ", "So what we just figured out is, if I have a set of size n,  it's got 2 to the n subsets.  And a slick way to say that without mentioning  n is that the size of the power set of A ", "is simply 2 the size of A.  One more example of bijection counting  that is kind of fun and interesting ", "will illustrate the fact that we learn something  by finding a bijection, even if we don't know  how to count either one yet.  So what I'm interested in is, suppose  I have a situation where there are ", "five kinds of doughnuts-- five different flavors of doughnuts.  And I want to sort of select a dozen.  Now, I want to know how many selections there are.  So for example-- these little O's represent doughnuts--  I might choose a selection of a dozen ", "by choosing two chocolate and no lemon-- I  don't like those so much-- and six sugars and two  glazed and two plain.  So there are 12 doughnuts here using four out ", "of the five possible flavors of doughnuts.  This is what I'll call a selection of a doughnut.  And I'd like to know how many such selections of doughnuts  are there.  Well, let that be the set A, the set of all these different ways ", "of selecting 12 doughnuts when there are five  flavors of doughnuts available.  Well, this is, again, an obvious correspondence between the set  A of doughnut selections and the set B of 0's and 1's of length ", "16 that contain four 1's.  What's the correspondence?  Well, here's my doughnut selection.  And of course, the reason why I use those O's for doughnuts is  that they also correspond to 0's. ", "I can just put in 1's as delimiters  between the groups of flavors.  So after the chocolate doughnuts, I put a 1.  And then after the lemon doughnuts, ", "that happen to be none, I put another 1.  And then after the six sugar doughnuts, I put a 1.  And then I kind of consolidate and I extract from the doughnut  selection this 16-bit word with 12 0's ", "corresponding to 12 doughnuts and four 1's  corresponding to breaking up those groups of 0's into five  categories, five slots, corresponding ", "to the number of doughnuts of each flavor.  So the general bijection, of course,  is that if I have a selection of c chocolate doughnuts,  l lemon doughnuts, s sugar doughnuts, g glazed, ", "and p plain of any number really,  a selection of doughnuts with this number of chocolates,  lemons, glazed, plain corresponds to a binary word ", "with c plus l plus s plus g plus p 0's and four 1's.  And so what we can say is that the set  of 16-digit words with four 1's is exactly the same size ", "as the number of doughnut selections,  even though at this moment we don't  know how to count either one.  We will see in the next lecture an easy way to count the number  of those 16-bit words with four 1's. ", "But for now, our conclusion from bijection counting  is that these two sets are the same size, even though I  haven't counted yet either one. "], "vid_duration": [11.45, 10.62, 10.1, 14.99, 10.07, 10.39, 11.56, 13.12, 12.14, 10.44, 11.98, 10.96, 13.69, 12.16, 12.9, 10.33, 14.17, 12.39, 12.27, 10.22, 12.596, 10.983, 10.151, 11.76, 10.78, 14.77, 13.29, 12.13, 12.17, 11.43, 12.12, 10.31, 10.81, 14.45, 13.82, 12.38, 15.1, 10.66, 11.83, 11.35, 11.65, 13.1, 12.25, 13.49, 10.16, 11.24, 11.7, 10.139, 15.081, 11.28, 12.29, 11.89, 11.63, 14.67, 10.97, 11.7, 13.58, 12.74, 13.439, 12.151, 10.81, 13.74, 11.948, 13.542, 12.18, 11.39, 13.31, 10.02, 12.174, 10.546, 12.29, 10.32, 11.819, 12.051, 11.17, 12.1, 10.06, 12.129, 11.271, 11.129, 14.451, 10.806, 12.124, 13.26, 13.28, 14.68, 11.65, 10.49, 15.04, 11.55, 12.339, 14.071, 14.54, 12.82, 6.21], "stet": [[0, 11.45], [11.45, 22.07], [22.07, 32.17], [32.17, 47.160000000000004], [47.160000000000004, 57.230000000000004], [57.230000000000004, 67.62], [67.62, 79.18], [79.18, 92.30000000000001], [92.30000000000001, 104.44000000000001], [104.44000000000001, 114.88000000000001], [114.88000000000001, 126.86000000000001], [126.86000000000001, 137.82000000000002], [137.82000000000002, 151.51000000000002], [151.51000000000002, 163.67000000000002], [163.67000000000002, 176.57000000000002], [176.57000000000002, 186.90000000000003], [186.90000000000003, 201.07000000000002], [201.07000000000002, 213.46000000000004], [213.46000000000004, 225.73000000000005], [225.73000000000005, 235.95000000000005], [235.95000000000005, 248.54600000000005], [248.54600000000005, 259.52900000000005], [259.52900000000005, 269.68000000000006], [269.68000000000006, 281.44000000000005], [281.44000000000005, 292.22], [292.22, 306.99], [306.99, 320.28000000000003], [320.28000000000003, 332.41], [332.41, 344.58000000000004], [344.58000000000004, 356.01000000000005], [356.01000000000005, 368.13000000000005], [368.13000000000005, 378.44000000000005], [378.44000000000005, 389.25000000000006], [389.25000000000006, 403.70000000000005], [403.70000000000005, 417.52000000000004], [417.52000000000004, 429.90000000000003], [429.90000000000003, 445.00000000000006], [445.00000000000006, 455.6600000000001], [455.6600000000001, 467.49000000000007], [467.49000000000007, 478.8400000000001], [478.8400000000001, 490.49000000000007], [490.49000000000007, 503.5900000000001], [503.5900000000001, 515.8400000000001], [515.8400000000001, 529.3300000000002], [529.3300000000002, 539.4900000000001], [539.4900000000001, 550.7300000000001], [550.7300000000001, 562.4300000000002], [562.4300000000002, 572.5690000000002], [572.5690000000002, 587.6500000000002], [587.6500000000002, 598.9300000000002], [598.9300000000002, 611.2200000000001], [611.2200000000001, 623.1100000000001], [623.1100000000001, 634.7400000000001], [634.7400000000001, 649.4100000000001], [649.4100000000001, 660.3800000000001], [660.3800000000001, 672.0800000000002], [672.0800000000002, 685.6600000000002], [685.6600000000002, 698.4000000000002], [698.4000000000002, 711.8390000000002], [711.8390000000002, 723.9900000000001], [723.9900000000001, 734.8000000000001], [734.8000000000001, 748.5400000000001], [748.5400000000001, 760.488], [760.488, 774.0300000000001], [774.0300000000001, 786.21], [786.21, 797.6], [797.6, 810.91], [810.91, 820.93], [820.93, 833.1039999999999], [833.1039999999999, 843.65], [843.65, 855.9399999999999], [855.9399999999999, 866.26], [866.26, 878.079], [878.079, 890.13], [890.13, 901.3], [901.3, 913.4], [913.4, 923.4599999999999], [923.4599999999999, 935.5889999999999], [935.5889999999999, 946.8599999999999], [946.8599999999999, 957.9889999999999], [957.9889999999999, 972.4399999999999], [972.4399999999999, 983.246], [983.246, 995.37], [995.37, 1008.63], [1008.63, 1021.91], [1021.91, 1036.59], [1036.59, 1048.24], [1048.24, 1058.73], [1058.73, 1073.77], [1073.77, 1085.32], [1085.32, 1097.6589999999999], [1097.6589999999999, 1111.7299999999998], [1111.7299999999998, 1126.2699999999998], [1126.2699999999998, 1139.0899999999997], [1139.0899999999997, 1145.2999999999997]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [445, 1145]}
{"example_id": "mit001@@ocw-18.01-f07-lec14_300k", "text": ["PROFESSOR: What we're going to talk about today is a  continuation of last time.  I want to review Newton's method because I want to talk  to you about its accuracy. ", "So if you remember, the way Newton's method works is this.  If you have a curve and you want to know whether  it crosses the axis. ", "And you don't know where this point is, this point which  I'll call x here, what you do is you take a guess.  Maybe you take a point x0 here. ", "And then you go down to this point on the graph. and  you draw the tangent line.  I'll draw these in a couple of different colors so that you  can see the difference between them. ", "So here's a tangent line.  It's coming out like that.  And that one is going to get a little closer  to our target point. ", "But now the trick is, and this is rather hard to see because  the scale gets small incredibly fast, is that if you go right  up from that, and you do this same trick over again. ", "That is, this is your second guess, x1, and now you draw  the second tangent line.  Which is going to come down this way. ", "That's really close.  You can see here on the chalkboard, it's practically  the same as the dot of x.  So that's the next guess. ", "Which is x2.  And I want to analyze, now, how close it gets.  And just describe to you how it works. ", "So let me just remind you of the formulas, too.  It's worth having them in your head.  So the formula for the next one is this. ", "And then the idea is just to repeat this process.  Which has a fancy name, which is in algorithms, which is  to iterate, if you like. ", "So we repeat the process.  And that means, for example, we generate x2 from x1  by the same formula. ", "And we did this last time.  And, more generally, the n + 1st is generated from the nth  guess, by this formula here. ", "So what I'd like to do is just draw the picture of one step  a little bit more closely.  So I want to blow up the picture, which ", "is above me there.  That's a little too high.  Where are my erasers? ", "Got to get it a little lower than that, since I'm going  to depict everything above the line here.  So here's my curve coming down.  And suppose that x1 is here, so this is directly above ", "it is this point here.  And then as I drew it, this green tangent  coming down like that.  It's a little bit closer, and this was the place, x2, and ", "then here was x, our target, which is where the curve  crosses as opposed to the straight tangent line crossing.  So that's the picture that I want you to keep in mind. ", "And now, we're just going to do a very qualitative  kind of error analysis.  So here's our error analysis. ", "And we're starting out, the distance between x1 and x is  what we want to measure.  In other words, how close we are to where we're heading. ", "And so I've called that, I'm going to call that Error 1.  That's x - x1.  In absolute value.  And then, E2 would be x - x2, in absolute value. ", "And so forth.  And, last time, when I was estimating the size of this, so  En would be whatever it was.  Last time, remember, we did it for a specific case. ", "So last time, I actually wrote down the numbers.  And they were these numbers, maybe you could call them En,  which was the absolute value of square root of 5 - xn. ", "These are the sizes that I was writing down last time.  And I just want to talk about in general what to expect.  That worked amazingly well, and I want to show you that that's ", "true pretty much in general.  So the first distance, again, is E1, is this distance here.  That's the E1. ", "And then this shorter distance, here, this little bit,  which I'll mark maybe in green, is E2. ", "So how much shorter is E1 than E2?  Well, the idea is pretty simple.  It's that if this distance in this vertical, distances are ", "probably about the same as the perpendicular distance.  And this is basically the situation of a curve  touching a tangent line.  Then the separation is going to be quadratic. ", "And that's basically what's going to happen.  So, in other words the distance E2 is going to be about the  square of the distance E1.  And that's really the only feature of this that ", "I want to point out.  So, approximately, this is the situation that  we're going to get.  And so what that means is, and maybe thinking from last time, ", "what we had was something roughly like this.  You have an E0, you have an E1, you have an E2, you  have an E3, and so forth.  Maybe I'll write down E4 here. ", "And last time, this was about 10 ^ - 1.  So the expectation based on this rule is that the next  error's the square of the previous one.  So that's 10 ^ - 2. ", "The next one is the square of the previous one.  So that's 10 ^ - 4.  And the next one is the square of that, that's 10 ^ - 8.  And this one is 10 ^ - 16. ", "So the thing that's impressive about this list of numbers is  you can see that the number of digits of accuracy  doubles at each stage. ", "Accuracy doubles at each step. ", "The number of digits of accuracy doubles at each step.  So, very, very quickly you get past the accuracy of your  calculator, as you saw on your problem set. ", "And this thing works beautifully.  So, let me just summarize by saying that Newton's  method works very well. ", "By which I mean this kind of rate.  And I want to be just slightly specific.  If, there's really two conditions disguised in ", "this, that are going on.  One is that f' has to be, not to be.  To be not small. ", "And f'' has to be not too big. ", "That's roughly speaking what's going on. i'll explain  these in just a second.  And x0 starts nearby. ", "Nearby the target value x.  So that's really what's going on here.  So let me just illustrate to you. ", "So I'm not going to explain this, except to say the reason  why this second derivative gets involved is that it's how  curved the curve is, that how far away you get. ", "If the second derivative were 0, that would be  the best possible case.  Then we would get it on the nose.  If the second derivative is not too big, that means the  quadratic part is not too big. ", "So we don't get away very far from the green line  to the curve itself.  The other thing to say is, as I said, that x0 ", "needs to start nearby.  So I'll explain that by explaining what maybe  could go wrong.  So the ways the method can fail, and one example which ", "actually would have happened in our example from last time,  which was y = x^2 - 5, is suppose we'd started ", "x0 over here.  Then this thing would have gone off to the left, and we would  have landed on not the square root of 5 but the other root. ", "So if it's too far away, then we get the wrong root.  So that's an example, explaining that the x0 needs ", "to start near the root that we're talking about.  Otherwise, the method doesn't know which root  you're asking for.  It only knows where you started.  So it may go off to the wrong place. ", "OK, it can't read your mind.  Yes, question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: Oh, good question.  So the question was, what if the first error  is larger than 1.  Are you in trouble?  And the answer is, absolutely, yes. ", "If you have quadratic behavior, you can see.  If you have a quadratic nearby, it's pretty close  to the straight line.  But far away, a parabola is miles from a straight line.  It's way, way, way far away. ", "So if you're foolish enough to start over here, you may have  some trouble making progress.  Actually, it isn't - when I, that little wiggle there ", "just meant proportional to.  In fact, in the particular case of a parabola, it  manages to get back.  It saves itself.  But there's no guarantee of that sort of thing. ", "You really do want to start reasonably close.  Yep.  STUDENT: [INAUDIBLE] ", "PROFESSOR: What you have to do is you have to watch out.  That is, it's hard to know what assumptions to make about x0.  You plug it into the machine and you see what you get. ", "And either it works or it doesn't.  You can tell that it's marching toward a specific place, and  you can tell that that place probably is a 0, usually.  But maybe it's not the one you were looking for. ", "So in other words, you have to use your head.  You run the program and then you see what it does.  And if you're lucky - the problem is, if you have no  idea where the 0 is, you may just wander around forever. ", "As we'll see in a second.  So the next example here is the following.  I said that f' has to be not too small. ", "There's a real catastrophe hiding just inside  this picture.  Which is the transition between when you find the positive root  and when you find the negative root here.  Which is, if you're right down here. ", "If you were foolish enough to get 0, then what's going to  happen is your tangent line is horizontal.  It doesn't even meet the axis.  So in the formula, you can see that's a catastrophe. ", "Because there's an f' in the denominator.  So that's 0.  That's undefined.  It's not surprising, it's consistent that the parallel ", "line doesn't meet the axis.  And you have no x1.  So you had, so if you like, another point here is that ", "f' = 0 is a disaster.  A disaster for the method. ", "Because the next, so say, if f (x0) = 0, then x1 is undefined. ", "And finally, there's one other weird thing that can happen.  Which is, which I'll just draw a picture of schematically.  Which you can get from a wiggle. ", "So this wiggle has three roots.  The way I've drawn it.  And it can be that you can start over here with your x0.  And draw your tangent line and go over here to an x1. ", "And then that tangent line will take you right back to the x0.  I didn't draw it quite right, but that's about right.  So it goes over like this. ", "So let me draw the two tangent lines, so that  you can see it properly.  Sorry, I messed it up.  So here are the two tangent lines.  This guy and this guy.  And it just goes back and forth. x0 cycles to x1, ", "and x1 goes back to x0.  We have a cycle.  And it never goes anywhere.  This is, the grass is always greener. ", "It's over here, it thinks, oh, I really would prefer to go to  this 0 and then it thinks oh, I want to go back.  And it goes back and forth, and back and forth.  Grass is always greener on the other side of the fence. ", "Never, never gets anywhere.  So those are the sorts of things that can go wrong  with Newton's method.  Nevertheless, it's fantastic.  It works very well, in a lot of situations. ", "And solves basically any equation that you can  imagine, numerically. ", "Next we're going to move on.  We're going to move on to something which is  a little theoretical.  Which is the mean value theorem.  And that will allow us in just a day or so to launch into the ", "ideas of integration, which is the whole second  half of the course.  So let's get started with that. ", "The mean value theorem will henceforth be abbreviated MVT.  So I don't have to write quite as much every  time I refer to it. ", "The mean values theorem, colloquially, says  the following.  If you go from Boston to LA, which I think a lot of Red Sox ", "fans are going to want to do soon, so that's 3,000 miles.  In 6 hours, then at some time you are going ", "at a certain speed.  The average of this speed. ", "Average, so speed, which in this case is what?  So we're going at the average speed.  That's 3,000 miles times 6 hours, so that's ", "500 miles per hour.  Exactly.  So sometime on your journey, of course, some of the time you're  going more than 500 miles an hour, sometimes you ", "are going less.  And some time you must've been going 500 miles  an hour exactly.  That's the mean value theorem.  The reason why it's called mean value theorem is that word mean ", "is the same as the word average. ", "So now I'm going to state it in math symbols, the same theorem. ", "And it's a formula.  It says that the difference quotient, so this is the ", "distance traveled divided by the time elapsed.  That's the average speed, is equal to the infinitesimal  speed for some time in between. ", "So some c, which is in between a and b. ", "I'm not quite done.  It's a real theorem, it has hypotheses.  I've told you the conclusion first, but there are some ", "hypotheses, they're straightforward hypotheses.  Provided f is differentiable; that is, it has a derivative ", "in the interval a < x < b.  And continuous in a < or = x, less than or equal to. ", "There has to be a sense that you can make out of the speed,  or the rate of change of f at each intermediate point.  And in order for the values at the ends to make sense, ", "it has to be continuous.  There has to be a link between the values at the ends and  what's going on in between.  If it were discontinuous, there would be no relation between ", "the left and right values and the rest of the function.  So here's the theorem, conclusion and its hypothesis. ", "And it means what I said more colloquially up above. ", "Now, I'm going to prove this theorem immediately.  At least, give a geometric intuitive argument, which is  not very different from the one that's given in a very ", "systematic treatment.  So here's the proof of the mean value theorem. ", "It's really just a picture.  So here's a place, and here's another place on the graph.  And the graph is going along like this, let's say. ", "And this line here is the secant line.  So this is (a, f ( a )) down here.  And this is (b, f ( b )) up there. ", "And this segment is the secant, its slope is the slope  that we're aiming for.  The slope of that line is the left-hand side of  this formula here. ", "So we need to find something with that slope.  And what we need to find is a tangent line with that slope,  because what's on the right-hand side is the  slip of a tangent line.  So here's how we construct it. ", "We take a parallel line, down here.  And then we just translate it up, leaving it  parallel, we move it up. ", "Towards this one.  Until it touches.  And where it touches, at this point of tangency, down there, ", "I've just found my value of c.  And you can see that if the tangent line is parallel to  this line, that's exactly the equation we want. ", "So this thing has slope f' (c).  And this other one has slope equal to this complicated ", "expression, f ( b) - f (a) / (b - a).  That is almost the end of the proof. ", "There's one problem.  So, again, we move a parallel line up. ", "Move up the parallel line until it touches. ", "There's a little subtlety here, which I just want to emphasize.  Which is that that dotted line keeps on going here.  But when we bring it up, we're going to ignore what's  happening outside of a. ", "And beyond b, alright?  So we're just going to ignore the rest of the graph.  But there is one thing that can go wrong. ", "So if it does not touch, then the picture looks likes this. ", "Here are the same two points.  And the graph is all above.  And we brought up our thing.  And it went like that.  So we didn't construct a tangent line. ", "If this happens.  So we're in trouble, in that point.  In this situation, sorry. ", "But there's a trick, which is a straightforward trick.  Then bring the tangent lines down from the top. ", "So parallel lines, sorry, not tangent lines.  Parallel lines. ", "From above.  So, that's the whole story. ", "That's how we cook up this point c, with  the right properties. ", "I want to point out just one more theoretical thing.  And then the rest, we're going to be drawing conclusions.  So there's one more theoretical remark about the proof, which ", "is something that is fairly important to understand.  When you understand a proof, you should always be thinking  about why the hypotheses are necessary. ", "Where do I use the hypothesis.  And I want to give you an example where the proof doesn't  work to show you that the hypothesis is an important one.  So the example is the following. ", "I'll just take a function which is two straight  lines like this.  And if you try to perform this trick with these things, then ", "it's going to come up and it's going to touch here.  But the problem is that the tangent line is  not defined here.  There are lots of tangents, and there's no derivative ", "at this point.  So the derivative doesn't exist here.  So this is the claim that one bad point ruins the proof. ", "We need f' to exist at all so, f' ( x ) to exist ", "at all x in between.  Can't get away even with one defective point. ", "Now it's time to draw some consequences. ", "And the main consequence is going to have to do with  applications to graphing. ", "But we'll see tomorrow and for the rest of the course that  this is even more significance.  It's significant to all the rest of Calculus. ", "I'm going to list three consequences which you're  quite familiar with already.  So, the first one is if f' is positive, then f is increasing. ", "And the second one is if f' is negative, then f is decreasing. ", "And the last one seems like the simplest.  But even this one alone is the key to everything.  If f' = 0, then f is constant. ", "These are three consequences, now, of the mean value theorem. ", "And let me show you how they're proved.  I just told you that they were true, maybe a while ago.  And certainly I mentioned the first two. ", "The last one was so simple that we maybe just  swept it under the rug.  You did use it on a problem set, once or twice.  But it turns out that this actually requires proof, ", "and we're going to give the proof right now.  The way that the proof goes is simply to write ", "down, to rewrite star.  Rewrite our formula.  Which says that f (b) - f (a) / (b - a) = f' (c). ", "And you see I've written it from left to right here to say  that the right-hand side information about the  derivative is going to be giving the information  about the function.  That's the way I'm going to read it. ", "In order to express this, though, I'm going to just  rewrite it a couple of times here.  So here's f ( a ), multiplying through by the denominator. ", "And now I'm going to write it in another customary form  for the mean value theorem.  Which is f ( b ) = f ( a ) + f' (c) ( b - a). ", "So here's another version.  I should probably have put this one in the box  to begin with anyway.  And, just changing it around algebraically, ", "it's this fact here.  They're the same thing. ", "And now with the formula written in this form, I  claim that I can check these three facts. ", "Let's start with the first one.  I'm going to set things up always so that a < b.  And that's the setup of the theorem. ", "And so that means that b - a is positive.  Which means that this factor over here is a positive number. ", "If f' is positive, which is what happens in the first case,  that's the assumption that we're making, then this ", "is a positive number.  And so f( b ) > f( a ).  Which means that it's increasing. ", "It goes up as the value goes up.  Similarly, if f' (c) is negative, then this is a ", "positive times a negative number, this is negative.  f ( b ) < f(a).  So it goes the other way. ", "Maybe I'll write this way.  And finally, if f' (c) = 0, then f ( b ) = f(a). ", "Which if you apply it to all possible ends means if you can  do it for every interval, which you can't, then that  means that f is constant.  It never gets to change values. ", "Well you might have believed these facts already.  But I just want to emphasize to you that this turns out to  be the one key link between infinitesimals, between limits ", "and these actual differences.  Before, we were saying that the difference quotient  was approximately equal to the derivative.  Now we're saying that it's exactly equal to a derivative. ", "Although we don't know exactly which point to use.  It's some point in between. ", "I'm going to be deducing some other consequences in a  second, but let me stop for second to make sure that  everybody's on board.  Especially since I've finished the blackboards here.  Before we, everybody happy? ", "One question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: I'm just going to repeat your question first.  I'm a little bit confused, you said, about what  guarantees that there's a point of tangency.  That's what you said. ", "So do you want to elaborate, or do you want to want to stop  with what you just send?  What is it that confuses you?  STUDENT: [INAUDIBLE] ", "PROFESSOR: Yeah.  STUDENT: [INAUDIBLE] ", "PROFESSOR: So I'm not claiming that there's only one point.  This could wiggle a lot of times and it maybe  touches at ten places.  In other words, it's OK with me if it touches more than once. ", "Then I just have more, the more the merrier.  In other words, I don't want there necessarily  only to be one.  It could come down like this.  And touch a second time. ", "Is that what was concerning you?  So in mathematics, when we claim that this is true  for some point, we don't necessarily mean that it  doesn't work for others. ", "In fact, if the function is constant, this is 0 and  in fact this equation is true for every c.  That satisfies your question? ", "The fact that this point exists actually is a touchy point.  I just convinced you of it visually.  It's a geometric issue, whether you're allowed to do this.  Indeed, it has to do with the existence of tangent lines and ", "more analysis then we can do in this class.  Yeah.  Another question.  STUDENT: [INAUDIBLE]  PROFESSOR: Pardon me.  STUDENT: [INAUDIBLE]  PROFESSOR: The question is, what's the difference ", "between this and the linear approximation.  And I think, let me see if I can describe that. ", "I'll leave the theorem on the board.  I'm going to get rid of the colloquial version  of the theorem.  And I'll try to describe to you the difference between this ", "and the linear approximation.  I was planning to do that in a while, but we'll do it  right now since that's what you're asking. ", "That's fine.  So here's the situation.  The linear approximation, so let's say comparison with ", "linear approximation.  They're very closely related.  The linear approximation says the change in f over the change ", "in x, that's the left-hand side of this thing, is  approximately f' (a).  For b near a, and b - a = delta x. ", "This statement, which is in the box, which is sitting right up  there, is the statement that this change in f is actually  equal to something. ", "Not approximately equal to it.  It's equal to f' of some c.  And the problem here is that we don't know exactly which c. ", "This is for some c.  Between a and b. ", "Right, so.  That's the difference between the two.  And let me elaborate a little bit. ", "If you're trying to understand what f ( b ) - f ( a ) / (b -  a) is, the mean value theorem is telling you for sure that ", "it's equal to this f' (c).  So that means it's less than or equal to the largest possible  value on the largest value you can get, for sure. ", "And this is on the whole interval.  And I'm going to include the ends, because when you  take a max it's sometimes achieved at the ends. ", "And similarly, because it's f' (c), it's definitely bigger  than the min on this same interval here. ", "This is all you can say based on the mean value theorem.  All you know is this.  And colloquially, what that means is that the average ", "speed is between the maximum and the minimum. ", "Not very surprising.  The mean value theorem is supposed to be very  intuitively obvious.  It's saying the average speed is trapped between the maximum ", "speed and the minimum speed.  For sure, that's something, that's why, incidentally this  wasn't really proved when Newton and Leibniz were around. ", "But, let's write this so that you can read it.  Average speed is between the max and the min. ", "But nobody had any trouble, they didn't disbelieve it  because it's a very natural thing.  Now if, for example, I take any kind of linear approximation; ", "say, for instance, e ^ x is approximately 1 + x.  Then I'm making the guess, now, don't want to say this yet. ", "That's not going to explain it to you well enough.  What we're saying, so this is the mean value here.  This is what the mean value theorem says. ", "And here's the linear approximation.  The linear approximation is saying that the average speed ", "is approximately the initial speed, or possibly  the final speed.  So if a is the left endpoint, then it's the initial speed. ", "If it happens to be the right endpoint, if the value of x is  to the left then it's the final speed.  So those are the - so you can see it's approximately right.  Because the speed, when you're on a short interval, shouldn't ", "be varying very much.  The max and the min should be pretty close together.  So that's why the linear approximation is reasonable.  And this is telling you absolutely, it's no less ", "than the min and no more than the max.  Yeah.  STUDENT: [INAUDIBLE] ", "PROFESSOR: The little kink?  STUDENT: [INAUDIBLE]  PROFESSOR: If you approach from the top.  So if it's still under here I can show you it again.  Oh yeah, it's still there. ", "Good.  STUDENT: [INAUDIBLE]  PROFESSOR: Oh, the one with the wiggle on top?  Yeah, this one you can't.  Because there's nothing to touch and it also fails  from the bottom because there's this bad point. ", "From the top, it could work.  It can certainly work both ways.  So, for example.  See if you're a machine, you maybe don't have  a way of doing this.  But if you're a human being you can spot all the places. ", "There are a bunch of spots where the slope is right.  And it's perfectly OK.  All of them work.  STUDENT: [INAUDIBLE] ", "PROFESSOR: It's not that the c is the same.  It's just we've now found one, two, three, four, five  c's for which it works.  STUDENT: [INAUDIBLE] ", "PROFESSOR: If you're asked to find a c, so first of all  that's kind of a phony question.  There are some questions on your problem set which  ask you to find a c. ", "That actually is struggling to get you to understand what the  statement of the mean value theorem is, but you should not  pay a lot of attention to those questions. ", "They're not very impressive.  But, of course, you would have to find all the - if it asked  you to find one, you find one.  If you can find some more, fine. ", "You can pick whichever one you want.  Mean value theorem just doesn't care.  The mean value theorem doesn't care because actually, the mean  value theorem is never used except in real life, except ", "in this context here.  You can never nail down which c it is, so the only thing you  can say is that you're going slower than the maximum speed ", "and faster than the minimum speed.  Sorry, say that again?  STUDENT: [INAUDIBLE] ", "PROFESSOR: If you're asked for a specific c, you have  to find a specific c.  And it has to be in the range.  In between, it has to be in here. ", "So now I want to tell you about another kind of application,  which is really just a consequence of what  I've described here. ", "I should emphasize, by the way, this, probably,  should be doing this.  I guess we've never used this color here. ", "This popular.  This is pink.  So this one is so good.  So since we're going to do this. ", "So the reason why the exclamation points are  temporary, this is such an obvious fact.  But this is the way that you're going to want to use the mean ", "value theorem, and this is the only way you need to understand  the mean value theorem.  On your test, or ever in your whole life.  So this is the way it will be used. ", "As I will make very clear when we review for the exam.  In practice what happens is you even forget about the mean  value theorem, and what you remember is these three ", "properties here.  Which are themselves consequences of the  mean value theorem.  So these are the ones that I want to illustrate now.  In my next discussion here. ", "I'm just going to talk about inequalities. inequalities  are relationships between functions. ", "And I'm going to prove a couple of them using the properties  over there, the properties that functions with positive  derivatives are increasing. ", "Here's an example. e ^ x > 1 + x, where x > 0. ", "The proof is the following.  I consider, so here's a proof.  I consider the function f ( x ), which is the difference. ", "e ^ x - (1 + x).  I observe that it starts at f ( 0 ) equal to, well, that's e ", "^ 0 - (1 + 0), which is 0.  And, it keeps on going. f' (x) = e ^ x. ", "If I differentiate here, the 1 goes away.  I get - 1.  That's the derivative of the function.  And this function, because e ^ x > 1, for ", "x positive is positive.  As x gets bigger and bigger, this rate of increase  is positive. ", "And therefore, three dots, that's therefore, f ( x ) is  bigger than its starting place. ", "For x > 0.  If it's increasing, then that's, in particular, it's  increasing starting from 0. ", "So this is true.  Now, all I have to do is read what this inequality says.  And what it says is that e ^ x, just plug in for f ( x ), which ", "is right here. -( 1 + x) is greater than the starting  value, which was 0.  Now, I put the thing that's negative on the other side. ", "So that's the same thing as e^x > 1 + x.  That's a typical inequality. ", "And now, we'll use this principle again.  Oh gee, I erased the wrong thing.  I erased the statement and not the proof. ", "Well, hide the proof.  The next thing I want to prove to you is that e ^ ", "x > 1 + x + (x^2 / 2).  So, how do I do that?  I introduce a function g (x), which is e^x minus this. ", "And now, I'm just going to do exactly the same  thing I did before.  Which is, I get started with g ( 0 ).  Which is 1 - 1.  Which is 0. ", "And g' ( x ) is e ^ x minus - now, look at what happens  when I differentiate this. ", "The 1 goes away.  The x gives me a 1, and the x^2 / 2 gives me a + x.  And this one is positive for x > 0, because of step 1. ", "Because of the previous one that I did.  So this one is increasing. g is increasing. ", "Which says that g ( x ) > g ( 0 ).  And if you just read that off, it's exactly the same as our  inequality here. e^x > 1 + x + (x^2 / 2). ", "Now, you can keep on going with this essentially forever.  And let me just write down what you get. ", "You get e ^ x > 1 + x + (x^2 / 2).  The next one turns out to be (x^3 / 3 * 2) ", "+ (x^4 / 4 * 3 * 2).  And you can do whatever you want.  You can do others. ", "And this is like the tortoise and the hare.  This is the tortoise, and this is the hare, it's always ahead.  But eventually, if you go infinitely far, it catches up. ", "So this turns out to be exactly equal to e ^ x in the limit.  And we'll talk about that maybe at the end of the course. ", ""], "vid_duration": [19.0, 11.0, 11.0, 10.0, 10.0, 11.0, 10.0, 10.0, 11.0, 14.0, 12.0, 10.0, 14.0, 10.0, 11.0, 14.0, 13.0, 13.0, 16.0, 11.0, 14.0, 14.0, 12.0, 11.0, 11.0, 12.0, 10.0, 11.0, 12.0, 13.0, 11.0, 10.0, 11.0, 14.0, 11.0, 11.0, 18.0, 10.0, 10.0, 10.0, 15.0, 10.0, 11.0, 10.0, 12.0, 22.0, 11.0, 13.0, 12.0, 12.0, 15.0, 14.0, 12.0, 12.0, 10.0, 10.0, 10.0, 10.0, 12.0, 12.0, 11.0, 12.0, 10.0, 12.0, 15.0, 10.0, 13.0, 14.0, 10.0, 14.0, 10.0, 12.0, 12.0, 12.0, 13.0, 26.0, 13.0, 20.0, 28.0, 10.0, 16.0, 11.0, 13.0, 14.0, 13.0, 11.0, 16.0, 11.0, 11.0, 12.0, 20.0, 11.0, 10.0, 10.0, 11.0, 11.0, 12.0, 13.0, 12.0, 12.0, 11.0, 10.0, 11.0, 10.0, 14.0, 12.0, 10.0, 14.0, 11.0, 12.0, 10.0, 11.0, 10.0, 18.0, 11.0, 10.0, 27.0, 10.0, 13.0, 11.0, 11.0, 11.0, 18.0, 10.0, 23.0, 10.0, 17.0, 12.0, 18.0, 13.0, 23.0, 10.0, 14.0, 12.0, 12.0, 19.0, 12.0, 15.0, 14.0, 12.0, 10.0, 11.0, 12.0, 12.0, 11.0, 10.0, 11.0, 17.0, 12.0, 23.0, 13.0, 10.0, 12.0, 12.0, 10.0, 10.0, 10.0, 14.0, 11.0, 11.0, 11.0, 14.0, 12.0, 11.0, 18.0, 15.0, 10.0, 16.0, 10.0, 19.0, 10.0, 10.0, 12.0, 26.0, 13.0, 12.0, 10.0, 13.0, 12.0, 10.0, 11.0, 10.0, 11.0, 15.0, 14.0, 10.0, 12.0, 15.0, 12.0, 11.0, 11.0, 10.0, 11.0, 12.0, 11.0, 12.0, 11.0, 10.0, 12.0, 15.0, 10.0, 12.0, 17.0, 18.0, 10.0, 15.0, 11.0, 12.0, 12.0, 13.0, 11.0, 10.0, 12.0, 13.0, 14.0, 13.0, 10.0, 10.0, 10.0, 10.0, 12.0, 12.0, 12.0, 11.0, 10.0, 17.0, 11.0, 10.0, 15.0, 10.0, 20.0, 10.0, 11.0, 10.0, 12.0, 10.0, 0.76], "stet": [[0, 19.0], [19.0, 30.0], [30.0, 41.0], [41.0, 51.0], [51.0, 61.0], [61.0, 72.0], [72.0, 82.0], [82.0, 92.0], [92.0, 103.0], [103.0, 117.0], [117.0, 129.0], [129.0, 139.0], [139.0, 153.0], [153.0, 163.0], [163.0, 174.0], [174.0, 188.0], [188.0, 201.0], [201.0, 214.0], [214.0, 230.0], [230.0, 241.0], [241.0, 255.0], [255.0, 269.0], [269.0, 281.0], [281.0, 292.0], [292.0, 303.0], [303.0, 315.0], [315.0, 325.0], [325.0, 336.0], [336.0, 348.0], [348.0, 361.0], [361.0, 372.0], [372.0, 382.0], [382.0, 393.0], [393.0, 407.0], [407.0, 418.0], [418.0, 429.0], [429.0, 447.0], [447.0, 457.0], [457.0, 467.0], [467.0, 477.0], [477.0, 492.0], [492.0, 502.0], [502.0, 513.0], [513.0, 523.0], [523.0, 535.0], [535.0, 557.0], [557.0, 568.0], [568.0, 581.0], [581.0, 593.0], [593.0, 605.0], [605.0, 620.0], [620.0, 634.0], [634.0, 646.0], [646.0, 658.0], [658.0, 668.0], [668.0, 678.0], [678.0, 688.0], [688.0, 698.0], [698.0, 710.0], [710.0, 722.0], [722.0, 733.0], [733.0, 745.0], [745.0, 755.0], [755.0, 767.0], [767.0, 782.0], [782.0, 792.0], [792.0, 805.0], [805.0, 819.0], [819.0, 829.0], [829.0, 843.0], [843.0, 853.0], [853.0, 865.0], [865.0, 877.0], [877.0, 889.0], [889.0, 902.0], [902.0, 928.0], [928.0, 941.0], [941.0, 961.0], [961.0, 989.0], [989.0, 999.0], [999.0, 1015.0], [1015.0, 1026.0], [1026.0, 1039.0], [1039.0, 1053.0], [1053.0, 1066.0], [1066.0, 1077.0], [1077.0, 1093.0], [1093.0, 1104.0], [1104.0, 1115.0], [1115.0, 1127.0], [1127.0, 1147.0], [1147.0, 1158.0], [1158.0, 1168.0], [1168.0, 1178.0], [1178.0, 1189.0], [1189.0, 1200.0], [1200.0, 1212.0], [1212.0, 1225.0], [1225.0, 1237.0], [1237.0, 1249.0], [1249.0, 1260.0], [1260.0, 1270.0], [1270.0, 1281.0], [1281.0, 1291.0], [1291.0, 1305.0], [1305.0, 1317.0], [1317.0, 1327.0], [1327.0, 1341.0], [1341.0, 1352.0], [1352.0, 1364.0], [1364.0, 1374.0], [1374.0, 1385.0], [1385.0, 1395.0], [1395.0, 1413.0], [1413.0, 1424.0], [1424.0, 1434.0], [1434.0, 1461.0], [1461.0, 1471.0], [1471.0, 1484.0], [1484.0, 1495.0], [1495.0, 1506.0], [1506.0, 1517.0], [1517.0, 1535.0], [1535.0, 1545.0], [1545.0, 1568.0], [1568.0, 1578.0], [1578.0, 1595.0], [1595.0, 1607.0], [1607.0, 1625.0], [1625.0, 1638.0], [1638.0, 1661.0], [1661.0, 1671.0], [1671.0, 1685.0], [1685.0, 1697.0], [1697.0, 1709.0], [1709.0, 1728.0], [1728.0, 1740.0], [1740.0, 1755.0], [1755.0, 1769.0], [1769.0, 1781.0], [1781.0, 1791.0], [1791.0, 1802.0], [1802.0, 1814.0], [1814.0, 1826.0], [1826.0, 1837.0], [1837.0, 1847.0], [1847.0, 1858.0], [1858.0, 1875.0], [1875.0, 1887.0], [1887.0, 1910.0], [1910.0, 1923.0], [1923.0, 1933.0], [1933.0, 1945.0], [1945.0, 1957.0], [1957.0, 1967.0], [1967.0, 1977.0], [1977.0, 1987.0], [1987.0, 2001.0], [2001.0, 2012.0], [2012.0, 2023.0], [2023.0, 2034.0], [2034.0, 2048.0], [2048.0, 2060.0], [2060.0, 2071.0], [2071.0, 2089.0], [2089.0, 2104.0], [2104.0, 2114.0], [2114.0, 2130.0], [2130.0, 2140.0], [2140.0, 2159.0], [2159.0, 2169.0], [2169.0, 2179.0], [2179.0, 2191.0], [2191.0, 2217.0], [2217.0, 2230.0], [2230.0, 2242.0], [2242.0, 2252.0], [2252.0, 2265.0], [2265.0, 2277.0], [2277.0, 2287.0], [2287.0, 2298.0], [2298.0, 2308.0], [2308.0, 2319.0], [2319.0, 2334.0], [2334.0, 2348.0], [2348.0, 2358.0], [2358.0, 2370.0], [2370.0, 2385.0], [2385.0, 2397.0], [2397.0, 2408.0], [2408.0, 2419.0], [2419.0, 2429.0], [2429.0, 2440.0], [2440.0, 2452.0], [2452.0, 2463.0], [2463.0, 2475.0], [2475.0, 2486.0], [2486.0, 2496.0], [2496.0, 2508.0], [2508.0, 2523.0], [2523.0, 2533.0], [2533.0, 2545.0], [2545.0, 2562.0], [2562.0, 2580.0], [2580.0, 2590.0], [2590.0, 2605.0], [2605.0, 2616.0], [2616.0, 2628.0], [2628.0, 2640.0], [2640.0, 2653.0], [2653.0, 2664.0], [2664.0, 2674.0], [2674.0, 2686.0], [2686.0, 2699.0], [2699.0, 2713.0], [2713.0, 2726.0], [2726.0, 2736.0], [2736.0, 2746.0], [2746.0, 2756.0], [2756.0, 2766.0], [2766.0, 2778.0], [2778.0, 2790.0], [2790.0, 2802.0], [2802.0, 2813.0], [2813.0, 2823.0], [2823.0, 2840.0], [2840.0, 2851.0], [2851.0, 2861.0], [2861.0, 2876.0], [2876.0, 2886.0], [2886.0, 2906.0], [2906.0, 2916.0], [2916.0, 2927.0], [2927.0, 2937.0], [2937.0, 2949.0], [2949.0, 2959.0], [2959.0, 2959.76]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [433, 886, 1568, 2069, 2562, 2960]}
{"example_id": "mit001@@ocw-18.01-f07-lec25_300k", "text": ["PROFESSOR: Now, today I need to get started by finishing  up what I did last time.  Namely, talking about numerical methods.  And I want to just carry out one example. ", "And then I want to fill in one loose end.  And then we'll talk about the unit overall. ", "We were talking, last time, about numerical integration. ", "I'm going to illustrate this just with the simplest  example that I can.  We're going to look at the integral from 1 to 2 of dx / x. ", "Which we know perfectly well already is the log of x  evaluated between 1 and 2, which is ln 2 - ln 1.  Which is just ln 2. ", "Now, if you punch that into your calculator, you're going  to get something like this.  I hope I saved it here. ", "Yeah.  It's about 0.693147. ", "That's more digits than we're going to get in  our discussion here.  Anyway, that's about how big this number is.  And the numerical integration methods will give you about ", "as much accuracy as you can get on the function itself.  And, of course, some functions we may have more  trouble approximating. ", "But the function 1 / x, we know pretty well how to do, because  we know how to divide.  So since the function that we're integrating here is 1 /  x, it's going to be not too difficult to get ", "some arithmetic.  Nevertheless, I'm going to do this in the simplest  possible case.  Namely, just with two intervals. ", "Now, you really can't expect things to work so well  with two intervals.  That's a pretty ridiculous approximation to your function.  When you have two intervals, that means you're looking at ", "the graph of this hyperbola.  And you have 1 here, and you have 2 here and you have 3/2.  And you're really only keeping track of the values ", "at these three spots.  So the idea that you can approximate the area just by  knowing the values of three places is a little bit of a ", "stretch of the imagination.  But we're going to try it anyway.  Now, the trapezoidal rule is the following formula. ", "It's delta x ( 1/2 the first value + the second value  + 1/2 the third value).  In this case, the pattern is 1/2, 1, 1, 1, 1, 1, 1/2. ", "And in this case, delta x = 1/2 because this  interval's of length 1.  The b - a, right. ", "Let's just point that out here.  Here, b = 2. a = 1. b - a = 1.  And the number n = 2. ", "And so, delta x, which is b - a / n = 1/2.  So here's what we get.  And let's just see what this number is. ", "It's 1/2 of the value at here.  Well, so let's just check what these values are.  This value is 1, this value over here is 2/3, and ", "the last value is 1/2.  Because the function, of course, was y = 1 / x.  And those were the three values that we have.  So y0, this one is y0, this one is y1, and this one is y2. ", "Now, here we have (1/2* 1 + 2/3 + 1/2 * 1/2). ", "Now, on an exam, I don't expect you to add up long messes  of numbers like this.  When you have two numbers, I expect you to add them up if ", "they're reasonable, or subtract them.  Just as we do when we take antiderivatives.  Like, for example, I don't want you to leave the answer to  an integration like this in this form.  I want you to simplify it at least down to here. ", "And I of course don't expect you to know the  numerical approximation.  But I certainly expect you to be able to do that.  On the other hand, when the arithmetic gets a little bit  long, you can relax a little bit. ", "But I did carry this out on my calculator.  Unless I'm mistaken, it's about 0.96.  It's pretty far off. ", "So remember what it was.  It's what you get when you get these straight lines.  And there are these little extra pieces of junk there.  Now, don't trust that too much, but the point ", "is that it's far off.  So now, let's take a look at Simpson's Rule. ", "And I claim that Simpson's Rule is surprisingly accurate.  In this case, really, even a little more than  it deserves to be.  The formula is (delta x / 3) ( y0 + 4 y1 + y2). ", "So the pattern is 1, 4, 1, or 1, 4 and then it alternates  2's and 4's until 4, 1 at the very end. ", "And if I just plug in the numbers now, what I get is 1/6,  because delta x = 1/2 again.  And the value for y0 = 1. ", "And the value for y1 = 2/3.  And the value for y2 = 1/2.  So here's the estimate in this case. ", "And this one I did carry out carefully.  And it came out to 0.69444. ", "Which is actually pretty impressive, if you  think about it.  Given what the logarithm is. ", "Now, what's going on with Simpson's Rule  in general is this.  If you -- Simpson's minus the exact answer. ", "In absolute value, is approximately of the  size of (delta x)^ 4.   That's really the way it behaves.  Which means that if delta x is about 1/10, so if we had ", "divided this up into 10, intervals which we didn't, but  if we'd divided it up into 10 intervals, then you could  expect that delta x, the error would be about 10 ^ - 4. ", "In other words, four digits of accuracy here for this thing.  But the exact analysis of this, a more careful analysis of ", "this, is in your textbook.  And I'm not going to do.  But I just want to point out that it is an effective method.  It really does give you nice four-digit with manageable, ", "you could even really do it by hand.  It's so convenient.  The Simpson's Rule.  Whereas the other rules aren't really that impressive as ", "far as giving fairly accurate answers.  The last little remark to make is that the reason  is that Simpson's Rule is matching a parabola. ", "And somehow the parabola follows this curve better.  It's giving the exact answer.  So I'll mention this.  Simpson's Rule is derived using the exact answer for all ", "degree 2 polynomials.  In other words, parabolas.  All parabolas. ", "But even all the ones of lower degree.  So straight lines would work, and constants  would work as well.  Whereas the other ones only work for, say, straight lines.  The trapezoidal rule only works for straight lines. ", "But ther isn't a weird accident.  It turns out that it also works for cubics.  Once you get the formulas, it works for cubics.  So it's also exact for cubics. ", "And that's what explains the fourth order validity.  The last thing that I want to point out is that this  is extremely vague, that I said there. ", "And you should be a little bit cautious about it.  You need to watch out for 1 / x for x near 0. ", "All bets are off if the function is singular.  And there's a lot of area under there.  And it's also true that if the derivative messes up, ", "you're in trouble too.  You really need for the function to be nice and smooth  in order for Simpson's Rule to work.  This is woth out.  That's a real woth out, but try to. ", "Watch out.  Watch out for whenever x near 0.  Then this thing doesn't work.  This thing really depends on bounds on derivatives.  But I'm going to be relatively vague about that. ", "I'm not attempting to give you an error analysis here.  OK, so if you were doing this on an exam, how do ", "you remember this strange pattern of numbers?  The one thing that I want to recommend to you is, as a way ", "of remembering it, so the one mnemonic device, we'll call it ", "a mnemonic device here, for remembering what it is that  you're doing, is to remind yourself of what happens for ", "the simplest possible case.  Which is f ( x) = 1.  It seems very modest, but if it doesn't give you the exact  answer for f (x) = 1, you've got the wrong weightings. ", "And here, if you check out what happens in the first formula  here, y0 / 2 + y1 +..., well, we'll go all the way ", "to yn - 1 + yn / 2.  If you check that formula out here, this is the  trapezoidal rule.  If you check it out for this case, then what you get is ", "that this is equal to delta x times what?  Well, all of these are 1's.  And how many are there in the middle?  There are n - 1 of them in the middle.  So it's 1/2 + n - 1 + 1/2. ", "At the tail end.  So all told it's (delta x)( n).  And I remind you that delta x = b - a / n. ", "So, delta x, this thing, is equal to b - a.  And that's just as it should be.  What we just calculated is an approximation to ", "this integral here.  Which is just the area of the rectangle of base  b - a and height 1.  Which of course is b - a. ", "So this is the check that you got your weighted  average correct here.  You've put the correct weightings on everything.  And you can do this same thing with Simpson's Rule. ", "And match up those quantities.  There was a question in the room at some point. ", "No, OK.  So now, the next thing I want to do for you is the loose  end which I left hanging. ", "Namely, I want to compute that mysterious constant  square root of pi / 2.  This is really one of the most famous computations ", "in calculus.  And it's a very, very clever trick.  I certainly don't expect you to come up with this trick.  I certainly wouldn't have myself. ", "But it's an important thing to calculate.  And it's just very useful.  So I'm going to tell you about it.  And it's just on the subject that we're dealing with in ", "this unit; namely, slicing.  Or adding up.  So the first step, which is just something that we already ", "did, was that we found the volume under this curve. ", "This bell-shaped curve, e ^ - r ^2.  But rotated around an axis. ", "Rotated around this axis.  Around this way. ", "So we figured that out.  And that was a relatively short computation.  I'm just going to remind you, it goes by shells.  We integrate the whole range from 0 to infinity. ", "And we have 2 pi r e^ - r ^2 dr. So this again is the  circumference of the shell.  This is the height of the shell, and this is the  thickness of the shell. ", "Circumference, height, thickness. ", "So we're just taking a little piece here and  sweeping it around.  And then adding up.  And then this antiderivative is pi, - pi e^ - r ^2, ", "evaluated at 0 and infinity.  And we worked this out last time.  This is pi.  It's pi (1 - 0). ", "Which is pi.  So the conclusion is that V = pi.  We already know that.  Now, the problem that we want to deal with now is the problem ", "not of a volume, but an area.  And this looks quite different.  And of course the answer is going to be different. ", "But let's do it.  So this is this question mark here.  And I'm going to do the one from minus  infinity to infinity. ", "And I'll relate it to what we talked about earlier in this  unit, in just a couple of minutes when I show you the ", "procedure that we're going to follow.  So here's the quantity and now, what this is interpreted as is  the area under this bell curve. ", "This time, Q is really an area. ", "Now, what's going to turn out to happen, is this.  This is the trick.  We're going to compute V in a different way.  And you'll see it laid out in just a second. ", "We will compute V by slices.  We're going to slice it like a piece of bread here. ", "We're going to solve for that same thing here.  And then, amazingly, what's going to happen is that we  will discover that V = Q ^2. ", "That's going to be what's going to come out.  And that's the end of the computation that we want. ", "Because actually we already know what V is.  We don't want to read this equation forward.  We want to read it the other way.  We want to say Q^2 = V, which we already know is pi. ", "And so Q = the square root of pi. ", "I haven't shown this yet, this is the weird part.  And I'm going to put it in a little box so that we know that  this is what we need to check.  We need to check this fact here. ", "We haven't done that yet.  Now, let me connect this with what we did a few days ago.  With what I called one of the important functions of ", "mathematics besides the ones you already know.  And so the function that we were faced with, and that we  discussed, was this one. ", "And then, we were interested in the value at infinity.  We were interested in this.  Which, if you draw a picture of it, and you draw the same bell ", "curve, that's the area under half. of it.  That's the area starting from 0 and going to infinity.  That's the area under half.  So this chunk is F of infinity. ", "And now I hope that this part of the connection is  not meant to be fancy.  The idea here is that Q = 2 F(infinity). ", "This number here.  And so F of infinity = to the square root of pi / 2, if we  believe what we said on the last panel. ", "And that was the thing that I drew a picture of on the board.  Namely, the graph of F looked like this.  And there was this asymptote, which was the limit F (x) tends ", "to square root of pi / 2.  As x goes to infinity.  That was that limiting value.  Which is F of infinity. ", "So this is the asymptote.  And now I've explained the connection between what we ", "claimed to be 4, which was quite mysterious, and what  we're actually going to be able to check now.  Concretely, by making this computation. ", "So how in the world can you get something like this.  What's in that orange box there, that V = Q ^2.  Again, the technique is to use slices here. ", "And I'm going to have to draw you a 3-D picture  to visualize the slice.  Let's do that.  I'm going to draw three axes now, because we're now going to ", "be in three-dimensional space, and I want you to imagine the x  axis as coming out of the blackboard, the y axis is  horizontal, and there's a new axis, which I'll call the ", "z axis which is going up.  So what's happening here is that I'm thinking of this,  this is, if you like, some kind of side view.  And this is a view where I've tilted things a ", "little bit up to the top.  Now, the distribution, or you could think of this target in  the plane, where the most likely places to hit were in ", "the middle and it died off.  As we went down.  Now, I want to draw a picture of this graph.  I'm going to draw a picture of e^ - r squared. ", "And it's basically a hump.  So I'm going to take the first, the slice along y = 0.  The y = 0 slice.  And I claim that that goes up like this. ", "And then comes back down.  Let me shade this in, so that you can see what  kind of a slice this is.  This is supposed to be along this vertical plane here. ", "Which is coming out of the blackboard and  coming towards you.  And that's a slice.  Now, I'm going to draw one more slice so that you  can see what's happening. ", "I'm going to draw a slice at another place.  Along here.  This will be y = b.  Some other level.  And now I'm going to show you what happens.  What happens is that the hump dies down a little bit. ", "So the bump is just a little bit lower.  And it's going to look a little bit the same way.  But it's just going to be a bit smaller.  So there's another slice here. ", "Like that.  And I want to give a name to these slices.  I'm going to call this A ( b). ", "That is, the area of the b slice. ", "Under the surface.  OK Yes, question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: Yeah, the solid.  Yeah.  We're trying to figure out this volume here, which is the one  we started out with, by slices.  So first I have to think of, I'm going to visualize. ", "So here I didn't even visualize.  I took a cross section and I thought about how to spin it  around without actually doing that in  three-dimensional space.  But now I'm going to take a different kind of slice. ", "I'm going to take that same bump, which is a  three-dimensional object.  I'm going to lay it down on a plane.  Which looks like this.  And then it's a bump here. ", "It's a hump.  And now I'm going to try to slice it by various planes.  STUDENT: [INAUDIBLE]  PROFESSOR: So one way of defining the bump, as you just ", "suggested, is you take this curve and you rotate it  around this z-axis.  So in other words, you make this the axis of rotation,  you spin it around.  That's correct.  So that shows you that the peaks as you go down here are ", "going to descend the same way.  But I don't want to draw those lines.  I want to imagine what the parallel slices are.  Because I don't want to get cross slices. ", "I want all slices parallel to the same thing.  STUDENT: [INAUDIBLE]  PROFESSOR: OK.  This is not particularly easy to visualize. ", "Now, here's the formula for volume by slices.  The formula for volume by slices is that you add up ", "the areas of the slices.  That's how you do it.  You take each slice.  You add the cross-sectional area, and then you take a ", "little thickness, dy, and then you add all of them up.  Because this is extending over the whole plane, we're going to  have to go all the way from minus infinity to  plus infinity. ", "And this is the formula for volumes by slicing. ", "And now our goal, in order to do this calculation, we're  going to just fix y = some b.  We're just going to fix one of these slices. ", "And we're going to calculate A ( b).  That's what we need to do in order to make this ", "procedure succeed.  This is the only place where this method works. ", "But it's an important one.  In order to make it work, I'm going to have to again  draw the plot from a different point of view. ", "I'm going to do the top view.  So I want to look down on this x-y plane here. ", "This is the x direction, and here's the y direction.  And then again I want to draw my slice.  My slice is here. ", "At y = b.  So we're just right on top of it.  And it's coming up at some kind of bump.  Here, with a little higher in the middle and going ", "down on the sides.  Now, the formula for the height is this.  If I take a distance r here, the formula for the height ", "of the bump is e ^ - r ^2.  I'll store that over here. e ^ - r ^2 is the ", "height at this place.  If this distance to the origin is r.  That's true all the way around.  And in terms of b and x, we can figure out that ", "by this right triangle.  This height is b, and this distance is x.  So r ^2 = b ^2 + x ^2. ", "Question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: The question is, is that the x-y plane.  So the answer is that over here I cleverly used the letter r.  I avoided using y's and z's or anything. ", "And over here, this is the distance r.  And you like this, is z, going up.  That's the way to think of it.  So that all of the letters are consistent.  So I just avoided giving it a name. ", "That's good, that's exactly the point.  Alright.  So now, I claim I have a formula for r ^2.  And so I can write this down.  This is e ^ - (b ^2 + x ^2). ", "But now I'm going to use the rule of exponents.  Which is that this is the same as (e ^ - b ^2) ( e^ - x^2).  And that's going to be the main way in which we use the ", "particular function that we're dealing with here.  That's really the main step, amazingly.  So now I get to compute what A ( b) is. ", "A( b) is the area under a curve.  So it's going to be, let me write it over here, A(b) is the  area under this curve here. ", "Which is some constant times, so if you imagine, call  this thing the name c.  Under some curve, c e ^ - x ^2. ", "Where the c = e^ - b ^2.  That's what our slice is. ", "In fact, it looks like one of those.  It looks like one of those bumps.  Here's its formula again.  It's the integral from minus infinity to infinity of (e^ ", "- b ^2)( e ^ - x ^2) dx.  We just recopied what I had up there. ", "And this is the height at each value of x, with b fixed.  And now, so we have a lot of steps here. ", "But each of them is very elementary.  The first one was just that law of exponents.  That we could split the two into products.  Now I'm going to make that splitting even further.  This is a constant. ", "It's not varying with x.  So I'm going to factor it out of the integral.  This is e ^ - b ^2 times the integral from minus infinity  to infinity of e^ -x^2 dx. ", "So this might look frightening, but actually it's just the  property of an integral.  All integrals have this kind of property.  You can always factor out a constant. ", "And now here comes the remarkable thing.  This is e ^ - b^2 times a number which is  now familiar to us.  What is this number? ", "This is what we're looking for.  This is our unknown, Q. ", "So I've computed A(b), and now I'm ready to finish  the problem off.  A (b) = ( e^ - b^2) Q.  Q is that strange number which we don't know yet. ", "What it is.  So now I'm going to compute the whole volume.  The whole volume, remember, it's over there, it's minus  infinity to infinity, A ( y) dy. ", "And now I'm just going to plug in the formula  that we've found for a.  Now I'm doing this for each b, so I'm doing it  varying over all b's.  So I have the integral from minus infinity to infinity. ", "And here I have e^ - y ^2.  I've replaced b by y.  And now I have Q.  And I have dy.  I just recopied what I had over there into the ", "formula for slicing.  And now, I'm going to do this trick of factoring out the  constant a second time.  This is a constant.  It doesn't depend on y. ", "It's the same for all y, it just will factor out.  So this is the same as Q times the integral from minus  infinity to infinity, e ^ - y ^2 dy. ", "And now, lo and behold, this expression here.  Of course, notice how I defined Q.  Let's go back carefully to where Q is defined.  Here's Q. ", "This t is a dummy variable.  It doesn't matter what I call it.  I can call it x, I can call it u, I can call it v.  In this case, I've given it two different names.  At this stage, I called it x. ", "And at this stage I'm calling it y.  But it's the same variable.  And so this little chunk is Q and altogether I have two of  them, for Q ^2 being the total. ", "And that's the end of the argument.  It's a real miracle. ", "STUDENT: [INAUDIBLE] ", "PROFESSOR: Great question.  The question is, wait a minute.  As y changes, doesn't x change.  And so then this wouldn't be a constant. ", "So that's the way in which we've used the letters x and  y in this whole course.  When you get to 18.02, you'll almost never do that.  Always y and x will be different variables. ", "And they won't have to depend on each other.  Now, let me show you where on this picture the  x and the y are.  We've got a whole x-y plain, and here I'm fixing y  = b, y isn't varying. ", "Whereas x is changing.  So, in other words, I don't have a relationship between  x and y, unless I fix it.  In this case I've decided that y is going to be constant.  For all x. ", "Over here, I made a computation.  And I have a Q, which is just a single number.  No matter which b I took, it didn't matter which.  No matter which y = b. ", "Of course, I changed the name to b so it wouldn't  be so jarring to you.  But in fact this b was y all along.  It's just that the x varied completely ", "independently of the y.  I could fix the y and vary the x, I could fix  the x and vary the y.  So it's a different use of the letters. ", "From what you're used to.  It happens that y is not a function of x.  In this case.  Yes.  STUDENT: [INAUDIBLE] ", "PROFESSOR: Yes.  STUDENT: [INAUDIBLE]  PROFESSOR: The question is, because I'm rotating around ", "the z axis, doesn't x change exactly as much as y does.  What happens is that x and y are symmetric variables.  They can be treated equally. ", "But if I decide to take slices with respect to y being fixed  and x varying, then of course they're now separated, and I  have a separate role for the x and a separate role for the y. ", "Or if I'd sliced it the other way, I would have  gotten the same answer.  I just would have reversed the roles of x and y.  So what's happening is that x and y are on equal  footing with each other. ", "In this picture, and I could've sliced the other way.  It would have gotten the same answer.  That's more or less the answer to your question.  OK. ", "Now I have given you a review sheet, and I want to run  through, briefly, what's going to be on the exam. ", "And this list of exam questions is what's  going to be on the exam.  There are, sorry this is not displayed correctly. ", "So, exam questions, but now I'm just going to show  you what they are.  There are five questions on the exam.  They are completely parallel to what you got last year. ", "So you should look at that test.  It's worth looking at.  And you'll see in the descriptions on this sheet  that what I'm describing is what's on that test. ", "So what's going to happen is, and this is also posted on the  Web, is that you'll be expected to calculate some definite ", "integrals using the fundamental theorem of calculus.  Do a numerical approximation.  There'll be a Riemann, a trapezoidal rule  and a Simpson's Rule.  Calculate areas and volumes. ", "And then some other cumulative sum.  Either an average value or probability or perhaps work.  And sketch a function which is given in this ", "form as an integral.  So those are the questions, and you'll see by the  example of last year's exam exactly the style. ", "They're really going to be very similar.  Yes, question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: OK, good question.  So the question is, for Riemann sums, what's the difference  between upper and lower, and right and left? ", "So here we have a Riemann sum.  And I'm going to give you a picture which is, maybe this ", "function y = 1 / x, which was the one that we were  discussing earlier.  If you take the function y = 1 / x and you break it up into ", "pieces here, however it doesn't matter how many pieces, let's  just say there are four of them.  Then the lower Riemann sum is the staircase which ", "fits underneath.  So this one is a picture of the lower sum.  It's always less. ", "And in the case of a decreasing function, it's going to be, so  since if you like, since 1 / x decreases, the lower sum ", "equals the right sum.  You can see that visually on this picture.  The values you're going to select are going to be the ", "right ends of the rectangles.  The upper sum is the left one.  Now, if the function wiggles up and down, then you have to pick ", "whichever side is appropriate.  Or maybe it'll be a point in the middle, if the maximum  is achieved in the middle. ", "Yeah, another question.  STUDENT: [INAUDIBLE]  PROFESSOR: Correct.  If the function is increasing, then the lower sum ", "is the left sum.  So it just exactly reverses what's here.  So this is decreasing, lower sum is right-hand sum.  Increasing, lower sum is left-hand sum. ", "STUDENT: [INAUDIBLE]  PROFESSOR: Yes.  STUDENT: [INAUDIBLE] ", "PROFESSOR: Good question.  Suppose you're faced with a function like this  in this last problem.  Which, generally, these are the trickiest problems.  And the question is, how are you ever going to be able to ", "decide on an asymptote, even whether there is an asymptote.  And the answer is, you're not.  It's going to be pretty tricky to get keep track ", "of what's happening as it goes to infinity.  We had an example on the homework where is was  oscillating and it's very unclear what's going on.  You have to do a very long analysis for that. ", "So in fact, just don't worry about that now.  At the very end of the class, we'll talk a little bit  about these asymptotes.  And really, the first issue is whether they exist or not. ", "And that's even something.  That's a serious question which we'll address at the  very end of this course.  STUDENT: [INAUDIBLE]  PROFESSOR: That's right.  It's not going to be anything that complicated. ", "Other questions?  We we still have a five whole minutes, and I have an example  to give, if nobody has a question. ", "Yeah.  STUDENT: [INAUDIBLE]  PROFESSOR: The question, uh, will I tell you which  one of what to use? ", "STUDENT: [INAUDIBLE]  PROFESSOR: When I tell you the numeric approximation is,  you'll see on the exam.  The practice exam that you have.  I will ask you for all three.  I will ask you for the Riemann sum, the trapezoidal rule, ", "and the Simpson's rule.  I'm guaranteeing you they'll all three be on the exam.  I'm guaranteeing that every single thing which is on that  piece of paper is on the exam.  And you'll see it on the exam that you've got. ", "It's exactly parallel to what's there.  STUDENT: [INAUDIBLE]  PROFESSOR: So with areas and volume, the question is will I ", "tell you which method to use.  So let's discuss that. ", "So with areas and volumes, there's basically, so this ", "is always true with areas.  And it's true with volumes of revolution.  By the way you should read this sheet. ", "Not everything that's on here is, have I said.  But you should read it.  Because it's all relevant.  So with volumes of revolution, you always work your way ", "back to some 2-D diagram.  So there's some 2-D diagram which is always two-dimensional ", "diagram, which is always connected with these problems.  I mean, something this hard is really just too hard  to do on an exam, right?  I mean, I'm not going to ask you something this  complicated on the exam. ", "Because this involves a three-dimensional  visualization.  But once you're down to 2-D, you're supposed to  be able to handle it. ", "Now, what's the main issue after you've  got your 2-D diagram?  The main issue is, do you want to integrate with  respect to dx or dy? ", "And the answer is that it will depend.  And if there's one that's going to cause you incredible ", "difficulty, and I feel that you're not able to dodge it,  then I might give you a hint and say you'd better use  shells, or you'd better use disks or washers or ", "something like that.  But if I feel that you're grown up enough to figure out which  one it is, because one of them is so ridiculous you say  forget it, immediately.  After thinking about it. ", "Then I won't tell you which one.  Because I figure, in other words, I don't want you  to waste your time.  But I'm willing to waste a minute or two of your time ", "on a wild goose chase.  So let me give you an example of this. ", "Suppose you're looking at the curve y < 0 < - x^3. ", "So this is some kind of lump.  Like this.  It goes from 0 to 1, because the right-hand side  is 0 at 0 and 1 here. ", "It's some kind of thing.  And there are these two possibilities.  One of them is to do shells.  And then, so this is supposed to be rotated ", "around the y axis.  In this case.  And the same would apply, actually, to the area problem. ", "So I'm doing a slightly more complicated problem.  But you could ask for the area underneath this.  So forth.  OK.  So we can integrate this dx, or we can integrate this dy.  This indicates that I'm deciding that this is going ", "to be of thickness dx, and I'm integrating dx.  So that's a choice that I'm making.  Now, the minute I made that choice I know  that these are shells. ", "Because they sweep around this way and that makes them shells.  Cylindrical shells.  And if I do that, the setup is this.  It's 2 pi x ( x - x ^3) dx. ", "Now, I claim that when you get to this point, you  already know you've won.  Because this is an easy integral to calculate.  So you're done here.  You're happy. ", "Now, if you happened to say, oh gee, I hate to do this.  I want to do something clever, you could try to do it ", "with cutting this way.  Let's do this.  And this would be the dy thickness. ", "And then when you sweep this around, you get  what we call a washer.  Which is really just the difference of two disks. ", "So the shape here is this thing swung around this axis. ", "And it looks like this.  So it's going to be the difference of radii.  So what's the formula for this?  It's some integral of pi times the right end, which I'll ", "call x2, and here the left end, which I'll call x1.  So this is pi (x2 ^2 - x1 ^2) dy. ", "Now, already at this stage, you think to yourself  this is more complicated than the other method.  So you've already abandoned it.  But I'm just going to go one step further into this one ", "to see what it is that's happening.  If you try to figure out what these values x1 and x2 are,  that corresponds to solving for x1 and x2 in terms of y. ", "So that's the following equation. x1 and x2 solve  the equation that the curve, x - x^3 = y. ", "Now, look at this equation.  That's the equation x ^3 - sorry, x ^3 - x + y, I guess. ", "Let's see.  Yeah, that's right, is equal to 0.  This is a cubic equation. ", "Although there is a formula for this.  You've never been taught the formula for this equation.  So therefore, you will never, ever be able to get a formula  for x2 and x1 as a function of y.  And you'll never be able to compute this one. ", "This is more than just a dead end, it's like crash, burn,  and, you know self-destruct.  So there may be such a thing, so do the other way.  Good luck, folks. ", ""], "vid_duration": [12.0, 14.0, 13.0, 13.0, 12.0, 15.0, 12.0, 14.0, 10.0, 11.0, 16.0, 11.0, 12.0, 11.0, 15.0, 14.0, 10.0, 11.0, 11.0, 10.0, 18.0, 13.0, 10.0, 11.0, 11.0, 12.0, 11.0, 14.0, 20.0, 10.0, 11.0, 13.0, 13.0, 10.0, 17.0, 20.0, 12.0, 11.0, 10.0, 10.0, 13.0, 28.0, 11.0, 13.0, 15.0, 11.0, 13.0, 10.0, 14.0, 11.0, 11.0, 11.0, 10.0, 11.0, 14.0, 11.0, 13.0, 12.0, 12.0, 12.0, 10.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 14.0, 14.0, 10.0, 10.0, 13.0, 11.0, 11.0, 13.0, 14.0, 11.0, 14.0, 10.0, 10.0, 10.0, 15.0, 13.0, 10.0, 12.0, 10.0, 11.0, 11.0, 14.0, 13.0, 19.0, 13.0, 18.0, 12.0, 12.0, 13.0, 10.0, 10.0, 24.0, 12.0, 12.0, 11.0, 10.0, 11.0, 12.0, 11.0, 13.0, 10.0, 13.0, 13.0, 10.0, 11.0, 11.0, 12.0, 11.0, 10.0, 16.0, 12.0, 11.0, 14.0, 10.0, 11.0, 11.0, 11.0, 10.0, 10.0, 11.0, 10.0, 11.0, 12.0, 11.0, 14.0, 10.0, 13.0, 14.0, 13.0, 12.0, 12.0, 19.0, 13.0, 22.0, 14.0, 10.0, 10.0, 12.0, 12.0, 11.0, 11.0, 13.0, 11.0, 10.0, 11.0, 11.0, 13.0, 10.0, 12.0, 11.0, 12.0, 14.0, 12.0, 10.0, 10.0, 12.0, 13.0, 13.0, 12.0, 12.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 12.0, 11.0, 14.0, 10.0, 10.0, 13.0, 14.0, 10.0, 12.0, 11.0, 13.0, 15.0, 18.0, 11.0, 11.0, 12.0, 10.0, 17.0, 13.0, 11.0, 10.0, 15.0, 15.0, 20.0, 10.0, 11.0, 10.0, 12.0, 13.0, 10.0, 10.0, 11.0, 12.0, 11.0, 14.0, 10.0, 10.0, 11.0, 12.0, 11.0, 10.0, 14.0, 12.0, 12.0, 10.0, 10.0, 11.0, 13.0, 12.0, 10.0, 13.0, 11.0, 10.0, 15.0, 12.0, 11.0, 13.0, 13.0, 10.0, 13.0, 10.0, 12.0, 15.0, 18.0, 10.0, 11.0, 12.0, 12.0, 1.03], "stet": [[0, 12.0], [12.0, 26.0], [26.0, 39.0], [39.0, 52.0], [52.0, 64.0], [64.0, 79.0], [79.0, 91.0], [91.0, 105.0], [105.0, 115.0], [115.0, 126.0], [126.0, 142.0], [142.0, 153.0], [153.0, 165.0], [165.0, 176.0], [176.0, 191.0], [191.0, 205.0], [205.0, 215.0], [215.0, 226.0], [226.0, 237.0], [237.0, 247.0], [247.0, 265.0], [265.0, 278.0], [278.0, 288.0], [288.0, 299.0], [299.0, 310.0], [310.0, 322.0], [322.0, 333.0], [333.0, 347.0], [347.0, 367.0], [367.0, 377.0], [377.0, 388.0], [388.0, 401.0], [401.0, 414.0], [414.0, 424.0], [424.0, 441.0], [441.0, 461.0], [461.0, 473.0], [473.0, 484.0], [484.0, 494.0], [494.0, 504.0], [504.0, 517.0], [517.0, 545.0], [545.0, 556.0], [556.0, 569.0], [569.0, 584.0], [584.0, 595.0], [595.0, 608.0], [608.0, 618.0], [618.0, 632.0], [632.0, 643.0], [643.0, 654.0], [654.0, 665.0], [665.0, 675.0], [675.0, 686.0], [686.0, 700.0], [700.0, 711.0], [711.0, 724.0], [724.0, 736.0], [736.0, 748.0], [748.0, 760.0], [760.0, 770.0], [770.0, 781.0], [781.0, 794.0], [794.0, 807.0], [807.0, 818.0], [818.0, 829.0], [829.0, 840.0], [840.0, 854.0], [854.0, 868.0], [868.0, 878.0], [878.0, 888.0], [888.0, 901.0], [901.0, 912.0], [912.0, 923.0], [923.0, 936.0], [936.0, 950.0], [950.0, 961.0], [961.0, 975.0], [975.0, 985.0], [985.0, 995.0], [995.0, 1005.0], [1005.0, 1020.0], [1020.0, 1033.0], [1033.0, 1043.0], [1043.0, 1055.0], [1055.0, 1065.0], [1065.0, 1076.0], [1076.0, 1087.0], [1087.0, 1101.0], [1101.0, 1114.0], [1114.0, 1133.0], [1133.0, 1146.0], [1146.0, 1164.0], [1164.0, 1176.0], [1176.0, 1188.0], [1188.0, 1201.0], [1201.0, 1211.0], [1211.0, 1221.0], [1221.0, 1245.0], [1245.0, 1257.0], [1257.0, 1269.0], [1269.0, 1280.0], [1280.0, 1290.0], [1290.0, 1301.0], [1301.0, 1313.0], [1313.0, 1324.0], [1324.0, 1337.0], [1337.0, 1347.0], [1347.0, 1360.0], [1360.0, 1373.0], [1373.0, 1383.0], [1383.0, 1394.0], [1394.0, 1405.0], [1405.0, 1417.0], [1417.0, 1428.0], [1428.0, 1438.0], [1438.0, 1454.0], [1454.0, 1466.0], [1466.0, 1477.0], [1477.0, 1491.0], [1491.0, 1501.0], [1501.0, 1512.0], [1512.0, 1523.0], [1523.0, 1534.0], [1534.0, 1544.0], [1544.0, 1554.0], [1554.0, 1565.0], [1565.0, 1575.0], [1575.0, 1586.0], [1586.0, 1598.0], [1598.0, 1609.0], [1609.0, 1623.0], [1623.0, 1633.0], [1633.0, 1646.0], [1646.0, 1660.0], [1660.0, 1673.0], [1673.0, 1685.0], [1685.0, 1697.0], [1697.0, 1716.0], [1716.0, 1729.0], [1729.0, 1751.0], [1751.0, 1765.0], [1765.0, 1775.0], [1775.0, 1785.0], [1785.0, 1797.0], [1797.0, 1809.0], [1809.0, 1820.0], [1820.0, 1831.0], [1831.0, 1844.0], [1844.0, 1855.0], [1855.0, 1865.0], [1865.0, 1876.0], [1876.0, 1887.0], [1887.0, 1900.0], [1900.0, 1910.0], [1910.0, 1922.0], [1922.0, 1933.0], [1933.0, 1945.0], [1945.0, 1959.0], [1959.0, 1971.0], [1971.0, 1981.0], [1981.0, 1991.0], [1991.0, 2003.0], [2003.0, 2016.0], [2016.0, 2029.0], [2029.0, 2041.0], [2041.0, 2053.0], [2053.0, 2064.0], [2064.0, 2074.0], [2074.0, 2084.0], [2084.0, 2094.0], [2094.0, 2104.0], [2104.0, 2114.0], [2114.0, 2126.0], [2126.0, 2137.0], [2137.0, 2151.0], [2151.0, 2161.0], [2161.0, 2171.0], [2171.0, 2184.0], [2184.0, 2198.0], [2198.0, 2208.0], [2208.0, 2220.0], [2220.0, 2231.0], [2231.0, 2244.0], [2244.0, 2259.0], [2259.0, 2277.0], [2277.0, 2288.0], [2288.0, 2299.0], [2299.0, 2311.0], [2311.0, 2321.0], [2321.0, 2338.0], [2338.0, 2351.0], [2351.0, 2362.0], [2362.0, 2372.0], [2372.0, 2387.0], [2387.0, 2402.0], [2402.0, 2422.0], [2422.0, 2432.0], [2432.0, 2443.0], [2443.0, 2453.0], [2453.0, 2465.0], [2465.0, 2478.0], [2478.0, 2488.0], [2488.0, 2498.0], [2498.0, 2509.0], [2509.0, 2521.0], [2521.0, 2532.0], [2532.0, 2546.0], [2546.0, 2556.0], [2556.0, 2566.0], [2566.0, 2577.0], [2577.0, 2589.0], [2589.0, 2600.0], [2600.0, 2610.0], [2610.0, 2624.0], [2624.0, 2636.0], [2636.0, 2648.0], [2648.0, 2658.0], [2658.0, 2668.0], [2668.0, 2679.0], [2679.0, 2692.0], [2692.0, 2704.0], [2704.0, 2714.0], [2714.0, 2727.0], [2727.0, 2738.0], [2738.0, 2748.0], [2748.0, 2763.0], [2763.0, 2775.0], [2775.0, 2786.0], [2786.0, 2799.0], [2799.0, 2812.0], [2812.0, 2822.0], [2822.0, 2835.0], [2835.0, 2845.0], [2845.0, 2857.0], [2857.0, 2872.0], [2872.0, 2890.0], [2890.0, 2900.0], [2900.0, 2911.0], [2911.0, 2923.0], [2923.0, 2935.0], [2935.0, 2936.03]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [335, 650, 796, 2151, 2247, 2402, 2488, 2936]}
{"example_id": "mit001@@ocw-18.01-f07-lec15_300k", "text": ["PROFESSOR: Today we're moving on from theoretical things from  the mean value theorem to the introduction to what's going to  occupy us for the whole rest of the course, which ", "is integration.  So, in order to introduce that subject, I need to introduce  for you a new notation, which is called differentials. ", "I'm going to tell you what a differential is, and we'll get  used to using it over time. ", "If you have a function which is y = f ( x), then the  differential of y is going to be denoted dy, and it's by ", "definition f' ( x ) dx.  So here's the notation. ", "And because y is really equal to f, sometimes we also call  it the differential of f.  It's also called the differential of f. ", "That's the notation, and it's the same thing as what happens  if you formally just take this dx, act like it's a number ", "and divide it into dy.  So it means the same thing as this statement here. ", "And this is more or less the Leibniz, not Leibniz,  interpretation of derivatives. ", "Of a derivative as a ratio of these so called differentials. ", "It's a ratio of what are known as infinitesimals. ", "Now, this is kind of a vague notion, this little bit here  being an infinitesimal.  It's sort of like an infinitely small quantity. ", "And Leibniz perfected the idea of dealing with  these intuitively.  And subsequently, mathematicians use  them all the time. ", "They're way more effective than the notation that Newton used.  You might think that notations are a small matter, but they ", "allow you to think much faster, sometimes.  When you have the right names and the right  symbols for everything.  And in this case it made it very big difference.  Leibniz's notation was adopted on the Continent and Newton ", "dominated in Britain and, as a result, the British fell behind  by one or two hundred years in the development of calculus.  It was really a serious matter. ", "So it's really well worth your while to get used  to this idea of ratios.  And it comes up all over the place, both in this class and  also in multivariable calculus. ", "It's used in many contexts.  So first of all, just to go a little bit easy.  We'll illustrate it by its use in linear approximations, ", "which we've already done. ", "The picture here, which we've drawn a number of times, is  that you have some function.  And here's a value of the function.  And it's coming up like that. ", "So here's our function.  And we go forward a little increment to a place which  is dx further along.  The idea of this notation is that dx is going to replace ", "the symbol delta x, which is the change in x.  And we won't think too hard about - well, this is a small  quantity, this is a small quantity, we're not going to  think too hard about what that means. ", "Now, similarly, if you see how much we've gone up - well,  this is kind of low, so it's a small bit here. ", "So this distance here is, previously we  called it delta y. ", "But now we're just going to call it dy.  So dy replaces delta y. ", "So this is the change in level of the function.  And we'll represent it symbolically this way.  Very frequently, this just saves a little bit of notation. ", "For the purposes of this, we'll be doing the same things we did  with delta x and delta y, but this is the way that  Leibniz thought of it.  And he would just have drawn it with this. ", "So this distance here is dx and this distance here is dy. ", "So for an example of linear approximation, we'll say what's  64.1, say, to the 1/3 power, approximately equal to? ", "Now, I'm going to carry this out in this new notation here.  The function involved is x ^ 1/3.  And then it's a differential, dy. ", "Now, I want to use this rule to get used to it.  Because this is what we're going to be doing all of today  is, we're differentiatating, or taking the differential of y. ", "So that is going to be just the derivative.  That's 1/3 x ^ - 2/3 dx. ", "And now I'm just going to fill in exactly what this is.  At x = 64, which is the natural place close by where it's easy ", "to do the evaluations, we have y = 64 ^ 1/3, which is just 4. ", "And how about dy?  Well, so this is a little bit more complicated.  Put it over here.  So dy = 1/3 ( 64) ^ - 2/3 dx. ", "And that is (1/3 ) 1/16 dx, which is 1/48 dx. ", "And now I'm going to work out what 64 to the, whatever it is  here, this strange fraction. ", "I just want to be very careful to explain to  you one more thing.  Which is that we're using x = 64, and so we're thinking of ", "x + dx is going to be 64.1.  So that means that dx is going to be 1/10. ", "So that's the increment that we're interested in.  And now I can carry out the approximation. ", "The approximation says that 64.1 ^ 1/3 is, well, it's  approximately what I'm going to call y + dy. ", "Because really, the dy that I'm determining here is determined  by this linear relation. dy = 1/48 dx. ", "And so this is only approximately true.  Because what's really true is that this = y + delta y. ", "In our previous notation.  So this is in disguise.  What this is equal to.  And that's the only approximately equal to what  the linear approximation would give you. ", "So, really, even though I wrote dy is this increment here, what  it really is if dx is exactly that, is it's the amount it  would go up if you went straight up the tangent line. ", "So I'm not going to do that because that's  not what people write.  And that's not even what they think.  They're really thinking of both dx and dy as being  infinitesimally small. ", "And here we're going to the finite level and doing it.  So this is just something you have to live with, is a little ", "ambiguity in this notation.  This is the approximation.  And now I can just calculate these numbers here. y ", "at this value is 4.  And dy, as I said, is 1/48 dx. ", "And that turns out to be 4 + 1/480, because dx is 1/10.  So that's approximately 4.002. ", "And that's our approximation. ", "Now, let's just compare it to our previous notation. ", "This will serve as a review of, if you like, of  linear approximation. ", "But what I want to emphasize is that these things are  supposed to be the same.  Just that it's really the same thing. ", "It's just a different notation for the same thing.  I remind you the basic formula for linear approximation is ", "that f ( x ) is approximately f ( a) + f' ( a )( x - a).  And we're applying it in the situation that a = ", "64 and f(x) = x ^ 1/3. ", "And so f ( a ), which is f ( 64 ) is of course 4. ", "And f' ( a ), which is a, (1/3)a ^ - 2/3, ", "is in our case 1/16.  No, 1/48. ", "OK, that's the same calculation as before.  And then our relationship becomes x ^ 1/3 is ", "approximately equal to 4 + 1/48 ( x - a ), which is 64. ", "So look, every single number that I've written over here  has a corresponding number for this other method.  And now if I plug in the value we happen to want, which is the ", "64.1, this would be 4 + 1/48 ( 1/10 ), which is just the  same thing we had before. ", "So again, same answer.  Same method, new notation. ", "Well, now I get to use this notation in a novel way.  So again, here's the notation.  This notation of differential. ", "The way I'm going to use it is in discussing something called  antiderivative Again, this is a new notation now. ", "But it's also a new idea.  It's one that we haven't discussed yet.  Namely, the notation that I want to describe here ", "is what's called the integral of g ( x ) dx.  And I'll denote that by a function capital G (x).  So it's, you start with a function g ( x ) and you ", "produce a function capital G ( x ), which is called  the antiderivative of G. ", "Notice there's a differential sitting in here.  This symbol, this guy here, is called an integral sign. ", "Or an integral, or this whole thing is called an integral.  And another name for the antiderivative of g is the  indefinite integral of g. ", "And I'll explain to you why it's indefinite in just,  very shortly here. ", "Well, so let's carry out some examples.  Basically what I'd like to do is as many examples along the ", "lines of all the derivatives that we derived at the  beginning of the course.  In other words, in principle you want to be able  to integrate as many things as possible.  We're going to start out with the integral of sine x dx. ", "That's a function whose derivative is sine x.  So what function would that be? ", "Cosine x, minus, right.  It's - cos x.  So - cos x differentiated gives you sine x. ", "So that is an antiderivative of sine.  And it satisfies this property.  So this function, capital G ( x ) = - cos x, has the property ", "that its derivative is sine x.  On the other hand, if you differentiate a ", "constant, you get 0.  So this answer is what's called indefinite.  Because you can also add any constant here.  And the same thing will be true. ", "So, c is constant.  And as I said, the integral is called indefinite.  So that's an explanation for this modifier in ", "front of the integral.  It's indefinite because we actually didn't specify  a single function.  We don't get a single answer.  Whenever you take the antiderivative of something  it's ambiguous up to a constant. ", "Next, let's do some other standard functions  from our repertoire.  We have an integral of (x ^ a)dx.  Some power, the integral of a power. ", "And if you think about it, what you should be differentiating  is one power larger than that.  But then you have to divide by 1 / a + 1, in order that the ", "differentiatiation be correct.  So this just is the fact that d / dx of x ^ a + 1, or maybe I ", "should even say it this way.  Maybe I'll do it in differential notation. d ( x ^  a + 1) = (a + 1) (x ^ a) dx. ", "So if I divide that through by a + 1, then I get  the relation above.  And because this is ambiguous up to a constant, it could be ", "any additional constant added to that function.  Now, the identity that I wrote down below is correct. ", "But this one is not always correct What's the exception?  Yeah. a equals ", "STUDENT: 0.  PROFESSOR: Negative 1.  So this one is OK for all a.  But this one fails because we've divided ", "by 0 when a = - 1.  So this is only true when a is not equal to - 1. ", "And in fact, of course, what's happening when a = 0,  you're getting 0 when you differentiate the constant.  So there's a third case that we have to carry out. ", "Which is the exceptional case, namely the integral of dx/x. ", "And this time, if we just think back to what are - so what  we're doing is thinking backwards here, which a  very important thing to do in math at all stages. ", "We got all of our formulas, now we're reading them backwards.  And so this one, you may remember, is ln x. ", "The reason why I want to do this carefully and slowly now,  is right now I also want to write the more standard  form which is presented.  So first of all, first we have to add a constant. ", "And please don't put the parentheses here.  The parentheses go there.  But there's another formula hiding in the woodwork ", "here behind this one.  Which is that you can also get the correct formula  when x is negative.  And that turns out to be this one here. ", "So I'm treating the case, x positive, as being  something that you know.  But let's check the case, x negative. ", "In order to check the case x negative, I have to  differentiate the logarithm of the absolute value  of x in that case. ", "And that's the same thing, again, for x negative as  the derivative of the lograrithm of negative x.  That's the formula, when x is negative. ", "And if you carry that out, what you get, maybe I'll put this  over here, is, well, it's the chain rule. ", "It's (1 / -x) d/dx(-x).   So see that there are two minus signs. ", "There's a - x in the denominator and then there's  the derivative of - x in the numerator.  That's just - 1.  This part is - 1.  So this negative 1 over negative x, which is 1 / x. ", "So the negative signs cancel. ", "If you just keep track of this in terms of ln negative x and  its graph, that's a function that looks like this. ", "For x negative.  And its derivative is 1 / x, I claim.  And if you just look at it a little bit carefully, you see ", "that the slope is always negative.  Right?  So here the slope is negative.  So it's going to be below the axis. ", "And, in fact, it's getting steeper and steeper  negative as we go down.  And it's getting less and less negative as we go horizontally.  So it's going like this, which is indeed the graph of this ", "function, for x negative.  Again, x negative. ", "So that's one other standard formula.  And very quickly, very often, we won't put the  absolute value signs.  We'll only consider the case x positive here. ", "But I just want you to have the tools to do it in case we want  to use, we want to handle, both positive and negative x. ", "Now, let's do two more examples. ", "The integral of sec^2 x dx.  These are supposed to get you to remember all of your ", "differentiatation formulas, the standard ones.  So this one, integral of sec^2 dx is what?  Tan x. ", "And here we have + c, alright?  And then the last one of, a couple of, this type  would be, let's see.  I should do at least this one here, square root of 1 - x ^2. ", "This is another notation, by the way, which is  perfectly acceptable.  Notice I've put the dx in the numerator and the function  in the denominator here.  So this one turns out to be sin-1 x. ", "And, finally, let's see.  About the integral of dx / 1 + x ^2. ", "That one is tan -1 x. ", "For a little while, because you're reading these things  backwards and forwards, you'll find this happens  to you on exams.  It gets slightly worse for a little while.  You will antidifferentiate when you meant to differentiate. ", "And you'll differentiate when you're meant to  antidifferentiate.  Don't get too frustrated by that.  But eventually, you'll get them squared away. ", "And it actually helps to do a lot of practice with  antidifferentiations, or integrations, as they're ", "sometimes called.  Because that will solidify your remembering all of the  differentiation formulas. ", "So, last bit of information that I want to emphasize before  we go on some more complicated examples is this It's obvious ", "because the derivative of a constant is 0.  That the antiderivative is ambiguous up to a constant. ", "But it's very important to realize that this is the only  ambiguity that there is.  So the last thing that I want to tell you about is  uniqueness of antiderivatives up to a constant. ", "The theorem is the following.  The theorem is if F' = F', then F = G. ", "So F ( x ) = G ( x) + c.   But that means, not only that these are antiderivatives, all ", "these things with these + c's are antiderivatives.  But these are the only ones.  Which is very reassuring.  And that's a kind of uniqueness, although its ", "uniqueness up to a constant, it's acceptable to us.  Now, the proof of this is very quick.  But this is a fundamental fact. ", "The proof is the following.  If F' = G', then if you take the difference between the two ", "functions, its derivative, which of course is F' - G' = 0. ", "Hence, F( x) - G (x) is a constant. ", "Now, this is a key fact.  Very important fact.  We deduced it last time from the mean value theorem.  It's not a small matter. ", "It's a very, very important thing.  It's the basis for calculus.  It's the reason why calculus make sense.  If we didn't have the fact that the derivative is 0 implied  that the function was constant, we would be done. ", "We would have, calculus would be just useless for us.  The point is, the rate of change is supposed to  determine the function up to this starting value. ", "So this conclusion is very important.  And we already checked it last time, this conclusion.  And now just by algebra, I can rearrange this to say ", "that f ( x) = G ( x) + c. ", "Now, maybe I should leave differentials up here.  Because I want to illustrate. ", "So let's go on to some trickier, slightly  trickier, integrals.  Here's an example. ", "The integral of, say, x^3 ( x ^ 4 + 2) ^ 5 dx. ", "This is a function which you actually do know how to  integrate, because we already have a formula for all powers.  Namely, the integral of x ^ a is equal to this. ", "And even if it were a negative power, we could do it.  So it's OK.  On the other hand, to expand the 5th power  here is quite a mess. ", "And this is just a very, very bad idea.  There's another trick for doing this that evaluates this  much more efficiently.  And it's the only device that we're going to learn ", "now for integrating.  Integration actually is much harder than differentiation.  Symbolically. ", "It's quite difficult.  And occasionally impossible.  And so we have to go about it gently.  But for the purposes of this unit, we're only going ", "to use one method.  Which is very good.  That means whenever you see an integral, either you'll be able  to divine immediately what the answer is, or you'll  use this method. ", "So this is it.  The trick is called the method of substitution. ", "And it is tailor-made for notion of differentials.  So tailor-made. for differential notation. ", "The idea is the following.  I'm going to to define a new function.  And it's the messiest function that I see here.  It's u = x ^ 4 + 2. ", "And then, I'm going to take its differential and what I  discover, if I look at its formula, is and the rule for  differentials, which is right here. ", "Its formula is what?  4x^3 dx.  Now, lo and behold with these two quantities, I can ", "substitute, I can plug in to this integral.  And I will simplify it considerably.  So how does that happen?  Well, this integral is the same thing as, well, really I should ", "combine it the other way.  So let me move this over.  So there are two pieces here.  And this one is u ^ 5. ", "And this one is 1/4 du.  Now, that makes it the integral of (u ^ 5 du) / 4. ", "And that's relatively easy to integrate.  That is just a power.  So let's see.  It's just 1/20 u to the - not 1/20. ", "The antiderivative of u ^ 5 is u ^ 6.  With the 1/6, so it's 1/24 u ^ 6 + c. ", "Now, that's not the answer to the question.  It's almost the answer to the question.  Why isn't it the answer?  It isn't the answer because now the answer's ", "expressed in terms of u.  Whereas the problem was posed in terms of this variable x.  So we must change back to our variable here. ", "And we do that just by writing it in.  So it's 1/24 (x ^ 4 + 2) ^ 6 + c. ", "And this is the end of the problem.  Yeah, question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: The question is, can you see it directly?  Yeah.  And we're going to talk about that in just one second.  OK. ", "Now, I'm going to do one more example and  illustrate this method. ", "Here's another example.  The integral of x dx / squre root of 1 + x ^2.  Now, here's another example. ", "Now, the method of substitution leads us to the idea u = 1  + x ^2. du = 2x dx, etc. ", "It takes about as long as this other problem did.  To figure out what's going on.  It's a very similar sort of thing.  You end up integrating u ^ - 1/2.  It needs to the integral of u ^ - 1/2 du. ", "Is everybody seeing where this..?  However, there is a slightly better method.  So recommended method. ", "And I call this method advanced guessing. ", "What advanced guessing means is that you've done enough  of these problems that you can see two steps ahead.  And you know what's going to happen.  So the advanced guessing leads you to believe that here you ", "had a power - 1/2, here you have the differential  of the thing.  So it's going to work out somehow.  And the advanced guessing allows you to guess that the  answer should be something like this. (1 + x ^2) ^ 1/2. ", "So this is your advanced guess.  And now you just differentiate it, and see whether it works.  Well, here it is.  It's 1/2 (1 + x ^2) ^ - 1/2( 2x), that's the ", "chain rule here.  Which, sure enough, gives you x / square root of 1 + x ^2.  So we're done.  And so the answer is square root of (1 + x^2) + c. ", "Let me illustrate this further with another example.  I strongly recommend that you do this, but you ", "have to get used to it.  So here's another example. e ^ 6x dx. ", "My advanced guess is e ^ 6x.  And if I check, when I differentiate ", "it, I get 6e ^ 6x.  That's the derivative.  And so I know that the answer, so now I know  what the answer is. ", "It's 1/6 e ^ 6x + c.  Now, OK, you could, it's also OK, but slow, to use a ", "substitution, to use u = 6x.  Then you're going to get du = 6dx ... ", "It's going to work, it's just a waste of time. ", "Well, I'm going to give you a couple more examples.  So how about this one. x ( e^ - x^2) dx. ", "What's the guess?  Anybody have a guess? ", "Well, you could also correct.  So I don't want you to bother - yeah, go ahead.  STUDENT: [INAUDIBLE]  PROFESSOR: Yeah, so you're already one step ahead of me.  Because this is too easy. ", "When they get more complicated, you just want to make  this guess here.  So various people have said 1/2, and they understand that  there's 1/2 going here.  But let me just show you what happens, OK? ", "If you make this guess and you differentiate it, what you get  here is e^ - x ^2 times the derivative of negative 2x, so ", "that's - 2x. - x^2, so it's - 2x.  So now you see that you're off by a factor of not 2, but - 2. ", "So a number of you were saying that.  So the answer is - 1/2 e^ - x ^2 + c.  And I can guarantee you, having watched this on various ", "problems, that people who don't write this out make  arithmetic mistakes.  In other words, there is a limit to how much people ", "can think ahead and guess correctly.  Another way of doing it, by the way, is simply to write this  thing in and then fix the coefficient by doing the  differentiation here. ", "That's perfectly OK as well.  Alright, one more example.  We're going to integrate sin x cos x dx. ", "So what's a good guess for this one?  STUDENT: [INAUDIBLE]  PROFESSOR: Someone suggesting sine ^2 x.  So let's try that. ", "Over 2 - well, we'll get the coefficient in just a second.  So sine ^2 x, if I differentiate I get  2 sine x cosine x.  So that's off by a factor of 2. ", "So the answer is 1/2 sine ^2 x. ", "But now I want to point out to you that there's another ", "way of doing this problem.  It's also true that if you differentiate cosine ^2 x, ", "you get 2 cos x ( - sine x).  So another answer is that the integral of sin x cos ", "x dx = - 1/2 cos^2 x + c. ", "So what is going on here?  What's the problem with this?  STUDENT: [INAUDIBLE] ", "PROFESSOR: Pardon me?  STUDENT: [INAUDIBLE]  PROFESSOR: Integrals aren't unique.  That's part of the - but somehow these two answers ", "still have to be the same.  STUDENT: [INAUDIBLE] ", "PROFESSOR: OK.  What do you think?  STUDENT: If you add them together, you just get c.  PROFESSOR: If you add them together you get c.  Well, actually, that's almost right. ", "That's not what you want to do, though.  You don't want to add them.  You want to subtract them.  So let's see what happens when you subtract them.  I'm going to ignore the c, for the time being. ", "I get sin^2 x, 1/2 sin^2 x - (-1/2 cos^2 x).  So the difference between them, we hope to be 0. ", "But actually of course it's not 0.  What it is, is it's 1/2 (sin^2 + cos^2) which is 1/2. ", "It's not 0, it's a constant.  So what's really going on here is that these two  formulas are the same. ", "But you have to understand how to interpret them.  The two constants, here's a constant up here.  There's a constant, c1 associated to this one.  There's a different constant, c2 associated to this one. ", "And this family of functions for all possible c1s and all  possible c2s, is the same family of functions.  Now, what's the relationship between c1 and c2?  Well, if you do the subtraction, c1 - c2 has ", "to be equal to 1/2.  They're both constants, but they differ by 1/2.  So this explains, when you're dealing with families of ", "things, they don't have to look the same.  And there are lots of trig functions which look  a little different.  So there can be several formulas that actually  are the same. ", "And it's hard to check that they're actually the same.  You need some trig identities to do it.  Let's do one more example here. ", "Here's another one. ", "Now, you may be thinking, and a lot of people are, thinking  ugh, it's got a ln in it. ", "If you're experienced, you actually can read off the  answer just the way there were several people who were  shouting out the answers when we were doing the rest  of these problems.  But, you do need to relax. ", "Because in this case, now this is definitely not true in  general when we do integrals.  But, for now, when we do integrals, they'll  all be manageable.  And there's only one method. ", "Which is substitution.  And in the substitution method, you want to go  for the trickiest part. ", "And substitute for that.  So the substitution that I proposed to you is that this  should be, you should be ln x. ", "And the advantage that that has is that its differential  is simpler then itself.  So du = dx /x. ", "Remember, we use that in logarithmic  differentiation, too.  So now we can express this using this substitution. ", "And what we get is, the integral of, so I'll divide  the two parts here.  It's 1 / ln x, and then it's dx / x.  And this part is 1 / u, and this part is du. ", "So it's the integral of du / u.  And that is ln u + c. ", "Which altogether, if I put back in what u is, is ln (ln x) + c. ", "And now we see some uglier things.  In fact, technically speaking, we could take  the absolute value here.  And then this would be absolute values there. ", "So this is the type of example where I really would recommend  that you actually use the substitution, at least for now. ", "Alright, tomorrow we're going to be doing  differential equations.  And we're going to review for the test.  I'm going to give you a handout telling you just exactly what's  going to be on the test.  So, see you tomorrow. "], "vid_duration": [11.0, 19.0, 10.0, 26.0, 13.0, 17.0, 14.0, 10.0, 16.0, 12.0, 14.0, 12.0, 10.0, 12.0, 14.0, 11.0, 11.0, 11.0, 11.0, 11.0, 16.0, 13.0, 10.0, 10.0, 15.0, 13.0, 10.0, 10.0, 15.0, 11.0, 10.0, 11.0, 14.0, 11.0, 19.0, 21.0, 10.0, 13.0, 14.0, 10.0, 11.0, 12.0, 11.0, 10.0, 13.0, 10.0, 11.0, 12.0, 10.0, 11.0, 10.0, 16.0, 15.0, 10.0, 11.0, 11.0, 10.0, 10.0, 11.0, 11.0, 10.0, 13.0, 14.0, 12.0, 17.0, 21.0, 16.0, 10.0, 12.0, 18.0, 19.0, 19.0, 14.0, 13.0, 17.0, 10.0, 12.0, 14.0, 10.0, 13.0, 12.0, 23.0, 12.0, 13.0, 12.0, 12.0, 15.0, 14.0, 12.0, 11.0, 15.0, 11.0, 10.0, 13.0, 11.0, 12.0, 13.0, 13.0, 16.0, 12.0, 13.0, 12.0, 10.0, 13.0, 10.0, 12.0, 13.0, 12.0, 11.0, 12.0, 10.0, 11.0, 14.0, 10.0, 10.0, 16.0, 14.0, 10.0, 13.0, 12.0, 12.0, 10.0, 10.0, 20.0, 10.0, 29.0, 17.0, 13.0, 11.0, 13.0, 11.0, 11.0, 15.0, 10.0, 13.0, 11.0, 10.0, 24.0, 17.0, 15.0, 16.0, 12.0, 11.0, 13.0, 10.0, 10.0, 10.0, 12.0, 27.0, 14.0, 12.0, 12.0, 21.0, 11.0, 15.0, 10.0, 14.0, 10.0, 10.0, 11.0, 20.0, 14.0, 14.0, 12.0, 15.0, 17.0, 18.0, 13.0, 12.0, 15.0, 12.0, 18.0, 10.0, 12.0, 11.0, 10.0, 18.0, 10.0, 16.0, 18.0, 10.0, 11.0, 11.0, 12.0, 12.0, 13.0, 10.0, 10.0, 20.0, 11.0, 12.0, 11.0, 10.0, 17.0, 18.0, 12.0, 10.0, 10.0, 11.0, 12.0, 12.0, 12.0, 10.0, 11.0, 14.0, 14.0, 12.0, 10.0, 36.0, 11.0, 16.0, 10.0, 10.0, 10.0, 10.0, 13.0, 13.0, 15.0, 15.0, 13.0, 17.0, 11.0, 13.01], "stet": [[0, 11.0], [11.0, 30.0], [30.0, 40.0], [40.0, 66.0], [66.0, 79.0], [79.0, 96.0], [96.0, 110.0], [110.0, 120.0], [120.0, 136.0], [136.0, 148.0], [148.0, 162.0], [162.0, 174.0], [174.0, 184.0], [184.0, 196.0], [196.0, 210.0], [210.0, 221.0], [221.0, 232.0], [232.0, 243.0], [243.0, 254.0], [254.0, 265.0], [265.0, 281.0], [281.0, 294.0], [294.0, 304.0], [304.0, 314.0], [314.0, 329.0], [329.0, 342.0], [342.0, 352.0], [352.0, 362.0], [362.0, 377.0], [377.0, 388.0], [388.0, 398.0], [398.0, 409.0], [409.0, 423.0], [423.0, 434.0], [434.0, 453.0], [453.0, 474.0], [474.0, 484.0], [484.0, 497.0], [497.0, 511.0], [511.0, 521.0], [521.0, 532.0], [532.0, 544.0], [544.0, 555.0], [555.0, 565.0], [565.0, 578.0], [578.0, 588.0], [588.0, 599.0], [599.0, 611.0], [611.0, 621.0], [621.0, 632.0], [632.0, 642.0], [642.0, 658.0], [658.0, 673.0], [673.0, 683.0], [683.0, 694.0], [694.0, 705.0], [705.0, 715.0], [715.0, 725.0], [725.0, 736.0], [736.0, 747.0], [747.0, 757.0], [757.0, 770.0], [770.0, 784.0], [784.0, 796.0], [796.0, 813.0], [813.0, 834.0], [834.0, 850.0], [850.0, 860.0], [860.0, 872.0], [872.0, 890.0], [890.0, 909.0], [909.0, 928.0], [928.0, 942.0], [942.0, 955.0], [955.0, 972.0], [972.0, 982.0], [982.0, 994.0], [994.0, 1008.0], [1008.0, 1018.0], [1018.0, 1031.0], [1031.0, 1043.0], [1043.0, 1066.0], [1066.0, 1078.0], [1078.0, 1091.0], [1091.0, 1103.0], [1103.0, 1115.0], [1115.0, 1130.0], [1130.0, 1144.0], [1144.0, 1156.0], [1156.0, 1167.0], [1167.0, 1182.0], [1182.0, 1193.0], [1193.0, 1203.0], [1203.0, 1216.0], [1216.0, 1227.0], [1227.0, 1239.0], [1239.0, 1252.0], [1252.0, 1265.0], [1265.0, 1281.0], [1281.0, 1293.0], [1293.0, 1306.0], [1306.0, 1318.0], [1318.0, 1328.0], [1328.0, 1341.0], [1341.0, 1351.0], [1351.0, 1363.0], [1363.0, 1376.0], [1376.0, 1388.0], [1388.0, 1399.0], [1399.0, 1411.0], [1411.0, 1421.0], [1421.0, 1432.0], [1432.0, 1446.0], [1446.0, 1456.0], [1456.0, 1466.0], [1466.0, 1482.0], [1482.0, 1496.0], [1496.0, 1506.0], [1506.0, 1519.0], [1519.0, 1531.0], [1531.0, 1543.0], [1543.0, 1553.0], [1553.0, 1563.0], [1563.0, 1583.0], [1583.0, 1593.0], [1593.0, 1622.0], [1622.0, 1639.0], [1639.0, 1652.0], [1652.0, 1663.0], [1663.0, 1676.0], [1676.0, 1687.0], [1687.0, 1698.0], [1698.0, 1713.0], [1713.0, 1723.0], [1723.0, 1736.0], [1736.0, 1747.0], [1747.0, 1757.0], [1757.0, 1781.0], [1781.0, 1798.0], [1798.0, 1813.0], [1813.0, 1829.0], [1829.0, 1841.0], [1841.0, 1852.0], [1852.0, 1865.0], [1865.0, 1875.0], [1875.0, 1885.0], [1885.0, 1895.0], [1895.0, 1907.0], [1907.0, 1934.0], [1934.0, 1948.0], [1948.0, 1960.0], [1960.0, 1972.0], [1972.0, 1993.0], [1993.0, 2004.0], [2004.0, 2019.0], [2019.0, 2029.0], [2029.0, 2043.0], [2043.0, 2053.0], [2053.0, 2063.0], [2063.0, 2074.0], [2074.0, 2094.0], [2094.0, 2108.0], [2108.0, 2122.0], [2122.0, 2134.0], [2134.0, 2149.0], [2149.0, 2166.0], [2166.0, 2184.0], [2184.0, 2197.0], [2197.0, 2209.0], [2209.0, 2224.0], [2224.0, 2236.0], [2236.0, 2254.0], [2254.0, 2264.0], [2264.0, 2276.0], [2276.0, 2287.0], [2287.0, 2297.0], [2297.0, 2315.0], [2315.0, 2325.0], [2325.0, 2341.0], [2341.0, 2359.0], [2359.0, 2369.0], [2369.0, 2380.0], [2380.0, 2391.0], [2391.0, 2403.0], [2403.0, 2415.0], [2415.0, 2428.0], [2428.0, 2438.0], [2438.0, 2448.0], [2448.0, 2468.0], [2468.0, 2479.0], [2479.0, 2491.0], [2491.0, 2502.0], [2502.0, 2512.0], [2512.0, 2529.0], [2529.0, 2547.0], [2547.0, 2559.0], [2559.0, 2569.0], [2569.0, 2579.0], [2579.0, 2590.0], [2590.0, 2602.0], [2602.0, 2614.0], [2614.0, 2626.0], [2626.0, 2636.0], [2636.0, 2647.0], [2647.0, 2661.0], [2661.0, 2675.0], [2675.0, 2687.0], [2687.0, 2697.0], [2697.0, 2733.0], [2733.0, 2744.0], [2744.0, 2760.0], [2760.0, 2770.0], [2770.0, 2780.0], [2780.0, 2790.0], [2790.0, 2800.0], [2800.0, 2813.0], [2813.0, 2826.0], [2826.0, 2841.0], [2841.0, 2856.0], [2856.0, 2869.0], [2869.0, 2886.0], [2886.0, 2897.0], [2897.0, 2910.01]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [236, 813, 1066, 1432, 1561, 1790, 2108, 2336, 2910]}
{"example_id": "mit001@@ocw-18.01-f07-lec19_300k", "text": ["PROFESSOR: Today we're going to continue with integration.  And we get to do the probably the most important thing  of this entire course.  Which is appropriately named. ", "It's called the fundamental theorem of calculus. ", "And we'll be abbreviating it FTC and occasionally I'll put  in a 1 here, because there will be two versions of it.  But this is the one that you'll be using the ", "most in this class.  The fundamental theorem of calculus says the following. ", "It says that if F' = f, so F' ( x) = little f ( x), there's a ", "capital F and a little f, then the integral from a to b of ", "f ( x) = F ( b) - F (a). ", "That's it.  That's the whole theorem.  And you may recognize it.  Before, we had the notation that f was the antiderivative, ", "that is, capital F was the integral of f(x).  We wrote it this way.  This is this indefinite integral.  And now we're putting in definite values.  And we have a connection between the two uses ", "of the integral sign.  But with the definite values, we get real numbers out  instead of a function.  Or a function up to a constant.  So this is it. ", "This is the formula.  And it's usually also written with another notation.  So I want to introduce that notation to you as well. ", "So there's a new notation here.  Which you'll find very convenient.  Because we don't always have to give a letter f to ", "the functions involved.  So it's an abbreviation.  For right now there'll be a lot of f's, but anyway.  So here's the abbreviation.  Whenever I have a difference between a function at two ", "values, I also can write this as F ( x) with an a down  here and a b up there.  So that's the notation that we use. ", "And you can also, for emphasis, and this sometimes turns out to  be important, when there's more than one variable floating  around in the problem.  To specify that the variable is x. ", "So this is the same thing as x = a.  And x = b.  It indicates where you want to plug in, what  you want to plug in.  And now you take the top value minus the bottom value. ", "So F ( b) - F(a).  So this is just a notation, and in that notation, of course,  the theorem can be written with this set of symbols here. ", "Equally well.  So let's just give a couple of examples.  The first example is the one that we did last  time very laboriously. ", "If you take the function capital F(x), which happens  to be x^3 / 3, then if you differentiate it, you get, ", "well, the the factor of 3 cancels.  So you get x^2, that's the derivative.  And so by the fundamental theorem, so this implies by the ", "fundamental theorem, that the integral from say, a to b of  x^3 over - sorry, x^2 dx, that's the derivative here. ", "This is the function we're going to use as f ( x) here  = this function here. ", "F ( b) - F ( a), that's here.  This function here.  So that's write F(b) - F( a), and that's equal ", "to b^3 / 3 - a^3 / 3.  Now, in this new notation, we usually don't have ", "all of these letters.  All we write is the following.  We write the integral from a to be, and I'm going to do the  case 0 to b, because that was the one that we actually  did last time.  So I'm going to set a = 0 here. ", "And then, the problem we were faced last time as this.  And as I said we did it very laboriously.  But now you can see that we can do it in ten ", "seconds, let's say.  Well, the antiderivative of this is x^3 / 3.  I'm going to evaluate it at 0 and at b and subtract.  So that's going to be b^3 / 3 - 0^3 / 3. ", "Which of course is b^3 / 3.  And that's the end, that's the answer.  So this is a lot faster than yesterday.  I hope you'll agree. ", "And we can dispense with those elaborate computations.  Although there's a conceptual reason, a very important one,  for understanding the procedure that we went through. ", "Because eventually you're going to be using integrals and these  quick ways of doing things, to solve problems like finding  the volumes of pyramids. ", "In other words, we're going to reverse the process.  And so we need to understand the connection between the two. ", "I'm going to give a couple more examples.  And then we'll go on.  So the second example would be one that would be quite  difficult to do by this Riemann sum technique that we ", "described yesterday.  Although it is possible.  It uses much higher mathematics to do it.  And that is the area under one hump of the sine curve, sine x. ", "Let me just draw a picture of that.  The curve goes like this, and we're talking  about this area here.  It starts out at 0, it goes to pi.  That's one hump. ", "And so the answer is, it's the integral from  0 to pi of sin x dx. ", "And so I need to take the antiderivative of that.  And that's - cos x.  That's the thing whose derivative is sin x.  Evaluating it at 0 and pi. ", "Now, let's do this one carefully.  Because this is where I see a lot of arithmetic mistakes.  Even though this is the easy part of the problem.  It's hard to pay attention and plug in the right numbers. ", "And so, let's just pay very close attention.  I'm plugging in pi.  That's - cos pi.  That's the first term.  And then I'm subtracting the value at the bottom, ", "which is - cos 0.  There are already five opportunities for you to make  a transcription error or an arithmetic mistake ", "in what I just did.  And I've seen all five of them.  So the next one is that this is - (- 1).  Minus negative 1, if you like. ", "And then this is minus, and here's another - 1.  So altogether we have 2.  So that's it.  That's the area. ", "This area, which is hard to guess, this is area 2. ", "The third example is maybe superfluous but I'm  going to say it anyway.  We can take the integral, say, from 0 to 1, of x ^ 100. ", " Any power, now, is within our power.  So let's do it.  So here we have the antiderivative is ", "x ^ 101 / 101.  Evaluate it at 0 and 1.  And that is just 1 / 101. ", "That's that.  So that's the fundamental theorem.  Now this, as I say, harnesses a lot of what we've already ", "learned, all about antiderivatives.  Now, I want to give you an intuitive interpretation. ", "So let's try that.  We'll talk about a proof of the fundamental theorem  a little bit later.  It's not actually that hard. ", "But we'll give an intuitive reason, interpretation,  if you like. ", "Of the fundamental theorem.  So this is going to be one which is not related to ", "area, but rather to time and distance.  So we'll consider x (t) is your position at time t. ", "And then x' (t), which is dx/dt, is going to be what  we know as your speed. ", "And then what the theorem is telling us, is the following.  It's telling us the integral from a to b of v ( t) dt. ", "So, reading the relationship is equal to x (b) - x ( a). ", "And so this is some kind of cumulative sum  of your velocities. ", "So let's interpret the right-hand side first.  This is the distance traveled. ", "And it's also what you would read on your odometer.  Right, from the beginning to the end of the trip.  That's what you would read on your odometer. ", "Whereas this is what you would read on your speedometer. ", "So this is the interpretation.  Now, I want to just go one step further into this  interpretation, to make the connection with the Riemann ", "sums that we had yesterday.  Because those are very complicated to understand.  And I want you to understand them viscerally on  several different levels. ", "Because that's how you'll understand integration better.  The first thing that I want to imagine, so we're going to do a  thought experiment now, which is that you are  extremely obsessive. ", "And you're driving your car from time a to time b, place  q to place r, whatever.  And you check your speedometer every second. ", "OK, so you've read your speedometer in the i'th second,  and you've read that you're going at this speed.  Now, how far do you go in that second? ", "Well, the answer is you go this speed times the time interval,  which in this case we're imagining as 1 second.  Alright?  So this is how far you went. ", "But this is the time interval.  And this is the distance traveled. in that a second ", "number, i, in the i'th second.  The distance traveled in the i'th second, that's a total  distance you traveled.  Now, what happens if you go the whole distance? ", "Well, you travel the sum of all these distances.  So it's some massive sum, where n is some ridiculous  number of seconds.  3600 seconds or something like that. ", "Whatever it is.  And that's going to turn out to be very similar to what you  would read on your odometer.  Because during that second, you didn't change  velocity very much. ", "So the approximation that the speed at one time that you  spotted it is very similar to the speed during  the whole second.  It doesn't change that much. ", "So this is a pretty good approximation to how  far you traveled.  And so the sum is a very realistic approximation  to the entire integral. ", "Which is denoted this way.  Which, by the fundamental theorem, is exactly  how far you traveled.  So this is x ( b) - x (a). ", "Exactly.  The other one is approximate.  OK, again this is called a Riemann sum. ", "Alright so that's the intro to the fundamental theorem.  And now what I need to do is extend it just a bit. ", "And the way I'm going to extend it is the following.  I'm going to do it on this example first.  And then we'll do it more formally. ", "So here's this example where we went someplace.  But now I just want to draw you an additional picture here.  Imagine I start here and I go over to there ", "and then I come back.  And maybe even I do a round trip.  I come back to the same place.  Well, if I come back to the same place, then the position ", "is unchanged from the beginning to the end.  In other words, the difference is 0.  And the velocity, technically rather than the speed. ", "It's the speed to the right and the the speed to the left maybe  are the same, but one of them is going in the positive  direction and one of them is going in the negative  direction, and they cancel each other.  So if you have this kind of situation, we want ", "that to be reflected.  We like that interpretation and we want to preserve it even  when in the case when the function v is negative. ", "And so I'm going to now extend our notion of integration. ", "So we'll extend integration to the case f negative. ", "Or positive.  In other words, it could be any sign.  Actually, there's no change.  The formulas are all the same. ", "We just, if this v is going to be positive, we write  in a positive number.  If it's going to be negative, we write in a negative number.  And we just leave it alone.  And the real, so here's, let me carry out an example ", "and show you how it works.  I'll carry out the example on this blackboard up here.  Of the sine function.  But we're going to try two humps. ", "We're going to try the first hump and the one that  goes underneath.  There.  So our example here is going to be the integral from  0 to 2pi of sin x dx. ", "And now, because the fundamental theorem is so  important, and so useful, and so convenient, we just assume  that it be true in this case as well. ", "So we insist that this is going to be - cos x.  Evaluate it at 0 and 2pi.  With the difference.  Now, when we carry out that difference, what we get here ", "is - cos 2pi. - (- cos 0). ", "Which is - 1 - (- 1), which is 0.  And the interpretation of this is the following. ", "Here's our double hump, here's pi and here's 2pi.  And all that's happening is that the geometric  interpretation that we had before of the area under ", "the curve has to be taken with a grain of salt.  In other words, I lied to you before when I said that the  definite integral was the area under the curve.  It's not. ", "The definite integral is the area under the curve when it's  above the curve, and it counts negatively when it's  below the curve.  So yesterday, my geometric interpretation was incomplete. ", "And really just a plain lie.  So the true geometric interpretation of the definite ", "integral is plus the area above the axis, above the x ", "axis, minus the area below the x axis. ", "As in the picture.  I'm just writing it down in words, but you should think  of it visually also.  So that's the setup here. ", "And now we have the complete definition of integrals.  And I need to list for you a bunch of their properties and  how we deal with integrals.  So are there any questions before we go on? ", "Yeah.  STUDENT: [INAUDIBLE]  PROFESSOR: Right. ", "So the question was, wouldn't the absolute value of the  velocity function be involved?  The answer is yes.  That is, that's one question that you could ask. ", "One question you could ask is what's the total  distance traveled.  And in that case, you would keep track of the absolute ", "value of the velocity as you said.  Whether it's positive or negative.  And then you would get the total length of  this curve here. ", "That's, however, not what the definite integral measures.  It measures the net distance traveled.  So it's another thing. ", "In other words, we can do that.  We now have the tools to do both.  We could also, so if you like, the total distance is equal ", "to the integral of this.  From a to b.  But the net distance is the one without the ", "absolute value signs.  So that's correct.  Other questions? ", "Alright.  So now, let's talk about properties of integrals. ", "So the properties of integrals that I want to mention ", "to you are these.  The first one doesn't bear too much comment. ", "If you take the cumulative integral of a sum, you're just  trying to get the sum of the separate integrals here. ", "And I won't say much about that.  That's because sums come out, the because the  integral is a sum.  Incidentally, you know this strange symbol here, ", "there's actually a reason for it historically.  If you go back to old books, you'll see that it actually  looks a little bit more like an s.  This capital Sigma is a sum.  S for sum, because everybody in those days knew ", "Latin and Greek.  And this one is also an s, but gradually it was such  an important s that they made a bigger.  And then they stretched it out and made it a little thinner,  because it didn't fit into one typesetting space. ", "And so just for typesetting reasons it got stretched.  And got a little bit skinny.  Anyway, so it's really an s.  And in fact, in French they call it sum. ", "Even though we call it integral.  So it's a sum.  So it's consistent with sums in this way. ", "And similarly, similarly we can factor constants out of sums.  So if you have an integral like this, the constant factors out. ", "But definitely don't try to get a function out of this.  That won't happen.  OK, in other words, c has to be a constant. ", "Doesn't depend on x. ", "The third property.  What do I want to call the third property here?  I have sort of a preliminary property, yes, here. ", "Which is the following.  And I'll draw a picture of it.  I suppose you have three points along a line.  So then I'm going to draw a picture that. ", "And I'm going to use the interpretation above the  curve, even though that's not the whole thing.  So here's a, here's b and here's c.  And you can see that the area of this piece, of the first ", "two pieces here, when added together, gives you the  area of the whole.  And that's the rule that I'd like to tell you.  So if you integrate from a to b, and you add to that the ", "integral from b to c, you'll get the integral from a to c. ", "This is going to be just a little preliminary, because  the rule is a little better than this.  But I will explain that in a minute. ", "The fourth rule is a very simple one.  Which is that the integral from a to a of f ( x ) dx = 0. ", "Now, that you can see very obviously because  there's no area.  No horizontal movement there.  The rectangle is infinitely thin, and there's  nothing there. ", "So this is the case.  You can also interpret it a F ( a) - F ( a).  So that's also consistent with our interpretation. ", "In terms of the fundamental theorem of calculus.  And it's perfectly reasonable that this is the case.  Now, the fifth property is a definition. ", "It's not really a property.  But it's very important.  The integral from a to b of f( x) dx = minus the integral ", "from b to a, of f( x) dx.  Now, really, the right-hand side here is an undefined ", "quantity so far.  We never said you could ever do this where the a < b.  Because this is working backwards here. ", "But we just have a convention that that's the definition.  Whenever we write down this number, it's the same as  minus what that number is.  And the reason for all of these is again that we want them to ", "be consistent with the fundamental theorem  of calculus.  Which is the thing that makes all of this work.  So if you notice the left-hand side here is F ( b) ", "- F ( a), capital F.  The antiderivative of little f.  On the other hand, the other side is minus, and if we just  ignore that, we say these are letters, if we were a machine, ", "we didn't know which one was bigger than which, we just  plugged them in, we would get here F( a) - F( b), over here.  And to make these two things equal, what we want is to ", "put that minus sign in.  Now it's consistent.  So again, these rules are set up so that everything ", "is consistent.  And now I want to improve on rule 3 here.  And point out to you.  So let me just go back to rule 3 for a second. ", "That now that we can evaluate integrals regardless of the  order, we don't have to have a < b, b < c in order to ", "make sense out of this.  We actually have the possibility of considering  integrals where the a's and the b's and the c's are  in any order you want. ", "And in fact, with this definition, with this  definition 5, 3 works no matter what the numbers are.  So this is much more convenient.  We don't, this is not necessary. ", "Not necessary.  It just works using convention 5.  OK, with 5. ", "Again, before I go on, let me emphasize we really  want to respect the sign of this velocity.  We really want the net change in the position. ", "And we don't want this absolute value here.  Because otherwise, all of our formulas are going to mess up.  We won't always be able to check.  Sometimes you have letters rather than actual numbers ", "here, and you won't know whether a is bigger than b.  So you'll want to know that these formulas work and are  consistent in all situations. ", "OK, I'm going to trade these again.  In order to preserve the ordering 1 through 5. ", "And now I have a sixth property that I want to talk about.  This one is called estimation. ", "And it says the following. if f(x) <= g ( )x, then the ", "integral from a to b of f(x) dx <= the integral from  a to b of g (x) dx. ", "Now, this one says that if I'm going more slowly than you,  then you go farther than I do. ", "OK.  That's all it's saying.  For this one, you'd better have a < b.  You need it.  Because we flip the signs when we flip the order of a and b. ", "So this one, it's essential that the lower limit be  smaller than the upper limit.  But let me just emphasize, because we're dealing with ", "the generalities of this.  Actually if one of these is negative and the other one is  negative, then it also works.  This one ends up being, if f is more negative than g, then ", "this added up thing is more negative than that one.  Again, under the assumption that a < b.  So as I wrote it's in full generality. ", "Let's illustrate this one.  And then we have one more property to learn after that. ", "So let me give you an example of estimation. ", "The example is the same as one that I already gave you.  But this time, because we have the tool of integration, we  can just follow our noses and it works. ", "I start with the inequality, so I'm trying to illustrate  estimation, so I want to start with an inequality which is  what the hypothesis is here.  And I'm going to integrate the inequality to ", "get this conclusion.  And see what conclusion it is.  The inequality that I want to take is that e  ^ x >= 1, for x >= 0. ", "That's going to be our starting place.  And now I'm going to integrate it.  That is, I'm going to use estimation to  see what that gives. ", "Well, I'm going to integrate, say, from 0 to b.  I can't integrate below 0 because it's only true above 0.  This is e ^ x dx >= the integral from 0 to b of 1 dx. ", "Alright, let's work out what each of these is.  The first one, e ^ x dx, is, the antiderivative is e ^ ", "x, evaluated at 0 and b.  So that's e ^ b - e ^ 0.  Which is e ^ b - 1. ", "The other one, you're supposed to be able to get by  the rectangle law.  This is one rectangle of base b and height 1. ", "So the answer is b.  Or you can do it by antiderivatives, but it's b.  That means that our inequality says if I just combine these ", "two things together, that e ^ b - 1 >= b.  And that's the same thing as e ^ b >= 1 + b. ", "Again, this only works for b >= 0.  Notice that if b were negative, this would be a well  defined quantity. ", "But this estimation would be false.  We need that the b > 0 in order for this to make sense.  So this was used. ", "And that's a good thing, because this  inequality is suspect.  Actually, it turns out to be true when b is negative.  But we certainly didn't prove it. ", "I'm going to just repeat this process.  So let's repeat it.  Starting from the inequality, the conclusion, which ", "is sitting right here.  But I'll write it in a form e ^ x >= 1 + x, for x >= 0.  And now, if I integrate this one, I get the integral from 0 ", "to b, e ^ x dx >= the integral from 0 to b, (1 + x) dx and I ", "remind you that we've already calculated this one.  This is e ^ b - 1.  And the other one is not hard to calculate.  The antiderivative is x + x^2 / 2. ", "We're evaluating that at 0 and b.  So that comes out to be b + b^2 / 2.  And so our conclusion is that the left side, which is e ", "^ b - 1 >= b + b^2 / 2.  And this is for b >= 0.  And that's the same thing as e ^ b >= 1 + b + b^2 / 2. ", "This one actually is false for b negative, so that's something  that you have to be careful with the b positives here. ", "So you can keep on going with this, and you  didn't have to think.  And you'll produce a very interesting polynomial,  which is a good approximation to e^ b. ", "So so that's it for the basic properties.  Now there's one tricky property that I need to tell you about.  It's not that tricky, but it's a little tricky. ", "And this is change of variables. ", "Change of variables in integration, we've  actually already done.  We called that, the last time we talked about it,  we called it substitution. ", "And the idea here, if you may remember, was that if you're  faced with an integral like this, you can change it to, if ", "you put in u = u (x) and you have a du, which is equal  to u' ( x) du, dx, sorry.  Then you can change the integral as follows. ", "This is the same as g (u( x)) u' (x) dx.  This was the general procedure for substitution. ", "What's new today is that we're going to put in the limits.  If you have a limit here, u1, and a limit here, u2, you want ", "to know what the relationship is between the limits here and  the limits when you change variables to the new variables.  And it's the simplest possible thing. ", "Namely the two limits over here are in the same relationship as  u ( x) is to this symbol u here.  In other words, u1 = u ( x1), and u2 = u(x2). ", "That's what works.  Now there's only one danger here, there's subtlety which  is, this only works if u' does not change sign. ", "I've been worrying a little bit about going backwards and  forwards, and I allowed myself to reverse and do all kinds of  stuff, right, with these integrals.  So we're sort of free to do it.  Well, this is one case where you want to avoid it, OK? ", "Just don't do it.  It is possible, actually, to make sense out of it, but it's  also possible to get yourself infinitely confused.  So just make sure that -- now it's OK is u' is always ", "negative, or always going one way, so OK if u' is always  positive, you're always going the other way, but if you mix  them up you'll get yourself mixed up. ", "Let me give you an example.  The example will be maybe close to what we did last time. ", "When we first did substitution.  So the integral from 1 to 2, this time I'll put in definite  limits, of x^2 plus -- sorry, maybe I call this x^3. x^3 + ", "2, let's say, I don't know, to the 5th power, x^2 dx.  So this is an example of an integral that we would ", "have tried to handle by substitution before.  And the substitution we would have used is u = x^3 + 2. ", "And that's exactly what we're going to do here.  But we're just going to also take into account the limits.  The first step as in any substitution or change ", "of variables, is this.  And so we can fill in the things that we would ", "have done previously.  Which is that this is the integral and this is u ^ 5.  And then because this is 3x^2, we see that this is 3. ", "Sorry, let's write it the other way.  1/3 du = x^2 dx.  So that's what I'm going to plug in for this factor here. ", "So here's 1/3 du, which replaces that.  But now there's the extra feature.  The extra feature is the limits. ", "So here, really in disguise, because, and now this is  incredibly important.  This is one of the reasons why we use this notation dx and du. ", "We want to remind ourselves which variable is involved  in the integration.  And especially if you're the one naming the variables, you  may get mixed up in this respect. ", "So you must know which variable is varying between 1 and 2.  And the answer is, it's x is the one that's  varying between 1 and 2. ", "So in disguise, even though I didn't write it, it  was contained in this little symbol here.  This reminded us which variable.  You'll find this amazingly important when you get to ", "multivariable calculus.  When there are many variables floating around.  So this is an incredibly important distinction to make.  So now, over here we have a limit.  But of course it's supposed to be with respect to u, now. ", "So we need to calculate what those corresponding limits are.  And indeed it's just, I plug in here u1 is going to be able to  what I plug in for x = 1, that's going to be 1  ^3 + 2, which is 3. ", "And then u2 is 2^3 + 2, which = 10, right?  8 + 2 = 10.  So this is the integral from 3 to 10, of u ^ 5 (1/3 du). ", "And now I can finish the problem.  This is 1/18 u ^ 6, from 3 to 10.  And this is where the most common mistake occurs in ", "substitutions of this type.  Which is that if you ignore this, and you plug in these 1  and 2 here, you think, oh I should just be putting  it at 1 and 2. ", "But actually, it should be, the u value that we're interested  in, and the lower limit is u = 3 and u = 10 as  the upper limit.  So those are suppressed here. ", "But those are the ones that we want.  And so, here we go.  It's 1/18 times some ridiculous number which I won't calculate. ", "10 ^ 6 - 3 ^ 6.  Yes, question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: So, if you want to do things with where you're  worrying about the sign change, the right strategy is, ", "what you suggested works.  And in fact I'm going to do an example right  now on this subject.  But, the right strategy is to break it up into pieces. ", "Where u' has one sign or the other, OK?  Let me show you an example.  Where things go wrong. ", "And I'll tell you how to handle it roughly.  So here's our warning. ", "Suppose you're integrating for - 1 to 1, x^2 dx.  Here's an example.  And you have the temptation to plug in u = x^2. ", "Now, of course, we know how to integrate this.  But let's just pretend we were stubborn and wanted  to use substitution. ", "Then we have du = 2x dx.  And now if I try to make the correspondence, notice that ", "the limits are u1 = (- 1)^2, that's the bottom limit.  And u2 is the upper limit. ", "That's 1 ^2, that's also equal to 1.  Both limits are 1.  So this is going from 1 to 1.  And no matter what it is, we know it's going to be 0. ", "But we know this is not 0.  This is the integral of a positive quantity.  And the area under a curve is going to be a positive area. ", "So this is a positive quantity.  It can't be 0.  If you actually plug it in, it looks equally strange.  You put in here this u and then, so that ", "would be for the u^2.   And then to plug in for dx, you would write dx = (1 / 2x) du.  And then you might write that as this. ", "And so what I should put in here is this quantity here.  Which is a perfectly OK integral.  And it has a value, I mean, it's what it is. ", "It's 0.  So of course this is not true.  And the reason is that u = x^2, and u' ( x ) = 2x, which was ", "positive for x positive, and negative for x negative.  And this was the sign change which causes us trouble.  If we break it off into its two halves, then it'll be OK and ", "you'll be able to use this.  Now, there was a mistake.  And this was essentially what you were saying.  That is, it's possible to see this happening as you're doing ", "it if you're very careful.  There's a mistake in this process, and the mistake  is in the transition.  This is a mistake here.  Maybe I haven't used any red yet today, so I get ", "to use some red here.  Oh boy.  This is not true, here.  This step here.  So why isn't it true?  It's not true for the standard reason. ", "Which is that really, x = plus or minus square root of u.  And if you stick to one side or the other, you'll have ", "a coherent formula for it.  One of them will be the plus and one of them will be the  minus and it will work out when you separate  it into its pieces.  So you could do that.  But this is a can of worms. ", "So I avoid this.  And just do it in a place where the inverse is well defined.  And where the function either moves steadily  up or steadily down.  "], "vid_duration": [11.0, 17.0, 11.0, 13.0, 13.0, 10.0, 15.0, 16.0, 12.0, 10.0, 10.0, 11.0, 13.0, 12.0, 12.0, 13.0, 18.0, 13.0, 11.0, 11.0, 16.0, 10.0, 10.0, 14.0, 11.0, 12.0, 13.0, 10.0, 11.0, 11.0, 10.0, 11.0, 23.0, 12.0, 10.0, 11.0, 13.0, 11.0, 12.0, 11.0, 10.0, 16.0, 14.0, 11.0, 15.0, 12.0, 11.0, 11.0, 12.0, 13.0, 14.0, 17.0, 12.0, 11.0, 10.0, 12.0, 10.0, 12.0, 10.0, 10.0, 11.0, 13.0, 13.0, 12.0, 12.0, 13.0, 11.0, 10.0, 10.0, 10.0, 12.0, 22.0, 15.0, 12.0, 14.0, 14.0, 10.0, 12.0, 10.0, 12.0, 15.0, 10.0, 13.0, 11.0, 14.0, 11.0, 13.0, 10.0, 15.0, 10.0, 10.0, 13.0, 18.0, 16.0, 14.0, 12.0, 13.0, 14.0, 12.0, 10.0, 12.0, 11.0, 11.0, 13.0, 15.0, 20.0, 12.0, 12.0, 14.0, 14.0, 12.0, 13.0, 10.0, 10.0, 20.0, 10.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 10.0, 13.0, 10.0, 11.0, 12.0, 13.0, 10.0, 13.0, 12.0, 10.0, 11.0, 11.0, 11.0, 12.0, 10.0, 10.0, 13.0, 15.0, 11.0, 10.0, 11.0, 11.0, 15.0, 12.0, 14.0, 12.0, 15.0, 12.0, 10.0, 17.0, 13.0, 11.0, 13.0, 10.0, 11.0, 10.0, 19.0, 12.0, 10.0, 12.0, 14.0, 13.0, 11.0, 11.0, 14.0, 12.0, 13.0, 10.0, 12.0, 17.0, 18.0, 15.0, 15.0, 17.0, 20.0, 16.0, 11.0, 11.0, 13.0, 12.0, 11.0, 14.0, 27.0, 12.0, 11.0, 14.0, 15.0, 15.0, 11.0, 16.0, 11.0, 10.0, 12.0, 11.0, 11.0, 13.0, 10.0, 10.0, 10.0, 12.0, 12.0, 19.0, 13.0, 10.0, 11.0, 10.0, 26.0, 12.0, 11.0, 10.0, 15.0, 14.0, 10.0, 11.0, 10.0, 13.0, 10.0, 11.0, 13.0, 10.0, 18.0, 13.0, 11.0, 14.0, 10.0, 11.0, 10.0, 10.0], "stet": [[0, 11.0], [11.0, 28.0], [28.0, 39.0], [39.0, 52.0], [52.0, 65.0], [65.0, 75.0], [75.0, 90.0], [90.0, 106.0], [106.0, 118.0], [118.0, 128.0], [128.0, 138.0], [138.0, 149.0], [149.0, 162.0], [162.0, 174.0], [174.0, 186.0], [186.0, 199.0], [199.0, 217.0], [217.0, 230.0], [230.0, 241.0], [241.0, 252.0], [252.0, 268.0], [268.0, 278.0], [278.0, 288.0], [288.0, 302.0], [302.0, 313.0], [313.0, 325.0], [325.0, 338.0], [338.0, 348.0], [348.0, 359.0], [359.0, 370.0], [370.0, 380.0], [380.0, 391.0], [391.0, 414.0], [414.0, 426.0], [426.0, 436.0], [436.0, 447.0], [447.0, 460.0], [460.0, 471.0], [471.0, 483.0], [483.0, 494.0], [494.0, 504.0], [504.0, 520.0], [520.0, 534.0], [534.0, 545.0], [545.0, 560.0], [560.0, 572.0], [572.0, 583.0], [583.0, 594.0], [594.0, 606.0], [606.0, 619.0], [619.0, 633.0], [633.0, 650.0], [650.0, 662.0], [662.0, 673.0], [673.0, 683.0], [683.0, 695.0], [695.0, 705.0], [705.0, 717.0], [717.0, 727.0], [727.0, 737.0], [737.0, 748.0], [748.0, 761.0], [761.0, 774.0], [774.0, 786.0], [786.0, 798.0], [798.0, 811.0], [811.0, 822.0], [822.0, 832.0], [832.0, 842.0], [842.0, 852.0], [852.0, 864.0], [864.0, 886.0], [886.0, 901.0], [901.0, 913.0], [913.0, 927.0], [927.0, 941.0], [941.0, 951.0], [951.0, 963.0], [963.0, 973.0], [973.0, 985.0], [985.0, 1000.0], [1000.0, 1010.0], [1010.0, 1023.0], [1023.0, 1034.0], [1034.0, 1048.0], [1048.0, 1059.0], [1059.0, 1072.0], [1072.0, 1082.0], [1082.0, 1097.0], [1097.0, 1107.0], [1107.0, 1117.0], [1117.0, 1130.0], [1130.0, 1148.0], [1148.0, 1164.0], [1164.0, 1178.0], [1178.0, 1190.0], [1190.0, 1203.0], [1203.0, 1217.0], [1217.0, 1229.0], [1229.0, 1239.0], [1239.0, 1251.0], [1251.0, 1262.0], [1262.0, 1273.0], [1273.0, 1286.0], [1286.0, 1301.0], [1301.0, 1321.0], [1321.0, 1333.0], [1333.0, 1345.0], [1345.0, 1359.0], [1359.0, 1373.0], [1373.0, 1385.0], [1385.0, 1398.0], [1398.0, 1408.0], [1408.0, 1418.0], [1418.0, 1438.0], [1438.0, 1448.0], [1448.0, 1459.0], [1459.0, 1469.0], [1469.0, 1479.0], [1479.0, 1489.0], [1489.0, 1502.0], [1502.0, 1515.0], [1515.0, 1525.0], [1525.0, 1538.0], [1538.0, 1548.0], [1548.0, 1559.0], [1559.0, 1571.0], [1571.0, 1584.0], [1584.0, 1594.0], [1594.0, 1607.0], [1607.0, 1619.0], [1619.0, 1629.0], [1629.0, 1640.0], [1640.0, 1651.0], [1651.0, 1662.0], [1662.0, 1674.0], [1674.0, 1684.0], [1684.0, 1694.0], [1694.0, 1707.0], [1707.0, 1722.0], [1722.0, 1733.0], [1733.0, 1743.0], [1743.0, 1754.0], [1754.0, 1765.0], [1765.0, 1780.0], [1780.0, 1792.0], [1792.0, 1806.0], [1806.0, 1818.0], [1818.0, 1833.0], [1833.0, 1845.0], [1845.0, 1855.0], [1855.0, 1872.0], [1872.0, 1885.0], [1885.0, 1896.0], [1896.0, 1909.0], [1909.0, 1919.0], [1919.0, 1930.0], [1930.0, 1940.0], [1940.0, 1959.0], [1959.0, 1971.0], [1971.0, 1981.0], [1981.0, 1993.0], [1993.0, 2007.0], [2007.0, 2020.0], [2020.0, 2031.0], [2031.0, 2042.0], [2042.0, 2056.0], [2056.0, 2068.0], [2068.0, 2081.0], [2081.0, 2091.0], [2091.0, 2103.0], [2103.0, 2120.0], [2120.0, 2138.0], [2138.0, 2153.0], [2153.0, 2168.0], [2168.0, 2185.0], [2185.0, 2205.0], [2205.0, 2221.0], [2221.0, 2232.0], [2232.0, 2243.0], [2243.0, 2256.0], [2256.0, 2268.0], [2268.0, 2279.0], [2279.0, 2293.0], [2293.0, 2320.0], [2320.0, 2332.0], [2332.0, 2343.0], [2343.0, 2357.0], [2357.0, 2372.0], [2372.0, 2387.0], [2387.0, 2398.0], [2398.0, 2414.0], [2414.0, 2425.0], [2425.0, 2435.0], [2435.0, 2447.0], [2447.0, 2458.0], [2458.0, 2469.0], [2469.0, 2482.0], [2482.0, 2492.0], [2492.0, 2502.0], [2502.0, 2512.0], [2512.0, 2524.0], [2524.0, 2536.0], [2536.0, 2555.0], [2555.0, 2568.0], [2568.0, 2578.0], [2578.0, 2589.0], [2589.0, 2599.0], [2599.0, 2625.0], [2625.0, 2637.0], [2637.0, 2648.0], [2648.0, 2658.0], [2658.0, 2673.0], [2673.0, 2687.0], [2687.0, 2697.0], [2697.0, 2708.0], [2708.0, 2718.0], [2718.0, 2731.0], [2731.0, 2741.0], [2741.0, 2752.0], [2752.0, 2765.0], [2765.0, 2775.0], [2775.0, 2793.0], [2793.0, 2806.0], [2806.0, 2817.0], [2817.0, 2831.0], [2831.0, 2841.0], [2841.0, 2852.0], [2852.0, 2862.0], [2862.0, 2872.0]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [221, 564, 886, 1302, 1872, 2362, 2665, 2872]}
{"example_id": "mit001@@ocw-18.01-f07-lec04_300k", "text": ["at ocw.mit.edu.  Professor: I am Haynes Miller, I am substituting for  David Jerison today.  So you have a substitute teacher today. ", "So I haven't been here in this class with you so I'm not  completely sure where you are.  I think just been talking about differentiation and you've ", "got some examples of differentiation like these  basic examples: the derivative of x^n is nx^(x-1).   But I think maybe you've spent some time computing the ", "derivative of the sine function as well, recently.  And I think you have some rules for extending these ", "calculations as well.  For instance, I think you know that if you differentiate a  constant times a function, what do you get? ", "Student: [INAUDIBLE].  Professor: The constant comes outside like this.  Or I could write (cu)' = cu'. ", " That's this rule, multiplying by a constant, and I  think you also know about differentiating a sum. ", "Or I could write this as (u  v)' = u' + v'.   So I'm going to be using those but today I'll talk about a ", "collection of other rules about how to deal with a product of  functions, a quotient of functions, and, best of all,  composition of functions.  And then at the end, I'll have something to say ", "about higher derivatives.  So that's the story for today.  That's the program.  So let's begin by talking about the product rule. ", "So the product rule tells you how to differentiate a product  of functions, and I'll just give you the rule,  first of all.  The rule is it's u'v + uv'.  ", "It's a little bit funny.  Differentiating a product gives you a sum.  But let's see how that works out in a particular example.  For example, suppose that I wanted to differentiate ", "the product.  Well, the product of these two basic examples that  we just talked about.  I'm going to use the same variable in both cases  instead of different ones like I did here. ", "So the derivative of (x^n)sin x.   So this is a new thing.  We couldn't do this without using the product rule. ", "So the first function is x^n and the second one is sin x.  And we're going to apply this rule.  So u is x^n. u' is, according to the rule, nx^(n - 1). ", "And then I take v and write it down the way it is, sine of x.  And then I do it the other way.  I take u the way it is, that's x^n, and multiply it by ", "the derivative of v, v'.  We just saw v' is cosine of x.  So that's it.  Obviously, you can differentiate longer products, ", "products of more things by doing it one at a time.  Let's see why this is true.  I want to try to show you why the product rule holds. ", "So you have a standard way of trying to understand this, and  it involves looking at the change in the function that  you're interested in differentiating. ", "So I should look at how much the product uv changes when  x changes a little bit.  Well, so how do compute the change?  Well, I write down the value of the function at some ", "new value of x, (x  delta x).  Well, I better write down the whole new value  of the function, and the function is uv. ", "So the whole new value looks like this.  It's u (x  delta x)v(x + delta x).  That's the new value.  But what's the change in the product? ", "Well, I better subtract off what the old value was,  which is u(x) v(x).  Okay, according to the rule we're trying to prove, I ", "have to get u' involved.  So I want to involve the change in u alone, by itself.  Let's just try that.  I see part of the formula for the change in u right there. ", "Let's see if we can get the rest of it in place.  So the change in x = ((u(x)  + delta x) - u(x)).  That's the change in x [Correction:___c ", "hange___in___u].  This part of it occurs up here, multiplied by v (x  delta x), so let's put that in too.  Now this equality sign isn't very good right now. ", "I've got this product here so far, but I've introduced  something I don't like.  I've introduced u (v ( x  delta x)), right?  Minus that. ", "So the next thing I'm gonna do is correct that little  defect by adding in u(x) (v (x + delta x)). ", "Okay, now I cancelled off what was wrong with this line.  But I'm still not quite there, because I haven't  put this in yet.  So I better subtract off uv, and then I'll be home. ", "But I'm going to do that in a clever way, because I noticed  that I already have a u here.  So I'm gonna take this factor of u and make it  the same as this factor. ", "So I get u(x) times this, minus u(x) times that.  That's the same thing as u times the difference.  So that was a little bit strange, but when you stand ", "back and look at it, you can see multiplied out, the  middle terms cancel.  And you get the right answer.  Well I like that because it's involved the change  in u and the change in v. ", "So this is equal to (delta u) v (x  delta x) - u(x) times the change in v. ", "Well, I'm almost there.  The next step in computing the derivative is take difference  quotient, divide this by delta x. ", "So, (delta (uv)) / (delta x) is well, I'll say (delta  u / delta x) v ( x ", "delta x).  Have I made a mistake here? ", "This plus magically became a minus on the way down here,  so I better fix that.  Plus u(delta v / (delta x). ", "This u is this u over here.  So I've just divided this formula by delta x, and now I  can take the limit as goes to 0, so this is as ", "delta x goes to 0.  This becomes the definition of the derivative, and on this ", "side, I get du/dx times... now what happens to this quantity  when delta x goes to 0? ", "So this quantity is getting closer and closer to x.  So what happens to the value of v?  It becomes equal to x(v).  That uses continuity of v. ", "So, v (x  delta x) goes to v(x) by continuity.  So this gives me times v, and then I have u(n delta v/ v ", "delta x) gives me dv/dx.  And that's the formula.  That's the formula as I wrote it down at the  beginning over here.  The derivative of a product is given by this sum. ", "Yeah?  Student: How did you get from the first line to the second  of the long equation? ", "Professor: From here to here?  Student: Yes.  Professor: So maybe it's easiest to work backwards and  verify that what I wrote down is correct here. ", "So, if you look there's a u(v (x  delta x)) there.  And there's also one here.  And they occur with opposite signs. ", "So they cancel.  What's left is u ( x  delta x) v (x  delta x) - (uv). ", "And that's just what I started with.  Student: They cancel right? ", "Professor: I cancelled out this term and this term, and  what's left is the ends.  Any other questions?  Student: [INAUDIBLE]. ", "Professor: Well, I just calculated what delta uv is,  and now I'm gonna divide that by delta x on my way to  computing the derivative. ", "And so I copied down the right hand side and divided delta x.  I just decided to divide the delta u by delta x ", "and delta v by delta x.  Good.  Anything else? ", "So we have the product rule here.  The rule for differentiating a product of two functions.  This is making us stronger.  There are many more functions you can find  derivatives of now.  How about quotients? ", "Let's find out how to differentiate a quotient  of two functions. ", "Well again, I'll write down what the answer is and then  we'll try to verify it.  So there's a quotient.  Let me write this down.  There's a quotient of two functions. ", "And here's the rule for it.  I always have to think about this and hope that I get  it right. u'v - uv' / v^2. ", "This may be the craziest rule you'll see in this  course, but there it is.  And I'll try to show you why that's true and see an example.  Yeah there was a hand?  Student: [INAUDIBLE] ", "Professor: What letters look the same? u and  v look the same?  I'll try to make them look more different.  The v's have points on the bottom. u's have little ", "round things on the bottom.  What's the new value of u?  The value of u at (x ", "delta x) is (u  delta u), right?  That's what delta u is.  It's the change in u when x gets replaced by (x ", "delta x).  And the change in v, the new value v, is (v  delta v).  So this is the new value of u divided by the new value of v. ", "That's the beginning.  And then I subtract off the old values, which are - u/v.  This'll be easier to work out when I write it out this way. ", "So now, we'll cross multiply, as I said.  So I get (uv  (delta u)v) minus, now I cross multiply this way, ", "you get (uv - u(delta v)).  And I divide all this by (v  delta v)u [Correction:___( v___+___delta___v)v]. ", " Okay, now the reason I like to do it this way is that you see  the cancellation happening here. uv and uv occur twice ", "and so I can cancel them.  And I will, and I'll answer these questions in a minute.  Audience: [INAUDIBLE].  Professor: Ooo, that's a v. ", "All right.  Good, anything else?  That's what all hands were.  Good.  All right, so I cancel these and what I'm left with then  is (delta u)v - u(delta v) and all this is over (v ", "delta v)v.  Ok, there's the difference.  There's the change in the quotient.  The change in this function is given by this formula. ", "And now to compute the derivative, I want to divide by  delta x, and take the limit.  So let's write that down, delta(u/v)/delta x ", "is this formula here divided by delta x.  And again, I'm going to put the delta x under these  delta u and delta v. ", "Okay?  I'm gonna put delta x in the denominator, but I can think  of that as dividing into this factor and this factor.  So this is ((delta u/ delta x)v) - u(delta v/delta x)). ", " And all that is divided by the same denominator, (v  delta v)v.  ", "Right?  Put the delta x up in the numerator there.  Next up, take the limit as delta x goes to 0.  I get, by definition, the derivative of (u/v). ", "And on the right hand side, well, this is the derivative  u(du/ dx) right?  Times v.  See and then u times, and here it's the derivative (dv/ dx). ", "Now what about the denominator?  So when delta x goes to 0, v stays the same,  v stays the same. ", "What happens to this delta v?  It goes to 0, again, because v is continuous.  So again, delta v goes to 0 with delta x because they're ", "continuous and you just get (v*v).   I think that's the formula I wrote down over there.  (du/dx)v - u(dv/dx).  ", "And all divided by the square of the old denominator.  Well, that's it.  That's the quotient rule.  Weird formula.  Let's see an application. ", "Let's see an example.  So the example I'm going to give is pretty simple.  I'm going to take the numerator to be just 1. ", "So I'm gonna take u = 1.  So now I'm differentiating 1 / v, the reciprocal of a ", "function; 1 over a function.  Here's a copy of my rule.  What's du/ dx in that case? u is a constant, so that ", "term is 0 in this rule.  I don't have to worry about this.  I get a minus.  And then u = 1, and dv/ dx. ", "Well, v is whatever v is.  I'll write dv/dx as v'.   And then I get a v^2 in the denominator.  So that's the rule. ", "I could write it as (v^-2)v'.   (-v'/v^2).  That's the derivative of 1 / v. ", "How about sub-example of that?  I'm going to take the special case where u = 1 again. ", "And v = x^n.   And I'm gonna use the rule that we developed earlier about  the derivative of x^n. ", "So what do I get here? d / dx (1/x^n) is, I'm plugging into ", "this formula here with v = x^n.  So I get minus, uh, v^-2. ", "If v = x^n, v^-2 is, by the rule of exponents, x^-2n.   And then v' is the derivative of x^n, which is (nx)^(n-1). ", " Ok, so let's put these together.  There's several powers of x here.  I can put them together.  I get -nx ^ ((- 2n) ", "(n - 1)).  One of these n's cancels.  And what I'm left with is ((-n) - 1).  So we've computed the derivative of 1 / x^n, ", "which I could also write as x^-n, right?  So I've computed the derivative of negative powers of x. ", "And this is the formula that I get.  If you think of this - n as a unit, as a thing to itself, it  occurs here in the exponent. ", "It occurs here, and it occurs here.  So how does that compare with the formula  that we had up here?  The derivative of a power of x is that power times x to ", "one less than that power.  That's exactly the same as the rule that I wrote down here.  But the power here happens to be a negative number, and the  same negative number shows up as a coefficient and ", "there in the exponent.  Yeah?  Student: [INAUDIBLE].  Professor: How did I do this? ", "Student: [INAUDIBLE]. ", "Professor: Where did that x^-2n come from?  So I'm applying this rule. ", "So the denominator in the quotient rule is v^2.  And v was x^n, so the denominator is x^2n. ", "And I decided to write it as x^-2n.   So the green comments there... ", "What they say is that I can enlarge this rule.  This exact same rule is true for negative values of n, as  well as positive values of n. ", "So there's something new in your list of rules that you  can apply, of values of the derivative. ", "That standard rule is true for negative as well  as positive exponents.  And that comes out of a quotient rule. ", "Okay, so we've done two rules.  I've talked about the product rule and the quotient rule.  What's next?  Let's see the chain rule.  So this is a composition rule. ", "So the kind of thing that I have in mind, composition of  functions is about substitution.  So the kind of function that I have in mind is, for  instance, y = (sin t)^10.  ", "That's a new one.  We haven't seen how to differentiate that  before, I think.  This kind of power of a trig function happens very often. ", "You've seen them happen, as well, I'm sure, already.  And there's a little notational switch that people use.  They'll write sin^10(t).  ", "But remember that when you write sin^10(t), what you mean  is take the sine of t, and then take the tenth power of that.  It's the meaning of sin^10(t). ", "So the method of dealing with this kind of composition of  functions is to use new variable names. ", "What I mean is, I can think of this (sin t)^10.   I can think of it it as a two step process.  First of all, I compute the sine of t. ", "And let's call the result x.  There's the new variable name.  And then, I express y in terms of x.  So y says take this and raise it to the tenth power. ", "In other words, y = x^10.   And then you plug x = sine of t into that, and you get the  formula for what y is in terms of t. ", "So it's good practice to introduce new letters when  they're convenient, and this is one place where  it's very convenient. ", "So let's find a rule for differentiating a composition,  a function that can be expressed by doing one function  and then applying another function.  And here's the rule. ", "Well, maybe I'll actually derive this rule first, and  then you'll see what it is.  In fact, the rule is very simple to derive.  So this is a proof first, and then we'll write down the rule. ", "I'm interested in delta y / delta t. y is a function of  x. x is a function of t.  And I'm interested in how y changes with respect to ", "t, with respect to the original variable t.  Well, because of that intermediate variable, I can  write this as ((delta y / delta x) (delta x/ delta t)). ", "It cancels, right?  The delta x cancels.  The change in that immediate variable cancels out. ", "This is just basic algebra.  But what happens when I let delta t get small?  Well this give me dy /dt. ", "On the right hand side, I get (dy/dx) (dx/dt).  So students will often remember this rule. ", "This is the rule, by saying that you can cancel  out for the dx's.  And that's not so far from the truth.  That's a good way to think of it. ", "In other words, this is the so-called chain rule.  And it says that differentiation of a ", "composition is a product. ", "It's just the product of the two derivatives.  So that's how you differentiate a composite of two functions. ", "And let's just do an example.  Let's do this example.  Let's see how that comes out.  So let's differentiate, what did I say? ", "(sin t)^10.   Okay, there's an inside function and an  outside function.  The inside function is x as a function of t. ", "This is the inside function, and this is  the outside function. ", "So the rule says, first of all let's differentiate  the outside function.  Take dy/ dx.  Differentiate it with respect to that variable x. ", "The outside function is the 10th power.  What's it's derivative?  So I get 10x^9. ", "In this account, I'm using this newly introduced  variable named x. ", "So the derivative of the outside function is 10x^9.  And then here's the inside function, and the next thing I  want to do is differentiate it.  So what's dx /dt, d/dt (sine t), the derivative of sine t? ", "All right, that's cosine t.  That's what the chain gives you.  This is correct, but since we were the ones to introduce ", "this notation x here, that wasn't given to us in the  original problem here.  The last step in this process should be to put back, to  substitute back in what x is in terms of t. ", "So x = sin t.  So that tells me that I get 10(sin(t))^9, that's ", "x^9, times the cos(t).  Or the same thing is sin^9(t)cos(t).  ", "So there's an application of the chain rule.  You know, people often wonder where the name  chain rule comes from.  I was just wondering about that myself. ", "So is it because it chains you down?  Is it like a chain fence? ", "I decided what it is.  It's because by using it, you burst the chains of  differentiation, and you can differentiate many more  functions using it.  So when you want to think of the chain rule, just think ", "of that chain there.  It lets you burst free. ", "Let me give you another application of the chain rule. ", "Ready for this one? ", "So I'd like to differentiate the sin(10t).   Again, this is the composite of two functions. ", "What's the inside function?  Okay, so I think I'll introduce this new notation. x = 10t, and  the outside function is the sine. ", "So y = sin x.  So now the chain rule says dy/ dt is...  Okay, let's see.  I take the derivative of the outside function, ", "and what's that?  Sine' and we can substitute because we know what sine' is.  So I get cosine of whatever, x, and then times what? ", "Now I differentiate the inside function, which is just 10.  So I could write this as 10cos of what?  10t, x = 10t. ", " Now, once you get used to this, this middle variable, you don't  have to give a name for it. ", "You can just to think about it in your mind without actually  writing it down, d/dt (sin(10t)). ", " I'll just do it again without introducing this middle  variable explicitly.  Think about it.  I first of all differentiate the outside function, ", "and I get cosine.  But I don't change the thing that I'm plugging into it.  It's still x that I'm plugging into it. x is 10t. ", "So let's just write 10t and not worry about the name  of that extra variable.  If it confuses you, introduce the new variable.  And do it carefully and slowly like this.  But, quite quickly, I think you'll get to be able to keep ", "that step in your mind.  I'm not quite done yet.  I haven't differentiated the inside function, the  derivative of 10t = 10.  So you get, again, the same result. ", "A little short cut that you'll get used to.  Really and truly, once you have the chain rule, the world  is yours to conquer.  It puts you in a very, very powerful position. ", "Okay, well let's see.  What have I covered today?  I've talked about product rule, quotient rule, composition. ", "I should tell you something about higher  derivatives, as well.  So let's do that. ", "This is a simple story.  Higher is kind of a strange word.  It just means differentiate over and over again. ", "All right, so let's see.  If we have a function u or u(x), please allow me to just  write it as briefly as u. ", "Well, this is a sort of notational thing.  I can differentiate it and get u'.   That's a new function. ", "Like if you started with the sine, that's  gonna be the cosine.  A new function, so I can differentiate it again.  And the notation for the differentiating  of it again, is u''. ", "So u'' is just u' differentiated again.  For example, if u = sin x, so u' = cos(x). ", "Has Professor Gerison talked about what the  derivative of cosine is?  What is it?  Ha, ok so u'' = - sin x. ", " Let me go on.  What do you suppose u''' means?  I guess it's the derivative of u''. ", "It's called the third derivative.  And u'' is called the second derivative.  And it's (u')' differentiated again. ", "So to compute u''' in this example, what do I do?  I differentiate that again.  There's a constant term, - 1, constant factor.  That comes out. ", "The derivative of sine is what?  Okay, so u''' = - cos x.  Let's do it again.  Now after a while, you get tired of writing these things. ", "And so maybe I'll use the notation u^(4).  That's the fourth derivative.  That's u''''.  Or it's (u''')' the fourth derivative. ", "And what is that in this example?  Okay, the cosine has derivative -sin , like you told me.  And that -sin cancels with that sine, and all together, I get ", "sin x.  That's pretty bizarre.  When I differentiate the function sine of x four  times, I get back to the sine of x again. ", "That's the way it is.  Now this notation, prime prime prime prime,  and things like that.  There are different variants of that notation. ", "For example, that's another notation. ", "Well, you've used the notation du/ dx before. u' could  also be denoted du/ dx. ", "I think we've already here, today, used this way  of rewriting du/ dx.  I think when I was talking about d/dt(uv) and so on, I ", "pulled that d / dt outside and put whatever function  you're differentiating over to the right.  So that's just a notational switch.  It looks good. ", "It looks like good algebra doesn't it?  But what it's doing is regarding this notation ", "as an operator.  It's something you apply to a function to get a new function.  I apply it to the sine function, and I get  the cosine function. ", "I apply it to x^2, and I get 2x.  This thing here, that symbol, represents an operator, which ", "you apply to a function.  And the operator says, take the function and differentiate it. ", "So further notation that people often use, is they give a  different name to that operator.  And they'll write capital D for it.  So this is just using capital D for the symbol d/dx. ", "So in terms of that notation, let's see.  Let's write down what higher derivatives look like. ", "So let's see.  That's what u' is.  How about u''?  Let's write that in terms of the d/dx notation.  Well I'm supposed to differentiate u' right? ", "So that's d/dx applied to the function du/ dx.  Differentiate the derivative. ", "That's what I've done.  Or I could write that as d/dx applied to d/dx applied to u. ", "Just pulling that u outside.  So I'm doing d/dx twice.  I'm doing that operator twice.  I could write that as (d/dx)^2 applied to u. ", "Differentiate twice, and do it to the function u.  Or, I can write it as, now this is a strange one. ", "I could also write as like that. ", "It's getting stranger and stranger, isn't it?  This is definitely just a kind of abuse of notation.  But people will go even further and write (d^2)u/dx^2. ", " So this is the strangest one.  This identity quality is the strangest one, because you ", "may think that you're taking d of the quantity x^2.  But that's not what's intended.  This is not d(x^2). ", "What's intended is the quantity dx^2.  In this notation, which is very common, what's intended by the  denominator is the quantity dx^2. ", "It's part of this second differentiation operator.  So I've written a bunch of equalities down here, and the  only content to them is that these are all different ", "notations for the same thing.  You'll see this notation very commonly.  So for instance the third derivative is  (d^3)u/dx^3, and so on. ", "Sorry?  Student: [INAUDIBLE]. ", "Professor: Yes, absolutely.  Or an equally good notation is to write the operator (D^3)u.   Absolutely. ", "So I guess I should also write over here when I was talking  about d^2, the second derivative, another notation  is do the operator capital D twice.  Let's see an example of how this can be applied. ", "I'll answer this question.  Student: [INAUDIBLE].  Professor: Yeah, so the question is whether the fourth ", "derivative always gives you the original function back,  like what happened here.  No.  That's very, very special to sines and cosines.  All right? ", "And, in fact, let's see an example of that.  I'll do a calculation.  Let's calculate the nth derivative of x^n. ", "Okay, n is a number, like 1, 2, 3, 4.  Here we go.  Let's do this.  So, let's do this bit by bit. ", "What's the first derivative of x^n?  So everybody knows this.  I'm just using a new notation, this capital D notation. ", "So it's n x ^ (n -1).  Now you know know, by the way, n could be a negative number  for that, but for now, for this application, I wanna take n to ", "be 1, 2, 3, and so on; one of those numbers.  Ok, we did one derivative.  Let's compute the second derivative of x ^ n. ", "Well there's this n constant that comes out, and then the  exponent comes down, and it gets reduced by 1. ", "All right?  Should I do one more?  D^3 (x^n) = n(n-1).  That's the constant from here.  Times that exponent, (n - 2), times 1 less, (n - ", "3) is the new exponent.  Well, I keep on going until I come to a new blackboard. ", "Now, I think I'm going to stop when I get to the n minus first  derivative, so we can see what's likely to happen.  So when I took the third derivative, I had the n ", "minus third power of x.  And when I took the second derivative, I had the  second power of x.  So, I think what'll happen when I have the n minus first  derivative is I'll have the first power of x left over. ", "The powers of x keep coming down.  And what I've done it n - 1 times, I get the first power.  And then I get a big constant out in front here times more ", "and more and more of these smaller and smaller  integers that come down.  What's the last integer that came down before  I got x^1 here? ", "Well, let's see.  It's just 2, because this x^1 occurred as the  derivative of x^2.  And the coefficient in front of that is 2. ", "So that's what you get.  The numbers n( n - 1)...2)x^1.  And now we can differentiate one more time and calculate ", "what (D^n)(x^n) is.  So I get the same number, n(n-1)...  and so on and so on, times 2.  And then I guess I'll say times 1. ", "Times, what's the derivative of x ^ 1?  1, so times 1.  Time 1, times 1.  Where this one means the constant function 1. ", "Does anyone know what this number is called?  That has a name.  It's called n factorial.  And it's written n! ", " And we just used an example of mathematical induction.  So the end result is (D^n) (x^n) = n! ", "constant.  Okay that's a neat fact.  Final question for the lecture is what's D^n ", "1 applied to x ^ n?  Ha.  Excellent.  It's the derivative of a constant. ", "So it's 0.  Okay.  Thank you.  "], "vid_duration": [19.88, 11.71, 11.83, 11.09, 11.26, 12.26, 18.84, 11.96, 11.2, 21.33, 13.92, 13.02, 10.49, 15.33, 13.33, 13.0, 12.53, 10.75, 11.62, 14.13, 10.0, 11.72, 11.85, 11.57, 12.692, 11.128, 11.57, 12.61, 13.8, 10.14, 11.62, 12.06, 13.83, 16.84, 12.67, 14.42, 13.26, 12.46, 11.14, 15.89, 10.27, 14.05, 12.1, 10.13, 10.5, 10.14, 10.59, 13.39, 15.74, 10.59, 10.45, 11.79, 11.09, 14.25, 11.14, 10.17, 18.16, 12.04, 11.65, 10.08, 12.06, 12.97, 12.79, 11.09, 10.75, 10.61, 16.86, 11.38, 12.07, 10.68, 14.65, 11.42, 15.07, 16.95, 10.3, 13.22, 11.57, 10.65, 11.94, 12.61, 13.01, 13.08, 13.269, 13.661, 12.11, 13.24, 11.32, 11.18, 13.97, 15.495, 11.505, 10.09, 11.67, 15.01, 13.18, 12.43, 14.22, 10.75, 11.29, 10.89, 14.23, 10.36, 10.62, 24.93, 17.48, 10.9, 12.31, 10.68, 19.6, 10.97, 13.91, 12.52, 11.23, 11.06, 11.01, 13.06, 15.72, 10.43, 11.27, 10.06, 10.73, 19.38, 12.15, 12.88, 15.68, 12.66, 11.26, 10.03, 13.24, 11.55, 13.74, 10.425, 14.285, 12.35, 11.25, 10.3, 11.73, 14.845, 15.045, 16.87, 11.44, 11.17, 10.82, 12.45, 15.76, 10.89, 15.83, 11.7, 13.21, 10.46, 12.39, 12.3, 13.48, 10.64, 13.07, 22.51, 12.06, 10.89, 11.57, 13.91, 11.64, 13.4, 12.58, 10.949, 11.941, 11.55, 12.443, 11.037, 16.73, 10.42, 11.66, 11.93, 10.45, 11.75, 10.82, 10.64, 13.54, 18.12, 17.46, 11.27, 11.32, 11.32, 13.68, 15.1, 10.2, 12.7, 11.31, 10.9, 10.01, 11.03, 18.26, 11.95, 12.16, 11.17, 12.04, 10.34, 20.93, 11.52, 10.18, 10.542, 11.158, 10.45, 13.44, 13.01, 14.25, 12.83, 10.72, 13.23, 10.34, 12.96, 11.74, 17.99, 10.91, 12.86, 11.29, 11.07, 5.65], "stet": [[0, 19.88], [19.88, 31.59], [31.59, 43.42], [43.42, 54.510000000000005], [54.510000000000005, 65.77000000000001], [65.77000000000001, 78.03000000000002], [78.03000000000002, 96.87000000000002], [96.87000000000002, 108.83000000000001], [108.83000000000001, 120.03000000000002], [120.03000000000002, 141.36], [141.36, 155.28], [155.28, 168.3], [168.3, 178.79000000000002], [178.79000000000002, 194.12000000000003], [194.12000000000003, 207.45000000000005], [207.45000000000005, 220.45000000000005], [220.45000000000005, 232.98000000000005], [232.98000000000005, 243.73000000000005], [243.73000000000005, 255.35000000000005], [255.35000000000005, 269.4800000000001], [269.4800000000001, 279.4800000000001], [279.4800000000001, 291.2000000000001], [291.2000000000001, 303.0500000000001], [303.0500000000001, 314.6200000000001], [314.6200000000001, 327.3120000000001], [327.3120000000001, 338.4400000000001], [338.4400000000001, 350.0100000000001], [350.0100000000001, 362.6200000000001], [362.6200000000001, 376.42000000000013], [376.42000000000013, 386.5600000000001], [386.5600000000001, 398.1800000000001], [398.1800000000001, 410.2400000000001], [410.2400000000001, 424.0700000000001], [424.0700000000001, 440.9100000000001], [440.9100000000001, 453.5800000000001], [453.5800000000001, 468.0000000000001], [468.0000000000001, 481.2600000000001], [481.2600000000001, 493.7200000000001], [493.7200000000001, 504.86000000000007], [504.86000000000007, 520.7500000000001], [520.7500000000001, 531.0200000000001], [531.0200000000001, 545.07], [545.07, 557.1700000000001], [557.1700000000001, 567.3000000000001], [567.3000000000001, 577.8000000000001], [577.8000000000001, 587.94], [587.94, 598.5300000000001], [598.5300000000001, 611.9200000000001], [611.9200000000001, 627.6600000000001], [627.6600000000001, 638.2500000000001], [638.2500000000001, 648.7000000000002], [648.7000000000002, 660.4900000000001], [660.4900000000001, 671.5800000000002], [671.5800000000002, 685.8300000000002], [685.8300000000002, 696.9700000000001], [696.9700000000001, 707.1400000000001], [707.1400000000001, 725.3000000000001], [725.3000000000001, 737.34], [737.34, 748.99], [748.99, 759.07], [759.07, 771.13], [771.13, 784.1], [784.1, 796.89], [796.89, 807.98], [807.98, 818.73], [818.73, 829.34], [829.34, 846.2], [846.2, 857.58], [857.58, 869.6500000000001], [869.6500000000001, 880.33], [880.33, 894.98], [894.98, 906.4], [906.4, 921.47], [921.47, 938.4200000000001], [938.4200000000001, 948.72], [948.72, 961.94], [961.94, 973.5100000000001], [973.5100000000001, 984.1600000000001], [984.1600000000001, 996.1000000000001], [996.1000000000001, 1008.7100000000002], [1008.7100000000002, 1021.7200000000001], [1021.7200000000001, 1034.8000000000002], [1034.8000000000002, 1048.0690000000002], [1048.0690000000002, 1061.7300000000002], [1061.7300000000002, 1073.8400000000001], [1073.8400000000001, 1087.0800000000002], [1087.0800000000002, 1098.4], [1098.4, 1109.5800000000002], [1109.5800000000002, 1123.5500000000002], [1123.5500000000002, 1139.045], [1139.045, 1150.5500000000002], [1150.5500000000002, 1160.64], [1160.64, 1172.3100000000002], [1172.3100000000002, 1187.3200000000002], [1187.3200000000002, 1200.5000000000002], [1200.5000000000002, 1212.9300000000003], [1212.9300000000003, 1227.1500000000003], [1227.1500000000003, 1237.9000000000003], [1237.9000000000003, 1249.1900000000003], [1249.1900000000003, 1260.0800000000004], [1260.0800000000004, 1274.3100000000004], [1274.3100000000004, 1284.6700000000003], [1284.6700000000003, 1295.2900000000002], [1295.2900000000002, 1320.2200000000003], [1320.2200000000003, 1337.7000000000003], [1337.7000000000003, 1348.6000000000004], [1348.6000000000004, 1360.9100000000003], [1360.9100000000003, 1371.5900000000004], [1371.5900000000004, 1391.1900000000003], [1391.1900000000003, 1402.1600000000003], [1402.1600000000003, 1416.0700000000004], [1416.0700000000004, 1428.5900000000004], [1428.5900000000004, 1439.8200000000004], [1439.8200000000004, 1450.8800000000003], [1450.8800000000003, 1461.8900000000003], [1461.8900000000003, 1474.9500000000003], [1474.9500000000003, 1490.6700000000003], [1490.6700000000003, 1501.1000000000004], [1501.1000000000004, 1512.3700000000003], [1512.3700000000003, 1522.4300000000003], [1522.4300000000003, 1533.1600000000003], [1533.1600000000003, 1552.5400000000004], [1552.5400000000004, 1564.6900000000005], [1564.6900000000005, 1577.5700000000006], [1577.5700000000006, 1593.2500000000007], [1593.2500000000007, 1605.9100000000008], [1605.9100000000008, 1617.1700000000008], [1617.1700000000008, 1627.2000000000007], [1627.2000000000007, 1640.4400000000007], [1640.4400000000007, 1651.9900000000007], [1651.9900000000007, 1665.7300000000007], [1665.7300000000007, 1676.1550000000007], [1676.1550000000007, 1690.4400000000007], [1690.4400000000007, 1702.7900000000006], [1702.7900000000006, 1714.0400000000006], [1714.0400000000006, 1724.3400000000006], [1724.3400000000006, 1736.0700000000006], [1736.0700000000006, 1750.9150000000006], [1750.9150000000006, 1765.9600000000007], [1765.9600000000007, 1782.8300000000006], [1782.8300000000006, 1794.2700000000007], [1794.2700000000007, 1805.4400000000007], [1805.4400000000007, 1816.2600000000007], [1816.2600000000007, 1828.7100000000007], [1828.7100000000007, 1844.4700000000007], [1844.4700000000007, 1855.3600000000008], [1855.3600000000008, 1871.1900000000007], [1871.1900000000007, 1882.8900000000008], [1882.8900000000008, 1896.1000000000008], [1896.1000000000008, 1906.5600000000009], [1906.5600000000009, 1918.950000000001], [1918.950000000001, 1931.250000000001], [1931.250000000001, 1944.730000000001], [1944.730000000001, 1955.370000000001], [1955.370000000001, 1968.440000000001], [1968.440000000001, 1990.950000000001], [1990.950000000001, 2003.010000000001], [2003.010000000001, 2013.900000000001], [2013.900000000001, 2025.470000000001], [2025.470000000001, 2039.380000000001], [2039.380000000001, 2051.020000000001], [2051.020000000001, 2064.420000000001], [2064.420000000001, 2077.000000000001], [2077.000000000001, 2087.949000000001], [2087.949000000001, 2099.890000000001], [2099.890000000001, 2111.440000000001], [2111.440000000001, 2123.883000000001], [2123.883000000001, 2134.920000000001], [2134.920000000001, 2151.650000000001], [2151.650000000001, 2162.070000000001], [2162.070000000001, 2173.730000000001], [2173.730000000001, 2185.6600000000008], [2185.6600000000008, 2196.1100000000006], [2196.1100000000006, 2207.8600000000006], [2207.8600000000006, 2218.6800000000007], [2218.6800000000007, 2229.3200000000006], [2229.3200000000006, 2242.8600000000006], [2242.8600000000006, 2260.9800000000005], [2260.9800000000005, 2278.4400000000005], [2278.4400000000005, 2289.7100000000005], [2289.7100000000005, 2301.0300000000007], [2301.0300000000007, 2312.350000000001], [2312.350000000001, 2326.0300000000007], [2326.0300000000007, 2341.1300000000006], [2341.1300000000006, 2351.3300000000004], [2351.3300000000004, 2364.03], [2364.03, 2375.34], [2375.34, 2386.2400000000002], [2386.2400000000002, 2396.2500000000005], [2396.2500000000005, 2407.2800000000007], [2407.2800000000007, 2425.540000000001], [2425.540000000001, 2437.4900000000007], [2437.4900000000007, 2449.6500000000005], [2449.6500000000005, 2460.8200000000006], [2460.8200000000006, 2472.8600000000006], [2472.8600000000006, 2483.2000000000007], [2483.2000000000007, 2504.1300000000006], [2504.1300000000006, 2515.6500000000005], [2515.6500000000005, 2525.8300000000004], [2525.8300000000004, 2536.3720000000003], [2536.3720000000003, 2547.53], [2547.53, 2557.98], [2557.98, 2571.42], [2571.42, 2584.4300000000003], [2584.4300000000003, 2598.6800000000003], [2598.6800000000003, 2611.51], [2611.51, 2622.23], [2622.23, 2635.46], [2635.46, 2645.8], [2645.8, 2658.76], [2658.76, 2670.5], [2670.5, 2688.49], [2688.49, 2699.3999999999996], [2699.3999999999996, 2712.2599999999998], [2712.2599999999998, 2723.5499999999997], [2723.5499999999997, 2734.62], [2734.62, 2740.27]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [127, 661, 982, 1313, 1766, 1944, 2482, 2741]}
{"example_id": "mit001@@ocw-18.01-f07-lec27_300k", "text": ["PROFESSOR: Well, because our subject today is trig integrals  substitutions, Professor Jerison called in his  substitute teacher for today. ", "That's me. ", "Professor Miller.  And I'm going to try to tell you about trig substitutions  and trig integrals.  And I'll be here tomorrow to do more of the same, as well. ", "So, this is about trigonometry, and maybe first thing I'll do  is remind you of some basic things about trigonometry. ", "So, if I have a circle, trigonometry is all based on  the circle of radius 1, and centered at the origin.  And so if this is an angle of theta, up from the x-axis, then ", "the coordinates of this point are cosine theta  and sine theta.  And so that leads right away to some trig identities,  which you know very well.  But I'm going to put them up here because we'll use them ", "over and over again today.  Remember the convention sin^2 theta secretly  means (sin theta)^2.  ", "It would be more sensible to write a parenthesis around  the sign of theta and then say you square that.  But everybody in the world puts the 2 up there over the sin,  and so I'll do that too. ", "So that follows just because the circle has radius 1.  But then there are some other identities too, which  I think you remember.  I'll write them down here.  Cos 2 theta, there's this double angle formula that ", "says cos 2 theta = cos ^2 theta - sin ^2 theta.  And there's also the double angle formula ", "for the sin 2 theta.  Remember what that says?  2 sin theta cos theta. ", "I'm going to use these trig identities and I'm going to  use them in a slightly different way.  And so I'd like to pay a little more attention to this one and  get a different way of writing this one out. ", "So this is actually the half angle formula.  And that says, I'm going to try to express the cos theta in ", "terms of the cos 2 theta.  So if I know the cos 2 theta, I want to try to express the  cos theta in terms of it.  Well, I'll start with a cos 2 theta and play with that. ", "OK.  Well, we know what this is, it's cos ^2 theta  - sin ^2 theta.  But we also know what the sin square root of theta  is in terms of the cosine. ", "So I can eliminate the sin^2 from this picture.  So this is equal to the cosine ^2 theta - (the quantity  1 - cos ^2 theta). ", "I put in what sin^2 is in terms of cos^2.   And so that's 2 cos ^2 of theta - 1.  There's this cos^2, which gets a plus sign. ", "Because of these two minus signs.  And there's the one that was there before, so altogether  there are two of them.  I want to isolate what cosine is. ", "Or rather, what cos^2 is.  So let's solve for that.  So I'll put the 1 on the other side.  And I get 1 + cos 2 theta. ", "And then, I want to divide by this 2, and so that puts a  2 in this denominator here.  So some people call that the half angle formula.  What it really is for us is it's a way of eliminating ", "powers from sines and cosines.  I've gotten rid of this square at the expense of putting  in a 2 theta here.  We'll use that. ", "And, similarly, same calculation shows that the sin  ^2 theta = 1 cos 2 theta / 2. ", "Same cosine, in that formula also, but it has a minus sign.  For the sin^2.   OK. so that's my little review of trig identities that we'll ", "make use of as this lecture goes on.  I want to talk about trig identity.  Trig integrals, and you know some trig integrals, ", "I'm sure, already.  Like, well, let me write the differential form first.  You know that d sin theta, or maybe I'll say d sin x, is, ", "let's see, that's the derivative of sin x dx, right.  The derivative of sin x = cos x dx. ", "And so if I integrate both sides here, the integral form  of this is the integral of the cos x dx.  Is the sin x + a constant. ", "And in the same way, d cos x = - sin x dx.  Right, the derivative of the cosine is - sine. ", "And when I integrate that, I find the integral of the  sin x dx = - cos x + c. ", "So that's our starting point.  And the game today, for the first half of the lecture, is  to use that basic, just those basic integration formulas, ", "together with clever use of trig identities in order to  compute more complicated formulas involving  trig functions.  So the first thing, the first topic, is to think about ", "integrals of the form sin^n (x) cos^n(x).   Where here I have in mind m and n. ", "Are non-negative integers.  So let's try to integrate these.  I'll show you some applications of these pretty soon.  Looking down the road a little bit, integrals like this show ", "up in Fourier series and many other subjects in mathematics.  It turns out they're quite important to be able to do.  So that's why we're doing them now. ", "Well, so there are two cases to think about here.  When you're integrating things like this.  There's the easy case, and let's do that one first. ", "The easy case is when at least one exponent is odd. ", "That's the easy case.  So, for example, suppose that I wanted to integrate, well,  let's take the case m = 1. ", "So I'm integrating sin^n (x) cos x dx.  I'm taking -- oh. ", "I could do that one.  Let's see if that's what I want to take.  Yeah. ", "My confusion is that I meant to have this a different power.  You were thinking that.  So let's do this case when m = 1.  So the integral I'm trying to do is any power of sin cos. ", "Well, here's the trick.  Recognize, use this formula up at the top there to see cos x ", "dx as something that we already have on the blackboard.  So, the way to exploit that is to make a substitution.  And substitution is going to be u = sin x. ", "And here's why.  Then this integral that I'm trying to do is  the integral of u ^ n.  That's already a simplification. ", "And then there's that cos x dx.  When you make a substitution, you've got to go all the way  and replace everything in the expression by things ", "involving this new variable that I've introduced.  So I'd better get rid of the cosine of x dx and rewrite it  in terms of du or in terms of u. ", "And I can do that because du, according to that  formula, is the cos x dx. ", "Let me put a box around that.  That's our substitution.  When  you make a substitution, you also want to compute the  differential of the variable that you substitute in. ", "So the cos x dx that appears here is just, exactly, du.  And I've replaced this trig integral with something that  doesn't involve trig functions at all. ", "This is a lot easier.  We can just plug into what we know here.  This is (u ^ (n + 1) / n + 1) + a constant, and ", "I've done the integral.  But I'm not quite done with the problem yet.  Because to be nice to your reader and to yourself, you ", "should go back at this point, probably, go back and get rid  of this new variable that you introduced.  You're the one who introduced this variable, you.  Nobody except you, really, knows what it is. ", "But the rest of the world knows what they asked for the  first place that involved x.  So I have to go back and get rid of this.  And that's not hard to do in this case, because u = sin x. ", "And so I make this back substitution.  And that's what you get.  So there's the answer. ", "OK, so the game was, I use this odd power of the cosine here,  and I could see it appearing as the differential of the sine.  So that's what made this substitution work. ", "Let's do another example to see how that works out in  a slightly different case. ", "So here's another example. ", "Now I do have an odd power.  One of the exponents is odd, so I'm in the easy case.  But it's not 1.  The game now is to use this trig identity to get rid of the ", "largest even power that you can, from this odd power here.  So use sin^2 x = 1 - cos^2 x, to eliminate a lot of ", "powers from that odd power.  Watch what happens.  So this is not really a substitution or anything, this  is just a trig identity. ", "This sin^3 = sin^2 sin.  And sin^2 = (1 - cos^2 x) And then I have  the remaining sin x.  And then I have cos^2 x dx. ", "So let me rewrite that a little bit to see how this works out.  This is the integral of (cos^2 (x) -, and then there's ", "the product of these two.  That's cos^ 4 x) sin of x dx.  So now I'm really exactly in the situation that ", "I was in over here.  I've got a single power of a sine or cosine.  It happens that it's a sine here.  But that's not going to cause any trouble, we can go ahead ", "and play the same game that I did there.  So, so far I've just been using trig identities.  But now I'll use a trig substitution. ", "And I think I want to write these as powers of a variable.  And then this is going to be the differential  of that variable.  So I'll take u to be cosine of x, and that means ", "that du = - sin x, dx.  There's the substitution. ", "So when I make that substitution, what do we get.  Cos^2 becomes u^2.  ", "Cos^ 4 becomes u ^ 4, and sin x dx becomes not quite du, watch  for the signum, watch for this minus sign here. ", "It becomes - du.  But that's OK.  The minus sign comes outside.  And I can integrate both of these powers, so ", "I get - u ^3 / 3.  And then this 4th power gives me a 5th power,  when I integrate. ", "And don't forget the constant.  Am I done?  Not quite done.  I have to back substitute and get rid of my choice ", "of variable, u, and replace it with yours.  Questions?  STUDENT: [INAUDIBLE]  PROFESSOR: There should indeed.  I forgot this minus sign when I came down here. ", "So these two gang up to give me a plus.  Was that what the other question was about, too?  Thanks.  So let's back substitute.  And I'm going to put that over here. ", "And the result is, well, I just replace the u by cosine of x.  So this is - cos^3 x / 3 +, thank you, cos^5 x / 5 + c. ", "And there's the answer.  By the way, you can remember one of the nice things about  doing an integral is it's fairly easy to ", "check your answer.  You can always differentiate the thing you get, and see  whether you get the right thing when you go back.  It's not too hard to use the power rules and the ", "differentiation rule for the cosine to get back to this if  you want to check the work.  Let's do one more example, just to handle an example of this ", "easy case, which you might have thought of at first.  Suppose I just want to integrate a cube.  Sin^3 x. ", "No cosine in sight.  But I do have an odd power of a trig function,  of a sine or cosine.  So I'm in the easy case. ", "And the procedure that I was suggesting says I want to take  out the largest even power that I can, from the sin^3.   So I'll take that out, that's a sin^2 and ", "write it as 1 - cos^2.   Well, now I'm very happy.  Because it's just like the situation we had somewhere ", "on the board here.  It's just like the situation we had up here.  I've got a power of a cos sin x dx.  So exactly the same substitution steps in. ", "You get, and maybe you can see what happens  without doing the work.  Shall I do the work here?  I make the same substitution.  And so this is (1 - u ^2 )( - du). ", "Which is u - u ^3 / 3.  But then I want to put this minus sign in place, and so  that gives me - u + u ^3 / 3 + a constant. ", "And then I back substitute and get cos x + cos^3 x / 3. ", "So this is the easy case.  If you have some odd power to play with, then you can  make use of it and it's pretty straightforward.  OK the harder case is when you don't have an odd power. ", "So what's the program?  I'm going to do the harder case, and then I'm going to  show you an example of how to integrate square roots.  And do an application, using these ideas from trigonometry. ", "So I want to keep this blackboard.  Maybe I'll come back and start here again.  So the harder case is when they're only even exponents. ", "I'm still trying to integrate the same form.  But now all the exponents are even.  So we have to do some game.  And here the game is use the half angle formula. ", "Which I just erased, very sadly, on the board here.  Maybe I'll rewrite them over here so we have  them on the board. ", "I think I remember what they were. ", "So the game is I'm going to use that half angle formula to  start getting rid of those even powers.  Half angle formula written like this, exactly, talks about, it ", "rewrites, even powers of sines and cosines.  So let's see how that works out in an example.  How about just the cos^2 for a start. ", "What to do?  I can't pull anything out.  I could rewrite this as 1 - sin^2, but then I'd be faced  with integrating the sin^2, which is exactly as hard. ", "So instead, let's use this formula here.  This is really the same as 1 + cos 2 theta / 2. ", "And now, this is easy.  It's got two parts to it.  Integrating one half gives me theta over -- oh.  Miraculously, the x turned into a theta. ", "Let's put it back as x.  I get x / 2 by integrating 1/2.  So, notice that something non-trigonometric occurs  here when I do these even integrals. x / 2 appears. ", "And then the other one, OK, so this takes a little thought.  The integral of the cosine is the sine, or is it  minus the sine. - sine. ", "Shall we take a vote?  I think it's positive.  And so you get the sin 2x, but is that right?  Over 2.  If I differentiate the sin 2x, this 2 comes out. ", "And would give me an extra 2 here.  So there's an extra 2 that I have to put in here  when I integrate it. ", "And there's the answer.  This is not a substitution.  I just played with trig identities here.  And then did a simple trig integral, getting your help ", "to get the sign right.  And thinking about what this 2 is going to do.  It produces a 2 in the denominator.  But it's not applying any complicated thing. ", "It's just using this identity.  Let's do another example that's a little bit harder.  This time, sin^2 cos^2.  ", "Again, no odd powers.  I've got to work a little bit harder.  And what I'm going to do is apply those  identities up there.  Now, what I recommend doing in this situation is going ", "over to the side somewhere.  And do some side work.  Because it's all just playing with trig functions. ", "It's not actually doing any integrals for a while.  So, I guess one way to get rid of the sin^2 and the cos^2 is ", "to use those identities and so let's do that.  So the sin = 1 - cos 2x / 2.  And the cos = 1 + cos 2x / 2. ", "So I just substitute them in.  And now I can multiply that out.  And what I have is a difference times a sum. ", "So you know a formula for that.  Taking the product of these two things, well there'll  be a 4 in the denominator.  And then in the numerator, I get the square of this minus  the square of this. (a - b)( a + b) = a ^2 - b^2. ", "So I get that.  Well, I'm a little bit happier, because at  least I don't have 4.  I don't have 2 different squares. ", "I still have a square, and want to integrate this.  I'm still not in the easy case.  I got myself back to an easier hard case.  But we do know what to do about this. ", "Because I just did it up there.  And I could play into this formula that we got.  But I think it's just as easy to continue to calculate here. ", "Use the half angle formula again for this, and  continue on your way.  So I get a 1/4 from this bit.  And then - 1/4 of the cos^2 2x. ", "And when I plug in 2x in for theta, there in the top  board, I'm going to get a 4x on the right-hand side. ", "So it comes out like that.  And I guess I could simplify that a little bit more.  This is a 1/4.  Oh, but then there's a 2 here.  It's half that. ", "So then I can simplify a little more.  It's 1/4 - 1/8, which is 1/8.  And then I have 1/8 cos 4x. ", "OK, that's my side work.  I just did some trig identities over here.  And rewrote sine squared times cosine squared as something  which involves just no powers of trig, just cosine by itself. ", "And a constant.  So I can take that and substitute it in here.  And now the integration is pretty easy. (1/8 - cos 4x / ", "8) dx, which is, OK the 1/8 is going to give me x / 8.  The integral or cosine is plus or minus the sine. ", "The derivative of the sine is plus the cosine.  So it's going to be plus the, only there's a minus here.  So it's going to be the sin - the sin 4x / 8, but then I ", "have an additional factor in the denominator.  And what's it going to be?  I have to put a 4 there. ", "So we've done that calculation, too.  So any of these, if you keep doing this kind of process, ", "these two kinds of procedures, you can now integrate any ", "expression that has a power of a sine times a power of  a cosine in it, by using these ideas.  Now, let's see. ", "Oh, let me give you an alternate method for  this last one here. ", "I know what I'll do. ", "Let me give an alternate method for doing, really doing the  side work over there. i'm trying to deal  with sin^2 cos^2.  Well that's the square of the sin x cos x. ", "And the sin x cos x shows up right here.  In another trig identity.  So we can make use of that, too.  That reduces the number of factors of sines ", "and cosines by 1.  So it's going in the right direction.  This is equal to 1/2 sine 2x, squared. ", "Sin cos = 1/2, say this right.  It's sin 2x / 2, and then I want to square that. ", "So what I get is the sin^2 2x / 4. ", "Which is, well, I'm not too happy yet, because I  still have an even power.  Remember I'm trying to integrate this thing in the  end, even powers are bad.  I try to get rid of them.  By using that formula, the half angle formula, so I can apply ", "that to the sin x here again.  I get 1/4 of 1 - cos of 4x / 2. ", "That's what the half angle formula says for the sin^2 2x.  And that's exactly the same as the expression that  I got up here, as well. ", "It's the same expression that I have there.  So it's the same expression as I have here.  So this is just an alternate way to play this game of using ", "the half angle formula.  OK, let's do a little application of these things and  change the topic a little bit. ", "So here's the problem.  So this is an application and example of a real ", "trig substitution. ", "So here's the problem I want to look at. ", "OK, so I have a circle whose radius is a.  And I cut out from it a sort of tab, here.  This tab here. ", "And the height of this thing is b.  So this length is a number b.  And what I want to do is compute the area  of that little tab. ", "That's the problem.  So there's an arc over here.  And I want to find the area of this, for a and b,  in terms of a and b. ", "So the area, well, I guess one way to compete the ", "area would be to take the integral of y dx.  You've seen the idea of splitting this up into vertical  strips whose height is given by a function, y (x). ", "And then you integrate that.  That's an interpretation for the integral.  The area is given by y dx.  But that's a little bit awkward, because my formula  for y is going to be a little strange. ", "Its constant value of b along here, and then at this  point it becomes this arc, of the circle.  So working this out, I could do it but it's a little awkward  because expressing y as a function of x, the top edge of ", "this shape, it's a little awkward and takes two  different regions to express.  So, a different way to say it is to say x dy. ", "Maybe that'll work a little bit better.  Or maybe it won't, but it's worth trying.  I could just as well split this region up into  horizontal strips. ", "Whose width is dy, and whose length is x.  Now I'm thinking of this as a function of y.  This is the graph of a function of y. ", "And that's much better, because the function of y is, well,  it's the square root of a^2 - y ^2, isn't it.  That's x ^2 + y ^2 = a ^2. ", "So that's what x is.  And that's what I'm asked to integrate, then.  Square root of (a ^2 - y ^2) dy. ", "And I can even put in limits of integration.  Maybe I should do that, because this is supposed  to be an actual number.  I guess I'm integrating it from y = 0, that's here. ", "To y = b, dy.  So this is what I want to find.  This is a integral formula for the area of that region. ", "And this is a new form.  I don't think that you've thought about integrating ", "expressions like this in this class before.  So, it's a new form and I want to show you how to do it, how  it's related to trigonometry. ", "It's related to trigonometry through that exact picture that  we have on the blackboard.  After all, this a^2 - y ^2 is the formula for this arc. ", "And so, what I propose is that we try to exploit the  connection with the circle and introduce polar coordinates. ", "So, here if I measure this angle then there are various ", "things you can say.  Like the coordinates of this point here are  (a, cosine theta, a.  Well, I'm sorry, it's not. ", "That's an angle, but I want to call it theta 0.  And, in general you know that the coordinates of this point  are (a, cosine theta, a, sine theta). ", "If the radius is a, then the angle here is theta.  So x is a cosine theta, and y is a sine theta, just from ", "looking at the geometry of the circle.  So let's make that substitution. y = a sine theta. ", "I'm using the picture to suggest that maybe making  the substitution is a good thing to do.  Let's follow along and see what happens. ", "If that's true, what we're interested in is  integrating a^2 - y ^2.  Which is a ^2, we're interested in integrating the square ", "root of (a ^2 - y^2).  Which is the square root of a ^2 minus this.  a ^2 sin ^2 theta.  And, well, that's = a cos theta. ", "That's just sin^2 + cos^2 = 1, all over again.  It's also x.  This is x.  And this was x. ", "So there are a lot of different ways to think of this.  But no matter how you say it, the thing we're trying to  integrate, a squared, a ^2 - y ^2 is, under this substitution ", "it is a cos theta.  So I'm interested in integrating the square  root of (a ^2 - y ^2) dy. ", "And I'm going to make this substitution y = a sin theta.  And so under that substitution, I've decided that the ", "square root of a ^2 - y ^2 = a cos theta.  That's this. ", "What about the dy?  Well, I'd better compute the dy.  So dy just differentiating this expression, is  a cos theta d theta. ", "So let's put that in. dy = a cos theta d theta. ", "OK.  Making that trig substitution, y = a sin theta has replaced  this integral that has a square root in it.  And no trig functions. ", "With an integral that involves no square roots  and only trig functions.  In fact, it's not too hard to integrate this now, because  of the work that we've done. ", "The a ^2 comes out.  This is cos^2 theta. d theta.  And maybe we've done that example already today.  I think we have. ", "Maybe we can think it through, but maybe the easiest thing is  to look back at notes and see what we got before.  That was the first example in the hard case that I did. ", "And what it came out to, I used x instead of theta at the time. ", "So this is a good step forward.  I started with this integral that I really didn't know  how to do by any means that we've had so far.  And I've replaced it by a trig integral that ", "we do know how to do.  And now I've done that trig integral.  But we're still not quite done, because of the problem  of back substituting.  I'd like to go back and rewrite this in terms of ", "the original variable, y.  Or, I'd like to go back and rewrite it in terms of the  original limits of integration that we had in the  original problem. ", "In doing that, it's going to be useful to rewrite this  expression and get rid of the sin 2 theta.  After all, the original y was expressed in terms of the sin ", "theta, not the sin 2 theta.  So let me just do that here, and say that this, in turn, ", "is equal to a^2 theta / 2 +, well, the sin 2 theta = ", "2 sin theta cos theta.  And so, when there's a 4 in the denominator, what I'll get  is sin theta cos theta / 2. ", "I did that because I'm getting closer to the original terms  that the problem started with.  Which was sin theta. ", "So let me write down the integral that we have now.  The square root of a ^2 - y ^2 dy is, so far, what we know ", "is a ^2 (theta / 2 + sin theta cos theta / 2) + c. ", "But I want to go back and rewrite this in terms  of the original value.  The original variable, y.  Well, what is theta in terms of y? ", "Let's see. y in terms of theta was given like this.  So what is theta in terms of y?  Ah.  So here the fearsome arc sin rears its head, right? ", "Theta is the angle so that y = a sin theta.  So that means that theta is the arc sign, or  sine inverse, of y / a. ", "So that's the first thing that shows up here.  Arc sin (y / a). ", "All over 2.  That's this term.  Theta is the arc sin ( y /a) / 2.  What about the other side, here?  Well sine and cosine, we knew what they were in terms of y ", "and in terms of x, if you like.  Maybe I'll put the a ^2 inside here. ", "That makes it a little bit nicer.  Plus, and the other term is a ^2 (sin theta cos theta).  So the a sin theta is just y. ", "Maybe I'll write this (a sin theta)( a cos theta) / 2 + c. ", "And so I get the same thing.  And now here a sin theta, that's y.  And what's the a cos theta? ", "It's x, or, if you like, it's the square root of a ^2 - y ^2. ", "And so there I've rewritten everything, back in terms of  the original variable, y.  And there's an answer. ", "So I've done this indefinite integration of a form of this  quadratic, this square root of something which is  a constant - y ^2. ", "Whenever you see that, the thing to think  of is trigonometry.  That's going to play into the sin^ 2 + cos^2 identity.  And the way to exploit it is to make the substitution ", "y = a sin theta.  You could also make a substitution y = a cos  theta, if you wanted to.  And the result would come out to exactly the same in the end. ", "I'm still not quite done with the original problem that I  had, because the original problem asked for a ", "definite integral.  So let's just go back and finish that as well.  So the area was the integral from 0 to b ", "of this square root.  So I just want to evaluate the right-hand side here. ", "The answer that we came up with, this indefinite integral.  I want to evaluate it at 0 and at b.  Well, let's see.  When I evaluate it at b, I get a ^2 ( arc sin (b / a) / 2 + y, ", "which is b times the square root of a ^2 - b ^2, putting  y = b, divided by 2. ", "So I've plugged in y = b into that formula,  this is what I get.  Then when I plug in y = 0, well the, sine of 0 is 0,  so the arc sine of 0 is 0. ", "So this term goes away.  And when y = 0, this term is 0 also.  And so I don't get any subtracted terms at all.  So there's an expression for this. ", "Notice that this arc sin ( b / a), that's exactly this angle.  The arc sin ( b / a), it's the angle that you get when y = b. ", "So this theta is the arc sin (b / a).  Put this over here. ", "That is theta 0.  That is the angle that the corner makes.  So I could rewrite this as a ^2 theta 0 / 2 + b times the ", "square root of a ^2 - b ^2 / 2.  Let's just think about this for a minute.  I have these two terms in the sum, is that reasonable? ", "The first term is a ^2.  That's the radius squared times this angle, times 1/2. ", "Well, I think that is exactly the area of this sector. a ^2  theta / 2 is the formula for the area of the sector. ", "And this one, this is the vertical elevation.  This is the horizontal. a ^2 - b ^2 is this distance. ", "Square root of a ^2 - b ^2.  So the right-hand term is b times the square root of a  ^2 - b ^2 / 2, that's the area of that triangle. ", "So using a little bit of geometry gives you the same  answer as all of this elaborate calculus.  Maybe that's enough cause for celebration for ", "us to quit for today.  "], "vid_duration": [11.0, 13.0, 13.0, 25.0, 11.0, 11.0, 11.0, 12.0, 12.0, 10.0, 15.0, 11.0, 17.0, 16.0, 10.0, 10.0, 12.0, 10.0, 12.0, 11.0, 10.0, 10.0, 13.0, 11.0, 15.0, 12.0, 13.0, 11.0, 11.0, 13.0, 13.0, 13.0, 12.0, 11.0, 12.0, 14.0, 13.0, 13.0, 12.0, 14.0, 10.0, 17.0, 10.0, 11.0, 10.0, 11.0, 13.0, 10.0, 10.0, 11.0, 11.0, 12.0, 14.0, 11.0, 14.0, 12.0, 19.0, 16.0, 11.0, 14.0, 12.0, 12.0, 10.0, 19.0, 11.0, 12.0, 11.0, 12.0, 10.0, 11.0, 10.0, 12.0, 13.0, 15.0, 11.0, 12.0, 13.0, 15.0, 10.0, 12.0, 14.0, 11.0, 17.0, 14.0, 11.0, 12.0, 16.0, 29.0, 15.0, 13.0, 21.0, 10.0, 14.0, 11.0, 10.0, 13.0, 12.0, 17.0, 13.0, 10.0, 11.0, 14.0, 36.0, 13.0, 10.0, 13.0, 16.0, 11.0, 19.0, 10.0, 11.0, 11.0, 16.0, 14.0, 11.0, 15.0, 12.0, 16.0, 13.0, 12.0, 10.0, 10.0, 10.0, 13.0, 15.0, 10.0, 24.0, 10.0, 11.0, 10.0, 10.0, 16.0, 10.0, 11.0, 12.0, 26.0, 11.0, 10.0, 15.0, 14.0, 11.0, 10.0, 10.0, 14.0, 10.0, 13.0, 14.0, 10.0, 12.0, 14.0, 11.0, 10.0, 12.0, 10.0, 13.0, 12.0, 10.0, 11.0, 14.0, 14.0, 14.0, 11.0, 10.0, 12.0, 17.0, 11.0, 11.0, 12.0, 13.0, 11.0, 11.0, 13.0, 11.0, 11.0, 16.0, 11.0, 17.0, 12.0, 14.0, 11.0, 12.0, 12.0, 10.0, 18.0, 33.0, 10.0, 11.0, 11.0, 11.0, 19.0, 10.0, 13.0, 10.0, 12.0, 10.0, 10.0, 10.0, 14.0, 10.0, 10.0, 16.0, 12.0, 14.0, 10.0, 25.0, 10.0, 11.0, 11.0, 15.0, 15.0, 13.0, 12.0, 10.0, 13.0, 11.0, 17.0, 10.0, 3.18], "stet": [[0, 11.0], [11.0, 24.0], [24.0, 37.0], [37.0, 62.0], [62.0, 73.0], [73.0, 84.0], [84.0, 95.0], [95.0, 107.0], [107.0, 119.0], [119.0, 129.0], [129.0, 144.0], [144.0, 155.0], [155.0, 172.0], [172.0, 188.0], [188.0, 198.0], [198.0, 208.0], [208.0, 220.0], [220.0, 230.0], [230.0, 242.0], [242.0, 253.0], [253.0, 263.0], [263.0, 273.0], [273.0, 286.0], [286.0, 297.0], [297.0, 312.0], [312.0, 324.0], [324.0, 337.0], [337.0, 348.0], [348.0, 359.0], [359.0, 372.0], [372.0, 385.0], [385.0, 398.0], [398.0, 410.0], [410.0, 421.0], [421.0, 433.0], [433.0, 447.0], [447.0, 460.0], [460.0, 473.0], [473.0, 485.0], [485.0, 499.0], [499.0, 509.0], [509.0, 526.0], [526.0, 536.0], [536.0, 547.0], [547.0, 557.0], [557.0, 568.0], [568.0, 581.0], [581.0, 591.0], [591.0, 601.0], [601.0, 612.0], [612.0, 623.0], [623.0, 635.0], [635.0, 649.0], [649.0, 660.0], [660.0, 674.0], [674.0, 686.0], [686.0, 705.0], [705.0, 721.0], [721.0, 732.0], [732.0, 746.0], [746.0, 758.0], [758.0, 770.0], [770.0, 780.0], [780.0, 799.0], [799.0, 810.0], [810.0, 822.0], [822.0, 833.0], [833.0, 845.0], [845.0, 855.0], [855.0, 866.0], [866.0, 876.0], [876.0, 888.0], [888.0, 901.0], [901.0, 916.0], [916.0, 927.0], [927.0, 939.0], [939.0, 952.0], [952.0, 967.0], [967.0, 977.0], [977.0, 989.0], [989.0, 1003.0], [1003.0, 1014.0], [1014.0, 1031.0], [1031.0, 1045.0], [1045.0, 1056.0], [1056.0, 1068.0], [1068.0, 1084.0], [1084.0, 1113.0], [1113.0, 1128.0], [1128.0, 1141.0], [1141.0, 1162.0], [1162.0, 1172.0], [1172.0, 1186.0], [1186.0, 1197.0], [1197.0, 1207.0], [1207.0, 1220.0], [1220.0, 1232.0], [1232.0, 1249.0], [1249.0, 1262.0], [1262.0, 1272.0], [1272.0, 1283.0], [1283.0, 1297.0], [1297.0, 1333.0], [1333.0, 1346.0], [1346.0, 1356.0], [1356.0, 1369.0], [1369.0, 1385.0], [1385.0, 1396.0], [1396.0, 1415.0], [1415.0, 1425.0], [1425.0, 1436.0], [1436.0, 1447.0], [1447.0, 1463.0], [1463.0, 1477.0], [1477.0, 1488.0], [1488.0, 1503.0], [1503.0, 1515.0], [1515.0, 1531.0], [1531.0, 1544.0], [1544.0, 1556.0], [1556.0, 1566.0], [1566.0, 1576.0], [1576.0, 1586.0], [1586.0, 1599.0], [1599.0, 1614.0], [1614.0, 1624.0], [1624.0, 1648.0], [1648.0, 1658.0], [1658.0, 1669.0], [1669.0, 1679.0], [1679.0, 1689.0], [1689.0, 1705.0], [1705.0, 1715.0], [1715.0, 1726.0], [1726.0, 1738.0], [1738.0, 1764.0], [1764.0, 1775.0], [1775.0, 1785.0], [1785.0, 1800.0], [1800.0, 1814.0], [1814.0, 1825.0], [1825.0, 1835.0], [1835.0, 1845.0], [1845.0, 1859.0], [1859.0, 1869.0], [1869.0, 1882.0], [1882.0, 1896.0], [1896.0, 1906.0], [1906.0, 1918.0], [1918.0, 1932.0], [1932.0, 1943.0], [1943.0, 1953.0], [1953.0, 1965.0], [1965.0, 1975.0], [1975.0, 1988.0], [1988.0, 2000.0], [2000.0, 2010.0], [2010.0, 2021.0], [2021.0, 2035.0], [2035.0, 2049.0], [2049.0, 2063.0], [2063.0, 2074.0], [2074.0, 2084.0], [2084.0, 2096.0], [2096.0, 2113.0], [2113.0, 2124.0], [2124.0, 2135.0], [2135.0, 2147.0], [2147.0, 2160.0], [2160.0, 2171.0], [2171.0, 2182.0], [2182.0, 2195.0], [2195.0, 2206.0], [2206.0, 2217.0], [2217.0, 2233.0], [2233.0, 2244.0], [2244.0, 2261.0], [2261.0, 2273.0], [2273.0, 2287.0], [2287.0, 2298.0], [2298.0, 2310.0], [2310.0, 2322.0], [2322.0, 2332.0], [2332.0, 2350.0], [2350.0, 2383.0], [2383.0, 2393.0], [2393.0, 2404.0], [2404.0, 2415.0], [2415.0, 2426.0], [2426.0, 2445.0], [2445.0, 2455.0], [2455.0, 2468.0], [2468.0, 2478.0], [2478.0, 2490.0], [2490.0, 2500.0], [2500.0, 2510.0], [2510.0, 2520.0], [2520.0, 2534.0], [2534.0, 2544.0], [2544.0, 2554.0], [2554.0, 2570.0], [2570.0, 2582.0], [2582.0, 2596.0], [2596.0, 2606.0], [2606.0, 2631.0], [2631.0, 2641.0], [2641.0, 2652.0], [2652.0, 2663.0], [2663.0, 2678.0], [2678.0, 2693.0], [2693.0, 2706.0], [2706.0, 2718.0], [2718.0, 2728.0], [2728.0, 2741.0], [2741.0, 2752.0], [2752.0, 2769.0], [2769.0, 2779.0], [2779.0, 2782.18]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [291, 670, 947, 1065, 1300, 1742, 2783]}
{"example_id": "mit001@@ocw-18.01-f07-lec18_300k", "text": ["PROFESSOR: So we're going on to the third unit here.  So we're getting started with Unit 3.  And this is our intro to integration. ", "It's basically the second half of calculus after  differentiation. ", "Today what I'll talk about is what are known as  definite integrals. ", "Actually, it looks like, are we missing a bunch  of overhead lights?  Is there a reason for that?  Hmm. ", "Let's see.  Ahh.  Alright.  OK, that's a little brighter now. ", "Alright.  So the idea of definite integrals can be presented  in a number of ways. ", "But I will be consistent with the rest of the  presentation in the course.  We're going to start with the geometric point of view.  And the geometric point of view is, the problem we want to ", "solve us to find the area under a curve. ", "The other point of view that one can take, and we'll mention  that at the end of this lecture, is the idea  of a cumulative sum. ", "So keep that in mind that there's a lot going on here.  And there are many different interpretations of  what the integral is. ", "Now, so let's draw a picture here.  I'll start at a place a and end at a place b.  And I have some curve here.  And what I have in mind is to find this area here. ", "And, of course, in order to do that, I need more information  than just where we start and where we end.  I also need the bottom and the top.  By convention, the bottom is the x axis and the top is the ", "curve that we've specified, which is y = f(x).  And we have a notation for this, which is the notation ", "using calculus for this as opposed to some  geometric notation.  And that's the following expression.  It's called an integral, but now it's going to have what ", "are known as limits on it.  It will start at a and end at b.  And we write in the function f(x) dx.  So this is what's known as a definite integral. ", "And it's interpreted geometrically as the  area under the curve.  The only difference between this collection of symbols  and what we had before with indefinite integrals is that ", "before we didn't specify where it started and where it ended. ", "Now, in order to understand what to do with this guy, I'm  going to just describe very abstractly what we do.  And then carry out one example in detail. ", "So, to compute this area, we're going to follow  initially three steps. ", "First of all, we're going to divide into rectangles.  And unfortunately, because it's impossible to divide a curvy ", "region into rectangles, we're going to cheat.  So they're only quote-unquote rectangles.  They're almost rectangles. ", "And the second thing we're going to do is  to add up the areas.  And the third thing we're going to do is to rectify this ", "problem that we didn't actually hit the answer on the nose.  That we were missing some pieces or were choosing  some extra bits.  And the way we'll rectify that is by taking the limit as ", "the rectangles get thin. ", "Infinitesimally thin, very thin.  Pictorially, again, that looks like this.  We have a and our b, and we have our guy here, ", "this is our curve.  And I'm going to chop it up.  First I'm going to chop up the x axis into little increments. ", "And then I'm going to chop things up here.  And I'll decide on some rectangle, maybe some  staircase pattern here.  Like this. ", "Now, I don't care so much.  In some cases the rectangles overshoot; in some cases  they're underneath.  So the new area that I'm adding up is off. ", "It's not quite the same as the area under the curve.  It's this region here.  But it includes these extra bits here. ", "And then it's missing this little guy here.  This little bit there is missing.  And, as I say, these little pieces up here, this a little ", "bit up here is extra.  So that's why we're not really dividing up the region  into rectangles.  We're just taking rectangles. ", "And then the idea is that as these get thinner and thinner,  the little itty bitty amounts that we miss by are going to 0.  And they're going to be negligible.  Already, you can see it's kind of a thin piece of area, so ", "we're not missing by much.  And as these get thinner and thinner, the problem goes away  and we get the answer on the nose in the limit. ", "So here's our first example.  I'll take the first interesting curve, which is f ( x) = x^2. ", "I don't want to do anything more complicated than one  example, because this is a real labor here, what  we're going to go through.  And to make things easier for myself, I'm going ", "to start at a = 0.  But in order to see what the pattern is, I'm going to  allow b to be arbitrary. ", "Let's draw the graph and start breaking things up.  So here's the parabola, and there's this piece that we  want, which is going to stop at this place, b, here. ", "And the first step is to divide into n pieces. ", "That means, well, graphically, I'll just mark the first three.  And maybe there are going to be many of them.  And then I'll draw some rectangles here, and I'm ", "going to choose to make the rectangles all the  way from the right.  That is, I'll make us this staircase pattern  here, like this. ", "That's my choice.  I get to choose whatever level I want, and I'm going to  choose the right ends as the shape of the staircase.  So I'm overshooting with each rectangle. ", "And now I have to write down formulas for  what these areas are.  Now, there's one big advantage that rectangles have.  And this is the starting place. ", "Which is that it's easy to find their areas.  All you need to know is the base and the height, and you  multiply, and you get the area.  That's the reason why we can get started with rectangles. ", "And in this case, these distances, I'm assuming that  they're all equal, equally spaced, intervals.  And I'll always be doing that. ", "And so the spacing, the bases, the base length,  is always b / n. ", "All equal intervals.  So that's the base length. ", "And next, I need the heights.  And in order to keep track of the heights, I'm going to draw  a little table here, with x and f ( x), and plug in a ", "few values just to see what the pattern is.  The first place here, after 0, is b / n. ", "So here's b / n, that's an x value.  And the f ( x) value is the height there.  And that's just, I value it f(x), f)x) = x^2.  ", "And that's (b / n)^2.   And similarly, the next one is 2b / n. ", "And the value here is (2b / n^2.   That's this.  This height here is 2b / n. ", "That's the second rectangle.  And I'll write down one more.  3b / n, that's the third one. ", "And the height is (3b / n^2.   And so forth. ", "Well, my next job is to add up these areas.  And I've already prepared that by finding out what  the base and the height is. ", "So the total area, or the sum of the areas, let's say, of ", "these rectangles, is - well, the first one is (b  / n) ( b / n)^2. ", " The second one is 2b / n - I'm sorry, is (b / n)( 2b / n)^2.   And it just keeps on going. ", "And the last one is (b / n)( nb / n)^2.  So it's very important to figure out what the  general formula is. ", "And here we have a base.  And here we have a height, and here we have the same kind of  base, but we have a new height.  And so forth. ", "And the pattern is that the coefficient here is 1, then 2,  then 3, all the way up to n. ", "The rectangles are getting taller and taller, and this  one, the last one is the biggest.  OK, this is a very complicated gadget. and the first thing I ", "want to do is simplify it and then I'm actually  going to evaluate it.  But actually I'm not going to evaluate it exactly.  I'm just going to evaluate the limit.  Turns out, limits are always easier. ", "The point about calculus here is that these  rectangles are hard.  But the limiting value is an easy value.  So what we're heading for is the simple formula, as opposed  to the complicated one. ", "Alright, so the first thing I'm going to do is factor  out all these b / n factors.  There's a b / n here, and there's a (b / n)^2.   So all told, we have a (b / n)^3. ", " As a common factor.  And then the first term is 1, and the second term,  what's left over, is 2^2.  ", "2^2.   And then the third term would be 3^2, although  I haven't written it.  In the last term, there's an extra factor of n^2. ", " In the numerator. ", "OK, is everybody with me here?  Now, what I'd like to do is to eventually take the limit ", "as n goes to infinity here.  And the quantity that's hard to understand is this  massive quantity here. ", "And there's one change that I'd like to make, but  it's a very modest one.  Extremely minuscule.  Which is that I'm going to write 1, just to see that ", "there's a general pattern here.  Going to write 1 as 1^2.   And let's put in the 3 here, why not. ", "And now I want to use a trick.  This trick is not completely recommended, but I will say ", "a lot more about that when we get through to the end.  I want to understand how big this quantity is.  So I'm going to use a geometric trick to draw a picture  of this quantity. ", "Namely, I'm going to build a pyramid.  And the base of the pyramid is going to be n by n blocks.  So imagine we're in Egypt and we're building a pyramid. ", "And the next layer is going to be n - 1 by n - 1.  So this next layer in is n minus 1 by n minus 1. ", "So the total number of blocks on the bottom is n squared.  That's this rightmost term here.  But the next term, which I didn't write in but maybe I  should, the next to the last term was this one. ", "And that's the second layer that I've put on.  Now, this is, if you like, the top view.  But perhaps we should also think in terms of a side view. ", "So here's the same picture, we're starting at n and we  build up this layer here.  And now we're going to put a layer on top of it, which ", "is a little shorter.  So the first layer is of length n.  And the second layers is of length n - 1, and then on top  of that we have something of length n - 2, and so forth. ", "And we're going to pile them up.  So we pile them up.  All the way to the top, which is just one  giant block of stone.  And that's this last one, 1^2. ", "So we're going backwards in the sum.  And so I have to build this whole thing up.  And I get all the way up in this staircase pattern to  this top block, up there. ", "So here's the trick that you can use to estimate the size  of this, and it's sufficient in the limit as n  goes to infinity.  The trick is that I can imagine the solid thing underneath ", "the staircase, like this.  That's an ordinary pyramid, not a staircase pyramid.  Which is inside. ", "And this one is inside.  And so, but it's an ordinary pyramid as opposed to  a staircase pyramid.  And so, we know the formula for the volume of that. ", "Because we know the formula for volumes of cones.  And the formula for the volume of this guy, of the inside, ", "is 1/3 base times height.  And in that case, the base here - so that's 1/3, and ", "the base is n by n, right?  So the base is n^2.   That's the base.  And the height, it goes all the way to the top point. ", "So the height is n.  And what we've discovered here is that this whole sum ", "is bigger than 1/3 n^3.  ", "Now, I claimed that - this line, by the way has slope 2.  So you go 1/2 over each time you go up 1.  And that's why you get to the top. ", "On the other hand, I can trap it on the outside, too, by  drawing a parallel line out here.  And this will go down 1/2 more on this side and 1/2 ", "more on the other side.  So the base will be (n + 1) by (n + 1) of this bigger pyramid.  And it'll go up 1 higher. ", "So on the other end, we get that this is less  than 1/3 (n + 1)^3.   Again, (n + 1)^2 ( n + 1) again this is a base times a height. ", "Of this bigger pyramid.  Yes, question.  STUDENT: [INAUDIBLE]  and then equating it to volume. ", "PROFESSOR: The question is, it seems as if I'm adding up areas  and equating it to volume.  But I'm actually creating volumes by making these ", "honest increments here.  That is, the base is n but the height is 1.  Thank you for pointing that out. ", "Each one of these little staircases here has  exactly height 1.  So I'm honestly sticking blocks there.  They're sort of square blocks, and I'm lining them up.  And I'm thinking of n by n cubeds, if you like. ", "Honest cubes, there.  And the height is 1.  And the base is n^2.  ", "Alright, so I claim that I've trapped this guy in between  two quantities here.  And now I'm ready to take the limit. ", "If you look at what our goal is, we want to have an  expression like this.  And I'm going to - this was the massive expression that we had.  And actually, I'm going to write it differently. ", "I'll write it as b^3( 1^2 + 2^2 + n^2 / n^3).   I'm going to combine all the n's together. ", "Alright, so the right thing to do is to divide  what I had up there.  Divide by n^3 in this set of inequalities there. ", "And what I get here is 1/3 < (1 + 2^2 + 3^2 + n^2 / n^3) ", "< 1/3 ( n + 1)^3 / n^3.   And that's 1/3( 1 + (1 / n))^3. ", " And now, I claim we're done.  Because this is 1/3, and the limit, as n goes to infinity, ", "of this quantity here, is easily seen to be, this is, as  n goes to infinity, this goes to 0.  So this also goes to 1/3.  And so our total here, so our total area, under x^2, which ", "we sometimes might write the integral from 0 to b x^2 / dx,  is going to be equal to - well, it's this 1/3 that I've got. ", "But then there was also a b^3 there.  So there's this extra b cubed here.  So it's 1/3 b^3.  That's the result from this whole computation. ", "Yes, question.  STUDENT: [INAUDIBLE]  PROFESSOR: So that was a very good question. ", "The question is, why did we leave the b / n^3  out, for this step.  And a part of the answer is malice aforethought. ", "In other words, we know what we're heading for.  We know, we understand, this quantity.  It's all one thing.  This thing is a sum, which is growing larger and larger. ", "It's not what's called a closed form.  So, the thing that's not known, or not well understood, is how  big is this quantity here.  1^2 + 2^2.  The sum of the squares. ", "Whereas, this is something that's quite easy  to understand.  So we factor it out.  And we analyze carefully the piece which we don't ", "know yet, how big it is.  And we discovered that it's very, very similar to n^3.   But it's more similar to 1/3 n^3.  ", "It's almost identical to 1/3 n^3.   This extra piece here.  So that's what's going on.  And then we match that.  Since this thing is very similar to 1/3 n^3 we ", "cancel the n^3's and we have our result. ", "Let me just mention that although this may seem odd,  in fact this is what you always do if you analyze  these kinds of sum.  You always factor out whatever you can. ", "And then you still are faced with a sum like this.  So this will happen systematically, every time  you're faced with such a sum. ", "OK, now I want to say one more word about notation.  Which is that this notation is an extreme nuisance here. ", "And it's really sort of too large for us to deal with.  And so, mathematicians have a shorthand for it.  Unfortunately, when you actually do a computation, ", "you're going to end up with this collection  of stuff anyway.  But I want to just show you this summation notation in  order to compress it a little bit. ", "The idea of summation notation is the following.  So this thing tends, the ideas are following. ", "I'll illustrate it with an example first.  So, the general notation is the sum of ai, i = 1 to n ", "= a1 + a2 + ... plus an.  So this is the abbreviation.  And this is a capital Sigma. ", "And so, this quantity here, for instance, is (1 / n^3)  the sum i^2, i = 1 to n. ", "So that's what this thing is equal to.  And what we just showed is that that tends to 1/3  as n goes to infinity.  So this is the way the summation notation is used. ", "There's a formula for each of these coefficients, each of  these entries here, or summands.  And then this is just an abbreviation for  what the sum is. ", "And this is the reason why I stuck in that 1^2 at the  beginning, so that you could see that the pattern worked  all the way down to i = 1.  It isn't an exception to the rule. ", "It's the same as all of the others.  Now, over here, in this board, we also had one of these  extremely long sums. ", "And this one can be written in the following way.  And I hope you agree, this is rather hard to scan.  But one way of writing it is, it's the sum from i = 1 to n ", "of, now I have to write down the formula for  the general term.  Which is (b / n)( ib / n)^2.  ", "So that's a way of abbreviating this massive formula into one  which is just a lot shorter.  And now, the manipulation that I performed with it, which is ", "to factor out this (b / n)^3, is something that I'm perfectly  well allowed to do also over here.  This is the distributive law. ", "This, if I factor out b^3 / n^3, I'm left with the sum  i = 1 to n of i^2, right?  So these notations make it a little bit more compact. ", "What we're dealing with.  The conceptual phenomenon is still the same.  And the mess is really still just hiding under the rug. ", "But the notation is at least fits with fewer  symbols, anyway. ", "So let's continue here.  I've giving you one calculation.  And now I want to fit it into a pattern. ", "And here's the thing that I'd like to calculate.  So, first of all let's try the case, so I'm going  to do two more examples. ", "I'll do two more examples, but they're going to  be much, much easier.  And then things are going to get much easier from now on.  So, the second example is going to be the function f(x) = x. ", "If I draw that, that's this function here, that's  the line with slope 1.  And here's b. ", "And so this area here is the same as the area of the  triangle with base b and height b.  So the area is equal to 1/2 b * b, so this is the base. ", "And this is the height.  We also know how to find the area of triangles.  And so, the formula is 1/2 b^2.  ", "And the third example, notice, by the way, I didn't have to do  this elaborate summing to do that, because we happen  to know this area. ", "The third example is going to be even easier. f(x) = 1.  By far the most important example, remarkably, when you ", "get to 18.02 and multivariable calculus, you will  forget this calculation.  Somehow.  And I don't know why, but it happens to everybody.  So, the function is just horizontal, like this. ", "Right?  It's the constant 1.  And if we stop it at b, then the area we're interested in  is just this, from 0 to b. ", "And we know that this is height 1, so this is area,  is base, which is b * 1.  So it's b. ", "Let's look now at the pattern. ", "We're going to look at the pattern of the function, and  it's the area under the curve, which is this, has this ", "elaborate formula in terms of, so this is just the  area under the curve. ", "Between 0 and b.  And we have x^2, which turned out to be b^3 / 3. ", "And we have x, which turned out to be - well, let me write them  over just a bit more to give myself some room. x, which  turns out to be b^2/ 2. ", "And then we have 1, which turned out to be b. ", "So this, I claim, is suggestive.  If you can figure out the pattern, one way of making  it a little clearer is to see that x = x^ 1. ", " And 1 = x ^ 0 .  So this is the case, 0, 1 and 2. ", "And b = b ^ 1 / 1. ", "So, if you want to guess what happens when f(x) = x^3, well ", "if it's 0, you do b ^ 1 / 1.  If it's 1, you do b ^ 2 / 2.  If it's 2, you do b ^ 3 / 3.  So it's reasonable to guess that this should be b ^ 4 / 4. ", "That's a reasonable guess, I would say.  Now, the strange thing is that in history, Archimedes figured ", "out the area under a parabola.  So that was a long time ago.  It was after the pyramids.  And he used, actually, a much more complicated method ", "than I just described here.  And his method, which is just fantastically amazing, was so  brilliant that it may have set back mathematics  by 2,000 years. ", "Because people were so, it was so difficult that people  couldn't see this pattern.  And couldn't see that, actually, these kinds of  calculations are easy.  So they couldn't get to the cubic. ", "And even when they got to the cubic, they were struggling  with everything else.  And it wasn't until calculus fit everything together that  people were able to make serious progress on  calculating these areas. ", "Even though he was the expert on calculating areas and  volumes, for his time.  So this is really a great thing that we now can have easy ", "methods of doing it.  And the main thing that I want to tell you is that's we will  not have to labor to build pyramids to calculate all  of these quantities. ", "We will have a way faster way of doing it.  This is the slow, laborious way.  And we will be able to do it so easily that it will happen as ", "fast as you differentiate.  So that's coming up tomorrow.  But I want you to know that it's going to be.  However, we're going to go through just a little ", "pain before we do it.  And I'll just tell you one more piece of notation here. ", "So you need to have a little practice just to recognize  how much savings we're going to make.  But never again will you have to face elaborate geometric  arguments like this. ", "So let me just add a little bit of notation for  definite integrals. ", "And this goes under the name of Riemann sums.  Named after a mathematician from the 1800s. ", "So this is the general procedure for  definite integrals. ", "We divide it up into pieces.  And how do we do that?  Well, so here's our a and here's our b. ", "And what we're going to do is break it up into little pieces.  And we're going to give a name to the increment.  And we're going to call that delta x. ", "So we divide up into these.  So how many pieces are there?  If there are n pieces, then the general formula is always the ", "delta x is 1 / n times the total length.  So it has to be b - a / n. ", "We will always use these equal increments, although you don't  absolutely have to do it.  We will, for these Riemann sums. ", "And now there's only one bit of flexibility that  we will allow ourselves.  Which is this. ", "We're going to pick any height of f between. ", "In the interval, in each interval.  So what that means is, let me just show it to you ", "on the picture here.  Is, I just pick any value in between, I'll call it  ci, which is in there. ", "And then I go up here.  And I have the level, which is f( ci).  And that's the rectangle that I choose.  In the case that we did, we always chose the right-hand, ", "which turned out to be the largest one.  But I could've chosen some level in between.  Or even the left-hand end.  Which would have meant that the staircase would've  been quite a bit lower. ", "So any of these staircases will work perfectly well.  So that means were picking f ( ci), and that's a height. ", "And now we're just going to add them all up.  And this is the sum of the areas of the rectangles, ", "because this is the height.  And this is the base.  This notation is supposed to be, now, very suggestive of the ", "notation that Leibniz used.  Which is that in the limit, this becomes an integral  from a to b of f(x) dx. ", "And notice that the delta x gets replaced by a dx.  So this is what happens in the limit.  As the rectangles get thin.  So that's as delta x goes to 0. ", "And these gadgets are called Riemann sums.  This is called a Riemann sum. ", "And we already worked out an example.  This very complicated guy was an example of a Riemann sum. ", "So that's a notation.  And we'll give you a chance to get used to it a little more  when we do some numerical work at the end. ", "Now, the last thing for today is, I promised you an example  which was not an area example. ", "I want to be able to show you that integrals can be  interpreted as cumulative sums. ", "Integrals as cumulative sums. ", "So this is just an example.  And, so here's the way it goes. ", "So we're going to consider a function f, we're going to  consider a variable t, which is time.  In years. ", "And we'll consider a function f( t), which  is in dollars per year.  Right, this is a financial example here. ", "That's the unit here, dollars per year.  And this is going to be a borrowing rate. ", "Now, the reason why I want to put units in here is to show  you that there's a good reason for this strange dx, which we ", "append on these integrals.  This notation.  It allows us to change variables, it allows this to  be consistent with units.  And allows us to develop meaningful formulas, which are ", "consistent across the board.  And so I want to emphasize the units in this when I set up  this modeling problem here.  Now, you're borrowing money. ", "Let's say, every day.  So that means delta t = 1/365. ", "That's almost 1 / infinity, from the point of view  of various purposes.  So this is how much you're borrowing.  In each time increment you're borrowing. ", "And let's say that you borrow, your rate varies over the year.  I mean, sometimes you need more money sometimes you need less. ", "Certainly any business would be that way.  And so here you are, you've got your money.  And you're borrowing but the rate is varying.  And so how much did you borrow?  Well, in Day 45, which is 45/365, you borrowed ", "the following amount.  Here was your borrowing rate times this quantity.  So, dollars per year.  And so this is, if you like, I want to emphasize the scaling ", "that comes about here.  You have dollars per year.  And this is this number of years. ", "So that comes out to be in dollars.  This final amount.  This is the amount that you actually borrow.  So you borrow this amount.  And now, if I want to add up how much you get, you've ", "borrowed in the entire year.  That's this sum. i = 1 to 365 of f of, well, it's  (i / 365) delta t. ", "Which I'll just leave as delta t here.  This is total amount borrowed. ", "This is kind of a messy sum.  In fact, your bank probably will keep track of it and  they know how to do that.  But when we're modeling things with strategies, you know,  trading strategies of course, you're really some kind of ", "financial engineer and you want to cleverly optimize  how much you borrow.  And how much you spend, and how much you invest.  This is going to be very, very similar to the integral ", "from 0 to 1 of f (t) dt.  At the scale of 1/35, it's probably, 365, it's probably ", "enough for many purposes.  Now, however, there's another thing that you would  want to model. ", "Which is equally important.  This is how much you borrowed, but there's also how much you  owe the back at the end of the year.  And the amount that you owe the bank at the end of the year, ", "I'm going to do it in a fancy way.  It's, the interest, we'll say, is compounded continuously.  So the interest rate, if you start out with P as your ", "principal, then after time t, you owe, so borrow P, after ", "time t, you owe P e ^ rt, where r is your interest rate. ", "Say, 0.05 per year.  That would be an example of an interest rate. ", "And so, if you want to understand how much money you  actually owe at the end of the year, at the end of the year ", "what you owe is, well, you borrowed these amounts here.  But now you owe more at the end of the year. ", "You owe e ^ r times the amount of time left in the year.  So the amount of time left in the year is 1 - (i / 365). ", "Or 365 - i days left.  So this is (1 - i / 365). ", "And this is what you have to add up, to  see how much you owe.  And that is essentially the integral from 0 to 1. ", "The delta t comes out.  And you have here e ^ r (1 - t), so the t is replacing ", "this i / 365, f (t) dt.  And so when you start computing and thinking about what's the  right strategy, you're faced with integrals of this type. ", "So that's just an example.  And see you next time.  Remember to think about questions that you'll  ask next time.  "], "vid_duration": [16.0, 13.0, 25.0, 11.0, 12.0, 10.0, 11.0, 13.0, 13.0, 11.0, 18.0, 10.0, 12.0, 11.0, 12.0, 12.0, 11.0, 14.0, 10.0, 15.0, 10.0, 16.0, 16.0, 11.0, 11.0, 11.0, 15.0, 11.0, 15.0, 13.0, 10.0, 12.0, 14.0, 14.0, 11.0, 19.0, 13.0, 13.0, 11.0, 10.0, 19.0, 11.0, 12.0, 10.0, 11.0, 10.0, 11.0, 12.0, 10.0, 12.0, 11.0, 11.0, 11.0, 10.0, 11.0, 10.0, 11.0, 11.0, 10.0, 11.0, 14.0, 10.0, 12.0, 10.0, 10.0, 10.0, 16.0, 18.0, 10.0, 10.0, 16.0, 11.0, 10.0, 12.0, 11.0, 14.0, 11.0, 10.0, 10.0, 11.0, 18.0, 18.0, 11.0, 11.0, 13.0, 13.0, 10.0, 13.0, 16.0, 10.0, 14.0, 12.0, 16.0, 14.0, 10.0, 11.0, 12.0, 12.0, 19.0, 11.0, 12.0, 13.0, 10.0, 12.0, 15.0, 24.0, 11.0, 14.0, 11.0, 11.0, 10.0, 11.0, 10.0, 10.0, 11.0, 16.0, 10.0, 11.0, 15.0, 10.0, 14.0, 11.0, 10.0, 18.0, 12.0, 15.0, 10.0, 10.0, 12.0, 13.0, 14.0, 11.0, 11.0, 15.0, 12.0, 14.0, 19.0, 11.0, 17.0, 10.0, 15.0, 13.0, 10.0, 10.0, 13.0, 12.0, 21.0, 10.0, 10.0, 11.0, 13.0, 10.0, 10.0, 13.0, 10.0, 10.0, 16.0, 15.0, 13.0, 10.0, 12.0, 10.0, 10.0, 10.0, 11.0, 10.0, 10.0, 12.0, 17.0, 11.0, 17.0, 17.0, 15.0, 12.0, 10.0, 10.0, 13.0, 12.0, 13.0, 13.0, 10.0, 14.0, 10.0, 12.0, 10.0, 13.0, 13.0, 16.0, 12.0, 11.0, 11.0, 14.0, 16.0, 15.0, 12.0, 11.0, 10.0, 12.0, 11.0, 10.0, 14.0, 10.0, 11.0, 10.0, 26.0, 13.0, 15.0, 17.0, 12.0, 11.0, 11.0, 11.0, 13.0, 10.0, 10.0, 12.0, 12.0, 10.0, 10.0, 13.0, 11.0, 11.0, 11.0, 13.0, 10.0, 15.0, 9.01], "stet": [[0, 16.0], [16.0, 29.0], [29.0, 54.0], [54.0, 65.0], [65.0, 77.0], [77.0, 87.0], [87.0, 98.0], [98.0, 111.0], [111.0, 124.0], [124.0, 135.0], [135.0, 153.0], [153.0, 163.0], [163.0, 175.0], [175.0, 186.0], [186.0, 198.0], [198.0, 210.0], [210.0, 221.0], [221.0, 235.0], [235.0, 245.0], [245.0, 260.0], [260.0, 270.0], [270.0, 286.0], [286.0, 302.0], [302.0, 313.0], [313.0, 324.0], [324.0, 335.0], [335.0, 350.0], [350.0, 361.0], [361.0, 376.0], [376.0, 389.0], [389.0, 399.0], [399.0, 411.0], [411.0, 425.0], [425.0, 439.0], [439.0, 450.0], [450.0, 469.0], [469.0, 482.0], [482.0, 495.0], [495.0, 506.0], [506.0, 516.0], [516.0, 535.0], [535.0, 546.0], [546.0, 558.0], [558.0, 568.0], [568.0, 579.0], [579.0, 589.0], [589.0, 600.0], [600.0, 612.0], [612.0, 622.0], [622.0, 634.0], [634.0, 645.0], [645.0, 656.0], [656.0, 667.0], [667.0, 677.0], [677.0, 688.0], [688.0, 698.0], [698.0, 709.0], [709.0, 720.0], [720.0, 730.0], [730.0, 741.0], [741.0, 755.0], [755.0, 765.0], [765.0, 777.0], [777.0, 787.0], [787.0, 797.0], [797.0, 807.0], [807.0, 823.0], [823.0, 841.0], [841.0, 851.0], [851.0, 861.0], [861.0, 877.0], [877.0, 888.0], [888.0, 898.0], [898.0, 910.0], [910.0, 921.0], [921.0, 935.0], [935.0, 946.0], [946.0, 956.0], [956.0, 966.0], [966.0, 977.0], [977.0, 995.0], [995.0, 1013.0], [1013.0, 1024.0], [1024.0, 1035.0], [1035.0, 1048.0], [1048.0, 1061.0], [1061.0, 1071.0], [1071.0, 1084.0], [1084.0, 1100.0], [1100.0, 1110.0], [1110.0, 1124.0], [1124.0, 1136.0], [1136.0, 1152.0], [1152.0, 1166.0], [1166.0, 1176.0], [1176.0, 1187.0], [1187.0, 1199.0], [1199.0, 1211.0], [1211.0, 1230.0], [1230.0, 1241.0], [1241.0, 1253.0], [1253.0, 1266.0], [1266.0, 1276.0], [1276.0, 1288.0], [1288.0, 1303.0], [1303.0, 1327.0], [1327.0, 1338.0], [1338.0, 1352.0], [1352.0, 1363.0], [1363.0, 1374.0], [1374.0, 1384.0], [1384.0, 1395.0], [1395.0, 1405.0], [1405.0, 1415.0], [1415.0, 1426.0], [1426.0, 1442.0], [1442.0, 1452.0], [1452.0, 1463.0], [1463.0, 1478.0], [1478.0, 1488.0], [1488.0, 1502.0], [1502.0, 1513.0], [1513.0, 1523.0], [1523.0, 1541.0], [1541.0, 1553.0], [1553.0, 1568.0], [1568.0, 1578.0], [1578.0, 1588.0], [1588.0, 1600.0], [1600.0, 1613.0], [1613.0, 1627.0], [1627.0, 1638.0], [1638.0, 1649.0], [1649.0, 1664.0], [1664.0, 1676.0], [1676.0, 1690.0], [1690.0, 1709.0], [1709.0, 1720.0], [1720.0, 1737.0], [1737.0, 1747.0], [1747.0, 1762.0], [1762.0, 1775.0], [1775.0, 1785.0], [1785.0, 1795.0], [1795.0, 1808.0], [1808.0, 1820.0], [1820.0, 1841.0], [1841.0, 1851.0], [1851.0, 1861.0], [1861.0, 1872.0], [1872.0, 1885.0], [1885.0, 1895.0], [1895.0, 1905.0], [1905.0, 1918.0], [1918.0, 1928.0], [1928.0, 1938.0], [1938.0, 1954.0], [1954.0, 1969.0], [1969.0, 1982.0], [1982.0, 1992.0], [1992.0, 2004.0], [2004.0, 2014.0], [2014.0, 2024.0], [2024.0, 2034.0], [2034.0, 2045.0], [2045.0, 2055.0], [2055.0, 2065.0], [2065.0, 2077.0], [2077.0, 2094.0], [2094.0, 2105.0], [2105.0, 2122.0], [2122.0, 2139.0], [2139.0, 2154.0], [2154.0, 2166.0], [2166.0, 2176.0], [2176.0, 2186.0], [2186.0, 2199.0], [2199.0, 2211.0], [2211.0, 2224.0], [2224.0, 2237.0], [2237.0, 2247.0], [2247.0, 2261.0], [2261.0, 2271.0], [2271.0, 2283.0], [2283.0, 2293.0], [2293.0, 2306.0], [2306.0, 2319.0], [2319.0, 2335.0], [2335.0, 2347.0], [2347.0, 2358.0], [2358.0, 2369.0], [2369.0, 2383.0], [2383.0, 2399.0], [2399.0, 2414.0], [2414.0, 2426.0], [2426.0, 2437.0], [2437.0, 2447.0], [2447.0, 2459.0], [2459.0, 2470.0], [2470.0, 2480.0], [2480.0, 2494.0], [2494.0, 2504.0], [2504.0, 2515.0], [2515.0, 2525.0], [2525.0, 2551.0], [2551.0, 2564.0], [2564.0, 2579.0], [2579.0, 2596.0], [2596.0, 2608.0], [2608.0, 2619.0], [2619.0, 2630.0], [2630.0, 2641.0], [2641.0, 2654.0], [2654.0, 2664.0], [2664.0, 2674.0], [2674.0, 2686.0], [2686.0, 2698.0], [2698.0, 2708.0], [2708.0, 2718.0], [2718.0, 2731.0], [2731.0, 2742.0], [2742.0, 2753.0], [2753.0, 2764.0], [2764.0, 2777.0], [2777.0, 2787.0], [2787.0, 2802.0], [2802.0, 2811.01]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [221, 425, 1463, 1690, 1841, 2077, 2370, 2811]}
{"example_id": "mit038@@MIT8_06S18_L19_300k", "text": ["PROFESSOR: Today, we begin with our study of scattering.  And so scattering is the next chapter ", "in our study of approximations.  What is the purpose of scattering?  Physicists want to study the interactions between particles, ", "the forces.  We know, for example, in a hydrogen atom  there is an electromagnetic force within the proton  and the electron.  We understand it rather well. ", "But there are other forces in nature  that we don't understand very well, are harder to understand.  Those at higher energies, the interactions between particles ", "can be rather complicated.  Also, it may happen that you have a situation where there's  a potential affecting particles, maybe a trap or something that ", "holds particles.  And there's a potential.  And you really cannot measure directly this potential.  There's no simple way of doing so.  And then what you do is you send particles in. ", "And you see how they get affected.  And by studying the reflection or the scattering  of the particles off of this potential, ", "you'll learn a lot about what this potential can be.  So this subject today is scattering.  ", "And in general, you have a beam of particles, a target,  and a number of detectors. ", "That's what happens in a big accelerator.  And in general, you have such situations.  OK?  So a beam, some sort of target, and particles get scattered. ", "And you have detectors.   And in general, the detectors are all over in all directions ", "because particles may back scatter,  may go in different ways.  So collisions, in general, are rather intricate. ", "Particles can change identity, can do  all kinds of different things.  For example, you can have a proton colliding with a proton.  This could be the case when the beam is a beam of protons. ", "And here, maybe there's a target in which  you study what happens when a proton encounters a proton.  Or it may be that in some cases there's ", "another beam that is coming also with protons.  And they collide.  But when protons collide with protons,  funny things can happen.  For example, you can get the two protons ", "plus a pion, a neutral pion, 0 denoting zero charge.  That's a hadron, a strongly interacting particle, ", "like the proton is.  It's made of quarks.  And this can happen.  There's no such thing as a conservation  of the number of particles. ", "That is one of the reasons you need quantum field theory to do  this kind of computation.  And this reaction is allowed because it, ", "at least the first thing you can check  is that it conserves charges.  Proton and proton go to proton and proton,  so a charge is conserved.  And pi 0 is neutral. ", "So that, for example, can happen.  Or proton plus proton can go to proton plus neutron. ", "Now, charge is not conserved.  But this time, a positively charged pion called pi plus.  ", "The particles can completely change identity.  You can have an electron and a positron colliding.  So that's electron.  This is the positron, the anti-particle of the electron, ", "equal mass, oppositely charged.  And then they can go into a mu plus plus a mu minus. ", "These are charged laptons.  Again, just like the electrical laptons, as opposed  to these particles here.  They're called hydrons. ", "These particles are, as far as we know, are elementary.  These particles are made out of quarks.  And in this case, you have a complete change of identity. ", "The original particles have disappeared.  And new particles have been created.  And you can look forward to study these processes ", "as you continue your studies of quantum mechanics.  But these are like reactions.  Now, in our name, in our nomenclature for scattering, ", "we will call the process a scattering process  where the identity of the particles is unchanged.  So we will have scattering, strictly ", "speaking, when there is no change of identity ", "in the initial and final states.  No change of identity of the particles in the process ", "of going from initial to final state. ", "So a scattering process looks like a plus b goes to a plus b.  ", "We don't change identity.  Those processes where you change identity are harder to discuss.  And we won't discuss them here. ", "Even here, there is still a lot of things that can happen.  It's very intricate.  So we will demand even more.  We will call or look for elastic scattering. ", "", "And that means that if these particles or objects have  internal states, those internal states are not changed. ", "So the internal states of the particles do not change.  ", "Of course, that can happen essentially  when the particles are complex.  They're bound states of other particles.  So you may have a bound state of one form. ", "And then when you have bound states,  you know you have all kinds of energy levels internal states.  And then when we say we have an elastic process, ", "it means that those internal states are not changed.  A classic example of an inelastic scattering ", "experiment, the most famous historically  of those experiments, is an experiment by Frank and Hertz ", "in 1914.  They were having a chamber with mercury gas.  And they shot electrons from one side to the other. ", "And the electrons and the mercury atoms collided.  And they found that the electrons were slowed down ", "by some quantized amount of energy.  And that was the first evidence that atoms had energy levels. ", "Bohr's theory of atoms had been proposed one year  before that, 1913.  And then, the process in which these electrons hit the atoms ", "and lost energy corresponding to producing transitions  in the atoms.  And that would be an inelastic scattering  because the atom changed its internal state. ", "This is a collision between an electron and an atom,  but the atom has changed internal states.  So we will want to consider cases ", "when we don't change the internal state.  And that will be when we have elastic scattering. ", "So a few more things that we're going to assume as we  do elastic scattering.  We will work without spin.  All we will do in the next lectures, one or two ", "more lectures in this, will be particles without spin.  As we're doing in our course, we also  work in the nonrelativistic approximation. ", "So these are the first things that we will assume.   One, no spin.  ", "This doesn't complicate matters as far  as the scattering is concerned.  It just complicates the algebra and the calculations ", "you have to do because you have more degrees of freedom.  We will be working nonrelativistically.  ", "Moreover, we will assume there are interactions.  There are interactions between the particles  that produce the scattering.  And those interactions are simple enough ", "that they just depend on the difference of position.  So the interaction potentials are ", "of the form v of R1 minus R2.  So processes in which will have two incoming particles ", "and they interact, and they scatter elastically.  And the potential depends on just the difference  of the two positions. ", "Eventually, we will even assume it's only  on the magnitude of these differences  for particular cases.  But if you have a potential like this, ", "like when we were studying with hydrogen  atom for the first time, a potential  that just depends on the differences of positions ", "can be treated in the center of mass frame.  It's a nice frame where you can work on it.  And then you can think of it as a single particle ", "scattering of a potential.  So you translate the Schrodinger equation  into a center of mass degrees of freedom ", "that are generally simple.  And we don't worry about and a relative degree of freedom.  So this can be done here. ", "So this makes a process equivalent to scattering  of a particle of a potential V of r. ", "And that particle has the reduced mass,  just like happened with a hydrogen atom.  The real mass of the equation we solve ", "for showing the Hamiltonian for a hydrogen atom,  the mass that shows up there is the reduced mass,  which is approximately equal to the electron mass. ", "But in general, in this scattering process,  it may be between two identical particles in which case  a reduced mass would be half the mass of the particle. ", "So again, we will work scattering  with energy eigenstates.  You may have studied already in 804 ", "a little bit of problems of scattering off  of rectangular barriers, tunneling, all these things.  And we work with energy eigenstates in those cases. ", "And we will work with energy eigenstates as well here.  Now, in some versions of 804, you discuss a lot wave packets. ", "I used to discuss a lot wave packets.  We would build wave packets and send them in.  And use a transmission on reflection coefficients  to figure out what the wave packets do. ", "And in general, a wave packet is a somewhat more physical way  of thinking of the processes.  Because the energy states, eigenstates, are unnormalizable ", "and don't have a direct interpretation  in terms of particles.  Rigorously speaking, you should always  do things with wave packets.  But the fact is that we all work with energy eigenstates. ", "And most of the times, what happens with wave packets  can be more or less gleaned from what is happening  with energy eigenstates.  So we will not new wave packets here. ", "We will not bother to construct wave packets.  They would not teach us too much at this moment.  So we will work with energy eigenstates. ", "", "OK.  So that's our introduction to the subject.  Now, we have to get going.  We have to explore how to set up this scattering problem. ", "So equations that we need to solve.  Well, what are the equations?  We will have a Hamiltonian, which ", "is p squared over 2m plus a potential v of r.  ", "Need not be yet a central potential.  As usual, we will think of a wave function that  depends on r and t that will be written ", "as a psi that depends on r times e to the minus iet over h bar.  An energy eigenstate. ", "And then the equation that you have to solve,  the time independent the Schrodinger equation, becomes ", "minus h squared over 2m Laplacian  plus v of r acting on psi of r is equal to e psi of r. ", "So these are the equations that you have seen already  endlessly in quantum mechanics.  These are equations we write to get warmed up, ", "and we just repeat for ourselves that we  have a Hamiltonian in the picture where  the particles are scattering off of a central potential. ", "Not a central potential, in fact,  just often of a potential.  Work with energy eigenstates, and these  are going to be the equation for the energy eigenstates. ", "Now, let's write the first picture of the scattering  process as some sort of target here  or potential and particles that come in ", "and scatter off of this potential.  So we're looking for energy eigenstates.  And we will try to identify our energy eigenstates, ", "and what we're going to assume is that this potential  is finite range as well.  Range.  ", "Finite range we can deal with potentials  that fall off relatively fast.  Already, the coolant potential doesn't fall off that fast, ", "but potentials that fall faster and the cooler potentials  are potentials that are just localized,  which is pretty common if you have an atom ", "and you scatter things off of it.  If it's a neutral atom, the potential due to the atom  is zero outside the atom, but as soon as you go inside the atom ", "you start to experience all the electrical forces that  are due to the nucleus and the electrons.  So a finite range potential, and we're ", "going to think of solutions that--  OK, away from the finite range our plane waves,  solutions of constant energy specified ", "with perhaps some momentum, so we will think of e as h  squared k squared over 2m.  ", "This is a way of thinking of the energy of a given energy  eigenstate.  So it's another label for the energy. ", "This one, it looks like I've done something  but I haven't done much except to begin an intuition process  in your head in which somehow these ", "are going to be related to energy eigenstates that  have some momentum as they propagate all over space. ", "So if I write that, I could just simply put  this on the left hand side and get an equation  that is kind of nicer. ", "Minus h squared over 2m Laplacian  squared plus k squared plus v of r psi of r equals zero. ", " OK, it's not really a matter scattering ", "of solving this equation at this moment.  There is infinitely many solutions of this equation,  and most of them may not be relevant for us. ", "We're not trying to find every solution of this equation.  We're trying to find solutions that  have something to do with physics,  and you've done that when you had ", "potentials in one dimension.  And that intuition is going to prove invaluable.  So when you have a potential in one dimension, you didn't say,  OK I'm going to find all the energy eigenstates. ", "You said, let's search for things  that are reasonable and physically motivated,  so you put in a wave that was moving in ", "and you said, OK, this wave is a solution  until it reaches this point where it just stops being  a solution and you need more. ", "If you put in this wave, you will generate a reflected wave  and a transmitted wave. ", "Those two waves are going to be generated,  and then you write an ansatz for this wave,  some coefficient a e to the ikx, b e to the minus ikx, c ", "e to the other, and then you solve your equation.  So we need to do the same thing with this kind of equation ", "and this kind of potential.  We have to set up some sort of situation  where we have the physics intuition of a wave that ", "is coming in and then whatever the system will do to that wave  to upgrade it into a full solution.  ", "So that's what we want to do here in analogy to that thing.  This could be called the incoming wave,  and this whole thing the reflected and the transmitted ", "could be called the scattered wave, the thing that  gets produced by the scattering process.  So if you had that there is lots of solutions of that equation, ", "if v was identical to zero, if you had no potential,  you could have lots of solutions, ", "because in fact if the potential is not zero,  plane waves are always solutions without any potential.  Particles that move as plane waves so if equal ", "zero, plane waves of the form psi equal e to the ikx ", "are solutions with k equal the square root of k dot k. ", " Or with k squared equals k dot k.  ", "Plane waves are always solutions of this equation.   So if plane waves are solutions of this equation for v ", "equal to zero, this is the same thing  as saying here that ae to the ikx ", "is a solution of this equation as long as you  don't hit the potential.   So here, we're going to do something quite similar. ", "We're going to say that we're going to put in an incident  wave function, and I will instead of writing psi, ", "I will call it 5x.  The incident wave function 5x is going to be just e to the ikz.  ", "So it's a wave function.  I call it phi to distinguish it from psi.  Psi in general is a full solution  of the Schrodinger equation. ", "That's our understanding of psi.  So phi, it reminds you that well, it's some wave function.  I'm not sure it's a solution.  In fact, it probably is not the solution as soon ", "as you have the potential different from zero.  So is this common, we forget that ksv equals zero,  and now we put an incident wave function which is of this form. ", "This solves the equation as long as you're away  from the potential.  This is true, it's a solution of the Schrodinger equation ", "away from v of r.  Away from v of r means wherever v of r is equal zero, ", "you have a solution.  Nevertheless, so if we call the range of the potential--  let's call the range of the potential finite range a-- ", " that is to take that if there is an origin here  up to a radius a, there is some potential and beyond the radius ", "a the potential vanishes.  So this definitely works.  It's all ks away from vr or as long as r is greater than a ", "for whatever value of z you take.  This is fine, so here is our wave, ", "and now this is just the incident wave.  This is not going to be the whole solution.  Just like in the one dimensional case, there must be more. ", "So what is there more?  And our challenge to begin with this problem  is to set up what else could there be. ", "So looking at it, you'd say, all right.  So the thing comes in.  If there is scattering, particles ", "are sometimes going to go off in various directions.  So the outgoing wave, here there were outgoing waves  reflected and transmitted. ", "The outgoing wave in the three dimensional scattering problem  should be some sort of spherical wave moving away from r ", "equals zero, which is the origin.  That should be the other wave that I would write.  So my ansatz should be that there ", "is some sort of spherical wave that is moving away.  So to complete this with a spherical outgoing wave. ", " So while here this is a plane wave moving ", "in the direction of the vector k,  if I want to write the spherical wave, I would write e to the i  just kr. ", " E to the ikr is spherically symmetric,  and it propagates radiantly out. ", "If you remember as usual that you  have e to the minus iet over h bar, so you have kr minus et,  that is a wave that propagates radially out. ", "So maybe this is kind of the scattered wave.  This e to the ikr moving out everywhere ", "would be your scattered wave.   If that is the scattered wave, remember ", "the scattered wave should solve the Schrodinger equation.  In fact, the sum of these two should  solve the scattering equation.  On the other hand, we've seen that this ", "solves it as long as you're away from the potential,  and therefore this should also solve it  if you're away from the potential.  ", "So I ask you, do you think this solves the Schrodinger equation  when you're away from the potential?  ", "Would e to the ikr solve the equation?  Well for that, you would need that if you're away  from the potential, do you have Laplacian of e ", "to the ikr roughly equals zero?   Is that true?  ", "Would it solve it.  No.  It doesn't solve it.  Doesn't even come close to solving it.  It's pretty bad, but the reason it's bad is physically clear. ", "This wave as it expands out must become weaker and weaker  so that the probability flux remains constant. ", "You know, you don't want an accumulation  of probability between a shell at one kilometer and a shell  at two kilometers.  So whatever flux is going out from the shell in one kilometer ", "should be going out of the bigger shell.  So therefore, it should fall off with r.  Oh, I'm sorry.  I didn't write this well. ", "So if you are going to have this to be  a solution of the Schrodinger equation outside of vr  equals zero, you should have Laplacian k squared ", "of this thing equal to zero.  So if this is equal to zero and the potential is equal to zero,  the whole thing is equal to zero.  So we need this to hold. ", "But even this one, of course, is not true.  It is just absolutely not true.  The one that works is the following.  ", "Laplacian plus k squared of e to the ikr over r ", "is equal to zero for r different from zero.  This is a computation I think you guys have  done before when you were studying ", "the Hermiticity of p squared.  You ended up doing this kind of things.  This Laplacian produces a delta function at r equals zero, ", "but r equals zero is not the place we're interested in.  We're trying to find how the waves look away  from the scattering center. ", "So we need this to hold away from r  equals zero, in fact, bigger for r bigger than a.  One way of checking this kind of thing ", "is to remember that the Laplacian of a function of r  is in fact one over r d second dr squared r times f. ", "That's a neat formula for the Laplacian of a function that  just depends on r.  If it depends on theta and phi, it's more complicated.  But with this function, it becomes a one line calculation ", "to do this, and the r here is just fantastic,  because by the time you multiply by r this function is  just exponential.  You take two derivatives, you get minus k squared, ", "and then the r gets canceled as well  and everything works beautifully here.  And so this equation holds OK. ", "And then we do have a possible scattered wave.  So we're almost there.  We can write the scattering wave size scattering ", "of x could be e to the ikr over r and then leave it at that. ", "But this would not be general enough.  There is no reason why this wave would not  depend also on theta and phi. ", " Here is the z direction, and there's  points with angle theta, and if you rotate it with some angle ", "phi here, and therefore this function could as well  depend on theta and phi.  So we'll include that factor f of theta and phi. ", " Now you would say, look, you have  a nice solution of the Schrodinger equation ", "already here, and what should you be doing?  Why do you add this factor? ", "With this factor, it may not be anymore a solution  of the Schrodinger equation.  The Schrodinger equation is going to have a Laplacian  and it's going to be more complicated. ", "Well, this is true and we will see that better soon,  but this will remain an approximate solution  for r much bigger than a is the leading term of the solution, ", "leaving term of the solution.  ", "So if you have a leading term of a solution here,  this is all you want.  You are working at r much bigger than a, and your whole wave ", "and finally be written.  So your full wave psi, or your full energy eigenstates psi  of rt, is going to be equal, approximately ", "equal to e to the ik--  well, I'll write it this way.  Phi of r, that incident wave we wrote-- ", "I wrote if x there, I'm sorry.  Plus psi scattering of--  I should decide x or r. ", "Let's call this r.  And I should call this r.  ", "Psi of r plus psi scattering of r,  and it's therefore equal to e to the ikz plus f of theta phi e ", "to the ikr over r, and this is only valid for r much bigger  than a. ", "Far away.  This had an analog in our problem in one dimension.  In one dimension, you set up a wave and you put here the wave ", "and there is a reflected wave, and there's a transmitted wave,  and in setting the problem, say this is valid far to the left,  far to the left meaning at least to the left of the barrier, ", "this is valid to the right.  And these were exact solutions in this region here.  You can't do that well, but you can do reasonably well, ", "you can write solutions that are leading term accurate  as long as you are far away. ", "So this is the first step in this whole process in which we  are setting up the wave functions that ", "is the most important equation.  This is the way we're going to try to find solutions.   Now, when you try to find solutions ", "at the end of the day, you will have  to work in the region r going to zero.  So sooner or later we'll get there. ", "But for the time being, we have all the information  about what's going on far away, and from there we  can get most of what we need. ", "In particular, this f of theta and phi  is the quantity we need to figure out.  This f of theta and phi is called ", "the scattering amplitude.  F of theta and phi called scattering amplitude. ", " PROFESSOR: OK.  So we have set up the problem.  ", "We now have to understand what is the physics  of this f of theta and phi.  In a way, solving this scattering problem  means solving for the thetas and phis. ", "Now, you would say, OK, that seems reasonable.  You know how the solution looks far away?  And that's where you're going to do the measurements.  That's where you have the detectors. ", "So we have to find what f of theta and phi is.  But suppose you had it.  What have you learned if you have the f of theta and phi? ", "So this is what we need to compute,  and we will build towards the computation of this using  what is called partial waves-- ", "waves and phase shifts.   This will allow us to calculate the f of theta and phi. ", "But doesn't tell you yet what f of theta and phi is.  So the nice thing of this f of theta and phi  is that it gives you the cross section of the process. ", "So we need to understand what is the cross section.  So what is a cross section?  It's a way to quantify the effect of the scattering ", "center on the particles.  Suppose you have your scattering center  and you shoot particles in.  Then you can say, OK, let me-- ", "let's see with my detectors how many particles go off  at an angle theta?  When you say three particles per second, ", "I'm finding as you should in particles,  I'm getting three particles per second  in this detector at this angle.  My detector at this angle covers a solid angle of 100, ", "and it's getting three particles per second.  Then you can say, OK, what is the area of a target that ", "out of the incoming beam captures  three particles per second?  And maybe-- there are lots of particles coming in,  but if you produce some area, that area ", "will capture three particles per second.  And that would be what we call the differential cross section.  The value of the area that captures or just ", "whose flux of particles is precisely what you're  getting out there.  So if you're looking at some process in which there's  this incoming particles and you look at some angle-- ", "d omega-- where there's a detector,  a detector that capture this angle,  you can associate to this object and d sigma-- ", "which is a differential cross section--  with units of area.   And the physical interpretation of the d sigma for this-- ", "the omega-- is that sigma is the area that  captures the amount of flux that you ", "see going in this direction.  So it's a way this area--  this differential cross sections-- give you ", "an iv, or a concrete representation,  of how big the target is as seen by the particles that  are coming in. ", "I'll write it in a way that makes it clear.  So d sigma, which is called the differential cross section-- ", "differential cross section-- is equal number of particles-- ", "there's lots of words here, but it's good to write them--  scattered per unit time into the solid angle-- ", "d omega-- divided by the flux of incident particles, which ", "is equal to the number of particles  per unit area per unit time. ", "So it's this ratio.  Number of particles scattered per unit time  into solid angle, d omega--  particles have no units. ", "Integers scatter per unit time is 1 over time  into the solid angle-- d omega has no units, either.  The solid angle floods of incident particles is-- ", "particles that has no units over area over time.  So here you had over time, here over time, they cancel,  this is 1 over area.  That ratio, therefore, has units of area. ", "And this is what I was telling you.  The differential cross section, which  is an area, multiplied by the flux,  gives you the number of particles per unit time ", "that are crossing at differential cross section  area.  And those are set equal to the number  of particles per unit time that end up within this solid angle. ", "So for a given little solid angle,  you get the d sigma, which is small, as well.  That's why it's called differential cross section. ", "So let's try to show that this d sigma is really determined  by f of theta and phi.  This angle-- solid angle, d omega-- ", "is happening at some theta and some phi.  That's a position, the center of the little solid angle.  A solid angle, d omega, at theta phi. ", " So this is our goal now, to just calculate  the differential cross section.  OK. ", "So we have to compute this fluxes.  We can do it here.  Now, we're not working with wave pockets.  We're working with energy eigenstates, ", "and we're going to have a little bit of a fun intuition.  We're not-- we're going to get it right,  but you have to appreciate it's a little funny.  If I have a little volume, and I say ", "that I find the probability to find the particle there  to be 1/2, I would say that there's  a half of a particle in that little volume. ", "If I have a volume that whose probability  to find a particle is 1, I say, OK, I have 1 particle in here.  That's the rough intuition. ", "So for wave functions that are not normalizable,  it's almost like--  suppose size squared is equal to 1.  In a momentum, I can say you would ", "be saying like you have a particle for every unit volume  where size squared integrates to 1.  So that's roughly the intuition.  And it's correct, really, to use it there. ", "If you think of the flux of incident particles--  so incident flux--   flux-- we think of it as the probability current, ", "which is number of particles per unit time per unit area.  So it's h bar over m, imaginary part of the incident flux. ", "So I should use the incident wave function, this phi  of r, gradient phi of r.  ", "And phi was e to the ikz.  That was the incident particle. ", "So this Laplacian gives you-- not Laplacian--  this gradient takes a gradient, it produces an ik,  the rest gets canceled, and the imaginary part gives you k. ", "So this is h bar k over m times the unit vector z.  So that's the incident flux. ", "This can be thought as the number of particles per unit  area and per unit time.  You can also think of it intuitively ", "as rho times v. The incident flux  is like the incident current, the current density,  it's rho times v. rho is phi squared-- ", " phi squared.  But that's equal to 1.  ", "And the velocity of the particles  is the momentum over the mass.  But that's hk over m. ", "And if I put the direction, I will have to put the z.   So it's kind of the same thing, rho v,  the incident flux are all there. ", "So this is the denominator of that big formula  we have there--  the incident flux.   Then we need the number of particles ", "scattered per unit time.  We could do it with a flux calculation.  Also, in spherical coordinates, but I can also ", "do it intuitively.  So I'll do it intuitively.  You can try doing it using a probability current.  ", "So intuitively what do we have?  We have a d omega here.  And let's consider a little volume element here. ", " So a little volume element. ", "Here you have r--  distance r-- a little vr.  So a small volume element here. ", "And let's calculate how many particles there are  in this small little element.  So dn is number of particles in the little volume-- ", " volume.   So I must square the wave function ", "and multiply by the volume.  That's what you would do.  So what is the square of the wave function?  Now, we are talking about the scattered wave function. ", "So I must take this part of the wave function  and square it and multiply by the volume. ", "So we will have f of theta and phi times  e to the ikr over r, all squared.  So that's the wave function squared. ", "That's psi carat squared times the air-- volume of this pill  box is r squared d omega times dr. ", "r squared d omega is the surface area of that little box.  dr is the little length there.  And, therefore, we have that volume over there. ", "So things simplify the n is equal,  therefore, the r squared cancels,  and it's just f of theta phi squared, d omega, dr. ", "So with all these particles-- this ", "is the number of particles inside the box.  But all these particles will go through  in a little time dt, which is equal to dr over the velocity. ", "This is the time to go through the box--   through the box. ", "dt is dr over the velocity.  And the velocity is hk over m.  So dr times the momentum over the mass, which is hk over m. ", " OK.  So we have dn, dt.  This is number of particles.  We divide them to form number of particles per unit time. ", "So the ratio dn dt is the numerator of this quantity  here-- ", "is numerator dn [? dt. ?]  And what do we get? ", "The dr cancels and we're dividing the ndt--  this factor goes into the numerator, ", "so we get h bar k over m f of theta phi squared d omega.  ", "So this is the numerator of that equation for the d sigma.  So let's compute-- finish that.  We finally-- I'm going to get off our identification. ", " And what do we get? ", " We get d sigma is the numerator there, ", "which is this quantity, h bar k over m f of theta phi  squared times d omega over h bar k over m, which is nice. ", "That all going to cancel.  And then we get the nice formula that we were after.  This differential cross section is just ", "determined by the function f of theta phi  that we need to calculate.  f of theta phi is our goal.  If we have it, we have the differential cross section. ", "Many people write this formula this way--  d sigma, d omega is equal to f of theta phi. ", " I think that's OK. ", "I think in many ways this is a little clearer.  This small little area associated  to a small little angle is given by that.  This is a ratio of differentials more than a derivative. ", "A derivative with respect to solid angle  doesn't mean too much, I think.  So-- but this is another way people write it. ", "And, finally, people integrate this total cross  section is the integral of the differential  cross section over-- ", "looking at all solid angles.  So this means integrating f of theta phi squared d omega. ", "And that's the total cross section.  ", "OK.   So we've set up the problem.  We-- what are the main things that we've learned? ", "We have the scattering center.  We have our physical condition of a wave coming in.  Our physical condition that the wave comes out. ", "Those are represented here.  And this situation is saying that this  is an approximate solution for a wave--  a wave coming out modulated by a theta and phi dependence ", "and your incoming wave.  This modulation is the thing that captures the effect  of the potential and associates to the strength of this ", "potential and its ability to scatter a differ--  a cross section, which is measurable--  which means a probability of interaction--  capture the probability of interaction. ", "This cross sections are very important.  When you design an experiment with an accelerator,  you want to have a cross section is sufficiently large,  because this cross section is going to tell you ", "how many particles your detector is going to get.  Whether with the flux that you have,  with the beam intensity that you have,  you're going to get one Higgs a day, or 500 Higgs's a day. ", "And it made a difference for the LHC.  It began with a few Higgs's a day,  and later, it's getting a few hundred Higgs's a day.  So I will begin with phase shifts ", "and do the introduction of how to make sure we can really--  so this is the important part of this. ", "Just like when we added the reflected and transmitted wave  we could find the solution I'm going  to try to explain why with this things ", "we can find solutions in general.   So this is the subject of partial waves, ", "and it's a nice subject, a little technical.  There might seem to be a lot of formulas here, ", "but the ideas are relatively simple once one keeps in mind  the one dimensional analogies.  The one dimensional analogies are very valuable here, ", "and we will emphasize them a lot.  So we will discuss partial waves and face shifts.  ", "So it's time to simplify this matters a little bit.   And to do that I will assume from now ", "on that the potential is central so v of r is equal to v of r. ", "That will simplify the azimuthal dependence.  There will be no azimuthal dependencies.  You see, the thing is spherical is symmetric, ", "but still you're coming from a particular direction, the z.  So you can expect now that the scatter wave depends  on the angle of the particle with respect ", "to z because it's spherically symmetrical.  But it shouldn't depend on five, the angle five,  should just depend on theta.  So expect f of theta. ", " Now, a free particle is something ", "we all know how to solve, e to the ikx.  Why do we bother with the free particle in so many ways?  Because free particle is very important. ", "Part of the solution is free particles.  To some degree far away it is free particles as well.  And we need to understand free particles  in spherical coordinates. ", "So it's something we've done in 805 and sometimes in 804,  and we look at the radial equation which ", "is associated to spherical coordinates  for a free particle.  So we'll consider free particle and we'd say, well, ", "that's very simple but it's not all that  simple in spherical coordinates, and you'd say, OK,  if it's not simple, it's spherical coordinates,  why do we bother?  We bother because scattering is happening ", "in spherical coordinates.  So we can't escape having to do the free particle  in spherical coordinates.  It is something you have to do.  So what are solutions in spherical coordinates? ", "We'll have solution SI of r.  Remember the language with coordinates  was a U of r divided by r and of Ylm of omega. ", "That was a typical solution, a single solution of the showing  our equation will--  the U only depends on l, the m disappears, so this is r. ", "This r's are r's without the vector because you're already  talking about the radial equations,  and depend on the energy and depend ", "on the value of the l quantum number.  So what is the Schrodinger equation?  The radial equation is minus h squared over 2m, ", "the second the r squared plus.  h squared over 2m l times l plus 1 over r squared. ", "Remember the potential centrifugal barrier  in the effective potential, then you would have v of r here,  but it's free particle, so v of r is equal to 0. ", "So if nothing else, U of El of little r  is equal to the energy, which is h  squared k squared over 2m UEl. ", "And that's a parliamentary session  of the energy in terms of the k squared, like that. ", " Well, there's lots of h squared, k squared,  and 2m's, so we can get rid of them. ", "Cancel the h squared over 2m.  You get minus d second dr squared plus l times l  plus 1 over r. ", "UEl is equal to k squared UEl.  ", "It's a nice equation.  It's the equation of the free particle  in spherical coordinates.  Now, this is like the Schrodinger equation. ", " And I think when you look at that you could get puzzled ", "whether or not the value of k squared or the energy  might end up being quantized.  With the Schrodinger equation many times ", "quantized is the energy, but here it shouldn't happen.  This is a free particle.  All values of k should be allowed,  so there should be no quantization. ", "This is an r squared here.   You can see one reason, at least analytically, ", "that there is no quantization is that you can define  a new variable row equal kr and then ", "this whole differential equation becomes  minus the second the row squared plus l times l  plus 1 over row squared. ", " Well, I can put the other number in there as well,  or should I not?  No, it's not done here.  UEl is equal to UEl, and the k squared disappeared completely. ", "That tells you that the case will kind of get quantized.  If there is a solution of this differential equation  it holds for all values of k. ", "And these are going to be like plane waves,  and maybe that's another reason you  can think that k doesn't get quantized  because these solutions are not normalizable anyway, ", "so it shouldn't get quantized.  So with this equation in here we get the two main solutions. ", "The solutions of this differential equation  are vessel functions, spherical vessel functions.  UEl is equal to a constant Al times row times the vessel ", "function lowercase j of row.  There's a row times that function.  That's the way it shows up. ", "It's kind of interesting.  It's because in fact you have to divide U by r,  so that would mean dividing U by row,  and it means that the radial function is just the vessel ", "function without anything else.  And then there's the other vessel function,  the n of l a row times of n of l of row. ", " So those are spherical vessel functions.  As you're familiar from the notation ", "that j is the one that this healthy at row  equals 0 doesn't diverge the n is the solution  that diverges at the origin. ", "And both of them behave nicely far away.  So Jl of x goes like 1 over x sine of x minus l pi over 2, ", "and ADA l of x behaves like minus 1  over x cosine of x minus l pi over 2. ", "This is for x big, x much greater than 1,  you have this behavior.  ", "So these are our solutions, and here is  the thing that we have to do.  We have to rewrite our solutions in terms of spherical waves ", "because this was the spherical wave so we should even write  this part as a spherical wave.  And this is a very interesting and in some way ", "strange representation of E to the ikz You have E to the ikz  that you have an intuition for it ", "as a plane wave in the z direction  represent it as an infinite sum of incoming and outgoing  spherical waves.  That's what's going to happen. ", " So this is the last thing we need do here. ", " We have that e to the ikz is a plane wave solution, ", "so it's a solution of a free particle,  so I should be able to write the superpositions of the solutions  that we have found. ", "So it should be a superposition of solutions of this type.  So it could be a sum of coefficients al times, ", "well, alm you think of some a's times solutions.  Remember, we're writing a full solution, ", "so a full solution you divide by r.  So you divide by this quantity.  So you could have an alm Jl of row ", "plus Blm ATA l of row times Ylm.  ", "So this should be a general solution,  and that would be a sum over l's and m's of all  those quantities.  But that's a lot more than what you need. ", "First, this does not diverge near r equals 0.  It has no divergence anywhere and the ATAs or the n's, I ", "think they're n such and not ATAs, the n's diverge for row  equal to 0.  So none of this are necessary, so I can erase those. ", " l and m.  But there is more.  This function is invariant and there ", "are some beautiful rotations.  If you have your axis here, here's the z,  and you have a point here and you rotate that the value of z ", "doesn't change.  It's independent of phi for a given theta,  z just depends on r of cosine theta.  So there's no phi dependence but all the Ylm's with m ", "difference from 0 have phi dependent.  So m cannot be here either.  m must be 0.  So you must be down to sum over l, ", "al some coefficient, Jl of row, Yl0.  ", "And all of those would be perfectly good plane wave  solutions.  Whatever numbers you choose for the little al's, ", "those are good solutions because we've build them  by taking linear combinations of exact solutions  of this equation. ", "But to represent this quantity the al's  must take particular values.  So what is that formula?  That formula is quite famous, and perhaps even you ", "could discuss this in recitation.  e to the ikz, which is e to the ikr cosine theta, ", "is the sum 4 pi.  Now you have to get all the constants right.  Square root of 4 pi, sum from l equals 0  to infinity, square root of 2l plus 1. ", "Coefficients are pretty funny.  They get worse very fast.  Now you have of i to the I, i to the l, Yl0 of theta ", "doesn't depend on phi, Jl of kr.  ", "This is the expansion that we need.  There's no way we can make problems with this problem  unless we have this expansion.  But now if Y the intuition that I was telling you ", "of these waves coming in and out,  well, you have e to the ikz, you sum an infinite sum  over partial waves. ", "A partial wave is a different value of l.  These are partial waves.  As I was saying, any solution is a sum of partial waves ", "is a sum over l.  And where are the waves?  Well, the Jl of kr far away is a sine, and the sine of x ", "is an exponential ix minus e to the minus ix over 2.  So here you have exponentials of e to the ikr ", "and exponentials of e to the minus ikr,  which are waves that are here like outgoing waves  and incoming waves. ", "So the E to the ikz's are sum of ingoing and outgoing spherical  waves.  And that's an intuition that we will exploit very clearly ", "to solve this problem.  So we will do that next. "], "vid_duration": [10.58, 12.03, 11.46, 12.42, 13.53, 12.99, 10.65, 18.16, 10.88, 23.13, 13.03, 10.71, 14.13, 11.52, 13.47, 12.46, 10.25, 10.98, 10.98, 10.62, 11.81, 13.05, 10.47, 10.76, 12.6, 11.1, 14.92, 14.33, 14.14, 17.05, 10.93, 12.15, 11.07, 14.13, 11.06, 12.15, 18.68, 11.72, 11.65, 11.21, 10.74, 12.9, 12.06, 10.99, 11.39, 12.9, 11.34, 10.09, 14.67, 11.31, 12.81, 10.03, 19.73, 11.01, 13.07, 10.58, 12.22, 10.5, 10.29, 10.95, 12.27, 10.96, 19.36, 10.26, 11.4, 10.52, 13.47, 11.91, 12.33, 11.46, 10.95, 13.95, 11.08, 10.66, 13.963, 15.86, 10.049, 10.291, 12.86, 11.44, 12.07, 21.159, 11.49, 11.411, 11.28, 15.9, 16.59, 12.14, 10.1, 10.79, 10.34, 12.44, 10.769, 13.431, 10.42, 10.4, 12.21, 10.76, 18.88, 21.69, 12.48, 11.46, 11.46, 12.21, 10.47, 11.05, 13.85, 11.94, 10.23, 11.3, 10.88, 15.0, 11.58, 12.18, 13.149, 14.77, 16.23, 12.431, 10.549, 11.321, 18.01, 16.07, 12.159, 13.161, 13.74, 17.01, 11.5, 10.38, 12.189, 20.431, 10.69, 10.21, 10.84, 10.68, 11.51, 10.02, 11.349, 19.491, 11.16, 10.139, 11.221, 14.45, 12.47, 10.64, 10.56, 13.06, 10.69, 12.11, 18.299, 13.44, 11.731, 12.47, 12.13, 14.93, 10.779, 12.661, 10.638, 12.062, 10.469, 11.561, 14.21, 15.66, 13.44, 15.089, 13.951, 19.78, 15.92, 10.8, 11.18, 17.14, 12.5, 10.93, 11.02, 15.65, 16.16, 13.42, 13.11, 12.3, 12.64, 11.506, 13.634, 10.23, 15.169, 12.671, 11.94, 10.9, 11.46, 11.81, 10.77, 10.949, 13.801, 10.88, 11.62, 15.65, 10.74, 12.33, 13.56, 10.51, 13.71, 13.14, 11.85, 11.67, 16.25, 10.23, 13.32, 14.64, 14.4, 13.03, 12.49, 10.53, 10.58, 11.07, 10.334, 10.976, 19.11, 17.395, 10.395, 11.97, 13.74, 13.3, 12.26, 12.0, 12.88, 15.58, 14.04, 10.52, 12.19, 12.83, 10.35, 11.37, 10.59, 13.89, 15.53, 11.73, 14.75, 10.47, 13.62, 12.02, 10.32, 12.485, 10.585, 11.53, 11.84, 14.36, 13.14, 11.94, 10.5, 11.5, 11.2, 13.1, 10.21, 12.92, 12.1, 13.01, 14.385, 12.745, 17.31, 12.32, 15.43, 12.58, 12.42, 13.35, 12.14, 10.94, 10.16, 16.53, 12.942, 11.198, 17.08, 19.57, 16.11, 13.05, 10.294, 11.306, 14.495, 11.545, 11.34, 12.79, 15.38, 13.09, 11.61, 15.3, 15.36, 12.87, 12.36, 14.78, 15.58, 10.65, 11.31, 10.08, 11.64, 13.47, 31.59, 11.01, 12.28, 10.38, 12.33, 16.17, 10.72, 13.47, 12.64, 11.03, 10.83, 11.85, 12.3, 14.16, 14.37, 11.61, 12.37, 10.6, 13.3, 15.33, 10.75, 11.11, 12.12, 12.51, 10.36, 12.97, 11.31, 11.55, 10.41, 10.98, 13.67, 21.849, 10.621, 12.0, 12.548, 16.892, 12.41, 12.75, 14.69, 10.46, 11.19, 19.41, 13.21, 15.7, 15.76, 11.64, 10.11, 10.59, 10.655, 16.175, 10.77, 21.54, 12.13, 14.03, 11.09, 12.15, 13.06, 12.14, 15.03, 10.5, 12.73, 11.09, 16.58, 10.29, 10.14, 15.18, 12.63, 15.66, 18.35, 10.23, 13.23, 10.38, 10.11, 15.839, 10.681, 11.11, 10.43, 2.747], "stet": [[0, 10.58], [10.58, 22.61], [22.61, 34.07], [34.07, 46.49], [46.49, 60.02], [60.02, 73.01], [73.01, 83.66000000000001], [83.66000000000001, 101.82000000000001], [101.82000000000001, 112.7], [112.7, 135.83], [135.83, 148.86], [148.86, 159.57000000000002], [159.57000000000002, 173.70000000000002], [173.70000000000002, 185.22000000000003], [185.22000000000003, 198.69000000000003], [198.69000000000003, 211.15000000000003], [211.15000000000003, 221.40000000000003], [221.40000000000003, 232.38000000000002], [232.38000000000002, 243.36], [243.36, 253.98000000000002], [253.98000000000002, 265.79], [265.79, 278.84000000000003], [278.84000000000003, 289.31000000000006], [289.31000000000006, 300.07000000000005], [300.07000000000005, 312.6700000000001], [312.6700000000001, 323.7700000000001], [323.7700000000001, 338.6900000000001], [338.6900000000001, 353.0200000000001], [353.0200000000001, 367.1600000000001], [367.1600000000001, 384.2100000000001], [384.2100000000001, 395.1400000000001], [395.1400000000001, 407.2900000000001], [407.2900000000001, 418.36000000000007], [418.36000000000007, 432.49000000000007], [432.49000000000007, 443.55000000000007], [443.55000000000007, 455.70000000000005], [455.70000000000005, 474.38000000000005], [474.38000000000005, 486.1000000000001], [486.1000000000001, 497.75000000000006], [497.75000000000006, 508.96000000000004], [508.96000000000004, 519.7], [519.7, 532.6], [532.6, 544.66], [544.66, 555.65], [555.65, 567.04], [567.04, 579.9399999999999], [579.9399999999999, 591.28], [591.28, 601.37], [601.37, 616.04], [616.04, 627.3499999999999], [627.3499999999999, 640.1599999999999], [640.1599999999999, 650.1899999999998], [650.1899999999998, 669.9199999999998], [669.9199999999998, 680.9299999999998], [680.9299999999998, 693.9999999999999], [693.9999999999999, 704.5799999999999], [704.5799999999999, 716.8], [716.8, 727.3], [727.3, 737.5899999999999], [737.5899999999999, 748.54], [748.54, 760.81], [760.81, 771.77], [771.77, 791.13], [791.13, 801.39], [801.39, 812.79], [812.79, 823.31], [823.31, 836.78], [836.78, 848.6899999999999], [848.6899999999999, 861.02], [861.02, 872.48], [872.48, 883.4300000000001], [883.4300000000001, 897.3800000000001], [897.3800000000001, 908.4600000000002], [908.4600000000002, 919.1200000000001], [919.1200000000001, 933.0830000000001], [933.0830000000001, 948.9430000000001], [948.9430000000001, 958.9920000000001], [958.9920000000001, 969.2830000000001], [969.2830000000001, 982.1430000000001], [982.1430000000001, 993.5830000000002], [993.5830000000002, 1005.6530000000002], [1005.6530000000002, 1026.8120000000004], [1026.8120000000004, 1038.3020000000004], [1038.3020000000004, 1049.7130000000004], [1049.7130000000004, 1060.9930000000004], [1060.9930000000004, 1076.8930000000005], [1076.8930000000005, 1093.4830000000004], [1093.4830000000004, 1105.6230000000005], [1105.6230000000005, 1115.7230000000004], [1115.7230000000004, 1126.5130000000004], [1126.5130000000004, 1136.8530000000003], [1136.8530000000003, 1149.2930000000003], [1149.2930000000003, 1160.0620000000004], [1160.0620000000004, 1173.4930000000004], [1173.4930000000004, 1183.9130000000005], [1183.9130000000005, 1194.3130000000006], [1194.3130000000006, 1206.5230000000006], [1206.5230000000006, 1217.2830000000006], [1217.2830000000006, 1236.1630000000007], [1236.1630000000007, 1257.8530000000007], [1257.8530000000007, 1270.3330000000008], [1270.3330000000008, 1281.7930000000008], [1281.7930000000008, 1293.2530000000008], [1293.2530000000008, 1305.4630000000009], [1305.4630000000009, 1315.933000000001], [1315.933000000001, 1326.9830000000009], [1326.9830000000009, 1340.8330000000008], [1340.8330000000008, 1352.7730000000008], [1352.7730000000008, 1363.0030000000008], [1363.0030000000008, 1374.3030000000008], [1374.3030000000008, 1385.183000000001], [1385.183000000001, 1400.183000000001], [1400.183000000001, 1411.7630000000008], [1411.7630000000008, 1423.943000000001], [1423.943000000001, 1437.0920000000008], [1437.0920000000008, 1451.8620000000008], [1451.8620000000008, 1468.0920000000008], [1468.0920000000008, 1480.5230000000008], [1480.5230000000008, 1491.0720000000008], [1491.0720000000008, 1502.3930000000007], [1502.3930000000007, 1520.4030000000007], [1520.4030000000007, 1536.4730000000006], [1536.4730000000006, 1548.6320000000007], [1548.6320000000007, 1561.7930000000008], [1561.7930000000008, 1575.5330000000008], [1575.5330000000008, 1592.5430000000008], [1592.5430000000008, 1604.0430000000008], [1604.0430000000008, 1614.423000000001], [1614.423000000001, 1626.612000000001], [1626.612000000001, 1647.043000000001], [1647.043000000001, 1657.733000000001], [1657.733000000001, 1667.9430000000011], [1667.9430000000011, 1678.783000000001], [1678.783000000001, 1689.463000000001], [1689.463000000001, 1700.973000000001], [1700.973000000001, 1710.993000000001], [1710.993000000001, 1722.342000000001], [1722.342000000001, 1741.833000000001], [1741.833000000001, 1752.993000000001], [1752.993000000001, 1763.132000000001], [1763.132000000001, 1774.353000000001], [1774.353000000001, 1788.803000000001], [1788.803000000001, 1801.273000000001], [1801.273000000001, 1811.9130000000011], [1811.9130000000011, 1822.473000000001], [1822.473000000001, 1835.533000000001], [1835.533000000001, 1846.223000000001], [1846.223000000001, 1858.333000000001], [1858.333000000001, 1876.632000000001], [1876.632000000001, 1890.072000000001], [1890.072000000001, 1901.803000000001], [1901.803000000001, 1914.273000000001], [1914.273000000001, 1926.4030000000012], [1926.4030000000012, 1941.3330000000012], [1941.3330000000012, 1952.1120000000012], [1952.1120000000012, 1964.7730000000013], [1964.7730000000013, 1975.4110000000012], [1975.4110000000012, 1987.473000000001], [1987.473000000001, 1997.9420000000011], [1997.9420000000011, 2009.503000000001], [2009.503000000001, 2023.713000000001], [2023.713000000001, 2039.3730000000012], [2039.3730000000012, 2052.813000000001], [2052.813000000001, 2067.902000000001], [2067.902000000001, 2081.853000000001], [2081.853000000001, 2101.633000000001], [2101.633000000001, 2117.5530000000012], [2117.5530000000012, 2128.3530000000014], [2128.3530000000014, 2139.5330000000013], [2139.5330000000013, 2156.673000000001], [2156.673000000001, 2169.173000000001], [2169.173000000001, 2180.103000000001], [2180.103000000001, 2191.123000000001], [2191.123000000001, 2206.773000000001], [2206.773000000001, 2222.933000000001], [2222.933000000001, 2236.353000000001], [2236.353000000001, 2249.463000000001], [2249.463000000001, 2261.7630000000013], [2261.7630000000013, 2274.403000000001], [2274.403000000001, 2285.909000000001], [2285.909000000001, 2299.543000000001], [2299.543000000001, 2309.773000000001], [2309.773000000001, 2324.942000000001], [2324.942000000001, 2337.6130000000007], [2337.6130000000007, 2349.553000000001], [2349.553000000001, 2360.453000000001], [2360.453000000001, 2371.913000000001], [2371.913000000001, 2383.723000000001], [2383.723000000001, 2394.493000000001], [2394.493000000001, 2405.442000000001], [2405.442000000001, 2419.243000000001], [2419.243000000001, 2430.123000000001], [2430.123000000001, 2441.743000000001], [2441.743000000001, 2457.393000000001], [2457.393000000001, 2468.1330000000007], [2468.1330000000007, 2480.4630000000006], [2480.4630000000006, 2494.0230000000006], [2494.0230000000006, 2504.533000000001], [2504.533000000001, 2518.243000000001], [2518.243000000001, 2531.3830000000007], [2531.3830000000007, 2543.2330000000006], [2543.2330000000006, 2554.9030000000007], [2554.9030000000007, 2571.1530000000007], [2571.1530000000007, 2581.3830000000007], [2581.3830000000007, 2594.703000000001], [2594.703000000001, 2609.3430000000008], [2609.3430000000008, 2623.743000000001], [2623.743000000001, 2636.773000000001], [2636.773000000001, 2649.263000000001], [2649.263000000001, 2659.793000000001], [2659.793000000001, 2670.373000000001], [2670.373000000001, 2681.443000000001], [2681.443000000001, 2691.777000000001], [2691.777000000001, 2702.753000000001], [2702.753000000001, 2721.863000000001], [2721.863000000001, 2739.258000000001], [2739.258000000001, 2749.653000000001], [2749.653000000001, 2761.623000000001], [2761.623000000001, 2775.3630000000007], [2775.3630000000007, 2788.663000000001], [2788.663000000001, 2800.923000000001], [2800.923000000001, 2812.923000000001], [2812.923000000001, 2825.8030000000012], [2825.8030000000012, 2841.383000000001], [2841.383000000001, 2855.423000000001], [2855.423000000001, 2865.943000000001], [2865.943000000001, 2878.133000000001], [2878.133000000001, 2890.963000000001], [2890.963000000001, 2901.313000000001], [2901.313000000001, 2912.683000000001], [2912.683000000001, 2923.273000000001], [2923.273000000001, 2937.163000000001], [2937.163000000001, 2952.693000000001], [2952.693000000001, 2964.423000000001], [2964.423000000001, 2979.173000000001], [2979.173000000001, 2989.643000000001], [2989.643000000001, 3003.263000000001], [3003.263000000001, 3015.283000000001], [3015.283000000001, 3025.603000000001], [3025.603000000001, 3038.088000000001], [3038.088000000001, 3048.673000000001], [3048.673000000001, 3060.2030000000013], [3060.2030000000013, 3072.0430000000015], [3072.0430000000015, 3086.4030000000016], [3086.4030000000016, 3099.5430000000015], [3099.5430000000015, 3111.4830000000015], [3111.4830000000015, 3121.9830000000015], [3121.9830000000015, 3133.4830000000015], [3133.4830000000015, 3144.6830000000014], [3144.6830000000014, 3157.7830000000013], [3157.7830000000013, 3167.9930000000013], [3167.9930000000013, 3180.9130000000014], [3180.9130000000014, 3193.0130000000013], [3193.0130000000013, 3206.0230000000015], [3206.0230000000015, 3220.4080000000017], [3220.4080000000017, 3233.1530000000016], [3233.1530000000016, 3250.4630000000016], [3250.4630000000016, 3262.7830000000017], [3262.7830000000017, 3278.2130000000016], [3278.2130000000016, 3290.7930000000015], [3290.7930000000015, 3303.2130000000016], [3303.2130000000016, 3316.5630000000015], [3316.5630000000015, 3328.7030000000013], [3328.7030000000013, 3339.6430000000014], [3339.6430000000014, 3349.8030000000012], [3349.8030000000012, 3366.3330000000014], [3366.3330000000014, 3379.2750000000015], [3379.2750000000015, 3390.4730000000013], [3390.4730000000013, 3407.5530000000012], [3407.5530000000012, 3427.1230000000014], [3427.1230000000014, 3443.2330000000015], [3443.2330000000015, 3456.2830000000017], [3456.2830000000017, 3466.5770000000016], [3466.5770000000016, 3477.8830000000016], [3477.8830000000016, 3492.3780000000015], [3492.3780000000015, 3503.9230000000016], [3503.9230000000016, 3515.2630000000017], [3515.2630000000017, 3528.0530000000017], [3528.0530000000017, 3543.433000000002], [3543.433000000002, 3556.523000000002], [3556.523000000002, 3568.133000000002], [3568.133000000002, 3583.4330000000023], [3583.4330000000023, 3598.7930000000024], [3598.7930000000024, 3611.6630000000023], [3611.6630000000023, 3624.0230000000024], [3624.0230000000024, 3638.8030000000026], [3638.8030000000026, 3654.3830000000025], [3654.3830000000025, 3665.0330000000026], [3665.0330000000026, 3676.3430000000026], [3676.3430000000026, 3686.4230000000025], [3686.4230000000025, 3698.0630000000024], [3698.0630000000024, 3711.533000000002], [3711.533000000002, 3743.1230000000023], [3743.1230000000023, 3754.1330000000025], [3754.1330000000025, 3766.4130000000027], [3766.4130000000027, 3776.793000000003], [3776.793000000003, 3789.123000000003], [3789.123000000003, 3805.293000000003], [3805.293000000003, 3816.0130000000026], [3816.0130000000026, 3829.4830000000024], [3829.4830000000024, 3842.1230000000023], [3842.1230000000023, 3853.1530000000025], [3853.1530000000025, 3863.9830000000024], [3863.9830000000024, 3875.8330000000024], [3875.8330000000024, 3888.1330000000025], [3888.1330000000025, 3902.2930000000024], [3902.2930000000024, 3916.6630000000023], [3916.6630000000023, 3928.2730000000024], [3928.2730000000024, 3940.6430000000023], [3940.6430000000023, 3951.243000000002], [3951.243000000002, 3964.5430000000024], [3964.5430000000024, 3979.8730000000023], [3979.8730000000023, 3990.6230000000023], [3990.6230000000023, 4001.7330000000024], [4001.7330000000024, 4013.8530000000023], [4013.8530000000023, 4026.3630000000026], [4026.3630000000026, 4036.7230000000027], [4036.7230000000027, 4049.6930000000025], [4049.6930000000025, 4061.0030000000024], [4061.0030000000024, 4072.5530000000026], [4072.5530000000026, 4082.9630000000025], [4082.9630000000025, 4093.9430000000025], [4093.9430000000025, 4107.613000000002], [4107.613000000002, 4129.462000000002], [4129.462000000002, 4140.083000000002], [4140.083000000002, 4152.083000000002], [4152.083000000002, 4164.631000000002], [4164.631000000002, 4181.523000000002], [4181.523000000002, 4193.933000000002], [4193.933000000002, 4206.683000000002], [4206.683000000002, 4221.373000000001], [4221.373000000001, 4231.833000000001], [4231.833000000001, 4243.023000000001], [4243.023000000001, 4262.433000000001], [4262.433000000001, 4275.643000000001], [4275.643000000001, 4291.343000000001], [4291.343000000001, 4307.103000000001], [4307.103000000001, 4318.743000000001], [4318.743000000001, 4328.853000000001], [4328.853000000001, 4339.443000000001], [4339.443000000001, 4350.098000000001], [4350.098000000001, 4366.273000000001], [4366.273000000001, 4377.0430000000015], [4377.0430000000015, 4398.583000000001], [4398.583000000001, 4410.713000000002], [4410.713000000002, 4424.743000000001], [4424.743000000001, 4435.833000000001], [4435.833000000001, 4447.983000000001], [4447.983000000001, 4461.0430000000015], [4461.0430000000015, 4473.183000000002], [4473.183000000002, 4488.213000000002], [4488.213000000002, 4498.713000000002], [4498.713000000002, 4511.443000000001], [4511.443000000001, 4522.533000000001], [4522.533000000001, 4539.113000000001], [4539.113000000001, 4549.403000000001], [4549.403000000001, 4559.5430000000015], [4559.5430000000015, 4574.723000000002], [4574.723000000002, 4587.353000000002], [4587.353000000002, 4603.013000000002], [4603.013000000002, 4621.363000000002], [4621.363000000002, 4631.593000000002], [4631.593000000002, 4644.823000000001], [4644.823000000001, 4655.203000000001], [4655.203000000001, 4665.313000000001], [4665.313000000001, 4681.152000000001], [4681.152000000001, 4691.8330000000005], [4691.8330000000005, 4702.943], [4702.943, 4713.3730000000005], [4713.3730000000005, 4716.120000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [933, 2433, 3651, 4716]}
{"example_id": "mit038@@MIT8_06S18_L05_300k", "text": ["PROFESSOR: Today we have to continue with our discussion  of the hydrogen atom.  We had derived or explained how you ", "would derive the corrections to the original Hamiltonian,  the Hamiltonian you've studied already in a couple of courses, ", "this h0 Hamiltonian for the hydrogen atom  that has a kinetic term and a potential term. ", " This Hamilton we've studied for a while.  And what we've said was that the Dirac equation provided a way ", "to get systematically all the corrections, the first order  of that Hamiltonian, and that's what we have here.  That was the end product of that discussion in which the better ", "Hamiltonian or the perturbed Hamiltonian including more  effects was the original one plus a relativistic correction  because this is not the relativistic kinetic energy. ", "Then there was a spin orbit coupling  in which you couple the spin of the electron  to the orbital angular momentum of the vector.  ", "And finally, there is a Darwin term.  It's a surprising term.  This is Charles Gaston Darwin, a British physicist,  that discovered this term. ", "And all these terms were suppressed with respect to h0,  in the sense that h0 had energies. ", "The energies associated to h0 went  like alpha squared mc squared.  The fine structure constant, that's for h0 veera. ", "But for h1 or for delta h, the energies  go like alpha to the fourth mc squared,  where m is the mass of the electron, ", "and that's about 20,000, 19,000 times smaller.  So this is our perturbation, and that's  what you have to understand. ", "So we'll begin with the Darwin term.  Then we'll turn to the relativistic term,  then to the spin orbit term, and, by the end ", "of today's lecture, we'll put it all together.  So that's our plan.  So let's start with the Darwin term.  What is this term? ", "So Darwin term, I will try to evaluate it. ", "So it depends on the potential energy.  It has the Laplacian of the potential energy.  So the potential energy is minus e squared over r. ", "So how much is the Laplacian of the potential energy?  Well, the Laplacian of v would be minus e squared  times the Leplacian of 1 over r. ", "And that's minus e squared times minus 4 pi delta function of r.  That's something you study in in E and M. The Laplacian of 1 ", "over r is related to a delta function.  It's the charge density of a point particle  that produces that potential. ", "So our result here is that this Laplacian is e square 4  pi e squared delta of r. ", "It's a delta function contribution.  So let's write it here.  ", "The delta h Darwin is pi over 2 e ", "squared h squared over m squared c squared delta of r.  ", "All right, so that's our correction.  And we want to do perturbation theory with it,  how it affects the energy levels of the various states ", "of hydrogen. So how are they changed?  What does it do to them?  Now, there is a simplifying fact here, the delta function. ", "So you remember, first order corrections  are always obtained by taking the interactive Hamiltonian  and putting states in it.  ", "And the first thing we notice is that unless the wave  function of the states does not vanish at 0,  the correction vanishes.  So this will pick up the value of the wave functions. ", "When you have two states, arbitrary  state 1 and state 2 and delta h Darwin here--  ", "there's two wave functions that you're  going to put here if you're trying to compute matrix  elements of the perturbation.  And if either of these wave functions ", "vanishes at the origin, that's not possible.  But all wave functions vanish at the origin,  unless the orbital angular momentum l is equal to 0. ", "Remember, all wave functions go like r  to the l near the origin.  So for l equals 0, that goes like 1, a constant, ", "and you get a possibility.  So this only affects l equals 0 states. ", "That's a great simplicity.  Not only does that, but that's another simplification.  Because at any energy level, l equals ", "0 states is just one of them.  If you consider spin, there are two of them.  Remember in our table of hydrogen atoms  states go like that. ", "So here are the l equals 0 states.  And those are the only ones that matter.  So the problem is really very simple. ", "We don't have to consider the fact that there are  other degenerate states here.  We just need to focus on l equals  0 states because both states have to be l equals 0 ", "and l equals 0.  So our correction that we can call e1 Darwin for n 0 0-- ", "because l is equal to 0, and therefore m is equal to 0--  would be equal to psi n zero zero delta h Darwin psi n 0 0. ", " So what is this? ", "We have this expression for delta h Darwin.  So let's put it here, pi over 2 e squared h squared over m  squared c squared. ", "And this will pick up the values of the wave functions.  This overlap means integral over all of space of this wave ", "function complex conjugated, this wave function and delta  h Darwin.  So at the end of the day, due the delta function,  it gives us just psi n 0 0 at the origin squared. ", " That's all it is.  Simple enough.  ", "Now, finding this number is not that easy.  Because while the wave function here for l equals 0 ", "is simple for the ground state, it already  involves more and more complicated  polynomials over here.  And the value of the wave function at the origin ", "requires that you normalize the wave function correctly.  So if you have the wave function and you have not  normalized it properly, how are you  going to get the value of the wave function at the origin? ", "This whole perturbation theory, we always  assume we have an orthonormal basis.  And indeed, if you change the normalization--  if the normalization was irrelevant here, ", "this number would change with the normalization,  and the correction would change.  So you really have to be normalized for this  to make sense.  And finding this normalization is complicated. ", "You could for a few problems maybe look look up tables  and see the normalized wave function, what it is.  But in general here, there is a method ", "that can be used to find this normalization analytically.  And it's something you will explore in the homework.  So in the homework there is a way ", "to do this, a very clever way, in which it actually turns out.  So in the homework, you will see that the wave function ", "at the origin for l equals 0 problems is  proportional to the expectation value ", "of the derivative of the potential with respect to r.   So it's something you will do. ", "This potential, of course, is the 1  over r potential in our case.  And the derivative means that you  need to evaluate the expectation value of 1 ", "over r squared in this state.  But the expectation values of 1 over r squared in the hydrogen  atom is something you've already done in the previous homework. ", "It's not that difficult.  So the end result is that this term is calculable.  And psi of n 0 0 at the origin squared ", "is actually 1 over pi n cube a0 cube.  ", "With that in, one can substitute this value  and get the Darwin correction.  ", "You can see there is no big calculation to be done.  But you can rewrite it in terms of the fine structure  constant Darwin. ", "And it's equal to alpha to the fourth mc squared 1  over 2n cubed.  And it's valid for l equals 0 states. ", " So this number goes in here, and then write ", "things in terms of the fine structure constant,   PROFESSOR: So far, so good.  We've really calculated.  And we could stop here. ", "But there is a nice interpretation  of this Darwin term that gives you intuition  as to what's really happening. ", "See, when you look at these terms overall--  these interactions with this class--  you say, well, the kinetic energy was not relativistic. ", "That gives rise to this term.  There is a story for the spin orbit as well.  We think of the proton--  creates an electric field. ", "You, the electron, are moving around.  As you move inside the static-electric field,  you see a magnetic field.  The magnetic field interacts with your dipole moment ", "of the electron.  That's the story here.  So what's the story for this term?  Where does it come from?  What is the physics behind it? ", "That's what I want to discuss now.   So the physics interpretation of the Darwin term ", "is that the electron behaves not as  if it would be a point particle but as if it would be, ", "kind of, a little ball where the charge is spread out.  We know that any mechanical model of the electron, where ", "you think of it as a ball, the spinning  doesn't work for the spin.  But somehow, here, we can see that this extra correction  to the energy is the correction that ", "would appear if, somehow, the electron, instead of feeling  the potential of the nucleus at one point,  as if it would be a point particle, ", "it's as if it would be spread.  So let me make a drawing here.  Here is the proton.  ", "And it creates a potential.  And we will put an electron at the point r.  ", "There's the electron.  But now, we're going to think that this electron is really  a cloud, like this. ", " And the charge is distributed over there.  And now, I'm going to try to estimate ", "what happens to the potential energy  if it's really behaving like that.   So for that, I'm going to make another [INAUDIBLE],, ", "its system starting here.  I'm going to call the vector that  goes to an arbitrary point here vector u.  So from the origin or center of this charge distribution, ", "we put the vector u.  And then I have this vector over here, which is r plus u.  ", "And this u points to a little bit of charge, a little cubit  here, for example.  ", "So this is our setup.  Now, the potential-- due to the proton--  ", "proton-- we have a potential V of r,  which is equal to minus the charge of the electron times ", "the scalar potential, phi of r--  it's minus e times e over r, which is our familiar minus e ", "squared over r.  So the potential energy--  this is the potential energy.  And so if you had a point particle-- ", "for a point particle--   you have that the proton creates a potential at a distance r. ", "You multiply by the charge.  And you get the potential energy.  So how do we do it a little more generally? ", "I'm going to call this V tilde of r.  ", "The true potential energy--  potential energy-- when the center of the electron is ", "at r--   electron at r. ", "So what is the true potential energy  when the center of the electron is at r?  Well, I would have to do an integral  over the electron of the little amount of charges ", "times the potential at those points.  ", "For every piece of charge, I must  multiply the charge times the potential generated  by the proton.  And that would give me the total energy of this electron ", "in this potential, V of r.  So let me use that terminology here.  I will describe the charge density-- ", "density-- rho of u--  the density of charge at a position given by a u vector. ", "I'll write it as minus e times rho 0 of u--  a little bit of notation.  I apologize, but it's necessary to do things cleanly. ", "The charge density of the electron--  electron-- is given by rho of u minus e rho 0. ", "And then it should be true that the integral  over the electron of d cube u rho 0 of u is equal to 1. ", "Look at that integral.  Why should it be equal to 1?  It should be equal to 1, because then the integral of the charge ", "density--  the integral of this over all of space would be minus e times 1.  And that's exactly what you expect. ", "So rho 0 is a unit free--  well, 1 over length cubed is a charge-free quantity. ", "The charge is carried by this constant over here.  So what happens then with this V of r?  This V of r is the charge-- ", "little charge q is d cubed u times rho of u times phi ", "at r plus u.   Look, the charge is this at some little element. ", "And then the potential there is the potential at r plus u.   So one more step--  V of r-- if you take from rho this extra minus e, ", "minus e times phi of r is what we call  the potential energy due to r.  So take the minus e out and append it ", "to the capital Phi here, so that we have integral d cube u rho  0 of u V of r plus u. ", " OK, this was our goal.  ", "It gives you the new energy--  the true potential energy of this electron  when this center is at r as the smearing ", "of the potential energy of a point particle  smeared over the electron.  ", "So this is a formula that represents our intuition.  And moreover, it has the rho 0 here  that tells you the weight that you should apply at any point, ", "because this rho 0 is proportional to the charge--  very good.  We have a formula.  But I was supposed to explain that term. ", "And we have not explained it yet.  But now, it's time to explain it.  We're going to try to do a computation that  helps us do that.  The idea is that we're going to expand the potential ", "around the point r and treat this as a small deviation  because, after all, we expect this little ball that I drew ", "big here for the purposes of illustration  to be rather small.  So let's write V of r plus u as V of r in Taylor series-- ", "plus the next term is the derivative  of V with respect to position evaluated  at r multiplied by the deviation that you moved. ", "So sum over i dv dx i evaluated at r times u i. ", "This is the component of this vector u.  That's the first term in the Taylor series.  And we need one more--  plus 1/2 sum over i and j, d 2nd V vx i vx j evaluated ", "at r ui uj.   And then we have to integrate here.  We substituted in here and integrate. ", "So V tilde of r-- let's see what it is.  Well, I can put this whole thing-- ", "we don't want to write so much.  So let's try to do it a little quick.  We're integrating over u.  And here, let's think of the first term here. ", "When you plug in the first term, this function of r  has nothing to do with u.  So it goes out and you get V of r times the integral d cube u ", "rho 0 of u.   For the next term in here, these derivatives ", "are evaluated at r-- have nothing to do with u.  They go out.  So plus sum over I dv dx i of r integral d cube u ", "rho 0 of u, ui.   Last term-- these derivatives go out. ", "They're evaluated at r.  They have nothing to do with you.  So plus 1/2 sum over i and j d second V dx i dx ", "j evaluated at r integral d cube u rho of u ui uj. ", "OK-- all these terms!   Happily we can interpret much of what we have here. ", "So what is this first integral?  ", "V of r equals--  this integral is our normalization integral.  ", "Over here, that's equal to 1.  So this is very nice.  That's what you would expect that  to first approximation, the total energy of the electron, ", "when it is at r--  as if it would be a point particle at r.  Now, let's look at the next terms.  Now, we will assume that the distribution of charge ", "is spherically symmetric.  So that means that rho of u vector  is actually a function rho 0 of u,  where u is the length of the u vector. ", "So it just depends on the distance from the point  that you're looking.  That's the charge.  Why would it be more complicated? ", "If that is the case, if this is spherically symmetric,  you can already see that these integrals would vanish, ", "because you're integrating the spherically symmetric quantity  times a power of a coordinate.  That's something you did in the homework  as well for this Stark effect. ", "You realized that integrals of spherically symmetric functions  then powers of x, y, and z-- well, they get  killed, unless those are even powers.  So this is an odd power. ", "And that's 0.  So this term is gone.  And this integral is interesting as well. ", "When you have a spherically symmetric quantity  and you have i and j different, the integral would be 0.  It's like having a power of x and a power of y  in your homework. ", "So if that integral would be 0, it would only be non-zero if i  is equal to j-- the first component, for example--  1 u1 u1.  But that integral would be the same as u2 u2 or u3 u3. ", "So in fact, each of these integrals  is proportional to delta i j, but equal to 1/3 ", "of the integral of d cube u rho of u--  I'll put the delta ij here--  times u squared. ", "u squared is-- u1 squared plus u2 squared plus u3 squared--  each one gives the same integral.  Therefore, the result has a 1/3 in front. ", "So what do we get?  Plus 1/6-- and here, we get a big smile. ", "Why?  Because delta i j, with this thing,  is the Laplacian of V evaluated at r.  They have the same derivative summed. ", "So what do we get here?  1/6 of the Laplacian of V evaluated  at r times the integral d cube u rho 0 of u u squared. ", " Very nice-- already starting to look like what we wanted, ", "a Laplacian.  Can we do a little better?  Yes, we can.  It's possible.  Let's assume the charged particle has a size. ", "So let's assume the electron is a ball of radius ", "the Compton wavelength, which is h bar over mc.   So that means rho 0 of u is non-zero when ", "u is less than this lambda.  And it's 0 when u is greater than this lambda.  That's a ball-- some density up to there. ", "And this must integrate to 1.  So it's 1 over the volume of that ball, 4 pi lambda cubed  over 3. ", " Do this integral. ", " This integral gives you, actually, 3/5 of lambda ", "squared with that function.  So the end result is that V tilde of r is equal to V of r. ", " Plus 3/5 of this thing times that is 1/10 h ", "squared m squared c squared Laplacian of V.  The new correction to the potential, when this mole came ", "out to this 1/10--  that's pretty close, I must say.  There's an 1/8 there.  We assume the electron is a ball of size, the Compton ", "wavelength of the electron.  It's a very rough assumption.  So even to see the number not coming off by a factor of 100 ", "is quite nice.  So that's the interpretation.  The known locality-- the spread out  of the electron into a little ball of its Compton size ", "is quite significant.  The Compton wavelength of the electron  is fundamental in quantum field theory.  The Compton wavelength of an electron ", "is the size of a photon whose energy is equal to the rest  mass of the electron.  So if you have a photon of this size equal ", "of wavelength equal to Compton length of the electron,  that photon packs enough energy to create  electron-positron pairs. ", "That's why, in quantum field theory, you care about this.  And the quantum field theory is really  the way you do relativistic quantum mechanics.  So it's not too surprising that, in relativistic analysis ", "such as that of the Dirac equation,  we find a role for the Compton wavelength of the electron  and a correction associated with it. ", " PROFESSOR: So we'll do the relativistic corrections.  And all the corrections that I'll do today,  I'll skip the easy but sometimes a little tedious algebra. ", "It's not very tedious.  Nothing that is pages and pages of algebra.  It's lines of algebra.  But why would I do it in lecture? ", "No point for that.  So let's see what we can do.  This is the relativistic correction,  the minus p squared. ", "So could we write this for the relativistic correction?  We're going to do first order correction, relativistic,  of the levels n l ml. ", " Let's put a question mark.  Minus 1 over 8 m cubed c squared psi n l ml p to the fourth. ", " Now recall that p to the fourth, the way it was given, ", "is really p squared times p squared.   You have four things that have to be multiplied. ", "So it's not px to the fourth plus py to the fourth plus  pz to the fourth is px squared plus py squared  plus pz squared, all squared, just in case ", "there's an ambiguity.  That seems reasonable.  The first order corrections should  be found by taking the states and finding this. ", "But there is a big question mark.  And this kind of question is going  to come up every time you think about these things.  ", "This formula, where I said the shift  of the energy of this state is that state evaluated here,  applies for nondegenerate perturbation theory. ", "And if the hydrogen atom is anything,  it's a system with a lot of degeneracies.  So why can I use that, or can I use that? ", "We have the hydrogen atom.  I just deleted it here.   So here, if you have n, for degeneracies you fix n. ", "For degeneracies, you fix some value of n.  And now you have the degeneracies between  the various l's, for each l between the various m's. ", "A gigantic amount of degeneracy.  Who allows me to do that?  I'm supposed to take that level three has nine states, ", "remember?  n square states.  Well, we should do a 9 by 9 matrix here and calculate this.  Nine sounds awful. ", "We don't want to do that so we better think.  So this is the situation you find yourself.  Technically speaking, this is a problem  in the degenerate perturbation theory. ", "We should do that.  And you better think about this every time you face this  problem because sometimes you can get away without doing ", "the degenerate analysis, but sometimes you can't.  Yes?  AUDIENCE: It's like rotationally symmetric.  So you can mix terms with different [INAUDIBLE]..  PROFESSOR: OK. ", " So you're saying, basically, that this thing in this basis--  so we have nine states here. ", "n equal 3.  In these nine states, it doesn't mix them.  So this is diagonal here.  And what one is claiming by doing  that is that this is a good basis, ", "that delta H is already diagonal there.  And don't worry, we can do it.  In fact, that is true. ", "And the argument goes like that.  We know that p to the fourth, the perturbation, ", "commutes with l squared.   We'll discuss it a little more.  And p to the fourth commutes with lz as well. ", "So these are two claims.  Very important claims.  Remember, we had a remark that I told you  few times few lectures ago.  Very important. ", "If you have a Hermitian operator that  commutes with your perturbation for which  the states of your bases are eigenstates  with different eigenvalues, then the basis is good. ", "So here it is.  l squared commutes with p to the fourth.  Why?  Because, in fact, p to the fourth commutes ", "with any angular momentum because p to the fourth  is p squared times p squared.  And p squared is rotational invariant.  p squared commutes with any l. ", "If that's not obvious intuitively,  which it should become something you trust--  this is rotational invariant. p squared dot product doesn't ", "depend on rotation.  If you have a p and you square it or you have a rotated p  and you square it, it's the same.  So p to the fourth commutes with any component  of angular momentum. ", "So these two are written like great facts,  but the basic fact is that p squared with any li is 0.  And all this follows from here. ", "But this is a Hermitian operator.  This is a Hermitian operator.  And the various states, when you have fixed n, ", "you can have different l's.  But when you have different l's, there  are different eigenvalues of l squared.  So in those cases, the matrix element will vanish. ", "When you have the same l's but different m's, these  are different eigenvalues of lz.  So the matrix element should also vanish. ", "So this establishes rigorously that that perturbation,  p to the fourth, is diagonal in that subspace. ", "So the subspace relevant here is this whole thing.  And in this subspace, it's completely diagonal.  Good. ", "So generally, this kind of point is not emphasized too much.  But it's, in fact, the most important and more interesting ", "and more difficult point in this calculations.  We'll have one more thing to say about this.  But let's continue with this. ", "I'll say the following.  We use the Hermiticity of p squared ", "to move one p squared to the other side.  So Enl ml 1 is equal to minus 1 over 8m cubed ", "c squared p squared psi nlm p squared psi nml--  ", "nlm.   OK.  We move this p to the fourth.  It was p squared times p squared.  One p squared is Hermitian. ", "We move it here.  And then, instead of calculating a billion derivatives here,  you use the fact that p squared over 2m plus v of r on the wave ", "function is equal to the energy of that wave function that  depends on n times the wave function.  ", "These are eigenstates.  So p squared-- we don't want to take derivatives,  and those expectation values can be replaced by a simpler thing.  P squared on psi is just 2m En minus v of r psi. ", " So Enlm 1 is equal to minus 1 over 8m cubed c squared. ", "Here we have, well, the m's.  Two m's are out, so we'll put a 2 and an mc squared.  Yep. ", "En minus v of r psi En minus v of r psi nlm nlm. ", "OK.  We got it to the point where I think you can all  agree this is doable.  Why?  Because, again, this term is Hermitian, ", "so you can put it to the other side.  And you'll have terms in which you compute the expectation  value on this state of E squared.  E squared is a number, so it goes out, times 1, easy. ", "En cross terms with vr is the expectation of v  of r in this state, is the expectation  of 1 over r in a state.  That's easy.  It comes from the Virial theorem. ", "Then you'll have the expectation of v squared in a state,  and that's the expectation of 1 over r squared in a state.  You've also done it.  So yes, getting all together, getting the factors right ", "would take you 15 minutes or 20 minutes or whatever.  But the answer is already clear. ", "So let's write the answer.  ", "And the answer is that Enl ml 1 relativistic is ", "minus 1/8 alpha to the fourth.  That's our very recognizable factor.  mc squared 4n over l plus 1/2 minus 3. ", "Now, fine structure is something all of us  must do at least once in our life.  So I do encourage you to read the notes carefully  and just do it. ", "Just become familiar with it.  It's a very nice subject, and it's something  you should understand. ", "So here, again, I have to do a comment about basis,  and those comments keep coming because it's  an important subject. ", "And I want to emphasize it.  So what is the reason?  The reason I wanted to comment is because in a second,  I'm going to do the spin orbit term. ", "And in that case, I would like to work with a coupled basis.  Here, I'm working with the uncoupled basis.  And really, this thing is the expectation value ", "of Hl relativistic in nl ml ms nl ml ms. This is really that. ", " I wrote psi nl ml, so you should trust the first three labels.  And ms goes for the ride. ", "It's this spin.  The operator you're putting here, delta H relativistic,  has nothing to do with spin.  Could not change the spin of the states.  This has to be diagonal in spin. ", "So this number you've computed is nothing else  than this overlap in the uncoupled basis. ", "So this calculation was uncoupled basis matrix element. ", " And we saw that it's diagonal.  ", "In fact, this whole thing is nothing  but the function of n and l.   n and l. ", "And independent of ml and ms. OK. ", "That's what we've calculated.  So here is the question.   We could consider this in the coupled bases nlj mj. ", " nlj mj.  ", "And the question is, do I have to recalculate this  in the coupled basis or not?  ", "And here is an argument that I don't have to recalculate it.  So I'm going to claim that this is really equal to that. ", "Just the same.   It's the kind of thing that makes you a little uneasy,  but bear with me.  Why should it be the same? ", "Think of this as fixed n and l because this  depends on n and l.  If we have the hydrogen atom here, ", "you'd take one of these elements, one of these states--  this is a fixed n, fixed l. ", "And we're looking at fixed n, fixed l.  Yes.  There are lots of states here that have different ml and ms.  But the answer doesn't depend on ml and ms. In this basis, ", "we are also looking at that subspace, that multiplet,  nl fixed.  And they have reorganized the states with j and mj. ", "In fact, with two values of j and several values of mj.  But at the end of the day, the coupled basis  is another way to describe these states coming ", "from tensoring the l multiplet with a spin 1/2.  So it gives you two multiplets, but they are the same states.   So the fact that every state here ", "is some linear combination of states in the uncoupled  bases with different values of ml and ms that add up to mj.  But this answer doesn't depend on ml and ms. ", "So whatever linear combination you need,  it doesn't change because the answer doesn't  depend on ml and ms. So this must be the same as that. ", "I'll give another argument.  Maybe a little more abstract, but clearer perhaps.  Think of this.  So this can be--  in the notes, I explain that by changing basis and explaining ", "why exactly everything works out.  But there is no need for that argument  if you think a little more abstractly.  Think of this subspace. ", "Because with fixed n and l, we have this subspace.  In this subspace, the uncoupled basis ", "makes the perturbation diagonal.  But more than diagonal, it makes the perturbation proportional  to the unit matrix, because every eigenvalue is the same. ", "Because in this subspace, n and l is fixed.  And yes, m and ms change, but the answer  doesn't depend on that.  So this matrix, delta H, in this subspace ", "is proportional to the unit matrix.  And when a matrix is proportional to the unit  matrix, it is proportional to the unit ", "matrix in any orthogonal basis.  A unit matrix doesn't get rotated.  So it should be a unit matrix here as well, ", "and it should be the same matrix.  So this is the same pair.  PROFESSOR: All right, spin orbit.  ", "We have it still there, delta H spin orbit, orbit.  ", "Well, we know what V is.  So that derivative, dv dr can be taken care of, the 1 over r.  That gives you e squared over 2m c squared 1 over r cubed S, L. ", "And you remember that S, L, from 805, J squared minus S  squared minus L squared. ", "The reason that's why you tend to do addition of angular  momentum, because S and L, calculating the matrix ", "elements of this thing is very easy,  in that base is because every state there  has a fixed value of S squared, a fixed value of L squared. ", "And j squared plus a couple of possibilities.  So we must work with the couple basis. ", " Basis.  And therefore, we can attempt to find E1 of a N, L, J, MJ, spin ", "orbit, equal e squared over 2m squared c squared and LJ, MJ, ", "S, L, R cubed.  The R cube has to stay inside the expectation value,  because the expectation value includes ", "integration over space.  So this is a very important.  N, L, J, MJ.  And again the useful question, the couple basis ", "will have have degeneracies.  All the states are degenerate there.  So this time, we fixed n, because the degeneracies ", "happen only when you fix n.  So do we have the right to do this,  to use the formula form perturbation,  the non-degenerate perturbation theory to do this calculation? ", "And the answer is yes, because the perturbation S.L over R  cubed commutes with with L squared, with J squared, ", "and with Jz.   you need all that because you can have degeneracies  by having different L values. ", "And that would be taken care by this operator that  has different eigenvalues when L is different.  You can have the degeneracies involving different J values.  This would be taken by this operator. ", "And you can have degeneracies when  m has different value so that involves the Jz operator.  So you really need a perturbation  that commutes with all of them. ", "And why does it commute with all of them?   You can see it in several ways.  Let's do L squared. ", "L squared is Casimir, it commutes with any LI.  It doesn't even think about S because it doesn't  know anything about S. So it commutes with S. ", "So L squared with any LI and commutes with S.  And L squared is an invariant, it  commute with r squared because r squared ", "is rotational invariant.  So everything commute with that.  In order to do the other ones, you  can also think in terms of this matrix J squared over here ", "and S squared and do all of them.  You should do it and convince yourself that they all commute.  So we can do this. ", " If we can do it, it's good because then we  can evaluate these quantities.  ", "So let's do a little of the the evaluation.  ", "So this E1nljmj is equal to.  Let's evaluate the S dot L part by using 1/2 j squared ", "s squared minus L squared.  So that gives you a factor of h bar squared over 2,  with this 2 over there. ", "So you get e squared h squared over 4m  squared c squared, J times J plus 1 minus l times l ", "plus 1 minus 3/4, times nljmj, 1 over r cubed, mljmj. ", "", "OK.   That should be clear from the fact  that you have a j squared minus s squared.  That's a 3/4 spin is always 1/2, and l squared. ", " This is known.  It's equal, in fact, to nlml 1 over cubed nlml. ", " Which is equal, let me discuss that again.  It's a little-- a0l, l plus 1, l plus 1/2. ", "OK.  So this is a known result. It's one of those expectation values  that you can get from Feynman, Hellman,  or for other recursion relations. ", "And this is always computed in the original uncoupled basis.   But we seem to need it in the coupled basis. ", "So again, are we in trouble?  No.  This is actually the same.  And it is the same only because this answer  doesn't depend on ml. ", "Because this states involve various combinations of ml  and ms. But doesn't depend on ml,  so the answer is really the same.  So these things are really the same. ", "Happily, that simplifies our work.  And now we have E1 nljm is equal to En 0-- ", "this is yet another notation, this is the ground state energy  here--  mc squared n, j, j plus 1 minus l, l plus 1 minus 3/4, ", "over l, l plus 1/2, l plus 1.  OK this is spin orbit. ", "  PROFESSOR: So again, much of the difficulty  here is just making sure you're doing the perturbation theory ", "right and working with the two basis correctly.  But now we're in the good position.  We can combine our results. ", " So here is what I want to combine.  ", "I want, in principle, to combine all the things, all the terms.  And we've calculated all the terms to some degree. ", "So we saw the Darwin term only affects l equals 0.  On the other hand, spin orbit really requires s dot l. ", "And the state should be acted nontrivially by l.  If all your states are singlets, l gives 0 on them. ", "So actually, you have a little bit  of an uncomfortable situation because l acting on l  equals 0 states will give you 0.  But you still have the 1 over r cubed. ", "And the 1 over r cubed has l dependencies here.  So it's 0 in the denominator, 0 in the numerator.  The whole spin orbit coupling doesn't seem ", "to make sense for l equals 0.  So most people say, physically, the spin orbit coupling  vanishes for l equals 0.  It should not be there. ", "But then something very funny happens.  If you take a proper limit of this as l goes to 0,  it gives you, for the spin orbit result, the same thing ", "as the Darwin result. So for l equals 0,  the spin orbit limit is actually the same as the Darwin. ", "It's almost as if you say, oh, the spin  orbit has everything in it.  But it's not legal for l equals 0.  But the Darwin does it.  So if I put together the spin orbit and relativistics ", "for l different from 0, I'm legal.  For l equals 0, I should really sum relativistic and Darwin. ", "But actually, it turns out that it's  the same as summing relativistic plus spin orbit.  Because the limit of spin orbit for l equals 0  is equal to the Darwin.  So we will just sum relativistic plus spin orbit. ", "And that gives the result for everything, including  Darwin for l equals 0.  So this is minor subtlety.  But the end result is that we can combine it. ", "So the happy thing, as well, is that we now can do this.  mj delta H relativistic plus delta H spin orbit nljmj. ", " Because whatever we calculated here  was actually the same that H relativistic ", "in the coupled basis.  And anyway, the spin orbit, we use the coupled basis  to get this number.  So this thing, you can add the two results, ", "and you get En0 squared over 2mc squared 3 plus n ", "J j plus 1 minus 3l l plus 1 minus 3/4 over l l ", "plus 1/2 l plus 1--  a little messy.  ", "OK.  Something very unexpected happens now.  It's something that when you do the algebra yourself, you say, ", "wow.  How did that happen?   Here is the issue.   We are trying to compute the splittings of the hydrogen ", "atom.  And for this, as we said in the coupled basis,  the degeneracies happen for a given value of n. ", " I'm getting good at doing this diagram now.  ", "So we're looking at the fixed n.   And then, you have all kind of degenerate states for various  l's and j's. ", "So is there a better way to rewrite this formula?  And you say the following--  suppose you think of some states of fixed j-- ", "fixed j states-- j.   For example, this state-- we'll use our l equals 1 over here-- ", "I have 1, 2, 3--  3P 3/2 and 3P 1/2. ", "Here, I have 3D 5/2 because this is l equals 2.  So 2 plus 1/2 and 2 minus 1/2.  ", "So I have here states of fixed j--  two states with the same j.  But they come from different l's. ", "Because when you get a total j of some value,  it can come from a lower l--  l plus 1/2 gives you that j--  or it can come from a top l with l minus 1/2 giving you that j. ", "So a given j value can arise from an l that is 1/2 higher  or an l that is 1/2 lower. ", "So for a fixed j, it may be that l is equal to j minus 1/2,  or l is equal to j plus 1/2. ", " Now, look at this quantity.  We'll call this whole quantity f of jl. ", " Very astonishingly, f of jl when l is j minus 1/2, or f of jl ", "where l is j plus 1/2, you can calculate it.  Put l equals j minus 1/2 on that formula. ", "And then put l equals j plus 1/2 in that formula.  You would say, it's going to be a mess.  In fact, both cases are the same. ", "And it give you minus 2 over a j plus 1/2.  So the whole l dependence here, amazingly, is fake. ", "There's no l dependence in this factor.  It is a little strange.  There's no l dependence because, given j, l can be two values. ", "And for those two values, that function gives you the same.  It's one of those, like x squared gives the same for 1  and minus 1.  This function, once you fix j, l can be two values. ", "And it so happens that these two values give the same.  So at the end of the day, this just depends on j.  That's the most important result of this lecture.  The whole structure, once you put relativity, ", "Darwin, and spin orbit, just depends on j.  And what is the result when you simplify this?  ", "Our result is that the fine structure Enljmj-- ", " fine structure 1-- is equal to minus alpha to the fourth mc ", "squared 1 over 2n to the fourth n over j plus 1/2 minus 3/4.  ", "Whole answer, all together--  Darwin fine spin orbit and relativistic. ", "So a few comments about this.  People that look at the Dirac equation  more seriously would have expected this result. ", "It turns out that in the Dirac equation, the symmetry  and the rotations--  the generator of rotations--  is exactly j, which is l plus s. ", "That generates rotation.  That commutes with the Hamiltonian.  So you should expect that the energy eigenstates  are j eigenstates.  So here, we're seeing that, yes, they can ", "be simultaneously diagonalized.  The eigenstates can also be labeled by the j value.  So the exact eigenstates in the Dirac equation  can be labeled by the j value, and we're ", "seeing a reflection of this.  This means that the j multiplets are not going to be split,  and there's going to be, moreover, some degeneracy. ", "They're not split because there's no mj dependence.  And they are all going to be the same.  So let me finish by drawing how the spectrum looks. ", "It's pretty important to see that.  This quantity over here, this numerical quantity,  is always positive-- ", "positive-- for any state in the hydrogen atom.  You can see that because j max--  the maximum value-- so this is negative. ", "So you need to know what is the minimum value of this quantity  to see if it goes negative.  The minimum value of this ratio is when j is maximum. ", "The maximum j is when j is l plus 1/2 with the maximum l.  So this is l plus 1 maximum. ", "But l plus 1 maximum is, in fact, n.  So the minimum value of this is 1.  So this is always positive.  As n increases, the corrections become smaller. ", "So what happens?  All the corrections are negative.  So if you had the original states, they all go down a bit. ", "Even the ground state goes down a bit.  1S 1/2 is down.   Because for n equal 1, you do get a state. ", "Then what do you get?  2S 1/2 is here.  It's also down a bit.  3S 1/2-- so this is l equals 0. ", "Then you have l equals 1.  Remember, what did we have here?  We have 2P 1/2 and 2P 3/2. ", "Because l equal 1 gives you j equals 3/2 and 1/2.  Look, these two remain degenerate because they  have the same n and the same j. ", "And that's all that matters.  So 1/2 and 1/2 have the same j, so they remain degenerate.  2P 3/2 has a higher j, therefore, ", "has a smaller number.  So it's lowered less, and it appears a little higher.  So here, you would have 3P 1/2 and here, 3P 3/2. ", " And the next state here is 3D.  ", "Now you're combining l equal 2.  So you get 5/2 and 3/2.  The 3/2 is degenerate with this 3/2 because it has the same j. ", "And the 5/2 is a little higher--  3D 5/2.   So this is our final picture. ", "The hydrogen atom, all the states get pushed down.  The various multiplets with different l but the same j ", "are still degenerate.  This formula has no l dependence.  So these two are the same.  These two are the same.  These two are the same.  Moreover, the j multiplets are not split. ", "Every j multiplet differs [? because of ?] a collection  of states with different mj.  But mj doesn't appear.  So this is your fine structure of hydrogen atom. ", "And this is where you study in detail the Zeeman splitting  and the Stark splitting.  And we'll talk a little bit about them  next time, as we will begin, also, ", "our study of the semiclassical approximation.  See you then. "], "vid_duration": [10.1, 10.11, 10.08, 13.07, 14.52, 12.45, 10.57, 12.76, 11.99, 13.18, 11.839, 10.071, 11.22, 12.53, 10.2, 12.13, 13.79, 13.78, 11.03, 11.05, 14.82, 13.22, 10.21, 12.65, 10.94, 12.65, 17.52, 10.37, 14.46, 11.67, 10.74, 13.82, 17.32, 12.91, 11.439, 11.141, 16.102, 19.568, 10.95, 13.03, 11.27, 15.665, 10.815, 15.27, 10.35, 14.02, 12.86, 15.75, 11.25, 10.8, 13.87, 11.57, 10.21, 10.11, 13.964, 17.906, 10.05, 11.34, 11.36, 10.305, 12.125, 10.782, 11.301, 12.0, 10.41, 12.06, 11.16, 12.03, 11.7, 12.27, 10.98, 11.13, 11.77, 10.306, 10.763, 12.151, 13.05, 13.21, 10.55, 10.67, 12.02, 12.9, 11.32, 17.26, 13.72, 12.46, 12.3, 13.209, 13.081, 16.149, 10.0, 16.531, 14.33, 12.94, 13.57, 10.14, 15.989, 10.081, 11.01, 10.56, 13.52, 12.18, 10.61, 21.86, 14.219, 13.46, 10.491, 14.54, 12.66, 11.84, 11.259, 13.861, 10.44, 18.1, 10.599, 14.131, 22.465, 12.565, 10.02, 12.589, 13.581, 10.78, 16.61, 10.95, 12.42, 11.29, 12.05, 10.69, 13.12, 13.16, 15.52, 15.59, 10.83, 14.49, 11.879, 11.581, 13.08, 11.44, 15.08, 12.69, 13.21, 13.54, 12.05, 12.96, 17.71, 11.6, 14.369, 13.261, 19.69, 11.839, 10.556, 10.969, 11.366, 12.79, 11.73, 12.14, 13.26, 10.5, 11.899, 11.951, 12.029, 10.471, 13.98, 10.333, 11.86, 10.21, 11.43, 11.688, 18.117, 12.855, 10.32, 14.47, 11.86, 11.21, 12.34, 12.15, 17.2, 10.97, 12.8, 10.31, 10.97, 10.65, 10.45, 12.17, 13.86, 10.21, 10.91, 17.47, 11.27, 15.71, 13.92, 13.47, 11.85, 10.65, 12.92, 10.21, 13.08, 10.83, 12.0, 10.95, 10.24, 13.23, 12.12, 12.6, 14.387, 11.213, 15.2, 11.4, 21.805, 18.165, 12.03, 17.64, 13.09, 13.08, 12.39, 14.64, 10.36, 15.15, 12.62, 18.13, 11.33, 10.02, 11.58, 12.96, 14.01, 20.4, 12.04, 11.43, 13.32, 10.54, 10.52, 10.25, 13.63, 19.33, 15.93, 11.35, 10.09, 10.75, 16.31, 12.12, 15.33, 11.1, 13.08, 16.21, 12.82, 14.4, 14.55, 10.23, 11.26, 13.29, 14.4, 10.62, 10.41, 12.203, 10.7, 19.05, 10.32, 11.59, 10.47, 10.86, 13.7, 14.03, 10.2, 20.53, 11.28, 15.02, 20.01, 12.71, 12.94, 13.12, 11.97, 10.35, 11.88, 16.99, 10.34, 14.74, 13.14, 14.82, 11.05, 11.61, 12.36, 10.5, 13.0, 16.41, 15.64, 13.36, 10.075, 10.665, 14.34, 13.74, 15.45, 10.6, 10.373, 10.75, 19.96, 12.82, 12.25, 14.44, 11.52, 11.37, 12.22, 14.56, 11.2, 12.81, 10.53, 15.15, 12.84, 15.18, 11.94, 12.84, 10.32, 11.31, 11.19, 11.02, 14.93, 11.67, 11.94, 11.67, 13.54, 15.44, 10.89, 12.99, 12.66, 15.24, 10.6, 11.8, 11.915, 20.495, 10.59, 12.21, 13.42, 10.62, 12.539, 14.721, 14.4, 11.46, 15.84, 13.11, 11.61, 13.03, 12.68, 13.35, 11.82, 10.71, 11.97, 12.85, 10.66, 10.28, 10.56, 13.0, 12.54, 14.29, 15.35, 17.06, 12.54, 12.1, 14.56, 12.46, 12.48, 13.31, 11.61, 14.61, 10.74, 11.97, 3.328], "stet": [[0, 10.1], [10.1, 20.21], [20.21, 30.29], [30.29, 43.36], [43.36, 57.879999999999995], [57.879999999999995, 70.33], [70.33, 80.9], [80.9, 93.66000000000001], [93.66000000000001, 105.65], [105.65, 118.83000000000001], [118.83000000000001, 130.669], [130.669, 140.74], [140.74, 151.96], [151.96, 164.49], [164.49, 174.69], [174.69, 186.82], [186.82, 200.60999999999999], [200.60999999999999, 214.39], [214.39, 225.42], [225.42, 236.47], [236.47, 251.29], [251.29, 264.51], [264.51, 274.71999999999997], [274.71999999999997, 287.36999999999995], [287.36999999999995, 298.30999999999995], [298.30999999999995, 310.9599999999999], [310.9599999999999, 328.4799999999999], [328.4799999999999, 338.8499999999999], [338.8499999999999, 353.3099999999999], [353.3099999999999, 364.9799999999999], [364.9799999999999, 375.7199999999999], [375.7199999999999, 389.5399999999999], [389.5399999999999, 406.8599999999999], [406.8599999999999, 419.7699999999999], [419.7699999999999, 431.20899999999995], [431.20899999999995, 442.34999999999997], [442.34999999999997, 458.45199999999994], [458.45199999999994, 478.0199999999999], [478.0199999999999, 488.9699999999999], [488.9699999999999, 501.9999999999999], [501.9999999999999, 513.2699999999999], [513.2699999999999, 528.9349999999998], [528.9349999999998, 539.7499999999999], [539.7499999999999, 555.0199999999999], [555.0199999999999, 565.3699999999999], [565.3699999999999, 579.3899999999999], [579.3899999999999, 592.2499999999999], [592.2499999999999, 607.9999999999999], [607.9999999999999, 619.2499999999999], [619.2499999999999, 630.0499999999998], [630.0499999999998, 643.9199999999998], [643.9199999999998, 655.4899999999999], [655.4899999999999, 665.6999999999999], [665.6999999999999, 675.81], [675.81, 689.774], [689.774, 707.68], [707.68, 717.7299999999999], [717.7299999999999, 729.0699999999999], [729.0699999999999, 740.43], [740.43, 750.7349999999999], [750.7349999999999, 762.8599999999999], [762.8599999999999, 773.6419999999999], [773.6419999999999, 784.943], [784.943, 796.943], [796.943, 807.353], [807.353, 819.4129999999999], [819.4129999999999, 830.5729999999999], [830.5729999999999, 842.6029999999998], [842.6029999999998, 854.3029999999999], [854.3029999999999, 866.5729999999999], [866.5729999999999, 877.5529999999999], [877.5529999999999, 888.6829999999999], [888.6829999999999, 900.4529999999999], [900.4529999999999, 910.7589999999999], [910.7589999999999, 921.5219999999999], [921.5219999999999, 933.6729999999999], [933.6729999999999, 946.7229999999998], [946.7229999999998, 959.9329999999999], [959.9329999999999, 970.4829999999998], [970.4829999999998, 981.1529999999998], [981.1529999999998, 993.1729999999998], [993.1729999999998, 1006.0729999999998], [1006.0729999999998, 1017.3929999999998], [1017.3929999999998, 1034.6529999999998], [1034.6529999999998, 1048.3729999999998], [1048.3729999999998, 1060.8329999999999], [1060.8329999999999, 1073.1329999999998], [1073.1329999999998, 1086.3419999999999], [1086.3419999999999, 1099.4229999999998], [1099.4229999999998, 1115.5719999999997], [1115.5719999999997, 1125.5719999999997], [1125.5719999999997, 1142.1029999999996], [1142.1029999999996, 1156.4329999999995], [1156.4329999999995, 1169.3729999999996], [1169.3729999999996, 1182.9429999999995], [1182.9429999999995, 1193.0829999999996], [1193.0829999999996, 1209.0719999999997], [1209.0719999999997, 1219.1529999999996], [1219.1529999999996, 1230.1629999999996], [1230.1629999999996, 1240.7229999999995], [1240.7229999999995, 1254.2429999999995], [1254.2429999999995, 1266.4229999999995], [1266.4229999999995, 1277.0329999999994], [1277.0329999999994, 1298.8929999999993], [1298.8929999999993, 1313.1119999999994], [1313.1119999999994, 1326.5719999999994], [1326.5719999999994, 1337.0629999999994], [1337.0629999999994, 1351.6029999999994], [1351.6029999999994, 1364.2629999999995], [1364.2629999999995, 1376.1029999999994], [1376.1029999999994, 1387.3619999999994], [1387.3619999999994, 1401.2229999999995], [1401.2229999999995, 1411.6629999999996], [1411.6629999999996, 1429.7629999999995], [1429.7629999999995, 1440.3619999999994], [1440.3619999999994, 1454.4929999999995], [1454.4929999999995, 1476.9579999999994], [1476.9579999999994, 1489.5229999999995], [1489.5229999999995, 1499.5429999999994], [1499.5429999999994, 1512.1319999999994], [1512.1319999999994, 1525.7129999999993], [1525.7129999999993, 1536.4929999999993], [1536.4929999999993, 1553.1029999999992], [1553.1029999999992, 1564.0529999999992], [1564.0529999999992, 1576.4729999999993], [1576.4729999999993, 1587.7629999999992], [1587.7629999999992, 1599.8129999999992], [1599.8129999999992, 1610.5029999999992], [1610.5029999999992, 1623.6229999999991], [1623.6229999999991, 1636.7829999999992], [1636.7829999999992, 1652.3029999999992], [1652.3029999999992, 1667.8929999999991], [1667.8929999999991, 1678.722999999999], [1678.722999999999, 1693.212999999999], [1693.212999999999, 1705.091999999999], [1705.091999999999, 1716.6729999999989], [1716.6729999999989, 1729.7529999999988], [1729.7529999999988, 1741.1929999999988], [1741.1929999999988, 1756.2729999999988], [1756.2729999999988, 1768.9629999999988], [1768.9629999999988, 1782.1729999999989], [1782.1729999999989, 1795.7129999999988], [1795.7129999999988, 1807.7629999999988], [1807.7629999999988, 1820.7229999999988], [1820.7229999999988, 1838.4329999999989], [1838.4329999999989, 1850.0329999999988], [1850.0329999999988, 1864.4019999999987], [1864.4019999999987, 1877.6629999999986], [1877.6629999999986, 1897.3529999999987], [1897.3529999999987, 1909.1919999999986], [1909.1919999999986, 1919.7479999999987], [1919.7479999999987, 1930.7169999999987], [1930.7169999999987, 1942.0829999999987], [1942.0829999999987, 1954.8729999999987], [1954.8729999999987, 1966.6029999999987], [1966.6029999999987, 1978.7429999999988], [1978.7429999999988, 1992.0029999999988], [1992.0029999999988, 2002.5029999999988], [2002.5029999999988, 2014.4019999999987], [2014.4019999999987, 2026.3529999999987], [2026.3529999999987, 2038.3819999999987], [2038.3819999999987, 2048.8529999999987], [2048.8529999999987, 2062.8329999999987], [2062.8329999999987, 2073.165999999999], [2073.165999999999, 2085.025999999999], [2085.025999999999, 2095.235999999999], [2095.235999999999, 2106.665999999999], [2106.665999999999, 2118.353999999999], [2118.353999999999, 2136.470999999999], [2136.470999999999, 2149.325999999999], [2149.325999999999, 2159.6459999999993], [2159.6459999999993, 2174.115999999999], [2174.115999999999, 2185.975999999999], [2185.975999999999, 2197.1859999999992], [2197.1859999999992, 2209.5259999999994], [2209.5259999999994, 2221.6759999999995], [2221.6759999999995, 2238.8759999999993], [2238.8759999999993, 2249.845999999999], [2249.845999999999, 2262.6459999999993], [2262.6459999999993, 2272.955999999999], [2272.955999999999, 2283.925999999999], [2283.925999999999, 2294.575999999999], [2294.575999999999, 2305.025999999999], [2305.025999999999, 2317.195999999999], [2317.195999999999, 2331.055999999999], [2331.055999999999, 2341.265999999999], [2341.265999999999, 2352.175999999999], [2352.175999999999, 2369.645999999999], [2369.645999999999, 2380.915999999999], [2380.915999999999, 2396.625999999999], [2396.625999999999, 2410.545999999999], [2410.545999999999, 2424.0159999999987], [2424.0159999999987, 2435.8659999999986], [2435.8659999999986, 2446.5159999999987], [2446.5159999999987, 2459.435999999999], [2459.435999999999, 2469.645999999999], [2469.645999999999, 2482.7259999999987], [2482.7259999999987, 2493.5559999999987], [2493.5559999999987, 2505.5559999999987], [2505.5559999999987, 2516.5059999999985], [2516.5059999999985, 2526.7459999999983], [2526.7459999999983, 2539.9759999999983], [2539.9759999999983, 2552.095999999998], [2552.095999999998, 2564.695999999998], [2564.695999999998, 2579.0829999999983], [2579.0829999999983, 2590.2959999999985], [2590.2959999999985, 2605.4959999999983], [2605.4959999999983, 2616.8959999999984], [2616.8959999999984, 2638.700999999998], [2638.700999999998, 2656.865999999998], [2656.865999999998, 2668.8959999999984], [2668.8959999999984, 2686.5359999999982], [2686.5359999999982, 2699.6259999999984], [2699.6259999999984, 2712.7059999999983], [2712.7059999999983, 2725.095999999998], [2725.095999999998, 2739.735999999998], [2739.735999999998, 2750.095999999998], [2750.095999999998, 2765.2459999999983], [2765.2459999999983, 2777.865999999998], [2777.865999999998, 2795.9959999999983], [2795.9959999999983, 2807.325999999998], [2807.325999999998, 2817.345999999998], [2817.345999999998, 2828.925999999998], [2828.925999999998, 2841.885999999998], [2841.885999999998, 2855.8959999999984], [2855.8959999999984, 2876.2959999999985], [2876.2959999999985, 2888.3359999999984], [2888.3359999999984, 2899.7659999999983], [2899.7659999999983, 2913.0859999999984], [2913.0859999999984, 2923.6259999999984], [2923.6259999999984, 2934.1459999999984], [2934.1459999999984, 2944.3959999999984], [2944.3959999999984, 2958.0259999999985], [2958.0259999999985, 2977.3559999999984], [2977.3559999999984, 2993.2859999999982], [2993.2859999999982, 3004.635999999998], [3004.635999999998, 3014.7259999999983], [3014.7259999999983, 3025.4759999999983], [3025.4759999999983, 3041.7859999999982], [3041.7859999999982, 3053.905999999998], [3053.905999999998, 3069.235999999998], [3069.235999999998, 3080.335999999998], [3080.335999999998, 3093.415999999998], [3093.415999999998, 3109.625999999998], [3109.625999999998, 3122.445999999998], [3122.445999999998, 3136.845999999998], [3136.845999999998, 3151.3959999999984], [3151.3959999999984, 3161.6259999999984], [3161.6259999999984, 3172.8859999999986], [3172.8859999999986, 3186.1759999999986], [3186.1759999999986, 3200.5759999999987], [3200.5759999999987, 3211.1959999999985], [3211.1959999999985, 3221.6059999999984], [3221.6059999999984, 3233.8089999999984], [3233.8089999999984, 3244.508999999998], [3244.508999999998, 3263.5589999999984], [3263.5589999999984, 3273.8789999999985], [3273.8789999999985, 3285.4689999999987], [3285.4689999999987, 3295.9389999999985], [3295.9389999999985, 3306.7989999999986], [3306.7989999999986, 3320.4989999999984], [3320.4989999999984, 3334.5289999999986], [3334.5289999999986, 3344.7289999999985], [3344.7289999999985, 3365.2589999999987], [3365.2589999999987, 3376.538999999999], [3376.538999999999, 3391.558999999999], [3391.558999999999, 3411.568999999999], [3411.568999999999, 3424.278999999999], [3424.278999999999, 3437.218999999999], [3437.218999999999, 3450.338999999999], [3450.338999999999, 3462.308999999999], [3462.308999999999, 3472.6589999999987], [3472.6589999999987, 3484.538999999999], [3484.538999999999, 3501.5289999999986], [3501.5289999999986, 3511.868999999999], [3511.868999999999, 3526.6089999999986], [3526.6089999999986, 3539.7489999999984], [3539.7489999999984, 3554.5689999999986], [3554.5689999999986, 3565.618999999999], [3565.618999999999, 3577.228999999999], [3577.228999999999, 3589.588999999999], [3589.588999999999, 3600.088999999999], [3600.088999999999, 3613.088999999999], [3613.088999999999, 3629.498999999999], [3629.498999999999, 3645.1389999999988], [3645.1389999999988, 3658.498999999999], [3658.498999999999, 3668.5739999999987], [3668.5739999999987, 3679.2389999999987], [3679.2389999999987, 3693.578999999999], [3693.578999999999, 3707.3189999999986], [3707.3189999999986, 3722.7689999999984], [3722.7689999999984, 3733.3689999999983], [3733.3689999999983, 3743.7419999999984], [3743.7419999999984, 3754.4919999999984], [3754.4919999999984, 3774.4519999999984], [3774.4519999999984, 3787.2719999999986], [3787.2719999999986, 3799.5219999999986], [3799.5219999999986, 3813.9619999999986], [3813.9619999999986, 3825.4819999999986], [3825.4819999999986, 3836.8519999999985], [3836.8519999999985, 3849.0719999999983], [3849.0719999999983, 3863.6319999999982], [3863.6319999999982, 3874.831999999998], [3874.831999999998, 3887.641999999998], [3887.641999999998, 3898.171999999998], [3898.171999999998, 3913.3219999999983], [3913.3219999999983, 3926.1619999999984], [3926.1619999999984, 3941.3419999999983], [3941.3419999999983, 3953.2819999999983], [3953.2819999999983, 3966.1219999999985], [3966.1219999999985, 3976.4419999999986], [3976.4419999999986, 3987.7519999999986], [3987.7519999999986, 3998.9419999999986], [3998.9419999999986, 4009.9619999999986], [4009.9619999999986, 4024.8919999999985], [4024.8919999999985, 4036.5619999999985], [4036.5619999999985, 4048.5019999999986], [4048.5019999999986, 4060.1719999999987], [4060.1719999999987, 4073.7119999999986], [4073.7119999999986, 4089.1519999999987], [4089.1519999999987, 4100.041999999999], [4100.041999999999, 4113.031999999998], [4113.031999999998, 4125.691999999998], [4125.691999999998, 4140.931999999998], [4140.931999999998, 4151.531999999998], [4151.531999999998, 4163.3319999999985], [4163.3319999999985, 4175.2469999999985], [4175.2469999999985, 4195.741999999998], [4195.741999999998, 4206.3319999999985], [4206.3319999999985, 4218.541999999999], [4218.541999999999, 4231.961999999999], [4231.961999999999, 4242.5819999999985], [4242.5819999999985, 4255.120999999998], [4255.120999999998, 4269.841999999998], [4269.841999999998, 4284.2419999999975], [4284.2419999999975, 4295.7019999999975], [4295.7019999999975, 4311.541999999998], [4311.541999999998, 4324.651999999997], [4324.651999999997, 4336.261999999997], [4336.261999999997, 4349.291999999997], [4349.291999999997, 4361.971999999997], [4361.971999999997, 4375.321999999997], [4375.321999999997, 4387.141999999997], [4387.141999999997, 4397.851999999997], [4397.851999999997, 4409.821999999997], [4409.821999999997, 4422.671999999998], [4422.671999999998, 4433.331999999998], [4433.331999999998, 4443.611999999997], [4443.611999999997, 4454.171999999998], [4454.171999999998, 4467.171999999998], [4467.171999999998, 4479.711999999998], [4479.711999999998, 4494.001999999998], [4494.001999999998, 4509.351999999998], [4509.351999999998, 4526.411999999998], [4526.411999999998, 4538.951999999998], [4538.951999999998, 4551.051999999999], [4551.051999999999, 4565.611999999999], [4565.611999999999, 4578.071999999999], [4578.071999999999, 4590.551999999999], [4590.551999999999, 4603.861999999999], [4603.861999999999, 4615.471999999999], [4615.471999999999, 4630.0819999999985], [4630.0819999999985, 4640.821999999998], [4640.821999999998, 4652.791999999999], [4652.791999999999, 4656.119999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [768, 2073, 3227, 3736, 4656]}
{"example_id": "mit038@@MIT8_06S18_L17_300k", "text": ["PROFESSOR: Today, we're going to continue  with the adiabatic subject.  And our main topic is going to be Berry's Phase.  It's interesting part of the phase ", "that goes in adiabatic process.  And we want to understand what it is  and why people care about it.  And then, we'll turn to another subject ", "in which the adiabatic approximation is of interest.  And it's a subject of molecules.  So I don't think I'll manage to get through all of that today, ", "but will we'll make an effort.  So let me remind you of what we had so far.  So we imagine we have a Hamiltonian that ", "depends on time and maybe had no dependents  before time equals 0 turns on.  And it has no further variation after some time t. ", "So the Hamiltonian changes like that.  And the adiabatic theorem states that if you ", "have a state at time equals 0, which  is a particular instantaneous eigenstate, that ", "is the instantaneous eigenstate, then  that's the full wave function at time equals 0 and it coincides.  Then, at time at any time in this process, if it's slow, ", "the process, the state of the system,  the full wave function, psi of t,  will tend to remain in that instantaneous eigenstate. ", "And the way it's stated precisely  is that psi of t minus--  I'll write it like this--  psi prime n of t, the norm of this state ", "is of order 1/T for any t in between 0 and T. ", "So I'm trying to state the adiabatic theorem in a way that  is mathematically precise.  And let me remind you the norm of a wave function ", "is you integrate the wave function square  and take the square root.  It's sort of the usual definition  of the norm of a vector is the inner product of the vector ", "with itself square root.  So that's the norm for wave function.  And here, what this means is that with some suitable choice ", "of phase, the instantaneous eigenstate  is very close to the true state.  And the error is a Fourier 1/T. So if the process is slow, ", "it means that the change occurs over long t,  this is a small number.  And there is some instantaneous eigenstate ", "with some peculiar phase--  that's why I put the prime--  for which this difference is very small.  And we calculated this phase, and we ", "found the state, psi of t is roughly equal  to e to theta n of t, e to the I gamma n of t, psi n of t. ", " And in this statement, this is what I would  call the psi n prime of t. ", "And that's why the real state is just approximately  equal to that one.  And we have these phases in which theta of t is minus 1 ", "over h bar integral from 0 to t E n of t prime dt prime.  That is kind of a familiar phase. ", "If you had a normal energy eigenstate, time independent 1,  this would be 1 to the--  well, would be minus e times t over h bar with an I ", "would be the familiar phase that you  put to an energy eigenstate.  Then it comes the gamma n of t, which  is an integral from 0 to t of some new n of t prime dt prime. ", "And this new n of t is I psi n of t psi n dot of t. ", " I think I have it right.  So the second part of the phase is the integral ", "of this new function.  And this new function is real, because this part  we showed before is imaginary, where with an I, this is real. ", "And this second part, this gamma n,  is called the geometric phase.  This is the phase that has to do with Berry's phase. ", "And it's a phase that we want to understand.  And it's geometrical because of one reason  that we're going to show that makes  it quite surprising and quite different from the phase theta. ", "The phase theta is a little like a clock,  because it runs with time.  The more time you wait on an energy ", "eigenstate, the more this phase changes.   What will happen with this geometric phase ", "is that somehow properly viewed is  independent of the time it takes the adiabatic process to occur. ", "So whether it takes us small time or a long time  to produce this change of the system,  the geometric phase will be essentially the same. ", "That's very, very unusual.  So that's the main thing we want to understand  about this geometric phase, that it depends only ", "on the evolution of the state in that configuration space--  we'll make that clear, what it means--  and not the time it takes this evolution to occur. ", "It's a little more subtle, this phase, than the other phase.  So I want to introduce this idea of a configuration space.  So basically, we have that-- ", "let me forget about time dependence for one second  and think of the Hamiltonian as a function  of a set of coordinates, or parameters. ", "So the Rs are some coordinates.  R1, R2, maybe up to R capital N are some coordinates ", "inside some vector space RN.   So its N components.  And what does that mean?  It means maybe that your Hamiltonian ", "has capital N parameters.  And those are these things.  So you buy this Hamiltonian.  It comes with some parameters. ", "You buy another one.  It comes with another set of parameters.  Those parameters can be changed.  Or you construct them in the lab, your Hamiltonians  with different parameters. ", "Those are the parameters of the Hamiltonian.  ", "And suppose you have learned to solve  this Hamiltonian for all values of the parameters.  That is whatever the Rs are you know how ", "to find the energy eigenstates.  So H of R times--  there are some eigenstates, psi n of R with energies En of R, ", "psi n of R. And n maybe is 1, 2, 3.  And these are orthonormal states, ", "those energy eigenstates.   So this equation says that you have  been able to solve this Hamiltonian whatever ", "the values of the parameters are.  And you have found all the states of the system,  n equal 1, 2 3, 4, 5, 6.  All of them are in now. ", "So this is a general situation.  And now, we imagine that for some reason,  these parameters start to begin to depend on time. ", "So they become time dependent parameters--   can become time dependent. ", "So that you now have R of t vector.  These are 1 of t up to our Rn of t.  ", "So how do we represent this?  ", "Well, this is a Cartesian space of parameters.  This is not our normal space.  This is a space where one axis could be the magnetic field. ", "Another axis could be the electric field.  Another axis could be the spring constant.  Those are abstract axis of configuration space. ", "Or this could be R1, R2, the axis, R3.  And those are your axes. ", "And now, how do you represent in this configuration space  the evolution of the system? ", "What is the evolution of the system in this configuration  space?   How does it look?  Is it a point? ", "A line?  A surface?  What is it?   Sorry? ", "STUDENT: A path.  PROFESSOR: It's a path.  It's a line.  Indeed, you look at your clock.  And at time equals 0, well, it takes some values.  And you're fine, OK, here it at time equals 0. ", "At time equal 1, the values change.  There's one parameter, which is time.  So this traces a path.  As time goes by, the core in this changing in time and this ", "is a line parameterized by time--  so a path gamma parameterized by time. ", "And that represents the evolution of your system.  At time equals 0, this point could be R at t equals 0. ", "And maybe this point is R a t equal T final.  And this system is going like that. ", "You should imagine the system as traveling in that configuration  space.  That's what it does.  That's why we put the configuration space. ", "And we now have a set--  not the set-- a time dependent Hamiltonian,  because while H was a function of R from the beginning, now ", "R is a function of time.  So this is your new Hamiltonian.  And this is time dependent--  dependent Hamiltonian. ", " But now, the interesting thing is  that the work you did before in finding the energy ", "eigenstates for any position in this configuration space  is giving you the instantaneous energy eigenstates, ", "because if this equation here holds for any value of R,  it certainly holds for the values of R corresponding ", "to some particular time.   So psi n of R of t is equal to En of R of t psi n of R of t. ", "So it's an interesting interplay in which  the act that you know your energy eigenstates everywhere  in your configuration space allows ", "you to find the time evolved states,  the time dependent energy eigenstates, the instantaneous ", "energy eigenstates are found here.  So what we want to do now is evaluate in this language  the geometric phase, this phase. ", "I want to understand what this phase is  PROFESSOR: I now have that new n of t that we wrote there. ", "I have to write it as what it is.  It's i psi n of r of t times-- ", "I will write it here this way-- d dt--  the dot will be replaced by the d dt--  psi n of r of t. ", " And then, of course, the gamma n of t  will be just the integral from 0 to t ", "of new n of t prime bt prime.  So that's the next step.   Well, if you have to differentiate ", "a function that depends on r of t, what do you have?  Let me do it for a simpler case, d dt of f of r of t. ", "This means d dt of a function of r1 of t  are all the ones up to rn of t. ", " And what must you do?  Well, you should do df dr1 times dr1 dt ", "all the way up to the df dr and drn dt.  You want to find the time dependence of a function that ", "depends on a collection of time-dependent coordinates.  Well, the chain rule applies.   But this can be written in a funny language-- ", "maybe not so funny--  as the gradient sub r vector of f dotted dr vector dt. ", " See, the gradient, in general, is d dx1 d dx2 d dx3.  It's a vector operator. ", "The gradient sub r would mean d dr1 d dr2 d dr3,  just the gradient in this Euclidean vector ", "space times dr dt.  So that's what I want to use for this derivative.  I have to differentiate that state. ", "And therefore, I'll write it that way.   So gamma n of t is equal to i, from the top line, ", "psi n of r of t times gradients of r acting on the state psi ", "n of r of t dotted with dr dt. ", " This is dot product.  So just to make sure you understand here, ", "you have one ket here, and you have this gradient.  So that gives you capital N components, ", "the derivative of the ket with respect to r1 r2 r3 r4.  Then with the inner product, it gives your capital  N numbers, which are the components of a vector that is ", "being dotted with this vector.  It's all about trying to figure out  that this language makes sense. ", "If this made sense to you, this should make sense,  a little more, maybe a tiny bit more confusing. ", "But maybe you should write it all out.  What do you think it is?  And that might help you.  Or we could do that later.  So if we have that, we can go to gamma n, the geometric phase. ", "So this is 0 2t, the integral with respect to prime time,  so new m. ", "So it's i psi n r of t prime--  there's lots of vectors here, gradient r vector ", "of psi n r of t prime dotted dr dt prime dt prime. ", "That's the last dt prime.   And the good thing that happened, the thing that ", "really makes all the difference, the thing that  is responsible for that conceptual thing  is just this cancellation. ", "This cancellation means that you can think of the integral  as happening just in the configuration space.  This is not really an integral over time. ", "This is an integral in configuration space  because now this integral is nothing else than the integral ", "over the path gamma.  Because the path gamma represents  the evolution of the coordinate capital R from 0 to time t. ", "This is nothing else than the integral over the path  gamma of i psi n of r--  I don't have to write the t anymore-- ", "dr psi n of r--  again no t-- dot dr. And this is the geometric phase gamma n ", "that depends on r on the path.  I'll write it like that.  You see, something very important has happened here. ", "It's a realization that time plays no role anymore.  This is the concept.  This is what you have to struggle to understand here. ", "This integral says take this path.  Take a little dr dot it with this gradient of this object, ", "which is kind of the gradient of this ket, which is  a lot of kets with this thing.  So it's a vector.  Dot it with this and integrate.  And time plays no role. ", "You just follow the path.  So whether this thing took one minute  to make the path or a billion years, ", "the geometric phase will be exactly the same.  It just depends on the path it took. ", "Time for some names for these things.   Let's see.  ", "So a first name is that this whole object ", "is going to be called the Berry connection.   i psi n of r gradient r psi n of r ", "is called the Berry connection a n vector of r.  Berry connection. ", " OK, a few things to notice, the Berry connection ", "is like a vector in the configuration space.  It has capital N components because this is a gradient. ", "And therefore, it produces of this ket n kets  and, therefore, n numbers because of the bra.  So this is a thing with capital N components. ", " So it's a vector in RN.  But people like the name connection. ", "Why Connection?  Because it's a little more subtle than a vector.   It transforms under Gage transformation, ", "your favorite things.  And it makes it interesting because it transforms  under Gage transformation.  We'll see it in a second.  So it's a connection because of that. ", "And there's one Berry connection for every eigenstate  of your system.  Because we fix some n, and we got the connection. ", "And we're going to get different connections for different n's.  So n components, one per eigenstate, ", "and they live all over the configuration space.  You can ask, what is the value of the Berry  connection at this point?  And there is an answer. ", "At every point, this connection exists.   Now, let's figure out the issue of gauge transformations here. ", "And it's important because this subject somehow--  these formulas, I think in many ways, ", "were known to everybody for a long time.  But Berry probably clarified this issue of the time ", "independence and emphasized that this could  be interesting in some cases.  But in fact, in most cases, you could say ", "they're not all that relevant.  You can change them.  So here is one thing that can happen.   You have your energy eigenstates, ", "your instantaneous eigenstates.  You solve them, and you box them.  You're very happy with them.  But in fact, they're far from unique. ", "Your energy eigenstates, your instantaneous energy  eigenstates can be changed.  If you have an energy eigenstate psi n of r-- ", "that's what it is--  well, you could decide to find another one.  Psi prime of r is going to be equal to e to the minus ", "some function, arbitrary function, of r times this.   And these new states are energy eigenstates, ", "instantaneous energy eigenstates that  are as good as your original psi n  because this equation also holds for the psi n primes. ", "If you add with the Hamiltonian, the Hamiltonian in here  just goes through this and hits here, produces the energy, ", "and then the state is just the same.   The r of t's are parameters of the Hamiltonian. ", "They're not operators.  So there's no reason why the Hamiltonian  would care about this factor.  The r's are just parameters. ", "Yes?  AUDIENCE: [INAUDIBLE]  PROFESSOR: No, they're still normalized.  I should put a phase here-- thank you very much-- ", "minus i.  Thank you.  Yes, I want the states to be normalized,  and I want them to be orthonormal.  And all that is not changed if I put them phase. ", "So this is the funny thing about quantum mechanics.  It's all about phases and complex numbers.  But you can, to a large degree, change those phases at will. ", "And whatever survives is some sort of very subtle effects  between the phases.  So here I put the i and beta of r is real. ", " PROFESSOR: So you can say let's compute the new Berry  connection associated with this new state a n prime of r. ", "So I must do that operation that we have up there  with the news state.  So I would have i psi n of r times e to the i beta of r. ", "That's The bra.  Then I have dr and now the ket, e to the minus i beta of r ", "psi n of r.  So this is, by definition, the new Berry connection  associated to your new, redefined eigenstates. ", " Now this nabla is acting on everything to the right.  Suppose it acts on the state and then the two exponentials ", "will cancel, and then you get the old connection.  So there is one term here, which is just the old a n of r. ", " There's all these arrows there.  There's probably five arrows at least I miss on every board.  Here is a 1, 2, 3, 4 5. ", " OK, so this is the first one, and then you  have the term for this gradient acts on this exponential. ", "When the gradient acts on the exponential,  it gives the same exponential times  the gradient of the exponent.  The exponentials then cancel. ", "The gradient of the exponent would give me plus i times  minus i gradient of beta.  ", "Maybe I'll put the r of the r.  And then these cancel, and you have the state with itself,  which gives you 1. ", "So that's all it is, all that the second term gives you.  So here we get a n of r plus gradient r of beta of r. ", " So this is the gauge transformation. ", "And you say, wow, I can see now why  this is called a connection.  Because just like the vector potential ", "under a gauge transformation, it transforms  with a gradient of a function.  So it really transforms as a vector potential, all ", "in this space called the configuration space,  not in real space.  In the configuration space it acts like a vector potential. ", "And that's why it's called a connection.  But let's see.  We have now what happens to the connection.  Let's see what happens to the Berry's phase if you do this. ", "So the Berry's phase over there is this integral.  ", "So the Berry's phase can change.  ", "And let's see what happens to the Berry's phase.  So what is the geometric phase gamma n of gamma? ", "In plain language, it is the integral over gamma--  from here, I'm just copying the formula--  of a n of r, the Berry connection, times dr. ", "So what is the new Berry phase for your new instantaneous  energy eigenstates? ", "Now you would say, if the Berry phase  is something that is observable, it better not  depend just on your convention to choose  the instantaneous energy eigenstates. ", "And this is just your convention.  Because if a problem is sufficiently messy,  I bet you guys would all come up with different energy ", "eigenstates because the phases are chosen in different ways.  So it better not change if the Berry phase  is to be significant. ", "So what is the prime thing?  Well, we still integrate over the same path, but now  the prime connection--  ", "but that is the old connection a n of rd r,  the old Berry's phase, plus the integral over gamma, ", "or I will write it from initial the final r.   Maybe I should have ir and i f in the picture. ", "If you want to, you can put this r of time equals 0 as ri  and r of time equal tf is rf the extra term, ", "the gradient of beta dot dr. So this is the old Berry phase. ", "So the new Berry phase is the old Berry phase.  And how about the last integral?  Does it vanish? ", "No, it doesn't vanish.  It gifts you.  But in fact, it can be done.  This is like derivative times this thing, ", "so it's one of those simple integrals.  The gradient times the d represents the change  in the function as you move a little dr. ", "So when you go from ri to rf, the integral of the gradient  is equal to the function beta at rf  minus the function beta on ri. ", "This is like when you integrate the electric field  along a line, and the electric field  is the gradient of the potential.  The integral of the electric field through a line ", "is the potential here minus the potential there.  So here this is plus beta or rf minus beta of ri. ", " So it's not gauge invariant in the Berry phase.  ", "And therefore, it will mean that most of the times it cannot be  observed.  It's not gauge invariant. ", "Whatever is not gauge invariant cannot be observed.  You cannot say you make a measurement and the answer is  gauge-dependent because everybody is going to get ", "a different answer.  And whose answer is right?  That's not possible.  So if this Barry phase seems to have failed a very basic thing, ", "then it's not gauge-invariant.  But there is one way in which this gets fixed.  If your motion in the configuration space ", "begins and ends in the same place, these two will cancel.  And then it will be gauge-invariant. ", "So the observable Berry's phase is a geometric phase  accumulated by the system in a motion in a configuration space ", "where it begins and ends in the same point.  Otherwise, it's not observable.  You can eliminate it.  And so this is an important result ", "that the geometric Berry phase for a closed path ", "in the configuration space is gauge-invariant. ", " PROFESSOR: So my comments. ", " First one-- if the psi n of t can be chosen to be real, ", "the geometric face vanishes.  ", "So why is that?  The geometric face is, remember, the integral  of this new factor, which was i psi n of t psi n of t dot. ", "You had to integrate that thing to get the geometric face.  We explained that this quantity in general is-- ", "well, in general, it's always imaginary, this quantity.  And then with an i, this is a real quantity  which we've been using.  But if this is imaginary-- look at this. ", "This is imaginary.  How can it be imaginary if psi is real?  It can't be.  If psi is real, imagine doing that integral. ", "You can kind of imagine.  So it has to be 0 if psi is real.  Yes?  AUDIENCE: [INAUDIBLE].  Why did we say that was imaginary?  PROFESSOR: We proved this was imaginary. ", "We did calculate the derivative with respect to time of psi  with psi, and we proved that this was imaginary.  And now I'm saying if this was imaginary but if psi is real, ", "the only possibility is that this is 0.  But you can prove, in fact, that this is 0, if this is real.  I can do it in a second. ", "It's i integral psi n of p-- because it's real--  d dt of psi n of t.  Output an x here, and this is dx. ", "That's what it is if psi is real.  Otherwise there would be a star here.  But if it's real, there's no star.  But this is just the integral of 1/2 ", "of d dt of psi of x and t squared dx.  The d dt is that. ", "And then the d dt goes out of the integral--  so this is i over 2 d dt of the integral  of psi squared of x and t dx. ", "But that integral is 1, so the derivative is 0.  So there's no geometric face.  So if you have real instantaneous eigenstates, ", "don't even think of Berry's phase.  There's another case where you don't get a Berry's phase.  ", "So when I'm speaking of Berry's phase at this moment,  I mean the Berry's phase from a closed pathing configuration  space. ", "So if the configuration space is one-dimensional,  the Berry phase vanishes.  Barry's phase vanishes for 1v configuration space. ", " Why is that?  Well, what do we have to do?  The Berry's phase will be the integral over the closed path ", "in the configuration space psi of r d, d r--  because there's just one side of r-- ", "d r.  You have to integrate that thing.  That is the Berry phase-- is the integral of the Berry ", "connection over--  this is capital R--  over the space.  But now, if this configuration space is one-dimensional-- ", "this is r--  a closed path is a path that goes like this and black.  It retraces itself. ", "So it integrates this quantity with increasing r,  and then it integrates the same quantity  with decreasing r, and the two cancel, ", "and this phase is equal to 0.  So you cannot get a Berry's phase if you have one  dimension.  You cannot get the Berry's phase if you have real instantaneous ", "eigenstates.  But you can get a Berry's phase in two dimensions,  in three dimensions, and there are several examples. ", "I will mention one example, and and then  leave Barry's phase for some exercises.  So in 3D, for example-- ", "3D's nice.  A 3D configuration space is the perfect place  to confuse yourself, because you have ", "three dimensions of configuration  and three dimensions of space.  So nice interplay between them--  r1, r2, r3. ", " And then you have an integral-- the Berry's phase  is an integral-- over a closed path here. ", "So let's call gamma and let's call this surface, s,  whose boundary is gamma.  So what is the Berry phase?  The Berry phase is the integral over gamma ", "of the Berry connection d r.   But what is that?  That is, by Stokes' theorem, the integral ", "over the surface of the curl of the Berry  connection times the area.  ", "And so the area on that surface.  Stokes' theorem-- remember in E&M? ", "So here was a vector potential gives you a magnetic field--  so the integral of a along a loop  was equal to the flux of the magnetic field ", "through the surface.  And now the berry phase along the loop  is equal to the integral of the-- ", "we should call it Berry magnetic field?  No.  When people think berries--  curvature.  As in the sense that the magnetic field is the curvature ", "of that connection.  So this is called the Berry's curvature,  but you think about magnetic field--  Berry's curvature.  ", "So the Berry's curvature-- people  go with d is the curl sub r of the Berry connection a of r. ", " It's the magnetic field, so it's the integral  of d over that surface.  So they're nice analogies. ", " So one example you will do in recitation--  I hope-- you have Max over there-- ", "is the classic example of a spin in a magnetic field.  So I will just say a couple of words as an introduction, ", "but it's a very nice computation.  It's a great exercise to figure out  if you understand all these things. ", "It's done in [INAUDIBLE] explicitly in some ways,  and it's a great thing to practice.  So if you want the little challenge-- ", "I know you're busy with papers and other things.  but the idea is that you have a magnetic field-- ", "the cogs of a magnetic field, B0n--  along some direction n, and you have a spin 1/2 particle  pointing in that direction n. ", "But then you start letting it vary in time--   that unit vector.  So this unit vector varies in time and traces a path. ", " And if it's idiomatic process, the spin ", "will remain in the instantaneous energy eigenstate, which  is spin up in this direction, and it will track  the magnetic field, basically. ", "There will be some small probability it flips,  but it's small.  And if this is an idiomatic process,  that error can be small. ", "So as you move around here, there will be a geometric face,  and the geometric face is quite nice.  So for the spin up state-- ", "m+ state-- if it follows this thing,  the geometric phase for the spin up state in this closed path ", "in configuration space--  this is the configuration space of the magnetic field--  will just be given by minus 1/2. ", "This comes from spin 1/2 times an invariant  of this loop, which is the solid angle traced by this loop. ", "So the geometric phase that's acquired by this motion  is proportional just to the solid angle of this loop.  PROFESSOR: The molecules and Born-Oppenheimer approximation. ", "", "OK, we all know that molecules are  a lot harder to solve than atoms,  and even atoms are not that easy once you ", "have more than one electron because  of the electrostatic repulsion, but molecules  are significantly different in that one of the greatest ", "simplicities that we had with atoms  is that the atom is such that the potential created  by the nucleus is spherically symmetric. ", "When you have a molecule you have separate nuclei  and therefore your spherical symmetry is gone, ", "and whether you have one electron  or more than one electron, there is no spherical symmetry.  All our tools of angular momentum don't help us much. ", "We have to start the problem anew.  So the difficulty with molecules is basically  that the potential for the electrons, where they move ", "is not spherically symmetric.  There is another thing that helps  us, however, is that there's a nice separation of mass scales. ", "You have the mass, little m, of the electron  and the nuclear mass, this could be the mass of one nucleus  or a mass of a few nuclei or doesn't matter, ", "but this is small, and typically it is 10 to the minus 4.  You know, an electron is about 2,000 times lighter ", "than a single proton.  If you already have a nice nucleus with a couple of them,  you're several thousandths already there,  so this is a nice number. ", "So we want to understand the scales of the physics of this,  so let's assume we have a molecule,  maybe a has few centers and then there's electronic cloud, ", "and it has a size of the order of a.  So we can estimate at first sight what ", "are the energies involved here?  What is the energy of the electron, for example?  And you can say the momentum of the electron  is of the order of h bar times the size of the cloud. ", " It's an estimate, and the energies, the electron ", "energies, are basically determined  by the size in which there are confined,  which is a, h bar, and the mass of the electron. ", "Those are the electronic energy, so h squared over  m a squared, those are the right units, ", "is p squared over m, the units, so it's natural like this.   So this is the electronic configuration ", "and typical electronic energy, so what  is the approximate picture of the physics of a molecule? ", "Basically you have nuclei, and the nuclei repel each other,  they want to be away. ", "Now the electrons come in and then they  fly around the nuclei, and the electrons attract the nuclei ", "and attract the nuclei, so the electrons, reasonably placed,  compensate the repulsion of the nuclei  by creating some new attraction. ", "At the end you get some kind of equilibrium.  It's not classical because you cannot create stable  equilibrium between classical particles. ", "This is one of the amazing things about quantum mechanics.  You know very well an atom would not  exist without quantum mechanics, you ", "would have stable classical orbits, circular orbits,  but they radiate energy so they decay.  If you have a molecule you have two repelling positive ", "charged particles.  In [? E&M ?] you saw the case when  you put the negative charge in the middle  and you create equilibrium, but that's absolutely unstable.  You move that electric charge a micron and then off it goes, ", "the whole thing is unstable.  But quantum mechanics solves those problems  and our physical picture is that of repelling nuclei, ", "an attracting cloud of electrons creating  an equilibrium in which the nuclei are reasonably  well-localized, they're quantum particles ", "but they're reasonably well-localized,  while the electrons are completely delocalized.  That is our picture, they are moving in that way. ", "So our picture will be-- we have that  and we have slow vibrations of the nuclei that  are mostly localized. ", "And you can imagine calculating the electronic configuration  for any particular separation of the nuclei ", "and that's the cloud for this separation.  As the nuclei vibrate, the electronic configuration  probably adjusts adiabatically to this thing ", "in the instantaneous eigenstates,  and they work that way.  We're going to do that in trying to understand things. ", "I also want to emphasize this kind  of remarkable property of an electron  to create the bound state. ", "So we are not amazed on the fact that if we have a proton  and we can have an electron here, we create a bound state, ", "and that's a hydrogen atom.  But suppose I bring in another proton from infinity. ", "Well, I-- if I bring it, I'm going  to start bringing it here, this kind of is neutral  but eventually this proton is gonna polarize this thing. ", "OK, I'm going to bring it and then if I come too close  it repels it so it will be a force repelling it  and we have to figure out what it does. ", "Suppose I try to bring it in.  Do you think that an electron is capable of stabilizing ", "two protons?  Can they create a cloud in which an electron stabilizes the two ", "protons?  Is that possible or not possible?  There's a lot of protons for one single electron.  Is that possible or not? ", "All right, you say yes, yes, any other opinions?   Can that happen? ", "Can the electric produce a bound state of two protons like that?  AUDIENCE: Isn't that just hydrogen?  PROFESSOR: Sorry?  AUDIENCE: Isn't that just hydrogen?  PROFESSOR: It is what? ", "AUDIENCE: Isn't that just hydrogen?  Or [INAUDIBLE] hydrogen [INAUDIBLE]??  PROFESSOR: OK, yes, it can produce it,  and this would be called, with an electron here, ", "the hydrogen molecule ion, so H2+.   It's a hydrogen molecule that had these two things ", "and it lost one electron, and yes, this can be done  and we'll analyze it.  And now you can get greedy and say, ", "can you get an electron to stabilize three protons?   Yes or no?  ", "AUDIENCE: [INAUDIBLE]  PROFESSOR: No, cannot get it, it's just too much work  for an electron.  It cannot do it. ", "There are theorems like that, Elliott  Lieb, a mathematical physicist, has proven  all kinds of these things, and we  might discuss some of that in the homework,  it's kind of nice stuff. ", "So we will be looking at the physics of those things  with a little detail.  So now of let's go back to our molecule  here and estimate the vibrational nuclear energy. ", " So we have this picture, the electrons are there,  the nuclei are kind of semi-classical, ", "they are roughly localized and they're varying,  and how would we estimate the nuclear vibration frequency? ", "So estimate nuclear vibration.  ", "So we think of a harmonic oscillator,  b squared over 2 mass of the nucleons,  plus a restoring force, H subnuclear oscillation. ", "So this is an estimate so it's not very rigorous,  but I think it will be clear enough.  Now this restoring force has to do ", "with the cloud of the electrons that adjusts and does things.  As you separate the nuclei you have  to restore the restoring energies ", "due to the electrons and the Coulomb forces,  but it does not depend on the mass, M, the restoring force.  So this k depends on the electrons and Coulomb forces ", "but definitely not on the mass of this quantity.  So k has units of E over L squared, ", "and for energy we have this energy  of the electron and length, the length,  the scale of the molecule, so k is proportional to h ", "squared over ma to the fourth.  It just cannot depend on the mass of the nuclei,  that's definitely not the origin of the restoring force, ", "so if the only mass you can use is the mass of the electron it  can only be that.  But then the frequency, omega, is square root ", "of k over M, that is the mass of the nuclei,  so the nuclear frequency is this,  and it's therefore equal to h squared ", "over ma fourth one over M, that was k,  and this is square root of little m over capital M times ", "square root of h squared over m squared a to the fourth,  I borrowed a little m up and a little m down. ", "So from here we get that h bar omega  nuclear is square root of little m over capital M, ", "h squared over ma squared.  If you take the square root here you get h bar over ma squared,  but there was another h bar I put in. ", "And now we get a sensible equation  in which we see that the nuclear energies for oscillation ", "are much smaller, significantly smaller,  so E nuclear oscillations go like square root of m over M ", "is 10 to the minus 4, we say square root is 10  to the minus 2, times E electronic.  ", "So it's considerably less which is this, so if you think-- ", "I want to make another observation here on timescales,  so omega n, we have it here, omega n, ", "or we have it here as well, is equal to this times  this quantity, so let me say it this way. ", "The omega electronic for vibrations  is the electronic energy divided by h bar, I need h bar over ma ", "squared, but here we see that that's precisely  that square root, so the omega nuclear is ", "equal to little m over M omega electronic.  Now that is nice because it says that the frequency associated ", "to the nuclear thing is much smaller  than the timescales associated with electronic changes.  So this is a good reason for our idiomatic thinking ", "that as the nuclei slowly oscillate,  the electronic cloud remains in that particular eigenstate ", "and thus and jump.  It's our use of the adiabatic approximation.  A last comment is that the rotational energy ", "of the molecule goes like the angular momentum squared  over twice the moment of inertia,  L squared is h squared times some numbers, ", "as usual, L times L plus 1, and here  you get the mass of the molecule times the size squared  of the molecule.  These energies are like little m over capital M times, ", "this is roughly h squared over little ma squared,  and therefore the rotational energies  are even smaller than the electronic energies. ", "The rotational energies go like little m  over capital M times the electronic energies.  ", "So you have the electronic energies, the nuclear energies  of oscillation, which go like square root,  and then finally the smallest of them ", "are the rotation, in which the molecule rotates  like a solid object.  We'll continue this next time and calculate a few more  things and molecules. "], "vid_duration": [11.96, 12.18, 10.11, 12.9, 14.01, 10.88, 12.72, 13.08, 16.6, 19.73, 10.69, 11.42, 15.15, 11.13, 14.76, 11.05, 11.11, 16.16, 11.67, 16.24, 11.25, 13.77, 17.76, 12.518, 10.422, 14.64, 11.17, 16.52, 10.09, 11.9, 13.44, 12.38, 10.29, 14.64, 13.7, 13.46, 12.84, 12.28, 10.26, 10.14, 13.82, 11.43, 21.12, 16.92, 11.57, 11.1, 13.96, 15.09, 15.01, 10.31, 11.76, 10.77, 11.32, 11.0, 10.04, 10.382, 13.868, 14.37, 19.2, 11.31, 10.14, 10.27, 12.86, 11.28, 12.69, 11.31, 13.17, 19.68, 12.21, 11.82, 15.03, 10.758, 10.549, 10.692, 10.909, 13.09, 16.309, 10.151, 18.089, 11.911, 16.149, 15.301, 10.44, 11.25, 11.98, 16.63, 14.23, 10.5, 12.21, 11.9, 13.9, 10.58, 10.48, 18.09, 10.16, 10.93, 14.76, 10.41, 11.7, 13.41, 11.23, 13.14, 12.54, 25.71, 11.52, 11.6, 15.94, 12.05, 13.36, 10.059, 14.221, 17.12, 19.01, 12.439, 10.52, 11.221, 12.64, 13.639, 11.291, 12.25, 10.439, 15.361, 10.68, 13.81, 10.94, 10.229, 12.241, 11.969, 11.671, 13.5, 13.89, 14.27, 11.07, 11.4, 10.55, 10.73, 10.649, 13.04, 12.631, 11.9, 18.335, 15.384, 11.671, 13.82, 14.07, 11.58, 14.964, 15.266, 10.71, 12.93, 10.578, 15.871, 11.391, 10.2, 12.449, 12.401, 14.9, 10.13, 12.93, 15.31, 17.92, 10.65, 11.97, 12.96, 11.11, 12.73, 14.1, 11.48, 16.25, 15.38, 11.18, 11.57, 12.03, 11.88, 11.49, 13.81, 10.61, 10.09, 10.71, 12.21, 14.04, 11.86, 11.77, 11.609, 37.811, 14.625, 10.415, 21.05, 12.91, 15.18, 12.6, 12.51, 13.07, 13.93, 14.61, 10.17, 15.84, 13.89, 12.2, 13.09, 10.79, 13.16, 10.64, 22.375, 10.255, 11.58, 10.77, 11.35, 11.21, 12.24, 12.27, 10.53, 13.75, 10.1, 10.77, 11.51, 14.33, 12.04, 11.96, 10.53, 10.01, 11.2, 10.62, 12.436, 10.784, 11.68, 10.12, 11.019, 11.741, 10.79, 10.79, 13.85, 12.84, 11.34, 12.84, 10.48, 12.35, 13.98, 12.14, 14.24, 24.128, 10.3, 12.9, 13.32, 13.17, 10.18, 12.99, 11.64, 10.6, 12.88, 11.28, 10.3, 15.16, 12.0, 14.745, 11.245, 11.97, 12.33, 14.8, 11.46, 10.2, 11.35, 11.4, 10.94, 11.22, 12.21, 14.46, 12.09, 12.24, 13.33, 12.93, 11.23, 12.32, 10.41, 11.77, 17.09, 14.81, 13.65, 10.69, 13.76, 10.53, 10.41, 10.03, 10.19, 13.09, 11.01, 12.27, 11.784, 11.376, 12.76, 20.595, 10.675, 10.02, 10.1, 20.1, 10.77, 12.05, 15.49, 14.08, 14.99, 10.62, 11.43, 11.64, 21.11, 11.9, 13.92, 13.03, 14.25, 14.13, 10.23, 10.63, 14.99, 11.2, 13.32, 15.8, 14.82, 14.19, 10.39, 11.21, 12.81, 19.198, 13.832, 13.65, 11.01, 8.574], "stet": [[0, 11.96], [11.96, 24.14], [24.14, 34.25], [34.25, 47.15], [47.15, 61.16], [61.16, 72.03999999999999], [72.03999999999999, 84.75999999999999], [84.75999999999999, 97.83999999999999], [97.83999999999999, 114.44], [114.44, 134.17], [134.17, 144.85999999999999], [144.85999999999999, 156.27999999999997], [156.27999999999997, 171.42999999999998], [171.42999999999998, 182.55999999999997], [182.55999999999997, 197.31999999999996], [197.31999999999996, 208.36999999999998], [208.36999999999998, 219.47999999999996], [219.47999999999996, 235.63999999999996], [235.63999999999996, 247.30999999999995], [247.30999999999995, 263.54999999999995], [263.54999999999995, 274.79999999999995], [274.79999999999995, 288.56999999999994], [288.56999999999994, 306.3299999999999], [306.3299999999999, 318.84799999999996], [318.84799999999996, 329.27], [329.27, 343.90999999999997], [343.90999999999997, 355.08], [355.08, 371.59999999999997], [371.59999999999997, 381.68999999999994], [381.68999999999994, 393.5899999999999], [393.5899999999999, 407.0299999999999], [407.0299999999999, 419.4099999999999], [419.4099999999999, 429.69999999999993], [429.69999999999993, 444.3399999999999], [444.3399999999999, 458.0399999999999], [458.0399999999999, 471.4999999999999], [471.4999999999999, 484.33999999999986], [484.33999999999986, 496.61999999999983], [496.61999999999983, 506.8799999999998], [506.8799999999998, 517.0199999999999], [517.0199999999999, 530.8399999999999], [530.8399999999999, 542.2699999999999], [542.2699999999999, 563.3899999999999], [563.3899999999999, 580.3099999999998], [580.3099999999998, 591.8799999999999], [591.8799999999999, 602.9799999999999], [602.9799999999999, 616.9399999999999], [616.9399999999999, 632.03], [632.03, 647.04], [647.04, 657.3499999999999], [657.3499999999999, 669.1099999999999], [669.1099999999999, 679.8799999999999], [679.8799999999999, 691.1999999999999], [691.1999999999999, 702.1999999999999], [702.1999999999999, 712.2399999999999], [712.2399999999999, 722.6219999999998], [722.6219999999998, 736.4899999999999], [736.4899999999999, 750.8599999999999], [750.8599999999999, 770.06], [770.06, 781.3699999999999], [781.3699999999999, 791.5099999999999], [791.5099999999999, 801.7799999999999], [801.7799999999999, 814.6399999999999], [814.6399999999999, 825.9199999999998], [825.9199999999998, 838.6099999999999], [838.6099999999999, 849.9199999999998], [849.9199999999998, 863.0899999999998], [863.0899999999998, 882.7699999999998], [882.7699999999998, 894.9799999999998], [894.9799999999998, 906.7999999999998], [906.7999999999998, 921.8299999999998], [921.8299999999998, 932.5879999999999], [932.5879999999999, 943.1369999999998], [943.1369999999998, 953.8289999999998], [953.8289999999998, 964.7379999999998], [964.7379999999998, 977.8279999999999], [977.8279999999999, 994.1369999999998], [994.1369999999998, 1004.2879999999998], [1004.2879999999998, 1022.3769999999997], [1022.3769999999997, 1034.2879999999998], [1034.2879999999998, 1050.437], [1050.437, 1065.7379999999998], [1065.7379999999998, 1076.1779999999999], [1076.1779999999999, 1087.4279999999999], [1087.4279999999999, 1099.408], [1099.408, 1116.038], [1116.038, 1130.268], [1130.268, 1140.768], [1140.768, 1152.978], [1152.978, 1164.8780000000002], [1164.8780000000002, 1178.7780000000002], [1178.7780000000002, 1189.3580000000002], [1189.3580000000002, 1199.8380000000002], [1199.8380000000002, 1217.928], [1217.928, 1228.0880000000002], [1228.0880000000002, 1239.0180000000003], [1239.0180000000003, 1253.7780000000002], [1253.7780000000002, 1264.1880000000003], [1264.1880000000003, 1275.8880000000004], [1275.8880000000004, 1289.2980000000005], [1289.2980000000005, 1300.5280000000005], [1300.5280000000005, 1313.6680000000006], [1313.6680000000006, 1326.2080000000005], [1326.2080000000005, 1351.9180000000006], [1351.9180000000006, 1363.4380000000006], [1363.4380000000006, 1375.0380000000005], [1375.0380000000005, 1390.9780000000005], [1390.9780000000005, 1403.0280000000005], [1403.0280000000005, 1416.3880000000004], [1416.3880000000004, 1426.4470000000003], [1426.4470000000003, 1440.6680000000003], [1440.6680000000003, 1457.7880000000002], [1457.7880000000002, 1476.7980000000002], [1476.7980000000002, 1489.2370000000003], [1489.2370000000003, 1499.7570000000003], [1499.7570000000003, 1510.9780000000003], [1510.9780000000003, 1523.6180000000004], [1523.6180000000004, 1537.2570000000003], [1537.2570000000003, 1548.5480000000002], [1548.5480000000002, 1560.7980000000002], [1560.7980000000002, 1571.2370000000003], [1571.2370000000003, 1586.5980000000004], [1586.5980000000004, 1597.2780000000005], [1597.2780000000005, 1611.0880000000004], [1611.0880000000004, 1622.0280000000005], [1622.0280000000005, 1632.2570000000005], [1632.2570000000005, 1644.4980000000005], [1644.4980000000005, 1656.4670000000006], [1656.4670000000006, 1668.1380000000006], [1668.1380000000006, 1681.6380000000006], [1681.6380000000006, 1695.5280000000007], [1695.5280000000007, 1709.7980000000007], [1709.7980000000007, 1720.8680000000006], [1720.8680000000006, 1732.2680000000007], [1732.2680000000007, 1742.8180000000007], [1742.8180000000007, 1753.5480000000007], [1753.5480000000007, 1764.1970000000006], [1764.1970000000006, 1777.2370000000005], [1777.2370000000005, 1789.8680000000006], [1789.8680000000006, 1801.7680000000007], [1801.7680000000007, 1820.1030000000007], [1820.1030000000007, 1835.4870000000008], [1835.4870000000008, 1847.1580000000008], [1847.1580000000008, 1860.9780000000007], [1860.9780000000007, 1875.0480000000007], [1875.0480000000007, 1886.6280000000006], [1886.6280000000006, 1901.5920000000006], [1901.5920000000006, 1916.8580000000006], [1916.8580000000006, 1927.5680000000007], [1927.5680000000007, 1940.4980000000007], [1940.4980000000007, 1951.0760000000007], [1951.0760000000007, 1966.9470000000008], [1966.9470000000008, 1978.3380000000009], [1978.3380000000009, 1988.538000000001], [1988.538000000001, 2000.987000000001], [2000.987000000001, 2013.388000000001], [2013.388000000001, 2028.2880000000011], [2028.2880000000011, 2038.4180000000013], [2038.4180000000013, 2051.3480000000013], [2051.3480000000013, 2066.6580000000013], [2066.6580000000013, 2084.5780000000013], [2084.5780000000013, 2095.2280000000014], [2095.2280000000014, 2107.1980000000012], [2107.1980000000012, 2120.1580000000013], [2120.1580000000013, 2131.2680000000014], [2131.2680000000014, 2143.9980000000014], [2143.9980000000014, 2158.0980000000013], [2158.0980000000013, 2169.5780000000013], [2169.5780000000013, 2185.8280000000013], [2185.8280000000013, 2201.2080000000014], [2201.2080000000014, 2212.3880000000013], [2212.3880000000013, 2223.9580000000014], [2223.9580000000014, 2235.9880000000016], [2235.9880000000016, 2247.8680000000018], [2247.8680000000018, 2259.3580000000015], [2259.3580000000015, 2273.1680000000015], [2273.1680000000015, 2283.7780000000016], [2283.7780000000016, 2293.8680000000018], [2293.8680000000018, 2304.578000000002], [2304.578000000002, 2316.788000000002], [2316.788000000002, 2330.828000000002], [2330.828000000002, 2342.688000000002], [2342.688000000002, 2354.458000000002], [2354.458000000002, 2366.067000000002], [2366.067000000002, 2403.878000000002], [2403.878000000002, 2418.503000000002], [2418.503000000002, 2428.918000000002], [2428.918000000002, 2449.968000000002], [2449.968000000002, 2462.878000000002], [2462.878000000002, 2478.058000000002], [2478.058000000002, 2490.6580000000017], [2490.6580000000017, 2503.168000000002], [2503.168000000002, 2516.238000000002], [2516.238000000002, 2530.168000000002], [2530.168000000002, 2544.778000000002], [2544.778000000002, 2554.948000000002], [2554.948000000002, 2570.7880000000023], [2570.7880000000023, 2584.678000000002], [2584.678000000002, 2596.878000000002], [2596.878000000002, 2609.968000000002], [2609.968000000002, 2620.758000000002], [2620.758000000002, 2633.918000000002], [2633.918000000002, 2644.558000000002], [2644.558000000002, 2666.933000000002], [2666.933000000002, 2677.188000000002], [2677.188000000002, 2688.768000000002], [2688.768000000002, 2699.538000000002], [2699.538000000002, 2710.8880000000017], [2710.8880000000017, 2722.098000000002], [2722.098000000002, 2734.3380000000016], [2734.3380000000016, 2746.6080000000015], [2746.6080000000015, 2757.1380000000017], [2757.1380000000017, 2770.8880000000017], [2770.8880000000017, 2780.9880000000016], [2780.9880000000016, 2791.7580000000016], [2791.7580000000016, 2803.268000000002], [2803.268000000002, 2817.598000000002], [2817.598000000002, 2829.6380000000017], [2829.6380000000017, 2841.598000000002], [2841.598000000002, 2852.128000000002], [2852.128000000002, 2862.138000000002], [2862.138000000002, 2873.338000000002], [2873.338000000002, 2883.958000000002], [2883.958000000002, 2896.394000000002], [2896.394000000002, 2907.178000000002], [2907.178000000002, 2918.858000000002], [2918.858000000002, 2928.978000000002], [2928.978000000002, 2939.9970000000017], [2939.9970000000017, 2951.7380000000016], [2951.7380000000016, 2962.5280000000016], [2962.5280000000016, 2973.3180000000016], [2973.3180000000016, 2987.1680000000015], [2987.1680000000015, 3000.0080000000016], [3000.0080000000016, 3011.348000000002], [3011.348000000002, 3024.188000000002], [3024.188000000002, 3034.668000000002], [3034.668000000002, 3047.018000000002], [3047.018000000002, 3060.998000000002], [3060.998000000002, 3073.1380000000017], [3073.1380000000017, 3087.3780000000015], [3087.3780000000015, 3111.5060000000017], [3111.5060000000017, 3121.806000000002], [3121.806000000002, 3134.706000000002], [3134.706000000002, 3148.026000000002], [3148.026000000002, 3161.196000000002], [3161.196000000002, 3171.376000000002], [3171.376000000002, 3184.366000000002], [3184.366000000002, 3196.0060000000017], [3196.0060000000017, 3206.6060000000016], [3206.6060000000016, 3219.4860000000017], [3219.4860000000017, 3230.766000000002], [3230.766000000002, 3241.066000000002], [3241.066000000002, 3256.226000000002], [3256.226000000002, 3268.226000000002], [3268.226000000002, 3282.971000000002], [3282.971000000002, 3294.2160000000017], [3294.2160000000017, 3306.1860000000015], [3306.1860000000015, 3318.5160000000014], [3318.5160000000014, 3333.3160000000016], [3333.3160000000016, 3344.7760000000017], [3344.7760000000017, 3354.9760000000015], [3354.9760000000015, 3366.3260000000014], [3366.3260000000014, 3377.7260000000015], [3377.7260000000015, 3388.6660000000015], [3388.6660000000015, 3399.8860000000013], [3399.8860000000013, 3412.0960000000014], [3412.0960000000014, 3426.5560000000014], [3426.5560000000014, 3438.6460000000015], [3438.6460000000015, 3450.8860000000013], [3450.8860000000013, 3464.2160000000013], [3464.2160000000013, 3477.146000000001], [3477.146000000001, 3488.376000000001], [3488.376000000001, 3500.6960000000013], [3500.6960000000013, 3511.106000000001], [3511.106000000001, 3522.876000000001], [3522.876000000001, 3539.9660000000013], [3539.9660000000013, 3554.776000000001], [3554.776000000001, 3568.4260000000013], [3568.4260000000013, 3579.1160000000013], [3579.1160000000013, 3592.8760000000016], [3592.8760000000016, 3603.4060000000018], [3603.4060000000018, 3613.8160000000016], [3613.8160000000016, 3623.846000000002], [3623.846000000002, 3634.036000000002], [3634.036000000002, 3647.126000000002], [3647.126000000002, 3658.1360000000022], [3658.1360000000022, 3670.406000000002], [3670.406000000002, 3682.1900000000023], [3682.1900000000023, 3693.5660000000025], [3693.5660000000025, 3706.3260000000028], [3706.3260000000028, 3726.9210000000026], [3726.9210000000026, 3737.5960000000027], [3737.5960000000027, 3747.6160000000027], [3747.6160000000027, 3757.7160000000026], [3757.7160000000026, 3777.8160000000025], [3777.8160000000025, 3788.5860000000025], [3788.5860000000025, 3800.6360000000027], [3800.6360000000027, 3816.1260000000025], [3816.1260000000025, 3830.2060000000024], [3830.2060000000024, 3845.196000000002], [3845.196000000002, 3855.816000000002], [3855.816000000002, 3867.246000000002], [3867.246000000002, 3878.886000000002], [3878.886000000002, 3899.996000000002], [3899.996000000002, 3911.896000000002], [3911.896000000002, 3925.816000000002], [3925.816000000002, 3938.8460000000023], [3938.8460000000023, 3953.0960000000023], [3953.0960000000023, 3967.2260000000024], [3967.2260000000024, 3977.4560000000024], [3977.4560000000024, 3988.0860000000025], [3988.0860000000025, 4003.0760000000023], [4003.0760000000023, 4014.276000000002], [4014.276000000002, 4027.5960000000023], [4027.5960000000023, 4043.3960000000025], [4043.3960000000025, 4058.2160000000026], [4058.2160000000026, 4072.4060000000027], [4072.4060000000027, 4082.7960000000026], [4082.7960000000026, 4094.0060000000026], [4094.0060000000026, 4106.8160000000025], [4106.8160000000025, 4126.014000000003], [4126.014000000003, 4139.846000000003], [4139.846000000003, 4153.496000000003], [4153.496000000003, 4164.506000000003], [4164.506000000003, 4173.080000000003]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [925, 2427, 3097, 4172]}
{"example_id": "mit038@@MIT8_06S18_L04_300k", "text": ["PROFESSOR: For a couple of lectures,  we're going to be discussing now the hydrogen atom.  So you've seen the hydrogen atom before.  You've seen it in 804. ", "You've seen it in 805.  Why do we see it again in 806?  Well, the hydrogen atom is a fairly sophisticated example. ", "It's the harmonic oscillator of atomic physics.  If some of you are going to be doing atomic physics,  eventually, you have to understand the atom perfectly ", "well, the energy levels, the degeneracies, why are they,  how do you separate the levels, how  do you split the degeneracies. ", "It's a fantastically good example  of perturbation theory, our degenerate perturbation  theory, non-degenerate perturbation  theory in some cases. ", "But overall, it's a very important physical system  that affects many areas of physics,  astrophysics with hyper fine splitting, ", "all kind of processes in atomic physics and lasers,  and things like that.  So it's something we really want to understand well. ", "And this time in 806, it's the right time for you  to understand the fine structure of this atom.  Bits and pieces of this have been done before. ", "But now, we're going to do it in detail.  So let's start with hydrogen atom fine structure.   Hydrogen atom fine structure. ", "That is the main topic for a couple of lectures.  So in terms of Hamiltonians, we've ", "been talking of an unperturbed Hamiltonian, an H0.  This Hamiltonian is known.  It's the momentum squared over 2m minus e squared over r. ", " Here, this is the momentum in three dimensions.  It's a three-dimensional system, of course.  This m is the mass of the electron times the mass ", "of the proton, divided by the mass of the electron  plus the mass of the proton.  And that's the reduced mass of the system,  but it's approximately equal to the mass of the electron. ", "So we will-- whenever we write m,  it will be the mass of the electron.   Now, if you happen to have a nucleus with z protons, what ", "you have to do is replace this e squared by z e squared.  And this is because the factor of e  squared comes from the product of the charge ", "of the electron times the charge of the nucleus.  So if the charge of the nucleus becomes z times bigger,  this e squared is replaced by this quantity. ", " What important length scales exist here  is the bore radius is the most important length scale, ", "and it's constructed with the quantities that appear  in this Hamiltonian and H bar.  So in particular, doesn't involve the speed of light. ", "There's nothing in this system that is relativistic.  So this quantity is h squared over m e squared. ", " And that this has units of length  is something that you should be able to derive  from here in a few instance. ", "Please make sure you know how to derive it  without having to count mass, length, time units here.  This is something you should be able to do very quickly. ", "One piece of intuition, of course,  is that the e appears in the denominator, which is intuition  that as the strength of electromagnetism  is made smaller and smaller by letting e goes to 0, ", "the orbit of the electron would be bigger and bigger.  So this is about 53 picometers, where a picometer ", "is 10 to the minus 12 meters.   A nice unit.  It's half an angstrom, roughly, but picometers ", "is the right unit for people that think of atoms.  Then the energy levels are given by minus e squared over 2a0 1 ", "over n squared.   This is a beautiful formula in terms of quantities  that you understand.  First, the energy just depends on n, and this 1 over n ", "squared.  And n is called the principle quantum  number, principle quantum number,  and it goes from 1 up to infinity. ", " This has units of energy, and that's  why this is nice, because e squared over ", "r is the units of potential energy in electromagnetism.  So when you see this, you know that this  has the right units of energy. ", "And for the ground state of hydrogen,  n equal 1, that energy is about minus 13.6 eV. ", "Now, in terms of thinking ahead for perturbation theory,  some of the perturbation theory here  will reflect the fact that electromagnetism is weak, ", "and the other fact will reflect that the electron is actually  moving with slow velocities.  So let's see these two things. ", "First, we can write the energy, or in terms  of defined structure constant.  So alpha, which is defined structure constant.  This e squared over [? hc, ?] the units we're working with. ", "And it's about 137.  So whenever you see e squared over a0, ", "which is a unit of energy, you should realize that--  if you wanted to change that, for example, ", "for the case that you have a nucleus with z protons,  you cannot just do e squared going to ze squared,  because in fact, a0, itself, has an e. ", "So don't think that the energy depends like e squared.  It actually depends more like e to the fourth times  other constants.  So let's do that. ", "So we have here m e to the fourth over h  squared, using the value of a0. ", "And then we can use e to the fourth from this equation.  So it would be alpha m alpha squared h bar squared ", "c squared over h bar squared.  And it's equal to alpha squared mc squared.  A nice way of thinking of the ground state ", "energy of the hydrogen as a small quantity alpha  squared times the rest energy of the electron. ", "After all, the system begins just with an electron,  and it has some rest energy, and there  should be a natural way of expressing this. ", "Of course, you start seeing this c squared here.  But the c squared really is nowhere there.  We've put it for convenience.  But it allows us to think of scales, ", "and in particular, the rest mass of the electron  is alpha is much bigger, because alpha squared is about 1  over 19,000. ", "1/137 squared is about that.  So the energy, en, can be written in a way ", "that we will use often as minus 1/2 alpha squared  mc squared 1 over n squared.  ", "All right.  And another observation, the momentum of the electron, we ", "could estimate it to be h bar over a0.   So this is me squared over h bar. ", "And we use the e squared for what it is.  So this is alpha.  Well, I'll put m, alpha hc over h bar. ", "So this is alpha mc.   It's a nice thing, alpha mc.  ", "It says that the momentum that you could construct  relativistically, the mass of the electron  times the velocity, you still have to divide by 137. ", "But it's clearer if you write it like m alpha c, and then  momentum, which is mass times velocity, at least  for slow velocities. ", "Now is mass times alpha times c.  So the approximate velocity that we estimate on the electron  is c over 137. ", "So that's very nice.  It's kind of non-relativistic.  OK.  So this is the basic things.  But the most important stuff is really ", "getting the table of how the atom looks.  So this is still review.  Half of this lecture, in a sense, is review. ", "We put here, not in scale, n equals 1, n equals 2,  n equals 3, and n equals 4. ", " In reality, the hydrogen atom, if this is 0 energy,  and this is the ground state, the ground state that's here, ", "the second excited state is here, the third is here,  the fourth is here, fifth, they all accumulate here.  But that I've written it this way.  Now, we'll have l equals 0 here, l ", "equals 1, l equals 2, l equals 3.  And there is another notation for this state. ", "I don't know why, but there is.  A capital l that is a function of l.  So capital l of l equals 0 is called s. ", "So these states are called s states.  Capital l of l equals 1 is called p. ", "So states with l equal 1 will be called p.  Then d and f.  These are names.  We'll use those names. ", "They're OK.  And here are the states.  For n equal 1, there's just one state here. ", "And here there's one state as well.  But for n equal 2, there is a state with l equal 0,  and there is a state with l equal 1.  For n equal 3, there's 0, 1, and 2. ", "For n equal 4, there's 0, 1, 2, and 3.   So these are the states in the spectrum of hydrogen, something ", "that we should know very well.  And what are the patterns here.  They're degeneracies.  Why?  Because when we talk l equal 2, for example, ", "that means a multiplet of angular momentum  with total angular momentum 2.  And that comes with as azimuthal angular momentum  that goes from minus 2 m to plus 2, that is five states. ", "So in principle, each bar here is five states, five states.  l equal 1 has m equal 1, 0, and minus 1.  So three states, three states, three states. ", "And here, really zero states.  So there's lots of degeneracy.  That's why we spend lots of time studying  degenerate perturbation theory, because this gigantic ", "degeneracies here.  So to determine the origin or the way  we parametrize the degeneracy, there's  just one formula that says it all. ", "And that formula is degeneracies.   It's the formula that explains it all,  and it says that the principle quantum ", "number is equal to capital n plus l plus 1, where  n is the degree of a polynomial in the wave function. ", "Wave function.  l is the orbital angular momentum.  ", "So this says, for example, that this degree of the polynomial n  can be 0, 1, 2. ", "It cannot be negative.  l can also be 0, 1, and go on.  But here, for example, you see the main rule ", "that for a fixed n, you can have l equals 0 1, 2,  up to n minus 1, because by the time ", "you take l equals to n minus 1, this whole thing  is equal to little n, and capital n is 0.  And that's as far as you can go. ", "So the angular momentum cannot exceed the principle quantum  number minus 1.  That is what we see here for n equal 3. ", "You can have up to l equal 2.  For n equal 4, you can have up to l equal 3.  So this is kind of well known. ", "Now, for each l, each l, you have  m from minus l all the way to plus l. ", "And that's 2l plus 1 values.   So the degeneracy at n, at the principle quantum number ", "equal n is the sum from l equals 0 up to n minus 1.  Those are all the possible values ", "of l of the number of states in each l multiplet.  And you've done this one before, and that actually ", "turns out to be equal to n squared, which  says there should be four states at n equal 2,  indeed one state for S equals 0, three states here is 4, 1, 3, ", "5.  It's that property that the sum of consecutive odd numbers  comes up equal to the square, a perfect square. ", "It's a very nice thing geometrically.   So the wave function--  we'll write it here-- the wave function psi mlm. ", " These are our quantum numbers and principal quantum number.  Once you know n, you know the sum of capital N plus l. ", "But l is a little more physical than n.  So we'll use l, and once you know l,  you still need to know where a given state, which value of m ", "you have.  So those are your three quantum numbers,  and this wave function goes like a constant times r over a0 ", "to the l times that polynomial we spoke about, 1 plus beta r  to the r over a0 all the way up to a number times r over a0 ", "to the capital N times e to the minus r over n a0 times ", "ylm of theta and phi.   So that's your wave function.  ", "Those numbers I have not determined.  I have not determined the normalization.  But if you're looking at the wave function,  the easiest place to see the principal quantum number ", "is here.   The easiest place to see the orbital angular momentum  is here. ", "You identify it from here.  It must be multiplying a polynomial that  begins with 1, because the leading power in the solution  must be r to the l, and has degree n here. ", "And the m quantum number you see it from the spherical harmonic.   So in particular, here you have a state with l ", "equals 0, n equal 1.  So this must have n equals 0.  This must have n equals 1, because you ", "must get to 2 with a capital N and l equals 0 and a 1 there.  So this is n equal 1.  This would be n equal 2, n equal 3. ", "Similarly here, n equals 0, n equals 1, n equals 2,  n equals 0, n equals 1, n equals 0 here. ", "The n's decrease in this direction as l increases,  keeping the sum of capital N and l constant and equal  to little m minus 1. ", " Interestingly, this makes sense as well.  If you may remember, the quantum number N, capital N, ", "tells you the number of nodes of the wave function,  because a polynomial of degree n can have n zeros,  and therefore, this wave function  has no nodes, one node, two nodes, three nodes. ", "The number of nodes increase.  That's another thing that wave functions should have.   So a couple more comments and this. ", "We'll write-- I'll write the ground state wave function.  I'll put it here.  I'm cluttering things a little bit.  But the ground state wave function ", "is one that we can have and normalize easily.  Square root of pi over a0 cubed e to the minus r over a0. ", "That's the ground state wave function.   OK.   Comments on this thing. ", "First, there is a very large degeneracy here.  And it has a nice interpretation. ", "This correspond to states with different values of the angular  momentum.  Semi-classically, if you were doing Keplerian emotion, ", "and think semi-classically of the electron orbit,  all the orbits here corresponds of orbits  of the electron with the same semi-major axis, ", "but with different eccentricity.  So as it turns out, the orbit with least  l is the most eccentric of all orbits. ", "And as you go in this direction, the orbit  becomes more and more circular.  So if you want an immediate intuition,  as to why are all these states distinguishable, ", "it's because they are orbits with different eccentricity.  There are ellipses with different eccentricity,  all with the same semi-major axis.  So it could be a circle like that, ", "or it could be just an ellipse like that.  So those are it.   Then, most important complication we've ", "ignored here, it's the spin of the electron.  Electron has spin.  So we know the spin of the electron  represents a degree of freedom described ", "by a two-dimensional vector space.  So there's two states in every one of this.  So we will have to consider that. ", "And if I want to put the number of states on each one,  here there was one state we said,  but now we know there are really two states.  ", "And here, there's two states is l equals 0, two  states, two states.  Here is l equal 1.  That's three configurations of orbital angular momentum. ", "But the electron has, again, up or down possibilities.  So these are six states, six states, six states. ", "l equals 2 is five states, but with the electron,  there is 10 states and 10 states here.  ", "In this one, l equals 3 is 7 states, 2l plus 1,  but with the electron degrees of freedom is 14 states. ", "So these are the right number of states.   When we'll do the fine structure,  we'll have corrections due to the spin and corrections ", "due to relativity.  Both things will make our corrections.  And by the time we do that, we may also  want to explore the atom by putting it ", "in an electric field.  That's the stark effect.  It will change energy levels, and you learn more  about the energy levels of a system.  You can put it in a magnetic field, ", "and that's a Zeeman effect.  And the magnetic field can be weak, or it can be strong,  and it's a different approximation,  ", "PROFESSOR: OK, so this is the picture you've studied so far.  And now we will consider the next thing. ", "So basis states.  What's going to happen? ", "We have to deal with basis states.  We have electron spin.  We have electron angular momentum.  What is the total angular momentum? ", "The sum of them.  We will have to deal with that.  So we will have to deal with addition of angular momentum  in the hydrogen atom.  It's awfully important. ", "That's the key of the matter.  So let's see what we have.  Let's look at our basis states.  ", "So now the spin, the most important thing,  we take it very seriously.  Recall that when you have angular momentum--  ", "in general, we use j and m, and those are the two quantum  numbers, j squared, the angular momentum eigenvalues, ", "h squared, l times--  j times j plus 1.   And jc over h bar has eigenvalues, m. ", "That's a notation for angular momentum.  So we have the electron spin.  ", "So what is the notation.  It's sms, and it's always equal to 1/2,  because the electron always has been 1/2. ", "The electron will have many orbital angular momentum, 0, 1,  3, but spin, it only has been 1/2.  So s is always 1/2. ", "ms can be plus minus 1/2.  So that's two states.  ", "For orbital electron, orbital, we have l and m. ", "Those are the names, l and m is the quantum number.  So how do we define the uncoupled basis? ", "The uncoupled basis is a set of states  that enumerates the whole spectrum of the hydrogen atom,  using those quantum numbers to distinguish all those states. ", "So the uncoupled basis are those states that we have there.  Uncoupled basis are all these states, ", "and they're described by n, and the principal quantum number,  l and m.  This is the orbital. ", " And you could say, well, s and ms,  that would be a correct thing to do. ", "But as we said, s is always So copying and copying again,  something that is always the same value  and doesn't have any new information ", "is not worth it, so people don't include the s.  And we put ms.  And that's electron spin along the z direction, electron sz. ", "And it takes values plus minus 1/2.  So this is our uncoupled basis.  For any electron in that table, you  need to know uniquely that electron state. ", "You need to give me all these numbers.  You have to tell me where I am horizontally,  after that, where I am vertically, I'm sorry, ", "for m, where I am horizontally for l, within the multiplate,  which is my value of m.  And once you've done that, you should tell me up or down. ", "So all those numbers are important.  They're one to one correspondence  to the basis state.  But now, let's do the coupled basis. ", "That's where things begin to get interesting.  Coupled basis.  So we'll consider the total angular momentum ", "j, which is l plus s.   When we add angular momentum, we basically say, ", "you know, you have states that are representations  of orbital angular momentum and spin.  But I want you to express those as eigenstates ", "of the total angular momentum.  That's all adding angular momentum means.  It's recognizing that we want to re-express our basis ", "states in terms of eigenstates of the total angular momentum.  It's all you do.  So what do we do then?  We have an l multiplate. ", " What does an l multiple mean?  That's a set of vectors, a vector space. ", "And we tensor it with a spin multiplate,  and the result is equal to the sum of j multiplate ", "because your states are nothing else but tensor products  of these things, even though we never wrote it  in the way of tensor product.  Basically, the wave function has some expression ", "having to do with l and m in here  and has some value of the spin.  So a given state has all these properties. ", "A given state lives in the tensor product,  and we want to write it the sum of j multiplate.   So I want to say a couple more things about this. ", "When we do addition of angular momentum,  what happens to the quantum numbers?  That's, again, also a thing that's  sometimes a little subtle, and I want to emphasize it. ", "So an l multiple it is described by l and m.  A spin multiplate is defined by s and ms. ", "But when you have a j mulitplate, you have j and j-- ", "how do they call it?  jm.   I think they call it.  Yeah, jm.  ", "But actually, you have a little more.   I claim that the states-- ", "so this is what I'm meaning my this.  These states have two quantum numbers you can specify.  You cannot specify any more.  This is the z component of l, and you cannot specify the x ", "or the y component.  Here is all you can specify of these states.  You certainly can specify the value of j,  and the value of jm, the m component, the z component ", "of j, but can you specify more?  And the answer is yes.  You can specify a little more. ", "You can actually specify here all the states in here  are eigenstates of l, of s, of j, and of jm. ", "So you add two more.   This may sound a little funny, but every state here ", "had the same l eigenvalues.  They were, for example l equal 3.  So all the states have l equal 3.  All the states are eigenstates of l squared, eigenstates. ", "All these states here are l squared eigenstates,  and all the states here are s squared eigenstates  with the same eigenvalues. ", "So if you multiply them, and you rearrange them,  because that's all this addition of angular momentum  is is just rearranging the states, ", "you still have that all the states that are here  have the same l squared and the same s squared.  So l and s are good quantum numbers here. ", "The things that are not good quantum numbers are m and ms  are not good.  ", "They are not good quantum numbers of this state.  They are not eigenstates of m or ms. ", "So this is something you've learned with addition  of angular momentum.  If this is a little fuzzy, it will be important  that you review it and make sure this becomes clear. ", "There will be [? stuffed ?] recitation about these things,  and we'll do more with it.  But now, what is the application in the hydrogen atom for this? ", "Well, our multiplates are multiplates  of [INAUDIBLE] value of l that are  being tensored with spin 1/2. ", " Orbital l, and when you have this, ", "you know that the answer is l plus 1/2 plus l minus 1/2.  Those are the two values of j, j max, and j min in this case. ", " So in the hydrogen atom, the notation  is that this is the l state with j equal l plus 1/2. ", "This is the j value plus the l state with l minus 1/2.  ", "So this is the capital L we were mentioning before,  in this case L of l.  And our notation is evolving. ", "This is the spectroscopic notation in which we  will describe states by an nLj.  ", "So that's the spectroscopic notation.  You put the principal quantum number, the capital L,  that is for L equals 0, put an s, a p, a d, and the number ", "which is the value of j here.  So let's look at our spectrum again.  We have to do that.  It's an important thing. ", "So we'll do three cases here, n equal 1, n equals 2,  and n equals 3.  We have l equals 0, l equal 1, l equals 2. ", "And that's s, p, and D. OK, let's begin.  This state, ground state, what is the ground state? ", "It's l equals 0, tensor with 1/2 for the ground state.  This is just the state 1/2.  So it will be a state with j equal 1/2. ", "So it should be written as n, which is a 1, the capital  L, which is 0. ", "So it's s and the j value 1/2.  That's the state.  1s 1/2.  Go here. ", "Well, that's still l equals 0.  So this product source is 2s 1/2, and here is 3s 1/2.  ", "That's the name of the multiplates  in the coupled basis.  What do we have here?  ", "We have l equals 1.  So with l equals 1, we have 1 tensor 1/2. ", "So we will get j equals 3/2 and 1/2.  So we must have 2.  ", "What is the value of l?  Remember, the value of l is preserved.  So if this was l equals 1, after you do the tensor product, ", "l is still a good quantum number.  So you have 2p 3/2, and 2p 1/2. ", " Here, you would have two states, 3p 3/2 and 3p 1/2. ", " Finally, here l equals 2, you have  2 tensor 1/2 is 5/2 plus 3/2. ", "So you would have 3D 5/2 and 3D 3/2.  Those are your states. ", "This is the notation we will use.  So what is the uncouple basis at the end of the day?  The uncoupled basis is n.  You still have n. ", "What is the coupled basis now?  We have the uncoupled basis being this.   The coupled basis is still n. ", "Still l.  We said l carries through.  Still s would carry through, but we don't have it there.  Now I cannot put m. ", "m is no good when [INAUDIBLE],, but I have j and jm.  ", "So these are your coupled basis states, coupled basis.  ", "And it's represented in this notation, the n,  the little l is representative for whatever letter is here,  the j is here, and well, the jm is not said, ", "but that's a multiplate.  OK, so we've rewritten the stating the couple basis,  because we will need those states in order ", " PROFESSOR: All right, so our next thing will be  getting into the electron spin.  And I want to discuss of two things, a little bit  of the Dirac equation and the Pauli ", "equation for the electron.  We need to understand electron a little better  and understand the perturbations, ", "the relativistic corrections so we'll  consider the Pauli equation.  ", "So the Pauli equation is what we have to do now.  So what is the Pauli equation?  It is the first attempt there was ", "to figure out how the Schrodinger equation should  be tailored for an electron.  So we can also think of the Pauli equation ", "as a baby version of the Dirac equation, which  is the complete equation for the electron.  So it all begins at the motivations  by considering what is the magnetic moment of an electron? ", " So it's a question that you've been addressing  in this course for a while, from Stern-Gerlach experiment ", "and how magnetic fields interact with electron.  So classically and in Gaussian units, ", "if you have a current loop and an area a,  the magnetic moment is equal to i times the area ", "vector divided by c.   You can use that to imagine an object that is rotating. ", "And as the object rotates, if its charged,  it generates a magnetic moment, and the magnetic moment  depends on the amount of rotation of the orbit. ", "So it turns out that, with a little classical argument,  you can derive that the magnetic moment is related  to the angular momentum by a relation of the form L, ", "so the charge of the object, the mass of the object c,  and the angular momentum.  And that's perfectly correct classically.  So people thought that quantum mechanically ", "they expect that for an electron or for an elementary particle,  you would get q times 2 mc times the spin of the particle. ", "So this would be the intrinsic magnetic moment of an electron  that it seems to have times a fudge factor, g ", "that you would have to measure.  Because after all, the world is not classical.  There's no reason why a classical relation like that  would give you the right exact value of the magnetic moment ", "of the electron.  As it turns out, this g happens to be equal to 2.  ", "And we get the following.  So for electrons g happens to be equal to 2. ", "So mu is equal to 2 times minus e-- the charge of the electron  is minus 2 mc, and the spin of the electron ", "is h bar over 2 times sigma, the Pauli matrices.  So this thing is minus eh bar over 2 mc sigma ", "mu of the electron.   So if you have a magnetic field, a B external, ", "the Hamiltonian that includes the energetics  of the magnetic field interacting  with the dipole moment, it's always minus mu dot b. ", "So in this case it would be eh bar over 2 mc sigma dot b. ", "That's the Hamiltonian for an electron  in a magnetic field, something you've used many, many times.  The most unpleasant part of this thing is this g equal 2. ", "Why did it turn out to be g equal 2?  People knew it was g equal 2.  But why?  And here we're going to see the beginning of an explanation. ", "In fact, it comes very close to an explanation of that  through the Pauli equation.  The Pauli equation is a nice equation you can write,  and you can motivate. ", "And it predicts.  Once you admit the Pauli equation,  it predicts that g would be equal to 2.   And that, of course, happens also for the Dirac equation. ", "And Dirac noticed that, and he was very happy about it.   So it's quite remarkable how these things showed up, ", "and the G equal to 2 was perfectly natural.  So let's see this Pauli equation first. ", "What is it?   Well, when you do the Schrodinger equation for a wave  function, you say p squared over 2m-- ", "say a free particle, and you would  put the wave function is equal to energies times the wave  function. ", "h on the wave function is equal to energy terms the wave  function.  So for this electron, you already ", "know it's a two-dimensional Hilbert space, the state  space of the up and down.  So it's convenient to change this and to say, you know what? ", "I'm going to put here something I'll call a spinor.   Chi is a Pauli.  It has two things, a chi 1 and a chi 2, and it's a Pauli spinor. ", " And this is reasonable so far.  The spin is defined by 2 degrees of freedom, 2 basis is vectors. ", "So you've done wave functions for spin.  And the wave functions for spin have these things,  and each themself can be a function of position. ", "So that's perfectly reasonable.  I don't think anyone of you is very impressed by this so far. ", "But here comes the funny thing.  In a sense here, there is a 2 by 2 identity matrix sitting here. ", "So Pauli observes the following identity.  If you have sigma dot 8 and sigma dot b, ", "it's equal to a dot b times 1 plus i sigma plot a cross b. ", "Look, these are two vectors, a and b.  And if you multiply half this product-- first,  this is a dot product.  It means sigma 1 times a1 sigma 2 times a2 sigma 3 times a3. ", "So this is a dot product.  This product here is a matrix product  because this is already a matrix,  this is already a matrix, so this is a matrix product. ", "And this is the result. This comes  from properties of the Pauli matrices you already know.  In particular, their commutator determines  this piece and the anticommutator ", "determines this piece.  So here, if you have, for example,  sigma dot p times sigma dot p-- ", "see, these two vectors are the same in this case--  you'll get just p squared times 1 plus 0. ", "Because p times P, those are two vector operators if you wish,  but still they commute.  So this is equal to 0. ", "So your p squared can be replaced by sigma dot p sigma  dot p.  So h, the Hamiltonian-- that is p squared over 2 m times ", "the identity matrix--  can be perhaps better thought as sigma  dot p times sigma dot p divided by 2m. ", " So this is the first step.  You haven't done really much, but you've ", "rewritten the Hamiltonian with a unit matrix  here perhaps in a somewhat provocative way.  In quantum mechanics, when we couple to electromagnetism, ", "there are simple changes we have to do.  And we will study that in detail in about three weeks, ", "but today I will just bench on what  you're supposed to do in order to couple to electromagnetism.  In order to couple to electromagnetism, ", "you're supposed to change p wherever you see  by an object you can call pi.  It's some sort of more canonical momentum ", "in which it's got to p minus q over c.  The vector potential is a function of x. ", "Well, people write it like this, qp minus q ac.   So you're supposed to do this replacement.  When you're dealing with a particle moving ", "in some electromagnetic field, that's the change you must do.  We will study that in detail.  But I think an obvious question at this moment ", "is the following.  You say, well, I'm in quantum mechanics,  and I work with p and x.  Those are my opera-- what is a? is it an operator? ", "Is it a vector?  Is it what? p is an operator, but what is a?  You should think of this vector potential.  In general, this vector potential ", "will depend on the position.  So if you put a magnetic field, you require a vector potential.  It has some position dependent.  So actually, this a here should be ", "thought as a of x, the same way as when  you have the potential that depends on x.  In quantum mechanics, we just think of that x as an operator. ", "So the a is an operator because x is an operator,  and a has x dependents.  So the Pauli Hamiltonian, h Pauli is nothing else but sigma ", "dot pi times sigma dot pi over 2 m.  Because we said p must be replaced by pi, ", "so this is the Pauli Hamiltonian.  And it's equal to 1 over 2m pi squared ", "pi dot pi times 1 plus i sigma dotted with pi cross pi. ", "", "OK, here is the computation we need to do.  What is pi cross pi?  You know what pi is.  It's given by this thing. ", "So how much is pi cross pi?   Well, it takes a little computation.  I'll tell you what you have to do. ", "It's a very interesting computation.  It's small.  It reminds you of this computation  in angular momentum, l cross l. ", "Maybe you've written the algebra of angular momentum  in this language.  It's equal to h bar l.  ", "That's your computation in relations of angular momentum  written like that.  So pi cross pi, the kth component  is epsilon ijk pi i pi j or 1/2 epsilon ", "ijk pi I commutator with pi j.   This last step, it can be explained ", "by writing out the commutator, which  is pi i pi j minus pi j pi i.  But with this epsilon, those two terms are the same,  and it becomes this. ", "So how much is this thing?  I'll leave it for you to do it.  It's simple thing. ", "You have to commute these things,  and you must think of p as derivatives.  So this pi i pi j is i h bar q over c di a j minus dj a i. ", "You can see it coming.  You see, you have a commutator of two factors like that.  The a with a will commute.  The p with p will commute. ", "The cross products won't, but that's just derivatives.  So therefore, you get the derivatives  of a antisymmetrized.  And the derivatives of a antisymmetrized ", "is the curl of a.  And the curl of a is the magnetic field.  So that's why this happens.  So at the end of the day, when you'll finish this computation, ", "get that pi cross pi is just i q i h bar q over c  times the magnetic field. ", "Pretty nice equation.   So the Pauli Hamiltonian includes h Pauli.  ", "It includes this term, which is i sigma over 2m ", "dotted with i hQ over cb plus the other terms. ", "I'm just looking at this term which has the magnetic field.  And therefore, look at this.  i with i is minus 1, but q is minus e. ", "So this is eh bar over 2 mc sigma dot b, which is here, ", "which came from g equal 2.  Nowhere I had to say there that g is equal to 2.  It came out of this calculation. ", "The Pauli Hamiltonian knew of this.  And therefore, it's a great progress, that Pauli  Hamiltonian, but it suggests to us ", " PROFESSOR: OK.  Let's turn then to the Dirac equation  and motivated, basically. ", " Through the Dirac equation is the simplest way  to do perturbation theory for the hydrogen atom. ", "It helps us derive what we should think of perturbation.  So I'll discuss that quickly.  And there may be some of that done in recitation. ", "So we're going to discuss now the Dirac equation.   So the Dirac equation begins with the observation ", "that we have E squared minus p squared  c squared for a free particle is m squared c to the fourth. ", "This dispersion relation that rates E and p for any particle.  So if you wanted to describe the dynamics  of a relativistic particle, you could say, look, ", "the energy is the square root of p squared c squared  plus m squared c to the fourth. ", "Therefore, I should take the Hamiltonian to be that thing.  I should take H' to be that.  And work with a Schrodinger equation ", "that has this H with the square root.  Nobody does that, of course.  But you can do a little bit with it.  If you notice that this is equal to mc squared square root of 1 ", "plus p squared over m squared c squared.   And then expand.  In small velocities where this is less than 1, ", "you get 1 plus 1/2 p squared over m  squared c squared minus 1/8 of this term squared.  So p squared p squared over m to the fourth c to the fourth. ", "And then what do you get?  mc squared plus 1/2 2m p squared.  That's very nice. ", "Apart from the rest energy, you get  the p squared over 2m that you would expect.  And the next correction is minus 18 p ", "squared p squared over m cube c squared plus dot dot dot.  You know, that's one way you could treat the Hamiltonian. ", "But it's very complicated.  Don't treat the Hamiltonian too seriously  because the Schrodinger equation would  have infinite number of spatial derivatives. ", "p to the fourth, p to the sixth, p to the eighth.  Never going to get that understood.  But in terms of perturbation theory,  we can think of p squared over 2m, your original Hamiltonian. ", "And here is a relativistic correction that is small.  But Dirac was puzzled by that square root. ", "He basically looked at it and I think  he had sort of mathematical inspiration in here.  He looked at this equation and that square root ", "and he said, how much would I wish  I could take that square root.  What can I do to take that square root?  So he said, well, I could take that square root. ", "This has p squared so c squared plus m squared c to the fourth.  I could take that square root if that would  be equal to something squared. ", "Which it's not because it's missing the cross product  of the right amount.  And it's not there.  But if it would be there, the cross product, ", "it would be a linear function of p and mc squared.  So he says, OK, let me put a linear function of p.  And the most general linear function of p is obtained, ", "I want the c squared, so c, by doing  the dot product of a vector with p, a constant vector.  A constant vector times p is the most general linear function ", "of p.  And here I'll output another constant, mc squared. ", "And I hope I can take the square root  because there will exist some constants  and it somehow will work.  As of now, it cannot work because it's always across ", "product.  But just follow these dots.  And then alpha dot p.  This is equal to c alpha 1 p1 plus c alpha 2 p2 ", "plus c alpha 3 p3 plus beta mc squared.  So let's list all the things that should  happen for this to work out. ", "Well, this square includes the square of this,  the square of this, the square of this,  and the square of this.  And those are what we want.  So we should have that alpha 1 squared ", "is equal to alpha 2 squared is equal to alpha  3 squared is equal to beta squared is equal to 1.  If that happens, well, this term will give you ", "c squared p1 squared, c squared p2 squared,  c squared p3 squared, and m squared c to the fourth,  and I get everything to work.  But the cross products must also work. ", "So for example, the cross product of p1 with p2  should vanish.  And that, well, if you ride these two factors like  that here you would say, oh, what they need now ", "is that alpha i times alpha j plus alpha j times alpha i  should be 0 for all i different from j. ", "So for example, alpha 1, alpha 2 plus alpha 2 alpha 1,  when you do the product, should vanish.  And I kept the order of these things there.  When I'm starting to think that maybe ", "numbers is not going to work.  So i difference from j.  This must happen too for this to be equal.  And moreover for all i alpha i beta. ", "There shouldn't be cross products between these ones  and this term either.  Plus beta alpha i is equal to 0. ", "And that's all that should happen.  If that happens, we can take the square root.   But if these things are numbers, well, this ", "could be phases or 1 or minus 1.  And that's never going to work.  This is twice this product.  So [INAUDIBLE] OK, they're matrices. ", "But that's not bad, if they're matrices,  we'll have like spinors, like Pauli was doing.  And we'll work on spinors.  But it turns out that this one, the simplest solution ", "is something with 4 by 4 matrices.  So the solution is alpha is 0 sigma sigma 0. ", "And beta is 1 minus 100.  This is the simplest solution, 4 by 4 matrices. ", "So that Dirac Hamiltonian, H Dirac, is equal to the energy. ", "And the energy was the square root of this.  So it's just this thing.  So it's c alpha dot p plus b mc squared. ", " That's our Dirac Hamiltonian.  ", "But we need to deal with spinors that now are four dimensional.  These matrices, alpha and beta, are  four dimensional because the segments that are inside ", "are two dimensional.  And these are 2 by 2 matrices.   So when you write the Dirac equation as i H bar d psi dt ", "equal H Dirac psi, psi is a four component thing, a chi  and a phi. ", "And what people discover is that chi  behaves like the Pauli spinor.  And this one is a small thing, a small correction. ", "So there is a whole analysis of this system in which, in order  to put the magnetic field, you can put in here ", "for the Dirac Hamiltonian, H Dirac,  coupled to electromagnetism has a c alpha p plus e over ", "ca plus beta mc squared.  And you still have to add the potential, V ", "of r, that comes from [INAUDIBLE] minus e squared  over r.  ", "It's the value of the electron charge  that is the potential of r.  The scalar potential phi of r. ", "So this is the Dirac Hamiltonian.  And you have these things.  And this is something you can read  if you're interested in [? Shankar. ?] There ", "is a derivation of the Pauli equation for the electron.  Which is the spinors that you are ", "familiar with by eliminating in a recursive expansion phi.  And it may be that Professor Metlitski  is going to go through that in recitation as well. ", "So what happens?  What you get is that you get an H chi equal E chi. ", "And H is what?   Here is the grand prize.  From the Dirac equation, we can rewrite the Hamiltonian ", "of the hydrogen atom in a more accurate way, a more complete  Hamiltonian.  And it has p squared over 2m plus V of r, ", "which is what we've called H0.  It's there.  It's the first term.  That's what you would expect.  Then there is that term that we anticipated. ", "Some relativistic correction here.  So it comes like minus p to the fourth over 8m cubed c squared. ", "And we call this delta H relativistic.   And then you get this term that corresponds ", "to spin orbit coupling that also shows up.  2m squared c squared 1 over r dv dr. You've studied this thing ", "and you gave a heuristic explanation for it.  That's another term.  It's kind of difficult to get the right value  by a simple argument. ", "You always get it off by a factor of 2  that is associated to Thomas precession.  But here it comes out directly with the right number.  This is called spin orbit coupling. ", "Delta H of spin orbit.   And there's one more term.  Plus H squared to this [INAUDIBLE] 8 m squared ", "c squared Laplacian of V. Which is called of this V of r.  It's called the Darwin term.  Delta H Darwin. ", " Not the biologist.  Some Darwin.  So the job is set for us. ", "We have to do perturbation theory.  Now you remember that all the terms associated with H0  were of the form energies with alpha squared mc squared. ", "This was like H0.   If you look at the units of all of these terms,  we looked at them in the notes. ", "Delta H. They all go like alpha to the fourth mc squared.  So there is a difference of alpha squared there. ", "1/19000 smaller.  That is the fine structure of the hydrogen atom.  And our task next time will be to compute the effect of this ", "and see what happens with all the levels of the hydrogen  atom.  This is our [? final ?] structure.  So we'll do that next time. "], "vid_duration": [10.19, 12.52, 11.4, 10.74, 11.34, 11.58, 10.8, 12.37, 16.56, 12.72, 15.15, 16.86, 14.5, 19.23, 13.32, 10.665, 15.575, 11.47, 10.93, 13.919, 10.861, 15.09, 15.24, 13.98, 12.24, 13.64, 14.87, 10.4, 10.11, 12.78, 13.77, 10.39, 14.58, 10.93, 10.23, 12.45, 11.6, 11.62, 12.36, 12.9, 11.94, 10.74, 13.77, 12.79, 10.7, 17.42, 11.77, 14.66, 18.28, 11.1, 11.93, 11.94, 12.54, 11.68, 10.08, 10.205, 12.125, 12.87, 11.91, 15.18, 11.82, 10.23, 11.01, 10.59, 11.85, 13.17, 14.34, 11.52, 11.07, 12.83, 10.08, 19.64, 13.58, 10.54, 10.5, 13.47, 10.8, 11.27, 10.72, 12.53, 15.19, 11.098, 11.432, 13.87, 11.07, 12.635, 12.195, 12.18, 11.52, 19.33, 13.78, 12.41, 11.67, 10.26, 14.62, 12.01, 10.23, 10.86, 12.54, 11.82, 13.51, 13.26, 12.66, 11.45, 13.48, 10.24, 10.31, 11.82, 14.26, 14.06, 12.75, 11.79, 12.91, 12.39, 11.05, 12.98, 12.73, 10.94, 11.84, 10.27, 10.94, 12.87, 11.62, 10.332, 15.331, 11.16, 11.76, 10.26, 12.59, 13.81, 16.09, 16.82, 10.33, 11.569, 10.921, 11.77, 11.35, 11.58, 13.84, 12.89, 10.05, 10.48, 11.29, 18.36, 13.32, 10.29, 11.58, 11.13, 13.15, 11.91, 15.0, 10.62, 11.31, 11.35, 17.93, 14.79, 10.38, 18.59, 11.06, 18.11, 10.01, 12.43, 11.47, 12.69, 13.469, 10.061, 13.26, 12.4, 13.64, 10.5, 11.75, 11.34, 13.01, 10.53, 15.51, 14.67, 12.365, 11.685, 16.485, 16.005, 12.17, 10.24, 11.62, 12.09, 11.03, 12.66, 14.89, 13.95, 11.25, 10.7, 12.45, 11.87, 10.52, 11.14, 10.44, 13.05, 11.21, 15.14, 12.21, 12.87, 13.19, 10.81, 10.49, 10.04, 12.3, 12.16, 11.28, 10.49, 10.51, 11.63, 10.59, 24.13, 14.02, 15.43, 15.38, 12.815, 11.465, 19.41, 11.7, 15.43, 13.86, 13.47, 14.37, 11.4, 10.72, 20.65, 14.87, 13.7, 10.79, 12.42, 11.7, 12.03, 13.06, 12.87, 12.5, 13.57, 12.25, 11.49, 10.23, 14.72, 14.52, 10.21, 10.59, 13.17, 13.118, 13.352, 15.54, 10.14, 12.55, 11.76, 10.48, 12.86, 11.07, 14.37, 11.51, 13.05, 10.48, 10.28, 12.27, 10.11, 12.88, 10.92, 10.17, 12.6, 11.73, 11.76, 22.22, 12.13, 12.55, 11.54, 13.31, 11.52, 11.03, 10.32, 10.36, 18.2, 13.06, 12.32, 13.41, 18.27, 11.52, 10.83, 12.18, 11.85, 11.5, 10.69, 12.27, 12.12, 14.38, 11.87, 11.07, 10.55, 14.38, 14.6, 13.28, 10.14, 13.83, 10.02, 12.96, 17.07, 15.08, 16.74, 10.23, 11.39, 11.94, 12.25, 14.59, 14.38, 11.01, 13.17, 12.159, 10.941, 14.13, 12.51, 10.64, 10.4, 12.29, 11.7, 11.52, 12.36, 12.51, 12.07, 11.05, 11.72, 12.69, 10.26, 13.81, 11.25, 12.089, 15.541, 12.12, 12.52, 12.205, 12.155, 13.74, 16.8, 11.462, 13.628, 13.02, 15.565, 10.825, 10.64, 14.46, 10.14, 10.68, 12.86, 11.16, 12.37, 14.77, 13.06, 13.53, 12.32, 10.68, 12.21, 13.05, 12.22, 11.545, 12.565, 14.19, 12.03, 10.95, 12.87, 6.657], "stet": [[0, 10.19], [10.19, 22.71], [22.71, 34.11], [34.11, 44.85], [44.85, 56.19], [56.19, 67.77], [67.77, 78.57], [78.57, 90.94], [90.94, 107.5], [107.5, 120.22], [120.22, 135.37], [135.37, 152.23000000000002], [152.23000000000002, 166.73000000000002], [166.73000000000002, 185.96], [185.96, 199.28], [199.28, 209.945], [209.945, 225.51999999999998], [225.51999999999998, 236.98999999999998], [236.98999999999998, 247.92], [247.92, 261.839], [261.839, 272.7], [272.7, 287.78999999999996], [287.78999999999996, 303.03], [303.03, 317.01], [317.01, 329.25], [329.25, 342.89], [342.89, 357.76], [357.76, 368.15999999999997], [368.15999999999997, 378.27], [378.27, 391.04999999999995], [391.04999999999995, 404.81999999999994], [404.81999999999994, 415.2099999999999], [415.2099999999999, 429.7899999999999], [429.7899999999999, 440.7199999999999], [440.7199999999999, 450.94999999999993], [450.94999999999993, 463.3999999999999], [463.3999999999999, 474.99999999999994], [474.99999999999994, 486.61999999999995], [486.61999999999995, 498.97999999999996], [498.97999999999996, 511.87999999999994], [511.87999999999994, 523.8199999999999], [523.8199999999999, 534.56], [534.56, 548.3299999999999], [548.3299999999999, 561.1199999999999], [561.1199999999999, 571.8199999999999], [571.8199999999999, 589.2399999999999], [589.2399999999999, 601.0099999999999], [601.0099999999999, 615.6699999999998], [615.6699999999998, 633.9499999999998], [633.9499999999998, 645.0499999999998], [645.0499999999998, 656.9799999999998], [656.9799999999998, 668.9199999999998], [668.9199999999998, 681.4599999999998], [681.4599999999998, 693.1399999999998], [693.1399999999998, 703.2199999999998], [703.2199999999998, 713.4249999999998], [713.4249999999998, 725.5499999999998], [725.5499999999998, 738.4199999999998], [738.4199999999998, 750.3299999999998], [750.3299999999998, 765.5099999999998], [765.5099999999998, 777.3299999999998], [777.3299999999998, 787.5599999999998], [787.5599999999998, 798.5699999999998], [798.5699999999998, 809.1599999999999], [809.1599999999999, 821.0099999999999], [821.0099999999999, 834.1799999999998], [834.1799999999998, 848.5199999999999], [848.5199999999999, 860.0399999999998], [860.0399999999998, 871.1099999999999], [871.1099999999999, 883.9399999999999], [883.9399999999999, 894.02], [894.02, 913.66], [913.66, 927.24], [927.24, 937.78], [937.78, 948.28], [948.28, 961.75], [961.75, 972.55], [972.55, 983.8199999999999], [983.8199999999999, 994.54], [994.54, 1007.0699999999999], [1007.0699999999999, 1022.26], [1022.26, 1033.358], [1033.358, 1044.79], [1044.79, 1058.6599999999999], [1058.6599999999999, 1069.7299999999998], [1069.7299999999998, 1082.3649999999998], [1082.3649999999998, 1094.5599999999997], [1094.5599999999997, 1106.7399999999998], [1106.7399999999998, 1118.2599999999998], [1118.2599999999998, 1137.5899999999997], [1137.5899999999997, 1151.3699999999997], [1151.3699999999997, 1163.7799999999997], [1163.7799999999997, 1175.4499999999998], [1175.4499999999998, 1185.7099999999998], [1185.7099999999998, 1200.3299999999997], [1200.3299999999997, 1212.3399999999997], [1212.3399999999997, 1222.5699999999997], [1222.5699999999997, 1233.4299999999996], [1233.4299999999996, 1245.9699999999996], [1245.9699999999996, 1257.7899999999995], [1257.7899999999995, 1271.2999999999995], [1271.2999999999995, 1284.5599999999995], [1284.5599999999995, 1297.2199999999996], [1297.2199999999996, 1308.6699999999996], [1308.6699999999996, 1322.1499999999996], [1322.1499999999996, 1332.3899999999996], [1332.3899999999996, 1342.6999999999996], [1342.6999999999996, 1354.5199999999995], [1354.5199999999995, 1368.7799999999995], [1368.7799999999995, 1382.8399999999995], [1382.8399999999995, 1395.5899999999995], [1395.5899999999995, 1407.3799999999994], [1407.3799999999994, 1420.2899999999995], [1420.2899999999995, 1432.6799999999996], [1432.6799999999996, 1443.7299999999996], [1443.7299999999996, 1456.7099999999996], [1456.7099999999996, 1469.4399999999996], [1469.4399999999996, 1480.3799999999997], [1480.3799999999997, 1492.2199999999996], [1492.2199999999996, 1502.4899999999996], [1502.4899999999996, 1513.4299999999996], [1513.4299999999996, 1526.2999999999995], [1526.2999999999995, 1537.9199999999994], [1537.9199999999994, 1548.2519999999995], [1548.2519999999995, 1563.5829999999994], [1563.5829999999994, 1574.7429999999995], [1574.7429999999995, 1586.5029999999995], [1586.5029999999995, 1596.7629999999995], [1596.7629999999995, 1609.3529999999994], [1609.3529999999994, 1623.1629999999993], [1623.1629999999993, 1639.2529999999992], [1639.2529999999992, 1656.0729999999992], [1656.0729999999992, 1666.402999999999], [1666.402999999999, 1677.971999999999], [1677.971999999999, 1688.8929999999991], [1688.8929999999991, 1700.662999999999], [1700.662999999999, 1712.012999999999], [1712.012999999999, 1723.592999999999], [1723.592999999999, 1737.4329999999989], [1737.4329999999989, 1750.322999999999], [1750.322999999999, 1760.372999999999], [1760.372999999999, 1770.852999999999], [1770.852999999999, 1782.142999999999], [1782.142999999999, 1800.5029999999988], [1800.5029999999988, 1813.8229999999987], [1813.8229999999987, 1824.1129999999987], [1824.1129999999987, 1835.6929999999986], [1835.6929999999986, 1846.8229999999987], [1846.8229999999987, 1859.9729999999988], [1859.9729999999988, 1871.882999999999], [1871.882999999999, 1886.882999999999], [1886.882999999999, 1897.5029999999988], [1897.5029999999988, 1908.8129999999987], [1908.8129999999987, 1920.1629999999986], [1920.1629999999986, 1938.0929999999987], [1938.0929999999987, 1952.8829999999987], [1952.8829999999987, 1963.2629999999988], [1963.2629999999988, 1981.8529999999987], [1981.8529999999987, 1992.9129999999986], [1992.9129999999986, 2011.0229999999985], [2011.0229999999985, 2021.0329999999985], [2021.0329999999985, 2033.4629999999986], [2033.4629999999986, 2044.9329999999986], [2044.9329999999986, 2057.6229999999987], [2057.6229999999987, 2071.0919999999987], [2071.0919999999987, 2081.152999999999], [2081.152999999999, 2094.412999999999], [2094.412999999999, 2106.812999999999], [2106.812999999999, 2120.452999999999], [2120.452999999999, 2130.952999999999], [2130.952999999999, 2142.702999999999], [2142.702999999999, 2154.042999999999], [2154.042999999999, 2167.0529999999994], [2167.0529999999994, 2177.5829999999996], [2177.5829999999996, 2193.093], [2193.093, 2207.763], [2207.763, 2220.1279999999997], [2220.1279999999997, 2231.8129999999996], [2231.8129999999996, 2248.298], [2248.298, 2264.303], [2264.303, 2276.473], [2276.473, 2286.7129999999997], [2286.7129999999997, 2298.3329999999996], [2298.3329999999996, 2310.423], [2310.423, 2321.453], [2321.453, 2334.113], [2334.113, 2349.0029999999997], [2349.0029999999997, 2362.9529999999995], [2362.9529999999995, 2374.2029999999995], [2374.2029999999995, 2384.9029999999993], [2384.9029999999993, 2397.352999999999], [2397.352999999999, 2409.222999999999], [2409.222999999999, 2419.742999999999], [2419.742999999999, 2430.882999999999], [2430.882999999999, 2441.322999999999], [2441.322999999999, 2454.372999999999], [2454.372999999999, 2465.582999999999], [2465.582999999999, 2480.722999999999], [2480.722999999999, 2492.932999999999], [2492.932999999999, 2505.802999999999], [2505.802999999999, 2518.992999999999], [2518.992999999999, 2529.802999999999], [2529.802999999999, 2540.2929999999988], [2540.2929999999988, 2550.3329999999987], [2550.3329999999987, 2562.632999999999], [2562.632999999999, 2574.7929999999988], [2574.7929999999988, 2586.072999999999], [2586.072999999999, 2596.5629999999987], [2596.5629999999987, 2607.072999999999], [2607.072999999999, 2618.702999999999], [2618.702999999999, 2629.292999999999], [2629.292999999999, 2653.4229999999993], [2653.4229999999993, 2667.4429999999993], [2667.4429999999993, 2682.872999999999], [2682.872999999999, 2698.2529999999992], [2698.2529999999992, 2711.0679999999993], [2711.0679999999993, 2722.5329999999994], [2722.5329999999994, 2741.9429999999993], [2741.9429999999993, 2753.642999999999], [2753.642999999999, 2769.072999999999], [2769.072999999999, 2782.932999999999], [2782.932999999999, 2796.402999999999], [2796.402999999999, 2810.772999999999], [2810.772999999999, 2822.172999999999], [2822.172999999999, 2832.8929999999987], [2832.8929999999987, 2853.5429999999988], [2853.5429999999988, 2868.4129999999986], [2868.4129999999986, 2882.1129999999985], [2882.1129999999985, 2892.9029999999984], [2892.9029999999984, 2905.3229999999985], [2905.3229999999985, 2917.0229999999983], [2917.0229999999983, 2929.0529999999985], [2929.0529999999985, 2942.1129999999985], [2942.1129999999985, 2954.9829999999984], [2954.9829999999984, 2967.4829999999984], [2967.4829999999984, 2981.0529999999985], [2981.0529999999985, 2993.3029999999985], [2993.3029999999985, 3004.7929999999983], [3004.7929999999983, 3015.0229999999983], [3015.0229999999983, 3029.742999999998], [3029.742999999998, 3044.262999999998], [3044.262999999998, 3054.472999999998], [3054.472999999998, 3065.0629999999983], [3065.0629999999983, 3078.2329999999984], [3078.2329999999984, 3091.3509999999983], [3091.3509999999983, 3104.702999999998], [3104.702999999998, 3120.242999999998], [3120.242999999998, 3130.382999999998], [3130.382999999998, 3142.932999999998], [3142.932999999998, 3154.6929999999984], [3154.6929999999984, 3165.1729999999984], [3165.1729999999984, 3178.0329999999985], [3178.0329999999985, 3189.1029999999987], [3189.1029999999987, 3203.4729999999986], [3203.4729999999986, 3214.982999999999], [3214.982999999999, 3228.032999999999], [3228.032999999999, 3238.512999999999], [3238.512999999999, 3248.792999999999], [3248.792999999999, 3261.062999999999], [3261.062999999999, 3271.1729999999993], [3271.1729999999993, 3284.0529999999994], [3284.0529999999994, 3294.9729999999995], [3294.9729999999995, 3305.1429999999996], [3305.1429999999996, 3317.7429999999995], [3317.7429999999995, 3329.4729999999995], [3329.4729999999995, 3341.2329999999997], [3341.2329999999997, 3363.4529999999995], [3363.4529999999995, 3375.5829999999996], [3375.5829999999996, 3388.133], [3388.133, 3399.673], [3399.673, 3412.9829999999997], [3412.9829999999997, 3424.5029999999997], [3424.5029999999997, 3435.533], [3435.533, 3445.853], [3445.853, 3456.213], [3456.213, 3474.413], [3474.413, 3487.473], [3487.473, 3499.793], [3499.793, 3513.203], [3513.203, 3531.473], [3531.473, 3542.993], [3542.993, 3553.823], [3553.823, 3566.0029999999997], [3566.0029999999997, 3577.8529999999996], [3577.8529999999996, 3589.3529999999996], [3589.3529999999996, 3600.0429999999997], [3600.0429999999997, 3612.3129999999996], [3612.3129999999996, 3624.4329999999995], [3624.4329999999995, 3638.8129999999996], [3638.8129999999996, 3650.6829999999995], [3650.6829999999995, 3661.7529999999997], [3661.7529999999997, 3672.303], [3672.303, 3686.683], [3686.683, 3701.283], [3701.283, 3714.563], [3714.563, 3724.703], [3724.703, 3738.533], [3738.533, 3748.553], [3748.553, 3761.513], [3761.513, 3778.583], [3778.583, 3793.663], [3793.663, 3810.403], [3810.403, 3820.633], [3820.633, 3832.0229999999997], [3832.0229999999997, 3843.9629999999997], [3843.9629999999997, 3856.2129999999997], [3856.2129999999997, 3870.803], [3870.803, 3885.183], [3885.183, 3896.193], [3896.193, 3909.3630000000003], [3909.3630000000003, 3921.5220000000004], [3921.5220000000004, 3932.463], [3932.463, 3946.5930000000003], [3946.5930000000003, 3959.1030000000005], [3959.1030000000005, 3969.7430000000004], [3969.7430000000004, 3980.1430000000005], [3980.1430000000005, 3992.4330000000004], [3992.4330000000004, 4004.1330000000003], [4004.1330000000003, 4015.6530000000002], [4015.6530000000002, 4028.0130000000004], [4028.0130000000004, 4040.5230000000006], [4040.5230000000006, 4052.5930000000008], [4052.5930000000008, 4063.643000000001], [4063.643000000001, 4075.3630000000007], [4075.3630000000007, 4088.053000000001], [4088.053000000001, 4098.313000000001], [4098.313000000001, 4112.123000000001], [4112.123000000001, 4123.373000000001], [4123.373000000001, 4135.462000000001], [4135.462000000001, 4151.0030000000015], [4151.0030000000015, 4163.123000000001], [4163.123000000001, 4175.643000000002], [4175.643000000002, 4187.848000000002], [4187.848000000002, 4200.0030000000015], [4200.0030000000015, 4213.743000000001], [4213.743000000001, 4230.5430000000015], [4230.5430000000015, 4242.005000000002], [4242.005000000002, 4255.633000000002], [4255.633000000002, 4268.653000000002], [4268.653000000002, 4284.218000000002], [4284.218000000002, 4295.0430000000015], [4295.0430000000015, 4305.683000000002], [4305.683000000002, 4320.143000000002], [4320.143000000002, 4330.283000000002], [4330.283000000002, 4340.9630000000025], [4340.9630000000025, 4353.823000000002], [4353.823000000002, 4364.983000000002], [4364.983000000002, 4377.353000000002], [4377.353000000002, 4392.123000000002], [4392.123000000002, 4405.183000000003], [4405.183000000003, 4418.7130000000025], [4418.7130000000025, 4431.033000000002], [4431.033000000002, 4441.7130000000025], [4441.7130000000025, 4453.9230000000025], [4453.9230000000025, 4466.973000000003], [4466.973000000003, 4479.193000000003], [4479.193000000003, 4490.738000000003], [4490.738000000003, 4503.303000000003], [4503.303000000003, 4517.493000000002], [4517.493000000002, 4529.523000000002], [4529.523000000002, 4540.473000000002], [4540.473000000002, 4553.343000000002], [4553.343000000002, 4560.000000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1548, 2578, 3667, 4565]}
{"example_id": "mit038@@MIT8_06S18_L11_300k", "text": ["PROFESSOR: Today, we have to discuss harmonic perturbations.  So we've done Fermi's golden rule for constant transitions.  We saw transitions from a discrete state to a continuum. ", "And by integrating over the continuum,  we found a nice rule, Fermi's golden rule,  that govern the transition rate for this process. ", "So the only thing we have to do different  now is consider the case that the perturbation is not  just a step that gets up and stays there,  but it has a frequency dependence. ", "So that will bring a couple of novel features.  But at the end of the day, as we will see,  our Fermi's golden rule is going to look pretty similar ", "to the original Fermi's golden rule.  A nice application of Fermi's golden rule  is the calculation of the ionization rate for hydrogen, ", "in which you take a hydrogen atom,  you put it in an electric field or send a light wave,  and then suddenly the electron and the hydrogen atom ", "from the ground state ionizes.  And we can compute already-- we have the technology  to compute the ionization rate. ", "That's a pretty physical quantity.  And that will be an example we'll develop today.  Those rates have the funny situation ", "that the calculation can be somewhat  involved and interesting.  And the answers, generally, by the time you simplify them,  are pretty simple and pretty nice. ", "So it's a good idea.  You have to have patience with those calculations  to simplify it till the end, and that's pretty instructive.  So we begin with harmonic perturbations. ", "So we did constant perturbations already.  So now harmonic perturbations.  ", "So our situation is that in which age H of t  is equal to a known Hamiltonian plus delta H of t.  And this time, delta H of t is conventionally ", "written as 2 H prime cosine omega t  for some t between t0 and 0, and 0 otherwise. ", " All of us wonder why the 2 here. ", "One reason for it-- it's all convention, of course.  You have your perturbation, and what you call E H prime  or what you call 2 H prime is your choice. ", "But this 2 has the advantage that when  you describe the cosine in terms of exponentials--  e to the i omega t plus e to the minus i omega t-- the over 2, ", "it cancels this one.  And that makes Fermi's golden rule, that will follow also  and will be valid for these perturbations, ", "take exactly the same form as it did  for the case of constant perturbation.  So it's fairly convenient to put that 2, and we'll put it in. ", "Some books don't, and then they have different looking formulas  for Fermi golden rule depending to which case you're  talking about. ", "Of course, when we mean that this is the time dependence,  we are implying that H prime is time independent.  ", "Because the time dependence is this one.  That's what we're interested in considering.  Of course-- this has been asked sometimes--  H prime can depend on all kinds of other thing-- position ", "coordinates, some other quantities.  But we're focusing on time here, so we'll leave it there.  Moreover, for reasons of convention, ", "just let's always thing of omega as positive.  It wouldn't make a difference if it would be negative here  with the cosine function, but let's just set by convention ", "that omega is positive.  Finally, we're going to do transitions again  from an initial to a final state.  So we will consider the case when  we go from an initial state to a final state. ", "And therefore, we will work in this language  with this constant coefficients Cn's, these  coefficients that multiply the states in psi tilde. ", "Psi tilde is equal to Cn n of t, sum over n.  And these Cn's, at time equals 0, ", "will be equal to delta ni, which means that they are all 0  except when we're talking about Ci at 0 is equal to 1 ", "because we start with an initial state.  We had a general formula for the transition coefficient. ", "And Cm of 1 at time equal t--  or I'll put t0-- ", "is equal to sum over n, integral from 0 to t0 e  to the i omega mn t prime, delta H mn of t prime over i h bar, ", "Cn at time equals 0, dt prime.   This was our general formula for transition coefficients. ", "The Cm's is the coefficient or the amplitude for the state  to be found in the m eigenstate at time t0 ", "to first order in perturbation theory.  And it depends on where you started on.  That's why the sum over n here with initial states. ", "But this sum is going to collapse because we  know we start with the state i.  So when we substitute Cn equal to this, ", "the sum only works when n is equal to i.  So we'll put for ni's.  And, of course, we're going to also take for the final state ", "to be f.  So the formula now reads Cf 1 at t0 ", "is equal to integral from 0 to t0 e to the I omega f--  m was f-- i t prime. ", "And now the delta H. The delta H is this whole quantity,  so we have to substitute it.  So 2 H prime is the only part that has matrix elements. ", "The cosine omega t is just a function.  So it's H prime fi cosine omega t prime, and dt prime. ", " There's the i h bar.  ", "So I think I got everything right.  The sum collapsed.  mn is being replaced by the right labels. ", "mn here, this is the expectation value between m and n.  And that becomes between f and i.  And it affects this whole thing, but it just ", "ends up affecting the Hamiltonian H prime here.  So I think we're OK.  We have everything there.  And Hfi, of course, doesn't have time dependence. ", "So we said H prime has no time dependence.  So that thing can go out of the integral.  So this will go out. ", "And the integral is simple because you have now  Hfi prime over i h bar.  And the 2, we leave it for the cosine. ", "So we get two integrals.  t0 e to the i omega fi plus omega t prime-- ", "from the first exponential in the cosine--  plus an e to the i omega fi minus omega t prime-- ", "from the second exponential in cosine--  dt prime.  Well, that's very nice.  This is all doable.  The Hfi doesn't give us any trouble. ", "It's a constant.  It's out of the integral.  It's all pretty nice and simple.  So we can do these two integrals. ", "They're integrals of exponentials,  so it's just an exponential divided by those coefficients.  So I'll just do it and evaluated it between t0 and 0. ", "So what do we get?  Minus i Hfi prime over h bar, e to the i omega  fi plus omega t0, minus 1, over omega fi plus omega. ", "You can imagine that e to the i omega  t integrates to e to the i omega t over omega.  So that's why that works.  And the two limits are t0 and 0. ", "Plus e to the i omega fi minus omega t0, minus 1  again, over omega fi minus omega. ", "Great.  Our integral is there.  It's done.  And now it's time to appreciate what it tells us,  because it tells us something very important, this formula. ", "", "So you look at this and you say, well, OK.  This is the transition amplitude to state omega--  I'm sorry-- state f, final state. ", "And it depends on omega fi.  And omega fi just Ef minus Ei over h bar. ", "So if I know my final discrete state Ef,  I can figure out what is the transition probability.  Now, these denominators are intriguing because maybe ", "if you adjust the frequency omega--  suppose you have an initial state and a final state here.  You may adjust the frequency omega to match them, ", "and in that case maybe make the denominators equal to 0.  And that's exactly what kind of happens here. ", "So, first of all, if you look at this expression,  it's a sum of two terms that are added together and multiplied  by a constant. ", "As t0 really goes to 0, completely  goes to 0, t0, each factor, actually, ", "if you see the Taylor expansion of the exponential,  you cancel the 1 and you then cancel the linear term  with the denominator.  This is just i t0. ", "And this is also i t0.  So they're comparable as time is really going to 0.  But time going to 0 is never of interest for us. ", "For us, we need to be the time a little big  already so that our calculations,  as we did in the constant transitions that had lobes that ", "decreases constants over t0--  we needed the time to be sufficiently large  so that the lobes are narrow. ", "And that, we could guarantee.  So t0 going to 0 is not very interesting.  We need t0 a little bigger.  Not too big that the rate of a process ", "overwhelms the probability.  But we need a little big.  So, in that case, the numerators are  going to be bounded numbers.  You see, you have an exponential minus 1. ", "So that varies from--  the magnitude of this thing varies from 2 to 0, basically.  In fact, in these numerators, you ", "can see, if the phase is 0 for some particular value--  if the exponential has a phase that's proportional to 2 pi, ", "this is 0.  And then sometimes this exponential is minus 1,  so it gets to minus 2.  So it's finite.  And the same is here.  So these are bounded numerators. ", "On the other hand, you may have the possibility  that these things become 0.  And those are the cases that are of interest to us,  PROFESSOR: OK, so we're good to consider, ", "therefore, the two cases.  So let's consider the first case,  that this can be pretty important,  this case one, when omega fi plus omega is nearly 0. ", "In this case, what's happening?  You have Ef minus Ei plus h bar omega is nearly 0, ", "or Ef roughly equal to Ei minus h bar omega.  So what has happened if you have a number-- so the question is, ", "when this happens, which means that your omega--  that is, your perturbation--  is tailored to produce this, then Ef is Ei minus h omega. ", "So you can think of the energy scale here.  And Ef is lower than Ei.   And the difference is h bar omega. ", "So what is this process?   This process is called stimulated emission.  And why is that called stimulated emission? ", "Because you're going from a state of energy Ei  to a state of energy Ef that has lower energy.  In that process, you're releasing energy h bar omega ", "to the perturbation.  So it's almost-- you would say it's  stimulated because the perturbation did it. ", "Still, it almost seems like something the system  would do by itself.  It has higher energy.  It can go to lower energy and emit something with frequency ", "with energy h omega.  But it does that only because there is a perturbation.  If there was no perturbation, this would not happen. ", "That's why, say if you consider a hydrogen atom or a system,  it's not that the electron that is in a higher state just  jumps by itself down. ", "It jumps by itself out because it can couple  to other degrees of freedom.  And in particular, it can couple to an electromagnetic field  and send out the photon.  So here, you have stimulated emission of energy h bar omega. ", "So stimulated emission-- emission.  ", "And then the other term corresponds to the case  when omega fi minus omega is equal to 0, in which case ", "Ef is equal Ei plus h bar omega.  This time, Ef is higher than Ei h bar omega. ", "And this process is called absorption--   absorption.  ", "You absorb energy h bar omega from the perturbation.  The perturbation is capable of giving the system energy h bar ", "omega to enable a transition between Ei and Ef.  So this harmonic perturbation has two tricks up its sleeve. ", "It can push you up by giving you energy,  or it can stimulate you to go to a lower state  and give energy to the system represented ", "by the perturbation.  So two good things it can do, and both cases  are pretty important.  So we're going to develop one of these cases. ", "The other one has exactly the same formulas.  And we need the Fermi golden rule for this situation.  So that's what I'll do right now.  To fix our notation, let's just do the case of absorption. ", " But both are going to be taken care simultaneously.  So absorption-- so what is C? ", "So when you're doing absorption, you're saying, OK.  I'm basically having this process in which Ef  is related to Ei in this way. ", "This term is becoming 0.  And this term is negligible.  So you can completely ignore one term ", "when you're doing absorption.  And you can ignore the other term  when you're doing a stimulated emission.  You would say, oh, but it's not exact.  What about if I keep it?  Well, there are many things that we don't do exact. ", "This term is much bigger than the other--  in principle, infinitely bigger--  because we're going to be integrated  over a narrow set of states. ", "So it would make no sense to keep those other things.  Those other terms would be much smaller, probably,  at even the next order of perturbation theory. ", "So we keep, therefore, the second term.  And so what do we have?  Cf of t naught 1 minus H fi prime over h bar, e ", "to the i omega fi minus omega t over 2.  You don't see that term, of course. ", "But I'm going to take out half of this phase  so that I get a sine function out here.  So I took out half of the phase. ", "And then I get 2i sine omega fi minus omega t over 2.  ", "OK, that's this thing.  So the probability to go from initial to final state  at time t naught would be the C f1 of t naught squared. ", "And that's 4H fi prime, because of the two here. ", "It's 4H fi prime squared over h squared  sine squared of omega fi minus omega over 2 times time ", "over omega fi minus omega squared.  And this is all for Ef roughly equal to Ei plus h bar omega. ", "So I didn't do much.  I really didn't do all that much so far.  I just took the second term, rewrote it with a sine, ", "and calculated its norm squared.  That's the probability to go from initial to final states.  ", "So the last step is integrating over a final state.  So you have this sum over final states of this probability ", "to go to the final state.  And we'll write it as the integral over the set of states  rho of e final dE final probability ", "final to initial of t naught.   And this is the same calculation we were doing before. ", " And for this calculation, we just substitute what P fi is. ", "We assume that as we integrate, we're  going to have a narrow range so that this function, rho  of Ef and h prime fi can go out of the integral. ", "So what are we going to have?   I'll write it here.  4-- from the matrix element, from this thing-- ", "H fi prime squared over h squared.   That goes out. ", "Then the rho of Ef goes out.  So I'll write it rho of Ef.  And rather than leaving it like Ef,  like that, because it seems like a variable, still, ", "of integration-- if I take it out,  I should be explicit what this Ef is.  And in this case, Ef--  we're doing absorption.  So this is equal to Ei plus h bar omega. ", "That's this central contribution.  And that's where you're taking rho out.  So this is pretty important. ", "This rho is evaluated at the final energy,  which in this process is h omega in addition to Ei. ", "And then the rest of the integral dE f--  you still have dE f-- and the sine function.  So sine squared of omega fi minus omega t over-- ", "t naught, I'm sorry.  I'm missing t naught everywhere.  But I did copy it.  t naught and t naught's up there.  ", "Over 2 over omega fi minus omega squared.  And this is the story of the lobes. ", "This is the function that has the lobes as a function of Ef.  As a function of Ef, this quantity  varies and starts developing the lobes. ", "And the lobes happen for values of Ef  that are separated by some h bar divided by t naught. ", "So this is the exact same integral  we analyzed for the constant transitions.  And it is the same integral that we  argued that could be done as a sine squared x over x squared. ", "So I will not do it again.  This integral gives h bar linear in t naught over 2 pi.  ", "When you study this, you will have the notes  and you can review it.  If you've taken notes, you will see  that is exactly the same integral  we had last time, except that we didn't have the omega, which ", "really doesn't change things.  It just shifts the zero.  So the peak of this contribution is when  omega fi is equal to omega. ", "Before when we did it was when omega fi was equal to 0.  That's why, in the constant transitions  you conserved energy. ", "So with this result in there, the whole answer  here is 2 pi over h bar-- ", " h bar only because one h bar cancels, indeed-- ", "rho at Ef equal Ei plus h omega H fi prime ", "squared times t naught.  That's all that is left, which is great because that  is our Fermi's golden rule. ", "Remember, that's a transition probability.  And the rate is obtained by dividing this  by the time that has elapsed to find the probability per unit ", "time.  That's the rate.  It's probability for transition per unit,  times 2 pi over h bar rho at Ef equal Ei plus h bar ", "omega times the matrix element f H prime initial squared. ", "That's Fermi's golden rule for harmonic transitions,  and in particular, for absorption.  But stimulated emission, the calculation ", "is completely analogous.  So the end result for stimulated emission is just minus H omega.  The final energy now is this one. ", "So the top sine--  plus is for absorption, minus for stimulated emission. ", " And if you want a reminder here, it ", "was that delta H was 2H prime cosine omega t. ", "So this reminds you that this H prime you have here  is the matrix element of the perturbation  with this convention. ", "This omega you have here is the frequency  of the perturbing Hamiltonian.  And that's what has happened.   So this is Fermi's golden rule. ", "It's over.  We've done it, done it basically for two cases--  the constant perturbation and the harmonic perturbation.  And there's a lot of physics here ", "that we will be exploring starting now, but continuing  with atoms and radiation in general, atomic transitions. ", "W is the rate.  So this is called the transition rate per unit time--  transition rate per unit time. ", "So the probability of transition or probability  of transition per unit time--  probability of transition per unit time-- ", " that's probably more understandable than the word  rate.  So this P fi gives you the probability of transition ", "after a time t naught.  Happily, it's proportional to t naught,  so you divide by the time that has elapsed,  and it's a probability of transition per unit time. ", "So once you compute this number, you  get the probability of transition per unit time.  So if this W is something and you have a billion atoms, ", "you multiply that probability by the number of atoms you have,  PROFESSOR: OK, time for us to do one  example, a non-trivial example, which  is the ionization of hydrogen. It's a fun example, ", "and let's see how it goes.  ", "So ionization of hydrogen. Ionization ", "of hydrogen. Very good.  So we're going to think of a hydrogen atom  on its ground state sitting there, ", "and then you shine an electromagnetic field,  and if the electromagnetic field is sufficiently strong, ", "the electron is going to be kicked out  by interacting, typically with the electric field of the wave.  So the wave comes in and interacts. ", "So we usually think of this in terms of photons.  So we'll have a hydrogen atom in its ground state. ", " And then you have a harmonic e field, ", "and the electron could get ejected.  So typically, you have a photon in this incident. ", "We think of this in terms of electromagnetism,  although our treatment of electromagnetism  was not going to include photons in our description. ", "But we physically think of a photon  that this incident on this-- here's a proton.  Here is the electron going in circles, ", "and the photon comes in, a photon gamma,  and it kicks the electron out.   So the photon has energy e of the photon is h bar omega. ", "So when we think of putting a light beam,  and we're going to send many photos,  we have to think of each photon, what it's doing-- ", "whether the energy is very big, whether the energy is  very small, and how does it affect our approximation.  So half of the story of doing such a calculation ", "is understanding when it could be valid,  because we're going to assume a series of things ", "in doing the calculation.  And the validity still won't turn out  to be for a rather wide range of values.  But we have to think about it. ", "So a couple of quantities you'll want to consider  is that the energy of the electron, energy ", "of the electron that is ejected is  h bar squared k of the electron that is ejected,  k squared over 2m of the electron. ", "And it's going to be equal to the energy of the photon  minus the ground state energy of the electron in the hydrogen ", "atom.  So the hydrogen atom here is energy equal 0.  Ground state is below 0. ", "So if you supply some energy, the first part of the energy  has to be to get it to energy 0, and then  to supply kinetic energy.  So the kinetic energy is the energy of the photon minus ", "what this called the Rydberg, or Ry.  The Rydberg is 13.6 eV with a plus sign. ", "And that's the magnitude of the depth of the well.   The Rydberg is e squared over 2a0 or 2 times the Rydberg is e ", "squared over a0.   That's what was calculated, and this is actually  equal to h bar c the constant alpha times h bar c over a0. ", "remember, the constant alpha was e squared over h bar c.  So those are some quantities.  OK.  ", "So we need the electron to be able to go out.  The energy of the photon must be bigger than a Rydberg.   OK, so conditions for our approximation. ", "One.  We're going to be using our harmonic variation.  We said in our harmonic variation,  Hamiltonian delta h was 2h prime cosine of omega t, ", "and we want this h prime to be simple enough.  We want to think of this photon that is coming into the atom ", "as a plane wave, something that doesn't  have big spatial dependence in the atom.  It hits the whole atom as with a uniform electric field. ", "The electric field is changing in time.  It's going up and down, but it's the same everywhere  in the atom.  So for that, we need that-- ", " if you have a wave, it has a wavelength, ", "if you have an atom that is this big,  you would have the different parts  of the atom are experiencing different values  of the electric field at the same time. ", "On the other hand, if the wavelength is very big,  the atom is experiencing the same spatially independent  electric field at every instant of time. ", "It's just varying up and down, but everywhere in the atom  is all the same.  So what we want for this is that lambda of the photon ", "be much greater than a0.  So that-- 1.  ", "So this means that the photon has to have sufficiently long  wave, and you cannot be too energetic.  If you're too energetic, the photon wave length ", "is too little.  By the time it becomes smaller than a0,  your approximation is not going to be good enough.  You're going to have to include the spatial dependence  of the wave everywhere. ", "It's going to make it much harder.  So we want to see what that means,  and in the interest of time, I will tell you  with a little bit of manipulation, ", "this shows that h omega over a Rydberg  must be much smaller than 4 pi over alpha, which ", "is about 1,772.  So that that's a condition for the energy.  The energy of the photon cannot exceed that much. ", " And let's write it here.  So that's a good exercise for you to do it. ", "You can see it also in the notes just  manipulating the quantities.   And this actually says h omega is much less than 23 keV. ", " OK, 23 keV is roughly the energy of a photon ", "whose wavelength is a0.   That's a nice thing to know.  OK.  While this photon cannot be too energetic, ", "it has to be somewhat energetic as well,  because it has to kick out the electron.  So at least, must be more energy than a Rydberg. ", "But if it just has a Rydberg energy,  it's just basically going to take the electron out  to 0 energy, and then you're going to have a problem. ", "People in the hydrogen atom compute the bound state  spectrum, and they computer the continuous spectrum  in the hydrogen atom, in which you  calculate the plane waves of the hydrogen atom, how they look. ", "They're not all that simple, because they're  affected by the hydrogen atom.  They're very interesting complicated solutions  for approximate plane waves in the presence of the hydrogen ", "atom.  And we don't want to get into that.  That's complicated.  We want to consider cases where the electron,  once it escapes the proton, it's basically a plane wave. ", "So that requires that the energy of the photon  is not just a little bit bigger than a Rydberg, ", "but it's much bigger a Rydberg.   And saw the electron, the free electron ", "does not feel the Coulomb field of the proton. ", " And it's really a plane wave.  So here, it's a point where you decide, ", "and let's be conventional and say  that 1 is much less than 10.  That's what we mean by much less 1/10. ", "So with this approximation, h omega  must be much bigger than 13.6.  So it should be bigger than 140 eV. ", "That's 10 times that.  And it should be smaller, much smaller and 23 keV,  so that's 2.3 keV. ", " So this is a range, and we can expect our answer  to make sense.  ", "If you want to do better, you have to work harder.  You can do better.  People have done this calculation better and better.  But you have to work much harder. ", "I want to emphasize one more thing that is maybe I  can leave you this an exercise.  So whenever you have a photon in this range,  you can calculate the k of the electrode, ", "and you can calculate how does the k of the electron behave.  And you find that k of the electron times a0  is in between 13 and 3 for these numbers. ", "When the energy of the photon is between those values,  you can calculate the momentum of the electron, k  of the electron.  I sometimes put an e to remind us of the electron. ", "But I'll erase it.  I think it's not necessary.   And that's the range. ", "OK.  So we're preparing the grounds.  You see, this is our typical additive.  We're given a problem, a complicated problem,  and we take our time to get started. ", "We just think when will it be valid, what can we do.  And don't rush too much.  That's not the attitude in an exam, ", "but when you're thinking about the problem in general, yes,  it is the best attitude.  So let's describe what the electric field is going to do. ", " That's the place where we connect now  to an electric field that is going  to produce the ionization.  So remember the perturbation of the Hamiltonian, ", "now, it's going to be the coupling of the system  to an electric field.  And this system is our electrons.  So it's minus the electron times the potential, electric ", "potential, scalar potential.  ", "Now, needless to say, actually, the electron  that is going to be kicked out it's  going to be non-relativistic. ", "That's also kind of obvious here.  You see h omega is 2.3 keV.  You subtract 13.6 eV.  Doesn't make any difference. ", "So that's the energy of the emitted electron roughly,  and for that energy, that's much smaller than 511 keV, which is ", "the rest mass of an electron.  So that electron is going to be non-relativistic,  which is important, too, because we're not trying  to do Dirac equation now. ", "So here is our potential, and then we'll  write the electric field.  Let's see.  The electric field. ", "We will align it to the z-axis to begin with.   2e0 cosine omega t times z hat. ", "These are conventions.  You see, we align it along the z-axis,  and we say it has a harmonic dependence.  That's the frequency.  That's the frequency of the photons that we've been talking ", "about, and the intensity, again, for these convention preference  will put 2e0 times cosine omega t. ", "So some people say ep, which is the peak e field is 2e0. ", "That's our convention.   Well, when you have an electric field like that, ", "the electric field is minus the gradient of phi,  and therefore, we can take phi to be ", "equal to minus the electric field as a function of time,  times z.  ", "So if you take the gradient minus the gradient,  you get the electric field.  And therefore, we have to plug it all in here. ", "So this is plus e, e of t, z, and this is e. ", "e of t has been given 2e0 cosine omega t.  And z, we can write this r cosine theta. ", "In the usual description, we have the z-axis  here, r, theta, and the electric field  is going in the z direction.  So z's are cosine theta. ", "So I think I have all my constants there.  So let's put it 2 e, e0, r cos theta cos omega t, ", "and this is our perturbation that we said  it's 2h prime cosine omega t.  That's harmonic perturbations were defined that way. ", "So we read the value of h prime as this one.   e e0 r cosine omega t. ", "No, r cosine theta.   OK.  We have our h prime. ", "So we have the conditions of validity.  We have our h prime.  Two more things so that we can really get started. ", "What is our initial state?  The initial state is the wave function  of the electron, which is 1 over square root of pi a0 cubed ", "e to the minus r over a0.  That's our initial state.  What is our final state, our momentum eigenstates ", "of the electron?  So you could call them psi, or u sub k of the electron. ", "And it would be 1 over l to the 3/2, e  to the ik of the electron times x.  ", "These are our initial and final states.  Remember, the plane waves had to be normalized in a box. ", "So the box is back.  u is the wave function of the plane wave electron.  And we could use a plane wave, because the electron  is energetic enough. ", "And it has the box thing.  This is perfectly well normalized.  If you square it, the exponential  vanishes, because it's a pure phase, ", "and you get 1 over l cubed.  The box has volume l cubed.  It's perfectly normalized.  PROFESSOR: We have to set up a little better the geometry ", "of the calculation.  And for that we have to think of various angles.  We oriented there the electric field along the z direction. ", "But that's not going to be too convenient for our calculation.  So these calculations are a bit of an art to do them. ", "They're not that trivial.  Not terribly difficult. But I think if you appreciate it,  next time you ever have to do one of these things ", "it will become clear.  So first your have to think physically.  Is there an angle in this problem? ", "Is there any important angle happening here?   It's a question to you. ", " I think if you figure out that you have a chance of doing ", "a diagram that reflects this.  Is there a physical angle, you think, in this process?  A relevant angle? ", "Yes, Lou?  AUDIENCE: [INAUDIBLE]  PROFESSOR: Perfect.  Yeah.  The relevant angle is you have a directional ", "ready for the electric field.  So if the electron comes off there's  going to be an angle with respect to that electric field.  So that's our physical angle in this question. ", "So let's try to draw this in a way.  So I will draw it this way.  ", "And I brought colored chalk for this.  I'll put the z-axis here, and I'll put the electron momentum ", "in this direction.   k is the lateral momentum.  Now the electric field is going to come  at some angle with respect to the-- ", "or the electron momentum is at some angle with respect  to the electric field.  So that angle will presumably stay there  for the rest of the calculation. ", "So let's do it with green.  So here is my electric field.  And it's going to have an angle theta with respect ", "to the direction of the electric field or the photon incident  direction.  ", "Now, this is actually more like the polarization of the photon.  The electric field is the direction of the polarization ", "of the photon.  So one more vector, however, the position that we  have to integrate over--  because we have the whole hydrogen atom and the whole ", "of space to integrate.  So x has a position.  So I'll use another color here.  Unfortunately, the colors are not that different.  Here is r, the vector r. ", " So now I have several angles.  I have theta for the electric field. ", "But now that I've put all this axis I not only have theta,  but I also have phi for the electric field. ", "And for r, I will have theta prime and phi prime. ", " So r has a theta prime and a phi prime.  We usually have theta and phi. ", "But the answers, at the end of the day,  are going to depend on theta.   And if you have theta here, we want the theta to remain. ", "So theta prime and phi prime are going  to be our variables of integration  because you integrate over r.  Finally, we have one more angle that we have to define. ", "So we have theta phi, theta prime, phi prime,  and the angle that was here--  ", "this was the angle between r and the direction  of the electric field.  And we called it theta.  So we have to give it a new name here. ", "And this angle, I'll call it gamma here.  ", "The angle between E and r.   OK.  So We have everything defined here. ", "Maybe I should list it.  E has angles theta and phi, the direction of E. r ", "has angles theta prime and phi prime.  And gamma is the angle between E and r. ", "And k along z hat.  So this is our situation. ", " So what are we trying to calculate? ", "Well, we want to use Fermi's golden rule.  So we need to calculate final H prime initial. ", "That's the matrix element of the Hamiltonian H  prime between the final and initial states.  ", "So what is this?  Well, these are all wave functions  that depend all over space, and this is a function of space.  So let's do it.  This is integral d cubed x. ", "Let's put the final state first because it shows up there.  So it's 1 over L cubed e to the minus i k dot r. ", " So here is our final state, u final.  Then the Hamiltonian. ", "That's simple.  e E0 r cosine what?   Cosine gamma. ", "Is that right?  This is what we had there.  It's the angle between the electric field and r. ", "It was theta to begin but now has become gamma.   And then the final state.  So this is our H prime. ", "And then the initial state is 1 over pi a0 cubed  e to the minus r over a0. ", "OK.  This is our task.  This is a matrix, and here it is.  An integral of a plane wave against an electron wave ", "function and an extra r dependence here.  This could range from undoable to difficult, basically. ", "And happily, it's just a little difficult.  But this is an integral--  we'll see what are the challenges on this integral.  So let's take a few constants out. ", "So e, E0, pi, a0, that all will go out.  So this is e E0 over square root of pi l cubed a0 cubed. ", "So I took the l's out, the e, E, this thing.  All right.  ", "Let's write the integral more explicitly.  This is r squared dr sine the volume element. ", "Sine theta d theta d phi.  But I'm integrating over x, which is integrating over r. ", "And r is theta prime and phi prime.  So these are all these ones.  I'm integrating over all values of theta prime and phi prime. ", " Then what do I have?  I have this exponent, k dot r.  Well, my diagram shows how k dot r is easy. ", "It involves a cosine of theta prime.  So it's e to the minus ik, the magnitude of k, ", "the magnitude of r cosine theta prime,  because after all, k was along the z-axis.  r is along the phi theta prime direction. ", " OK.  We're progressing.  This, this, that term, it's r cosine gamma. ", " And the final term is not that difficult. e to the minus r  over a0. ", "That's what we have to do.  An integral over phi prime, theta prime, and r.   This is our challenge. ", " And the reason it's a challenge is the cosine gamma  because this gamma is the angle. ", "It depends on theta, depends on theta prime, depends on phi,  phi prime.  That's the problem.  If we can solve that cosine gamma thing ", "we can do this integral.  And I think even if you were doing it numerically,  that cosine gamma there is a little bit of a headache. ", "You don't want to do an integral that you can really  do like this numerically.  So you really want to do it.  So what we need is to calculate.  So we can begin by saying, I'm going ", "to calculate what cosine gamma is.   And here is the way you can calculate cosine gamma. ", "When you have two unit vectors, cosine  of the angle between two unit vectors  is just the dot product of those two unit vectors. ", "So for gamma, we can consider a unit vector along e  and a unit vector along r and take the dot product. ", "And remember, for an arbitrary unit vector,  it's sine theta cos phi sine theta sine phi cos theta. ", "This is the theta phi decomposition  of an arbitrary unit vector.  So cosine gamma is the dot product ", "of a vector n along the e times a vector n along r. ", "And vector n along e and r are just  with theta in one case and phi and theta prime and phi prime.  So when I make the dot product, I ", "get sine theta, cos phi, sine theta prime, cos phi prime. ", "That is the product of the x components.  Plus sine theta, sine phi prime times sine theta and sine phi. ", "Sine theta prime sine phi prime, plus cos theta,  cos theta prime.  ", "OK.  Doesn't look much easier, but at least it's explicit.  But it's actually much easier.  ", "And why is that?  Because there's a lot of factors in common here.  ", "In fact, sine theta and sine theta prime are in both.  ", "So what you get here is cosine gamma  is equal to sine theta sine theta prime. ", "And then you have cos phi, cos phi  prime, plus sine phi, sine phi prime.  And that's cosine of phi minus phi prime plus cos theta cos ", "theta prime.   OK.  So that's cosine gamma.  Now suppose you were to put this whole thing in here. ", "It's a big mess but all quantities that we know.  But there's one nice thing, though--  a very nice thing happening. ", "Think of the interval over d phi prime.   This does not depend on phi prime. ", "This does not depend on phi prime.  But cosine gamma can depend on phi prime.  But here it has this thing, cosine of phi minus phi prime. ", "So when you try to do the integral of this phi prime  with this term, this term will give,  eventually, the integral of d phi prime times ", "cosine of phi minus phi prime.  There is a lot of messy things.  But this integral is 0 because you  are averaging over a full term. ", "So happily, all this term will not contribute.  And that's what makes the integral doable. ", "So what do we have then?  Our whole matrix element, f H prime i, ", "has become e E0 over square root of pi l cube a0 cube. ", " And now you just have to integrate.  This is the only term that contributes.  ", "And when you put this term, for sure  you can now do the d phi prime integral  because that term is phi dependent. ", "So that integral gives you just a factor  of 2 pi from the integral of d phi. ", "And from this thing, cosine theta  is the angle between the electric field and k.  So it's a constant for your integral.  You're integrating over theta prime and phi prime. ", "So cosine theta also goes out.   And here is the integral that remains.  r cube dr. It was r squared, but there was an extra r ", "from the perturbation.  r cubed dr into the minus a over r--  r over a0. ", "And this thing you can pass two cosine variables.  It's pretty useful.  So this goes minus 1 to 1 d cos theta ", "prime, cos theta prime e to the minus ikr cos theta prime.  ", "This cos theta prime came from here.   And that's it. ", "So this is a nice result. It looks still difficult, ", "but we've made great progress.  And in fact, we've dealt with a really difficult part  of this problem, which is orienting yourself  of how you're going to approach the matrix element. ", "So to finish up I'll just give you a little more  of the answer.  We'll complete the discussion.  We need probably 15 more minutes to finish it up. ", "So the only thing I'm going to say now  is that if you look at the notes,  every integral here is easily doable.  ", "So basically, there's two integrals.  And the way to do them is first do the r integral. ", "You will have to have these terms.  And then do the theta integral.  And they are kind of simple, both of them. ", "You have to keep up a lot of constants.  But here is the answer for the matrix element.  So that part of the integral I think you all can do. ", "But you have to take your time.  i 32 square root of pi e E0 a0. ", "I did a lot of work here, actually,  in writing it in a comprehensible way  because it's pretty messy.  l cube a0 cube, 1 over 1 plus k squared ", "a0 squared cube cosine theta.  By now, it starts to simplify a little.  ", "OK.  That was actually plenty of work to get it to write it this way.  I feel pretty happy about that writing.  Why? ", "First, OK, there is these numbers.  Nothing I can do about it.  But there's a multitude of constants  that I have simplified and done all kinds of things.  But it was not worth it.  First, ka0, that is unit free. ", "This is unit free.  This is unit free.  k is 1 over length.  ka0 to the 4 is the length cube, and here is the length cube. ", "No units here either.  Here, nice units.  This is units of energy.  Why?  Electric field times distance is potential, ", "times electric charge is energy.  Energy.  So this is how this should be.  The matrix element of an energy between normalizable states ", "should be an energy.  And that has become clear here.  The next steps that we have to do, which we'll do next time,  is to integrate over states, and put in the density of states, ", "and do a little simplification.  But now it's all trivial.  We don't really have to integrate anymore  because Fermi's golden rule did the job for us. "], "vid_duration": [12.95, 11.56, 12.32, 10.73, 12.99, 11.8, 10.11, 10.59, 11.6, 14.62, 13.39, 15.96, 11.31, 12.29, 11.79, 12.47, 12.34, 12.63, 10.85, 11.86, 13.34, 10.53, 12.18, 17.23, 13.75, 17.74, 12.57, 10.27, 10.36, 19.42, 13.33, 11.31, 10.64, 10.6, 11.21, 10.19, 13.9, 15.1, 13.995, 11.775, 10.64, 10.38, 15.94, 12.85, 12.06, 15.63, 10.83, 11.55, 10.36, 13.02, 20.67, 15.09, 16.46, 10.665, 10.435, 12.63, 15.34, 14.6, 11.91, 14.3, 11.6, 10.54, 12.32, 12.25, 13.49, 10.24, 12.15, 13.03, 10.82, 10.62, 12.69, 12.895, 17.15, 12.96, 14.56, 13.1, 12.34, 12.66, 15.27, 12.39, 11.669, 10.721, 10.97, 15.63, 13.07, 13.73, 15.01, 10.7, 12.63, 13.81, 13.46, 12.13, 13.49, 15.3, 12.75, 11.092, 14.317, 10.221, 10.61, 19.16, 11.11, 11.46, 12.96, 18.92, 11.01, 15.54, 16.19, 10.05, 14.14, 10.45, 14.88, 11.1, 11.19, 15.5, 13.16, 11.639, 13.611, 14.55, 10.2, 10.77, 17.94, 12.94, 11.83, 12.17, 11.87, 15.06, 12.3, 15.18, 10.77, 11.16, 10.455, 10.815, 12.64, 12.58, 11.88, 17.82, 11.7, 13.98, 11.2, 10.78, 13.279, 10.441, 10.47, 14.1, 10.719, 12.621, 16.03, 15.84, 12.89, 12.69, 10.44, 12.868, 24.57, 15.18, 13.91, 12.04, 11.16, 12.84, 12.77, 14.33, 12.6, 10.02, 17.11, 11.84, 13.08, 11.31, 11.94, 10.02, 15.07, 11.12, 12.98, 11.94, 11.25, 23.14, 21.36, 12.95, 13.72, 15.36, 11.07, 14.31, 12.83, 12.07, 13.44, 12.41, 11.65, 11.8, 11.38, 11.3, 15.28, 11.098, 13.582, 13.37, 17.96, 10.93, 14.02, 12.09, 13.89, 14.58, 12.81, 14.88, 11.65, 16.59, 12.19, 13.74, 12.51, 15.38, 11.96, 12.95, 11.56, 15.29, 18.29, 12.09, 10.001, 10.999, 10.47, 15.39, 13.56, 15.7, 14.53, 10.68, 11.14, 12.53, 11.37, 10.95, 12.75, 12.12, 10.35, 10.38, 10.18, 10.28, 12.15, 13.26, 11.606, 12.394, 13.57, 14.1, 11.82, 13.68, 12.36, 12.21, 10.94, 11.1, 12.72, 12.26, 10.2, 12.21, 11.25, 14.418, 13.15, 11.91, 10.73, 12.72, 10.32, 10.4, 10.9, 10.63, 10.72, 10.932, 11.056, 12.582, 10.06, 13.67, 11.19, 12.71, 13.98, 12.69, 11.57, 12.37, 13.93, 11.29, 13.25, 11.82, 11.58, 11.53, 11.29, 12.29, 10.01, 13.39, 10.32, 11.25, 13.74, 11.53, 15.03, 11.13, 10.335, 12.725, 10.63, 12.89, 11.39, 11.38, 10.304, 12.946, 17.7, 10.72, 11.76, 10.11, 11.68, 13.645, 11.105, 11.718, 12.132, 10.45, 10.36, 12.21, 12.3, 10.18, 11.57, 11.72, 11.13, 12.18, 17.69, 13.17, 10.09, 12.03, 12.27, 16.97, 12.47, 19.66, 11.47, 11.05, 12.94, 19.09, 13.72, 10.08, 11.13, 12.6, 11.52, 12.36, 13.17, 10.08, 10.185, 18.155, 10.78, 10.8, 12.72, 13.09, 11.67, 15.6, 11.66, 10.06, 14.15, 11.95, 12.44, 12.54, 10.26, 11.2, 12.04, 11.62, 17.64, 12.67, 11.08, 15.87, 11.64, 12.82, 14.25, 12.94, 7.709], "stet": [[0, 12.95], [12.95, 24.509999999999998], [24.509999999999998, 36.83], [36.83, 47.56], [47.56, 60.550000000000004], [60.550000000000004, 72.35000000000001], [72.35000000000001, 82.46000000000001], [82.46000000000001, 93.05000000000001], [93.05000000000001, 104.65], [104.65, 119.27000000000001], [119.27000000000001, 132.66000000000003], [132.66000000000003, 148.62000000000003], [148.62000000000003, 159.93000000000004], [159.93000000000004, 172.22000000000003], [172.22000000000003, 184.01000000000002], [184.01000000000002, 196.48000000000002], [196.48000000000002, 208.82000000000002], [208.82000000000002, 221.45000000000002], [221.45000000000002, 232.3], [232.3, 244.16000000000003], [244.16000000000003, 257.5], [257.5, 268.03], [268.03, 280.21], [280.21, 297.44], [297.44, 311.19], [311.19, 328.93], [328.93, 341.5], [341.5, 351.77], [351.77, 362.13], [362.13, 381.55], [381.55, 394.88], [394.88, 406.19], [406.19, 416.83], [416.83, 427.43], [427.43, 438.64], [438.64, 448.83], [448.83, 462.72999999999996], [462.72999999999996, 477.83], [477.83, 491.825], [491.825, 503.59999999999997], [503.59999999999997, 514.24], [514.24, 524.62], [524.62, 540.5600000000001], [540.5600000000001, 553.4100000000001], [553.4100000000001, 565.47], [565.47, 581.1], [581.1, 591.9300000000001], [591.9300000000001, 603.48], [603.48, 613.84], [613.84, 626.86], [626.86, 647.53], [647.53, 662.62], [662.62, 679.08], [679.08, 689.745], [689.745, 700.18], [700.18, 712.81], [712.81, 728.15], [728.15, 742.75], [742.75, 754.66], [754.66, 768.9599999999999], [768.9599999999999, 780.56], [780.56, 791.0999999999999], [791.0999999999999, 803.42], [803.42, 815.67], [815.67, 829.16], [829.16, 839.4], [839.4, 851.55], [851.55, 864.5799999999999], [864.5799999999999, 875.4], [875.4, 886.02], [886.02, 898.71], [898.71, 911.605], [911.605, 928.755], [928.755, 941.715], [941.715, 956.275], [956.275, 969.375], [969.375, 981.715], [981.715, 994.375], [994.375, 1009.645], [1009.645, 1022.035], [1022.035, 1033.704], [1033.704, 1044.425], [1044.425, 1055.395], [1055.395, 1071.025], [1071.025, 1084.095], [1084.095, 1097.825], [1097.825, 1112.835], [1112.835, 1123.535], [1123.535, 1136.1650000000002], [1136.1650000000002, 1149.9750000000001], [1149.9750000000001, 1163.4350000000002], [1163.4350000000002, 1175.5650000000003], [1175.5650000000003, 1189.0550000000003], [1189.0550000000003, 1204.3550000000002], [1204.3550000000002, 1217.1050000000002], [1217.1050000000002, 1228.1970000000003], [1228.1970000000003, 1242.5140000000004], [1242.5140000000004, 1252.7350000000004], [1252.7350000000004, 1263.3450000000003], [1263.3450000000003, 1282.5050000000003], [1282.5050000000003, 1293.6150000000002], [1293.6150000000002, 1305.0750000000003], [1305.0750000000003, 1318.0350000000003], [1318.0350000000003, 1336.9550000000004], [1336.9550000000004, 1347.9650000000004], [1347.9650000000004, 1363.5050000000003], [1363.5050000000003, 1379.6950000000004], [1379.6950000000004, 1389.7450000000003], [1389.7450000000003, 1403.8850000000004], [1403.8850000000004, 1414.3350000000005], [1414.3350000000005, 1429.2150000000006], [1429.2150000000006, 1440.3150000000005], [1440.3150000000005, 1451.5050000000006], [1451.5050000000006, 1467.0050000000006], [1467.0050000000006, 1480.1650000000006], [1480.1650000000006, 1491.8040000000005], [1491.8040000000005, 1505.4150000000006], [1505.4150000000006, 1519.9650000000006], [1519.9650000000006, 1530.1650000000006], [1530.1650000000006, 1540.9350000000006], [1540.9350000000006, 1558.8750000000007], [1558.8750000000007, 1571.8150000000007], [1571.8150000000007, 1583.6450000000007], [1583.6450000000007, 1595.8150000000007], [1595.8150000000007, 1607.6850000000006], [1607.6850000000006, 1622.7450000000006], [1622.7450000000006, 1635.0450000000005], [1635.0450000000005, 1650.2250000000006], [1650.2250000000006, 1660.9950000000006], [1660.9950000000006, 1672.1550000000007], [1672.1550000000007, 1682.6100000000006], [1682.6100000000006, 1693.4250000000006], [1693.4250000000006, 1706.0650000000007], [1706.0650000000007, 1718.6450000000007], [1718.6450000000007, 1730.5250000000008], [1730.5250000000008, 1748.3450000000007], [1748.3450000000007, 1760.0450000000008], [1760.0450000000008, 1774.0250000000008], [1774.0250000000008, 1785.2250000000008], [1785.2250000000008, 1796.0050000000008], [1796.0050000000008, 1809.2840000000008], [1809.2840000000008, 1819.7250000000008], [1819.7250000000008, 1830.1950000000008], [1830.1950000000008, 1844.2950000000008], [1844.2950000000008, 1855.0140000000008], [1855.0140000000008, 1867.635000000001], [1867.635000000001, 1883.6650000000009], [1883.6650000000009, 1899.5050000000008], [1899.5050000000008, 1912.395000000001], [1912.395000000001, 1925.085000000001], [1925.085000000001, 1935.525000000001], [1935.525000000001, 1948.393000000001], [1948.393000000001, 1972.9630000000009], [1972.9630000000009, 1988.143000000001], [1988.143000000001, 2002.053000000001], [2002.053000000001, 2014.093000000001], [2014.093000000001, 2025.253000000001], [2025.253000000001, 2038.093000000001], [2038.093000000001, 2050.863000000001], [2050.863000000001, 2065.193000000001], [2065.193000000001, 2077.793000000001], [2077.793000000001, 2087.813000000001], [2087.813000000001, 2104.923000000001], [2104.923000000001, 2116.7630000000013], [2116.7630000000013, 2129.843000000001], [2129.843000000001, 2141.153000000001], [2141.153000000001, 2153.093000000001], [2153.093000000001, 2163.113000000001], [2163.113000000001, 2178.1830000000014], [2178.1830000000014, 2189.3030000000012], [2189.3030000000012, 2202.2830000000013], [2202.2830000000013, 2214.2230000000013], [2214.2230000000013, 2225.4730000000013], [2225.4730000000013, 2248.613000000001], [2248.613000000001, 2269.9730000000013], [2269.9730000000013, 2282.923000000001], [2282.923000000001, 2296.643000000001], [2296.643000000001, 2312.003000000001], [2312.003000000001, 2323.0730000000012], [2323.0730000000012, 2337.383000000001], [2337.383000000001, 2350.213000000001], [2350.213000000001, 2362.2830000000013], [2362.2830000000013, 2375.7230000000013], [2375.7230000000013, 2388.133000000001], [2388.133000000001, 2399.7830000000013], [2399.7830000000013, 2411.5830000000014], [2411.5830000000014, 2422.9630000000016], [2422.9630000000016, 2434.2630000000017], [2434.2630000000017, 2449.543000000002], [2449.543000000002, 2460.641000000002], [2460.641000000002, 2474.223000000002], [2474.223000000002, 2487.5930000000017], [2487.5930000000017, 2505.5530000000017], [2505.5530000000017, 2516.4830000000015], [2516.4830000000015, 2530.5030000000015], [2530.5030000000015, 2542.5930000000017], [2542.5930000000017, 2556.4830000000015], [2556.4830000000015, 2571.0630000000015], [2571.0630000000015, 2583.8730000000014], [2583.8730000000014, 2598.7530000000015], [2598.7530000000015, 2610.4030000000016], [2610.4030000000016, 2626.9930000000018], [2626.9930000000018, 2639.183000000002], [2639.183000000002, 2652.9230000000016], [2652.9230000000016, 2665.433000000002], [2665.433000000002, 2680.813000000002], [2680.813000000002, 2692.773000000002], [2692.773000000002, 2705.723000000002], [2705.723000000002, 2717.2830000000017], [2717.2830000000017, 2732.5730000000017], [2732.5730000000017, 2750.8630000000016], [2750.8630000000016, 2762.953000000002], [2762.953000000002, 2772.954000000002], [2772.954000000002, 2783.953000000002], [2783.953000000002, 2794.4230000000016], [2794.4230000000016, 2809.8130000000015], [2809.8130000000015, 2823.3730000000014], [2823.3730000000014, 2839.0730000000012], [2839.0730000000012, 2853.6030000000014], [2853.6030000000014, 2864.2830000000013], [2864.2830000000013, 2875.423000000001], [2875.423000000001, 2887.9530000000013], [2887.9530000000013, 2899.3230000000012], [2899.3230000000012, 2910.273000000001], [2910.273000000001, 2923.023000000001], [2923.023000000001, 2935.143000000001], [2935.143000000001, 2945.493000000001], [2945.493000000001, 2955.873000000001], [2955.873000000001, 2966.053000000001], [2966.053000000001, 2976.333000000001], [2976.333000000001, 2988.483000000001], [2988.483000000001, 3001.7430000000013], [3001.7430000000013, 3013.3490000000015], [3013.3490000000015, 3025.7430000000013], [3025.7430000000013, 3039.3130000000015], [3039.3130000000015, 3053.4130000000014], [3053.4130000000014, 3065.2330000000015], [3065.2330000000015, 3078.9130000000014], [3078.9130000000014, 3091.2730000000015], [3091.2730000000015, 3103.4830000000015], [3103.4830000000015, 3114.4230000000016], [3114.4230000000016, 3125.5230000000015], [3125.5230000000015, 3138.2430000000013], [3138.2430000000013, 3150.5030000000015], [3150.5030000000015, 3160.7030000000013], [3160.7030000000013, 3172.9130000000014], [3172.9130000000014, 3184.1630000000014], [3184.1630000000014, 3198.5810000000015], [3198.5810000000015, 3211.7310000000016], [3211.7310000000016, 3223.6410000000014], [3223.6410000000014, 3234.3710000000015], [3234.3710000000015, 3247.0910000000013], [3247.0910000000013, 3257.4110000000014], [3257.4110000000014, 3267.8110000000015], [3267.8110000000015, 3278.7110000000016], [3278.7110000000016, 3289.3410000000017], [3289.3410000000017, 3300.0610000000015], [3300.0610000000015, 3310.9930000000013], [3310.9930000000013, 3322.0490000000013], [3322.0490000000013, 3334.631000000001], [3334.631000000001, 3344.691000000001], [3344.691000000001, 3358.3610000000012], [3358.3610000000012, 3369.5510000000013], [3369.5510000000013, 3382.2610000000013], [3382.2610000000013, 3396.2410000000013], [3396.2410000000013, 3408.9310000000014], [3408.9310000000014, 3420.5010000000016], [3420.5010000000016, 3432.8710000000015], [3432.8710000000015, 3446.8010000000013], [3446.8010000000013, 3458.0910000000013], [3458.0910000000013, 3471.3410000000013], [3471.3410000000013, 3483.1610000000014], [3483.1610000000014, 3494.7410000000013], [3494.7410000000013, 3506.2710000000015], [3506.2710000000015, 3517.5610000000015], [3517.5610000000015, 3529.8510000000015], [3529.8510000000015, 3539.8610000000017], [3539.8610000000017, 3553.2510000000016], [3553.2510000000016, 3563.5710000000017], [3563.5710000000017, 3574.8210000000017], [3574.8210000000017, 3588.5610000000015], [3588.5610000000015, 3600.0910000000017], [3600.0910000000017, 3615.121000000002], [3615.121000000002, 3626.251000000002], [3626.251000000002, 3636.586000000002], [3636.586000000002, 3649.311000000002], [3649.311000000002, 3659.941000000002], [3659.941000000002, 3672.831000000002], [3672.831000000002, 3684.221000000002], [3684.221000000002, 3695.601000000002], [3695.601000000002, 3705.905000000002], [3705.905000000002, 3718.851000000002], [3718.851000000002, 3736.5510000000017], [3736.5510000000017, 3747.2710000000015], [3747.2710000000015, 3759.0310000000018], [3759.0310000000018, 3769.141000000002], [3769.141000000002, 3780.8210000000017], [3780.8210000000017, 3794.4660000000017], [3794.4660000000017, 3805.5710000000017], [3805.5710000000017, 3817.2890000000016], [3817.2890000000016, 3829.4210000000016], [3829.4210000000016, 3839.8710000000015], [3839.8710000000015, 3850.2310000000016], [3850.2310000000016, 3862.4410000000016], [3862.4410000000016, 3874.741000000002], [3874.741000000002, 3884.9210000000016], [3884.9210000000016, 3896.491000000002], [3896.491000000002, 3908.2110000000016], [3908.2110000000016, 3919.3410000000017], [3919.3410000000017, 3931.5210000000015], [3931.5210000000015, 3949.2110000000016], [3949.2110000000016, 3962.3810000000017], [3962.3810000000017, 3972.471000000002], [3972.471000000002, 3984.501000000002], [3984.501000000002, 3996.771000000002], [3996.771000000002, 4013.741000000002], [4013.741000000002, 4026.2110000000016], [4026.2110000000016, 4045.8710000000015], [4045.8710000000015, 4057.3410000000013], [4057.3410000000013, 4068.3910000000014], [4068.3910000000014, 4081.3310000000015], [4081.3310000000015, 4100.421000000001], [4100.421000000001, 4114.141000000001], [4114.141000000001, 4124.221000000001], [4124.221000000001, 4135.3510000000015], [4135.3510000000015, 4147.951000000002], [4147.951000000002, 4159.471000000002], [4159.471000000002, 4171.831000000002], [4171.831000000002, 4185.001000000002], [4185.001000000002, 4195.081000000002], [4195.081000000002, 4205.266000000002], [4205.266000000002, 4223.421000000002], [4223.421000000002, 4234.201000000002], [4234.201000000002, 4245.001000000002], [4245.001000000002, 4257.721000000002], [4257.721000000002, 4270.811000000002], [4270.811000000002, 4282.4810000000025], [4282.4810000000025, 4298.081000000003], [4298.081000000003, 4309.741000000003], [4309.741000000003, 4319.801000000003], [4319.801000000003, 4333.951000000003], [4333.951000000003, 4345.901000000003], [4345.901000000003, 4358.341000000002], [4358.341000000002, 4370.881000000002], [4370.881000000002, 4381.141000000002], [4381.141000000002, 4392.341000000002], [4392.341000000002, 4404.381000000002], [4404.381000000002, 4416.001000000002], [4416.001000000002, 4433.641000000002], [4433.641000000002, 4446.311000000002], [4446.311000000002, 4457.391000000002], [4457.391000000002, 4473.261000000002], [4473.261000000002, 4484.901000000003], [4484.901000000003, 4497.721000000002], [4497.721000000002, 4511.971000000002], [4511.971000000002, 4524.911000000002], [4524.911000000002, 4532.620000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [910, 1940, 3193, 4532]}
{"example_id": "mit038@@MIT8_06S18_L09_300k", "text": [" PROFESSOR: We're finished with WKB.   In recitation, you saw some transmission across the barrier ", "and that's also included in the notes.  That's an important application of WKB and should look at it. ", "And today we're going to start with a new topic.  It's time-dependent perturbation theory.  And time-dependent perturbation theory  is going to keep us busy for a number of lectures. ", "There's a lot of applications of these ideas  and the methods are rather general.  Here is the place where we will learn about Fermi's Golden ", "Rule.  The kind of rule that is useful for radiation  problems, ionization problems, transitions.  It's all very applied. ", "Nevertheless, we have to develop the theory carefully and see  what are the main concepts.  So time-dependent perturbation theory is our subject. ", "Time-dependent perturbation theory. ", " Again, we will begin with a Hamiltonian ", "that is time independent.  And we know about it.  We call this Hamiltonian H zero.  The same name we used for time-independent perturbation ", "theory.  We have H zero.  This time, however, we will have a perturbation.  The perturbation will also be called delta H. ", "But the big difference is this time the perturbation will  be time dependent.  And this will be our whole Hamiltonian. ", " So this is the subject we're trying to understand. ", "Whenever you have a Hamiltonian, this time independent,  we already know how we're supposed to deal with it.  We're supposed to find the energy eigenstates. ", "And then we'll have the whole collection  of energy eigenstates.  We can solve any problem.  In the initial condition of the wave function,  you expand it in energy eigenstates. ", "You evolve the state in time.  Everything is nice and simple.  In a sense, for the first time in your studies  of quantum mechanics at MIT, we're ", "going to face very directly the difficulties of time  dependence.  And the first difficulty of a time dependent Hamiltonian is ", "that you cannot define energy eigenstates anymore.  The whole concept is gone.  That's pretty radical.  But it's unfortunately the truth. ", "When you first learn in 804, how to work  with energy eigenstates, it was all  dependent on a factorization. ", "A possible factorization of the solution  in the factor that depends on position and a function that  depends on time.  And that time-dependence was always very simple. ", "E to the minus iEt over h-bar, where  E was the energy which was a solution  of the time-independent, spatial part of the problem. ", "So separating the differential equation  was possible because, for example, the potentials never  depended on time.  If the potential depends on time, ", "imagine the equation H psi equal e psi.  This supposed to be time independent.  But H has a time dependent potential. ", "It's just impossible.  So we don't have energy eigenstates, any more,  for this potential, for the new potential, ", "for the new Hamiltonian.  And we'll have to think how we're going  to face these difficulties.  So no energy eigenstates for H of t. ", "Of course, there are energy eigenstates for H0.  H0 is supposed to be your time-independent Hamiltonian. ", "So how do we think of this?   We will think of time, evolving here, ", "and typically we will have an initial time t0.  And throughout this region, the Hamiltonian, H is equal to H0, ", "for time less than 10 0.  Then we imagine that the perturbation turns on,  and suddenly things start happening, up to time tf. ", "Here the Hamiltonian is H0 plus delta H t.  ", "And after, the time tf, the Hamiltonian, is back to H0.  ", "So that's a nice way of thinking about the problem, in which we  imagine, OK, perturbation is localized ", "that some time t begins there before you  have the known Hamiltonian, after you have the known  Hamiltonian. ", "That allows you to rephrase questions in a clearer way,  because there are energy eigenstates here. ", "If you sit at that energy eigenstate  before time equal t0, you will remain in an energy eigenstate.  There's no reason why it changes. ", "That's what time-independent Hamiltonians do.  The energy eigenstate changes by a phase.  And that's all it does.  So here, we can speak about energy eigenstates, ", "and after time tf, we can speak about energy eigenstates.  So we can ask the question, suppose  you were sitting on this particular energy eigenstate, ", "here.  Then the world shakes for a few moments.  Which state are you going to find yourself,  after this process? ", "And this is a question of going from one energy aide and state  to some collection of energy eigenstates.  By the time the lecture will be finished,  we will have solved this problem in principle, ", "and set up how you would do it, in practice, for any case.  This is a very physical way of thinking, as well. ", "You can imagine, you have a hydrogen atom  in its ground state.  So the original system is a Hamiltonian ", "for a particle, an electron, and a proton.  And it happens to be in a ground state.  Then you send in an electromagnetic wave, something ", "we will do next lecture.  No, in a couple of lectures.  And then, it's possible that the atom gets ionized,  or that the electron is kicked up to a higher level. ", "You will be able to calculate those transition functions.  You will be able to calculate the probability of ionization.  In which, after the perturbation is all said and done, you ask, ", "what is the probability that you're  in an eigenstate, that this a higher excited state  of the hydrogen atom?  And with a little bit of flexibility in your mind, ", "you can think of the hydrogen atom  as a system that has bound states,  and continuum states, in which you  have a proton and an electron traveling a wave. ", "If you your electron is far enough from the proton,  it's like a plane wave.  If it's not that far, it can travel.  And its wave is deformed a little. ", "Those are the continuum states of the hydrogen atom.  So you could ask, what is the probability that it's ionized,  and it's a transition to a continuum eigenstate ", "in the hydrogen atom?  This sounds more complicated.  It's a little more complicated.  Why?  Because when you go from one state to another, ", "you can count it.  But when you ask what is the probability that the electron  goes into the continuum of plane wave,  you'll have infinitely many continuum states. ", "And we will have to deal with that.  Where we will know--  we will not be able to avoid this complication.  And that complication makes for a very interesting result, ", "transitions to the continuum.  So this is what we want to do.  And if given, that in general, this ", "is not a problem of finding energy eigenstates,  the energy eigenstates are known,  we want to find the wave function, psi of t. ", "That's our real unknown.   And to do that, we will use something  called the interaction picture. ", " Just like we have Heisenberg picture, Schrodinger picture, ", "we'll have an interaction picture.  Don't worry.  It's not more complicated than anything you've seen.  It's, in fact, a very sensible way ", "of doing things, in which you combine  good things from the Heisenberg picture,  and nice things from the Schrodinger picture, together. ", "So remember, a little of what was going on  with the Heisenberg picture. ", "It all began by saying that, if you have the expectation  value of a Schrodinger operator, that was the same thing. ", "A s for A Schrodinger, that was possible to compute  as the expectation value of the Heisenberg operator on the time ", "equals 0 states, in the states that don't vary.  You don't need to compute expectation values of operators ", "used in the time involved states.  You can think of time involved operators  and compute in this expectation value  in the time equals 0 states. ", "For that, you use the unitary operator,  that does time evolution, u of t psi  at 0 u dagger of t psi at 0. ", "And this unitary operator, it's in general  difficult to calculate.  It's a unitary operator that does time evolution ", "and, in our case, it's hard because the Hamiltonian  is complicated.  But in general, we call this the Heisenberg operator. ", "A Heisenberg of t.  That's the definition of the Heisenberg operator.   Another concept that is kind of useful, ", "is the idea of operators that brings states to rest.  So suppose you have the state psi at sum time t. ", "I want to act with an operator that will bring it to rest.  That means that this is time-dependent.  I want to act with something that ", "will make it time-independent.  So the answer is U dagger.  U dagger is a unitary operator, so it's the inverse of U. ", "So look at this expression, U dagger on this state  gives you U dagger.  The state is U on the state at time equals 0. ", "U dagger U, being unitary, it's just  the unit matrix, and your 2 0.  So this operator, U dagger, removes the time-dependence. ", "The [INAUDIBLE] uses the expression,  brings the operator to rest.  So we can think of doing something of this kind. ", "You see, the whole Hamiltonian is H0 plus delta H.  H0 you understand well.  Delta H is complicated. ", "So how about doing the time evolution through Heisenberg,  with H0, with what you know. ", "You don't know the full U, but you  know the U that would do the time  evolution, for the time-independent Hamiltonian,  H0. ", "So let's attempt to do the part that is easy.  You see, there's going to be time evolution  as you go from t0 to tf. ", "Some of that is going to be generated by H0,  some of that by delta H. Let's let Heisenberg do the work  for H0, and Schrodinger do the work for delta H. ", "That's basically the idea. .  You see, you know that what is difficult about this problem  is the delta H. So you solve the Schrodinger equation. ", "Let's solve the Schrodinger equation that just has delta H,  doesn't have H anymore.  So motivated by this, we'll do exactly that. ", "Think of for H0, the operator U is e to the minus i H0 ", "t over h-bar.  This is the operator that generates  time evolution for H0.  ", "So we will take the state psi of t  and remove the time-dependence associated to H0. ", "So try to bring the state to rest.  So we'll put here, e to the minus--   I'm sorry.  I'm supposed to put U dagger. ", "So I'll put e to the I H0 t over H-bar.  And look at that. ", "This is U dagger.  That's the kind of thing that brings the state to rest.  If the Hamiltonian had only been H0, only H0, ", "this would be time-independent.  H0 brings it to rest.  Because the Hamilton is not just H0,  this will not be, in general, time-independent. ", "But it will depend on time.  So this is a kind of a nice wave function in which you  sort of have removed the time evolution having to do with H0. ", "So we will define this as our auxiliary variable, psi of t.   That's the definition. ", "It's motivated by the idea that, if delta H was equal to 0, then ", "psi tilde is constant in time.  ", "Because if delta H was equal to 0,  all the evolution is created by H0.  You would put here, oh, this is e to the minus i H0 times psi ", "of t equal 0, the exponentials would cancel,  and everything would be simple.  So this is a wave function that is  going to be our new variable. ", "We wanted to find psi of t.  Now you can say your task is find psi tilde of t.  ", "That's your new task.  And it's an equally good task, because if you  find psi tilde of t, then you can write psi of t ", "as, from this equation, e to the minus  i H0 t over H-bar psi tilde of t. ", " So our task now will be to find psi tilde. ", "If we have psi tilde, we have psi, as well.  So we haven't lost any information.  And this is all good.  So let's try to see what equation is satisfied ", "by psi tilde, what kind of Schrodinger equation  is satisfied by it.  So what is the Schrodinger equation for psi tilde. ", "I'll just take i H-bar d dt of psi tilde and see what I get. ", "OK.  If I have to differentiate this term, i H-bar d dt.  I have to differentiate this exponential. ", "And the i is going to give you a minus sign.  The H's are going to cancel.  And this is just going to bring an H0 down. ", "So I'm going to get minus H0 times that exponential.  And that exponential times psi of t is psi tilde of t. ", " So the derivative of the first term ", "gives me something with H0.  And the face times that is still psi tilde.  Now I have to differentiate the second one so I have plus  e to the i H0 t over H-bar. ", "And i H-bar d dt of this cat.  But that's the Schrodinger equation for the original cat.  So I should put here the full Hamiltonian, H0 plus delta H ", "times psi of t.   So when the i dd H hits the state, ", "you get the full Hamiltonian time psi of t.  But I actually were right for psi of t e to the minus i H0 t ", "over H-bar psi tilde of t.  Because I'm looking for an equation for psi tilde. ", "I'm going a little--  I'm speaking slowly, but going a little fast.   Now what happens? ", " What you wanted to happen, happened.  H0 is here.  And look, H0 is here. ", "Well it's accompanied by these two exponentials,  but they have H0.  So they commute through and these two exponentials  cancel as far as this first term is concerned. ", "So nice consolation over here.  And then we get the following equation, ", "i H-bar d dt of psi tilde is equal to, well, this delta H  sandwiched in these two operators. ", "So I'll just copy it.  e to the H0 t over H-bar delta H e to the minus i H0 t ", "over H-S bar times pi tilde of t.  ", "So this equation makes what we wanted manifest.  If delta H vanishes, psi tilde is time-independent. ", "But it's more than that.  This which we will call delta H tilde.  ", "So tilde objects are objects that  have been acted by H0, like the tilde state,  it has an H0 with respect to the other. ", "This delta H tilde is because it has been acted by similarity  with those things.  But even more, I think you should  realize that this thing is really the Heisenberg 0 ", "version of delta H. A Heisenberg operator is obtained  by taking the Schrodinger operator, putting U dagger ", "and U. And that's exactly what you've done here.  You've taken the Schrodinger operator and put U  dagger with respect to H0, and U for H0. ", "So this is the Heisenberg version of delta H  relative to H0.  So delta H has been \"Heisenberg-ed\" using H0. ", "And then this whole thing looks like i H-bar d dt of psi  tilde equal delta H tilde psi tilde. ", " And this is a Schrodinger equation.  ", "So there it is, for you, the so-called interaction picture.  The interaction picture says whatever  is not an interaction will make it Heisenberg. ", "Whatever is purely interactive will make it Schrodinger.  And therefore, this state varies in time.  And there are some operators that ", "have acquired extra time-dependence, as well, due  to the Heisenberg process.  So this is the situation we are going to try to solve. ", " PROFESSOR: So I want to demystify  a little of this equation.  We sometimes use the basis to show  everything that is happening. ", "So we have a good basis.  So let's look at it.  So how does it all look in an orthonormal basis? ", "So which basis?  Well, you have one.  H 0 was supposed to be known.  So we'll call these states n. ", "These are the eigenstates of H 0.  We'll have E n.  We could put a zero.  We used to have that zero there.  But since we're never going to try ", "to solve this equation in a different way, as time goes on,  the time-dependent system, I said to you,  doesn't have energy eigenstates.  So perturbation theory is not going ", "to be about perturbing these energies.  So I will erase.  E n, and there will be no confusion.  That's never going to change. ", " Now I'm going to write an equation that  may seem a little strange.  We want to solve for this psi ~. ", "So let's write an ansatz for psi ~ of t.  It's going to be the following, sum over n C n n. ", " If C ns are constants, this is definitely not right. ", "This state must have some time-dependence.  So at least, I should put a time-dependence here.  But even that sounds a little wrong, a priori. ", "You knew that in time-independent problems,  you can always write a state as a superposition of your energy  eigenstate.  So now, this is the interacting picture ", "we have not any more energy eigenstates in any sense.  Can I write this? ", "Does this make sense still?   Well, the answer is yes, you can.  And the reason is that whatever you ", "can say about this energy eigenstate,  they apply for early times.  They apply for late times.  They anyway exist.  They're a basis. ", "And what I said, they are a basis.  So any wave function can be written in terms of them.  So if I look psi ~ at time 1 second, ", "I should be able to find numbers that make this possible.  And if I look at it at 2 seconds,  I will find another set of numbers and make it possible. ", "So by the fact that I've included here a time-dependence  for the coefficients, it is possible to write this. ", "These coefficients change in time in strange ways,  but that's our unknown.  If I knew how they change in time, ", "I would have solved the problem.  I don't know how the change in time.  But in general, we will try to find for this coefficient. ", "So if you have psi ~, you know at the end of the day,  your goal is psi of t.  So what is psi of t?  ", "Psi of t, from this blackboard, is the action  of this operator on psi ~.  That operator moves through the constants and through the sum. ", " And with the end states eigenstates of H 0,  this just gives me minus I E n t over H bar n. ", " And this expansion should make you feel good.   You say, OK, here it is. ", "These are my states in my time-dependent we function,  let's say.  And it's given by this formula. ", "If I didn't have a delta H, we know that without a delta H,  psi ~ is constant.  So they C ns would be constant if there is no delta H. ", "And if the C ns are constant and there's  no delta H, that's exactly how energy eigenstates evolve  in time.  They are evolving with exponentials ", "of the action of each 0.  So this is consistent with all you know.  If delta H turns on, the C ns are going ", "to acquire time-dependence.  And we will know what the state is doing.  So this is good.  So let's plug, into the new Schrodinger ", "equation, this expansion.   And this is our new Schrodinger equation.  So what do we get? ", "I get I H bar d/dt of this.  I'll write it here with a sum. ", "I'll change to letter m.   I'll use dots.  C m of t dot. ", "For time derivative, we'll many time use dots.  So I'm taking the time derivative of psi ~  as in the Schrodinger equation.  I go here, C m m. ", " And this is supposed to be equal to delta H  ~ times this same state. ", "So it's going to be sum over n C n of t delta H ~ n. ", " So this is the Schrodinger equation for this state.  We're now looking at the Schrodinger equation  in a basis, because that may be a good way to solve it. ", " Well, one way to solve it is to do, ", "in the right-hand side, a complete set,  introduce a complete set of states.  So I'll put a sum over m m m and this whole sum ", "over n C n of t delta H n.  So this will be equal to sum over m. ", "The m is here.  And sum over n, the bra can go all the way in.  And you write C n of t m delta H n. ", " So this is our Schrodinger equation still. ", "And now it's kind of in a nice way in which we have  similar letters on both sides. ", " A little bit of notation.  ", "I'll call this delta H ~ m n.  We've done that in perturbation theory many, many times. ", "So what is our equation?  Well, compare terms with equal value of the function ", "in front of the state m.  So we gave I H bar C m dot of t is ", "equal to the sum over n C n or delta H m n C n of t. ", " That's it.  It's a nice looking equation. ", "There's a couple sets of differential equations  for an infinite set of functions in which the derivatives are ", "obtained in terms of the Hamiltonian matrix elements  for the transition Hamiltonian for the perturbation  times these functions there.  ", "A little more notation here in the sense  of just understanding the structure of that matrix ", "element.   That's useful, because in practice, all the tilde things,  at the end of the day, we don't want them. ", "We want the original ones, things without tilde.  And we always look for them.  So what is this matrix element delta H m n ~ is m delta H ~ n. ", "But remember what delta H ~ was.  You have it here.  So we have m E to the I H 0 t over H bar delta H ", "E to the minus I H 0 t over H bar n.  That's no problem.  Everything is good here, because those are eigenstates. ", "So we know how much you get by letting  this act on that state and that other exponential act  on this state on the right. ", "So what do we get?  E to the I e m t over H bar.  And from the other one, E n t over H bar like this. ", "The two exponential give you that.  And then you have just delta H, your original perturbation,  between states of the Hamiltonian. ", " I'll write it this way.  Delta H mn, just without the tilde, which is m delta H n. ", " Most people call this the frequency m n. ", "E over H bar is a frequency.  So the harmonic oscillator reminds you  of that, E equal H bar omega. ", "And for easier writing, you write an omega mn.  So this becomes E to the I omega mn t times delta H mn. ", "So this is kind of a nice notation.   So this matrix elements there--  well, I'll write again the equation I H bar C m dot of t ", "would be the sum over n of E to the I omega mn t delta H mn C ", "n of t.   That same equation has been rewritten ", "in the viewpoint of this, where we simplified the tilde.  And we can refer everything to our original basis. ", " So in a sense, I think this should demystify things.  What's the situation? ", "What has happened is that if you have a basis,  you write an ansatz for the wave function of this form. ", "And the coefficients are solutions of those differential  equations.  So we've translated the problem to something doable. ", "If you have lots of resources, a computer,  and you solve coupled time-dependent differential  equations first order.  There this are not partricularly-- ", "well, it all depends how difficult  is the time-dependence here.  The exponential is not bad.  This?  Well, it all depends. ", "But this can be solved numerically.  It can be solved with many methods.  This has made the problem concrete.  And we're going to try to understand how to solve it  ", "PROFESSOR: So here is a problem example based ", "on Griffith's problem 9.3.  So it's a two-state system, and we'll call the states a and b, ", "with energy's Ea and Eb.  And we'll call omega 0 the difference Ea minus Eb ", "over h bar.   So those are energy eigenstates, which ", "means that H0 is really Ea Eb.  ", "We represent the first column vector by the state a.  The second state is the second column vector  with entry 0 and 1-- ", "is the state b.  That's why the matrix looks like that.  And then you put a perturbation.  And the perturbation, delta H, is ", "going to take the form U delta t, where U is a matrix that  has Uaa, Uab, Uba, Ubb-- ", "the matrix elements.  And they're simple enough.  It's a 0 here and an alpha here, and an alpha dagger here. ", "It should be a Hermitian matrix, and that's the way it is.  The letter U, I guess, is not great,  because it suggests unitary.  But maybe I should put a v. I'll leave it, to not create ", "problems with my notation.  So here is the question.  This is your perturbation Hamiltonian. ", "Actually, I wrote it wrong here.  It's a delta function of t.  That's delta H. So in terms of H0 applies everywhere, ", "H0 applies everywhere, and in the middle  there is a delta H for one little instant. ", "So what happens here?   We're going to try to figure out what's going on.  But the question will be posed as follows.  Assume the system is in the state a for t less than 0. ", " Let's ask the probability to be in the state ", "b for t greater than 0.   Find the probability to be, and be greater than 0. ", "So what's going on?  Here are the states a and b.  They were eigenstates of H0.  If you had the system in the state a-- that's an energy ", "eigenstate--  it would stay in the state a forever.  It wouldn't do anything.  Indeed if whoever prepared that state, ", "ever since he or she prepared it, it has stayed in the state  a until time equals 0.  But then the system is kicked and it's  kicked with some delta function strength, ", "and in the off-diagonal terms.  That's pretty important.  It's not kicked on the diagonal terms, it's kicked here.  So these terms suggest a transition from state a ", "to b here.  And presumably, due to this, the system will transition.  And when it transitions, it must transition instantaneously ", "in a sense.  Because if it takes time to transition,  the delta function asks for zero time.  If it takes time to transition, then it would not transition. ", "Because after the delta function has come and gone,  the system doesn't change anymore.  So it really has to transition instantaneously. ", "So at time equals 0, you must generate  a probability or an amplitude to be in the state b already.  ", "So there must be an immediate transition  in which the state, originally, at time less than 0  was the state a, but at time a little bit after zero ", "must be a little bit of a plus a little bit of b.  So this is t0 minus, 0 minus, and 0 plus. ", "At 0 minus, it's a, and at 0 plus  must be something like that.  Because if at 0 plus it's still a, ", "it's going to stay a forever.  So it must have some amplitude to be at b at 0 plus.  So you're having your first transition amplitude problem-- ", "how does an interaction make you jump from one state to another?   Now my letters here, alpha and beta, are pretty bad-- ", "U and V maybe--  because I have an alpha there in the interaction.  And maybe, if you think perturbatively, ", "you would say, look, if alpha is very small,  there must be a small transition probability.  If the perturbation is of order alpha, ", "maybe I expect the perturbed state to be of order alpha.  So maybe, after all, this is like alpha times  b, or proportional to alpha times b, a number here. ", "And this one-- well, if alpha is very small,  that's probably roughly about 1 still--  a little bit less, alpha squared less, ", "for probability conservation.  But I expect an alpha b here.   So OK, when you're given a problem like that, ", "under normal conditions it's a good idea  to think about it before trying to solve it.  And I think we've done a little bit of thinking.  We've realized the state stays in a after a while, ", "and immediately must transition into some other state.   And once it's in that other state, its going  to remain in that state forever because those are energy ", "eigenstates, so you're going to get exponentials of E  to the minus iEt.  But this is going to be that.  OK, so let's solve this. ", "Here is our equation.  Let's try to write it for this case.  So I would have i h bar C a dot of t. ", "We have two states--  1 and 2-- but here is a and b.  So you would have i omega a then something, t and delta H ", "a with something.  Well, the delta H is clear that it can only  be a delta H from a to b. ", "Because there's Uab.  There's only that transition amplitude.  And then it would be an i omega ab, ", "which was defined as omega 0, delta Hab of time, cb of time. ", "And that's the only term that exists here from the sum.  You could sum over a and b, but we saw that over a, you get 0.  So there's just this term. ", "And then we have i H bar Cb dot of [? t ?]  is equal to E to the i.  And now you're going to have ba-- ", "so delta Hba of t Ca of t.  And here I would have omega ba, which ", "is the opposite sign as omega ab, which we anyway  call omega 0.  So here's minus i omega 0 t. ", " Yes.  AUDIENCE: [INAUDIBLE] perturbation disappears?  PROFESSOR: Sorry.  AUDIENCE: Does the perturbation vanish? ", "PROFESSOR: Right.  Because delta Haa is equal to 0, and therefore there's ", "no coupling to Ca.  And delta Hbb is 0 from that matrix element.  And therefore, you cannot couple b to b. ", " And now I'll just write it i H bar Ca dot of t, ", "i H bar Cb dot of t is equal E to the i omega 0t.  Delta Hab was alpha delta of time-- ", "Cb of t.  And this is E to the minus i omega  0t, alpha star delta of time-- ", "Ca of t.  Hba was Uba, which is alpha star times the delta function  of time.  ", "Here I have a delta function of time.  It says that this only matters when time is equal to 0.  So things are a little delicate here. ", "But let's see.  Can I write here--  well, if I have f of x times delta of x, ", "we know this is f of 0 times delta of x.  Because anyway, only zeros [INAUDIBLE]..  So I can put time equals 0 here, and forget ", "about this exponential-- have alpha delta of t, cb of t,  and here have alpha star delta of t Ca of t. ", " Everybody happy so far?  ", "But here, I have Cb of t and Ca of t, and a delta t.  So I should put alpha delta of t Cb at 0, ", "and alpha star delta of t Ca at 0.  Right?  ", "Yes?   People look less convinced, which I congratulate you  for doubting this. ", "This would be bad.  It seems like I'm just following the logic,  but I've gone too far now.  Why did I go too far? ", "First, this is going to be a disaster.  Because in many ways, we don't know what these numbers are. ", "You see, we are argued that this is going  to change this continuously.  Those numbers are going to change this continuously.  At time equals 0-- ", "before time equals 0, Ca was 1 and Cb was 0.  But after time equals 0, Cb is going to be a number--  something that we don't know. ", "So the delta function, which does it  hiy-- the one before 0, the one after 0, the average?  What does it do?  This is a case where you have a delta function that we ", "don't know what it's doing.   So this is totally wrong.  So I will just stop there. ", "And I will consider, however these two equations.   So we have the equations now in a nice way. ", "I'll reconsider them.  And we are facing a difficulty, the difficulty  of the delta function not allowing us to treat nicely ", "the transition of i h bar Ca dot is equal to alpha delta of Cb, ", "and i h bar Cb dot equal alpha star delta of t Ca.  ", "Well now, the only way to resolve this difficulty  is to think about this physically, ", "and introduce a regulator that is physical.  You see, no signal in the world really is a delta function.  Nothing becomes infinite, and nothing lasts for zero time. ", "So this interaction, this delta function,  represents a function of time--  delta of time. ", "It's a spike, but we can think of it as a regulated thing.  You've regulated delta functions in all kinds of ways. ", "It might be useful to regulate it as follows,  as a function of time that is 0 before time equals 0,  it's 0 after some time, t star, and it ", "has height 1 over t star.   That's a picture of a delta function.  ", "It has the right area at least.  And we're going to think of this system  as exactly doing that in between, for t, ", "in the interval 0 to t star.  The delta function is going to be  replaced by this function, this constant function. ", "So it will have i h bar h Ca dot is  equal to alpha over t star Cb. ", " And i h bar Cb dot is equal to alpha star over t sub star. ", "Now the star doesn't mean complex conjugation for t.  It's just a number, a glyph called t0 or something  like that.  And this is true for this time interval. ", "And then you would say, look, I have two problems with this.  First, you've entered this at t star,  and now your calculation is going to depend on t star. ", "And then the answer is going to depend on t star.  And what are you going to put for t star?  Well, that better not happen. ", "We have to go on a limb.  Many times when you do a calculation of something,  you go on a limb.  You say something, and see if it works.  This seems reasonable. ", "And what we expect is that we will  find an answer that this independent on this t star.  So that we can take this star to 0 and make sense of it. ", "The other question that could come  is that, oh, that was your delta function.  So one seconds, you used delta function for this. ", "Maybe we have to put back these terms, these exponentials.  We set them to 1.  But then you could say, look, I don't ", "think I have to put them back.  Why?  Because I can choose t star as small as I want,  such that omega t star, which is the possible value ", "that this can get, at most, is like 10 to the minus 60.  And therefore, this phase is going to be 0, essentially,  and that's going to be 1. ", "So I claim that I don't have to worry about this anymore.  So what do we have?  We have two simple differential equations, like this. ", "With the conditions that Ca at time equals 0 is 1,  and Cb at time equals 0 is 0. ", "The state before the delta function hits is given by that.  And now what we want to know is, how much is  Ca after the delta function and Cb after the delta function? ", " So for that, we have all the tools needed. ", "I can take this equation.  This is a coupled system of equations.  It's a simple system.  I could differentiate again here. ", "And I get a Ca double-dot, Cb dot, and use this equation.  So you get the equation-- if you differentiate again, take a dot ", "to form Ca double-dot, you get that Ca double-dot is  equal to minus alpha over h bar t star squared Ca. ", " You can see that you put the i h bar here, take the derivative, ", "you get an alpha times an alpha star, which  is length of alpha squared.  And the h bar appears two times, t star appears two times. ", "This is an oscillating solution.  So that's simple enough.  ", "So what happens here is that Ca will oscillate in time,  and you will have a solution of the form ", "Ca is equal to a constant, beta 0 cosine of alpha h bar t star ", "t, plus beta 1 sine of alpha p, over h bar t star. ", " And if you wish, Cb from the first equation ", "is proportional to Ca dot.   And Ca dot is going to be of the form beta ", "0 sine off this thing, plus beta 1 cosine of this thing.  ", "OK, so we've turned this into a tractable problem because  of flattening the delta function.  And your initial conditions-- again, Cb must vanish at time ", "equals 0.  So if Cb must vanish at time equals 0, beta 1 must be 0.  ", "If beta 1 is zero, this term is gone,  and Ca was 1 for time equals 0.  So beta 0 is 1. ", " Therefore, Ca is equal to cosine alpha t, over h star t star ", "Ca of t.   And Cb of t, you can calculate it from the top equation. ", "You take the derivative of Ca, and divide  by alpha multiplied by t star.  ", "I'll let you do it.  You get minus i alpha, over alpha, sine, alpha t ", "over ht star.  OK, we solved for the functions. ", "We know what's going to happen.  And now, what did we want?  We wanted to know what are those things for later times, ", "for times t star or more.  Now you cannot use this equation beyond time t star,  because they assumed the delta function is there. ", "So what you have to figure out is  what are these coefficients at time t star.  And those would be the coefficients at any later time,  because there's no more Hamiltonian. ", "So Ca at t greater than t star is, in fact,  equal to Ca at t star. ", "And Ca at t star, happily, is a number  that doesn't depend on t star--  cosine alpha over h bar. ", " And Cb at t greater than t star is Cb at t star. ", "It doesn't change any more after the delta  function has turned off.  And Cb at t star is minus i alpha over alpha-- ", "alpha over alpha, like this, times sine of alpha over h bar. ", " And this is really what you wanted.  Now you know what the state is doing after the delta ", "function has turned on.  It has this amplitude to be in the b state.  And it is, as we predicted-- remember, ", "this is like the face of alpha, because the alpha is alpha  times its face--  length of alpha times it face, and it will cancel. ", "And here you have sine of this quantity.  So it is proportional.  Cb is proportional to alpha. ", "And that's exactly what you would expect.  So just to complete the story, let's write the answer.  ", "And what is the answer?  Phi of t for t greater than 0 is the coefficient Ca ", "of t, which was cosine, alpha over h bar,  times E to the minus iEat, over h bar a. ", "Remember, the solution is Ca E to the minus iEta.  And then the other one, which is minus i alpha, over alpha, ", "sine of alpha over h bar, e to the minus iEbt over h bar, b. ", "That is the state after the delta function has turned on.  And what is the probability to be  found in the state b, time t? ", "It would be b times the state squared.  ", "So you get-- b will couple just to that. b with b gives you 1.  This is a phase.  This is a phase. ", "Sine squared of this thing is sine  squared of alpha over h bar.  What is the probability to be in a? ", "It's a psi of t.  And in this case, it will be cosine squared  of alpha over h bar. ", "And it's very handy that cosine squared  plus sine squared is equal to 1, because it  has to be either in a or on b. ", "And it's kind of interesting, if you  were doing this in perturbation-- we solved it  exactly.  If you were doing this in perturbation theory, ", "we would have found P of b proportional to alpha squared.  Because the first term in the expansion here, ", " PROFESSOR: Now let me conclude for a few minutes  by introducing the idea of how we're going to perturb things.  So how are we going to set up our perturbation theory? ", " So for a perturbation theory we will do the following. ", "We will take our system and introduce again--  so setting up the perturbation expansion. ", " So we want to give you just an idea of what we're going to do.  So H of t is going to be H of 0 plus delta of H of t. ", "And now your lambda is going to be treated as small.  So again, we're going to use a power series expansion,  and everything is going to depend on lambda. ", "And we're going to think coefficients in that way.  We're going to work with the state psi tilde.  You remember, if you know psi tilde,  you put an e to the minus ih 0t over H bar and you can get H. ", "So we'll set the perturbation for psi tilde.  And it will have a zeroth part that  is time dependent plus a first part that is time dependent. ", "Every term is going to be time dependent in the perturbation.  ", "And what was our Schroedinger equation?  Our Schroedinger equation was ih bar d dt of psi tilde of t ", "was delta H, like that, times psi of t. ", "But we need to change things a little bit.  We replace delta H by lambda delta H.  So now it's going to have a lambda here. ", " So I now need to plug in this thing,  which is not going to be too difficult.  It's easier than what we did in time independent perturbation ", "theory.  d dt of psi 0--  let me not put the time dependence in the case psi 1 ", "lambda square psi 2.   And this is equal to lambda delta H bar psi tilde again. ", "So it's psi 0 plus psi 1 plus those terms. ", " So for here we'll just read the first few terms. ", "They're pretty easy.  There's not much of a lambda thing there.   So what do we get? ", "Terms without lambda.  ih bar d dt of psi tilde 0 of t equals 0. ", "This is lambda to the 0.  That's the only term without the lambda,  the one that arises here.  Terms without lambda already. ", "Well, there's one term here, which  is Schroedinger-like. d dt of psi 1 ", "is, in fact, equal to order of lambda.  You have delta H tilde psi 0 of t. ", "And the next one, ih bar d dt of psi 2 of t--  that's lambda squared-- comes from the derivative acting ", "here.  We have to look for lambda squared here.  And I forgot this lambda.   And therefore, this time you get delta H psi 1 of t. ", " In general, for lambda n, you will get ih bar d dt of psi n-- ", "I'll actually put n plus 1, n plus 1 here--   is given by delta H acting on the previous one. ", " So this will be simple. ", "Once you know psi 0, which is a constant, you put it here.  This will be easily solved as an integral.  Once you have psi 1, you put it here. ", "You easily solve psi 2 and start solving one after another.  The fun thing is that you can write these equations  explicitly. ", "And just even the first order result, and sometimes  the second, give you all the physics you want,  which we will explore in the next few lectures. "], "vid_duration": [10.47, 11.08, 14.24, 12.18, 11.82, 11.66, 11.22, 12.98, 12.02, 12.99, 12.15, 11.65, 13.08, 11.4, 11.82, 10.35, 12.58, 10.58, 11.88, 14.24, 12.03, 10.15, 10.55, 20.21, 11.4, 11.28, 14.54, 12.7, 10.41, 11.56, 10.2, 11.55, 11.52, 10.41, 13.89, 11.97, 12.04, 14.24, 10.86, 10.65, 10.98, 13.11, 15.69, 11.91, 12.36, 10.2, 11.09, 11.48, 10.76, 11.55, 11.07, 18.55, 10.83, 10.65, 11.84, 10.29, 13.88, 16.51, 14.01, 10.57, 10.4, 21.36, 11.58, 10.62, 13.34, 17.54, 11.73, 10.2, 13.89, 15.84, 12.33, 10.41, 11.04, 11.04, 10.95, 16.89, 10.9, 12.74, 14.63, 15.15, 20.35, 11.73, 11.91, 12.06, 13.29, 13.05, 10.74, 14.72, 10.44, 10.835, 10.495, 11.95, 11.31, 10.4, 10.52, 14.25, 17.82, 10.94, 11.55, 10.5, 13.42, 11.13, 18.67, 16.61, 11.74, 12.3, 10.29, 10.62, 10.8, 12.06, 15.13, 16.2, 15.68, 10.54, 10.8, 11.86, 10.03, 27.14, 12.15, 12.87, 16.82, 14.04, 12.56, 13.05, 11.49, 11.888, 11.51, 21.19, 10.03, 13.69, 12.36, 10.26, 10.75, 20.555, 12.305, 14.85, 13.74, 10.66, 11.08, 11.01, 11.79, 10.03, 10.04, 10.74, 11.65, 14.28, 11.515, 15.585, 11.84, 11.55, 13.2, 11.79, 10.055, 12.415, 11.16, 10.98, 10.38, 10.678, 10.112, 12.16, 12.81, 10.885, 15.645, 13.78, 17.46, 10.9, 10.395, 13.195, 15.73, 10.16, 10.2, 15.35, 12.38, 10.49, 13.02, 10.586, 11.914, 23.28, 17.685, 12.255, 12.97, 16.54, 10.36, 18.75, 15.03, 11.97, 17.57, 15.7, 13.522, 10.428, 10.11, 10.84, 11.28, 12.72, 12.12, 10.66, 10.303, 11.87, 19.509, 12.931, 10.56, 11.26, 11.13, 14.04, 13.14, 10.26, 17.27, 12.54, 11.13, 11.58, 22.31, 10.17, 15.45, 13.8, 10.95, 13.26, 11.85, 16.99, 10.35, 10.42, 11.9, 14.85, 14.46, 10.83, 11.74, 13.1, 11.34, 10.74, 14.13, 11.73, 16.34, 13.71, 13.22, 10.66, 13.04, 13.5, 11.94, 10.32, 15.48, 11.67, 12.84, 11.58, 10.86, 10.062, 10.568, 12.27, 13.94, 14.46, 11.25, 15.86, 11.82, 10.26, 10.5, 15.12, 10.75, 14.09, 11.065, 10.245, 12.15, 13.74, 10.95, 12.12, 11.37, 11.5, 15.13, 12.05, 11.39, 15.26, 10.5, 15.45, 10.22, 10.03, 14.01, 12.27, 14.52, 10.32, 14.555, 16.444, 13.48, 12.601, 11.55, 10.5, 13.65, 11.55, 11.1, 14.46, 10.32, 13.02, 13.28, 16.21, 11.21, 10.13, 14.59, 18.135, 11.215, 10.14, 12.18, 10.03, 12.41, 10.54, 10.7, 13.48, 15.41, 14.07, 12.37, 11.4, 18.75, 12.58, 10.09, 13.22, 11.28, 11.28, 10.45, 11.63, 10.74, 11.73, 10.33, 15.84, 12.495, 13.895, 10.82, 10.74, 10.33, 24.44, 12.03, 15.359, 14.641, 14.79, 14.655, 11.205, 10.59, 15.0, 13.64, 10.31, 10.0, 10.16, 12.855, 15.105, 15.87, 20.45, 12.27, 16.5, 16.65, 10.85, 12.66, 15.83, 11.13, 13.89, 13.35, 16.96, 11.64, 13.81, 11.24, 12.93, 14.22, 10.47, 12.99, 15.03, 20.3, 14.826, 11.354, 10.68, 10.86, 10.83, 8.074], "stet": [[0, 10.47], [10.47, 21.55], [21.55, 35.79], [35.79, 47.97], [47.97, 59.79], [59.79, 71.45], [71.45, 82.67], [82.67, 95.65], [95.65, 107.67], [107.67, 120.66], [120.66, 132.81], [132.81, 144.46], [144.46, 157.54000000000002], [157.54000000000002, 168.94000000000003], [168.94000000000003, 180.76000000000002], [180.76000000000002, 191.11], [191.11, 203.69000000000003], [203.69000000000003, 214.27000000000004], [214.27000000000004, 226.15000000000003], [226.15000000000003, 240.39000000000004], [240.39000000000004, 252.42000000000004], [252.42000000000004, 262.57000000000005], [262.57000000000005, 273.12000000000006], [273.12000000000006, 293.33000000000004], [293.33000000000004, 304.73], [304.73, 316.01], [316.01, 330.55], [330.55, 343.25], [343.25, 353.66], [353.66, 365.22], [365.22, 375.42], [375.42, 386.97], [386.97, 398.49], [398.49, 408.90000000000003], [408.90000000000003, 422.79], [422.79, 434.76000000000005], [434.76000000000005, 446.80000000000007], [446.80000000000007, 461.0400000000001], [461.0400000000001, 471.9000000000001], [471.9000000000001, 482.55000000000007], [482.55000000000007, 493.5300000000001], [493.5300000000001, 506.6400000000001], [506.6400000000001, 522.3300000000002], [522.3300000000002, 534.2400000000001], [534.2400000000001, 546.6000000000001], [546.6000000000001, 556.8000000000002], [556.8000000000002, 567.8900000000002], [567.8900000000002, 579.3700000000002], [579.3700000000002, 590.1300000000002], [590.1300000000002, 601.6800000000002], [601.6800000000002, 612.7500000000002], [612.7500000000002, 631.3000000000002], [631.3000000000002, 642.1300000000002], [642.1300000000002, 652.7800000000002], [652.7800000000002, 664.6200000000002], [664.6200000000002, 674.9100000000002], [674.9100000000002, 688.7900000000002], [688.7900000000002, 705.3000000000002], [705.3000000000002, 719.3100000000002], [719.3100000000002, 729.8800000000002], [729.8800000000002, 740.2800000000002], [740.2800000000002, 761.6400000000002], [761.6400000000002, 773.2200000000003], [773.2200000000003, 783.8400000000003], [783.8400000000003, 797.1800000000003], [797.1800000000003, 814.7200000000003], [814.7200000000003, 826.4500000000003], [826.4500000000003, 836.6500000000003], [836.6500000000003, 850.5400000000003], [850.5400000000003, 866.3800000000003], [866.3800000000003, 878.7100000000004], [878.7100000000004, 889.1200000000003], [889.1200000000003, 900.1600000000003], [900.1600000000003, 911.2000000000003], [911.2000000000003, 922.1500000000003], [922.1500000000003, 939.0400000000003], [939.0400000000003, 949.9400000000003], [949.9400000000003, 962.6800000000003], [962.6800000000003, 977.3100000000003], [977.3100000000003, 992.4600000000003], [992.4600000000003, 1012.8100000000003], [1012.8100000000003, 1024.5400000000002], [1024.5400000000002, 1036.4500000000003], [1036.4500000000003, 1048.5100000000002], [1048.5100000000002, 1061.8000000000002], [1061.8000000000002, 1074.8500000000001], [1074.8500000000001, 1085.5900000000001], [1085.5900000000001, 1100.3100000000002], [1100.3100000000002, 1110.7500000000002], [1110.7500000000002, 1121.5850000000003], [1121.5850000000003, 1132.0800000000002], [1132.0800000000002, 1144.0300000000002], [1144.0300000000002, 1155.3400000000001], [1155.3400000000001, 1165.7400000000002], [1165.7400000000002, 1176.2600000000002], [1176.2600000000002, 1190.5100000000002], [1190.5100000000002, 1208.3300000000002], [1208.3300000000002, 1219.2700000000002], [1219.2700000000002, 1230.8200000000002], [1230.8200000000002, 1241.3200000000002], [1241.3200000000002, 1254.7400000000002], [1254.7400000000002, 1265.8700000000003], [1265.8700000000003, 1284.5400000000004], [1284.5400000000004, 1301.1500000000003], [1301.1500000000003, 1312.8900000000003], [1312.8900000000003, 1325.1900000000003], [1325.1900000000003, 1335.4800000000002], [1335.4800000000002, 1346.1000000000001], [1346.1000000000001, 1356.9], [1356.9, 1368.96], [1368.96, 1384.0900000000001], [1384.0900000000001, 1400.2900000000002], [1400.2900000000002, 1415.9700000000003], [1415.9700000000003, 1426.5100000000002], [1426.5100000000002, 1437.3100000000002], [1437.3100000000002, 1449.17], [1449.17, 1459.2], [1459.2, 1486.3400000000001], [1486.3400000000001, 1498.4900000000002], [1498.4900000000002, 1511.3600000000001], [1511.3600000000001, 1528.18], [1528.18, 1542.22], [1542.22, 1554.78], [1554.78, 1567.83], [1567.83, 1579.32], [1579.32, 1591.2079999999999], [1591.2079999999999, 1602.7179999999998], [1602.7179999999998, 1623.908], [1623.908, 1633.9379999999999], [1633.9379999999999, 1647.628], [1647.628, 1659.9879999999998], [1659.9879999999998, 1670.2479999999998], [1670.2479999999998, 1680.9979999999998], [1680.9979999999998, 1701.5529999999999], [1701.5529999999999, 1713.858], [1713.858, 1728.7079999999999], [1728.7079999999999, 1742.4479999999999], [1742.4479999999999, 1753.108], [1753.108, 1764.1879999999999], [1764.1879999999999, 1775.1979999999999], [1775.1979999999999, 1786.9879999999998], [1786.9879999999998, 1797.0179999999998], [1797.0179999999998, 1807.0579999999998], [1807.0579999999998, 1817.7979999999998], [1817.7979999999998, 1829.4479999999999], [1829.4479999999999, 1843.7279999999998], [1843.7279999999998, 1855.243], [1855.243, 1870.828], [1870.828, 1882.668], [1882.668, 1894.2179999999998], [1894.2179999999998, 1907.418], [1907.418, 1919.2079999999999], [1919.2079999999999, 1929.263], [1929.263, 1941.6779999999999], [1941.6779999999999, 1952.838], [1952.838, 1963.818], [1963.818, 1974.198], [1974.198, 1984.8760000000002], [1984.8760000000002, 1994.9880000000003], [1994.9880000000003, 2007.1480000000004], [2007.1480000000004, 2019.9580000000003], [2019.9580000000003, 2030.8430000000003], [2030.8430000000003, 2046.4880000000003], [2046.4880000000003, 2060.2680000000005], [2060.2680000000005, 2077.7280000000005], [2077.7280000000005, 2088.6280000000006], [2088.6280000000006, 2099.0230000000006], [2099.0230000000006, 2112.2180000000008], [2112.2180000000008, 2127.948000000001], [2127.948000000001, 2138.1080000000006], [2138.1080000000006, 2148.3080000000004], [2148.3080000000004, 2163.6580000000004], [2163.6580000000004, 2176.0380000000005], [2176.0380000000005, 2186.5280000000002], [2186.5280000000002, 2199.5480000000002], [2199.5480000000002, 2210.134], [2210.134, 2222.0480000000002], [2222.0480000000002, 2245.3280000000004], [2245.3280000000004, 2263.0130000000004], [2263.0130000000004, 2275.2680000000005], [2275.2680000000005, 2288.2380000000003], [2288.2380000000003, 2304.7780000000002], [2304.7780000000002, 2315.1380000000004], [2315.1380000000004, 2333.8880000000004], [2333.8880000000004, 2348.9180000000006], [2348.9180000000006, 2360.8880000000004], [2360.8880000000004, 2378.4580000000005], [2378.4580000000005, 2394.1580000000004], [2394.1580000000004, 2407.6800000000003], [2407.6800000000003, 2418.108], [2418.108, 2428.2180000000003], [2428.2180000000003, 2439.0580000000004], [2439.0580000000004, 2450.3380000000006], [2450.3380000000006, 2463.0580000000004], [2463.0580000000004, 2475.1780000000003], [2475.1780000000003, 2485.838], [2485.838, 2496.141], [2496.141, 2508.011], [2508.011, 2527.52], [2527.52, 2540.451], [2540.451, 2551.011], [2551.011, 2562.271], [2562.271, 2573.4010000000003], [2573.4010000000003, 2587.4410000000003], [2587.4410000000003, 2600.581], [2600.581, 2610.8410000000003], [2610.8410000000003, 2628.1110000000003], [2628.1110000000003, 2640.6510000000003], [2640.6510000000003, 2651.7810000000004], [2651.7810000000004, 2663.3610000000003], [2663.3610000000003, 2685.6710000000003], [2685.6710000000003, 2695.8410000000003], [2695.8410000000003, 2711.291], [2711.291, 2725.0910000000003], [2725.0910000000003, 2736.041], [2736.041, 2749.3010000000004], [2749.3010000000004, 2761.1510000000003], [2761.1510000000003, 2778.141], [2778.141, 2788.491], [2788.491, 2798.911], [2798.911, 2810.811], [2810.811, 2825.661], [2825.661, 2840.121], [2840.121, 2850.951], [2850.951, 2862.691], [2862.691, 2875.7909999999997], [2875.7909999999997, 2887.131], [2887.131, 2897.8709999999996], [2897.8709999999996, 2912.0009999999997], [2912.0009999999997, 2923.7309999999998], [2923.7309999999998, 2940.071], [2940.071, 2953.781], [2953.781, 2967.0009999999997], [2967.0009999999997, 2977.6609999999996], [2977.6609999999996, 2990.7009999999996], [2990.7009999999996, 3004.2009999999996], [3004.2009999999996, 3016.1409999999996], [3016.1409999999996, 3026.461], [3026.461, 3041.941], [3041.941, 3053.611], [3053.611, 3066.451], [3066.451, 3078.031], [3078.031, 3088.891], [3088.891, 3098.953], [3098.953, 3109.521], [3109.521, 3121.791], [3121.791, 3135.731], [3135.731, 3150.1910000000003], [3150.1910000000003, 3161.4410000000003], [3161.4410000000003, 3177.3010000000004], [3177.3010000000004, 3189.1210000000005], [3189.1210000000005, 3199.3810000000008], [3199.3810000000008, 3209.8810000000008], [3209.8810000000008, 3225.0010000000007], [3225.0010000000007, 3235.7510000000007], [3235.7510000000007, 3249.841000000001], [3249.841000000001, 3260.906000000001], [3260.906000000001, 3271.1510000000007], [3271.1510000000007, 3283.301000000001], [3283.301000000001, 3297.0410000000006], [3297.0410000000006, 3307.9910000000004], [3307.9910000000004, 3320.1110000000003], [3320.1110000000003, 3331.481], [3331.481, 3342.981], [3342.981, 3358.1110000000003], [3358.1110000000003, 3370.1610000000005], [3370.1610000000005, 3381.5510000000004], [3381.5510000000004, 3396.8110000000006], [3396.8110000000006, 3407.3110000000006], [3407.3110000000006, 3422.7610000000004], [3422.7610000000004, 3432.981], [3432.981, 3443.0110000000004], [3443.0110000000004, 3457.0210000000006], [3457.0210000000006, 3469.2910000000006], [3469.2910000000006, 3483.8110000000006], [3483.8110000000006, 3494.1310000000008], [3494.1310000000008, 3508.6860000000006], [3508.6860000000006, 3525.1300000000006], [3525.1300000000006, 3538.6100000000006], [3538.6100000000006, 3551.2110000000007], [3551.2110000000007, 3562.761000000001], [3562.761000000001, 3573.261000000001], [3573.261000000001, 3586.911000000001], [3586.911000000001, 3598.461000000001], [3598.461000000001, 3609.561000000001], [3609.561000000001, 3624.021000000001], [3624.021000000001, 3634.3410000000013], [3634.3410000000013, 3647.3610000000012], [3647.3610000000012, 3660.6410000000014], [3660.6410000000014, 3676.8510000000015], [3676.8510000000015, 3688.0610000000015], [3688.0610000000015, 3698.1910000000016], [3698.1910000000016, 3712.7810000000018], [3712.7810000000018, 3730.916000000002], [3730.916000000002, 3742.131000000002], [3742.131000000002, 3752.271000000002], [3752.271000000002, 3764.451000000002], [3764.451000000002, 3774.481000000002], [3774.481000000002, 3786.891000000002], [3786.891000000002, 3797.431000000002], [3797.431000000002, 3808.1310000000017], [3808.1310000000017, 3821.6110000000017], [3821.6110000000017, 3837.0210000000015], [3837.0210000000015, 3851.0910000000017], [3851.0910000000017, 3863.4610000000016], [3863.4610000000016, 3874.8610000000017], [3874.8610000000017, 3893.6110000000017], [3893.6110000000017, 3906.1910000000016], [3906.1910000000016, 3916.2810000000018], [3916.2810000000018, 3929.5010000000016], [3929.5010000000016, 3940.7810000000018], [3940.7810000000018, 3952.061000000002], [3952.061000000002, 3962.511000000002], [3962.511000000002, 3974.141000000002], [3974.141000000002, 3984.8810000000017], [3984.8810000000017, 3996.6110000000017], [3996.6110000000017, 4006.9410000000016], [4006.9410000000016, 4022.7810000000018], [4022.7810000000018, 4035.2760000000017], [4035.2760000000017, 4049.1710000000016], [4049.1710000000016, 4059.991000000002], [4059.991000000002, 4070.7310000000016], [4070.7310000000016, 4081.0610000000015], [4081.0610000000015, 4105.501000000001], [4105.501000000001, 4117.531000000001], [4117.531000000001, 4132.890000000001], [4132.890000000001, 4147.531000000001], [4147.531000000001, 4162.321000000001], [4162.321000000001, 4176.976000000001], [4176.976000000001, 4188.1810000000005], [4188.1810000000005, 4198.771000000001], [4198.771000000001, 4213.771000000001], [4213.771000000001, 4227.411000000001], [4227.411000000001, 4237.721000000001], [4237.721000000001, 4247.721000000001], [4247.721000000001, 4257.881000000001], [4257.881000000001, 4270.736000000001], [4270.736000000001, 4285.841], [4285.841, 4301.711], [4301.711, 4322.161], [4322.161, 4334.4310000000005], [4334.4310000000005, 4350.9310000000005], [4350.9310000000005, 4367.581], [4367.581, 4378.4310000000005], [4378.4310000000005, 4391.091], [4391.091, 4406.921], [4406.921, 4418.051], [4418.051, 4431.941000000001], [4431.941000000001, 4445.291000000001], [4445.291000000001, 4462.251000000001], [4462.251000000001, 4473.891000000001], [4473.891000000001, 4487.701000000002], [4487.701000000002, 4498.941000000002], [4498.941000000002, 4511.871000000002], [4511.871000000002, 4526.091000000002], [4526.091000000002, 4536.561000000002], [4536.561000000002, 4549.551000000002], [4549.551000000002, 4564.581000000002], [4564.581000000002, 4584.881000000002], [4584.881000000002, 4599.707000000002], [4599.707000000002, 4611.061000000002], [4611.061000000002, 4621.741000000003], [4621.741000000003, 4632.601000000002], [4632.601000000002, 4643.431000000002], [4643.431000000002, 4651.505000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1591, 2496, 4259, 4653]}
{"example_id": "mit075@@MIT14_01SCF10_lec12_300k", "text": [" PROFESSOR: Today we're going to continue  discussing firm behavior.  But today we're going to deviate from our fantasy land  of 14.01 to come to the real world a little bit which is to ", "talk a bit about whether firms actually maximize profits.  The whole presumption of producer theory is just as we ", "think with consumer theory, consumers maximize utility.  Except producers maximize profits.  That turns out to be an incredibly useful shorthand  for lots of things.  And it will turn out to be, as with any simplifying ", "assumption, largely right and largely will help us draw a  lot of interesting conclusions about firms and markets.  Nonetheless, it's clearly not right in ", "reality for every firm.  For example, we see lots of firms doing things which look  pretty wasteful like big corporate jets or  other things like that. ", "More relevantly, huge pay for CEOs seems pretty wasteful.  So, for example, on 2004 the net income of Eli Lilly, the  drug manufacturer, fell by 29%. ", "Yet the CEO got a 41% raise to to $12.5 million a year.  Or even more so in the financial crisis, in 2009,  Citigroup and Merrill each lost more than $27 billion. ", "It's a pretty bad year for the financial  sector, you might think.  And yet their CEO's pay in each company rose by more than  10% to about $15 million.  So in the worst year for the financial system since 1929, ", "the CEO pay increased in these two companies.  So you might think that this sounds kind of off.  How could we explain that?  Well, there's two possible explanations.  So one explanation is that things which look wasteful ", "really aren't.  That is that we pay CEOs a huge amount of money, but  they're worth it.  So, for example, even at his ultimate salary of $33 million  per year, Michael Jordan was vastly underpaid. ", "By any reasonable economic analysis of the value he added  to the Chicago Bulls, it was well in excess of $50 million.  So even though he was paid $33 million,  Michael Jordan was underpaid. ", "Similarly, just because someone gets paid a lot of  money, doesn't mean that they're overpaid.  These CEOs are very talented people.  They may be underpaid.  Now this is an argument you might have made with a  somewhat straight face maybe 10 or 15 years ago. ", "It's hard to make that with a straight face now.  It's hard to believe that these CEOs of these companies  aren't overpaid given their company performance and even  the kind of facts we just talked about. ", "So a better explanation for things like excessive CEO pay  is something which we call the agency problem.  ", "And that's what I want to emphasize in today's lecture.  In reality, we think of a firm as something where there's a  guy who's an owner. ", "He hires some machines and some workers.  They make stuff that he thought of, and you produce  it, and some profit is made.  So the model we have in mind when we talked about the firms ", "so far in this course is the model of what we might call a  sole proprietorship or a partnership.  It's a model where one individual, where there's  basically a commonality. ", "The key thing that we've discussed so far is a  commonality of interest between the owners who own the  company and the control of production. ", "So the people who earn the money from the company also  control the production.  So when you start your start-ups when you graduate,  you will start them as a sole proprietorship or a  partnership where you own the company, and you control ", "what's done.  You're there 18 hours a day making sure the guys are doing  what they're supposed to do.  And you're who gets the money if they succeed or lose the  money if they fail. ", "And that's the model we've had in mind as we've thought about  corporations or firms so far in our class.  But, in fact, most production in the US  doesn't happen that way. ", "Most production in the US happens through the guise of  corporations.   Corporations are marked by a separation of ", "ownership and control.  What defines a corporation is a separation of  ownership and control.  The owners of corporations are the stockholders or what we ", "call the equity holders, people who have invested money  in the corporation.  So the owners of the corporation are its investors,  its stockholders, its equity holders.  ", "All of you, most of you, probably somewhere--  if you're Jewish, it's in some Bar Mitzvah gift you got, if  you're not, it's in some other gift you got-- probably have  some equity ownership in something somewhere. ", "OK.  You maybe have a little bond which says you own five shares  of GM that someone gave you, because they thought it'd be  cute or whatever.  That's now worthless, but maybe some other company.  ", "We're equity holders.  We invest in companies.  But we don't make the production decision.  The production decision is made by the firm's managers  who are employees of the owners, the equity holders. ", "Now these managers may have some ownership.  And we'll talk about that in a little bit.  But, by and large, the primary ownership of the firm is done  by people who do not control the everyday decisions of  production.  And it sort of makes sense it has to be that way. ", "When a company's as big as Microsoft, you  couldn't have me.  Somewhere, I'm sure if you add up my various stock funds I  own, I own 0.000000000001% of Microsoft. ", "It'd be crazy to have me involved with a  0.000000000001% of the decision making.  I don't know anything about anything that Microsoft does.  It makes sense that there's a separation of ownership and ", "control once companies get big enough.  But the fact that there is a separation of ownership and  control can lead to this agency problem and can lead to  firms not maximizing profits. ", "So, basically, the point is that managers care not just  about the profits they make but also how  happy their life is.  And things which make their life happy may be things which ", "aren't profit maximizing.  The managers who are in charge of production may have their  own agenda that deviates from profit maximization. ", "And the problem is it may be hard to figure that out if  you're the owner of the firm.  So the agency problem is the first example of a problem  we'll talk about later in the semester of imperfect ", "information.  This is the first time we'll see imperfect information.  We've assumed in our class so far, and we'll assume in our ", "class going forward that there's perfect information  the world, that everyone knows what stuff costs, that  everyone can shop costlessly across providers, et cetera.  But, in fact, the world is marked by imperfect ", "information.  As an owner of Microsoft, as a trivial owner of Microsoft, I  don't know for sure that every Microsoft employee is doing  what's profit maximizing for the company. ", "I can't.  It's just impossible for me to own that.  So that creates an agency problem.  And the agency problem arises because it's in the employees'  interest, perhaps, to do things which aren't profit ", "maximizing.  So so as a simple example, imagine that you're an  investor in the company that's a medium-sized company.  And the head of that company is jealous because all of his  friends at bigger companies have their own jets, and he's ", "got to fly commercial.  He says, I want my own jet, because I'm not cool enough.  There's this great episode of the Simpsons where Burns goes ", "to the billionaires club.  And he's in the billionaires club.  And then eventually his wealth drops so low he gets thrown  into the millionaires club, and it's these yokels in the  millionaires club.  He's like, I want to be back in the billionaires club.  The point is managers of companies care about how they ", "look and who they hang out with.  And you've got this manager of a medium-sized company who  wants his own private jet.  But he knows that that's not profit maximizing.  Because he knows that if he figures out his travel, and  prices it out at competitive prices, it'll be cheaper to ", "just travel commercial.  So what does he do?  He puts together a glossy PowerPoint which he presents  to you, the owner of the company, showing that  financially it would be more prudent to own a jet than to ", "fly commercial.  What he doesn't point out and put into that PowerPoint is  that in putting together the commercial prices he used, he  chose the highest rates from flying from point A to point  B, not the lowest rates. ", "Now, unless you're an expert on the cost of flying from  point A to point B, you won't know that.  You'll say, well, that's a pretty impressive  presentation.  Yes, you can show you've saved 20% by having your own plane.  Go get it.  But it turned out he didn't save 20%. ", "He just cooked the numbers in a way to make his life nicer  even if it wasn't profit maximizing.  And that's an example of the kind of problem that arises  with imperfect information.  ", "And I could go through examples all the time.  But I think you guys probably all understand what I'm  talking about, which is there's lots of ways employees  of companies might make their lives nicer that aren't profit  maximizing.  Now, corporations have recognized this from time ", "immemorial.  And they've recognized that their owners are too diffuse  to monitor this.  So what corporations do is they have set up an  intermediary between the owners and the producers ", "called the board of directors.   The board of directors is a set of individuals appointed  by the owners that are supposed to actually pay ", "attention to what's going on in production.  The owners say, look, we can't afford to pay attention.  But we're going to appoint you, the board of directors,  and we're going to pay you quite a lot of money.  A typical director on the Fortune 500 company will make ", "$100,000 plus a year.  It's a part-time job.  We appointed you to keep an eye on the tools of  production.  The problem is the board of directors aren't  that good at it either.  Because it turns out to be really hard to figure out ", "exactly what's going on.  And this is made worse, because the members of the  board of directors are often chosen by management of the  company, by the people running the ", "production, not by the owners.  So they'll make selections of who's going to be on the board  of directors.  And they'll pack it with their friends who  will be nice to them.  So, for example, Richard Grasso was the CEO of the New ", "York Stock Exchange.  He started out in the mail room, worked his way up.  He became CEO of the New York Stock Exchange and retired  with $187 million severance package which was outrageous ", "and totally unearned.  But the board of directors were a bunch of his buddies  who'd known him since he was a kid.  And they said, he seems like a nice guy.  Let's give him a bunch of money.  And a lot of the board of directors, when actually ", "grilled on it, didn't actually know he'd gotten that much.  They were like, wow.  We didn't realize his retirement  package was that big.  So it turns out having the board of directors does not  solve the agency problem.  Because there's still too much of an information imperfection ", "between the managers and the board of directors, not to  mention the managers and the owners.  So what do we do?  What do we do with this agency problem?  Well, this was known for a lot of years. ", "And about 25 years ago, the thinking was, look, the way to  solve this problem is we need to align the incentives of the  managers and the owners. ", "If we're going to solve this problem, we need to get the  managers, the producers, to actually care about maximizing  profits enough that they'll do that even if it makes their  life a little uncomfortable.  And how do we do that? ", "We turn the managers into owners.  We give the managers, the producers, an ownership stake  in the company.  We say look, your income is going to be directly derived ", "from the profitability of this company.  So now you'll have a direct incentive to do what's profit  maximizing even if it makes your life a little  uncomfortable.  Even if it means flying commercial, you recognize if I ", "have my own jet, then I'm going to suffer.  So you align the incentives.  So we want to give them an ownership  stake in the company.  Well, how do you do that?  How do you give managers an ownership stake?  Well, there's two ways you can do it. ", "One way is you can directly give them stock.  So you can directly say, look, instead of paying you in cash,  we are going to pay you in company stock.  So your fortunes will directly be tied to the performance of ", "this company if you pay them in stock.  Or, alternatively, you can do something which turns out to  be cheaper.  You can give them stock options.  It turns out to be cheaper, at least, in principle. ", "We can give them stock options.  So let's talk about what a stock option is.  And some of you may deal with these along the way.   A stock is a piece of paper which says you only 0.00001% ", "of the company.  A stock option is simply a piece of paper which says we  are granting you the right to buy the stock at some price.  Typically, it's today's price. ", "We're not giving you a share of the company.  You have a piece of paper which says if the value of  stock today is $100, you have a piece of paper which says no  matter where the stock ends up, you can  always buy it for $100.  Why is that valuable? ", "Well, that's valuable because let's say you give a CEO of a  company a million options at $100 each when the price of  the stock is $100.  Well, if the price of the stock rises to $150, that CEO ", "can then take his million options, say, I want to buy  the shares for 100, which I'm allowed to by these pieces of  paper, and I'll turn around and sell them for $150.  I've just made $50 million.  So a stock option is valuable if the stock goes up. ", "But it's worthless if the stock goes down.  So it's kind of the ultimate incentive, if  you think about it.  Because what it says to the CEO is, look, we're going to  incent you to do better. ", "And you make a lot of money by doing better.  But if you do worse, you're not going to get anything.  And as myself as the owner it seems great,  because it's cheaper.  Because if the stock goes up, I share some with the guy. ", "But I don't care.  I'm happy.  The stock goes up.  If it goes down, I don't have to give him anything.  And, in fact, giving someone a stock option costs,  effectively, about half as much as giving them stock. ", "So if I say today's stock price, if I instead of giving  you a share of stock, I give you an option to buy a share  of stock at today's price, the value to that, what it costs  me in the market is about half of what it costs when I  actually give you the share of stock. ", "So it seems like the best deal.  You get all the incentives for them to raise the price, but  it costs you half as much.  And, in fact, there's been tremendous growth in use of  stock and stock options. ", "So if you look at Figure 12-1, now, this sort of changes.  Before 1992, there's only two categories.  And after '92, there's three. ", "So before '92, we just have to divide into salary and bonus  versus options.  So you see there was essentially no options in '84. ", "This is the mean CEO pay.  So the typical CEO in 1984 made $500,000, and it was all  cash, all salary and bonus.  By 1992, they made about $1 million, and a decent share of ", "it started to be stock options.  Now, starting after '92, we actually break into three  categories which is salary, bonus, and options.  But that doesn't really matter.  The main thing is to pay attention to the option share, ", "which you see grew astronomically.  And so by its peak, in about 2002, first of all, the  typical CEO was making $3.5 million.  ", "Second of all, the majority of that was in stock options.  In fact, if you look at salary and bonus, it didn't grow that  much over time.  If you look at 1992 versus 2002, over that decade, salary ", "and bonus barely grew, but options went through the roof.  So there's a huge increase in use of these.  And the motivation is pretty basic economic intuition. ", "What we're going to do is this is a cheap way to align the  incentives of owners and managers.   And that was why they took off.  And everyone thought it was great. ", "And people like Michael Jensen at Harvard Business School  made fortunes off having suggested this, et cetera.  It was like we solved the problem.  And, remember, we did pretty damn well in the 1990s.  And a lot of it, people attributed it to exactly ", "what's in this graph.  That by finally figuring out how to align the incentives of  producers and owners, we'd figured out a way to change  the economy.  And people thought we sort of entered this new economic era ", "of massive productivity.  Well people, as we know now, were wrong.  Things slowed down in the 2000s and then now have  completely crashed. ", "And why were they wrong?  Well, they're wrong because what makes economics fun is  unintended consequences.  And these stock options had two kinds of unintended ", "consequences.  The first unintended consequence is that they lead  to excessive gambling.  ", "And what I mean by that is that once your stock option is  out of the money, once, if you've got it for 100,  you're below 100.  You don't care how low it goes. ", "If you're at 99 or 20, you don't care.  All we care about is being 100 verses above.  What that means is as an owner, as a manager, you'll  take excessive risks to go into the positive territory. ", "Even if there's a huge risk you'll get  nailed on the downside.   Contrast to guys working for a company that's ", "currently worth $100.  One is given stock, and one is given stock options at $100. ", "Imagine they're both going to leave the company in one year.  Because there's dynamics with the long run issues.  Let's put that aside.  They're both going to leave in one year.  One today is given a share of stock, and one today is given ", "an option to buy at $100.  And then they're given the choice of a risky investment.  Someone comes to them and says, have I  got a deal for you.  I've got an investment that has a 10% chance it will ", "double the value of your company and a 90% chance the  value of your company will fall by 20%.  So there's a 10% chance of a 100% return and a 90% chance ", "of a 20% decline in your company's value.  Now, what is the profit maximizing thing  to do in this situation?  Well, to do that, we have to consider the concept of what ", "delivers the company the highest expected value.   Expected value is a concept we'll use-- and we'll come  back to this later when we talk about uncertainty-- ", "it's a concept we use to measure how you value things  when there's uncertainty.  So the expected value of a gamble is the probability that  you win times the value if you win plus the probability that ", "you lose times the value if you lose.  That's the expected value of a gamble.  And the profit maximizing thing to do would be to take ", "gambles of expected values of greater than zero.  The expected value is the summation of the  value of that gamble.  This gamble has an expected value of 0.1 times 100-- ", "100% return and a 10% chance--  plus 0.9 times negative 20--  a 90% of losing 20-- or an expected value of minus 8%. ", "That is if you take this gamble, and you took it an  infinite number of times, you would end up  losing 8% on average.  Any one time might work out.  But by the law of large numbers, if we took this ", "enough times, you'd lose 8% on average.  So you will lower the value of your company.  You will reduce profits by taking this gamble.  Your company is worse off if you take this gamble. ", "Well, what would the person who got the $100 in stocks do?  They won't take the gamble.  Because their $100 in stock will be worth, on average, 8%  less if they take this gamble. ", "So I'm not taking the gamble.  This is stupid.  But now let's look at the guy who got the option.  His gamble is a little bit different.  Because he doesn't care whether the value of the  company is 99 or 80. ", "He just cares about how much it goes above 100.  So what is his calculation?  Well, his calculation is he has a 10% chance of making  100% and a 90% chance of what? ", "Zero, ending up with zero.  He can't lose.  He has a 90% chance of zero.  So what is his calculation?  Well, he uses the positive 10% gamble. ", "He makes money on this gamble, because head he wins, tails he  walks away.  The guy who owns the stock loses if it's tails with this  weighted coin that only hits heads 10% of the time. ", "This guy only wins.  So he says, sure.  Any gamble which has a huge upside, I'm going to take.  Because I get all the upside, and I don't bear the downside.  So what this does is it leads to excessive gambling, ", "excessive risk taking.  And that's exactly what we saw in economy, was companies  gambling on things which sounded very good, managers  gambling on things which sounded very good, some of  which worked out very well and some of which didn't. ", "And that's the first problem we have with the  use of stock options.  And questions about that?  Yeah.  AUDIENCE: What about using a package of options like a  number of stock options [INAUDIBLE PHRASE] ", " package of stock options [INAUDIBLE PHRASE].  PROFESSOR: Certainly there are more sophisticated ways you  can do that.  I mean, there's certainly more sophisticated ", "ways you can do that.  But that's a great segue to the second problem with these.  The second problem is who decided the structure of the  stock options?  The managers. ", "So the managers had executive compensation committees that  designed the stock options the managers got.  So the second problem was there was  just outright cheating. ", "So what you just described would be a great structure  which would incentivize them maximally, but it would not  make them the most money.  So the second problem we had was outright cheating.  So there's a wonderful investigation by the Wall ", "Street Journal that investigated a whole list of  stock option arrangements.  And what they found was companies would frequently do  what's called backdating stock options.  What they'd say is, look, the value of the company just went ", "up from $100 to $15 last week.  We're going to give you an option at $100.  And let's pretend it was issued before the company  value went up.  We've just given you money. ", "You haven't done anything to earn that.  We've just given you money.  And the Wall Street Journal found incredible evidence of  backdating stock options.  So they had one CEO. ", "They Yeah, I'm sorry.  AUDIENCE: Is the company paying the money?  I thought it was like the market who gives it.  PROFESSOR: The owners are paying the money, the owners. ", "AUDIENCE: People who are buying the stock are  exercising the option to.  PROFESSOR: No.  But here's the thing.  When I gave it to you, then, basically, I gave you  something of value.  I have to pay for that thing of value. ", "Now, ultimately, the transaction  happens in the market.  But, basically, in other words, I give you this option  to buy the stock at $100.  This is an important point that I wasn't clear enough on.  I give you an option to buy a stock at $100. ", "The stock is now worth $150.  That means that stock I could have had at $150 as an owner.  And it's worth $150.  But by letting you take it at $100, I let you keep the extra ", "$50 instead of me getting it.  I have a share of stock which [INAUDIBLE]  $150.  I've given that to you.  I've, essentially, transferred to you $150. ", "AUDIENCE: So when companies [INAUDIBLE PHRASE].   PROFESSOR: They'll keep some amount of shares.  ", "The owners, they will sell stock  and they'll do offerings.  But the owners own the majority of the stock.  That's what makes them the owners.  Maybe that's the right way to put it.  AUDIENCE: [INAUDIBLE PHRASE].  ", "PROFESSOR: No.  Well, in principle, the board of directors approves stock.  They don't decide.  An executive management committee decides.  The executive management committee consists of all the  golf buddies of the CEO. ", "They decide.  The board of directors is supposed to make sure nothing  untoward happens.  The board of directors, they're just a bunch of  retired former executives who are also golf  buddies of the manager.  So they don't really get it right. ", "So there's outright cheating.  So, for instance, one CEO, he got six stock options.  Each one happened to be issued, happened to be issued ", "the day before-- at least on paper-- was issued the day  before a huge increase in the stock price.  Now, the CEO said he was just lucky.  But the Wall Street Journal did a simulation and  calculated that there's a 1 in 1 billion chance he could've ", "been that lucky.  That, in fact, what clearly happened was he got the stock  options later, and they were backdated to make it seem like  he got them before the price went up.  But that's not the best example.  The best example is Cablevision. ", "They granted and backdated options to their vice chairman  from 1997 to 2002.  So from 1997 to 2002, they gave them options and they  kept backdating them to make them look good.  The only problem was that he died in 1999. ", "So, basically, they were just giving money away to this  guy's heirs.  Clearly they weren't incentivizing his performance.  As the quote said, trying to incentivize a corpse suggests  they were not complying with the spirit of shareholder ", "approved stock option plans.  They were just giving money to his heirs, because they felt  bad for him, because they weren't keeping their yacht up  or whatever.  So, basically, this is an example of a kind of cheating. ", "Of course, then you can go further, and  there's outright fraud.  The backdating is sort of cheating.  You can go even further.  I don't know what determines fraud versus cheating. ", "You can just do what Enron did.  What Enron did is the executives there just lied  about how much money they were making.  They just went public with figures that were wrong.  The stock price went up.  They cashed in their options and quit. ", "And as long as you don't get caught, that's a great deal.  And if you do get caught, well, they fine you for 1/3 of  what you made.  So who cares?  So basically it was outright fraud. ", "And this was a lot of what happened.  A lot of the wealth that we thought was created in the  1990s in the stock market was really just false wealth  created by people saying their company's were worth more than  they actually were.  Yeah. ", "AUDIENCE: Who decides the salary [INAUDIBLE PHRASE].   PROFESSOR: No.  I mean, once again, it varies by company to company. ", "But, basically, the dividend payout would be something that  a different set of managers would decide, once again,  subject to approval of the owners.  But, once again, the point is that the owners of a company, ", "of a big company, are just a diffuse set of people who  don't know what they're doing.  The managers know exactly what they're doing.  The board of directors is in between and is half clueless,  half knows what it's doing. ", "And that's what leads to the agency problem.  What's so interesting about this example is it sort of  points out, like in many things in economics, why we're  called the dismal science. ", "There is no right answer here.  On the one hand, if you don't incentivize your owners, then  they might not do what's profit maximizing.  On the other hand, if they incentivize your owners, they ", "might do cheating to maximize their profits as opposed to  the company's profits.  And that's why you need complicated structures, the  type that was suggested in the back.  And that's why, for example, they find that companies with  much more concentrated ownership, the ones that ", "Warren Buffett owns 20% of, they do a much better job in  their CEO compensation than the ones where it's just a  bunch of people owning a tiny, tiny percent.  So that's exactly the kind of difficulty you face in setting ", "up executive compensation.  Now, this was a real departure from the kind of things we  talked about, just one example.  Partly what we want to do in this course, I want to teach  you about basic economics.  I partly want to excite you about what else you can go on ", "and do in economics.  What I've just done in the last half hour is a microcosm  of the field of corporate finance.  There's an entire field in economics  called corporate finance.  We teach it in course 15. ", "And it's a terrific course.  15.401 and 15.402 are the introductory courses.  And if you find this stuff exciting, as I'm sensing some  of you are, that's a great place to take what we're  learning in this course and go on and actually dive in. ", "Realize that half the stuff I've told you, I'm  talking out of my ass.  I don't really know for sure.  But those guys do in course 15.  And you can really get into these agency relationships and  understand our corporations work and how you set up these ", "kinds of compensation arrangements.  So this is kind of just a very exciting area.  Now, we're going to go back after this and assume  corporations maximize profits again.  And, once again, as with any assumption we make, by and ", "large, it's right.  And by and large it will deliver the kind of important  knowledge that we need to know about how firms function.  But it's important to remember that these kinds of  things are behind it.  What we do in this course is teach you the basics. ", "Then you go on in these other electives and actually learn  about this kind of more interesting tweaks  and what we do here.  And other questions about this before I move on?  OK. ", "Now we're going to stop with that topic, and we're going to  move to sort of an in between topic.  That is, we've been talking about firms and firm profit ", "maximization.  And we talked about how that depends on the structure of  the market and perfect competition.  Starting in two lectures, we're going to start talking  about alternative market structures like ", "monopoly and oligopoly.  But in order to talk about them, we need to introduce a  new concept we haven't used before.  And that's what we'll do the rest of this  lecture and next lecture. ", "We need to move from positive economics to normative  economics, from positive economics to normative. ", " Positive analysis is the study of the way things are.  So positive analysis is explaining why do firms ", "produce this many widgets?  Why do they hire this many workers?  Why did I buy this many CDs?  That's a positive analysis, trying to explain the way  things are.  That's what we've done, by and large, so far. ", "Normative analysis is the analysis of the way  things should be.  Is it good that I bought that many CDs?  Is it good that the company made that much profits?  Would be better if we have a minimum wage or don't have a ", "minimum wage?  Normative analysis is the analysis of the way things  should be as opposed to the way they are.  So, for example, we showed in the last lecture that in the ", "long run, with free entry and exit, all firms are driven to  zero profit, and the supply curve is horizontal.  Well, is that a good thing? ", "We don't know.  We just said it happened.  I described why it happened.  But I didn't tell you if it was a good  thing or a bad thing.  Zero profits, I make a lot of money off the profits that the  companies I own make.  I don't know if I want to work with zero profits. ", "I've got a lot of stock and stuff.  And I'm making money because these companies make profits.  I don't think I'd be that happy to  work with zero profits.  How do we think about whether that's a good  world or a bad world?  How do we think about whether we like these outcomes or ", "don't like them?  These are the tools of normative economics or what we  will refer to as welfare economics.  ", "Now, let me be clear here.  The term welfare, as you might have heard it, often refers to  money you give to low income populations.  And we'll talk about that kind of welfare  later in the semester.  Here, when I say welfare, I mean well-being. ", "Welfare is the term economists use as the measure of  well-being.  We need to start talking about welfare economics, measuring  the impact of economic outcomes on well-being, not ", "just studying what happens when firms maximize profits or  consumers maximize utility, but measuring how we feel  about it, measuring whether it's good or bad, and ", "measuring whether some outcomes might be  preferred to others.  Because if we don't do that, we can't ever talk about the  role of the government in the economy.  Until you start talking about welfare, you can't talk about ", "whether we should have government  interventions or not.  You can only talk about what happens, not  whether it should happen.  Now, the problem of welfare economics is that it's a lot  harder because of something I mentioned when we ", "talked about utility.  Utility is an ordinal concept, not a cardinal concept.  Utility is an ordinal concept, not a cardinal concept.  That is, utils are meaningless. ", "We use utility functions to decide whether you prefer  package A or package B. But the actual amount of utils you  get, unlike profits, is sort of a meaningless concept.  It's just sort of an index. ", "So what we do to do welfare economics is we turn from  utils to dollars.  We measure welfare in dollars which is easy on  the corporate side.  That's profits. ", "How do we do it on the consumer side?  We do it through the concept that we call compensating  variation, which is one of these things where economists ", "use fancy terms for something which isn't that hard to  understand.  But you need to know the fancy terms, because that's kind of  how we teach, compensating variation.  That is instead of asking, how sad are you about outcome x, ", "we ask, how many dollars would it take?   Instead of asking, how sad would you be to not have a CD, ", "we ask, how much would you pay to avoid  being in that situation?   So instead of asking, how sad are you that you end up with ", "this car instead of that car, we don't want to measure the  utils of driving a Hyundai versus a Lexus.  We can't measure those.  What we can ask, is how much more will you pay to get the ", "Lexus than the Hyundai?  And that's $1 measure of your utils.  That's a compensating variation.  How much do you have to be compensated? ", "So, in other words, instead of asking you how sad are you  that you couldn't get tickets to a Lady Gaga concert--  maybe that's not a good example because no one's sad  about that.  But let's say you were. ", "Let's say I am because my daughter wants to see her.  How sad are you?  I ask, instead, how much would you pay to get the tickets to  the Lady Gaga concert?  ", "That's a measure of how sad you were you  couldn't get them.  Because you'll pay an amount to compensate yourself for the  sadness of not getting them.  So it's a way of turning utils into dollars. ", "And that leads to the concept that we'll refer to throughout  the semester.   That leads to the concept of consumer surplus.  ", "Consumer surplus measures the benefit that a consumer gets  from consuming a good above and beyond what they  paid for the good. ", "So it's the benefit of consumption beyond the price. ", "So your consumer surplus--  surplus means extra--  is how much you enjoy consuming something above and  beyond what you had to pay for it.  In other words, the idea is if you have to pay exactly as ", "much as you'd enjoy the good, there's no consumer surplus.  So let's do an example.  So consider my demand to buy a Lady Gaga CD.  I've got to update my examples.  You guys don't buy CDs anymore. ", "How many of you have bought a CD in the last year?  Wow.  OK, let me ask another question,  just one for the record.  Just because I have to decide how hard a time to give my  16-year-old son.  How many of you typically pay when you buy a song? ", "Wow.  OK.  Let me ask another one.  How many of you typically don't pay when you buy a song.  Well, when you get a song, when you download a song, you  know what I mean, when you download a song.  So the majority of you don't pay when you download a song. ", "Interesting.  OK.   I'll update this next year.  But, for now, we're still 10 years ago.  Consider my demand for Lady Gaga CDs.  I'm trying to decide whether to buy the marginal CD. ", "And let's say that it's worth $15 to me.  I'd be willing to pay $15 for the Lady Gaga CD.  And let's say the price is $15. ", "In that case, there's no surplus to me.  There's nothing extra.  I've paid what I was willing to pay.  So that's a case of a zero consumer surplus. ", "The consumer surplus is how much extra I got from  consuming it.  I've got no extra.  It was worth $15.  I paid $15, no surplus.  Now let's say that the price was $10. ", "Then I've got a surplus.  I've got $5 in surplus.  I was willing to pay $15.  It makes me $15 happier to have this Lady Gaga CD.  But I only had to pay $10 for it. ", "So I've derived some surplus.  Well, how do we know what people's willingness to pay  for a good is?  The demand curve. ", "That's the definition of the demand curve.  The demand curve measures your willingness to pay.  So let's go to the second figure.  Think about the demand curve for CDs. ", "There's some demand curve for CDs.  What this measures is the utility maximizing choice.  Every point in this demand curve represents my utility ", "maximizing choice at that price.   This is backwards.  That should be a $15 on the y-axis and a $5 on the x-axis, ", "Sorry, guys.  It should be $15 on the y-axis and a--  no.  Wait, hold on one second.  Time out.   At $5, I get no consumer surplus. ", "", "Yeah, this graph is kind of messed up.  Let me draw a new one here.   So you've got my demand curve for CDs.  You've got the quantity and the price.  ", "And I've got some utility function that delivers this  demand curve.  And let's say the way this works, this demand curve for ", "CDs, let's say the way this works is that I am  willing to buy 1 CD.  I'm willing to buy if the price is $20, I'm ", "willing to buy 1 CD.  So at a price of $20, I'm willing to buy 1 CD.  So if I get that 1 CD at $20, then basically that's my ", "willingness to pay.  It equals a price, so there's no consumer surplus.  Really imagine it's right next to that y-axis.  ", "Now let's the price falls to $15.  Sorry.  That's a 1.  That's the 1.  That's a 20.  At a price of $20, I'm willing to buy 1. ", "At a price of $15, I'm willing to buy 5.  I'm willing to buy 5 CDs.   Now, what is my consumer surplus?  Well, let's ask. ", "For the first CD, I got no consumer surplus.  But for the second, I was willing to pay.  When the price was $20, I got no consumer surplus. ", "Now let's say the price is $15.  So what was I willing to pay for the first CD?  $20.  So what's my consumer surplus on the first CD?  5.  So on that first CD, I got a consumer surplus of 5. ", "The second CD, I was willing to pay less because I've got  diminishing marginal utility.  But I was still willing to pay more than $15.  So I've got some surplus there. ", "Third CD here, et cetera.  But on the fifth CD, I derive no surplus, because I was  willing to pay $15 for that fifth CD, and I paid $15 for  that fifth CD. ", "What that means is that all of this is my consumer surplus.  Because on every unit, because I paid a fixed price of $15, ", "and for my fifth CD, that delivered no surplus, that was  indifferent.  But in my first through fourth CDs, that made me very happy.  Because I was willing to pay more than $15 for those. ", "So my consumer surplus is the amount by which I derive  utility above what I was willing to  pay, above the price--  I'm sorry-- the amount that I was willing to  pay about the price. ", "The amount I'm willing to pay is every point on this curve.  So anything I buy that I was willing to pay more for the  price for, I derived surplus on.  So this becomes my consumer surplus. ", "So, basically, consumer surplus is the area under the  demand curve above the price.  So, graphically, consumer surplus is going to be the ", "area under the demand curve above the price.  Intuitively, why is that?  Intuitively, what's going on is that every unit above the ", "price under the demand curve are units which I valued  higher than the price.  So I get surplus on them.  OK.  Question?  Yeah.  AUDIENCE: If you're [UNINTELLIGIBLE] this, would ", "you start at zero?  PROFESSOR: Yeah.  Really, in some sense, you'd want to start at zero.  It's really the integral of this whole area.  The problem is it's discrete.  I should have a stepwise curve here. ", "I made it discrete.  But, really, it's the integral of this area.  Yeah.  AUDIENCE: [INAUDIBLE PHRASE].  upward sloping demand curve?  PROFESSOR: I'm sorry.  AUDIENCE: With an upward sloping demand curve. ", "PROFESSOR: With an upward sloping demand curve, well, as  I said, we don't believe in Giffen goods.  We think they are a fantasy.  So with an upward sloping demand curve,  how would that work? ", " So an upward sloping demand curve, then that would say  that if the price is here, then you'd have an infinite ", "consumer surplus.  It wouldn't be well-defined.  It wouldn't be well-defined.  So I don't know how you'd do that.  That's why we don't like upward sloping demand curves.  Yeah.  Question?  No?  OK. ", "So, basically, what you end up with is this consumer surplus  concept which, basically, as pointed out mathematically, is  the integral of this area.  But we're not going to make you integrate.  It's basically this triangle which is basically all the ", "units above the price, all the units for which you're willing  to pay more than the price.  And you get consumer surplus on every unit you buy up to  the point where your willingness to ", "pay equals the price.  And that's our normative measure of welfare.  That's our normative measure of how happy you are.  And the key that drives this is ", "diminishing marginal utility.  That's why we don't like upward sloping demand curves.  What drives this is diminishing marginal utility.  It's that with each additional unit I'm willing to pay less  and less for.  So I'm going to get less and less surplus off each ", "additional unit I buy.  And that's going to be the key thing.  The key intuition that you guys have to remember is that  the last unit that I'm willing to buy at that price, by ", "definition, I get no surplus on, or I get a $0.001 of  surplus on.  Because if I've got a lot of surplus, I'd buy 1 more. ", "So, by definition, the marginal unit is the one where  surplus is driven to 0.  And units before that are the ones with positive surplus.  And that's why an important intuition to have is the ", "amount of surplus you're going to get from a purchase is  going to be about how far away from the price point you are.  Those first units are going to give you more surplus.  And that's going to dwindle as you get to the actual last ", "unit you buy at that price.  Any questions about that?  OK.  Let me stop there.  We will come back next time, and we're going to spend the  whole lecture talking about welfare economics, we'll ", "introduce producer surplus, and talk about how we then  think about whether changes are good or bad.  "], "vid_duration": [13.579, 11.61, 12.281, 11.08, 11.21, 11.04, 11.485, 14.095, 11.61, 12.61, 10.42, 11.91, 10.41, 16.94, 10.43, 10.4, 11.53, 11.1, 13.13, 11.2, 11.19, 14.53, 11.01, 12.14, 11.63, 10.24, 15.42, 12.03, 13.57, 10.81, 13.05, 12.53, 10.19, 11.68, 11.07, 10.64, 10.83, 10.34, 11.87, 10.53, 13.61, 11.925, 12.875, 10.21, 10.65, 11.78, 12.03, 12.98, 11.89, 11.14, 12.42, 10.02, 11.11, 10.11, 10.69, 11.9, 10.4, 11.255, 10.095, 12.21, 11.926, 10.514, 14.83, 12.0, 11.27, 11.97, 10.68, 13.83, 12.42, 10.13, 11.61, 10.21, 11.61, 11.22, 11.36, 10.72, 11.615, 10.975, 11.06, 14.04, 11.25, 10.97, 12.5, 12.16, 10.48, 10.41, 17.77, 10.54, 13.15, 10.28, 10.36, 10.19, 11.42, 19.9, 11.76, 10.11, 14.56, 10.74, 15.96, 12.62, 10.55, 10.96, 10.09, 11.02, 14.5, 12.34, 12.3, 12.52, 13.82, 12.466, 10.354, 10.89, 10.86, 10.01, 11.893, 10.037, 10.51, 12.93, 10.21, 11.18, 12.3, 12.718, 12.662, 14.4, 10.852, 12.418, 10.29, 11.21, 11.91, 13.88, 10.78, 10.87, 10.34, 13.62, 10.47, 10.056, 11.004, 11.7, 11.25, 10.67, 10.37, 11.76, 13.7, 11.99, 10.44, 10.22, 11.99, 11.1, 10.91, 11.14, 11.51, 10.41, 10.84, 11.07, 10.91, 11.16, 12.28, 11.35, 10.08, 12.64, 10.74, 10.91, 10.87, 11.15, 11.59, 10.72, 12.19, 10.99, 12.4, 10.46, 10.79, 15.2, 10.08, 13.33, 10.89, 10.2, 10.62, 11.0, 10.71, 14.55, 11.36, 13.86, 14.34, 10.95, 13.883, 11.667, 12.36, 10.58, 10.11, 13.73, 10.44, 10.15, 11.98, 11.73, 12.8, 10.08, 10.162, 12.838, 10.3, 13.29, 10.79, 14.99, 10.06, 10.69, 11.09, 13.03, 10.02, 10.91, 12.56, 11.26, 11.11, 13.66, 11.14, 11.7, 11.046, 10.454, 11.85, 10.04, 17.6, 10.39, 12.59, 10.94, 10.09, 12.17, 11.13, 13.71, 11.28, 10.22, 10.13, 6.87], "stet": [[0, 13.579], [13.579, 25.189], [25.189, 37.47], [37.47, 48.55], [48.55, 59.76], [59.76, 70.8], [70.8, 82.285], [82.285, 96.38], [96.38, 107.99], [107.99, 120.6], [120.6, 131.01999999999998], [131.01999999999998, 142.92999999999998], [142.92999999999998, 153.33999999999997], [153.33999999999997, 170.27999999999997], [170.27999999999997, 180.70999999999998], [180.70999999999998, 191.10999999999999], [191.10999999999999, 202.64], [202.64, 213.73999999999998], [213.73999999999998, 226.86999999999998], [226.86999999999998, 238.06999999999996], [238.06999999999996, 249.25999999999996], [249.25999999999996, 263.78999999999996], [263.78999999999996, 274.79999999999995], [274.79999999999995, 286.93999999999994], [286.93999999999994, 298.56999999999994], [298.56999999999994, 308.80999999999995], [308.80999999999995, 324.22999999999996], [324.22999999999996, 336.25999999999993], [336.25999999999993, 349.8299999999999], [349.8299999999999, 360.63999999999993], [360.63999999999993, 373.68999999999994], [373.68999999999994, 386.2199999999999], [386.2199999999999, 396.4099999999999], [396.4099999999999, 408.0899999999999], [408.0899999999999, 419.1599999999999], [419.1599999999999, 429.7999999999999], [429.7999999999999, 440.6299999999999], [440.6299999999999, 450.96999999999986], [450.96999999999986, 462.83999999999986], [462.83999999999986, 473.36999999999983], [473.36999999999983, 486.97999999999985], [486.97999999999985, 498.90499999999986], [498.90499999999986, 511.77999999999986], [511.77999999999986, 521.9899999999999], [521.9899999999999, 532.6399999999999], [532.6399999999999, 544.4199999999998], [544.4199999999998, 556.4499999999998], [556.4499999999998, 569.4299999999998], [569.4299999999998, 581.3199999999998], [581.3199999999998, 592.4599999999998], [592.4599999999998, 604.8799999999998], [604.8799999999998, 614.8999999999997], [614.8999999999997, 626.0099999999998], [626.0099999999998, 636.1199999999998], [636.1199999999998, 646.8099999999998], [646.8099999999998, 658.7099999999998], [658.7099999999998, 669.1099999999998], [669.1099999999998, 680.3649999999998], [680.3649999999998, 690.4599999999998], [690.4599999999998, 702.6699999999998], [702.6699999999998, 714.5959999999999], [714.5959999999999, 725.1099999999999], [725.1099999999999, 739.9399999999999], [739.9399999999999, 751.9399999999999], [751.9399999999999, 763.2099999999999], [763.2099999999999, 775.18], [775.18, 785.8599999999999], [785.8599999999999, 799.6899999999999], [799.6899999999999, 812.1099999999999], [812.1099999999999, 822.2399999999999], [822.2399999999999, 833.8499999999999], [833.8499999999999, 844.06], [844.06, 855.67], [855.67, 866.89], [866.89, 878.25], [878.25, 888.97], [888.97, 900.585], [900.585, 911.5600000000001], [911.5600000000001, 922.62], [922.62, 936.66], [936.66, 947.91], [947.91, 958.88], [958.88, 971.38], [971.38, 983.54], [983.54, 994.02], [994.02, 1004.43], [1004.43, 1022.1999999999999], [1022.1999999999999, 1032.74], [1032.74, 1045.89], [1045.89, 1056.17], [1056.17, 1066.53], [1066.53, 1076.72], [1076.72, 1088.14], [1088.14, 1108.0400000000002], [1108.0400000000002, 1119.8000000000002], [1119.8000000000002, 1129.91], [1129.91, 1144.47], [1144.47, 1155.21], [1155.21, 1171.17], [1171.17, 1183.79], [1183.79, 1194.34], [1194.34, 1205.3], [1205.3, 1215.3899999999999], [1215.3899999999999, 1226.4099999999999], [1226.4099999999999, 1240.9099999999999], [1240.9099999999999, 1253.2499999999998], [1253.2499999999998, 1265.5499999999997], [1265.5499999999997, 1278.0699999999997], [1278.0699999999997, 1291.8899999999996], [1291.8899999999996, 1304.3559999999995], [1304.3559999999995, 1314.7099999999996], [1314.7099999999996, 1325.5999999999997], [1325.5999999999997, 1336.4599999999996], [1336.4599999999996, 1346.4699999999996], [1346.4699999999996, 1358.3629999999996], [1358.3629999999996, 1368.3999999999996], [1368.3999999999996, 1378.9099999999996], [1378.9099999999996, 1391.8399999999997], [1391.8399999999997, 1402.0499999999997], [1402.0499999999997, 1413.2299999999998], [1413.2299999999998, 1425.5299999999997], [1425.5299999999997, 1438.2479999999998], [1438.2479999999998, 1450.9099999999999], [1450.9099999999999, 1465.31], [1465.31, 1476.162], [1476.162, 1488.58], [1488.58, 1498.87], [1498.87, 1510.08], [1510.08, 1521.99], [1521.99, 1535.8700000000001], [1535.8700000000001, 1546.65], [1546.65, 1557.52], [1557.52, 1567.86], [1567.86, 1581.4799999999998], [1581.4799999999998, 1591.9499999999998], [1591.9499999999998, 1602.0059999999999], [1602.0059999999999, 1613.0099999999998], [1613.0099999999998, 1624.7099999999998], [1624.7099999999998, 1635.9599999999998], [1635.9599999999998, 1646.6299999999999], [1646.6299999999999, 1656.9999999999998], [1656.9999999999998, 1668.7599999999998], [1668.7599999999998, 1682.4599999999998], [1682.4599999999998, 1694.4499999999998], [1694.4499999999998, 1704.8899999999999], [1704.8899999999999, 1715.11], [1715.11, 1727.1], [1727.1, 1738.1999999999998], [1738.1999999999998, 1749.11], [1749.11, 1760.25], [1760.25, 1771.76], [1771.76, 1782.17], [1782.17, 1793.01], [1793.01, 1804.08], [1804.08, 1814.99], [1814.99, 1826.15], [1826.15, 1838.43], [1838.43, 1849.78], [1849.78, 1859.86], [1859.86, 1872.5], [1872.5, 1883.24], [1883.24, 1894.15], [1894.15, 1905.02], [1905.02, 1916.17], [1916.17, 1927.76], [1927.76, 1938.48], [1938.48, 1950.67], [1950.67, 1961.66], [1961.66, 1974.0600000000002], [1974.0600000000002, 1984.5200000000002], [1984.5200000000002, 1995.3100000000002], [1995.3100000000002, 2010.5100000000002], [2010.5100000000002, 2020.5900000000001], [2020.5900000000001, 2033.92], [2033.92, 2044.8100000000002], [2044.8100000000002, 2055.01], [2055.01, 2065.63], [2065.63, 2076.63], [2076.63, 2087.34], [2087.34, 2101.8900000000003], [2101.8900000000003, 2113.2500000000005], [2113.2500000000005, 2127.1100000000006], [2127.1100000000006, 2141.4500000000007], [2141.4500000000007, 2152.4000000000005], [2152.4000000000005, 2166.2830000000004], [2166.2830000000004, 2177.9500000000003], [2177.9500000000003, 2190.3100000000004], [2190.3100000000004, 2200.8900000000003], [2200.8900000000003, 2211.0000000000005], [2211.0000000000005, 2224.7300000000005], [2224.7300000000005, 2235.1700000000005], [2235.1700000000005, 2245.3200000000006], [2245.3200000000006, 2257.3000000000006], [2257.3000000000006, 2269.0300000000007], [2269.0300000000007, 2281.830000000001], [2281.830000000001, 2291.9100000000008], [2291.9100000000008, 2302.0720000000006], [2302.0720000000006, 2314.9100000000008], [2314.9100000000008, 2325.210000000001], [2325.210000000001, 2338.500000000001], [2338.500000000001, 2349.290000000001], [2349.290000000001, 2364.2800000000007], [2364.2800000000007, 2374.3400000000006], [2374.3400000000006, 2385.0300000000007], [2385.0300000000007, 2396.120000000001], [2396.120000000001, 2409.150000000001], [2409.150000000001, 2419.170000000001], [2419.170000000001, 2430.080000000001], [2430.080000000001, 2442.640000000001], [2442.640000000001, 2453.900000000001], [2453.900000000001, 2465.010000000001], [2465.010000000001, 2478.670000000001], [2478.670000000001, 2489.810000000001], [2489.810000000001, 2501.5100000000007], [2501.5100000000007, 2512.5560000000005], [2512.5560000000005, 2523.0100000000007], [2523.0100000000007, 2534.8600000000006], [2534.8600000000006, 2544.9000000000005], [2544.9000000000005, 2562.5000000000005], [2562.5000000000005, 2572.8900000000003], [2572.8900000000003, 2585.4800000000005], [2585.4800000000005, 2596.4200000000005], [2596.4200000000005, 2606.5100000000007], [2606.5100000000007, 2618.6800000000007], [2618.6800000000007, 2629.810000000001], [2629.810000000001, 2643.520000000001], [2643.520000000001, 2654.800000000001], [2654.800000000001, 2665.020000000001], [2665.020000000001, 2675.150000000001], [2675.150000000001, 2682.020000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [663, 986, 1758, 2682]}
{"example_id": "mit075@@MIT14_01SCF10_lec14_300k", "text": [" JON GRUBER: All right, so today we are going to continue  with our discussion of producer theory.  And today we're going to move beyond the unrealistic case of ", "perfect competition to the somewhat more realistic case  of monopoly.  Now, we've been discussing perfect competition thus far  as a form of market organization, and that makes ", "sense in some context like fast food and other things.  But in most contexts, we think perfect composition is not the  way the world works.  There's some limits on competition. ", "And we think that markets--  many markets, many of the goods we consume have only a  few firms. Operating systems or cars or a lot of things we ", "consume, typically have only a few firms in them.  So the most realistic model of markets would be one which  accounts for the fact that there's less than an infinite ", "number of firms, there's only a few firms.  That turns out also to be the hardest model.  So what we do is we sort of iterate there.  We started with one extreme, which is a competitive market  where there's an infinite number of firms, that allows ", "us to draw some interesting conclusions.  Now we're going to reverse field and talk about the other  extreme, monopoly, which is only one firm.  We'll talk about monopoly markets with only one firm. ", "Then we'll talk about oligopoly, that middle case,  which is multiple firms.  So let's talk about monopoly, a market where  there's only one firm.  ", "The key thing to remember for monopolies is they're no  longer price takers, they're now price makers.  Competitive firms are price takers.  They were given a price by the market and ", "they reacted to that.  And as we saw in the long run, that price settled at the  minimum of average cost. So basically, they were given the  price which dictated production efficiency.  They reacted to that in how much they produced. ", "You got a flat long run supply curve.   However, in a monopoly market, we don't meet the conditions  for perfect competition.  In particular, one condition was that consumers had perfect ", "substitutes between your good and other  goods they could buy.  That's not true in a monopoly market.  So if we think about that era, sort of maybe, I don't know, I ", "don't have my computer history isn't as good.  Maybe 10 years ago when Macs were sort of at the nadir of  their popularity.  And really you had to be a pretty high tech guy to be  using Linux and things like that. ", "That Windows had virtually a monopoly on operating systems.  Not really, but virtually.  Certainly unless you were a high tech guy who could do  Linux and things like that, pretty much if you wanted an  operating system, you got Windows. ", "Windows pretty much had a monopoly.  And that's may be as close as we've come in the modern  economy to thinking about an example of monopoly.  In that case, Bill Gates had to decide-- ", "wasn't given a price, he had to decide how much to charge  for Windows.  And that decision determined in turn how  much he would produce.  And that's exactly what we'll talk about today, is how does ", "a monopolist decide both what to charge and how much to  produce of their good?  So to do that, we're going to turn to a new concept.  Well, not a new concept, but a different way of looking at ", "something we've talked about before,  which is marginal revenue.   If you remember, the profit maximizing condition that we  derived when we started our competition lectures was that ", "marginal revenue equals marginal cost. That was our  profit maximizing condition, was that marginal revenue  equals marginal cost. ", "Now we're going go to--  in perfect competition.   And the way we thought about this marginal revenue equals  marginal cost, remember the logic was this notion of ", "climbing this profit hill.  You want to produce any unit.  Think of yourself as climbing this profit hill.  You're deciding, do I produce the next unit?  And I produce the next unit as long as the money I make off ", "that unit exceeds what it cost to produce that unit.  So I climb that profit hill.  If marginal revenue is greater than marginal cost,  I keep going up.  At the peak, marginal revenue will equal marginal cost. Once ", "I go beyond that peak, marginal revenue will fall  down below marginal cost and I'll stop producing.  So the notion is I climb this hill, which in the peak is  dictated by marginal revenue equals marginal cost. ", "Now for a competitive firm, we said marginal  revenue was just price.  So in perfect competition, the rule was set price equal to  marginal cost. But that was a particular ", "case of marginal revenue.  So for example, to see that, let's look at Figure 14-1.  This is another way.  Probably next year when I teach this, I'll put this in  the lecture on competition. ", "Just a way to think about how marginal revenue is priced.  Remember, a perfectly competitive firm faces a  perfectly elastic demand curve.  They face a perfectly elastic demand curve. ", "So they have to think about what the implications are of  the marginal unit they sell.  Well if they sell little q units, their revenue's a. ", "If they sell one more unit, their revenue is b.  And the marginal revenue is the height of that rectangle B  times the base.  The base is 1 because it goes from q plus 1. ", "The height is p.  So the marginal revenue is price.  This is a pretty basic diagram.  So marginal revenue is price for the  perfectly competitive firm. ", "Now let's look at the monopoly case.  The difference with a monopolist, as you see in  Figure 14-2, is they no longer face a perfectly elastic ", "demand curve.  They now face a downward-sloping demand curve.  Why is that?  Well remember, this is the graph for little q.  The reason the graph for little q was perfectly elastic ", "with a perfectly competitive case was not that we said the  demand for the entire good was perfectly elastic.  It's just that the residual demand facing anyway one firm  was perfectly elastic. ", "Well now, a monopolist is the only firm in the market.  So their residual demand equals total demand.  Their residual demand equals total demand.  So as long as total demand is downward-sloping, as we ", "typically think it is, then they'll face a  downward-sloping demand curve.  So unlike a perfectly competitive firm, which faces  a perfectly elastic residual demand curve, a monopoly firm ", "will face a downward-sloping market demand curve.  They face the entire market demand curve.  So this is demand curve.  Now we're talking about big Q's not little q's anymore.  Or we could say little q equals big Q. ", "There's only one firm.  So little q's and the big Q's are the same.  So now the firm reacts not to its residual firm demand  curve, which is flat, but the downward-sloping  market demand curve. ", "Now, we're going to make one assumption  here that's very important.  We'll come back to this at the end of the lecture.  We're going to assume that the monopolist can only charge one  price for their good to all consumers. ", "So most of this lecture we're going to assume a non-price  discriminating monopolist. We're going to say that Bill  Gates can't look at you and say, look, you look like you  really want Windows.  I'm going to charge you more than her. ", "He can't do that.  He has one price.  He sells it to the stores at one price.  So it's a non-price discriminating monopolist  we're going to work with for the first 2/3 of this lecture. ", "That monopolist has to set one price.  Now, for that monopolist, for Bill Gates with Windows circa  10 years ago, let's think about his decision to produce ", "another unit.  He's originally producing at Q, big Q at a price p1.  He's originally producing a big Q at a price p1.  If he wants to sell one more unit, he's going to have to ", "lower the price.  Because he now faces a downward-sloping demand curve.  So if he wants to sell one more unit, he's going to have  to lower the price to P2.  ", "I have a big cockatoo at home.  This is his feather.  So he's going to have to lower the price to P2.  What's that going to do? ", "Well, on the one hand, what that's going to do is that's  going to mean on that next unit he's going to make p2.  So he's going to get the rectangle B. On the other ", "hand, on all the units he was selling at p1, he now gets a  lower price p2.  So he loses the rectangle C. So the marginal revenue for ", "this monopolist, the marginal revenue is equal to the  rectangle B minus the rectangle C. The marginal ", "revenue is rectangle B minus rectangle C.  Or alternatively, you could say that if we just write that  out, write out what that is, that's p2 minus p1 ", "minus p2 times Q1.   Or rewriting, we could rewrite this then as marginal revenue ", "equals p plus delta p delta q, how much the price changes  when you change the quantity, times the ", "original quantity Q1.   Or one more time, for those of you who prefer calculus.  If revenue equals p times q, and q is a function of p, then ", "marginal revenue, differentiating that, is p  plus dp dq times Q. So marginal revenue is the price ", "plus the change in price from selling another unit times the  initial quantity.   Once again, the graphics are in this graph. ", "The math is here.  We just differentiate the revenue equation.   This term is positive.  Price is always greater than 0. ", "But this term is negative because demand  curves slope down.  So there's now two effects.  There's a positive effect, which is if I sell another  unit, I make money on that other unit. ", "There's a negative effect, which is to sell that other  unit, I have to lower the price because I face  downward-sloping demand.  So there's two effects a monopolist as he thinks about ", "wanting to sell another unit.  There's the money from that unit, but the lower  willingness to pay for all previous units.  And that's what makes a monopolist a little more ", "interesting.  We basically think of the monopolist as basically having  to work down the demand curve.  With a perfectly competitive firm, they don't have to work  down the demand curve.  The demand's flat to them. ", "They can sell as much as they want at that price because  they don't affect the price.  They want to sell 10 of that price or a million at that  price, it doesn't matter.  Their demand curve's flat.  Not true for the monopolist.  If the monopolist wants to sell more, he has to face the ", "wrath of the market.  And the wrath of the market is such that if he wants to sell  more, he's going to have to lower the price to do so.   Remember, once again assuming he has to charge the same ", "price to everyone.  Assuming he's going to charge the same price to everyone, if  he wants to sell more, he's going to have to lower the  price to do so.   There's different ways of [UNINTELLIGIBLE]  intuition on this. ", "I like to call this the poisoning effect.  That's how I like to think about it.  That basically, if I want to sell another unit, I'm going  to poison the money I made on all previous units.  Because if I want to sell another unit, I have ", "to lower the price.  That's going to take away from the money I was making on my  previous units.  So it's sort of a poisoning effect is how I like  to think about it.  But you can have your own intuition for it. ", "And basicallly, this poisoning effect did not exist for the  perfectly competitive firm because they couldn't affect  the price with their action.  They could sell however many units they wanted at that flat ", "price and their actions did not affect that price.  The poisoning effect only exists with monopolists  because to sell that next unit, they have  to lower the price.   Now, basically what that means is to find equilibrium for a ", "monopolist, it's going to be a little bit trickier.  And so let's go to Figure 14-3 and slowly walk  through Figure 14-3.  And we'll start walking through. ", "What the monopolist is going to want to do is draw a  marginal revenue curve.  With the perfectly competitive firm, marginal revenue curve  was just a price, it was given to them. ", "There was no marginal revenue curve.  For a monopolist, there is a marginal revenue curve.  So here I have a demand curve.  The demand curve I've drawn here in this example.  ", "The demand curve I've drawn here is q equals 24 minus p.  That's a typical demand curve, downward-sloping.  As the price goes up, people want less of it. ", "And now we're in market demands.  Because remember, little q equals pq.  There's only one firm in the market.  Now, here's the trick with monopoly: mathematics. ", "The first thing you're going to want to do is you're going  to want to invert this.  You're going to want say, OK, that takes q, but what takes  the price a monopolist is going to charge?  The price a monopolist is going to charge is therefore  going to be 24 minus q. ", "That's going to be the price that the  monopolist is going to charge.   Therefore, revenues, pq, is 24q minus q squared. ", "So we inverted the demand equation.  We do this because we want to write down a revenue equation.  So that's the trick.  This is the mathematical trick here is to invert this, so  then you can write down a revenue equation.  We then differentiate this revenue equation to get that ", "marginal revenues equals 24 minus 2q.  That's marginal revenues.  The next unit you sell, you make 24 minus 2 times the ", "amount you're now selling.   And that's the marginal revenue curve graphed here.  Now, basically what you see is in this case the marginal ", "revenue curve starts at the same point as the demand curve  on the y-axis and lies everywhere  below the demand curve.  Now that first fact, that it starts at the same intercept, ", "is not always true.  That is true because in this case we assumed a linear  demand curve.  With a nonlinear demand curve, marginal revenue curves can  start at different points on the y-axis. ", "The second point about the marginal revenue curve always  being below the demand curve is always true regardless of  the function.  The marginal revenue is always below demand. ", "Marginal revenue is always below demand.  So that marginal revenue curve will always be below the  demand curve because of this poisoning effect.   Now, what I want to highlight here is this means there's a ", "very important relationship between marginal revenue and  the elasticity of demand.  So let's take our marginal revenue equation and put it ", "back in change terms. p plus delta p over delta q times Q.  And let's multiply and divide by p. ", "So marginal revenue you can rewrite as p plus p times  delta p over delta q times Q over p. ", "So I just took this second term, multiplied and divided  by p, the second term.  I just multiplied and divided by p.  The reason I did that is because that means you can  rewrite this. ", "This now starts to look like an elasticity expression.  Remember the expression for elasticity.  This looks like the inverse of an elasticity expression.  Remember what elasticity of demand was, delta q delta p ", "times p over Q. So that's the inverse to  the elasticity demand.  So we can rewrite this as marginal revenue equals p  times 1 plus 1 over the elasticity of demand. ", "Marginal revenue equals p times 1 plus 1 over the  elasticity of demand.  Think about what this means for a second.  What is the marginal revenue in a ", "perfectly competitive firm?  Well, as a perfectly competitive firm, what's the  elasticity of demand facing a perfectly competitive firm?  Infinity.  Perfectly elastic. ", "So marginal revenue by L'Hopital's rule equals p.   So for a perfectly competitive firm where elasticity is  infinity, marginal revenue equals p. ", "Now instead, if we took a firm where the elasticity of demand  was minus 1, the electricity demand was minus 1, the  marginal revenue would be 0. ", "Why is that?  What that says is, if you're a monopolist facing an  elasticity of demand of minus 1, then you make no money by  selling the next unit.  Because these two effects exactly cancel. ", "It turns out with elasticity of demand of negative 1, these  two effects exactly cancel.  Exactly what you make by selling one more unit is  offset by how much you have to lower the price on all your  previous units. ", "So an elasticity of demand of minus 1, marginal  revenue equals 0.  And as you can see as the elasticity of demand gets  below minus 1, as it approaches 0 from below. ", "As the elasticity of demand approaches 0 from below--  OK, I should have said perfect competition, I'm sorry, was  negative infinity, not infinity.  Negative infinity.  As the elasticity of demand approaches 0 from below, then ", "you're going to see that the marginal revenue--  as you approach 0 from below, marginal revenue is going to  become negative.  So for example, if the elasticity of demand equals  minus 0.5, then the marginal revenue equals minus p. ", "So if this is minus 0.5, then this becomes minus 2.  So marginal revenue equals minus p.  You lose money.  So as that elasticity of demand approaches 0, you're ", "going to have a negative marginal revenue from selling  the next unit.  And why is that?  With a very inelastic good, you have to push the price ", "down so much to sell the next unit that you lose money.  Think about a very elastic versus very inelastic good.  With a very elastically demanded good, to sell another ", "unit you don't have to change the price much.  Because the demand curve's very flat.  So there's not much of a poisoning effect.  dp dq is small, or dq dp is big. ", "OK, this is the inverse.  So dq dp is big with elasticity, so dp dq is small.  With a very inelastically demanded good, to sell one  more unit you're going to lower the price a ton, which ", "is going to poison the revenues you get from selling  that extra unit.  So that's why marginal revenue will be higher, or will be a ", "larger fraction of p as this elasticity  becomes more negative.   Yeah. ", "AUDIENCE: [UNINTELLIGIBLE PHRASE]  elastic that means [UNINTELLIGIBLE PHRASE]  irrespective of the price.  So couldn't you just charge a higher price and get marginal  revenue [UNINTELLIGIBLE]. ", "JON GRUBER: No, because here's the thing.  You should have already been charging that high price.  The point this is the margin.  So you go into a market for insulin.  You say, look, these guys are going to die without it.  I'm going to charge $500,000 a shot. ", "But now the question we're asking about marginal revenue.  And at $500,000, you sell to everyone who can afford it and  everyone else dies.  Now you want to ask, what's the marginal revenue as you're ", "trying to sell that 500,000 and first unit?  Well to sell that, since it's inelastically demanded, if  that person could afford anything like $500,000, they  would have bought it already. ", "They can't.  They can only afford $400,000.  We have to lower the price to $400,000.  You're going to sell one more unit at $400,000 but lose  $500,000 on all those other units you were going to sell  at $500,000. ", "The point is it's about the margin not the level.  Yes, monopolists make a huge profit when it's inelastic.  I'll talk about that in a minute.  But that next unit they're going to lose money on.  ", "So that's actually a good point to segue to now, let's  talk about with this in place, let's talk about how  monopolists maximize profits.  Let's talk about monopoly profit maximization. ", "Let's go to Figure 14-4.  Profit Maximization for a Monopolist.  Now, this is a lot more confusing than perfectly  competitive firms, so let's follow along here. ", " This is a case the cost function here  is 12 plus q squared.  So I'm doing the cost function, which  is 12 plus q squared. ", "That's the cost function.  And the demand function, as before, is Q  equals 24 minus p.  So that's what's graphed here.  ", "Now, recall the rule that profit is maximized where  marginal revenue equals marginal cost. Well, we know  marginal revenue.  We know marginal revenue-- ", "we derived that above--  is 24 minus 2Q.  What's marginal cost with this expression? ", "Well, marginal cost, differentiation of the cost  equation, which is 2Q.   So the optimization term for a monopolist is going to where  marginal revenue, which is 24 minus 2Q, equals marginal ", "cost, which is 2Q.  Or Q equals 6.  That's going to be the optimal production level for the  monopolist. ", "So we can see that graphically that's where the marginal cost  curve hits the marginal revenue curve.  If you go downward from that point, you get that the sales ", "are 6 units.  So marginal revenue equals marginal cost at 6.  You should be able to see that graphically, it's just where  the curves intersect.  Mathematically I just did it here.  It's actually pretty straightforward. ", "Here's the hard part.  What's the price?  We might say, well, gee, marginal cost and marginal  revenue intersect at 6.  I'm going to draw the dashed line over.  That means the price is going to be 12. ", "Why can that not be the price?  Why is that wrong?  What would that violate if the price was 12?  If you tried to sell 6 at a price of 12?  Yeah.  AUDIENCE: [INAUDIBLE]. ", "JON GRUBER: It's not on the the demand curve.  The monopolist still has to respect the demand curve.  So monopolists in setting their quantity, gets the  intersection of marginal revenue and marginal cost. But ", "then in setting the price, they still have to read off  the demand curve.  They can't change consumer tastes.  So they charge a price of 18.  That's where you sell a quantity of 6. ", "So monopolists it's a little bit trickier in a perfectly  competitive firm.  You set marginal revenue equal marginal cost to derive Q. But  then to get p, you've got to go back and plug that into the ", "demand curve.  So with a Q of 6, I have my Q of 6.  Well, what's the p?  Well, to get that p, I've got to go back and  plug this in here.  At Q equals 6, p is 24 minus q, or 18. ", "So I've got to respect the demand curve.  The monopolist has to respect the demand curve.  The monopolist picks both price and quantity, but he has  to pick them such that you get a point on the demand curve. ", "And the way we solve it, is the monopolist chooses a  quantity to set marginal revenue equal to marginal  cost, and then chooses the price that's consistent with  demand for that quantity.  ", "Questions about that?  Now one last thing.  In the short run, we still have another condition for  profit maximization, which is the shutdown rule.  Remember the shutdown rule we talked about perfectly ", "competitive firms in the short run, which is even if profits  are negative, you might not shut down.  You only shut down if price is less than average variable  cost. So there's still the shutdown rule. ", " So you only shutd own if price is less than average variable  cost. ", "Now in this case, what's the monopolist profits?  Well, the monopolist made a profit of 60.  How do we see that?  Well that's graphically the box, the rectangle, that's the ", "difference between the average cost curve and  the price they get.  So they're charging 18.  Now once again, marginal revenue is gone.  Think about marginal revenue like an imaginary concept. ", "Marginal revenue isn't something that actually exists  in the market.  Marginal revenue is just something the monopolist draws  to pick what they're going to do.  But then it disappears.  What the monopolist cares about then is price. ", "They're charging 18.  Their average cost for that unit is only 8.  So they're making a profit of 10 per unit on 6 units. ", "So they're making a profit of 60.  And what you can see, what you should be able to demonstrate  to yourself is, if a monopolist sold 5 units.  I'm sorry, selling 6 units. ", "If the monopoly sold that seventh unit, what you'll be  able to see is they would lose money on the seventh unit.  Because yes, if they sold that seventh unit, what happened if  they sold the seventh unit? ", "Well then their price would have to be what if they wanted  to sell a seventh unit?  The price would have to be 17.  The price would have to be 17.  So to sell a seventh unit, they'd have to ", "have a price of 17.  So basically at a price of 17, the price was 17. ", "Then what would happen?  Well, they'd sell one more unit at 17.  That'd be good.  But they'd lose $1 on the previous 6  units, which is bad.  So how much revenues would they make? ", "What would be their marginal revenue?  Well, the marginal revenue would be they make 17 minus  the 6 poisoning effect.  So marginal revenue equals 11. ", "What's their marginal cost?  Their marginal cost is 2Q.  Marginal cost is 14.  So they lose money. ", "So you should be able to walk through  this exercise yourself.  You might say, gee, the marginal cost of that next  unit is only 14.  They sell it for 17.  Gosh, they should do it. ", "What you're missing is by selling it for 17, they've  lost the dollar extra they make on each of  the previous 6 units.  And that poisoning effect makes it  unprofitable to do this.  And that's why the monopolists stop short of what would be ", "the perfectly competitive outcome.  What would the perfectly competitive firm do?  The perfectly competitive firm would set marginal  cost equal to demand.  And they would end up producing where marginal cost ", "equals demand.  So demand here is 24 minus p.  Marginal cost is 2Q.  So they would end up producing where marginal cost equals ", "demand at a much higher level charging a  slightly lower price.  So what you see is the monopolist ends up selling  fewer units at a higher price. ", "Questions about that?  Yeah.  AUDIENCE: How does this work for Microsoft where their  marginal costs are very low or nonexistent?  JON GRUBER: Well, then what would happen, if their  marginal costs were very low or nonexistent.  Think of that marginal cost curve then as ", "being much, much flatter.  It would intersect demand at a much higher quantity.  Or it'd intersect marginal revenue at a  somewhat higher quantity.  Not that much higher. ", "So if marginal cost is very low, they produce more but  they make even more profits.  So it's a good question actually, a good comparative  statics exercise.  You bring that marginal cost curve down,  what's going to happen?  Quantity is going to go up, but not as quickly as profits ", "are going to go up.  That's why Bill Gates is the richest man in the world.  That's what happens.  You get really rich.  So basically, when you're a monopoly, low marginal cost  you get really rich. ", " But that's a great thought exercise to understand how  this monopoly example works.  Other questions about that?  So this is a good opportunity to introduce an important ", "concept with monopolists, the concept of market power.  What monopolists have, what Bill Gates has that my local  McDonald's does not is market power. ", "Or what he had, has less of now, is market power.  Market power is the ability to charge price above marginal ", "cost. The summary statistic of how much power a monopolist  has is how much they can drive their price above marginal  cost.  When Bill Gates marginal cost dwindles to 0, his market ", "power gets bigger.  Price above marginal cost.  Now to think about this, remember the condition for  profit maximization.  It was that marginal revenue, which we wrote as p times 1 ", "plus 1 over epsilon equals marginal cost. So we can  rewrite this as marginal cost over price equals 1 plus 1 ", "over epsilon.   Now let's define the markup.  Let's define the markup as price minus marginal cost, how ", "much money you make on the next unit.  You sell for p, you get marginal cost. It's money you  make the next unit.  If you define the markup, p minus MC over p, that's the  percentage markup. ", "It's how much you make on the next unit,  the percentage markup.  Then you can see that that markup equals  minus 1 over epsilon. ", "So the markup for a monopoly firm equals  minus 1 over epsilon.  This comes to the question before about the insulin  example's sort of confusing.  Here we see your intuition on insulin.  The lower its elasticity, the more the monopolists can mark ", "up their price.  So your intuition is shown here.  Yes, the monopolist will charge an  incredible price for insulin.  They'll still lose a lot of money if they try to raise  that price, if they try to sell one more unit. ", "But the first initial price they'll set will  be incredibly high.  Basically, what is the constraint on Bill Gates?  What is the constraint on Bill Gates? ", "It's Steve Jobs.  It's substitutes.  The only constraint on a monopolist is the extent to  which people can sub--  actually, let me go back, that's not a good example. ", "Let's [UNINTELLIGIBLE]  Bill Gates circa 10 years ago.  The constraint on Bill Gates circa 10 years ago was a  mainframe or some other form of doing a set of-- ", "or 20 years ago it was a typewriter.  It was basically the fact that there was some other way to do  what Bill Gates was letting you do.  If there was no other way to do what Bill Gates was letting ", "you do, he would charge an infinite price.  Clearly if there's some other way--  and also, elasticity of course, comes from substitutes  or one substitute is just not to compute. ", "So if Bill Gates tried to charge infinity for Windows,  people just wouldn't own computers.  So the reason Bill Gates can't charge infinity, and the  reason he can't charge infinity for insulin is that  there's some elasticity of demand. ", "People at some point will just stop buying.  Either because they'll choose to use a typewriter instead or  they just won't compute.  They'll write by hand or something.  So basically at some point, there is some elasticity ", "because there's a market demand curve.  And basically what's going to determine how much market  power the monopolist has is going to be how elastic it is.  Basically, how close the substitutes are for that good. ", "If there's close substitutes, the monopolist won't be able  to charge a very high markup.  If there's not close substitutes as of Window circa  10 years ago, the monopolist can charge a very high markup ", "and become very, very rich.  Yeah.  AUDIENCE: But if there are substitutes for the market,  then it's not a monopoly anymore.  JON GRUBER: No, no, this is the key thing. ", "Substitutes for that producer.  So basically, that's why I said Steve Jobs  is not a good example.  Because then it's not a monopoly anymore.  But the typewriter is a good example.  That's a different good, that's a different market, ", "different good that substitutes.  So my point is any given good, insulin being an exception,  but any good there's always something you can do instead.  Insulin there is something you can do  instead, you can be sick. ", "There's always something you can do instead.  We don't have only one thing in life.  So the elasticity of demand is never perfectly inelastic.  ", "It seems silly 10 years ago, but 20 years ago it actually  was a legitimate decision whether to have a PC or not.  A lot of people just didn't have computers.  You could always just not have one.  That gives you inelasticity of demand. ", "So basically, it's important to recognize when we talk  about substitutes, I'm talking about here not substitutes  within the market, but substitutable activities,  other things you could do with your money. ", "And the more other things are you could do with your money,  the less markup that Bill Gates can make on his Windows  operating system.  Questions about that? ", "OK, now we can ask, OK, gee, John, this is all good and  interesting, but why did you just waste the last lecture  and a half teaching us about welfare if you're just going  to go back to producer theory?  Well, the reason is because now we come to what the ", "welfare effects of monopoly.  And ask, what effects do monopoly have on society?  And in fact, we can show you that there's a deadweight loss  on society imposed by monopoly.  To see that, let's go to Figure 14-5. ", "And here we can show the deadweight loss of monopoly.  And here's the same example we were using.  Demand is Q equals 24 minus p. ", "Marginal cost is 2Q.  The cost function is 12 plus Q squared.  So marginal cost is 2Q.  As we saw before, the monopolist chose to sell 6  units at a price of 18. ", "6 units at a price of 18.  The perfectly competitive firm sets demand, which is 24 minus ", "Q, sets price, I'm sorry, equal to marginal cost. Well,  price comes to demand curve as 24 minus Q.  Marginal cost is 2Q. ", "So the perfectly competitive firm sets Q equal to 8.  The perfectly competitive firm sets q equal to 8.  They choose to sell 8 units at a price of 16. ", "So you get the competitive quantity Q sub c is eight and  the competitive price piece p sub c is 16.  That's where graphically demand equals marginal cost.  Or price equals marginal cost. ", "The monopoly firm sells 6 units at a price of 18.  So what is the welfare effects of monopoly?  What we see is we know that the competitive ", "firm maximizes welfare.  We learned that last time.  We know that the best you can do is to sell 8 units at a  price of 16.  What happens when you sell 6 units at a price of 18? ", "What happens is consumer surplus falls from A plus B  plus C. So with perfect competition, consumer surplus ", "is A plus B plus C. With a monopoly, consumer surplus  falls to the area A. So you lose B plus C with monopoly. ", "Producer surplus under perfect competition was the area D  plus E. Now under a monopolist, the producer ", "surplus is equal to D plus E plus B. The monopolist , in ", "this case, gained the rectangle B, but gave up the  rectangle E. The consumer lost the rectangle B, that was a  transfer to the monopolist. So there was a transfer of the ", "rectangle B from the consumer to the monopolist. But C plus  E have disappeared.  They're a deadweight loss.  They're deadweight loss because in the perfectly ", "competitive equilibrium these are trades that would have  made both parties better off.  That is, these are trades which socially should happen.  They are trades where the value to the consumer exceeds ", "the cost of producing that unit.  Those seventh and eighth units are units--  so take the seventh unit.  What's that worth to someone?  Well, it's worth 17. ", "We can read that off the demand curve.  That's a willingness to pay curve.  People are willing to pay 17 for that seventh unit.  What's it cost to produce?  It cost 14.  So you have a unit which people want more than it costs ", "to produce, yet it's not getting sold.  That's deadweight loss.  So monopolists induce deadweight loss because units  that people value above their marginal  cost doesn't get sold. ", " Units people value above their marginal cost don't get sold.  And that's because this poisoning effect. ", "Because while it's socially optimal to sell those units,  while society is better off, it's privately sub-optimal.  From the monopolist's perspective, it's bad to sell  that unit because of this poisoning effect. ", "So basically, the monopolist is underselling,  underproducing.  In general, monopolists will underproduce goods.  They'll sell too few goods because to sell the right  amount would not be profit maximizing. ", "Because remember, what's the profits for the perfectly  competitive firm?  Profits for the perfectly competitive firm?  Well, we know the profits of perfectly competitive firm.  We know cost if they sell 8 units. ", "We know the cost function is, the cost here  is 12 plus Q squared.  So if they sell 8 units, their costs are 12 plus 64, ", "which equals 76.  Their revenues if they sell 8 units are 8 units times the  price of 16. ", "8 units time the price of 16, which is 128.  So what are their profits?  Their profits are 52. ", "So their profits are 52.  The monopolist's profits are 60.  So the monopolist is better off than the  competitive firm would be.  The competitive firm would only make profits of 52. ", "Obviously the short run.  The long run they make no profits.  But in the short run they make profits of 52.  The monopolist makes profits of 60.  So the monopolist is better off than the competitive firm. ", "The difference of course, is to do so they cause a social  deadweight loss.  Questions about that?  Yeah.  AUDIENCE: Is that what the OPEC is doing right now? ", "JON GRUBER: I'm going to come to that actually.  Time out on that.  Because OPEC is more of an oligopoly.  And we'll come to that when we talk about that  in a couple of lectures.  But I want to talk about one more thing before we stop,  which is I want to talk about the key assumption we made ", "here, which was the monopolist could only charge  one price to everyone.  In fact, we know that's not true.  In fact, we know in the world, there's a large amount of what ", "we call price discrimination.  There's a large amount of price discrimination.  We know that for many goods, different prices get charged  to different consumers.  If you ever tried to book an airline ticket the last ", "minute, you know exactly what I mean.  Basically, different prices in many, many contexts get  charged different consumers.  Everything from discounts for senior citizens, to higher ", "price last-minute flights, to  specials, two for one specials.  People who buy two get a special price on  the third, et cetera.  There's all sorts of price discrimination just out there ", "in the world.  And in fact, there's very few goods that are  sold at just one price.  McDonald's hamburger is typically  sold at just one price.  They don't say like, fat people got to pay more for ", "McDonald's hamburgers or something.  But many, many goods we buy in the real world are sold at  many prices.  And that's an example of a price-discriminating firm. ", "And here's the crazy part.  Here's the crazy part.  It turns out that a price-discriminating  monopolist maximizes social welfare.  A price-discriminating monopolist is as good as a ", "competitive outcome.  How can that be?  Let's go to Figure 14-6.  Here's the price-discriminating  monopolist. Now, the price-discriminating ", "monopolist, what does he do?  This is a perfectly price-discriminating  monopolist, someone who can charge a different price to  every single consumer.  Well, if you were a price-discriminating ", "monopolist, perfectly price-discriminating  monopolist and you could charge a different price to  every consumer, what do you charge the first consumer?  ", "24.  What do you charge the second consumer?  23.  Third consumer, 22.  You literally charge them their willingness to pay.  If you're perfectly price-discriminating, then ", "what you do is literally charge every consumer exactly  their willingness to pay.  You say look, I know your willingness to pay function.   Your willingness pay function is p is 24 minus Q. That's ", "your willingness to pay function.  So I'm going to literally charge you that.  I know that about you, it's stamped on your head.  So I'm going to say, ah, you're willing to pay 24 for ", "the first unit, 23 for the second, et cetera.  In that case, what will the perfectly price-discriminating  monopolist do?  Will they stop at 6 units? ", "No, they won't.  Because for that guy, there's no poisoning effect.  There's no reason to stop at 6 units.  That seventh unit, as we just did the math, there's money to  be made on that seventh unit. ", "Because that seventh unit is worth 17, but it only costs 14  to produce.  So the perfectly discriminating monopolist will  sell it at 17.  Likewise the eighth unit, people willing to pay 16 and ", "it cost 16 to produce.  So they'll sell it or not.  They're basically indifferent.  So we typically say they'll sell it.  The point is, the perfectly price-discriminating  monopolist will work all the way down the demand curve to ", "the competitive outcome.  They will move to the competitive market outcome  because there's no poisoning effect.  There's no reason not to. ", "No reason not to sell as many units.  No reason not to climb the same hill the competitive firm  climbs and sell any unit where the price exceeds the marginal  cost. ", "Well, what's interesting is let's ask what's happened to  social welfare with this perfectly price-discriminating  monopolist. Well, consumer surplus is what? ", "What's consumer surplus with the perfectly  price-discriminating monopolist?  Somebody raised their hand.  Yeah.  AUDIENCE: Zero.  JON GRUBER: Zero.  Why is it zero?  AUDIENCE: Because they're charged exactly  how the value is.  JON GRUBER: Exactly.  Consumer surplus is defined as willingness ", "to pay minus price.  But your price is set equal to your willingness to pay.  So by definition, consumer surplus is 0.  With a perfectly price-discriminating  monopolist, there's no consumer surplus.  But what's producer surplus? ", "Same person, what's producer surplus?  AUDIENCE: Everything else.  JON GRUBER: Everything else.  A plus B plus C plus D plus E. There's no deadweight loss.  You get exactly the same social welfare as you got with ", "perfect competition.  It's just divided differently.  With perfect competition, consumers got A plus B plus C.  Producers got D plus E.  With a perfectly price-discriminating ", "monopolist, the monopolist gets everything.  But the total shaded area is the same.  So really fascinating because here we have the ultimate ", "screw on consumers.  We think about competition as being the  best thing for consumers.  Lots of firms selling goods at a competitive market where you  can shop and do what's best for you.  It's not surprising intuitively that that's the ", "best thing for society.   What's very surprising intuitively is having a  producer who can screw every single consumer out of every  penny they value something is equally good for society. ", "And why is that?  That's because we've made a particular assumption, which  is social welfare is the sum of producer surplus and  consumer surplus.  The linear sum.  Since it's is sum, we don't care in that function who gets ", "the dollars.  We just care about the total amount of dollars, the total  size of the pie.  We don't care who gets what slice of the pie, we just care  about the total size of the pie.  And the total size of the pie is the same with a perfectly ", "price-discriminating monopolist and  a competitive firm.  What this highlights is that that's a pretty stupid way to  think about social welfare.  Clearly, we don't feel the same way about a market where ", "people get everything they want and a  market where people--  all they're willing to pay is sucked out of them by a greedy  monopolist. Clearly we don't.  And that's why we're going to need to think more richly  about equity and think more richly about the division of ", "resources in society.  Because it turns out that you can have equally good outcomes  from an efficiency perspective that are very, very different  from an equity perspective. ", "And this is the first example we'll see of that.  What we'll do when we get towards the end of the course  lectures, like 23, 24, lectures like that, we're  going to start talking about equity. ", "And what are different rules we can think of for dividing  this pie that might give us a different answer?  OK, questions about that?  All right.  ", "OK, so anyway, we'll stop here then.  Let's remember that perfectly price-discriminating  monopolist is obviously also a silly concept just like a  perfectly competitive firm's a silly concept.  What we're going to do next time is come back and talk ", "about price discrimination in reality and what firms do to  try to approximate this golden outcome.  "], "vid_duration": [11.31, 10.28, 10.49, 10.37, 10.73, 11.71, 10.19, 12.1, 10.55, 11.4, 11.99, 12.73, 11.54, 10.7, 11.45, 11.45, 10.35, 12.13, 13.2, 10.62, 10.63, 11.14, 11.37, 13.66, 10.57, 11.5, 13.56, 12.02, 10.69, 10.47, 11.79, 10.36, 10.98, 11.05, 10.03, 10.94, 11.26, 11.15, 10.06, 12.38, 13.19, 11.26, 10.4, 10.1, 12.23, 14.28, 13.23, 14.96, 11.09, 15.31, 13.35, 11.56, 10.59, 11.25, 10.27, 10.82, 11.33, 11.77, 10.05, 10.95, 11.13, 10.24, 10.77, 13.86, 10.34, 11.36, 10.29, 10.37, 11.62, 11.98, 14.52, 12.41, 12.16, 14.05, 10.07, 10.49, 10.29, 12.19, 11.83, 13.39, 15.99, 11.16, 10.29, 13.03, 13.35, 10.14, 12.26, 13.48, 11.07, 11.069, 10.731, 11.48, 13.79, 11.18, 12.1, 10.21, 12.91, 12.19, 14.16, 10.062, 11.678, 13.54, 11.15, 11.05, 11.39, 14.47, 11.79, 11.34, 12.13, 11.36, 10.3, 11.01, 12.19, 11.3, 11.89, 10.35, 10.69, 10.76, 10.29, 12.43, 10.32, 17.98, 12.84, 12.04, 11.15, 12.11, 10.47, 13.61, 10.34, 11.05, 12.08, 10.325, 10.345, 11.3, 12.07, 11.96, 11.73, 11.33, 11.56, 12.08, 10.67, 12.16, 11.96, 11.5, 11.07, 12.2, 10.64, 10.87, 14.06, 10.18, 10.86, 13.26, 12.3, 11.63, 10.31, 10.21, 13.73, 11.65, 10.08, 10.94, 10.67, 10.03, 10.56, 10.48, 10.05, 11.43, 10.82, 10.17, 11.57, 10.58, 10.11, 11.27, 11.25, 10.62, 11.46, 13.609, 10.83, 13.971, 10.96, 11.41, 11.02, 13.11, 10.64, 12.18, 14.99, 13.56, 11.18, 14.55, 12.12, 10.07, 10.82, 11.31, 12.83, 10.73, 10.24, 12.44, 12.19, 11.69, 11.15, 12.08, 11.04, 11.56, 11.11, 11.43, 11.01, 12.0, 10.33, 11.23, 10.88, 11.5, 10.76, 12.11, 11.69, 11.06, 10.11, 12.11, 16.9, 11.29, 11.29, 10.35, 12.23, 12.66, 11.18, 11.39, 11.31, 12.23, 10.57, 14.79, 10.29, 10.83, 11.9, 13.81, 11.56, 11.04, 12.93, 11.07, 11.12, 10.83, 13.15, 11.71, 4.94], "stet": [[0, 11.31], [11.31, 21.59], [21.59, 32.08], [32.08, 42.449999999999996], [42.449999999999996, 53.17999999999999], [53.17999999999999, 64.88999999999999], [64.88999999999999, 75.07999999999998], [75.07999999999998, 87.17999999999998], [87.17999999999998, 97.72999999999998], [97.72999999999998, 109.12999999999998], [109.12999999999998, 121.11999999999998], [121.11999999999998, 133.84999999999997], [133.84999999999997, 145.38999999999996], [145.38999999999996, 156.08999999999995], [156.08999999999995, 167.53999999999994], [167.53999999999994, 178.98999999999992], [178.98999999999992, 189.33999999999992], [189.33999999999992, 201.4699999999999], [201.4699999999999, 214.6699999999999], [214.6699999999999, 225.2899999999999], [225.2899999999999, 235.9199999999999], [235.9199999999999, 247.0599999999999], [247.0599999999999, 258.4299999999999], [258.4299999999999, 272.0899999999999], [272.0899999999999, 282.6599999999999], [282.6599999999999, 294.1599999999999], [294.1599999999999, 307.7199999999999], [307.7199999999999, 319.7399999999999], [319.7399999999999, 330.4299999999999], [330.4299999999999, 340.8999999999999], [340.8999999999999, 352.68999999999994], [352.68999999999994, 363.04999999999995], [363.04999999999995, 374.03], [374.03, 385.08], [385.08, 395.10999999999996], [395.10999999999996, 406.04999999999995], [406.04999999999995, 417.30999999999995], [417.30999999999995, 428.4599999999999], [428.4599999999999, 438.5199999999999], [438.5199999999999, 450.8999999999999], [450.8999999999999, 464.0899999999999], [464.0899999999999, 475.3499999999999], [475.3499999999999, 485.7499999999999], [485.7499999999999, 495.8499999999999], [495.8499999999999, 508.0799999999999], [508.0799999999999, 522.3599999999999], [522.3599999999999, 535.5899999999999], [535.5899999999999, 550.55], [550.55, 561.64], [561.64, 576.9499999999999], [576.9499999999999, 590.3], [590.3, 601.8599999999999], [601.8599999999999, 612.4499999999999], [612.4499999999999, 623.6999999999999], [623.6999999999999, 633.9699999999999], [633.9699999999999, 644.79], [644.79, 656.12], [656.12, 667.89], [667.89, 677.9399999999999], [677.9399999999999, 688.89], [688.89, 700.02], [700.02, 710.26], [710.26, 721.03], [721.03, 734.89], [734.89, 745.23], [745.23, 756.59], [756.59, 766.88], [766.88, 777.25], [777.25, 788.87], [788.87, 800.85], [800.85, 815.37], [815.37, 827.78], [827.78, 839.9399999999999], [839.9399999999999, 853.9899999999999], [853.9899999999999, 864.06], [864.06, 874.55], [874.55, 884.8399999999999], [884.8399999999999, 897.03], [897.03, 908.86], [908.86, 922.25], [922.25, 938.24], [938.24, 949.4], [949.4, 959.6899999999999], [959.6899999999999, 972.7199999999999], [972.7199999999999, 986.0699999999999], [986.0699999999999, 996.2099999999999], [996.2099999999999, 1008.4699999999999], [1008.4699999999999, 1021.9499999999999], [1021.9499999999999, 1033.02], [1033.02, 1044.089], [1044.089, 1054.82], [1054.82, 1066.3], [1066.3, 1080.09], [1080.09, 1091.27], [1091.27, 1103.37], [1103.37, 1113.58], [1113.58, 1126.49], [1126.49, 1138.68], [1138.68, 1152.8400000000001], [1152.8400000000001, 1162.902], [1162.902, 1174.5800000000002], [1174.5800000000002, 1188.1200000000001], [1188.1200000000001, 1199.2700000000002], [1199.2700000000002, 1210.3200000000002], [1210.3200000000002, 1221.7100000000003], [1221.7100000000003, 1236.1800000000003], [1236.1800000000003, 1247.9700000000003], [1247.9700000000003, 1259.3100000000002], [1259.3100000000002, 1271.4400000000003], [1271.4400000000003, 1282.8000000000002], [1282.8000000000002, 1293.1000000000001], [1293.1000000000001, 1304.1100000000001], [1304.1100000000001, 1316.3000000000002], [1316.3000000000002, 1327.6000000000001], [1327.6000000000001, 1339.4900000000002], [1339.4900000000002, 1349.8400000000001], [1349.8400000000001, 1360.5300000000002], [1360.5300000000002, 1371.2900000000002], [1371.2900000000002, 1381.5800000000002], [1381.5800000000002, 1394.0100000000002], [1394.0100000000002, 1404.3300000000002], [1404.3300000000002, 1422.3100000000002], [1422.3100000000002, 1435.15], [1435.15, 1447.19], [1447.19, 1458.3400000000001], [1458.3400000000001, 1470.45], [1470.45, 1480.92], [1480.92, 1494.53], [1494.53, 1504.87], [1504.87, 1515.9199999999998], [1515.9199999999998, 1527.9999999999998], [1527.9999999999998, 1538.3249999999998], [1538.3249999999998, 1548.6699999999998], [1548.6699999999998, 1559.9699999999998], [1559.9699999999998, 1572.0399999999997], [1572.0399999999997, 1583.9999999999998], [1583.9999999999998, 1595.7299999999998], [1595.7299999999998, 1607.0599999999997], [1607.0599999999997, 1618.6199999999997], [1618.6199999999997, 1630.6999999999996], [1630.6999999999996, 1641.3699999999997], [1641.3699999999997, 1653.5299999999997], [1653.5299999999997, 1665.4899999999998], [1665.4899999999998, 1676.9899999999998], [1676.9899999999998, 1688.0599999999997], [1688.0599999999997, 1700.2599999999998], [1700.2599999999998, 1710.8999999999999], [1710.8999999999999, 1721.7699999999998], [1721.7699999999998, 1735.8299999999997], [1735.8299999999997, 1746.0099999999998], [1746.0099999999998, 1756.8699999999997], [1756.8699999999997, 1770.1299999999997], [1770.1299999999997, 1782.4299999999996], [1782.4299999999996, 1794.0599999999997], [1794.0599999999997, 1804.3699999999997], [1804.3699999999997, 1814.5799999999997], [1814.5799999999997, 1828.3099999999997], [1828.3099999999997, 1839.9599999999998], [1839.9599999999998, 1850.0399999999997], [1850.0399999999997, 1860.9799999999998], [1860.9799999999998, 1871.6499999999999], [1871.6499999999999, 1881.6799999999998], [1881.6799999999998, 1892.2399999999998], [1892.2399999999998, 1902.7199999999998], [1902.7199999999998, 1912.7699999999998], [1912.7699999999998, 1924.1999999999998], [1924.1999999999998, 1935.0199999999998], [1935.0199999999998, 1945.1899999999998], [1945.1899999999998, 1956.7599999999998], [1956.7599999999998, 1967.3399999999997], [1967.3399999999997, 1977.4499999999996], [1977.4499999999996, 1988.7199999999996], [1988.7199999999996, 1999.9699999999996], [1999.9699999999996, 2010.5899999999995], [2010.5899999999995, 2022.0499999999995], [2022.0499999999995, 2035.6589999999994], [2035.6589999999994, 2046.4889999999994], [2046.4889999999994, 2060.459999999999], [2060.459999999999, 2071.419999999999], [2071.419999999999, 2082.829999999999], [2082.829999999999, 2093.849999999999], [2093.849999999999, 2106.959999999999], [2106.959999999999, 2117.599999999999], [2117.599999999999, 2129.779999999999], [2129.779999999999, 2144.7699999999986], [2144.7699999999986, 2158.3299999999986], [2158.3299999999986, 2169.5099999999984], [2169.5099999999984, 2184.0599999999986], [2184.0599999999986, 2196.1799999999985], [2196.1799999999985, 2206.2499999999986], [2206.2499999999986, 2217.069999999999], [2217.069999999999, 2228.3799999999987], [2228.3799999999987, 2241.2099999999987], [2241.2099999999987, 2251.9399999999987], [2251.9399999999987, 2262.1799999999985], [2262.1799999999985, 2274.6199999999985], [2274.6199999999985, 2286.8099999999986], [2286.8099999999986, 2298.4999999999986], [2298.4999999999986, 2309.6499999999987], [2309.6499999999987, 2321.7299999999987], [2321.7299999999987, 2332.7699999999986], [2332.7699999999986, 2344.3299999999986], [2344.3299999999986, 2355.4399999999987], [2355.4399999999987, 2366.8699999999985], [2366.8699999999985, 2377.8799999999987], [2377.8799999999987, 2389.8799999999987], [2389.8799999999987, 2400.2099999999987], [2400.2099999999987, 2411.4399999999987], [2411.4399999999987, 2422.319999999999], [2422.319999999999, 2433.819999999999], [2433.819999999999, 2444.579999999999], [2444.579999999999, 2456.689999999999], [2456.689999999999, 2468.379999999999], [2468.379999999999, 2479.439999999999], [2479.439999999999, 2489.5499999999993], [2489.5499999999993, 2501.6599999999994], [2501.6599999999994, 2518.5599999999995], [2518.5599999999995, 2529.8499999999995], [2529.8499999999995, 2541.1399999999994], [2541.1399999999994, 2551.4899999999993], [2551.4899999999993, 2563.7199999999993], [2563.7199999999993, 2576.379999999999], [2576.379999999999, 2587.559999999999], [2587.559999999999, 2598.949999999999], [2598.949999999999, 2610.259999999999], [2610.259999999999, 2622.489999999999], [2622.489999999999, 2633.059999999999], [2633.059999999999, 2647.849999999999], [2647.849999999999, 2658.139999999999], [2658.139999999999, 2668.969999999999], [2668.969999999999, 2680.869999999999], [2680.869999999999, 2694.679999999999], [2694.679999999999, 2706.239999999999], [2706.239999999999, 2717.279999999999], [2717.279999999999, 2730.2099999999987], [2730.2099999999987, 2741.279999999999], [2741.279999999999, 2752.3999999999987], [2752.3999999999987, 2763.2299999999987], [2763.2299999999987, 2776.3799999999987], [2776.3799999999987, 2788.089999999999], [2788.089999999999, 2793.029999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [894, 1237, 1719, 2010, 2374, 2793]}
{"example_id": "mit088@@MIT6_004S17_01-02_300k", "text": ["In order to build circuits to manipulate,  transmit or store information, we are going to need some  engineering tools to see if we're choosing a good  representation for the information -- ", "that's the subject of this chapter.  We'll study different ways of encoding information as bits  and learn the mathematics that help us determine  if our encoding is a good one. ", "We'll also look into what we can do if our representation gets  corrupted by errors.  It would be nice to detect that something bad has happened  and possibly even correct the problem. ", "Let's start by asking \"what is information?\"  From our engineering perspective,  we'll define information as data communicated or received  that resolves uncertainty about a particular fact ", "or circumstance.  In other words, after receiving the data  we'll know more about that particular fact  or circumstance.  The greater the uncertainty resolved by the data, ", "the more information the data has conveyed.   LET'S LOOK AT AN EXAMPLE: a card has  been chosen at random from a normal deck of 52  playing cards.  Without any data about the chosen card, ", "there are 52 possibilities for the type of the card.  Now suppose you receive one of the following pieces of data  about the choice.  A. You learn the suit of the card is \"heart\". ", "This narrows the choice to down one of 13 cards.  B. You learn instead the card is NOT the Ace of Spades.  This still leaves 51 cards that it might be. ", "C. You learn instead that the card is a face card, that  is, a Jack, Queen or King.  So the choice is one of 12 cards.  D. You learn instead that the card is the \"suicide king.\" ", "Our little blue friend is showing us that this is  actually a particular card ‚Äì the King of Hearts where the king  is sticking the sword through his head!  No uncertainty here, we know exactly what the choice was. ", "Which of the possible pieces of data  conveys the most information?  In other words, which data resolves the most uncertainty  about the chosen card?  Similarly, which data conveys the least ", "amount of information?  Before we talk about the mathematics  behind the correct answers to these questions,  vote for your answers in the following poll.   Mathematicians like to model uncertainty ", "about a particular circumstance by introducing the concept  of a random variable.  For our application, we'll always  be dealing with circumstances where there are a finite number  N of distinct choices, so we'll be ", "using a discrete random variable that  can take on one of N possible values:  x_1, x_2, and so on up to x_N.  The probability that X will take on the value x_1 ", "is given by the probability p_1, the value  x_2 by probability p_2, and so on.  The smaller the probability, the more uncertain ", "it is that X will take on that particular value.  Claude Shannon, in his seminal work on the theory  of information, defined the information received when  learning that X had taken on the value x_i as the log-base-2 ", "of 1/p_i.  Note that uncertainty of a choice  is inversely proportional to its probability,  so the term inside of the log is basically the uncertainty  of that particular choice. ", "We use the log-base-2 to measure the magnitude  of the uncertainty in bits -- where a bit is a quantity that  can take on the value 0 or 1 -- think of the information  content as the number of bits we would require to encode this ", "choice.  Suppose the data we receive doesn't  resolve all the uncertainty.  For example, when earlier we received the data  that the card was a heart: some of uncertainty ", "has been resolved since we know more about the card  than we did before the receiving the data,  but we don't yet know the exact card,  so some uncertainty still remains.  We can still use the formula for information content ", "from the previous slide, using the probability  we received to compute the information content.  In our example the probability of learning  that a card chosen randomly from a 52-card deck is a heart ", "is 13/52, the number of hearts over the total number  of choices.  So p_data is 13/52, or 1/4 and the information content is ", "computed as log-base-2 of 1/(1/4),  which figures out to be 2 bits.  This example is one we encounter often --  we receive partial information about N equally-probable ", "choices (each choice has probability 1/N) that narrows  the number of choices down to M.  The probability of receiving such information is M*(1/N), ", "so information received is log-base-2 of N/M bits.  Let's look at some examples.  If we learn the result (HEADS or TAILS) ", "of a flip of a fair coin, we go from 2 choices  to a single choice.  So the information received is log-base-2 of 2/1,  or a single bit.  This makes sense: it would take us ", "one bit to encode which of the two possibilities  actually happened, say, \"1\" for heads and \"0\" for tails.  Reviewing the example from the previous slide:  learning that a card drawn from a fresh deck is a heart ", "gives us log-base-2 of 52/13, or 2 bits of information.  Again this makes sense: it would take us  two bits to encode which of four possible card suits ", "had turned up.  Finally consider what information  we get from rolling two dice, one red and one green.  Each die has six faces, so there are 36 possible combinations. ", "Once we learn the exact outcome of the roll,  we've received log-base-2 of 36/1 or 5.17 bits  of information.  Hmm.  What do those fractional bits mean? ", "Our circuitry will only deal with whole bits!  So to encode a single outcome, we'd need to use six bits.  But suppose we wanted to record the outcome of 10  successive rolls. ", "At 6 bits per roll, we would need a total of 60 bits.  What this formula is telling us is  that we would need not 60 bits, but only  52 bits to unambiguously encode the results. ", "Whether we can come with an encoding that  achieves this lower bound is an interesting question,  which we will take up later in the chapter.  To wrap up, let's return to our initial example. ", "Here's table showing the different choices for the data  received, along with the probability  of that event and the computed information content.  We've already talked about learning ", "that the card was a heart.  The probability of this event is 13/52 with an information  content of 2 bits.  Learning that a card is not the Ace of spades ", "is quite likely, since there's only one chance in 52  that it is the Ace of spades.  So we only get a small amount of information from this event --  .028 bits. ", "There twelve face cards in a card deck,  so the probability of this event is 12/52  and we would receive 2.115 bits.  A bit more information than learning about the card's suit ", "since there's slightly less residual uncertainty.  Finally, we get the most information when all  uncertainty is eliminated -- a bit more than 5.7 bits.  The results line up nicely with our and Mr. Blue's intuition: ", "the more uncertainty is resolved, the more information  we have received.  Now try your hand at computing the information for a few  ", "In the next section we're going to start our discussion on how to actually engineer the  bit encodings we'll use in our circuitry, but first we'll need a way to evaluate the  efficacy of an encoding. ", "The entropy of a random variable is average amount of information received when learning  the value of the random variable.  The mathematician's name for \"average\" is \"expected value\"; that's what the capital ", "E means.  We compute the average in the obvious way: we take the weighted sum, where the amount  of information received when learning of particular choice i -- that's the log-base-2 of 1/p_i ", "-- is weighted by the probability of that choice actually happening.  Here's an example.  We have a random variable that can take on one of four values: A, B, C or D. ", "The probabilities of each choice are shown in the table, along with the associated information  content.  Now we'll compute the entropy using the probabilities and information content. ", "So we have the probability of A (1/3) times its associated information content (1.58 bits),  plus the probability of B times its associated information content, and so on. ", "The result is 1.626 bits.  This is telling us that a clever encoding scheme should be able to do better than simply  encoding each symbol using 2 bits to represent which of the four possible values is next. ", "Food for thought!  We'll discuss this further in the third section of this chapter.  So, what is the entropy telling us? ", "Suppose we have a sequence of data describing a sequence of values of the random variable  X.  If, on the average, we use less than H(X) bits to transmit each piece of information ", "in the sequence, we will not be sending enough information to resolve the uncertainty about  the values.  In other words, the entropy is a lower bound on the number of bits we need to transmit. ", "Getting less than this number of bits wouldn't be good if the goal was to unambiguously describe  the sequence of values -- we'd have failed at our job!  On the other hand, if we send, on the average, more than H(X) bits to describe the sequence ", "of values, we will not be making the most effective use of our resources, since the  same information might have been able to be represented with fewer bits.  This is okay, but perhaps with some insights we could do better. ", "Finally, if we send, on the average, exactly H(X) bits, then we'd have the perfect encoding.  Alas, perfection is, as always, a tough goal, so most of the time we'll have to settle for ", "getting close.  In the final set of exercises for this section, try computing the entropy for various scenarios.   Next we turn our attention to encoding data as sequences of 0's and 1's, a string of bits. ", "An encoding is an unambiguous mapping between bit strings and the members of the set of  data to be encoded.  For example, suppose we have a set of four symbols -- A, B, C, and D ‚Äì and we want ", "to use bit strings to encode messages constructed of these symbols, for example \"ABBA\".  If we choose to encode the message one character at a time, our encoding would assign a unique ", "bit string to each symbol.  Since we have four symbols, we might choose a unique two-bit string for each: \"A\" could  be \"00\", B = \"01\", C = \"10\", and D = \"11\". ", "This would be called a \"fixed-length encoding\" since the bit strings used to represent the  symbols all have the same length.  The encoding for the message \"ABBA\" would be \"00-01-01-00\". ", "And we can run the process backwards: given a bit string and the encoding key, we can  look up the next bits in the bit string, using the key to determine the symbol they represent. ", "\"00\" would be decoded as \"A\", \"01\" as B and so on.  We can also use bit strings of different lengths to encode symbols -- this is called a variable-length ", "encoding.  So A could be \"01\", B = \"1\", C = \"000\" and D = \"001\".  \"ABBA\" would be encoded as \"01-1-1-01\". ", "We'll see that carefully constructed variable-length encodings are useful for the efficient encoding  of messages where the symbols occur with different probabilities.  We have to be careful that the encoding is unambiguous! ", "Suppose we had decided to encode A as \"0\", B as \"1\", C as \"10\" and D as \"11\".  The encoding for \"ABBA\" would be \"0-1-1-0\". ", "Looking good since that encoding is shorter than either of the previous two encodings.  Now let's try to decode this bit string -- oops.  Using the encoding key, we can unfortunately arrive at several decodings: \"ABBA\" of course, ", "but also \"ADA\" or \"ABC\" depending on how we group the bits.  This attempt at specifying an encoding has failed since the message cannot be interpreted  unambiguously. ", "Graphically we can represent an unambiguous encoding as a binary tree, labeling the branches  from each tree node with \"0\" and \"1\", placing the symbols to be encoded as the leaves of ", "the tree.  If you build a binary tree for a proposed encoding and find that there are no symbols  labeling interior nodes and exactly one symbol at each leaf, then your encoding is good to ", "go!  For example, consider the encoding shown on the left.  It takes just a second to draw the corresponding binary tree.  The symbol B is distance 1 from the root of the tree, along an arc labeled \"0\". ", "A is distance two, and C and D are distance 3.  If we receive an encoded message, for example \"01111\", we can decode it using successive ", "bits of the encoding to identify a path from the root of tree, descending step-by-step  until we come to leaf, then repeating the process starting at the root again, until  all the bits in the encoded message have been consumed. ", "So the message from the sheep is: \"0\" takes us from the root to the leaf B, which is our  first decoded symbol.  Then \"1-1\" takes us to A and the next \"1-1\" results in a second A. ", "The final decoded message -- \"BAA\" -- is not totally unexpected, at least from an American  sheep.   If the symbols we are trying to encode occur with equal probability (or if we have no a ", "priori reason to believe otherwise), then we'll use a fixed-length encoding, where all  leaves in the encoding's binary tree are the same distance from the root. ", "Fixed-length encodings have the advantage of supporting random access, where we can  figure out the Nth symbol of the message by simply skipping over the required number of  bits.  For example, in a message encoded using the fixed-length code shown here, if we wanted ", "to determine the third symbol in the encoded message, we would skip the 4 bits used to  encode the first two symbols and start decoding with the 5th bit of message. ", "Mr. Blue is telling us about the entropy for random variables that have N equally-probable  outcomes.  In this case, each element of the sum in the entropy formula is simply (1/N)*log2(N), and, ", "since there are N elements in the sequence, the resulting entropy is just log2(N).  Let's look at some simple examples.  In binary-coded decimal, each digit of a decimal number is encoded separately. ", "Since there are 10 different decimal digits, we'll need to use a 4-bit code to represent  the 10 possible choices.  The associated entropy is log2(10), which is 3.322 bits. ", "We can see that our chosen encoding is inefficient in the sense that we'd use more than the minimum  number of bits necessary to encode, say, a number with 1000 decimal digits: our encoding ", "would use 4000 bits, although the entropy suggests we *might* be able to find a shorter  encoding, say, 3400 bits, for messages of length 1000. ", "Another common encoding is ASCII, the code used to represent English text in computing  and communication.  ASCII has 94 printing characters, so the associated entropy is log2(94) or 6.555 bits, so we would ", "use 7 bits in our fixed-length encoding for each character.  One of the most important encodings is the one we use to represent numbers.  Let's start by thinking about a representation for unsigned integers, numbers starting at ", "0 and counting up from there.  Drawing on our experience with representing decimal numbers, i.e., representing numbers  in \"base 10\" using the 10 decimal digits, our binary representation of numbers will ", "use a \"base 2\" representation using the two binary digits.  The formula for converting an N-bit binary representation of a numeric value into the  corresponding integer is shown below ‚Äì just multiply each binary digit by its corresponding ", "weight in the base-2 representation.  For example, here's a 12-bit binary number, with the weight of each binary digit shown  above.  We can compute its value as 0*2^11 plus 1*2^10 plus 1*2^9, and so on. ", "Keeping only the non-zero terms and expanding the powers-of-two gives us the sum 1024 +  512 + 256 + 128 + 64 + 16 which, expressed in base-10, sums to the number 2000. ", "With this N-bit representation, the smallest number that can be represented is 0 (when  all the binary digits are 0) and the largest number is 2^N ‚Äì 1 (when all the binary digits ", "are 1).  Many digital systems are designed to support operations on binary-encoded numbers of some  fixed size, e.g., choosing a 32-bit or a 64-bit representation, which means that they would ", "need multiple operations when dealing with numbers too large to be represented as a single  32-bit or 64-bit binary string.  Long strings of binary digits are tedious and error-prone to transcribe, so let's find ", "a more convenient notation, ideally one where it will be easy to recover the original bit  string without too many calculations.  A good choice is to use a representation based on a radix that's some higher power of 2, ", "so each digit in our representation corresponds to some short contiguous string of binary  bits.  A popular choice these days is a radix-16 representation, called hexadecimal or \"hex\" ", "for short, where each group of 4 binary digits is represented using a single hex digit.  Since there are 16 possible combinations of 4 binary bits, we'll need 16 hexadecimal \"digits\": ", "we'll borrow the ten digits \"0\" through \"9\" from the decimal representation, and then  simply use the first six letters of the alphabet, \"A\" through \"F\", for the remaining digits. ", "The translation between 4-bit binary and hexadecimal is shown in the table to the left below.  To convert a binary number to \"hex\", group the binary digits into sets of 4, starting ", "with the least-significant bit (that's the bit with weight 2^0).  Then use the table to convert each 4-bit pattern into the corresponding hex digit: \"0000\" is ", "the hex digit \"0\", \"1101\" is the hex digit \"D\", and \"0111\" is the hex digit \"7\".  The resulting hex representation is \"7D0\". ", "To prevent any confusion, we'll use a special prefix \"0x\" to indicate when a number is being  shown in hex, so we'd write \"0x7D0\" as the hex representation for the binary number \"0111 ", "1101 0000\".  This notation convention is used by many programming languages for entering binary bit strings.   Our final challenge is figuring out how to represent signed integers, for example, what ", "should be our representation for the number -2000?  In decimal notation, the convention is to precede the number with a \"+\" or \"-\" to indicate  whether it's positive or negative, usually omitting the \"+\" to simplify the notation ", "for positive numbers. We could adopt a similar notation -- called  \"signed magnitude\" -- in binary, by allocating a separate bit at the front of the binary ", "string to indicate the sign, say \"0\" for positive numbers and \"1\" for negative numbers.  So the signed-magnitude representation for -2000 would be an initial \"1\" to indicate ", "a negative number, followed by the representation for 2000 (as described on the previous two  slides). However there are some complications in using  a signed-magnitude representation. There are two possible binary representations ", "for zero: \"+0\" and \"-0\". This makes the encoding slightly inefficient  but, more importantly, the circuitry for doing addition of signed-magnitude numbers is different ", "than the circuitry for doing subtraction. Of course, we're used to that ‚Äì in elementary  school we learned one technique for addition and another for subtraction. ", "To keep the circuitry simple, most modern digital systems use the two's complement binary  representation for signed numbers. In this representation, the high-order bit ", "of an N-bit two's complement number has a negative weight, as shown in the figure.  Thus all negative numbers have a 1 in the high-order bit and, in that sense, the high-order  bit is serving as the \"sign bit\" ‚Äì if it's 1, the represented number is negative. ", "The most negative N-bit number has a 1-bit in the high-order position, representing the  value -2^(N-1). The most positive N-bit number has a 0 in ", "the negative-weight high-order bit and 1's for all the positive-weight bits, representing  the value 2^(N-1)-1. This gives us the range of possible values ", "‚Äì for example, in an 8-bit two's complement representation, the most negative number is  -2^7 = -128 and the most positive number is 2^7 ‚Äì 1 = 127. ", "If all N bits are 1, think of that as the sum of the most negative number with the most  positive number, i.e., -2^(N-1) + 2^(N-1)-1, which equals -1. ", "And, of course, if all N bits are 0, that's the unique representation of 0.  Let's see what happens when we add the N-bit values for -1 and 1, keeping an N-bit answer. ", "In the rightmost column, 1 plus 1 is 0, carry the 1.  In the second column, the carry of 1 plus 1 plus 0 is 0, carry the 1.  And so on ‚Äì the result is all zero's, the representation for 0‚Ä¶ perfect! ", "Notice that we just used ordinary binary addition, even when one or both of the operands are  negative. Two's complement is perfect for N-bit arithmetic! ", "To compute B - A, we can just use addition and compute B + (-A).  So now we just need to figure out the two's complement representation for ‚ÄìA, given ", "the two's complement representation for A. Well, we know that A + (-A) = 0 and using  the example above, we can rewrite 0 as 1 + (-1). ", "Reorganizing terms, we see that ‚ÄìA equals 1 plus the quantity (-1) ‚Äì A.  As we saw above, the two's complement representation for -1 is all 1-bits, so we can write that ", "subtraction as all 1's minus the individual bits of A: A_0, A_1, ‚Ä¶ up to A_N-1.  If a particular bit A_i is 0, then 1-A_i = 1 and if A_i is 1, then 1-A_i = 0. ", "So in each column, the result is the bitwise complement of A_i, which we'll write using  the C-language bitwise complement operator tilde.  So we see that ‚ÄìA equals the bitwise complement of A plus 1. ", "Ta-dah! To practice your skill with two's complement,  try your hand at the following exercises. All you need to remember is how to do binary   addition and two's complement negation (which is \"bitwise complement and add 1\"). ", " Fixed-length encodings work well when all the possible choices have the same information  content, i.e., all the choices have an equal probability of occurring. ", "If those choices don't have the same information content, we can do better.  To see how, consider the expected length of an encoding, computed by considering each  x_i to be encoded, and weighting the length of its encoding by p_i, the probability of ", "its occurrence.  By \"doing better\" we mean that we can find encodings that have a shorter expected length  than a fixed-length encoding.  Ideally we'd like the expected length of the encoding for the x_i to match the entropy ", "H(X), which is the expected information content.  We know that if x_i has a higher probability (i.e., a larger p_i), that is has a smaller ", "information content, so we'd like to use shorter encodings.  If x_i has a lower probability, then we'd use a longer encoding.  So we'll be constructing encodings where the x_i may have different length codes - we'll ", "call these variable-length encodings.  Here's an example we've seen before.  There are four possible choices to encode (A, B, C, and D), each with the specified ", "probability.  The table shows a suggested encoding where we've followed the advice from the previous  slide: high-probability choices that convey little information (e.g., B) are given shorter ", "encodings, while low-probability choices that convey  more information (e.g., C or D) are given longer encodings.  Let's diagram this encoding as a binary tree. ", "Since the symbols all appear as the leaves of the tree, we can see that the encoding  is unambiguous.  Let's try decoding the following encoded data.  We'll use the tree as follows: start at the root of the tree and use bits from the encoded ", "data to traverse the tree as directed, stopping when we reach a leaf.  Starting at the root, the first encoded bit is 0, which takes us down the left branch  to the leaf B. So B is the first symbol of the decoded data. ", "Starting at the root again, 1 takes us down the right branch, 0 the left branch from there,  and 0 the left branch below that, arriving at the leaf C, the second symbol of the decoded ", "data.  Continuing on: 11 gives us A, 0 decodes as B, 11 gives us A again, and, finally, 101  gives us D. The entire decoded message is \"BCABAD\". ", "The expected length of this encoding is easy to compute: the length of A's encoding (2  bits) times its probability, plus the length of B's encoding (1 bit) times 1/2, plus the ", "contributions for C and D, each 3 times 1/12.  This adds up to 1 and 2/3 bits.  How did we do?  If we had used a fixed-length encoding for our four possible symbols, we'd have needed ", "2 bits each, so we'd need 2000 bits to encode 1000 symbols.  Using our variable-length encoding, the expected length for 1000 symbols would be 1667. ", "The lower bound on the number of bits needed to encode 1000 symbols is 1000 times the entropy  H(X), which is 1626 bits, so the variable-length code got us closer to our goal, but not quite ", "all the way there.  Could another variable-length encoding have done better?  In general, it would be nice to have a systematic way to generate the best-possible variable-length ", "code, and that's the subject of the next video.   Given a set of symbols and their probabilities,  Huffman‚Äôs Algorithm tells us how to construct an optimal ", "variable-length encoding.  By ‚Äúoptimal‚Äù we mean that, assuming we‚Äôre encoding each  symbol one-at-a-time, no other variable-length code will have  a shorter expected length. ", "The algorithm builds the binary tree for the encoding  from the bottom up.  Start by choosing the two symbols with the smallest  probability (which means they have  highest information content and should have the longest ", "encoding).  If anywhere along the way, two symbols  have the same probability, simply choose one arbitrarily.  In our running example, the two symbols with the lowest  probability are C and D. ", "Combine the symbols as a binary subtree,  with one branch labeled ‚Äú0‚Äù and the other ‚Äú1‚Äù.  It doesn‚Äôt matter which labels go with which branch.  Remove C and D from our list of symbols, ", "and replace them with the newly constructed subtree, whose root  has the associated probability 1/6,  the sum of the probabilities of its two branches. ", "Now continue, at each step choosing the two symbols  and/or subtrees with the lowest probabilities,  combining the choices into a new subtree.  At this point in our example, the symbol A ", "has the probability 1/3, the symbol B the probability 1/2  and the C/D subtree probability 1/6.  So we‚Äôll combine A with the C/D subtree. ", "On the final step we only have two choices left:  B and the A/C/D subtree, which we  combine in a new subtree, whose root then becomes  the root of the tree representing  the optimal variable-length code. ", "Happily, this is the code we‚Äôve been using all along!  As mentioned above, we can produce a number of different  variable-length codes by swapping the ‚Äú0‚Äù and ‚Äú1‚Äù labels  on any of the subtree branches. ", "But all those encodings would have the same expected length,  which is determined by the distance of each symbol  from the root of the tree, not the labels along the path  from root to leaf. ", "So all these different encodings are  equivalent in terms of their efficiency.  Now try your hand at using Huffman‚Äôs Algorithm  ", "\"Optimal\" sounds pretty good!  Does that mean we can't do any better?  Well, not by encoding symbols one-at-a-time.  But if we want to encode long sequences of symbols, we can reduce the expected length ", "of the encoding by working with, say, pairs of symbols instead of only single symbols.  The table below shows the probability of pairs of symbols from our example. ", "If we use Huffman's Algorithm to build the optimal variable-length code using these probabilities,  it turns out the expected length when encoding pairs is 1.646 bits/symbol. ", "This is a small improvement on the 1.667 bits/symbols when encoding each symbol individually.  And we'd do even better if we encoded sequences of length 3, and so on. ", "Modern file compression algorithms use an adaptive algorithm to determine on-the-fly  which sequences occur frequently and hence should have short encodings.  They work quite well when the data has many repeating sequences, for example, natural ", "language data where some letter combinations or even whole words occur again and again.  Compression can achieve dramatic reductions from the original file size. ", "If you'd like to learn more, look up \"LZW\" on Wikipedia to read the Lempel-Ziv-Welch  data compression algorithm.   Now let's think a bit about what happens if there's an error and one or more of the bits ", "in our encoded data gets corrupted.  We'll focus on single-bit errors, but much of what we discuss can be generalized to multi-bit  errors.  For example, consider encoding the results of some unpredictable event, e.g., flipping ", "a fair coin.  There are two outcomes: \"heads\", encoded as, say, 0, and \"tails\" encoded as 1.  Now suppose some error occurs during processing - for example, the data is corrupted while ", "being transmitted from Bob to Alice: Bob intended to send the message \"heads\",  but the 0 was corrupted and become a 1 during transmission, so Alice receives 1, which she ", "interprets as \"tails\".  So this simple encoding doesn't work very well if there's the possibility of single-bit  errors.  To help with our discussion, we'll introduce the notion of \"Hamming distance\", defined ", "as the number of positions in which the corresponding digits differ in two encodings of the same  length.  For example, here are two 7-bit encodings, which differ in their third and fifth positions, ", "so the Hamming distance between the encodings is 2.  If someone tells us the Hamming distance of two encodings is 0, then the two encodings  are identical.  Hamming distance is a handy tool for measuring how encodings differ. ", "How does this help us think about single-bit errors?  A single-bit error changes exactly one of the bits of an encoding, so the Hamming distance  between a valid binary code word and the same code word with a single-bit error is 1. ", "The difficulty with our simple encoding is that the two valid code words (\"0\" and \"1\")  also have a Hamming distance of 1.  So a single-bit error changes one valid code word into another valid code word. ", "We'll show this graphically, using an arrow to indicate that two encodings differ by a  single bit, i.e., that the Hamming distance between the encodings is 1.  The real issue here is that when Alice receives a 1, she can't distinguish between an uncorrupted ", "encoding of tails and a corrupted encoding of heads - she can't detect that an error  occurred.  Let's figure how to solve her problem!  The insight is to come up with a set of valid code words such that a single-bit error does ", "NOT produce another valid code word.  What we need are code words that differ by at least two bits, i.e., we want the minimum  Hamming distance between any two code words to be at least 2. ", "If we have a set of code words where the minimum Hamming distance is 1, we can generate the  set we want by adding a parity bit to each of the original code words.  There's \"even parity\" and \"odd parity.\" ", "Using even parity, the additional parity bit is chosen so that the total number of 1 bits  in the new code word are even.  For example, our original encoding for \"heads\" was 0, adding an even parity bit gives us ", "00.  Adding an even parity bit to our original encoding for \"tails\" gives us 11.  The minimum Hamming distance between code words has increased from 1 to 2. ", "How does this help?  Consider what happens when there's a single-bit error: 00 would be corrupted to 01 or 10,  neither of which is a valid code word. ", "Aha!  We can detect that a single-bit error has occurred.  Similarly, single-bit errors for 11 would also be detected.  Note that the valid code words 00 and 11 both have an even number of 1-bits, but that the ", "corrupted code words 01 or 10 have an odd number of 1-bits.  We say that corrupted code words have a \"parity error\".  It's easy to perform a parity check: simply count the number of 1s in the code word. ", "If it's even, a single-bit error has NOT occurred; if it's odd, a single-bit error HAS occurred.  We'll see in a couple of chapters that the Boolean function exclusive-or can be used ", "to perform parity checks.  Note that parity won't help us if there's an even number of bit errors, where a corrupted  code word would have an even number of 1-bits and hence appear to be okay. ", "Parity is useful for detecting single-bit errors; we'll need a more sophisticated encoding  to detect more errors.  In general, to detect some number E of errors, we need a minimum Hamming distance of E+1 ", "between code words.  We can see this graphically below which shows how errors can corrupt the valid code words  000 and 111, which have a Hamming distance of 3. ", "In theory this means we should be able to detect up to 2-bit errors.  Each arrow represents a single-bit error and we can see from the diagram that following  any path of length 2 from either 000 or 111 doesn't get us to the other valid code word. ", "In other words, assuming we start with either 000 or 111, we can detect the occurrence of  up to 2 errors.  Basically our error detection scheme relies on choosing code words far enough apart, as ", "measured by Hamming distance, so that E errors can't corrupt one valid code word so that  it looks like another valid code word.   Is there any chance we can not only detect a single-bit error but also correct the error ", "to recover the original data?  Sure!  Here's how.  By increasing the Hamming distance between valid code words to 3, we guarantee that the  sets of code words produced by single-bit errors don't overlap. ", "The set of code words produced by corrupting 000 (100, 010, or 001) has no code words in  common with the set of code words produced by corrupting 111 (110, 101, or 011). ", "Assuming that at most one error occurred, we can deduce the original code word from  whatever code word we receive.  For example, if we receive 001, we deduce that the original code word was 000 and there ", "has been a single-bit error.  Again we can generalize this insight: if we want to correct up to E errors, the minimum  Hamming distance between valid code words must be at least 2E + 1. ", "For example, to correct single-bit errors we need valid code words with a minimum Hamming  distance of 3.  Coding theory is a research area devoted to developing algorithms to generate code words ", "that have the necessary error detection and correction properties.  You can take entire courses on this topic!  But we'll stop here with our basic insights: by choosing code words far enough apart (as ", "measured by Hamming distance) we can ensure that we can detect and even correct errors  that have corrupted our encoded data.  Pretty neat! "], "vid_duration": [10.23, 10.24, 11.689, 10.571, 10.15, 11.67, 12.42, 11.61, 13.11, 12.5, 12.24, 11.601, 12.021, 10.66, 10.08, 13.989, 12.221, 12.68, 11.18, 11.76, 12.539, 11.21, 12.781, 10.89, 11.42, 11.17, 12.64, 10.229, 13.0, 12.271, 11.08, 13.07, 11.23, 10.27, 10.13, 11.54, 12.25, 16.08, 11.504, 11.051, 11.319, 13.89, 11.82, 11.799, 12.412, 13.74, 10.719, 12.041, 11.789, 14.491, 13.419, 11.1, 15.496, 12.32, 12.049, 13.701, 14.72, 11.66, 11.979, 15.04, 12.76, 12.61, 14.441, 11.29, 10.31, 10.88, 12.44, 11.89, 13.63, 11.78, 12.701, 11.199, 14.891, 11.02, 14.44, 13.81, 13.47, 10.75, 11.319, 15.84, 14.461, 11.92, 15.27, 18.34, 19.36, 11.94, 13.289, 13.64, 13.401, 11.83, 13.35, 10.74, 12.5, 11.44, 12.56, 14.54, 13.74, 13.63, 10.03, 10.58, 12.97, 10.32, 10.03, 10.06, 15.25, 10.48, 11.91, 16.19, 14.9, 13.27, 16.01, 11.56, 10.279, 12.631, 12.51, 17.91, 14.669, 13.548, 10.44, 15.02, 13.52, 12.69, 14.88, 11.72, 11.45, 10.21, 13.91, 14.05, 10.829, 15.701, 10.289, 14.081, 13.39, 13.25, 10.449, 10.233, 10.41, 10.64, 12.3, 10.74, 10.59, 11.01, 11.64, 12.15, 11.85, 10.27, 10.57, 12.24, 10.73, 12.281, 12.35, 13.409, 10.551, 11.856, 13.789, 12.18, 10.651, 12.16, 12.36, 15.12, 13.34, 12.6, 14.41, 13.64, 12.92, 12.31, 13.44, 11.61, 10.84, 15.39, 13.25, 10.42, 12.06, 12.849, 11.141, 16.13, 13.229, 12.839, 13.44, 18.19, 13.15, 12.62, 11.02, 11.57, 8.323], "stet": [[0, 10.23], [10.23, 20.47], [20.47, 32.159], [32.159, 42.73], [42.73, 52.879999999999995], [52.879999999999995, 64.55], [64.55, 76.97], [76.97, 88.58], [88.58, 101.69], [101.69, 114.19], [114.19, 126.42999999999999], [126.42999999999999, 138.031], [138.031, 150.05200000000002], [150.05200000000002, 160.71200000000002], [160.71200000000002, 170.79200000000003], [170.79200000000003, 184.78100000000003], [184.78100000000003, 197.00200000000004], [197.00200000000004, 209.68200000000004], [209.68200000000004, 220.86200000000005], [220.86200000000005, 232.62200000000004], [232.62200000000004, 245.16100000000003], [245.16100000000003, 256.37100000000004], [256.37100000000004, 269.15200000000004], [269.15200000000004, 280.04200000000003], [280.04200000000003, 291.46200000000005], [291.46200000000005, 302.63200000000006], [302.63200000000006, 315.27200000000005], [315.27200000000005, 325.50100000000003], [325.50100000000003, 338.50100000000003], [338.50100000000003, 350.77200000000005], [350.77200000000005, 361.85200000000003], [361.85200000000003, 374.922], [374.922, 386.15200000000004], [386.15200000000004, 396.422], [396.422, 406.552], [406.552, 418.09200000000004], [418.09200000000004, 430.34200000000004], [430.34200000000004, 446.422], [446.422, 457.92600000000004], [457.92600000000004, 468.97700000000003], [468.97700000000003, 480.29600000000005], [480.29600000000005, 494.18600000000004], [494.18600000000004, 506.00600000000003], [506.00600000000003, 517.8050000000001], [517.8050000000001, 530.2170000000001], [530.2170000000001, 543.9570000000001], [543.9570000000001, 554.6760000000002], [554.6760000000002, 566.7170000000002], [566.7170000000002, 578.5060000000002], [578.5060000000002, 592.9970000000002], [592.9970000000002, 606.4160000000002], [606.4160000000002, 617.5160000000002], [617.5160000000002, 633.0120000000002], [633.0120000000002, 645.3320000000002], [645.3320000000002, 657.3810000000002], [657.3810000000002, 671.0820000000002], [671.0820000000002, 685.8020000000002], [685.8020000000002, 697.4620000000002], [697.4620000000002, 709.4410000000003], [709.4410000000003, 724.4810000000002], [724.4810000000002, 737.2410000000002], [737.2410000000002, 749.8510000000002], [749.8510000000002, 764.2920000000003], [764.2920000000003, 775.5820000000002], [775.5820000000002, 785.8920000000002], [785.8920000000002, 796.7720000000002], [796.7720000000002, 809.2120000000002], [809.2120000000002, 821.1020000000002], [821.1020000000002, 834.7320000000002], [834.7320000000002, 846.5120000000002], [846.5120000000002, 859.2130000000002], [859.2130000000002, 870.4120000000001], [870.4120000000001, 885.3030000000001], [885.3030000000001, 896.3230000000001], [896.3230000000001, 910.7630000000001], [910.7630000000001, 924.5730000000001], [924.5730000000001, 938.0430000000001], [938.0430000000001, 948.7930000000001], [948.7930000000001, 960.1120000000001], [960.1120000000001, 975.9520000000001], [975.9520000000001, 990.4130000000001], [990.4130000000001, 1002.3330000000001], [1002.3330000000001, 1017.6030000000001], [1017.6030000000001, 1035.943], [1035.943, 1055.3029999999999], [1055.3029999999999, 1067.243], [1067.243, 1080.532], [1080.532, 1094.172], [1094.172, 1107.573], [1107.573, 1119.403], [1119.403, 1132.753], [1132.753, 1143.493], [1143.493, 1155.993], [1155.993, 1167.433], [1167.433, 1179.993], [1179.993, 1194.533], [1194.533, 1208.273], [1208.273, 1221.903], [1221.903, 1231.933], [1231.933, 1242.513], [1242.513, 1255.483], [1255.483, 1265.8029999999999], [1265.8029999999999, 1275.8329999999999], [1275.8329999999999, 1285.8929999999998], [1285.8929999999998, 1301.1429999999998], [1301.1429999999998, 1311.6229999999998], [1311.6229999999998, 1323.533], [1323.533, 1339.723], [1339.723, 1354.623], [1354.623, 1367.893], [1367.893, 1383.903], [1383.903, 1395.463], [1395.463, 1405.742], [1405.742, 1418.373], [1418.373, 1430.883], [1430.883, 1448.7930000000001], [1448.7930000000001, 1463.4620000000002], [1463.4620000000002, 1477.0100000000002], [1477.0100000000002, 1487.4500000000003], [1487.4500000000003, 1502.4700000000003], [1502.4700000000003, 1515.9900000000002], [1515.9900000000002, 1528.6800000000003], [1528.6800000000003, 1543.5600000000004], [1543.5600000000004, 1555.2800000000004], [1555.2800000000004, 1566.7300000000005], [1566.7300000000005, 1576.9400000000005], [1576.9400000000005, 1590.8500000000006], [1590.8500000000006, 1604.9000000000005], [1604.9000000000005, 1615.7290000000005], [1615.7290000000005, 1631.4300000000005], [1631.4300000000005, 1641.7190000000005], [1641.7190000000005, 1655.8000000000004], [1655.8000000000004, 1669.1900000000005], [1669.1900000000005, 1682.4400000000005], [1682.4400000000005, 1692.8890000000006], [1692.8890000000006, 1703.1220000000005], [1703.1220000000005, 1713.5320000000006], [1713.5320000000006, 1724.1720000000007], [1724.1720000000007, 1736.4720000000007], [1736.4720000000007, 1747.2120000000007], [1747.2120000000007, 1757.8020000000006], [1757.8020000000006, 1768.8120000000006], [1768.8120000000006, 1780.4520000000007], [1780.4520000000007, 1792.6020000000008], [1792.6020000000008, 1804.4520000000007], [1804.4520000000007, 1814.7220000000007], [1814.7220000000007, 1825.2920000000006], [1825.2920000000006, 1837.5320000000006], [1837.5320000000006, 1848.2620000000006], [1848.2620000000006, 1860.5430000000006], [1860.5430000000006, 1872.8930000000005], [1872.8930000000005, 1886.3020000000006], [1886.3020000000006, 1896.8530000000005], [1896.8530000000005, 1908.7090000000005], [1908.7090000000005, 1922.4980000000005], [1922.4980000000005, 1934.6780000000006], [1934.6780000000006, 1945.3290000000006], [1945.3290000000006, 1957.4890000000007], [1957.4890000000007, 1969.8490000000006], [1969.8490000000006, 1984.9690000000005], [1984.9690000000005, 1998.3090000000004], [1998.3090000000004, 2010.9090000000003], [2010.9090000000003, 2025.3190000000004], [2025.3190000000004, 2038.9590000000005], [2038.9590000000005, 2051.8790000000004], [2051.8790000000004, 2064.1890000000003], [2064.1890000000003, 2077.6290000000004], [2077.6290000000004, 2089.2390000000005], [2089.2390000000005, 2100.0790000000006], [2100.0790000000006, 2115.4690000000005], [2115.4690000000005, 2128.7190000000005], [2128.7190000000005, 2139.1390000000006], [2139.1390000000006, 2151.1990000000005], [2151.1990000000005, 2164.0480000000007], [2164.0480000000007, 2175.1890000000008], [2175.1890000000008, 2191.319000000001], [2191.319000000001, 2204.5480000000007], [2204.5480000000007, 2217.3870000000006], [2217.3870000000006, 2230.8270000000007], [2230.8270000000007, 2249.0170000000007], [2249.0170000000007, 2262.167000000001], [2262.167000000001, 2274.7870000000007], [2274.7870000000007, 2285.8070000000007], [2285.8070000000007, 2297.377000000001], [2297.377000000001, 2305.7000000000007]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [136, 458, 626, 854, 1204, 1478, 1697, 1825, 1904, 2212, 2306]}
{"example_id": "mit088@@MIT6_004S17_07-02_300k", "text": ["In this chapter our goal is to introduce some metrics for measuring the performance of a  circuit and then investigate ways to improve that performance.  We'll start by putting aside circuits for a moment and look at an everyday example that ", "will help us understand the proposed performance metrics.  Laundry is a processing task we all have to face at some point!  The input to our laundry \"system\" is some number of loads of dirty laundry and the output ", "is the same loads, but washed, dried, and folded.  There two system components: a washer that washes a load of laundry in 30 minutes, and  a dryer that dries a load in 60 minutes. ", "You may be used to laundry system components with different propagation delays, but let's  go with these delays for our example.  Our laundry follows a simple path through the system: ", "each load is first washed in the washer and afterwards moved to the dryer for drying.  There can, of course, be delays between the steps of loading the washer, or moving wet, ", "washed loads to the dryer, or in taking dried loads out of the dryer.  Let's assume we move the laundry through the system as fast as possible, moving loads to  the next processing step as soon as we can. ", "Most of us wait to do laundry until we've accumulated several loads.  That turns out to be a good strategy!  Let's see why‚Ä¶  To process a single load of laundry, we first run it through the washer, which takes 30 ", "minutes.  Then we run it through the dryer, which takes 60 minutes.  So the total amount of time from system input to system output is 90 minutes.  If this were a combinational logic circuit, we'd say the circuit's propagation delay is ", "90 minutes from valid inputs to valid outputs.  Okay, that's the performance analysis for a single load of laundry.  Now let's think about doing N loads of laundry. ", "Here at MIT we like to make gentle fun of our colleagues at the prestigious institution  just up the river from us.  So here's how we imagine they do N loads of laundry at Harvard. ", "They follow the combinational recipe of supplying new system inputs after the system generates  the correct output from the previous set of inputs.  So in step 1 the first load is washed and in step 2, the first load is dried, taking ", "a total of 90 minutes.  Once those steps complete, Harvard students move on to step 3, starting the processing  of the second load of laundry.  And so on‚Ä¶  The total time for the system to process N laundry loads is just N times the time it ", "takes to process a single load.  So the total time is N*90 minutes.  Of course, we're being silly here!  Harvard students don't actually do laundry. ", "Mummy sends the family butler over on Wednesday mornings to collect the dirty loads and return  them starched and pressed in time for afternoon tea.  But I hope you're seeing the analogy we're making between the Harvard approach to laundry ", "and combinational circuits.  We can all see that the washer is sitting idle while the dryer is running and that inefficiency  has a cost in terms of the rate at which N load of laundry can move through the system. ", "As engineering students here in 6.004, we see that it makes sense to overlap washing  and drying.  So in step 1 we wash the first load.  And in step 2, we dry the first load as before, but, in addition, we start washing the second ", "load of laundry.  We have to allocate 60 minutes for step 2 in order to give the dryer time to finish.  There's a slight inefficiency in that the washer finishes its work early, but with only ", "one dryer, it's the dryer that determines how quickly laundry moves through the system.  Systems that overlap the processing of a sequence of inputs are called pipelined systems and ", "each of the processing steps is called a stage of the pipeline.  The rate at which inputs move through the pipeline is determined by the slowest pipeline  stage. ", "Our laundry system is a 2-stage pipeline with a 60-minute processing time for each stage.  We repeat the overlapped wash/dry step until all N loads of laundry have been processed. ", "We're starting a new washer load every 60 minutes and getting a new load of dried laundry  from the dryer every 60 minutes.  In other words, the effective processing rate of our overlapped laundry system is one load ", "every 60 minutes.  So once the process is underway N loads of laundry takes N*60 minutes.  And a particular load of laundry, which requires two stages of processing time, takes 120 minutes. ", "The timing for the first load of laundry is a little different since the timing of Step  1 can be shorter with no dryer to wait for.  But in the performance analysis of pipelined systems, we're interested in the steady state ", "where we're assuming that we have an infinite supply of inputs.  We see that there are two interesting performance metrics.  The first is the latency of the system, the time it takes for the system to process a ", "particular input.  In the Harvard laundry system, it takes 90 minutes to wash and dry a load.  In the 6.004 laundry, it takes 120 minutes to wash and dry a load, assuming that it's ", "not the first load.  The second performance measure is throughput, the rate at which the system produces outputs.  In many systems, we get one set of outputs for each set of inputs, and in such systems, ", "the throughput also tells us the rate at inputs are consumed.  In the Harvard laundry system, the throughput is 1 load of laundry every 90 minutes.  In the 6.004 laundry, the throughput is 1 load of laundry every 60 minutes. ", "The Harvard laundry has lower latency, the 6.004 laundry has better throughput.  Which is the better system?  That depends on your goals! ", "If you need to wash 100 loads of laundry, you'd prefer to use the system with higher  throughput.  If, on the other hand, you want clean underwear for your date in 90 minutes, you're much more ", "concerned about the latency.  The laundry example also illustrates a common tradeoff between latency and throughput.  If we increase throughput by using pipelined processing, the latency usually increases ", "since all pipeline stages must operate in lock-step and the rate of processing is thus  determined by the slowest stage.   Okay, now let's apply all this analysis to improving the performance of our circuits. ", "The latency of a combinational logic circuit is simply its propagation delay t_PD.  And the throughput is just 1/t_PD since we start processing the next input only after ", "finishing the computation on the current input.  Consider a combinational system with three components: F, G, and H, where F and G work  in parallel to produce the inputs to H. Using this timing diagram we can follow the ", "processing of a particular input value X. Sometime after X is valid and stable, the  F and G modules produce their outputs F(X) and G(X). ", "Now that the inputs to H are valid and stable, the H module will produce the system output  P(X) after a delay set by the propagation delay of H.  The total elapsed time from valid input to valid output is determined by the propagation ", "delays of the component modules.  Assuming we use those modules as-is, we can't make any improvements on this latency.  But what about the system's throughput? ", "Observe that after producing their outputs, the F and G modules are sitting sitting idle,  just holding their outputs stable while H performs its computation.  Can we figure out a way for F and G to get started processing the next input while still ", "letting H do its job on the first input?  In other words, can we divide the processing of the combinational circuit into two stages  where the first stage computes F(X) and G(X), and the second stage computes H(X)? ", "If we can, then we can increase the throughput of the system.  Mr. Blue's inspiration is to use registers to hold the values F(X) and G(X) for use by ", "H, while the F and G modules start working on the next input value.  To make our timing analysis a little easier, we'll assume that our pipelining registers  have a zero propagation delay and setup time. ", "The appropriate clock period for this sequential circuit is determined by the propagation delay  of the slowest processing stage.  In this example, the stage with F and G needs a clock period of at least 20 ns to work correctly. ", "And the stage with H needs a clock period of 25 ns to work correctly.  So the second stage is the slowest and sets the system clock period at 25 ns. ", "This will be our general plan for increasing the throughput of combinational logic:  we'll use registers to divide the processing into a sequence of stages, where the registers  capture the outputs from one processing stage and hold them as inputs for the next processing ", "stage.  A particular input will progress through the system at the rate of one stage per clock  cycle.  In this example, there are two stages in the processing pipeline and the clock period is ", "25 ns, so the latency of the pipelined system is 50 ns, i.e., the number of stages times  the system's clock period. ", "The latency of the pipeline system is a little longer than the latency of the unpipelined  system.  However, the pipeline system produces 1 output every clock period, or 25 ns. ", "The pipeline system has considerably better throughput at the cost of a small increase  in latency.  Pipeline diagrams help us visualize the operation of a pipelined system. ", "The rows of the pipeline diagram represent the pipeline stages and the columns are successive  clock cycles.  At the beginning of clock cycle i the input X_i becomes stable and valid. ", "Then during clock cycle i the F and G modules process that input and at the end of the cycle  the results F(X_i) and G(X_i) are captured by the pipeline registers between the first ", "and second stages.  Then in cycle i+1, H uses the captured values do its share of the processing of X_i.  And, meanwhile, the F and G modules are working on X_i+1. ", "You can see that the processing for a particular input value moves diagonally through the diagram,  one pipeline stage per clock cycle.  At the end of cycle i+1, the output of H is captured by the final pipeline register and ", "is available for use during cycle i+2.  The total time elapsed between the arrival of an input and the availability of the output  is two cycles. ", "The processing continues cycle after cycle, producing a new output every clock cycle.  Using the pipeline diagram we can track how a particular input progresses through the  system or see what all the stages are doing in any particular cycle. ", "We'll define a K-stage pipeline (or K-pipeline for short) as an acyclic circuit having exactly  K registers on every path from input to output. ", "An unpipelined combinational circuit is thus a 0-stage pipeline.  To make it easy to build larger pipelined systems out of pipelined components, we'll  adopt the convention that every pipeline stage, and hence every K-stage pipeline, has a register ", "on its output.  We'll use the techniques we learned for analyzing the timing of sequential circuits to ensure  the clock signal common to all the pipeline registers has a period sufficient to ensure ", "correct operation of each stage.  So for every register-to-register and input-to-register path, we need to compute the sum of the propagation  delay of the input register, plus the propagation delay of the combinational logic, plus the ", "setup time of the output register.  Then we'll choose the system's clock period to be greater than or equal to the largest  such sum.  With the correct clock period and exactly K-registers along each path from system input ", "to system output, we are guaranteed that the K-pipeline will compute the same outputs as  the original unpipelined combinational circuit.  The latency of a K-pipeline is K times the period of the system's clock. ", "And the throughput of a K-pipeline is the frequency of the system's clock, i.e., 1 over  the clock period.   Here's a failed attempt at pipelining a circuit. ", "For what value of K is the circuit a K-pipeline?  Well, let's count the number of registers along each path from system inputs to system  outputs. ", "The top path through the A and C components has 2 registers.  As does the bottom path through the B and C components.  But the middle path through all three components has only 1 register. ", "Oops, this not a well-formed K-pipeline.  Why do we care?  We care because this pipelined circuit does not compute the same answer as the original ", "unpipelined circuit.  The problem is that successive generations of inputs get mixed together during processing.  For example, during cycle i+1, the B module is computing with the current value of the ", "X input but the previous value of the Y input.  This can't happen with a well-formed K-pipeline.  So we need to develop a technique for pipelining a circuit that guarantees the result will ", "be well-formed.  Here's our strategy that will ensure if we add a pipeline register along one path from  system inputs to system outputs, we will add pipeline registers along every path. ", "Step 1 is to draw a contour line that crosses every output in the circuit and mark its endpoints  as the terminal points for all the other contours we'll add. ", "During Step 2 continue to draw contour lines between the two terminal points across the  signal connections between modules.  Make sure that every signal connection crosses the new contour line in the same direction. ", "This means that system inputs will be one side of the contour and system outputs will  be on the other side.  These contours demarcate pipeline stages. ", "Place a pipeline register wherever a signal connection intersects the pipelining contours.  Here we've marked the location of pipeline registers with large black dots. ", "By drawing the contours from terminal point to terminal point we guarantee that we cross  every input-output path, thus ensuring our pipeline will be well-formed.  Now we can compute the system's clock period by looking for the pipeline stage with the ", "longest register-to-register or input-to-register propagation delay.  With these contours and assuming ideal zero-delay pipeline registers, the system clock must ", "have a period of 8 ns to accommodate the operation of the C module.  This gives a system throughput of 1 output every 8 ns. ", "Since we drew 3 contours, this is a 3-pipeline and the system latency is 3 times 8 ns or  24 ns total.  Our usual goal in pipelining a circuit is to achieve maximum throughput using the fewest ", "possible registers.  So our strategy is to find the slowest system component (in our example, the C component)  and place pipeline registers on its inputs and outputs. ", "So we drew contours that pass on either side of the C module.  This sets the clock period at 8 ns, so we position the contours so that longest path  between any two pipeline registers is at most 8. ", "There are often several choices for how to draw a contour while maintaining the same  throughput and latency.  For example, we could have included the E module in the same pipeline stage as the F ", "module.  Okay, let's review our pipelining strategy.  First we draw a contour across all the outputs.  This creates a 1-pipeline, which, as you can see, will always have the same throughput ", "and latency as the original combinational circuit.  Then we draw our next contour, trying to isolate the slowest component in the system.  This creates a 2-pipeline with a clock period of 2 and hence a throughput of 1/2, or double ", "that of the 1-pipeline.  We can add additional contours, but note that the 2-pipeline had the smallest possible clock  period, so after that additional contours add stages and hence increase the system's ", "latency without increasing its throughput.  Not illegal, just not a worthwhile investment in hardware.  Note that the signal connection between the A and C module now has two back-to-back pipelining ", "registers.  Nothing wrong with that; it often happens when we pipeline a circuit where the input-output  paths are of different lengths.  So our pipelining strategy will be to pipeline implementations with increased throughput, ", "usually at the cost of increased latency.  Sometimes we get lucky and the delays of each pipeline stage are perfectly balanced, in  which case the latency will not increase. ", "Note that a pipelined circuit will NEVER have a smaller latency than the unpipelined circuit.  Notice that once we've isolated the slowest component, we can't increase the throughput ", "any further.  How do we continue to improve the performance of circuits in light of these performance  bottlenecks?  One solution is to use pipelined components if they're available! ", "Suppose we're able to replace the original A component with a 2-stage pipelined version  A-prime.  We can redraw our pipelining contours, making sure we account for the internal pipeline ", "registers in the A-prime component.  This means that 2 of our contours have to pass through the A-prime component, guaranteeing  that we'll add pipeline registers elsewhere in the system that will account for the two-cycle ", "delay introduced by A-prime.  Now the maximum propagation delay in any stage is 1 ns, doubling the throughput from 1/2 ", "to 1/1.  This is a 4-pipeline so the latency will be 4 ns.  This is great!  But what can we do if our bottleneck component doesn't have a pipelined substitute. ", "We'll tackle that question in the next section.   6.004 students work around the dryer bottleneck by finding a laundromat that has two dryers  for every washer. ", "Looking at the timeline you can see the plan, which is divided into 30-minute steps.  The washer is in use every step, producing a newly-washed load every 30 minutes. ", "Dryer usage is interleaved, where Dryer #1 is used to dry the odd-numbered loads and  Dryer #2 is used to dry the even-numbered loads.  Once started, a dryer runs for a duration of two steps, a total of 60 minutes. ", "Since the dryers run on a staggered schedule, the system as a whole produces a load of clean,  dry laundry every 30 minutes.  The steady-state throughput is 1 load of laundry every 30 minutes and the latency for a particular ", "load of laundry is 90 minutes.  And now here's the take-home message from this example.  Consider the operation of the two-dryer system.  Even though the component dryers themselves aren't pipelined, the two-dryer interleaving ", "system is acting like a 2-stage pipeline with a clock period of 30 minutes and a latency  of 60 minutes.  In other words, by interleaving the operation of 2 unpipelined components we can achieve ", "the effect of a 2-stage pipeline.  Returning to the example of the previous section, we couldn't improve the throughput of our  pipelined system past 1/8 ns because the minimum clock period was set by the 8 ns latency of ", "the C module.  To improve the throughput further we either need to find a pipelined version of the C  component or use an interleaving strategy to achieve the effect of a 2-stage pipeline ", "using two instances of the unpipelined C component.  Let's try that‚Ä¶  Here's a circuit for a general-purpose two-way interleaver, using, in this case, two copies ", "of the unpipelined C component, C_0 and C_1.  The input for each C component comes from a D-latch, which has the job of capturing  and holding the input value. ", "There's also a multiplexer to select which C-component output will be captured by the  output register.  In the lower left-hand corner of the circuit is a very simple 2-state FSM with one state ", "bit.  The next-state logic is a single inverter, which causes the state to alternate between  0 and 1 on successive clock cycles.  This timing diagram shows how the state bit changes right after each rising clock edge. ", "To help us understand the circuit, we'll look at some signal waveforms to illustrate its  operation.  To start, here are the waveforms for the CLK signal and our FSM state bit from the previous ", "slide.  A new X input arrives from the previous stage just after the rising edge of the clock.  Next, let's follow the operation of the C_0 component. ", "Its input latch is open when FSM Q is low, so the newly arriving X_1 input passes through  the latch and C_0 can begin its computation, producing its result at the end of clock cycle ", "#2.  Note that the C_0 input latch closes at the beginning of the second clock cycle, holding  the X_1 input value stable even though the X input is starting to change. ", "The effect is that C_0 has a valid and stable input for the better part of 2 clock cycles  giving it enough time to compute its result. ", "The C_1 waveforms are similar, just shifted by one clock cycle.  C_1's input latch is open when FSM Q is high, so the newly arriving X_2 input passes through ", "the latch and C_1 can begin its computation, producing its result at the end of clock cycle  #3.  Now let's check the output of the multiplexer. ", "When FSM Q is high, it selects the value from C_0 and when FSM Q is low, it selects the  value from C_1.  We can see that happening in the waveform shown. ", "Finally, at the rising edge of the clock, the output register captures the value on  its input and holds it stable for the remainder of the clock cycle.  The behavior of the interleaving circuit is like a 2-stage pipeline: the input value arriving ", "in cycle i is processed over two clock cycles and the result output becomes available on  cycle i+2.  What about the clock period for the interleaving system? ", "Well, there is some time lost to the propagation delays of the upstream pipeline register that  supplies the X input, the internal latches and multiplexer, and the setup time of the ", "output register.  So the clock cycle has to be just a little bit longer than half the propagation delay  of the C module.  We can treat the interleaving circuit as a 2-stage pipeline, consuming an input value ", "every clock cycle and producing a result two cycles later.  When incorporating an N-way interleaved component in our pipeline diagrams, we treat it just  like a N-stage pipeline. ", "So N of our pipelining contours have to pass through the component.  Here we've replaced the slow unpipelined C component with a 2-way interleaved C-prime ", "component.  We can follow our process for drawing pipeline contours.  First we draw a contour across all the outputs.  Then we add contours, ensuring that two of them pass through the C-prime component. ", "Then we add pipeline registers at the intersections of the contours with the signal connections.  We see that the contours passing through C-prime have caused extra pipeline registers to be ", "added on the other inputs to the F module, accommodating the 2-cycle delay through C-prime.  Somewhat optimistically we've specified the C-prime minimum t_CLK to be 4 ns, so that ", "means that the slow component which determines the system's clock period is now the F module,  with a propagation delay of 5 ns.  So the throughput of our new pipelined circuit is 1 output every 5 ns, and with 5 contours, ", "it's a 5-pipeline so the latency is 5 times the clock period or 25 ns.  By running pipelined systems in parallel we can continue to increase the throughput. ", "Here we show a laundry with 2 washers and 4 dryers, essentially just two copies of the  1-washer, 2-dryer system shown earlier.  The operation is as described before, except that at each step the system produces and ", "consumes two loads of laundry.  So the throughput is 2 loads every 30 minutes for an effective rate of 1 load every 15 minutes.  The latency for a load hasn't changed; it's still 90 minutes per load. ", "We've seen that even with slow components we can use interleaving and parallelism to  continue to increase throughput.  Is there an upper bound on the throughput we can achieve?  Yes! ", "The timing overhead of the pipeline registers and interleaving components will set a lower  bound on the achievable clock period, thus setting an upper bound on the achievable throughput.  Sorry, no infinite speed-up is possible in the real world. ", " We've been designing our processing pipelines to have all the stages operate in lock step,  choosing the clock period to accommodate the worst-case processing time over all the stages. ", "This is what we'd call a synchronous, globally timed system.  But what if there are data dependencies in the processing time, i.e., if for some data  inputs a particular processing stage might be able to produce its output in a shorter ", "time?  Can we design a system that could take advantage of that opportunity to increase throughput?  One alternative is to continue to use a single system clock, but for each stage to signal ", "when it's ready for a new input and when it has a new output ready for the next stage.  It's fun to design a simple 2-signal handshake protocol to reliably transfer data from one ", "stage to the next.  The upstream stage produces a signal called HERE-IS-X to indicate that is has new data  for the downstream stage.  And the downstream stage produces a signal called GOT-X to indicate when it is willing ", "to consume data.  It's a synchronous system so the signal values are only examined on the rising edge of the  clock.  The handshake protocol works as follows: the upstream stage asserts HERE-IS-X if it ", "will have a new output value available at the next rising edge of the clock.  The downstream stage asserts GOT-X if it will grab the next output at the rising edge of ", "the clock.  Both stages look at the signals on the rising edge of the clock to decide what to do next.  If both stages see that HERE-IS-X and GOT-X are asserted at the same clock edge, the handshake ", "is complete and the data transfer happens at that clock edge.  Either stage can delay a transfer if they are still working on producing the next output  or consuming the previous input. ", "It's possible, although considerably more difficult, to build a clock-free asynchronous  self-timed system that uses a similar handshake protocol. ", "The handshake involves four phases.  In phase 1, when the upstream stage has a new output and GOT-X is deasserted, it asserts  its HERE-IS-X signal and then waits to see the downstream stage's reply on the GOT-X ", "signal.  In phase 2, the downstream stage, seeing that HERE-IS-X is asserted, asserts GOT-X when  it has consumed the available input. ", "In phase 3, the downstream stage waits to see the HERE-IS-X go low, indicating that  the upstream stage has successfully received the GOT-X signal. ", "In phase 4, once HERE-IS-X is deasserted, the downstream stage deasserts GOT-X and the  transfer handshake is ready to begin again. ", "Note that the upstream stage waits until it sees the GOT-X deasserted before starting  the next handshake.  The timing of the system is based on the transitions of the handshake signals, which can happen ", "at any time the conditions required by the protocol are satisfied.  No need for a global clock here!  It's fun to think about how this self-timed protocol might work when there are multiple ", "downstream modules, each with their own internal timing.  In this example, A's output is consumed by both the B and C stages.  We need a special circuit, shown as a yellow box in the diagram, to combine the GOT-X signals ", "from the B and C stages and produce a summary signal for the A stage.  Let's take a quick look at the timing diagram shown here.  After A has asserted HERE-IS-X, the circuit in the yellow box waits until both the B and ", "the C stage have asserted their GOT-X signals before asserting GOT-X to the A stage.  At this point the A stage deasserts HERE-IS-X, then the yellow box waits until both the B ", "and C stages have deasserted their GOT-X signals, before deasserting GOT-X to the A stage.  Let's watch the system in action!  When a signal is asserted we'll show it in red, otherwise it's shown in black. ", "A new value for the A stage arrives on A's data input and the module supplying the value  then asserts its HERE-IS-X signal to let A know it has a new input. ", "At some point later, A signals GOT-X back upstream to indicate that it has consumed  the value, then the upstream stage deasserts HERE-IS-X, followed by A deasserting its GOT-X ", "signal.  This completes the transfer of the data to the A stage.  When A is ready to send a new output to the B and C stages, it checks that its GOT-X input ", "is deasserted (which it is), so it asserts the new output value and signals  HERE-IS-X to the yellow box which forwards the signal to the downstream stages. ", "B is ready to consume the new input and so asserts its GOT-X output.  Note that C is still waiting for its second input and has yet to assert its GOT-X output. ", "After B finishes its computation, it supplies a new value to C and asserts its HERE-IS-X  output to let C know its second input is ready. ", "Now C is happy and signals both upstream stages that it has consumed its two inputs.  Now that both GOT-X inputs are asserted, the yellow box asserts A's GOT-X input to let ", "it know that the data has been transferred.  Meanwhile B completes its part of the handshake, and C completes its transaction with B and  A deasserts HERE-IS-X to indicate that it has seen its GOT-X input. ", "When the B and C stages see their HERE-IS-X inputs go low, they their finish their handshakes  by deasserting their GOT-X outputs, and when they're both low, the yellow box ", "lets A know the handshake is complete by deserting A's GOT-X input.  Whew!  The system has returned to the initial state where A is now ready to accept some future ", "input value.  This an elegant design based entirely on transition signaling.  Each module is in complete control of when it consumes inputs and produces outputs, and ", "so the system can process data at the fastest possible speed, rather than waiting for the  worst-case processing delay.   Let‚Äôs summarize what we‚Äôve learned about controlling ", "pipelined systems.  The most straightforward approach  is to use a pipeline with the system  clock chosen to accommodate the worst-case processing time.  These systems are easy to design but can‚Äôt produce higher ", "throughputs if the processing stages might run more quickly  for some data values.  We saw that we could use a simple handshake  protocol to move data through the system. ", "All communication still happens on the rising edge  of the system clock, but the specific clock edge  used to transfer data is determined  by the stages themselves.  It‚Äôs tempting to wonder if we can might adjust the global ", "clock period to take advantage of data-dependent processing  speedups.  But the necessary timing generators  can be very complicated in large systems.  It‚Äôs usually much easier to use local communication between ", "modules to determine system timing than trying to figure  out all the constraints at the system level.  So this approach isn‚Äôt usually a good one.  But what about locally-timed asynchronous systems ", "like the example we just saw?  Each generation of engineers has heard the siren call  of asynchronous logic.  Sadly, it usually proves too hard to produce  a provably reliable design for a large system, ", "say, a modern computer.  But there are special cases, such as the logic for integer  division, where the data-dependent speed-ups  make the extra work worthwhile. ", "We characterized the performance of our systems  by measuring their latency and throughput.  For combinational circuits, the latency  is simply the propagation delay of the circuit  and its throughput is just 1/latency. ", "We introduced a systematic strategy for designing  K-pipelines, where there‚Äôs a register on the outputs of each  stage, and there are exactly K registers on every path from ", "input to output.  The period of the system clock t_CLK  is determined by the propagation delay of the slowest pipeline  stage.  The throughput of a pipelined system is 1/t_CLK and its ", "latency is K times t_CLK.  Pipelining is the key to increasing  the throughput of most high-performance digital  systems. "], "vid_duration": [12.451, 13.4, 12.27, 10.42, 10.39, 13.17, 12.76, 13.33, 11.9, 10.689, 13.561, 14.42, 11.0, 13.06, 12.93, 14.74, 11.31, 11.22, 10.029, 12.401, 11.419, 14.321, 11.62, 11.65, 11.88, 12.05, 16.04, 10.12, 11.09, 13.29, 12.933, 10.969, 14.681, 11.45, 14.37, 11.279, 14.34, 14.671, 10.369, 13.591, 14.11, 11.22, 14.69, 11.62, 10.07, 11.57, 11.64, 13.17, 11.23, 14.49, 14.0, 10.9, 14.37, 11.34, 15.75, 11.47, 14.13, 12.82, 14.43, 10.784, 10.52, 12.57, 10.889, 12.011, 12.68, 13.63, 10.53, 13.92, 11.32, 11.31, 13.61, 10.63, 10.66, 13.35, 11.11, 14.1, 10.91, 12.999, 14.991, 12.98, 13.81, 14.02, 10.54, 10.11, 11.72, 12.2, 11.64, 10.0, 12.52, 11.562, 10.85, 15.25, 12.989, 14.89, 12.321, 15.54, 11.55, 10.93, 11.72, 11.4, 15.909, 11.631, 11.41, 12.33, 12.73, 10.27, 10.53, 10.28, 12.11, 15.23, 11.16, 10.62, 12.08, 11.87, 10.24, 13.94, 10.55, 12.66, 15.15, 11.06, 12.86, 13.99, 10.52, 14.108, 12.15, 13.83, 11.179, 10.93, 13.47, 14.661, 10.2, 12.55, 11.689, 10.31, 14.851, 11.02, 11.75, 10.08, 10.77, 11.89, 14.11, 15.11, 11.71, 13.7, 10.63, 12.61, 10.581, 10.119, 11.57, 10.9, 12.78, 15.38, 10.63, 10.94, 11.9, 10.458, 13.09, 10.71, 12.14, 12.47, 12.06, 12.83, 11.91, 13.38, 10.52, 13.52, 9.725], "stet": [[0, 12.451], [12.451, 25.851], [25.851, 38.120999999999995], [38.120999999999995, 48.541], [48.541, 58.931], [58.931, 72.101], [72.101, 84.861], [84.861, 98.191], [98.191, 110.09100000000001], [110.09100000000001, 120.78], [120.78, 134.341], [134.341, 148.761], [148.761, 159.761], [159.761, 172.821], [172.821, 185.751], [185.751, 200.491], [200.491, 211.80100000000002], [211.80100000000002, 223.02100000000002], [223.02100000000002, 233.05], [233.05, 245.45100000000002], [245.45100000000002, 256.87], [256.87, 271.19100000000003], [271.19100000000003, 282.81100000000004], [282.81100000000004, 294.461], [294.461, 306.341], [306.341, 318.391], [318.391, 334.43100000000004], [334.43100000000004, 344.55100000000004], [344.55100000000004, 355.641], [355.641, 368.93100000000004], [368.93100000000004, 381.86400000000003], [381.86400000000003, 392.833], [392.833, 407.514], [407.514, 418.964], [418.964, 433.334], [433.334, 444.613], [444.613, 458.953], [458.953, 473.62399999999997], [473.62399999999997, 483.99299999999994], [483.99299999999994, 497.58399999999995], [497.58399999999995, 511.69399999999996], [511.69399999999996, 522.914], [522.914, 537.604], [537.604, 549.224], [549.224, 559.2940000000001], [559.2940000000001, 570.8640000000001], [570.8640000000001, 582.5040000000001], [582.5040000000001, 595.6740000000001], [595.6740000000001, 606.9040000000001], [606.9040000000001, 621.3940000000001], [621.3940000000001, 635.3940000000001], [635.3940000000001, 646.2940000000001], [646.2940000000001, 660.6640000000001], [660.6640000000001, 672.0040000000001], [672.0040000000001, 687.7540000000001], [687.7540000000001, 699.2240000000002], [699.2240000000002, 713.3540000000002], [713.3540000000002, 726.1740000000002], [726.1740000000002, 740.6040000000002], [740.6040000000002, 751.3880000000001], [751.3880000000001, 761.9080000000001], [761.9080000000001, 774.4780000000002], [774.4780000000002, 785.3670000000002], [785.3670000000002, 797.3780000000002], [797.3780000000002, 810.0580000000001], [810.0580000000001, 823.6880000000001], [823.6880000000001, 834.2180000000001], [834.2180000000001, 848.138], [848.138, 859.4580000000001], [859.4580000000001, 870.768], [870.768, 884.378], [884.378, 895.008], [895.008, 905.668], [905.668, 919.018], [919.018, 930.128], [930.128, 944.2280000000001], [944.2280000000001, 955.138], [955.138, 968.1370000000001], [968.1370000000001, 983.128], [983.128, 996.1080000000001], [996.1080000000001, 1009.918], [1009.918, 1023.938], [1023.938, 1034.478], [1034.478, 1044.588], [1044.588, 1056.308], [1056.308, 1068.508], [1068.508, 1080.1480000000001], [1080.1480000000001, 1090.1480000000001], [1090.1480000000001, 1102.6680000000001], [1102.6680000000001, 1114.23], [1114.23, 1125.08], [1125.08, 1140.33], [1140.33, 1153.319], [1153.319, 1168.209], [1168.209, 1180.53], [1180.53, 1196.07], [1196.07, 1207.62], [1207.62, 1218.55], [1218.55, 1230.27], [1230.27, 1241.67], [1241.67, 1257.5790000000002], [1257.5790000000002, 1269.2100000000003], [1269.2100000000003, 1280.6200000000003], [1280.6200000000003, 1292.9500000000003], [1292.9500000000003, 1305.6800000000003], [1305.6800000000003, 1315.9500000000003], [1315.9500000000003, 1326.4800000000002], [1326.4800000000002, 1336.7600000000002], [1336.7600000000002, 1348.8700000000001], [1348.8700000000001, 1364.1000000000001], [1364.1000000000001, 1375.2600000000002], [1375.2600000000002, 1385.88], [1385.88, 1397.96], [1397.96, 1409.83], [1409.83, 1420.07], [1420.07, 1434.01], [1434.01, 1444.56], [1444.56, 1457.22], [1457.22, 1472.3700000000001], [1472.3700000000001, 1483.43], [1483.43, 1496.29], [1496.29, 1510.28], [1510.28, 1520.8], [1520.8, 1534.908], [1534.908, 1547.058], [1547.058, 1560.888], [1560.888, 1572.067], [1572.067, 1582.997], [1582.997, 1596.467], [1596.467, 1611.1280000000002], [1611.1280000000002, 1621.3280000000002], [1621.3280000000002, 1633.8780000000002], [1633.8780000000002, 1645.5670000000002], [1645.5670000000002, 1655.8770000000002], [1655.8770000000002, 1670.7280000000003], [1670.7280000000003, 1681.7480000000003], [1681.7480000000003, 1693.4980000000003], [1693.4980000000003, 1703.5780000000002], [1703.5780000000002, 1714.3480000000002], [1714.3480000000002, 1726.2380000000003], [1726.2380000000003, 1740.3480000000002], [1740.3480000000002, 1755.458], [1755.458, 1767.1680000000001], [1767.1680000000001, 1780.8680000000002], [1780.8680000000002, 1791.4980000000003], [1791.4980000000003, 1804.1080000000002], [1804.1080000000002, 1814.689], [1814.689, 1824.808], [1824.808, 1836.378], [1836.378, 1847.278], [1847.278, 1860.058], [1860.058, 1875.438], [1875.438, 1886.0680000000002], [1886.0680000000002, 1897.0080000000003], [1897.0080000000003, 1908.9080000000004], [1908.9080000000004, 1919.3660000000004], [1919.3660000000004, 1932.4560000000004], [1932.4560000000004, 1943.1660000000004], [1943.1660000000004, 1955.3060000000005], [1955.3060000000005, 1967.7760000000005], [1967.7760000000005, 1979.8360000000005], [1979.8360000000005, 1992.6660000000004], [1992.6660000000004, 2004.5760000000005], [2004.5760000000005, 2017.9560000000006], [2017.9560000000006, 2028.4760000000006], [2028.4760000000006, 2041.9960000000005], [2041.9960000000005, 2051.7210000000005]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [377, 748, 1107, 1536, 1917, 2053]}
{"example_id": "mit088@@MIT6_004S17_04-02_300k", "text": ["In this lecture you'll learn various techniques for creating combinational logic circuits  that implement a particular functional specification.  A functional specification is part of the static discipline we use to create the combinational ", "logic abstraction of a circuit.  One approach is to use natural language to describe the operation of a device.  This approach has its pros and cons.  In its favor, natural language can convey complicated concepts in surprisingly compact ", "form and it is a notation that most of us know how to read and understand.  But, unless the words are very carefully crafted, there may be ambiguities introduced by words  with multiple interpretations or by lack of completeness since it's not always obvious ", "whether all eventualities have been dealt with.  There are good alternatives that address the shortcomings mentioned above.  Truth tables are a straightforward tabular representation that specifies the values of ", "the outputs for each possible combination of the digital inputs.  If a device has N digital inputs, its truth table will have 2^N rows. ", "In the example shown here, the device has 3 inputs, each of which can have the value  0 or the value 1.  There are 2*2*2 = 2^3 = 8 combinations of the three input values, so there are 8 rows ", "in the truth table.  It's straightforward to systematically enumerate the 8 combinations, which makes it easy to  ensure that no combination is omitted when building the specification. ", "And since the output values are specified explicitly, there isn't much room for misinterpreting  the desired functionality!  Truth tables are an excellent choice for devices with small numbers of inputs and outputs. ", "Sadly, they aren't really practical when the devices have many inputs.  If, for example, we were describing the functionality of a circuit to add two 32-bit numbers, there ", "would be 64 inputs altogether and the truth table would need 2^64 rows.  Hmm, not sure how practical that is!  If we entered the correct output value for a row once per second, it would take 584 billion ", "years to fill in the table!  Another alternative specification is to use Boolean equations to describe how to compute  the output values from the input values using Boolean algebra. ", "The operations we use are the logical operations AND, OR, and XOR, each of which takes two  Boolean operands, and NOT which takes a single Boolean operand. ", "Using the truth tables that describe these logical operations, it's straightforward to  compute an output value from a particular combination of input values using the sequence  of operations laid out in the equation. ", "Let me say a quick word about the notation used for Boolean equations.  Input values are represented by the name of the input, in this example one of \"A\", \"B\", ", "or \"C\".  The digital input value 0 is equivalent to the Boolean value FALSE and the digital input  value 1 is equivalent to the Boolean value TRUE. ", "The Boolean operation NOT is indicated by a horizontal line drawn above a Boolean expression.  In this example, the first symbol following the equal sign is a \"C\" with line above it, ", "indicating that the value of C should be inverted before it's used in evaluating the rest of  the expression.  The Boolean operation AND is represented by the multiplication operation using standard ", "mathematical notation.  Sometimes we'll use an explicit multiplication operator - usually written as a dot between  two Boolean expressions - as shown in the first term of the example equation. ", "Sometimes the AND operator is implicit as shown in the remaining three terms of the  example equation.  The Boolean operation OR is represented by the addition operation, always shown as a ", "\"+\" sign.  Boolean equations are useful when the device has many inputs.  And, as we'll see, it's easy to convert a Boolean equation into a circuit schematic. ", "Truth tables and Boolean equations are interchangeable.  If we have a Boolean equation for each output, we can fill in the output columns for a row  of the truth table by evaluating the Boolean equations using the particular combination ", "of input values for that row.  For example, to determine the value for Y in the first row of the truth table, we'd  substitute the Boolean value FALSE for the symbols A, B, and C in the equation and then ", "use Boolean algebra to compute the result.  We can go the other way too.  We can always convert a truth table into a particular form of Boolean equation called  a sum-of-products. ", "Let's see how‚Ä¶  Start by looking at the truth table and answering the question \"When does Y have the value 1?\"  Or, in the language of Boolean algebra: \"When is Y TRUE?\". ", "Well, Y is TRUE when the inputs correspond to row 2 of the truth table, OR to row 4,  OR to rows 7 OR 8. ", "Altogether there are 4 combinations of inputs for which Y is TRUE.  The corresponding Boolean equation thus is the OR for four terms, where each term is  a boolean expression which evaluates to TRUE for a particular combination of inputs. ", "Row 2 of the truth table corresponds to C=0, B=0, and A=1.  The corresponding Boolean expression is (NOT C) AND (NOT B) ", "AND A, an expression that evaluates to TRUE if and only if C is 0, B is 0, and A is 1.  The boolean expression corresponding to row 4 is (NOT C) AND B AND A. ", "And so on for rows 7 and 8.  The approach will always give us an expression in the form of a sum-of-products.  \"Sum\" refers to the OR operations and \"products\" refers to the groups of AND operations. ", "In this example we have the sum of four product terms.  Our next step is to use the Boolean expression as a recipe for constructing a circuit implementation ", "using combinational logic gates.  As circuit designers we'll be working with a library of combinational logic gates, which  either is given to us by the integrated circuit manufacturer, or which we've designed ourselves ", "as CMOS gates using NFET and PFET switches.  One of the simplest gates is the inverter, which has the schematic symbol shown here.  The small circle on the output wire indicates an inversion, a common convention used in ", "schematics.  We can see from its truth table that the inverter implements the Boolean NOT function.  The AND gate outputs 1 if and only if the A input is 1 *and* the B input is 1, hence ", "the name \"AND\".  The library will usually include AND gates with 3 inputs, 4 inputs, etc., which produce  a 1 output if and only if all of their inputs are 1. ", "The OR gate outputs 1 if the A input is 1 *or* if the B input is 1, hence the name \"OR\".  Again, the library will usually include OR gates with 3 inputs, 4 inputs, etc., which ", "produce a 1 output when at least one of their inputs is 1.  These are the standard schematic symbols for AND and OR gates.  Note that the AND symbol is straight on the input side, while the OR symbol is curved. ", "With a little practice, you'll find it easy to remember which schematic symbols are which.  Now let's use these building blocks to build a circuit that implements a sum-of-products ", "equation.  The structure of the circuit exactly follows the structure of the Boolean equation.  We use inverters to perform the necessary Boolean NOT operations. ", "In a sum-of-products equation the inverters are operating on particular input values,  in this case A, B and C. To keep the schematic easy to read we've used ", "a separate inverter for each of the four NOT operations in the Boolean equation, but in  real life we might invert the C input once to produce a NOT-C signal, then use that signal ", "whenever a NOT-C value is needed.  Each of the four product terms is built using a 3-input AND gate.  And the product terms are ORed together using a 4-input OR gate. ", "The final circuit has a layer of inverters, a layer of AND gates and final OR gate.  In the next section we'll talk about how to build AND or OR gates with many inputs from  library components with fewer inputs. ", "The propagation delay for a sum-of-products circuit looks pretty short: the longest path  from inputs to outputs includes an inverter, an AND gate and an OR gate. ", "Can we really implement any Boolean equation in a circuit with a tPD of three gate delays?  Actually not, since building ANDs and ORs with many inputs will require additional layers ", "of components, which will increase the propagation delay.  We'll learn about this in the next section.  The good news is that we now have straightforward techniques for converting a truth table to ", "its corresponding sum-of-products Boolean equation, and for building a circuit that  implements that equation.   On our to-do list from the previous section  is figuring out how to build AND and OR gates with many inputs. ", "These will be needed when creating circuit  implementations using a sum-of-products equation  as our template.  Let‚Äôs assume our gate library only has 2-input gates  and figure how to build wider gates using the 2-input gates ", "as building blocks.  We‚Äôll work on creating 3- and 4-input gates,  but the approach we use can be generalized to create AND  and OR gates of any desired width. ", "The approach shown here relies on the associative property  of the AND operator.  This means we can perform an N-way  AND by doing pair-wise ANDs in any convenient order. ", "The OR and XOR operations are also associative,  so the same approach will work for designing wide OR and XOR  circuits from the corresponding 2-input gate. ", "Simply substitute 2-input OR gates or 2-input XOR gates  for the 2-input AND gates shown below and you‚Äôre good to go!  Let‚Äôs start by designing a circuit that computes the AND ", "of three inputs A, B, and C.  In the circuit shown here, we first compute (A AND B),  then AND that result with C. ", "Using the same strategy, we can build a 4-input AND gate  from three 2-input AND gates.  Essentially we‚Äôre building a chain of AND gates,  which implement an N-way AND using N-1 2-input AND gates. ", "We can also associate the four inputs a different way:  computing (A AND B) in parallel with (C AND D),  then combining those two results using a third AND gate. ", "Using this approach, we‚Äôre building a tree of AND gates.  Which approach is best: chains or trees?  First we have to decide what we mean by ‚Äúbest‚Äù.  When designing circuits we‚Äôre interested in cost, ", "which depends on the number of components, and performance,  which we characterize by the propagation delay  of the circuit.  Both strategies require the same number of components ", "since the total number of pair-wise ANDs  is the same in both cases.  So it‚Äôs a tie when considering costs.  Now consider propagation delay. ", "The chain circuit in the middle has a tPD of 3 gate delays,  and we can see that the tPD for an N-input chain  will be N-1 gate delays.  The propagation delay of chains grows linearly ", "with the number of inputs.   The tree circuit on the bottom has  a tPD of 2 gates, smaller than the chain.  The propagation delay of trees grows logarithmically ", "with the number of inputs.  Specifically, the propagation delay  of tree circuits built using 2-input gates grows as log2(N).  When N is large, tree circuits can ", "have dramatically better propagation delay  than chain circuits.  The propagation delay is an upper  bound on the worst-case delay from inputs to outputs  and is a good measure of performance ", "assuming that all inputs arrive at the same time.  But in large circuits, A, B, C and D  might arrive at different times depending  on the tPD of the circuit generating each one. ", "Suppose input D arrives considerably  after the other inputs.  If we used the tree circuit to compute the AND of all four  inputs, the additional delay in computing Z ", "is two gate delays after the arrival of D.  However, if we use the chain circuit,  the additional delay in computing Z  might be as little as one gate delay. ", "The moral of this story: it‚Äôs hard to know which  implementation of a subcircuit, like the 4-input AND shown  here, will yield the smallest overall tPD unless we know ", "the tPD of the circuits that compute the values  for the input signals.  In designing CMOS circuits, the individual gates  are naturally inverting, so instead of using AND and OR ", "gates, for the best performance we want to the use  the NAND and NOR gates shown here.  NAND and NOR gates can be implemented as a single CMOS  gate involving one pullup circuit and one pulldown ", "circuit.  AND and OR gates require two CMOS gates  in their implementation, e.g., a NAND gate  followed by an INVERTER.  We‚Äôll talk about how to build sum-of-products circuitry using ", "NANDs and NORs in the next section.  Note that NAND and NOR operations are not associative:  NAND(A,B,C) is not equal to NAND(NAND(A,B),C). ", "So we can‚Äôt build a NAND gate with many inputs by building  a tree of 2-input NANDs.  We‚Äôll talk about this in the next section too!  We‚Äôve mentioned the exclusive-or operation, ", "sometimes called XOR, several times.  This logic function is very useful  when building circuitry for arithmetic or parity  calculations.  As you‚Äôll see in Lab 2, implementing a 2-input XOR gate ", "will take many more NFETs and PFETs than required  for a 2-input NAND or NOR.  We know we can come up with a sum-of-products expression  for any truth table and hence build ", "a circuit implementation using INVERTERs, AND gates,  and OR gates.  It turns out we can build circuits  with the same functionality using only 2-INPUT NAND gates. ", "We say the the 2-INPUT NAND is a universal gate.  Here we show how to implement the sum-of-products building  blocks using just 2-input NAND gates.  In a minute we‚Äôll show a more direct implementation ", "for sum-of-products using only NANDs,  but these little schematics are a proof-of-concept showing that  NAND-only equivalent circuits exist.  2-INPUT NOR gates are also universal, ", "as shown by these little schematics.  Inverting logic takes a little getting used to,  but its the key to designing low-cost high-performance  ", "Now would be a good time to take a moment to look at the documentation for the library  of logic gates we'll use for our designs.  Look for \"The Standard Cell Library\" handout in the Updates & Handouts tab, which is next ", "to the Courseware tab.  The information on this slide is taken from there.  The library has both inverting gates (such as inverters, NANDs and NORs) and non-inverting ", "gates (such as buffers, ANDs and ORs).  Why bother to include both types of gates?  Didn't we just learn we can build any circuit using only NAND or NOR? ", "Good questions!  We get some insight into the answers if we look at these three implementations for a  4-input AND function.  The upper circuit is a direct implementation using the 4-input AND gate available in the ", "library.  The tPD of the gate is 160 picoseconds and its size is 20 square microns.  Don't worry too much about the actual numbers, what matters on this slide is how the numbers ", "compare between designs.  The middle circuit implements the same function, this time using a 4-INPUT NAND gate hooked  to an inverter to produce the AND functionality we want. ", "The tPD of this circuit is 90 picoseconds, considerably faster than the single gate above.  The tradeoff is that the size is somewhat larger.  How can this be? ", "Especially since we know the AND gate implementation is the NAND/INVERTER pair shown in the middle  circuit.  The answer is that the creators of the library decided to make the non-inverting gates small ", "but slow by using MOSFETs with much smaller widths than used in the inverting logic gates,  which were designed to be fast.  Why would we ever want to use a slow gate? ", "Remember that the propagation delay of a circuit is set by the longest path in terms of delay  from inputs to outputs.  In a complex circuit, there are many input/output paths, but it's only the components on the ", "longest path that need to be fast in order to achieve the best possible overall tPD.  The components on the other, shorter paths, can potentially be a bit slower. ", "And the components on short input/output paths can be very slow indeed.  So for the portions of the circuit that aren't speed sensitive, it's a good tradeoff to use  slower but smaller gates. ", "The overall performance isn't affected, but the total size is improved.  So for faster performance we'll design with inverting gates, and for smallest size we'll ", "design with non-inverting gates.  The creators of the gate library designed the available gates with this tradeoff in  mind.  The 4-input inverting gates are also designed with this tradeoff in mind. ", "For the ultimate in performance, we want to use a tree circuit of 2-input gates, as shown  in the lower circuit.  This implementation shaves 10 picoseconds off the tPD, while costing us a bit more in ", "size.  Take a closer look at the lower circuit.  This tree circuit uses two NAND gates whose outputs are combined with a NOR gate.  Does this really compute the AND of A, B, C, and D? ", "Yup, as you can verify by building the truth table for this combinational system using  the truth tables for NAND and NOR.  This circuit is a good example of the application of a particular Boolean identity known as ", "Demorgan's Law.  There are two forms of Demorgan's law, both of which are shown here.  The top form is the one we're interested in for analyzing the lower circuit. ", "It tells us that the NOR of A with B is equivalent to the AND of (NOT A) with (NOT B).  So the 2-input NOR gate can be thought of as a 2-input AND gate with inverting inputs. ", "How does this help?  We can now see that the lower circuit is actually a tree of AND gates, where the inverting outputs  of the first layer match up with the inverting inputs of the second layer. ", "It's a little confusing the first time you see it, but with practice you'll be comfortable  using Demorgan's law when building trees or chains of inverting logic. ", "Using Demorgan's Law we can answer the question of how to build NANDs and NORs with large  numbers of inputs.  Our gate library includes inverting gates with up to 4 inputs. ", "Why stop there?  Well, the pulldown chain of a 4-input NAND gate has 4 NFETs in series and the resistance  of the conducting channels is starting to add up. ", "We could make the NFETs wider to compensate, but then the gate gets much larger and the  wider NFETs impose a higher capacitive load on the input signals. ", "The number of possible tradeoffs between size and speed grows rapidly with the number of  inputs, so it's usually just best for the library designer to stop at 4-input gates  and let the circuit designer take it from there. ", "Happily, Demorgan's law shows us how build trees of alternating NANDs and NORs to build  inverting logic with a large number of inputs.  Here we see schematics for an 8-input NAND and an 8-input NOR gate. ", "Think of the middle layer of NOR gates in the left circuit as AND gates with inverting  inputs and then it's easy to see that the circuit is a tree of ANDs with an inverting  output. ", "Similarly, think of the middle layer of NAND gates in the right circuit as OR gates with  inverting inputs and see that we really have a tree of OR gates with an inverting output. ", "Now let's see how to build sum-of-products circuits using inverting logic.  The two circuits shown here implement the same sum-of-products logic function.  The one on the top uses two layers of NAND gates, the one on the bottom, two layers of ", "NOR gates.  Let's visualize Demorgan's Law in action on the top circuit.  The NAND gate with Y on its output can be transformed by Demorgan's Law into an OR gate ", "with inverting inputs.  So we can redraw the circuit on the top left as the circuit shown on the top right.  Now, notice that the inverting outputs of the first layer are cancelled by the inverting ", "inputs of the second layer, a step we can show visually by removing matching inversions.  And, voila, we see the NAND/NAND circuit in sum-of-products form: a layer of inverters, ", "a layer of AND gates, and an OR gate to combine the product terms.  We can use a similar visualization to transform the output gate of the bottom circuit, giving  us the circuit on the bottom right. ", "Match up the bubbles and we see that we have the same logic function as above.  Looking at the NOR/NOR circuit on the bottom left, we see it has 4 inverters, whereas the ", "NAND/NAND circuit only has one.  Why would we ever use the NOR/NOR implementation?  It has to do with the loading on the inputs.  In the top circuit, the input A connects to a total of four MOSFET switches. ", "In the bottom circuit, it connects to only the two MOSFET switches in the inverter.  So, the bottom circuit imposes half the capacitive load on the A signal.  This might be significant if the signal A connected to many such circuits. ", "The bottom line: when you find yourself needing a fast implementation for the AND/OR circuitry  for a sum-of-products expression, try using the NAND/NAND implementation. ", "It'll be noticeably faster than using AND/OR.   The previous sections showed us how  to build a circuit that computes a given  sum-of-products expression. ", "An interesting question to ask is  if we can implement the same functionality using  fewer gates or smaller gates?  In other words is there an equivalent Boolean expression  that involves fewer operations? ", "Boolean algebra has many identities  that can be used to transform an expression into an equivalent,  and hopefully smaller, expression.  The reduction identity in particular ", "offers a transformation that simplifies  an expression involving two variables and four operations  into a single variable and no operations.  Let‚Äôs see how we might use that identity to simplify ", "a sum-of-products expression.  Here‚Äôs the equation from the start of this chapter,  involving 4 product terms.  We‚Äôll use a variant of the reduction identity involving ", "a Boolean expression alpha and a single variable A.  Looking at the product terms, the middle two  offer an opportunity to apply the reduction identity  if we let alpha be the expression (C AND B). ", "So we simplify the middle two product terms  to just alpha, i.e., (C AND B), eliminating the variable A  from this part of the expression.  Considering the now three product terms, ", "we see that the first and last terms can also  be reduced, this time letting alpha be  the expression (NOT C and A).  Wow, this equivalent equation is much smaller! ", "Counting inversions and pair-wise operations,  the original equation has 14 operations,  while the simplified equation has 4 operations.  The simplified circuit would be much cheaper ", "to build and have a smaller tPD in the bargain!  Doing this sort of Boolean simplification by hand  is tedious and error-prone.  Just the sort of task a computer program could help with. ", "Such programs are in common use, but the computation  needed to discover the smallest possible form for an expression  grows faster than exponentially as the number  of inputs increases. ", "So for larger equations, the programs  use various heuristics to choose which simplifications to apply.  The results are quite good, but not necessarily optimal. ", "But it sure beats doing the simplification by hand!  Another way to think about simplification is by searching  the truth table for ‚Äúdon‚Äôt-care‚Äù situations.  For example, look at the first and third rows ", "of the original truth table on the left.  In both cases A is 0, C is 0, and the output Y is 0.  The only difference is the value of B, which we can then tell ", "is irrelevant when both A and C are 0.  This gives us the first row of the truth table on the right,  where we use X to indicate that the value of B doesn‚Äôt matter  when A and C are both 0. ", "By comparing rows with the same value for Y,  we can find other don‚Äôt-care situations.  The truth table with don‚Äôt-cares has only three rows where  the output is 1. ", "And, in fact, the last row is redundant in the sense that  the input combinations it matches (011 and 111) are  covered by the second and fourth rows. ", "The product terms derived from rows two and four  are exactly the product terms we found by applying the reduction  identity.  Do we always want to use the simplest possible equation ", "as the template for our circuits?  Seems like that would minimize the circuit cost  and maximize performance, a good thing.  The simplified circuit is shown here. ", "Let‚Äôs look at how it performs when A is 1, B is 1,  and C makes a transition from 1 to 0.  Before the transition, C is 1 and we can see from  the annotated node values that it‚Äôs the bottom AND gate that‚Äôs ", "causing the Y output to be 1.  When C transitions to 0, the bottom AND gate turns off  and the top AND gate turns on, and, eventually the Y output ", "becomes 1 again.  But the turning on of the top AND is delayed by the tPD  of the inverter, so there‚Äôs a brief period of time where  neither AND gate is on, and the output momentarily becomes 0. ", "This short blip in Y‚Äôs value is called a glitch and it may  result in short-lived changes on many node values as it  propagates through other parts of the circuit.  All those changes consume power, so it ", "would be good to avoid these sorts of glitches if we can.  If we include the third product term BA in our implementation,  the circuit still computes the same long-term answer ", "as before.  But now when A and B are both high,  the output Y will be 1 independently  of the value of the C input.  So the 1-to-0 transition on the C input doesn‚Äôt cause a glitch ", "on the Y output.  If you recall the last section of the previous chapter,   When trying to minimize a sum-of-products expression using the reduction identity, our ", "goal is to find two product terms that can be written as one smaller product term, eliminating  the \"don't-care\" variable.  This is easy to do when two the product terms come from adjacent rows in the truth table. ", "For example, look at the bottom two rows in this truth table.  Since the Y output is 1 in both cases, both rows will be represented in the sum-of-products  expression for this function. ", "It's easy to spot the don't care variable: when C and B are both 1, the value of A isn't  needed to determine the value of Y.  Thus, the last two rows of the truth table can be represented by the single product term ", "(B AND C).  Finding these opportunities would be easier if we reorganized the truth table so that  the appropriate product terms were on adjacent rows. ", "That's what we've done in the Karnaugh map, K-map for short, shown on the right.  The K-map organizes the truth table as a two-dimensional table with its rows and columns labeled with ", "the possible values for the inputs.  In this K-map, the first row contains entries for when C is 0 and the second row contains  entries for when C is 1. ", "Similarly, the first column contains entries for when A is 0 and B is 0.  And so on.  The entries in the K-map are exactly the same as the entries in the truth table, they're ", "just formatted differently.  Note that the columns have been listed in a special sequence that's different from the  usual binary counting sequence.  In this sequence, called a Gray Code, adjacent labels differ in exactly one of their bits. ", "In other words, for any two adjacent columns, either the value of the A label changed, or  the value of the B label changed.  In this sense, the leftmost and rightmost columns are also adjacent. ", "We write the table as a two-dimensional matrix, but you should think of it as cylinder with  its left and right edges touching.  If it helps you visualize which entries are adjacent, the edges of the cube shows which ", "3-bit input values differ by only one bit.  As shown by the red arrows, if two entries are adjacent in the cube, they are also adjacent  in the table. ", "It's easy to extend the K-map notation to truth tables for functions with 4 inputs,  as shown here.  We've used a Gray code sequencing for the rows as well as the columns. ", "As before, the leftmost and rightmost columns are adjacent, as are the top and bottom rows.  Again, as we move to an adjacent column or an adjacent row, only one of the four input ", "labels will have changed.  To build a K-map for functions of 6 variables we'd need a 4x4x4 matrix of values.  That's hard to draw on the 2D page and it would be a challenge to tell which cells in ", "the 3D matrix were adjacent.  For more than 6 variables we'd need additional dimensions.  Something we can handle with computers, but hard for those of us who live in only a three-dimensional ", "space!  As a practical matter, K-maps work well for up to 4 variables, and we'll stick with that.  But keep in mind that you can generalize the K-map technique to higher dimensions. ", "So why talk about K-maps?  Because patterns of adjacent K-map entries that contain 1's will reveal opportunities  for using simpler product terms in our sum-of-products expression. ", "Let's introduce the notion of an implicant, a fancy name for a rectangular region of the  K-map where the entries are all 1's.  Remember when an entry is a 1, we'll want the sum-of-products expression to evaluate ", "to TRUE for that particular combination of input values.  We require the width and length of the implicant to be a power of 2, i.e., the region should ", "have 1, 2, or 4 rows, and 1, 2, or 4 columns.  It's okay for implicants to overlap.  We say that an implicant is a prime implicant if it is not completely contained in any other ", "implicant.  Each product term in our final minimized sum-of-products expression will be related to some prime implicant  in the K-map.  Let's see how these rules work in practice using these two example K-maps. ", "As we identify prime implicants, we'll circle them in red.  Starting with the K-map on the left, the first implicant contains the singleton 1-cell that's  not adjacent to any other cell containing 1's. ", "The second prime implicant is the pair of adjacent 1's in the upper right hand corner  of the K-map.  This implicant is has one row and two columns, meeting our constraints on an implicant's ", "dimensions.  Finding the prime implicants in the right-hand K-map is a bit trickier.  Recalling that the left and right columns are adjacent, we can spot a 2x2 prime implicant. ", "Note that this prime implicant contains many smaller 1x2, 2x1 and 1x1 implicants, but none  of those would be prime implicants since they are completely contained in the 2x2 implicant. ", "It's tempting draw a 1x1 implicant around the remaining 1, but actually we want to find  the largest implicant that contains this particular cell.  In this case, that's the 1x2 prime implicant shown here. ", "Why do we want to find the largest possible prime implicants?  We'll answer that question in a minute‚Ä¶  Each implicant can be uniquely identified by a product term, a Boolean expression that ", "evaluates to TRUE for every cell contained within the implicant and FALSE for all other  cells.  Just as we did for the truth table rows at the beginning of this chapter, we can use  the row and column labels to help us build the correct product term. ", "The first implicant we circled corresponds to the product term (not A) AND (not B)  AND C, an expression that evaluates to TRUE when A is 0, B is 0, and C is 1. ", "How about the 1x2 implicant in the upper-right hand corner?  We don't want to include the input variables that change as we move around in the implicant.  In this case the two input values that remain constant are C (which has the value 0) and ", "A (which has the value 1), so the corresponding product term is A AND (not C).  Here are the two product terms for the two prime implicants in the right-hand K-map. ", "Notice that the larger the prime implicant, the smaller the product term!  That makes sense: as we move around inside a large implicant, the number of inputs that  remain constant across the entire implicant is smaller. ", "Now we see why we want to find the largest possible prime implicants: they give us the  smallest product terms!  Let's try another example.  Remember that we're looking for the largest possible prime implicants. ", "A good way to proceed is to find some un-circled 1, and then identify the largest implicant  we can find that incorporates that cell.  There's a 2x4 implicant that covers the middle two rows of the table. ", "Looking at the 1's in the top row, we can identify two 2x2 implicants that include those  cells.  There's a 4x1 implicant that covers the right column, leaving the lonely 1 in the lower ", "left-hand corner of the table.  Looking for adjacent 1's and remembering the table is cyclic, we can find a 2x2 implicant  that incorporates this last un-circled 1. ", "Notice that we're always looking for the largest possible implicant, subject to constraint  that each dimension has to be either 1, 2 or 4.  It's these largest implicants that will turn out to be prime implicants. ", "Now that we've identified the prime implicants, we're ready to build the minimal sum-of-products  expression.  Here are two example K-maps where we've shown only the prime implicants needed to cover ", "all the 1's in the map.  This means, for example, that in the 4-variable map, we didn't include the 4x1 implicant covering  the right column.  That implicant was a prime implicant since it wasn't completely contained by any other ", "implicant, but it wasn't needed to provide a cover for all the ones in the table.  Looking at the top table, we'll assemble the minimal sum-of-products expression by including ", "the product terms for each of the shown implicants.  The top implicant has the product term A AND (not C), and the bottom implicant has the  product term (B AND C). ", "And we're done!  Why is the resulting equation minimal?  If there was some further reduction that could be applied, to produce a yet smaller product  term, that would mean there was a larger prime implicant that could have been circled in ", "the K-map.  Looking the bottom table, we can assemble the sum-of-products expression term-by-term.  There were 4 prime implicants, so there are 4 product terms in the expression. ", "And we're done.  Finding prime implicants in a K-map is faster and less error-prone that fooling around with  Boolean algebra identities.  Note that the minimal sum-of-products expression isn't necessarily unique. ", "If we had used a different mix of the prime implicants when building our cover, we would  have come up with different sum-of-products expression.  Of course, the two expressions are equivalent in the sense that they produce the same value ", "of Y for any particular combination of input values - they were built from the same truth  table after all.  And the two expressions will have the same number of operations. ", "So when you need to come with up a minimal sum-of-products expression for functions of  up to 4 variables, K-maps are the way to go!  We can also use K-maps to help us remove glitches from output signals. ", "Earlier in the chapter we saw this circuit and observed that when A was 1 and B was 1,  then a 1-to-0 transition on C might produce a glitch on the Y output as the bottom product ", "term turned off and the top product term turned on.  That particular situation is shown by the yellow arrow on the K-map, where we're transitioning  from the cell on the bottom row of the 1-1 column to the cell on the top row. ", "It's easy to see that we're leaving one implicant and moving to another.  It's the gap between the two implicants that leads to the potential glitch on Y. ", "It turns out there's a prime implicant that covers the cells involved in this transition  - shown here with a dotted red outline.  We didn't include it when building the original sum-of-products implementation since the other ", "two product terms provided the necessary functionality.  But if we do include that implicant as a third product term in the sum-of products, no glitch ", "can occur on the Y output.  To make an implementation lenient, simply include all the prime implicants in the sum-of-products  expression.  That will bridge the gaps between product terms that lead to potential output glitches. ", " The truth table we've been using as an example describes a very useful  combinational device called a 2-to-1 multiplexer.  A multiplexer, or MUX for short, selects one of its two input values ", "as the output value.  When the select input, marked with an S in the diagram, is 0, the  value on data input D0 becomes the value of the Y output. ", "When S is 1, the value of data input D1 is selected as the Y output  value.  MUXes come in many sizes, depending on the number of select inputs. ", "A MUX with K select inputs will choose between the values of 2^K data  inputs.  For example, here's a 4-to-1 multiplexer with 4 data inputs and 2 ", "select inputs.  Larger MUXes can be built from a tree of 2-to-1 MUXes, as shown here.  Why are MUXes interesting? ", "One answer is that they provide a very elegant and general way of  implementing a logic function.  Consider the 8-to-1 MUX shown on the right.  The 3 inputs ‚Äî A, B, and CIN ‚Äî are used as the three select signals ", "for the MUX.  Think of the three inputs as forming a 3-bit binary number.  For example, when they're all 0, the MUX will select data input 0, and  when they're all 1, the MUX will select data input 7, and so on. ", "How does make it easy to implement the logic function shown in the  truth table?  Well, we'll wire up the data inputs of the MUX to the constant values  shown in the output column in the truth table. ", "The values on the A, B and CIN inputs will cause the MUX to select the  appropriate constant on the data inputs as the value for the COUT output. ", "If later on we change the truth table, we don't have to redesign some   complicated sum-of-products circuit, we simply have to change the  constants on the data inputs.  Think of the MUX as a table-lookup device that can be reprogrammed to ", "implement, in this case, any three-input equation.  This sort of circuit can be used to create various forms of  programmable logic, where the functionality of the integrated circuit ", "isn't determined at the time of manufacture, but is set during a  programming step performed by the user at some later time.  Modern programmable logic circuits can be programmed to replace ", "millions of logic gates.  Very handy for prototyping digital systems before committing to the  expense of a custom integrated circuit implementation. ", "So MUXes with N select lines are effectively stand-ins for N-input  logic circuits.  Such a MUX would have 2^N data inputs.  They're useful for N up to 5 or 6, but for functions with more inputs, ", "the exponential growth in circuit size makes them impractical.  Not surprisingly, MUXes are universal as shown by these MUX-based  implementations for the sum-of-products building blocks. ", "There is some speculation that in molecular-scale logic technologies,  MUXes may be the natural gate, so it's good to know they can be used  to implement any logic function.  Even XOR is simple to implement using only 2-to-1 MUXes! ", " Here's a final logic implementation strategy using read-only memories.  This strategy is useful when you need to generate many different outputs from the same set of ", "inputs, a situation we'll see a lot when we get to finite state machines later on in the  course.  Where MUXes are good for implementing truth tables with one output column, read-only memories ", "are good for implementing truth tables with many output columns.  One of the key components in a read-only memory is the decoder which has K select inputs and ", "2^K data outputs.  Only one of the data outputs will be 1 (or HIGH) at any given time, which one is determined  by the value on the select inputs. ", "The Jth output will be 1 when the select lines are set to the binary representation of J.  Here's a read-only memory implementation for the 2-output truth table shown on the left. ", "This particular 2-output device is a full adder, which is used as a building block in  addition circuits.  The three inputs to the function (A, B, and CI) are connected to the select lines of a ", "3-to-8 decoder.  The 8 outputs of the decoder run horizontally in the schematic diagram and each is labeled  with the input values for which that output will be HIGH. ", "So when the inputs are 000, the top decoder output will be HIGH and all the other decoder  outputs LOW.  When the inputs are 001 - i.e., when A and B are 0 and CI is 1 - the second decoder output ", "will be HIGH.  And so on.  The decoder outputs control a matrix of NFET pulldown switches.  The matrix has one vertical column for each output of the truth table. ", "Each switch connects a particular vertical column to ground, forcing it to a LOW value  when the switch is on.  The column circuitry is designed so that if no pulldown switches force its value to 0, ", "its value will be a 1.  The value on each of the vertical columns is inverted to produce the final output values.  So how do we use all this circuitry to implement the function described by the truth table? ", "For any particular combination of input values, exactly one of the decoder outputs will be  HIGH, all the others will be low.  Think of the decoder outputs as indicating which row of the truth table has been selected ", "by the input values.  All of the pulldown switches controlled by the HIGH decoder output will be turned ON,  forcing the vertical column to which they connect LOW. ", "For example, if the inputs are 001, the decoder output labeled 001 will be HIGH.  This will turn on the circled pulldown switch, forcing the S vertical column LOW. ", "The COUT vertical column is not pulled down, so it will be HIGH.  After the output inverters, S will be 1 and COUT will be 0, the desired output values. ", "By changing the locations of the pulldown switches, this read-only memory can be programmed  to implement any 3-input, 2-output function. ", "For read-only memories with many inputs, the decoders have many outputs and the vertical  columns in the switch matrix can become quite long and slow.  We can reconfigure the circuit slightly so that some of the inputs control the decoder ", "and the other inputs are used to select among multiple shorter and faster vertical columns.  This combination of smaller decoders and output MUXes is quite common in these sorts of memory ", "circuits.  Read-only memories, ROMs for short, are an implementation strategy that ignores the structure  of the particular boolean expression to be implemented.  The ROM's size and overall layout are determined only by the number of inputs and outputs. ", "Typically the switch matrix is fully populated, with all possible switch locations filled  with an NFET pulldown.  A separate physical or electrical programming operation determines which switches are actually ", "controlled by the decoder lines.  The other switches are configured to be in the permanently off state.  If the ROM has N inputs and M outputs, then the switch matrix will have 2^N rows and M ", "output columns, corresponding exactly to the size of the truth table.  As the inputs to the ROM change, various decoder outputs will turn off and on, but at slightly ", "different times.  As the decoder lines cycle, the output values may change several times until the final configuration  of the pulldown switches is stable. ", "So ROMs are not lenient and the outputs may show the glitchy behavior discussed earlier.  Whew!  This has been a whirlwind tour of various circuits we can use to implement logic functions. ", "The sum-of-products approach lends itself nicely to implementation with inverting logic.  Each circuit is custom-designed to implement a particular function and as such can be made  both fast and small. ", "The design and manufacturing expense of creating such circuits is worthwhile when you need  high-end performance or are producing millions of devices.  MUX and ROM circuit implementations are mostly independent of the specific function to be ", "implemented.  That's determined by a separate programming step, which may be completed after the manufacture  of the devices.  They are particularly suited for prototyping, low-volume production, or devices where the ", "functionality may need to be updated after the device is out in the field. "], "vid_duration": [13.14, 15.51, 13.949, 12.221, 10.72, 15.31, 11.97, 13.04, 10.881, 15.819, 12.15, 11.38, 13.11, 10.2, 11.67, 12.06, 11.61, 13.31, 12.26, 13.14, 13.21, 13.09, 11.3, 13.87, 10.91, 15.58, 11.27, 15.389, 14.861, 10.28, 13.89, 15.04, 15.47, 13.35, 12.44, 12.87, 10.579, 10.761, 10.09, 10.619, 12.99, 13.74, 11.341, 11.699, 12.301, 13.421, 12.769, 11.461, 10.919, 10.62, 12.571, 11.839, 15.681, 10.95, 12.0, 10.109, 10.791, 12.572, 12.088, 10.98, 11.48, 12.54, 10.389, 10.801, 10.449, 11.111, 11.35, 11.199, 14.411, 12.069, 13.5, 10.641, 10.32, 12.079, 10.82, 10.982, 13.59, 11.279, 11.062, 13.38, 12.299, 13.091, 11.22, 11.659, 11.371, 12.28, 10.96, 11.5, 10.6, 12.24, 11.2, 13.83, 12.94, 10.34, 12.6, 12.859, 10.101, 10.16, 10.85, 10.08, 12.53, 13.5, 11.12, 11.3, 14.44, 11.01, 11.64, 11.729, 12.521, 10.86, 13.899, 15.121, 10.259, 10.23, 12.35, 10.48, 11.89, 10.58, 13.91, 11.47, 12.35, 10.93, 13.09, 11.42, 10.63, 11.9, 11.72, 13.03, 11.54, 10.98, 11.15, 10.92, 12.69, 11.91, 14.139, 11.701, 10.93, 12.83, 13.807, 12.219, 11.389, 13.402, 11.599, 10.05, 10.62, 10.48, 15.079, 12.61, 11.18, 11.211, 10.28, 11.29, 12.85, 11.0, 13.85, 12.16, 12.22, 10.0, 13.8, 14.45, 13.0, 10.12, 12.99, 11.73, 13.65, 11.14, 15.15, 13.02, 14.63, 13.06, 12.08, 12.83, 13.16, 12.229, 13.421, 12.66, 10.57, 13.97, 10.25, 11.52, 13.62, 14.21, 14.38, 11.59, 10.55, 11.55, 10.78, 15.58, 10.56, 12.179, 10.331, 13.487, 13.08, 10.689, 10.661, 10.42, 10.669, 13.371, 15.019, 12.631, 10.06, 13.0, 10.54, 11.069, 11.431, 14.52, 11.829, 14.971, 10.07, 11.13, 10.39, 10.55, 12.78, 12.729, 11.71, 14.54, 13.371, 12.279, 13.72, 12.071, 11.509, 13.22, 11.051, 10.46, 14.59, 11.27, 15.609, 12.02, 13.98, 11.561, 10.38, 12.739, 12.771, 14.53, 11.9, 5.505], "stet": [[0, 13.14], [13.14, 28.65], [28.65, 42.599], [42.599, 54.81999999999999], [54.81999999999999, 65.53999999999999], [65.53999999999999, 80.85], [80.85, 92.82], [92.82, 105.85999999999999], [105.85999999999999, 116.74099999999999], [116.74099999999999, 132.55999999999997], [132.55999999999997, 144.70999999999998], [144.70999999999998, 156.08999999999997], [156.08999999999997, 169.2], [169.2, 179.39999999999998], [179.39999999999998, 191.06999999999996], [191.06999999999996, 203.12999999999997], [203.12999999999997, 214.73999999999995], [214.73999999999995, 228.04999999999995], [228.04999999999995, 240.30999999999995], [240.30999999999995, 253.44999999999993], [253.44999999999993, 266.6599999999999], [266.6599999999999, 279.7499999999999], [279.7499999999999, 291.0499999999999], [291.0499999999999, 304.9199999999999], [304.9199999999999, 315.8299999999999], [315.8299999999999, 331.4099999999999], [331.4099999999999, 342.6799999999999], [342.6799999999999, 358.0689999999999], [358.0689999999999, 372.9299999999999], [372.9299999999999, 383.20999999999987], [383.20999999999987, 397.09999999999985], [397.09999999999985, 412.1399999999999], [412.1399999999999, 427.6099999999999], [427.6099999999999, 440.9599999999999], [440.9599999999999, 453.3999999999999], [453.3999999999999, 466.2699999999999], [466.2699999999999, 476.84899999999993], [476.84899999999993, 487.60999999999996], [487.60999999999996, 497.69999999999993], [497.69999999999993, 508.31899999999996], [508.31899999999996, 521.309], [521.309, 535.049], [535.049, 546.39], [546.39, 558.0889999999999], [558.0889999999999, 570.39], [570.39, 583.811], [583.811, 596.58], [596.58, 608.041], [608.041, 618.96], [618.96, 629.58], [629.58, 642.1510000000001], [642.1510000000001, 653.9900000000001], [653.9900000000001, 669.6710000000002], [669.6710000000002, 680.6210000000002], [680.6210000000002, 692.6210000000002], [692.6210000000002, 702.7300000000002], [702.7300000000002, 713.5210000000003], [713.5210000000003, 726.0930000000003], [726.0930000000003, 738.1810000000003], [738.1810000000003, 749.1610000000003], [749.1610000000003, 760.6410000000003], [760.6410000000003, 773.1810000000003], [773.1810000000003, 783.5700000000003], [783.5700000000003, 794.3710000000003], [794.3710000000003, 804.8200000000003], [804.8200000000003, 815.9310000000003], [815.9310000000003, 827.2810000000003], [827.2810000000003, 838.4800000000002], [838.4800000000002, 852.8910000000002], [852.8910000000002, 864.9600000000002], [864.9600000000002, 878.4600000000002], [878.4600000000002, 889.1010000000001], [889.1010000000001, 899.4210000000002], [899.4210000000002, 911.5000000000001], [911.5000000000001, 922.3200000000002], [922.3200000000002, 933.3020000000001], [933.3020000000001, 946.8920000000002], [946.8920000000002, 958.1710000000002], [958.1710000000002, 969.2330000000002], [969.2330000000002, 982.6130000000002], [982.6130000000002, 994.9120000000001], [994.9120000000001, 1008.0030000000002], [1008.0030000000002, 1019.2230000000002], [1019.2230000000002, 1030.8820000000003], [1030.8820000000003, 1042.2530000000004], [1042.2530000000004, 1054.5330000000004], [1054.5330000000004, 1065.4930000000004], [1065.4930000000004, 1076.9930000000004], [1076.9930000000004, 1087.5930000000003], [1087.5930000000003, 1099.8330000000003], [1099.8330000000003, 1111.0330000000004], [1111.0330000000004, 1124.8630000000003], [1124.8630000000003, 1137.8030000000003], [1137.8030000000003, 1148.1430000000003], [1148.1430000000003, 1160.7430000000002], [1160.7430000000002, 1173.602], [1173.602, 1183.7030000000002], [1183.7030000000002, 1193.8630000000003], [1193.8630000000003, 1204.7130000000002], [1204.7130000000002, 1214.7930000000001], [1214.7930000000001, 1227.323], [1227.323, 1240.823], [1240.823, 1251.943], [1251.943, 1263.243], [1263.243, 1277.683], [1277.683, 1288.693], [1288.693, 1300.333], [1300.333, 1312.0620000000001], [1312.0620000000001, 1324.583], [1324.583, 1335.443], [1335.443, 1349.3419999999999], [1349.3419999999999, 1364.463], [1364.463, 1374.722], [1374.722, 1384.952], [1384.952, 1397.302], [1397.302, 1407.782], [1407.782, 1419.672], [1419.672, 1430.252], [1430.252, 1444.162], [1444.162, 1455.632], [1455.632, 1467.982], [1467.982, 1478.912], [1478.912, 1492.002], [1492.002, 1503.422], [1503.422, 1514.0520000000001], [1514.0520000000001, 1525.9520000000002], [1525.9520000000002, 1537.6720000000003], [1537.6720000000003, 1550.7020000000002], [1550.7020000000002, 1562.2420000000002], [1562.2420000000002, 1573.2220000000002], [1573.2220000000002, 1584.3720000000003], [1584.3720000000003, 1595.2920000000004], [1595.2920000000004, 1607.9820000000004], [1607.9820000000004, 1619.8920000000005], [1619.8920000000005, 1634.0310000000004], [1634.0310000000004, 1645.7320000000004], [1645.7320000000004, 1656.6620000000005], [1656.6620000000005, 1669.4920000000004], [1669.4920000000004, 1683.2990000000004], [1683.2990000000004, 1695.5180000000005], [1695.5180000000005, 1706.9070000000004], [1706.9070000000004, 1720.3090000000004], [1720.3090000000004, 1731.9080000000004], [1731.9080000000004, 1741.9580000000003], [1741.9580000000003, 1752.5780000000002], [1752.5780000000002, 1763.0580000000002], [1763.0580000000002, 1778.1370000000002], [1778.1370000000002, 1790.747], [1790.747, 1801.9270000000001], [1801.9270000000001, 1813.1380000000001], [1813.1380000000001, 1823.4180000000001], [1823.4180000000001, 1834.708], [1834.708, 1847.558], [1847.558, 1858.558], [1858.558, 1872.408], [1872.408, 1884.568], [1884.568, 1896.788], [1896.788, 1906.788], [1906.788, 1920.588], [1920.588, 1935.038], [1935.038, 1948.038], [1948.038, 1958.158], [1958.158, 1971.148], [1971.148, 1982.878], [1982.878, 1996.528], [1996.528, 2007.6680000000001], [2007.6680000000001, 2022.8180000000002], [2022.8180000000002, 2035.8380000000002], [2035.8380000000002, 2050.4680000000003], [2050.4680000000003, 2063.5280000000002], [2063.5280000000002, 2075.608], [2075.608, 2088.438], [2088.438, 2101.598], [2101.598, 2113.8269999999998], [2113.8269999999998, 2127.2479999999996], [2127.2479999999996, 2139.9079999999994], [2139.9079999999994, 2150.4779999999996], [2150.4779999999996, 2164.4479999999994], [2164.4479999999994, 2174.6979999999994], [2174.6979999999994, 2186.2179999999994], [2186.2179999999994, 2199.8379999999993], [2199.8379999999993, 2214.0479999999993], [2214.0479999999993, 2228.4279999999994], [2228.4279999999994, 2240.0179999999996], [2240.0179999999996, 2250.5679999999998], [2250.5679999999998, 2262.118], [2262.118, 2272.898], [2272.898, 2288.478], [2288.478, 2299.038], [2299.038, 2311.217], [2311.217, 2321.5480000000002], [2321.5480000000002, 2335.0350000000003], [2335.0350000000003, 2348.1150000000002], [2348.1150000000002, 2358.804], [2358.804, 2369.465], [2369.465, 2379.885], [2379.885, 2390.554], [2390.554, 2403.925], [2403.925, 2418.944], [2418.944, 2431.575], [2431.575, 2441.6349999999998], [2441.6349999999998, 2454.6349999999998], [2454.6349999999998, 2465.1749999999997], [2465.1749999999997, 2476.2439999999997], [2476.2439999999997, 2487.6749999999997], [2487.6749999999997, 2502.1949999999997], [2502.1949999999997, 2514.024], [2514.024, 2528.995], [2528.995, 2539.065], [2539.065, 2550.195], [2550.195, 2560.585], [2560.585, 2571.135], [2571.135, 2583.9150000000004], [2583.9150000000004, 2596.6440000000002], [2596.6440000000002, 2608.3540000000003], [2608.3540000000003, 2622.8940000000002], [2622.8940000000002, 2636.2650000000003], [2636.2650000000003, 2648.5440000000003], [2648.5440000000003, 2662.264], [2662.264, 2674.335], [2674.335, 2685.844], [2685.844, 2699.064], [2699.064, 2710.115], [2710.115, 2720.575], [2720.575, 2735.165], [2735.165, 2746.435], [2746.435, 2762.044], [2762.044, 2774.064], [2774.064, 2788.044], [2788.044, 2799.605], [2799.605, 2809.985], [2809.985, 2822.724], [2822.724, 2835.4950000000003], [2835.4950000000003, 2850.0250000000005], [2850.0250000000005, 2861.9250000000006], [2861.9250000000006, 2867.4300000000007]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [578, 934, 1380, 1680, 2337, 2531, 2869]}
{"example_id": "mit153@@MITRES6_012S18_L20_300k", "text": [" In this lecture, we provide a quick introduction into the  conceptual framework of classical statistics.  We use the words \"classical\" to make the distinction from ", "the Bayesian framework that we have been using so far.  Recall that in the Bayesian framework, unknown quantities  are viewed as random variables that have a certain prior ", "distribution.  In contrast, in the classical setting an unknown quantity is  viewed as a non-random constant that just happens to  be unknown. ", "We can still carry out estimation without assuming a  prior for the unknown quantity.  For example, if the unknown theta is the mean of a certain  distribution, we can generate many samples from that ", "distribution and form the sample mean.  The weak law of large numbers then tells us that this  estimate will approach in the limit as n increases the true ", "value of theta.  After going through this argument, we will then take  the occasion to introduce some terminology that is often used  in connection with classical estimation methods. ", "Now, the sample mean provides us a point estimate for the  unknown theta, but does not tell us how accurate that  estimate is.  To give a sense of the accuracy involved, we ", "introduce the concept of a confidence interval, which is  an interval that has high probability of containing the  true theta.  In general, it is a common practice to report not just ", "estimates, but also confidence intervals.  But as we will discuss, one has to be careful in  interpreting what exactly a confidence interval tells us. ", "We will see that we can easily calculate confidence intervals  using the central limit theorem.  And we will discuss in some detail some extra steps that  need to be taken if we do not know the variance of the ", "random variables involved.  We will then continue in the direction of greater  generality.  We will see that by repeated use of various sample means, ", "we can also estimate more complicated quantities, such  as, for example, the correlation coefficient  between two random variables.  We will conclude by introducing a general ", "estimation methodology, the so-called maximum likelihood  estimation method.  This is a method that applies always, even when the unknown ", "parameter of interest cannot be interpreted as an  expectation.  It is a universally-applicable method.  And fortunately, has some very desirable properties. ", "  In this segment we provide a high level introduction into  the conceptual framework of classical statistics.  In order to get there, it is better to start from what we ", "already know and then make a comparison.  We already know how to make inferences by just using the  Bayes rule.  In this setting, we have an unknown quantity, theta, which ", "we model as a random variable.  And so in particular, it's going to have a probability  distribution.  And then we make some observations.  And those observations are modeled as random variables. ", "And typically we are given the conditional distribution of  the observations given the unknown variable.  So these two distributions are the starting points, and then ", "we do some calculations.  And we use the Bayes rule.  And we find the posterior distribution of theta given  the observations.  And this tells us all that there is to know about the ", "unknown quantity, theta, given the observations  that we have made.  What is important in this framework is that theta is  treated as a random variable. ", "And so it has a distribution of its own.  And that's our starting point.  These are our prior beliefs about theta before we obtain  any observations. ", "However, one can think of situations where theta maybe  cannot be modeled as a random variable.  Suppose that theta is at some universal, physical constant. ", "For example the mass of the electron.  Does it make sense to think of that quantity as random?  And how do we come up with a probability distribution for  that quantity? ", "One can argue that in certain situations one should not  think of unknown quantities as being random, but rather they  are just unknown constants. ", "They are absolute constants.  It just happens that we do not know their value.  Or there may be other situations in which even ", "though we may think that there is something random that  determines theta, we are reluctant to postulate any  prior distribution.  We do not want to impose any biases. ", "And that leads us to the classic statistical framework  in which unknown quantities are treated as constants, not  as random variables.  Pictorially the setting is as follows. ", "There's an unknown quantity that we wish to estimate.  And we make some observations, X. Those  observations are random.  And they're drawn according to a probability distribution. ", "And that probability distribution depends, or  rather is affected, by that unknown quantity.  So for example, for one value of theta, the distribution of ", "the X's might be this one.  And for another value of theta, the distribution of the  X's could be a different one.  And we're trying to guess what theta is. ", "Which in some ways is the question, do my data come from  this distribution or do they come from that distribution?  In order to make a choice of theta, what we do is we take ", "the data and we process them.  And after we process them, we come up with our estimate--  or rather estimator. ", "What is the estimator?  We take the data, and we calculate a  function of the data.  That's what it means to process the data. ", "And that function is our theta hat.  Now this function, our data processing mechanism, is what  we can call an estimator.  But quite often, or usually, we also use the same ", "terminology to call theta hat itself an estimator.  Now notice that theta hat is a function of the random  variable X. So theta hat is actually a random variable. ", "And that's why we denote it with an uppercase theta.  On the other hand, after you obtain some concrete data,  little x, which are the realized values of the random ", "variable capital X. Then we can apply your estimator to  that particular input, and we compute a specific value-- ", "call it theta hat lower case.  And that quantity we call an estimate.  So this is a useful distinction. ", "Always, with random variables, we want to distinguish between  the random variable itself indicated by uppercase letters  and the values of the random variable, which are indicated  with lower case letters. ", "Similarly, the estimator is a random variable.  It's essentially a description of how we generate estimates.  Whereas the realized value, once we have some specific ", "observations at hand--  that's what we call an estimate.   Now let me continue with a few comments.  The picture, or the setting, that I have here suggests that ", "X is just one variable and theta is one variable.  But we can have the same framework, even if X and theta  are multi-dimensional.  For example, X might consist of several random variables. ", "And theta may be a parameter that consists of multiple  components.  Now you may notice that this notation that we're using here  is a little different from our traditional notation which was ", "of this form.   In what ways is it different?  The main difference is that here, theta is ", "not a random variable.  Theta is just a parameter.  So what we're dealing with, here, is just an ordinary-- ", "not a conditional distribution.  It's an ordinary distribution that happens to involve,  inside its description, some parameters theta. ", "Just to emphasize the point that these are not conditional  probabilities, because theta is not a random variable, we  use a semicolon instead of using a bar. ", "And since theta is not a random variable, we do not  include it in the subscript down here when we talk about  the classical setting.  The best way to think of the situation mathematically is ", "that we're essentially dealing with multiple candidate  models, as in this picture.  This could be one possible model of X. This could be ", "another possible model of X. We have one such model for  each possible value of theta.  And if, for example, I were to get data points that sit down ", "here, then a reasonable way to make an inference could be to  say, these data are extremely unlikely to have been  generated according to this model. ", "This data are quite likely to have been  generated by this model.  So I'm going to pick this particular model.  So even though we're not treating theta as a random  variable, and we do not have the Bayes rule in our hands-- ", "we can still see, at least from this trivial example,  that there should be a reasonable way of making  inferences.  And let me close with some comments on the different ", "types of problems that we may encounter in classical  statistics.  One class of problems are so-called hypothesis testing  problems in which we're asked to choose between two ", "candidate models.  So the unknown parameter, as in this example, can take one  of two values.  So think of a machine that produces coins.  And coins are either fair or they have a ", "very specific bias.  You want to flip the coin, maybe multiple times, and then  decide whether you're dealing with a coin of this  type or of that type. ", "There's another type of hypothesis testing problems  which is a little more complicated, for  example this one.  We have one hypothesis which says that my coin is fair, ", "versus an alternative hypothesis in  which my coin is unfair.  But notice that this hypothesis actually includes  many possible scenarios.  There are many possible values of theta under which this ", "hypothesis would be true.  We will not deal with problems of this kind in this segment,  or in this lecture sequence.  Instead we will focus exclusively ", "on estimation problems.  In estimation problems, the unknown parameter, theta, is  either continuous or can take one of many, many values. ", "What we want to do is to design an estimator--  a way of processing the data--  that comes up with estimates that are good. ", "What does it mean that an estimate is good?  An estimate would be good if the resulting value of the  estimation error--  that is the difference between the estimated value and the ", "true value--  if that difference is small.  You want to keep that difference  small in some sense.  Well one may need a criterion of what it means to be small. ", "And whether we want this in expectation, or with high  probability, and so on.  This statement, to keep the estimation error small, can be  interpreted in various ways. ", "And because of that reason, there's no single approach to  the problem of designing a good estimator.  And this is something that happens more generally in  classical statistics. ", "Typically problems do not admit a single best approach.  They do not admit unique answers.  Reasonable people can come up with different methodologies ", "for approaching the same problem.  And there is a little bit of an element of an  art involved here.  In general, one wants to come up with reasonable methods ", "that will have good properties.  And we will see some examples of what this may mean.  But again, I'm emphasizing that there is  no single best method. ", "So whereas the Bayes rule is a completely unambiguous way for  making inferences, here, in the context of classical  statistics, there will be some freedom as to what approaches ", "one might take.    Let us now discuss a little bit the simplest estimation  problem that there is, the problem of estimating the mean  of a certain probability distribution, and we will take ", "this occasion to introduce some additional terminology  and discuss some desirable properties of estimators.  So the context is as follows.  We have n random variables that are independent, and ", "they're identically distributed.  They are drawn from some distribution that has a  certain mean theta and some variance.  We assume that we do not know the value of the mean, and we ", "want to estimate it.  The most natural way of estimating the mean is to form  the sample mean, that is, we take the n observations and  take their average. ", "Notice, that this quantity, the sample mean or, in this  case, it is the estimator that we're using, is a random  variable because its value is determined by the values of ", "the random variables X1 up to Xn.  Let us discuss some properties of this estimator.  The first property is that the expected value of this ", "estimator is equal to the true mean.  This is because the expected value of each one of the Xs is  theta, and therefore, the expected value of this ratio  is theta as well. ", "Now, this is a relation that's true for all  possible values of theta.   Let us appreciate the content of this statement. ", "Let us think what this expectation actually is.  More generally, suppose that we're dealing with some  estimator, which is some function of the data. ", "Then, the expected value of this estimator is using the  expected value rule, and assuming that we're dealing ", "with a discrete random variable X, the expected value  of theta hat is determined as follows.  ", "And so we see that the expected value for estimator  depends, or is affected, by what the true  value of theta is.  So this is a quantity that generally depends on theta. ", "And what we want in order to have a so-called unbiased  estimator is that no matter what theta is, this  expectation evaluates to the true unknown ", "value equal to theta.  In general, having this property, having an unbiased  estimator, is a desirable one.  We do not want our estimates to be systematically high or ", "systematically low, no matter what the true  value of theta is.  A second property of the sample mean  estimator is the following.  By the weak law of large numbers, we know that the ", "sample mean converges to the true mean in the sense of  convergence in probability.  Once more, this is a property that's true, no matter what ", "the underlying unknown value little theta is.  When this is true, this convergence is true, for all  values of little theta, then we say that our estimator is ", "consistent or that we have consistency.  Having a consistent estimator is definitely a  very desirable property.  We would like, when we obtain more and more data, that our ", "estimator will give us the correct value.  Finally, we would like to say something about the size of  the estimation error.  This is measured-- ", "one way of measuring it, but which is the most common, it's  measured in terms of the mean squared error.  So theta is the unknown value.  This is our estimator. ", "This is the error.  We square the error, and we take the average.  What we've got here for this specific example of the sample  mean estimator is the following. ", "Since it is unbiased, we have a random variable minus the  mean of that random variable, so this is just the variance  of the estimator. ", " And for the sample mean, we know that its variance is  sigma squared over n. ", "So this gives us some very specific knowledge about how  the mean squared error behaves as we change n.  In this particular example, the mean squared error did not ", "depend on theta.  It's the same no matter what the true theta is.  But in other situations and with other estimators, you  might actually obtain here a function of theta. ", "  In this segment, we discuss a little more the  mean squared error.  Consider some estimator.  It can be any estimator, not just the sample mean. ", "We can decompose the mean squared error as  a sum of two terms.  Where does this formula come from?  Well, we know that for any random variable Z, this ", "formula is valid.  And if we let Z be equal to the difference between the  estimator and the value that we're trying to estimate, then ", "we obtain this formula here.  The expected value of our random variable Z squared is  equal to the variance of that random variable plus the  square of its mean. ", "Let us now rewrite these two terms in a  more suggestive way.  We first notice that theta is a constant.  When you add or subtract the constant from a random  variable, the variance does not change. ", "So this term is the same as the variance of theta hat.  This quantity here, we will call it  the bias of the estimator. ", "It tells us whether theta hat is systematically above or  below than the unknown parameter theta that we're  trying to estimate.  And using this terminology, this term here is just equal ", "to the square of the bias.  So the mean squared error consists of two components,  and these capture different aspects of an estimator's  performance. ", "Let us see what they are in a concrete setting.  Suppose that we're estimating the unknown mean of some  distribution, and that our estimator is the sample mean. ", "In this case, the mean squared error is the variance, which  we know to be sigma squared over n, plus the bias term. ", "But we know that the sample mean is unbiased.  The expected value of the sample mean is equal to the  unknown mean.  And so the bias contribution is equal to zero. ", "Now, for the sake of a comparison, let us consider a  somewhat silly estimator which ignores the data all together,  and always gives you an estimate of zero. ", "In this case, the mean squared error is as follows.  Since our estimator is just a constant, its variance is  going to be equal to zero. ", "On the other hand, since theta hat is zero, this term here is  just the constant, theta, squared. ", "And this gives us the corresponding  mean squared error.  Let us now compare the two estimators.  We will plot the mean squared error as a function of the ", "unknown parameter, theta.  For the sample mean estimator, the mean squared error is  constant, it does not depend on theta, and is equal to this ", "value, sigma squared over n.  On the other hand, for the zero estimator, the mean  squared error is equal to theta squared. ", "How do they compare?  Which one is better?  At this point, there's no way to say that one is  better than the other.  For some theta, the sample mean has a smaller mean ", "squared error.  But for other theta, the zero estimator has a smaller mean  squared error.  But we do not know where the true value of theta is. ", "It could be anything.  So we cannot say that one is better than the other.  Of course, we know that the sample mean is  a consistent estimator. ", "As n goes to infinity, it will give you the  true value of theta.  And this is a very desirable properties that the zero  estimator does not have.  But if n is moderate, the situation is less clear. ", "If we have some good reason to expect that the true value of  theta is somewhere in the vicinity of zero, then the  zero estimator might be a better one, because it then ", "will achieve a smaller mean squared error.  But in a classical statistical framework, there is no way to  express a belief of this kind. ", "In contrast, if we were following a Bayesian approach,  you could provide a prior distribution for theta that  would be highly concentrated around zero.  This would express your beliefs about theta, and would ", "provide you with the guidance to choose between the two  estimators, or maybe suggest an even better estimator.  In any case, going back to this formula, this quantity, ", "the variance of the estimator plays an important role in the  analysis of different estimators.  And the more intuitive variant of this quantity is its square ", "root, which is the standard deviation of the estimator,  and is usually called the standard  error of the estimator.  We can interpret the standard error as follows. ", "We have the true value of theta.   Then on day one, we collect some data, we perform the  estimation procedure, and we come up with an estimate. ", "On day two, we do the same thing, but independently.  We collect a new set of data, and we come up  with another estimate.  And so on. ", "We do this many times.  We use different data sets to come up  with different estimates.  And because of the randomness in the data, these estimates ", "may be all over the place.  Well, the standard error tells us how spread out all these  estimates will be.  It is the standard deviation of this ", "collection of estimates.  Having a large standard error means that our estimation  procedure is quite noisy, and that our estimates have some ", "inherent randomness.  And therefore, also have a lack of accuracy.  That is, they cannot be trusted too much.  That's the case of a large standard error. ", "Conversely, a small standard error would tell us that the  estimates would tend to be concentrated  close to each other.  As such, the standard error is a very useful piece of ", "information to have.  Besides designing and implementing an estimator, one  usually also tries to find a way to calculate and report ", "the associated standard error.    In this segment we introduce the concept of  a confidence interval.  The starting point is that an estimate, the value of an ", "estimator, does not tell the whole story.  One option is to also provide the standard error of the  estimator, but a more common practice is to report a  confidence interval. ", "What is that?  We'll introduce the notion of a confidence  interval through a story.  You're working for a polling company.  You carry out a poll, and then you go and report to your boss ", "that my estimate is this particular number.  And then your boss says, I appreciate the five digit ", "accuracy, but are your conclusions that accurate?  You go back to your desk, you do some more calculations, and  then you tell your boss, here is a 95% confidence interval. ", " Your boss tells you, that looks great, but what does  that exactly mean?  You go back to your textbook, you pull out the definition, ", "and you reply as follows.  Well, a 95% confidence interval--  so here I am letting alpha to be 5%-- ", "a 95% confidence interval is an interval that has the  following property.  That the unknown value of the parameter that we're trying to ", "estimate falls inside this interval with  probability at least 95%.  And if you wish, I could also let alpha be equal to 1%, in ", "which case I could give you a 99% confidence interval.  Your boss replies, no, that sounds good.  A 95% interval sounds fine. ", "And your boss goes out to the press, holds a press  conference, and reports that the true value of the  parameter lies inside this range, inside the reported ", "confidence interval with probability at least 95%.   Does this statement make sense? ", "Actually, no.  This statement is the most common misconception of what a  confidence interval is.  To see why this statement does not make ", "sense, look at it carefully.  We're talking about the probability of something.  But that something does not involve anything random.  0.3 and 0.52 are just numbers. ", "And theta is also a number which we do not know what it  is, but it is not random.  It is a constant.  So this statement is incorrect on a purely syntactic basis. ", "I mean the true parameter theta either is inside this  interval, or it is not.  But there's nothing random here, and so this statement  does not make sense. ", "Instead, let us look carefully at this definition.  This statement does make sense because it  involves random variables.  The lower and the upper end of the confidence interval are ", "quantities that are determined by the data, and therefore  they are random.  So we do have random variables in here.  And so it makes sense to talk about probabilities. ", "To really understand what's going on, think as follows.  We're dealing with a poll that is trying to estimate some  unknown value, theta. ", "You carry out the poll, and you come up with a confidence  interval based on the data.  You might be lucky, and your confidence interval happens to  capture the true parameter. ", "You carry the poll one more time, maybe on another day.  You come up with another confidence interval.  And you're again lucky, and it captures the true parameter.  You carry it on another day, and you come up with a ", "confidence interval.  And maybe the data that you got were kind of skewed.  You were unlucky, and your confidence interval does not  capture the true parameter. ", "Having a 95% confidence interval means that 95% of the  time, 95% of the polls that you carry out will capture the ", "true parameter.  So the word 95% really talks about your method of  constructing confidence intervals.  It's a method that 95% of the time will ", "capture the true parameter.  It is not a statement about the actual numbers that you  are reporting on one specific poll. ", "So it is important to keep this in mind, and to always  interpret confidence intervals the correct way.  So how does one come up with confidence intervals? ", "The most common method is based on normal  approximations, as we will be seeing next.    We now discuss how to come up with confidence intervals when ", "we try to estimate the unknown mean of some random variable,  or of some distribution, using the  sample mean as our estimator.  So here X1 up to Xn are independent, identically ", "distributed random variables that are drawn from a  distribution that has a certain mean theta, the  quantity that we want to estimate, and some variance  sigma squared. ", "Let us say that we want to construct a  95% confidence interval.  Our starting point will be the fact that the sample mean,  according to the central limit theorem, can be described ", "approximately using normal distributions.  And we look up at the normal table, and we observe the  following--  that if we take a standard normal random variable, then ", "there is probability, 97.5% of falling below this number,  1.96, which means that there is probability 2 1/2% of ", "falling above that number.  And by symmetry, the probability of falling below  minus 1.96 is also 2 1/2%. ", "This means that this middle interval here has probability  95%, and we exploit this fact as follows.  ", "If we take the sample mean, subtract the true mean, and  then divide by the standard deviation of the sample mean,  then we obtain a random variable, which is ", "approximately a standard normal.  Therefore, what we have here is the probability of an  approximately standard normal random variable.  Or actually, its absolute value falling below 1.96. ", "This is just the event that our standard normal falls  inside this middle interval here, according to this entry  from the normal tables and the previous discussion, this ", "probability is going to be approximately 95%.   And now we take this statement, send this term to ", "the other side of the inequality, and then interpret  what it means for an absolute value to  be less than something.  And we obtain an equivalent statement. ", "This event here is algebraically identical to the  event that we have up there, and this provides us with the  desired confidence interval.  We think of this quantity here as the lower end of the ", "confidence interval.  This quantity here is the upper end of  the confidence interval.  And this statement tells us that there is probability  approximately equal to 95% that the confidence interval ", "constructed this way contains the true value  of the unknown parameter.  So this is how we obtain a 95% confidence interval. ", "If instead we wanted a 90% confidence interval, we would  proceed in more or less in the same way.  Here, we would want to have the number 0.95. ", "Why is that?  We want this middle interval to have probability 90%, which  means that we want to have probability 5% at ", "each one of the tails.   And then we look up at the normal tables, and we find  that the entry that gives us probability 95% of being below ", "that value is 1.645.  So if we use 1.645 in place of 1.96, we obtain a 90%  confidence interval, and similarly for other choices. ", "For example, if we want a 99% confidence interval.  There's only one issue that's left to discuss, and this is  the following.  In order to obtain numerical values for the endpoints of ", "the confidence interval, we need to know sigma, the  standard deviation of the random  variables that we are observing.  But if we do not know the value of sigma, then we may ", "have to do some additional work.    By this time, we know how to construct confidence intervals  when we try to estimate an unknown mean of a certain ", "distribution using the sample mean as our estimator.  Or actually, these are approximate confidence  intervals, because we are using the approximation ", "suggested by the central limit theorem.  But what if we do not know the value of sigma, the standard  deviation of the X's?  Then we have a few options. ", "One option is to use an upper bound on sigma.  So we will be using a value that's larger  than or equal to sigma.  And this is going to make our interval somewhat larger. ", "So this is a conservative choice, but it is  definitely an option.  For example, if we're dealing with Bernoulli random  variables, we know that the standard deviation is less  than or equal to 1/2, so we can just plug-in the value of ", "1/2 at this point.  Another option is to try to estimate sigma.  How do we estimate it?  We can perhaps use an ad hoc estimate of sigma that fits to ", "the particular situation at hand.  So for example, in the Bernoulli case, we know that  sigma is given by this formula, where theta is the ", "mean of the Bernoulli.  And using this, and since we do have an estimate of theta--  this is just the sample mean--  we can plug-in that particular estimate. ", "And that gives us an estimate of the standard deviation.  When n is large, this estimate is going to be very close to  the true value.  And so this estimate of the standard deviation will also ", "be very close to the true value.  Both of these options were discussed for special cases  where we have special structure and we can derive an ", "upper bound, or there is a natural estimate  that suggests itself.  More generally, what can we do?  One general option is to use a generic way of ", "estimating the variance.  And here's how it goes.  The variance is, by definition, the expected value  of something, of this expression. ", "And we can estimate expected values by taking several  samples of this quantity, and taking the average of them.  So if we have n pieces of data, for each piece of data, ", "we calculate this quantity, divide by n.  And by the weak law of large numbers, this is the sample  mean of this particular random variable. ", "And it converges to the expected value  of this random variable.  So that's how we could estimate the variance.  But there is a catch. ", "This expression here involves the mean  of the random variable.  And this is something that we do not know.  So what can we do?  Well, we have an estimate for the mean, so we could just ", "plug in that estimate instead of the true value.  And this gives us this alternative expression.  Now, when n is very large, as n increases, this sample mean ", "converges to the true mean.  So this expression here would become closer and closer to  this expression.  Now, this expression converges to sigma squared, and we ", "conclude from this that this expression will also converge  to sigma squared.  And so here we have a way of estimating sigma squared from  the data, and by taking the square root, we obtain an ", "estimate of sigma as well that we can plug in in this  expression.  And this gives us a complete way of coming up with  confidence intervals when we only have data available in ", "our hands, but do not know ahead of time what sigma is.  Some remarks.  This procedure of constructing confidence intervals involves ", "two separate approximations.  One approximation has to do with the fact that the sample  mean is approximately normal according to the  central limit theorem. ", "And then there is a second approximation that comes in in  using an estimate of sigma instead of the  true value of sigma.  Now, when we estimate sigma instead of using the true ", "value, we're introducing some additional  randomness in this procedure.  And because of this randomness, the confidence  intervals actually should be a little larger. ", "There is a systematic way of doing that, and it involves  using the so-called t-distribution tables.  And those tables are going to give us certain numbers that ", "are a little different from what we have here.  So instead of 1.96, we might have a somewhat larger number.  This correction is relevant when n is a small number, ", "let's say n smaller than 30.  But for larger values of n, this correction, where we use  t tables instead of normal tables, is rather  insignificant and one doesn't bother with it. ", "In any case, we will not discuss any further this  additional correction, but it is useful to know that it is  something that the statisticians will often do. ", "Finally, one last remark.  One will often see an alternative way of estimating  the variance where instead of this factor of 1/n, one uses a ", "factor of 1 over n minus 1.  With this alternative form, it turns out that this is an  unbiased estimator of the variance. ", "And that could be a reason for preferring to use this  alternative form.  On the other hand, when n is large, whether we use n or n  minus 1 makes very little difference. ", "And this concludes our discussion  of confidence intervals.    As we have already discussed, we can estimate an unknown  mean of a certain random variable by generating several ", "independent samples of that random variable and taking  their average.  And this procedure is well justified, because of the weak  law of large numbers, which tells us that this estimator ", "converges when n goes to infinity, in probability, to  the true mean.  Now we can apply this idea more generally.  Suppose we want to estimate the expected value of a ", "function of a random variable X. Now g of X is itself a  random variable.  So if we have samples of g of X, we can  use the same procedure. ", "How do we do that?  We generate independent samples of X, and these give  us independent samples of g of X. We use those independent ", "samples, we average them, and by the weak law of large  numbers, this quantity, as n goes to infinity, will  converge in probability to the expected value of g of X. ", "We already used an idea of this form when we tried to  estimate an unknown variance.  A variance is defined as an expectation.  And now we can generate samples of X, many independent ", "samples, calculate this quantity,  and take the average.  However, we might not know the mean of the distribution.  So instead of the true mean, we use an estimated mean, ", "which is estimated the usual way using a sample average.  So when n is large, this estimated mean is  close to the true mean.  So using the estimated mean here will not make a ", "substantial difference.  And then we have essentially independent  samples of this quantity.  And by averaging them, we obtain an estimate of the ", "variance, which asymptotically, as n goes to  infinity, will be equal to the true variance.  Now we can push this idea even further.  Suppose we wish to estimate a covariance. ", "What's a natural way of doing this?  We can generate independent samples of the pair of the  random variables X and Y, so this will be a typical ", "independent sample, and replace the expected value by  a sample average.  That is, we take our i-th sample, i-th pair, and ", "calculate this quantity, which looks very much like the  quantity in here except that we're using the estimated  means in place of the true means.  We obtain these quantities and average n of them, again using ", "the weak law of large numbers.  One can argue that this estimate will converge to the  true value of the covariance as n goes to infinity.  And once we have estimates of a covariance and of variance, ", "then we can use that to estimate correlation  coefficients.  Look at this formula, which is the definition of the  correlation coefficient.  If we just replace all quantities involved here by ", "corresponding estimates, this gives us an estimate of the  correlation coefficient.  All of these ways of forming estimates can be shown.  We are omitting the details of the argument, but hopefully ", "you get the idea by now.  All of these quantities are consistent estimators.  That is, when the sample size goes to infinity, they  approach the correct values of what we're trying to estimate. ", "So this is just an opening of what else a statistician might  be interested in.  And if you're wondering what's the further agenda after this  point, it would be something like the following. ", "Typically, a statistician might to want to say as much  as possible about the probability  distribution of an estimator.  For example, we have here an estimate of a covariance. ", "This estimate is going to be a random variable because it is  determined by random quantities.  What is the probability distribution of this quantity?  Can we describe it approximately? ", "What is the mean squared error  associated with this estimator?  And if you wish to construct confidence intervals how  would you do it?  These are all topics that statisticians have studied in ", "depth, and you could see more about these topics if you were  to take a further class on statistics and inference.  But we will not go any deeper in this course.  ", " We will finish our discussion of classical statistical  methods by discussing a general method for estimation,  the so-called maximum likelihood method. ", "If an unknown parameter can be expressed as an expectation,  we have seen that there's a natural way of estimating it.  But what if this is not the case? ", "Suppose there's no apparent way of interpreting theta as  an expectation.  So we need to do something else.  So rather than using this approach, we will use a ", "different approach, which is the following.  We will find a value of theta that makes the data that we  have seen most likely. ", "That is, we will find the value of theta under which the  probability of obtaining the particular x  that we have seen--  that probability is as large as possible. ", "And that value of theta is going to be our estimate, the  maximum likelihood estimate.  Here, I wrote a PMF.  That's what you would do if X was a  discrete random variable. ", "But the same procedure, of course, applies when X is a  continuous random variable.  And more generally, this procedure also applies when X ", "is a vector of observations and when theta is a vector of  parameters.  But what does this method really do?  It is instructive to compare maximum likelihood estimation ", "to a Bayesian approach.  In a Bayesian setting, what we do is, we find the posterior  distribution of the unknown parameter, which is now  treated as a random variable. ", "And then we look for the most likely value of theta.  We look at this distribution and try to find its peak.  So we want to maximize this quantity over theta. ", "The denominator does not involve any thetas.  So we ignore it.  And suppose now that we use a prior for  theta, which is flat. ", "Suppose that this prior is constant over the range of  possible values of theta.  In that case, what we need to do is to just take this ", "expression and to maximize it over all thetas.  And this looks very similar to what is happening here, where  we take this expression and maximize it over all thetas. ", "So operationally, maximum likelihood estimation is the  same as Bayesian estimation, in which we find the peak of  the posterior for the special case where we're using ", "constant or a flat prior.  But despite this similarity, the two methods are  philosophically very different.  In the Bayesian setting, you're asking the question, ", "what is the most likely value of theta?  Whereas in the maximum likelihood setting, you're  asking, what is the value of theta that makes ", "my data most likely?  Or what is the value of theta under which my data are the  least surprising?  So the interpretation of the two methods is quite ", "different, even though the mechanics  can be fairly similar.  The maximum likelihood method has some remarkable properties  that we would like now to discuss. ", "But first, one comment--  we need to take the probability of the observed  data given theta.  This is a function of theta, and maximize it over theta. ", "In some problems, we can find closed form solutions for the  optimal value of theta, which is going to be our estimate  but more often, and especially for large problems, one has to ", "do this maximization in a numerical way.  This is possible these days, and routinely, people solve  very high dimensional problems with lots of data and lots of ", "parameters using the maximum likelihood methodology.  The maximum likelihood methodology is very popular  because it has a very sound theoretical basis. ", "I will list a few facts, which we will not attempt to prove  or even justify.  But they're useful to know as general background.  Suppose that we have n pieces of data that are drawn from a ", "model from a certain structure.  Then under mild assumptions, the maximum likelihood  estimator has the property that it is consistent. ", "That is, as we draw more and more data, our estimate is  going to converge to the true value of the parameter.  In addition, we know quite a bit more.  Asymptotically, the maximum likelihood estimator behaves ", "like a normal random variable.  That is, after we normalize, subtract the target and divide  by its standard deviation, it approaches a standard normal ", "distribution.  So in this sense, it behaves the same way that the sample  mean behaves.  Notice that this expression here involves the standard ", "error of the maximum likelihood estimator.  This is an important quantity.  And for this reason, people have developed either  analytical or simulation methods for calculating or ", "approximating this standard error.  Once you have an estimate or an approximation of the  standard error in your hands, you can further use it to ", "construct confidence intervals.  Using the asymptotic normality, then we can  construct a confidence interval in exactly the same  way as we did for the case of the sample mean estimator. ", "And this, for example, would be a 95% confidence interval.  Finally, one last important property is that the maximum  likelihood estimator is what is called an asymptotically ", "efficient estimator.  That is, it is the best possible estimator in the  sense that it achieves the smallest possible variance. ", "So all of these are very strong properties.  And this is the reason why maximum likelihood estimation  is the most common approach for problems that do not have ", "any particular special structure that  you can exploit otherwise.    In this segment, we will go through two examples  of maximum likelihood estimation, ", "just in order to get a feel for the procedure involved  and the calculations that one has to go through.  Our first example will be very simple.  We have a binomial random variable ", "with parameters n and theta.  So think of having a coin that you flip n times,  and theta is the probability of heads  at each one of the tosses. ", "So we flip it n times and we observe  a certain numerical value, little k  for the random variable K. And on the basis  of that numerical value, we would like to estimate theta. ", "According to the maximum likelihood methodology,  the first step is to write down the likelihood function.  This is the probability of obtaining this particular piece  of data if the true parameter is theta. ", "Now, since K is a binomial random variable,  the probability of obtaining k heads in n tosses  is given by this expression here.  So what we need to do is to take the data that we have observed, ", "plug it in this formula, leave theta free--  we have here a function of theta--  and then maximize this function of theta over all theta. ", "Let us now do this calculation.  Actually, instead of maximizing this expression,  it's a little easier to maximize the logarithm  of this expression. ", "And the logarithm of this expression is as follows.  There's a first term, which is the logarithm of the n  choose k term.  Then, the logarithm of theta to the k is k times log theta. ", "And finally, the logarithm of the last term  is n minus k, log of 1 minus theta.  So we need to maximize this expression with respect ", "to theta.  In order to do that, we take the derivative with respect  to theta.  Here, there is no theta involved.  We get a contribution of 0.  This term has a derivative of k divided by theta. ", "And this term here has a derivative,  which is n minus k times the derivative  of this logarithmic term, which is  1 over what is inside the logarithm. ", "But by the chain rule, because of this minus sign  here, we get also a minus sign, and we obtain this expression.  Now, at the maximum, the derivative ", "has to be equal to 0.  And this gives us now an equation for theta  that we can solve.  Let us take this term, move it to the right-hand side,  and then cross-multiply with the denominators ", "to obtain the relation that k minus k theta-- this  is obtained by multiplying this k with this one minus theta  factor-- has to be equal to this term times theta, which ", "is n times theta minus k theta.  The k theta terms cancel, and we're  left with this expression, which tells us ", "that theta should be equal to k over n.  So this is the maximum likelihood estimate  for this particular problem, which  is a pretty reasonable answer.  If you would like to rephrase what we just ", "found in terms of estimators and random variables,  the maximum likelihood estimator is as follows.  We take the random variable that we observe, our observations, ", "and divide it by n.  And this is now a random variable,  which will be our estimator.  Now, notice that in this particular example,  the answer that we got is exactly the same as the answer ", "that we got in the context of Bayesian inference  when we were finding the maximum a posteriori probability  estimator, but for the special case  where the prior was a uniform distribution. ", "So if we assume that theta is actually a random variable  but has a uniform distribution, so that we have a flat prior,  and we carry out maximum a posteriori probability ", "estimation.  We do obtain exactly the same estimate.  And this is consistent with the comments  that we made earlier, that maximum likelihood estimation  can be interpreted also as MAP estimation with a flat prior. ", "Let us now move to our second example, which  will be a little more complicated.  Here, we have n random variables that are independent,  identically distributed. ", "They all have a normal distribution  with a certain mean and variance.  But both the mean and the variance are unknown,  and we want to estimate them on the basis  of these observations. ", "The first step is to write down the likelihood function.  That is the probability density function  for the vector of observations given some set of parameters. ", "Because of independence, the joint distribution  of the vector of X's that we have obtained is the product  of the PDFs of the individual X's, of the Xi's. ", "So the PDF of the typical Xi that has variance v and mean mu  is of this form. ", "So this is the likelihood function in this case.  This is the probability density of obtaining  a particular vector X of observations  when we have these particular parameters. ", "We would like to maximize this function.  As in our previous example, it is actually a little easier  to maximize the logarithm of this expression. ", "And this is the same as minimizing  the negative of the logarithm of this expression.  Now, when we take the logarithm of this expression,  we have a product.  So we're going to get a sum of logarithms. ", "And I leave it to you to verify that the negative logarithm  of this expression is of this form plus some other constant ", "that does not involve the parameters,  and which comes from this factor of 1 over square root 2pi.  In particular, this term here appears ", "when we take the logarithm of this.  And this happens n times because we have a product of n terms.  And this term here appears when we  take the logarithm of this expression, ", "and after we put in the minus sign,  because we're actually considering  the negative of the logarithm.  Now, to carry out the minimization, what  we need to do is to take the derivative of this expression ", "with respect to mu, set it to zero,  and also take the derivative with respect to v  and set it to zero as well.  Solve those equations and find the optimal mu and v. So let's ", "start by optimizing with respect to mu.  So we're going to take the derivative of this expression  with respect to mu and set it to zero.  This term does not involve mu, so we only ", "need to take the derivative of this.  And the derivative of this is going  to be-- there's a term 1 over v. And then  the derivative of a quadratic divided by 2 ", "is just xi minus mu.  And we have one term for each possible i.  We get this equation. ", "Now we can cancel out v, and we're left with the equation  that the sum of the xi's is equal to the sum ", "of the mus, which is n times mu.  And now we can send n to the denominator  to obtain that the estimate of mu  is going to be the sum of the xi's divided by n. ", "So the maximum likelihood estimate of the mean  takes a very simple and very natural form.  It is just the sample mean.  Now, let us continue with the minimization with respect ", "to v. In order to carry out that minimization,  we need to take the derivative of this expression with respect  to v and set it to zero.  The derivative of the first term is ", "equal to n over 2 times 1 over v. And then from here,  when we take the derivative, we obtain ", "the sum of all these terms divided by 2v squared. ", "But actually, when we take the derivative of 1 over v,  the derivative is minus 1 over v squared.  And for this reason here, we will have a minus sign. ", "So this is the derivative with respect  to v. We set it equal to zero and carry out some algebra.  What is the algebra involved here?  We can delete this term, 2, that appears here and there. ", "This term v cancels out this exponent here.  Then we take this v, move it to the other side,  and then take this n and move it to this side, ", "underneath this term.  And finally, what we obtain after you carry out  this algebra is this expression, that the estimate  of the variance is some form of the sample variance ", "where we use the optimal value of mu.  And the optimal value of mu we have already found.  It's given by this expression here. ", "So we obtain a pretty natural estimate for the variance  as well by using this maximum likelihood methodology.  Now, these two examples were particularly nice ", "because the algebra was not too complicated.  And the answers turned out to be what  you might have guessed without using any fancy methods. ", "But in other problems, the calculations  may be more complicated and the answers may not be so obvious.  "], "vid_duration": [11.71, 10.4, 11.82, 12.7, 11.06, 13.32, 12.39, 13.16, 11.74, 12.63, 11.62, 12.44, 10.31, 10.03, 12.539, 12.4, 11.94, 11.44, 12.11, 11.159, 12.131, 11.79, 11.021, 12.649, 10.85, 11.99, 11.839, 12.551, 12.25, 11.91, 14.39, 11.72, 10.01, 13.78, 14.92, 12.03, 10.94, 10.79, 10.85, 13.34, 13.01, 14.12, 14.019, 10.78, 11.531, 11.19, 11.57, 13.6, 10.25, 12.2, 10.77, 13.57, 11.01, 11.05, 13.03, 10.82, 11.82, 13.19, 10.9, 11.74, 11.13, 10.65, 13.29, 10.86, 10.84, 11.76, 11.76, 11.91, 11.88, 12.435, 13.26, 10.58, 11.56, 13.84, 11.7, 11.32, 12.41, 11.41, 10.13, 11.6, 12.46, 13.36, 13.31, 12.94, 13.44, 13.62, 12.15, 11.07, 10.55, 11.83, 10.45, 10.08, 12.4, 11.68, 10.184, 10.61, 10.62, 11.65, 12.15, 11.09, 12.19, 10.73, 13.09, 10.81, 10.22, 12.84, 10.53, 10.24, 11.72, 12.91, 10.73, 11.13, 13.37, 10.09, 14.89, 11.995, 11.105, 13.07, 12.59, 10.63, 13.28, 13.33, 11.24, 11.05, 11.01, 10.66, 11.67, 13.32, 12.7, 11.828, 10.801, 12.61, 10.1, 14.26, 11.1, 10.57, 10.16, 11.68, 10.53, 14.57, 10.12, 10.18, 11.51, 13.05, 10.63, 13.17, 12.01, 11.7, 12.24, 12.16, 11.49, 12.23, 10.87, 10.19, 10.87, 10.663, 13.04, 11.09, 11.65, 15.02, 12.5, 10.42, 10.81, 10.68, 15.94, 11.67, 10.38, 10.66, 12.79, 14.63, 11.1, 13.42, 10.82, 14.09, 13.33, 13.55, 11.3, 11.286, 10.47, 11.09, 12.24, 12.3, 12.26, 11.16, 12.09, 13.24, 10.55, 10.9, 12.61, 13.24, 11.57, 11.37, 12.16, 13.96, 12.11, 12.14, 13.04, 13.16, 10.5, 11.81, 11.55, 12.6, 11.8, 12.76, 10.39, 12.42, 11.12, 12.42, 13.338, 11.61, 11.23, 10.33, 10.37, 12.95, 14.35, 11.99, 12.62, 14.24, 12.01, 11.27, 11.61, 14.32, 13.44, 12.29, 12.41, 14.48, 12.16, 11.15, 11.51, 10.86, 10.733, 10.65, 10.08, 11.38, 10.31, 12.48, 10.57, 10.57, 12.38, 11.76, 13.03, 11.55, 10.76, 11.88, 13.76, 11.85, 11.74, 14.83, 11.85, 11.87, 10.89, 10.51, 11.699, 13.371, 10.42, 13.68, 10.61, 11.46, 11.38, 10.08, 13.29, 14.98, 10.4, 10.71, 11.504, 11.56, 11.36, 12.13, 13.41, 12.68, 10.36, 10.7, 13.93, 11.66, 12.84, 12.09, 10.31, 13.48, 14.65, 10.47, 11.99, 12.2, 13.51, 14.07, 10.86, 14.61, 10.46, 11.48, 11.81, 14.13, 10.26, 12.14, 12.99, 12.81, 10.1, 10.01, 11.82, 13.26, 13.1, 11.94, 12.24, 10.52, 10.47, 14.79, 11.11, 11.04, 10.806, 12.264, 11.15, 14.949, 13.581, 14.29, 10.84, 10.89, 10.53, 8.279], "stet": [[0, 11.71], [11.71, 22.11], [22.11, 33.93], [33.93, 46.629999999999995], [46.629999999999995, 57.69], [57.69, 71.00999999999999], [71.00999999999999, 83.39999999999999], [83.39999999999999, 96.55999999999999], [96.55999999999999, 108.29999999999998], [108.29999999999998, 120.92999999999998], [120.92999999999998, 132.54999999999998], [132.54999999999998, 144.98999999999998], [144.98999999999998, 155.29999999999998], [155.29999999999998, 165.32999999999998], [165.32999999999998, 177.86899999999997], [177.86899999999997, 190.26899999999998], [190.26899999999998, 202.20899999999997], [202.20899999999997, 213.64899999999997], [213.64899999999997, 225.75899999999996], [225.75899999999996, 236.91799999999995], [236.91799999999995, 249.04899999999995], [249.04899999999995, 260.83899999999994], [260.83899999999994, 271.85999999999996], [271.85999999999996, 284.50899999999996], [284.50899999999996, 295.359], [295.359, 307.349], [307.349, 319.188], [319.188, 331.739], [331.739, 343.989], [343.989, 355.899], [355.899, 370.289], [370.289, 382.009], [382.009, 392.019], [392.019, 405.799], [405.799, 420.719], [420.719, 432.74899999999997], [432.74899999999997, 443.68899999999996], [443.68899999999996, 454.479], [454.479, 465.329], [465.329, 478.669], [478.669, 491.679], [491.679, 505.799], [505.799, 519.818], [519.818, 530.598], [530.598, 542.1289999999999], [542.1289999999999, 553.319], [553.319, 564.889], [564.889, 578.489], [578.489, 588.739], [588.739, 600.9390000000001], [600.9390000000001, 611.7090000000001], [611.7090000000001, 625.2790000000001], [625.2790000000001, 636.2890000000001], [636.2890000000001, 647.339], [647.339, 660.369], [660.369, 671.1890000000001], [671.1890000000001, 683.0090000000001], [683.0090000000001, 696.1990000000002], [696.1990000000002, 707.0990000000002], [707.0990000000002, 718.8390000000002], [718.8390000000002, 729.9690000000002], [729.9690000000002, 740.6190000000001], [740.6190000000001, 753.9090000000001], [753.9090000000001, 764.7690000000001], [764.7690000000001, 775.6090000000002], [775.6090000000002, 787.3690000000001], [787.3690000000001, 799.1290000000001], [799.1290000000001, 811.0390000000001], [811.0390000000001, 822.9190000000001], [822.9190000000001, 835.354], [835.354, 848.614], [848.614, 859.1940000000001], [859.1940000000001, 870.754], [870.754, 884.594], [884.594, 896.2940000000001], [896.2940000000001, 907.6140000000001], [907.6140000000001, 920.0240000000001], [920.0240000000001, 931.4340000000001], [931.4340000000001, 941.5640000000001], [941.5640000000001, 953.1640000000001], [953.1640000000001, 965.6240000000001], [965.6240000000001, 978.9840000000002], [978.9840000000002, 992.2940000000001], [992.2940000000001, 1005.2340000000002], [1005.2340000000002, 1018.6740000000002], [1018.6740000000002, 1032.294], [1032.294, 1044.4440000000002], [1044.4440000000002, 1055.5140000000001], [1055.5140000000001, 1066.064], [1066.064, 1077.894], [1077.894, 1088.344], [1088.344, 1098.424], [1098.424, 1110.824], [1110.824, 1122.5040000000001], [1122.5040000000001, 1132.688], [1132.688, 1143.298], [1143.298, 1153.918], [1153.918, 1165.568], [1165.568, 1177.718], [1177.718, 1188.808], [1188.808, 1200.998], [1200.998, 1211.728], [1211.728, 1224.818], [1224.818, 1235.628], [1235.628, 1245.848], [1245.848, 1258.6879999999999], [1258.6879999999999, 1269.2179999999998], [1269.2179999999998, 1279.4579999999999], [1279.4579999999999, 1291.1779999999999], [1291.1779999999999, 1304.088], [1304.088, 1314.818], [1314.818, 1325.948], [1325.948, 1339.318], [1339.318, 1349.408], [1349.408, 1364.298], [1364.298, 1376.293], [1376.293, 1387.398], [1387.398, 1400.4679999999998], [1400.4679999999998, 1413.0579999999998], [1413.0579999999998, 1423.6879999999999], [1423.6879999999999, 1436.9679999999998], [1436.9679999999998, 1450.2979999999998], [1450.2979999999998, 1461.5379999999998], [1461.5379999999998, 1472.5879999999997], [1472.5879999999997, 1483.5979999999997], [1483.5979999999997, 1494.2579999999998], [1494.2579999999998, 1505.9279999999999], [1505.9279999999999, 1519.2479999999998], [1519.2479999999998, 1531.9479999999999], [1531.9479999999999, 1543.7759999999998], [1543.7759999999998, 1554.5769999999998], [1554.5769999999998, 1567.1869999999997], [1567.1869999999997, 1577.2869999999996], [1577.2869999999996, 1591.5469999999996], [1591.5469999999996, 1602.6469999999995], [1602.6469999999995, 1613.2169999999994], [1613.2169999999994, 1623.3769999999995], [1623.3769999999995, 1635.0569999999996], [1635.0569999999996, 1645.5869999999995], [1645.5869999999995, 1660.1569999999995], [1660.1569999999995, 1670.2769999999994], [1670.2769999999994, 1680.4569999999994], [1680.4569999999994, 1691.9669999999994], [1691.9669999999994, 1705.0169999999994], [1705.0169999999994, 1715.6469999999995], [1715.6469999999995, 1728.8169999999996], [1728.8169999999996, 1740.8269999999995], [1740.8269999999995, 1752.5269999999996], [1752.5269999999996, 1764.7669999999996], [1764.7669999999996, 1776.9269999999997], [1776.9269999999997, 1788.4169999999997], [1788.4169999999997, 1800.6469999999997], [1800.6469999999997, 1811.5169999999996], [1811.5169999999996, 1821.7069999999997], [1821.7069999999997, 1832.5769999999995], [1832.5769999999995, 1843.2399999999996], [1843.2399999999996, 1856.2799999999995], [1856.2799999999995, 1867.3699999999994], [1867.3699999999994, 1879.0199999999995], [1879.0199999999995, 1894.0399999999995], [1894.0399999999995, 1906.5399999999995], [1906.5399999999995, 1916.9599999999996], [1916.9599999999996, 1927.7699999999995], [1927.7699999999995, 1938.4499999999996], [1938.4499999999996, 1954.3899999999996], [1954.3899999999996, 1966.0599999999997], [1966.0599999999997, 1976.4399999999998], [1976.4399999999998, 1987.1], [1987.1, 1999.8899999999999], [1999.8899999999999, 2014.52], [2014.52, 2025.62], [2025.62, 2039.04], [2039.04, 2049.86], [2049.86, 2063.9500000000003], [2063.9500000000003, 2077.28], [2077.28, 2090.8300000000004], [2090.8300000000004, 2102.1300000000006], [2102.1300000000006, 2113.4160000000006], [2113.4160000000006, 2123.8860000000004], [2123.8860000000004, 2134.9760000000006], [2134.9760000000006, 2147.2160000000003], [2147.2160000000003, 2159.5160000000005], [2159.5160000000005, 2171.7760000000007], [2171.7760000000007, 2182.9360000000006], [2182.9360000000006, 2195.0260000000007], [2195.0260000000007, 2208.2660000000005], [2208.2660000000005, 2218.8160000000007], [2218.8160000000007, 2229.716000000001], [2229.716000000001, 2242.326000000001], [2242.326000000001, 2255.5660000000007], [2255.5660000000007, 2267.136000000001], [2267.136000000001, 2278.5060000000008], [2278.5060000000008, 2290.6660000000006], [2290.6660000000006, 2304.6260000000007], [2304.6260000000007, 2316.736000000001], [2316.736000000001, 2328.8760000000007], [2328.8760000000007, 2341.9160000000006], [2341.9160000000006, 2355.0760000000005], [2355.0760000000005, 2365.5760000000005], [2365.5760000000005, 2377.3860000000004], [2377.3860000000004, 2388.9360000000006], [2388.9360000000006, 2401.5360000000005], [2401.5360000000005, 2413.3360000000007], [2413.3360000000007, 2426.096000000001], [2426.096000000001, 2436.486000000001], [2436.486000000001, 2448.906000000001], [2448.906000000001, 2460.0260000000007], [2460.0260000000007, 2472.446000000001], [2472.446000000001, 2485.784000000001], [2485.784000000001, 2497.394000000001], [2497.394000000001, 2508.624000000001], [2508.624000000001, 2518.954000000001], [2518.954000000001, 2529.324000000001], [2529.324000000001, 2542.274000000001], [2542.274000000001, 2556.6240000000007], [2556.6240000000007, 2568.6140000000005], [2568.6140000000005, 2581.2340000000004], [2581.2340000000004, 2595.474], [2595.474, 2607.4840000000004], [2607.4840000000004, 2618.7540000000004], [2618.7540000000004, 2630.3640000000005], [2630.3640000000005, 2644.6840000000007], [2644.6840000000007, 2658.1240000000007], [2658.1240000000007, 2670.4140000000007], [2670.4140000000007, 2682.8240000000005], [2682.8240000000005, 2697.3040000000005], [2697.3040000000005, 2709.4640000000004], [2709.4640000000004, 2720.6140000000005], [2720.6140000000005, 2732.1240000000007], [2732.1240000000007, 2742.984000000001], [2742.984000000001, 2753.717000000001], [2753.717000000001, 2764.367000000001], [2764.367000000001, 2774.447000000001], [2774.447000000001, 2785.827000000001], [2785.827000000001, 2796.137000000001], [2796.137000000001, 2808.617000000001], [2808.617000000001, 2819.1870000000013], [2819.1870000000013, 2829.7570000000014], [2829.7570000000014, 2842.1370000000015], [2842.1370000000015, 2853.8970000000018], [2853.8970000000018, 2866.927000000002], [2866.927000000002, 2878.477000000002], [2878.477000000002, 2889.2370000000024], [2889.2370000000024, 2901.1170000000025], [2901.1170000000025, 2914.8770000000027], [2914.8770000000027, 2926.7270000000026], [2926.7270000000026, 2938.4670000000024], [2938.4670000000024, 2953.2970000000023], [2953.2970000000023, 2965.147000000002], [2965.147000000002, 2977.017000000002], [2977.017000000002, 2987.907000000002], [2987.907000000002, 2998.417000000002], [2998.417000000002, 3010.1160000000023], [3010.1160000000023, 3023.4870000000024], [3023.4870000000024, 3033.9070000000024], [3033.9070000000024, 3047.5870000000023], [3047.5870000000023, 3058.1970000000024], [3058.1970000000024, 3069.6570000000024], [3069.6570000000024, 3081.0370000000025], [3081.0370000000025, 3091.1170000000025], [3091.1170000000025, 3104.4070000000024], [3104.4070000000024, 3119.3870000000024], [3119.3870000000024, 3129.7870000000025], [3129.7870000000025, 3140.4970000000026], [3140.4970000000026, 3152.0010000000025], [3152.0010000000025, 3163.5610000000024], [3163.5610000000024, 3174.9210000000026], [3174.9210000000026, 3187.0510000000027], [3187.0510000000027, 3200.4610000000025], [3200.4610000000025, 3213.1410000000024], [3213.1410000000024, 3223.5010000000025], [3223.5010000000025, 3234.2010000000023], [3234.2010000000023, 3248.131000000002], [3248.131000000002, 3259.791000000002], [3259.791000000002, 3272.631000000002], [3272.631000000002, 3284.7210000000023], [3284.7210000000023, 3295.031000000002], [3295.031000000002, 3308.5110000000022], [3308.5110000000022, 3323.1610000000023], [3323.1610000000023, 3333.631000000002], [3333.631000000002, 3345.621000000002], [3345.621000000002, 3357.8210000000017], [3357.8210000000017, 3371.331000000002], [3371.331000000002, 3385.401000000002], [3385.401000000002, 3396.2610000000022], [3396.2610000000022, 3410.8710000000024], [3410.8710000000024, 3421.3310000000024], [3421.3310000000024, 3432.8110000000024], [3432.8110000000024, 3444.6210000000024], [3444.6210000000024, 3458.7510000000025], [3458.7510000000025, 3469.0110000000027], [3469.0110000000027, 3481.1510000000026], [3481.1510000000026, 3494.1410000000024], [3494.1410000000024, 3506.9510000000023], [3506.9510000000023, 3517.051000000002], [3517.051000000002, 3527.0610000000024], [3527.0610000000024, 3538.8810000000026], [3538.8810000000026, 3552.141000000003], [3552.141000000003, 3565.2410000000027], [3565.2410000000027, 3577.1810000000028], [3577.1810000000028, 3589.4210000000026], [3589.4210000000026, 3599.9410000000025], [3599.9410000000025, 3610.4110000000023], [3610.4110000000023, 3625.2010000000023], [3625.2010000000023, 3636.3110000000024], [3636.3110000000024, 3647.3510000000024], [3647.3510000000024, 3658.1570000000024], [3658.1570000000024, 3670.4210000000026], [3670.4210000000026, 3681.5710000000026], [3681.5710000000026, 3696.5200000000027], [3696.5200000000027, 3710.101000000003], [3710.101000000003, 3724.391000000003], [3724.391000000003, 3735.231000000003], [3735.231000000003, 3746.121000000003], [3746.121000000003, 3756.651000000003], [3756.651000000003, 3764.930000000003]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [166, 825, 1122, 1535, 1838, 2104, 2476, 2753, 3145, 3764]}
{"example_id": "mit153@@MITRES6_012S18_L02_300k", "text": [" Suppose I look at the registry of residents of my town and  pick a person at random.  What is the probability that this person is  under 18 years of age? ", "The answer is about 25%.  Suppose now that I tell you that this person is married.  Will you give the same answer?  Of course not.  The probability of being less than 18 years ", "old is now much smaller.  What happened here?  We started with some initial probabilities that reflect  what we know or believe about the world. ", "But we then acquired some additional  knowledge, some new evidence--  for example, about this person's family situation.  This new knowledge should cause our beliefs to change, ", "and the original probabilities must be replaced with new  probabilities that take into account the new information.  These revised probabilities are what we call conditional ", "probabilities.  And this is the subject of this lecture.  We will start with a formal definition of conditional  probabilities together with the motivation behind this ", "particular definition.  We will then proceed to develop three tools that rely  on conditional probabilities, including the Bayes rule,  which provides a systematic way for incorporating new ", "evidence into a probability model.  The three tools that we introduce in this lecture  involve very simple and elementary mathematical  formulas, yet they encapsulate some very powerful ideas. ", "It is not an exaggeration to say that much of this class  will revolve around the repeated application of  variations of these three tools to increasingly ", "complicated situations.  In particular, the Bayes rule is the foundation for the  field of inference.  It is a guide on how to process data and make ", "inferences about unobserved quantities or phenomena.  As such, it is a tool that is used all the time, all over  science and engineering.  ", " Conditional probabilities are probabilities associated with  a revised model that takes into account some additional  information about the outcome of a probabilistic experiment. ", "The question is how to carry out this  revision of our model.  We will give a mathematical definition of conditional  probabilities, but first let us motivate this definition by ", "examining a simple concrete example.  Consider a probability model with 12 equally likely  possible outcomes, and so each one of them has probability ", "equal to 1/12.   We will focus on two particular events, event A and  B, two subsets of the sample space. ", "Event A has five elements, so its probability is 5/12, and  event B has six elements, so it has probability 6/12. ", "Suppose now that someone tells you that event B has occurred,  but tells you nothing more about the outcome.  How should the model change?  First, those outcomes that are outside event B ", "are no longer possible.  So we can either eliminate them, as was done in this  picture, or we might keep them in the picture but assign them ", "0 probability, so that they cannot occur.  How about the outcomes inside the event B?  So we're told that one of these has occurred. ", "Now these 6 outcomes inside the event B were equally  likely in the original model, and there is no reason to  change their relative probabilities. ", "So they should remain equally likely in revised model as  well, so each one of them should have now probability  1/6 since there's 6 of them. ", "And this is our revised model, the  conditional probability law.  0 probability to outcomes outside B, and probability 1/6  to each one of the outcomes that is inside the event B. ", "Let us write now this down mathematically.  We will use this notation to describe the conditional  probability of an event A given that some other event B ", "is known to have occurred.  We read this expression as probability of A given B. So  what are these conditional probabilities in our example? ", "So in the new model, where these outcomes are equally  likely, we know that event A can occur in  two different ways.  Each one of them has probability 1/6. ", "So the probability of event A is 2/6 which  is the same as 1/3.  How about event B. Well, B consists of 6 possible ", "outcomes each with probability 1/6.  So event B in this revised model should have probability  equal to 1.  Of course, this is just saying the obvious. ", "Given that we already know that B has occurred, the  probability that B occurs in this new model  should be equal to 1.  How about now, if the sample space does not consist of ", "equally likely outcomes, but instead we're given the  probabilities of different pieces of the sample space, as  in this example.  Notice here that the probabilities are consistent ", "with what was used in the original example.  So this part of A that lies outside B has probability  3/12, but in this case I'm not telling you how that ", "probability is made up.  I'm not telling you that it consists of 3  equally likely outcomes.  So all I'm telling you is that the collective probability in  this region is 3/12.  The total probability of A is, again, 5/12 as before. ", "The total probability of B is 2 plus 4 equals  6/12, exactly as before.  So it's a sort of similar situation as before. ", "How should we revise our probabilities and create--  construct--  conditional probabilities once we are told ", "that event B has occurred?  First, this relation should remain true.  Once we are told that B has occurred, then B is certain to ", "occur, so it should have conditional  probability equal to 1.  How about the conditional probability of A given that B  has occurred?  Well, we can reason as follows. ", "In the original model, and if we just look inside event B,  those outcomes that make event A happen had a collective ", "probability which was 1/3 of the total probability assigned  to B. So out of the overall probability assigned to B, 1/3 ", "of that probability corresponds to outcomes in  which event A is happening.  So therefore, if I tell you that B has occurred, I should ", "assign probability equal to 1/3 that event A is  also going to happen.  So that, given that B happened, the conditional  probability of A given B should be equal to 1/3. ", "By now, we should be satisfied that this approach is a  reasonable way of constructing conditional probabilities.  But now let us translate our reasoning into a formula.  ", "So we wish to come up with a formula that gives us the  conditional probability of an event given another event.  The particular formula that captures our way of thinking, ", "as motivated before, is the following.  Out of the total probability assigned to B--  which is this-- ", "we ask the question, which fraction of that probability  is assigned to outcomes under which event A also happens? ", "So we are living inside event B, but within that event, we  look at those outcomes for which event A also happens. ", "So this is the intersection of A and B. And we ask, out of  the total probability of B, what fraction of that  probability is allocated to that intersection of A with B? ", "So this formula, this definition, captures our  intuition of what we did before to construct  conditional probabilities in our particular example. ", "Let us check that the definition indeed does what  it's supposed to do.  In this example, the probability of the  intersection was 2/12 and the total probability of B was ", "6/12, which gives us 1/3, which is the answer that we  had gotten intuitively a little earlier. ", "At this point, let me also make a comment that this  definition of conditional probabilities makes sense only  if we do not attempt to divide by zero. ", "That this, only if the event B on which we're conditioning,  has positive probability.  If B, if an event B has 0 probability, then conditional ", "probabilities given B will be left undefined.  And one final comment.  This is a definition. ", "It's not a theorem.  What does that mean?  It means that there is no question whether this equality  is correct or not. ", "It's just a definition.  There's no issue of correctness.  The earlier argument that we gave was just a motivation of ", "the definition.  We tried to figure out what the definition should be if we  want to have a certain intuitive and meaningful  interpretation of the conditional probabilities. ", " Let us now continue with a simple example.  ", " This is a simple example where we want to just apply the  formula for conditional probabilities  and see what we get. ", "The example involves a four-sided die, if you can  imagine such an object, which we roll twice, and we record  the first roll, and the second roll. ", "So there are 16 possible outcomes.  We assume to keep things simple, that each one of those  16 possible outcomes, each one of them has the same ", "probability, so each outcome has the probability 1/16.   Let us consider now a particular event B on which ", "we're going to condition.  This is the event under which the smaller of the two die  rolls is equal to 2, which means that one of the dice ", "must have resulted in two, and the other die has resulted in  something which is 2 or larger.  So this can happen in multiple ways.  And here are the different ways that it can happen. ", "So at 2, 2, or 2, 3, or 2, 4; then a 3, 2 and a 4, 2.  All of these are outcomes in which one of the dice has a ", "value equal to 2, and the other die  is at least as large.  So we condition on this event.  This results in a conditional model where each one of those ", "five outcomes are equally likely since they used to be  equally likely in the original model.  Now let's look at this quantity.  The maximum of the two die rolls-- ", "that is, the largest of the results.  And let us try to calculate the following quantity--  the conditional probability that the maximum is equal to 1 ", "given that the minimum is equal to 2.  So this is the conditional probability of  this particular outcome.  Well, this particular outcome cannot happen. ", "If I tell you that the smaller number is 2, then the larger  number cannot be equal to 1, so this outcome is impossible,  and therefore this conditional probability is equal to 0. ", "Let's do something a little more interesting.  Let us now look at the conditional probability that  the maximum is equal to 3 given the information that ", "event B has occurred.  It's best to draw a picture and see what that event  corresponds to.  M is equal to 3--  the maximum is equal to 3-- ", "if one of the dice resulted in a 3, and the other die  resulted in something that's 3 or less. ", "So this event here corresponds to the blue  region in this diagram.  Now let us try to calculate the conditional probability by ", "just following the definition.  The conditional probability of one event given another is the  probability that both of them-- ", "both of the two events--  occur, divided by the probability of the  conditioning event.  That is, out of the total probability in the ", "conditioning event, we ask, what fraction of that  probability is assigned to outcomes in which the event of  interest is also happening?  So what is this event? ", "The maximum is equal to 3, which is the blue event.  And simultaneously, the red event is happening.  These two events intersect only in two places. ", "This is the intersection of the two events.  And the probability of that intersection is 2 out of 16,  since there's 16 outcomes and that event happens only with ", "two particular outcomes.  So this gives us 2/16 in the numerator.  How about the denominator?  Event B consists of a total of five possible outcomes. ", "Each one has probability 1/16, so this is 5/16, so the final  answer is 2/5.  We could have gotten that same answer in a simple and perhaps ", "more intuitive way.  In the original model, all outcomes were equally likely.  Therefore, in the conditional model, the five outcomes that  belong to B should also be equally likely. ", "Out of those five, there's two of them that make the event of  interest to occur.  So given that we live in B, there's two ways out of five ", "that the event of interest will materialize.  So the event of interest has  conditional probability [equal to]  2/5.   ", "I now want to emphasize an important point.  Conditional probabilities are just the same as ordinary  probabilities applied to a different situation. ", "They do not taste or smell or behave any differently than  ordinary probabilities.  What do I mean by that?  I mean that they satisfy the usual probability axioms. ", "For example, ordinary probabilities must also be  non-negative.  Is this true for conditional probabilities?  Of course it is true, because conditional probabilities are ", "defined as a ratio of two probabilities.  Probabilities are non-negative.  So the ratio will also be non-negative, of course as  long as it is well-defined. ", "And here we need to remember that we only talk about  conditional probabilities when we condition on an event that  itself has positive probability. ", "How about another axiom?  What is the probability of the entire sample space,  given the event B?  Let's check it out. ", "By definition, the conditional probability is the probability  of the intersection of the two events involved divided by the ", "probability of the conditioning event.  Now, what is the intersection of omega with B?  B is a subset of omega.  So when we intersect the two sets, we're ", "left just with B itself.  So the numerator becomes the probability of B. We're  dividing by the probability of B, and so the  answer is equal to 1. ", "So indeed, the sample space has unit probability, even  under the conditional model.  Now, remember that when we condition on an event B, we ", "could still work with the original sample space.  However, possible outcomes that do not belong to B are  considered impossible, so we might as well think of B ", "itself as being our sample space.  If we proceed like that and think now of B as being our  new sample space, what is the probability of this new sample ", "space in the conditional model?  Let's apply the definition once more.  It's the probability of the intersection of the two events  involved, B intersection B, divided by the probability of ", "the conditioning event.  What is the numerator?  The intersection of B with itself is just B, so the  numerator is the probability of B. We're dividing by the ", "probability of B. So the answer is, again, 1.  Finally, we need to check the additivity axiom.  Recall what the additivity axiom says. ", "If we have two events, two subsets of the sample space  that are disjoint, then the probability of their union is  equal to the sum of their individual probabilities. ", "Is this going to be the case if we now condition on a  certain event?  What we want to prove is the following statement. ", "If we take two events that are disjoint, they have empty  intersection, then the probability of the union is  the sum of their individual probabilities, but where now ", "the probabilities that we're employing are the conditional  probabilities, given the event B. So let us verify whether  this relation, this fact is correct or not. ", "Let us take this quantity and use the  definition to write it out.  By definition, this conditional probability is the  probability of the intersection of the first ", "event of interest, the one that appears on this side of  the conditioning, intersection with the event on which we are  conditioning. ", "And then we divide by the probability of the  conditioning event, B. Now, let's look at this quantity,  what is it?  We're taking the union of A with C, and then intersect it ", "with B. This union consists of these two pieces.  When we intersect with B, what is left is  these two pieces here. ", " So A union C intersected with B is the union of two pieces. ", "One piece is A intersection B, this piece here.  And another piece, which is C intersection B, this is the ", "second piece here.  So here we basically used a set theoretic identity.  And now we divide by the same [denominator] ", "as before.  And now let us continue.  Here's an interesting observation.   The events A and C are disjoint. ", "The piece of A that also belongs in B, therefore, is  disjoint from the piece of C that also belongs to B.  Therefore, this set here and that set here are disjoint. ", "Since they are disjoint, the probability of their union has  to be equal to the sum of their individual  probabilities.  So here we're using the additivity axiom on the ", "original probabilities to break this probability up into  two pieces.  ", "And now we observe that here we have the ratio of an  intersection by the probability of B. This is just  the conditional probability of A given B using the definition ", "of conditional probabilities.  And the second part is the conditional probability of C  given B, where, again, we're using the definition of ", "conditional probabilities.  So we have indeed checked that this additivity property is  true for the case of conditional probabilities when ", "we consider two disjoint events.  Now, we could repeat the same derivation and verify that it  is also true for the case of a disjoint union, of finitely ", "many events, or even for countably  many disjoint events.  So we do have finite and countable additivity. ", "We're not proving it, but the argument is exactly the same  as for the case of two events.  So conditional probabilities do satisfy all of the standard ", "axioms of probability theory.  So conditional probabilities are just like ordinary  probabilities.  This actually has a very important implication.  Since conditional probabilities satisfy all of ", "the probability axioms, any formula or theorem that we  ever derive for ordinary probabilities will remain true  for conditional probabilities as well. ", "  Let us now examine what conditional  probabilities are good for.  We have already discussed that they are used to revise a ", "model when we get new information, but there is  another way in which they arise.  We can use conditional probabilities to build a  multi-stage model of a probabilistic experiment. ", "We will illustrate this through an example involving  the detection of an object up in the sky by a radar.  We will keep our example very simple. ", "On the other hand, it turns out to have all the basic  elements of a real-world model.  So, we are looking up in the sky, and either there's an ", "airplane flying up there or not.  Let us call Event A the event that an airplane is indeed  flying up there, and we have two possibilities. ", "Either Event A occurs, or the complement of A occurs, in  which case nothing is flying up there.  ", "At this point, we can also assign some probabilities to  these two possibilities.  Let us say that through prior experience, perhaps, or some  other knowledge, we know that the probability that something ", "is indeed flying up there is 5% and with probability 95%  nothing is flying.  Now, we also have a radar that looks up there, and there are ", "two things that can happen.  Either something registers on the radar  screen or nothing registers.  Of course, if it's a good radar, probably Event B will ", "tend to go together with Event A. But it's also possible that  the radar will make some mistakes.  And so we have various possibilities. ", "If there's a plane up there, it's possible that the radar  will detect it, in which case Event B will also happen.  But it's also conceivable that the radar will not detect it, ", "in which case we have a so-called miss.  And so a plane is flying up there, but the radar missed  it, did not detect it.  Another possibility is that nothing is flying up there, ", "but the radar does detect something, and this is a  situation that's called a false alarm.  ", "Finally, there's the possibility that nothing is  flying up there, and the radar did not see anything either.  Now, let us focus on this particular situation. ", "Suppose that Event A has occurred.  So we are living inside this particular universe.  In this universe, there are two possibilities, and we can ", "assign probabilities to these two possibilities.  So let's say that if something is flying up there, our radar  will find it with probability 99%, but will also miss it ", "with probability 1%.  What's the meaning of this number, 99%?  Well, this is a probability that applies to a situation ", "where an airplane is up there.  So it is really a conditional probability.  It's the conditional probability that we will  detect something, the radar will detect the plane, given ", "that the plane is already flying up there.  And similarly, this 1% can be thought of as the conditional  probability that the complement of B occurs, so the ", "radar doesn't see anything, given that there is a plane up  in the sky.   We can assign similar probabilities ", "under the other scenario.  If there is no plane, there is a probability that there will  be a false alarm, and there is a probability that the radar  will not see anything. ", "Those four numbers here are, in essence, the  specs of our radar.  They describe how the radar behaves in a world in which an ", "airplane has been placed in the sky, and some other  numbers that describe how the radar behaves in a world where  nothing is flying up in the sky. ", "So we have described various probabilistic properties of  our model, but is it a complete model?  Can we calculate anything that we might wish to calculate? ", "Let us look at this question.  Can we calculate the probability that  both A and B occur?  It's this particular scenario here.  How can we calculate it? ", "Well, let us remember the definition of conditional  probabilities.  The conditional probability of an event given another event  is the probability of their intersection divided by the  probability of the conditioning event. ", "But this doesn't quite help us because if we try to calculate  the numerator, we do not have the value of the probability ", "of A given B. We have the value of the probability of B  given A. What can we do?  Well, we notice that we can use this definition of  conditional probabilities, but use it in the reverse ", "direction, interchanging the roles of A and B. If we  interchange the roles of A and B, our definition leads to the  following expression.  The conditional probability of B given A is the probability ", "that both events occur divided by the probability, again, of  the conditioning event.  Therefore, the probability that A and B occur is equal to ", "the probability that A occurs times the conditional  probability that B occurs given that A occurred. ", "And in our example, this is 0.05 times the conditional  probability that B occurs, which is 0.99. ", "So we can calculate the probability of this particular  event by multiplying probabilities and conditional  probabilities along the path in this tree diagram that ", "leads us here.  And we can do the same for any other leaf in this diagram.  So for example, the probability that this happens  is going to be the probability of this event times the ", "conditional probability of B complement given that A  complement has occurred.  How about a different question? ", "What is the probability, the total probability, that the  radar sees something?  Let us try to identify this event. ", "The radar can see something under two scenarios.  There's the scenario where there is a plane up in the sky  and the radar sees it. ", "And there's another scenario where nothing is up in the  sky, but the radar thinks that it sees something.  So these two possibilities together make up the event B. ", "And so to calculate the probability of B, we need to  add the probabilities of these two events.  For the first event, we already calculated it. ", "It's 0.05 times 0.90.  For the second possibility, we need to do a similar  calculation. ", "The probability that this occurs is equal to 0.95 times  the conditional probability of B occurring under the scenario ", "where A complement has occurred, and this is 0.1.  If we add those two numbers together, the answer turns out ", "to be 0.1445.  Finally, a last question, which is perhaps the most ", "interesting one.  Suppose that the radar registered something.  What is the probability that there is an  airplane out there? ", " How do we do this calculation?  Well, we can start from the definition of the conditional  probability of A given B, and note that we already have in ", "our hands both the numerator and the denominator.  So the numerator is this number, 0.05 times 0.99, and ", "the denominator is 0.1445, and we can use our calculators to  see that the answer is approximately 0.34. ", "So there is a 34% probability that an airplane is there  given that the radar has seen or thinks ", "that it sees something.  So the numerical value of this answer is somewhat interesting  because it's pretty small. ", "Even though we have a very good radar that tells us the  right thing 99% of the time under one scenario and 90% ", "under the other scenario.  Despite that, given that the radar has seen something, this  is not really convincing or compelling evidence that there ", "is an airplane up there.  The probability that there's an airplane up there is only  34% in a situation where the radar thinks  that it has seen something. ", "So in the next few segments, we are going to revisit these  three calculations and see how they can generalize. ", "In fact, a large part of what is to happen in the remainder  of this class will be elaboration  on these three ideas. ", "They are three types of calculations that will show up  over and over, of course, in more complicated forms, but  the basic ideas are essentially captured in this ", "simple example.    As promised, we will now start developing generalizations of  the different calculations that we carried out in the ", "context of the radar example.  The first kind of calculation that we carried out goes under  the name of the multiplication rule.  And it goes as follows.  Our starting point is the definition of conditional ", "probabilities.  The conditional probability of A given another event, B, is  the probability that both events have occurred divided  by the probability of the conditioning event. ", "We now take the denominator term and send it to the other  side of this equality to obtain this relation, which we  can interpret as follows.  The probability that two events occur is equal to the ", "probability that a first event occurs, event B in this case,  times the conditional probability that the second  event, event A, occurs, given that event B has occurred. ", "Now, out of the two events, A and B, we're of course free to  choose which one we call the first event and which one we  call the second event.  So the probability of the two events happening is also equal ", "to an expression of this form, the probability that A occurs  times the conditional probability that B occurs,  given that A has occurred.  We used this formula in the context of a tree diagram. ", "And we used it to calculate the probability of a leaf of  this tree by multiplying the probability of taking this  branch, the probability that A occurs, times the conditional ", "probability of taking this branch, the probability that  event B also occurs given that event A has occurred.  How do we generalize this calculation? ", "Consider a situation in which the experiment has an  additional third stage that has to do with another event,  C, that may or may not occur. ", "For example, if we have arrived here, A and B have  both occurred.  And then C also occurs, then we reach this particular leaf  of the tree. ", "Or there could be other scenarios.  For example, it could be the case that A did not occur.  Then event B occurred, and finally, event C did not ", "occur, in which case we end up at this particular leaf.  What is the probability of this scenario happening?  Let us try to do a calculation similar to the one that we ", "used for the case of two events.  However, we need to deal here with three events.  What should we do?  Well, we look at the intersection of these three ", "events and think of it as the intersection of a composite  event, A complement intersection B, then  intersected with the event C complement. ", "Clearly, you can form the intersection of three events  by first taking the intersection of two of them  and then intersecting with a third.  After we group things this way, we're dealing with the ", "probability of two events happening, this composite  event and this ordinary event.  And the probability of two events happening is equal to ", "the probability that the first event happens, and then the  probability that the second event happens, given that the ", "first one has happened.   Can we simplify this even further?  Yes.  The first term is the probability ", "of two events happening.  So it can be simplified further as the probability  that A complement occurs times the conditional probability  that B occurs, given that A complement has occurred. ", "And then we carry over the last term  exactly the way it is.   The conclusion is that we can calculate the probability of ", "this leaf by multiplying the probability of the first  branch times the conditional probability of the second  branch, given that the first branch was taken, and then ", "finally multiply with the probability of the third  branch, which is the probability that C complement  occurs, given that A complement and B ", "have already occurred.  In other words, we can calculate the probability of a  leaf by just multiplying the probabilities of the different ", "branches involved and where we use conditional probabilities  for the intermediate branches.  At this point, you can use your imagination to see that  such a formula should also be valid for the case of more ", "than three events.  The probability that a bunch of events all occur should be  the probability of the first event times a number of ", "factors, each corresponding to a branch in a  tree of this kind.  In particular, the probability that events A1, A2, up to An ", "all occur is going to be the probability that the first  event occurs times a product of conditional probabilities ", "that the i-th event occurs, given that all of the previous  events have already occurred.  ", "And we obtain a term of this kind for every event, Ai,  after the first one, so this product ranges from 2 up to n. ", "And this is the most general version of the multiplication  rule and allows you to calculate the probability of  several events happening by multiplying probabilities and ", "conditional probabilities.    Let us now revisit the second calculation that we carried  out in the context of our earlier example. ", "In that example, we calculated the total probability of an  event that can occur under different scenarios.  And it involves the powerful idea of divide and conquer ", "where we break up complex situations  into simpler pieces.  Here is what is involved.  We have our sample space.  And our sample space is partitioned into a number of ", "subsets or events.  In this picture we take that number to be 3, so we'll have  it partitioned into three possible scenarios.  It is a partition which means that these events cover the ", "entire sample, space and they're  disjoint from each other.  For each one of the scenarios we're given their  probabilities.  If you prefer, you can also draw this situation ", "in terms of a tree.  There are three different scenarios that can happen.  We're interested in a particular event, B. That  event B can happen in three different ways. ", "It can happen under scenario one, under scenario two, or  under scenario three.  And this corresponds to these particular sub-events. ", "So for example, this is the event  where scenario A1 happens.  And then event B happens as well.   In terms of a tree diagram, the ", "picture becomes as follows.  If scenario A1 materializes, event B may occur or event B  might not occur.  Finally, we are given conditional probabilities that ", "event B will materialize under each one of the different  possible scenarios.  Under those circumstances, can we calculate the probability ", "of event B?  Of course we can.  And here's how we do it.  First we realize that event B consists of a number of ", "disjoint pieces.  One piece is when event B occurs together with event A1.  Another piece is when event B occurs together with A2. ", "Another piece is when event B occurs together with A3.  These three sets are disjoint from each other, as we see in  this picture. ", "And together they form the event B. Therefore, the  probability of B is going to be, by the additivity axiom of  probabilities, equal to the sum of the probabilities of ", "these sub-events.  Furthermore, for each one of these sub-events we can use  the multiplication rule and write their  probabilities as follows. ", "The probability that B and A1 both occur is the probability  that scenario one materializes times the conditional  probability that B occurs given that A1 occurred. ", "And then we're going to have similar terms under the second  scenario and a similar term under the third scenario.  So putting everything together, we have arrived at a ", "formula of this form.  The total probability of event B is the sum of the  probabilities of the different ways that B may occur, that ", "is, B occurring under the different scenarios.  And those particular probabilities are the product  of the probability of the scenario times the conditional  probability of B given that scenario. ", "Now, note that the sum of the probabilities of the different  scenarios is of course equal to 1.  And this is because the scenarios form a partition of ", "our sample space.  So if we look at this formula here, we realize that it is a  weighted average of the conditional probabilities of ", "event B, weighted average of the conditional probabilities  where these probabilities of the individual scenarios are ", "the weights.   In words, the probability that an event occurs is a weighted  average of the probability that it has under each ", "possible scenario, where the weights are the probabilities  of the different scenarios.  One final comment--  our derivation was for the case of three events. ", "But you can certainly see that the same derivation would go  through if we had any finite number of events.  But even more, if we had a partition of our sample space ", "into an infinite sequence of events, the same derivation  would still go through, except that in this place in the  derivation, instead of using the ordinary additivity axiom ", "we would have to use the countable additivity axiom.  But other than that, all the steps would be the same.  And we would end up with the same formula, except that now ", "this would be an infinite sum over the  infinite set of scenarios.    We now come to the third and final kind of calculation out ", "of the calculations that we carried out  in our earlier example.  The setting is exactly the same as in our discussion of  the total probability theorem.  We have a sample space which is partitioned into a number ", "of disjoint subsets or events which  we think of as scenarios.  We're given the probability of each scenario.  And we think of these probabilities as being some ", "kind of initial beliefs.  They capture how likely we believe each scenario to be. ", "Now, under each scenario, we also have the probability that  an event of interest, event B, will occur. ", "Then the probabilistic experiment is carried out.  And perhaps we observe that event B did indeed occur.  Once that happens, maybe this should cause us to revise our ", "beliefs about the likelihood of the different scenarios.  Having observed that B occurred, perhaps certain  scenarios are more likely than others. ", "How do we revise our beliefs?  By calculating conditional probabilities.  And how do we calculate conditional probabilities?  We start from the definition of conditional probabilities. ", "The probability of one event given another is the  probability that both events occur divided by the  probability of the conditioning event. ", "How do we continue?  We simply realize that the numerator is what we can  calculate using the multiplication rule.  And the denominator is exactly what we calculate using the ", "total probability theorem.  So we have everything we need to calculate those revised  beliefs, or conditional probabilities.  And this all there is in the Bayes rule. ", "It is actually a very simple calculation.   It's a very simple calculation.  However, it is a quite important one. ", "Its history goes way back.  In the middle of the 18th century, a Presbyterian  minister, Thomas Bayes, worked it out.  It was published a few years after his death. ", "And it was quickly reorganized for its significance.  It's a systematic way for incorporating new evidence.  It's a systematic way for learning from experience. ", "And it forms the foundation of a major branch of mathematics,  so-called Bayesian inference, which we will study in some  detail later in this course. ", "The general idea is that we start with a probabilistic  model, which involves a number of possible scenarios.  And we have some initial beliefs on the likelihood of ", "each possible scenario.  There's also some particular event that may occur under  each scenario.  And we know how likely it is to occur under each scenario. ", "This is our model of the situation.  Under each particular situation, the model tells us  how likely event B is to occur.  If we actually observe that B occurred, then we use that ", "information to draw conclusions about the possible  causes of B, or conclusions about the more likely or less  likely scenarios that may have caused this events to occur. ", "That's what inference is.  Having observed b, we make inferences as to how likely a  particular scenario, Ai, is going to be. ", "And that likelihood is captured by this conditional  probabilities of Ai, given the event B. So that's what the  Bayes rule is doing.  Starting from conditional probabilities going in one ", "direction, it allows us to calculate conditional  probabilities going in the opposite direction.  It allows us to revise the probabilities of the different ", "scenarios, taking into account the new information.  And that's exactly what inference is all about, as  we're going to see later in this class. ", ""], "vid_duration": [10.26, 12.78, 10.74, 11.25, 11.4, 11.86, 12.61, 14.37, 10.42, 10.35, 10.153, 13.85, 11.88, 12.45, 10.569, 12.44, 15.261, 11.77, 13.24, 11.039, 11.211, 14.41, 14.16, 12.48, 12.07, 14.52, 11.42, 12.24, 12.79, 12.39, 14.63, 10.62, 10.36, 13.979, 10.36, 11.911, 10.18, 10.78, 13.43, 14.48, 13.71, 10.66, 15.36, 10.64, 12.17, 11.07, 13.22, 10.42, 13.06, 12.24, 11.41, 10.72, 11.309, 12.256, 10.074, 10.61, 11.22, 10.99, 10.43, 10.74, 13.14, 10.95, 11.44, 11.82, 10.9, 10.24, 12.39, 11.82, 11.42, 10.08, 12.42, 10.25, 13.02, 12.32, 12.64, 13.88, 12.27, 13.48, 13.0, 11.03, 10.635, 10.52, 12.75, 10.48, 10.35, 10.99, 10.35, 10.26, 12.68, 11.45, 12.06, 10.75, 11.84, 14.47, 11.84, 12.92, 12.04, 10.18, 13.25, 12.9, 13.15, 10.85, 13.41, 11.035, 10.745, 12.74, 10.129, 12.541, 17.22, 13.64, 10.73, 14.5, 10.97, 12.21, 15.36, 12.91, 12.79, 12.29, 11.77, 10.404, 13.25, 11.87, 12.23, 12.2, 10.76, 12.62, 10.05, 10.08, 10.03, 13.11, 13.89, 11.47, 13.29, 11.07, 11.1, 11.52, 12.52, 10.96, 13.38, 11.72, 10.69, 12.48, 11.78, 11.83, 13.05, 10.32, 13.18, 13.35, 13.36, 10.17, 12.76, 14.0, 13.04, 10.44, 10.58, 11.02, 13.09, 10.83, 10.48, 13.42, 13.32, 10.62, 10.12, 14.9, 13.92, 13.02, 11.53, 10.77, 10.22, 12.68, 13.83, 10.771, 11.168, 12.201, 10.528, 11.81, 10.94, 13.17, 12.6, 12.74, 13.69, 13.03, 11.99, 10.59, 10.799, 12.311, 12.08, 11.81, 13.83, 11.19, 10.81, 11.84, 10.71, 14.53, 12.09, 14.67, 11.04, 10.69, 13.15, 10.23, 16.04, 12.66, 12.83, 12.15, 10.73, 10.756, 10.06, 12.39, 12.37, 11.58, 10.31, 11.26, 10.95, 13.13, 10.18, 10.76, 10.45, 10.02, 12.05, 11.11, 11.71, 11.43, 14.25, 11.55, 13.96, 15.2, 12.77, 13.43, 11.71, 11.64, 15.24, 10.39, 13.184, 12.11, 11.75, 10.35, 10.38, 13.719, 11.581, 11.31, 11.05, 13.41, 11.75, 10.56, 12.45, 10.87, 11.66, 10.94, 12.63, 13.9, 14.23, 11.09, 11.76, 10.91, 10.09, 1.671], "stet": [[0, 10.26], [10.26, 23.04], [23.04, 33.78], [33.78, 45.03], [45.03, 56.43], [56.43, 68.28999999999999], [68.28999999999999, 80.89999999999999], [80.89999999999999, 95.27], [95.27, 105.69], [105.69, 116.03999999999999], [116.03999999999999, 126.193], [126.193, 140.043], [140.043, 151.923], [151.923, 164.373], [164.373, 174.94199999999998], [174.94199999999998, 187.38199999999998], [187.38199999999998, 202.64299999999997], [202.64299999999997, 214.41299999999998], [214.41299999999998, 227.653], [227.653, 238.69199999999998], [238.69199999999998, 249.903], [249.903, 264.313], [264.313, 278.473], [278.473, 290.95300000000003], [290.95300000000003, 303.023], [303.023, 317.543], [317.543, 328.963], [328.963, 341.20300000000003], [341.20300000000003, 353.99300000000005], [353.99300000000005, 366.38300000000004], [366.38300000000004, 381.01300000000003], [381.01300000000003, 391.63300000000004], [391.63300000000004, 401.99300000000005], [401.99300000000005, 415.97200000000004], [415.97200000000004, 426.33200000000005], [426.33200000000005, 438.24300000000005], [438.24300000000005, 448.42300000000006], [448.42300000000006, 459.20300000000003], [459.20300000000003, 472.63300000000004], [472.63300000000004, 487.11300000000006], [487.11300000000006, 500.82300000000004], [500.82300000000004, 511.48300000000006], [511.48300000000006, 526.8430000000001], [526.8430000000001, 537.4830000000001], [537.4830000000001, 549.653], [549.653, 560.7230000000001], [560.7230000000001, 573.9430000000001], [573.9430000000001, 584.363], [584.363, 597.423], [597.423, 609.663], [609.663, 621.073], [621.073, 631.793], [631.793, 643.102], [643.102, 655.358], [655.358, 665.4319999999999], [665.4319999999999, 676.0419999999999], [676.0419999999999, 687.262], [687.262, 698.252], [698.252, 708.6819999999999], [708.6819999999999, 719.4219999999999], [719.4219999999999, 732.5619999999999], [732.5619999999999, 743.512], [743.512, 754.952], [754.952, 766.772], [766.772, 777.672], [777.672, 787.912], [787.912, 800.302], [800.302, 812.1220000000001], [812.1220000000001, 823.542], [823.542, 833.6220000000001], [833.6220000000001, 846.042], [846.042, 856.292], [856.292, 869.312], [869.312, 881.6320000000001], [881.6320000000001, 894.272], [894.272, 908.152], [908.152, 920.422], [920.422, 933.902], [933.902, 946.902], [946.902, 957.932], [957.932, 968.567], [968.567, 979.087], [979.087, 991.837], [991.837, 1002.317], [1002.317, 1012.667], [1012.667, 1023.657], [1023.657, 1034.007], [1034.007, 1044.267], [1044.267, 1056.9470000000001], [1056.9470000000001, 1068.3970000000002], [1068.3970000000002, 1080.457], [1080.457, 1091.207], [1091.207, 1103.047], [1103.047, 1117.517], [1117.517, 1129.357], [1129.357, 1142.277], [1142.277, 1154.317], [1154.317, 1164.497], [1164.497, 1177.747], [1177.747, 1190.6470000000002], [1190.6470000000002, 1203.7970000000003], [1203.7970000000003, 1214.6470000000002], [1214.6470000000002, 1228.0570000000002], [1228.0570000000002, 1239.0920000000003], [1239.0920000000003, 1249.8370000000002], [1249.8370000000002, 1262.5770000000002], [1262.5770000000002, 1272.7060000000001], [1272.7060000000001, 1285.247], [1285.247, 1302.467], [1302.467, 1316.1070000000002], [1316.1070000000002, 1326.8370000000002], [1326.8370000000002, 1341.3370000000002], [1341.3370000000002, 1352.3070000000002], [1352.3070000000002, 1364.5170000000003], [1364.5170000000003, 1379.8770000000002], [1379.8770000000002, 1392.7870000000003], [1392.7870000000003, 1405.5770000000002], [1405.5770000000002, 1417.8670000000002], [1417.8670000000002, 1429.6370000000002], [1429.6370000000002, 1440.0410000000002], [1440.0410000000002, 1453.2910000000002], [1453.2910000000002, 1465.161], [1465.161, 1477.391], [1477.391, 1489.5910000000001], [1489.5910000000001, 1500.351], [1500.351, 1512.971], [1512.971, 1523.021], [1523.021, 1533.1009999999999], [1533.1009999999999, 1543.1309999999999], [1543.1309999999999, 1556.2409999999998], [1556.2409999999998, 1570.1309999999999], [1570.1309999999999, 1581.6009999999999], [1581.6009999999999, 1594.8909999999998], [1594.8909999999998, 1605.9609999999998], [1605.9609999999998, 1617.0609999999997], [1617.0609999999997, 1628.5809999999997], [1628.5809999999997, 1641.1009999999997], [1641.1009999999997, 1652.0609999999997], [1652.0609999999997, 1665.4409999999998], [1665.4409999999998, 1677.1609999999998], [1677.1609999999998, 1687.8509999999999], [1687.8509999999999, 1700.331], [1700.331, 1712.1109999999999], [1712.1109999999999, 1723.9409999999998], [1723.9409999999998, 1736.9909999999998], [1736.9909999999998, 1747.3109999999997], [1747.3109999999997, 1760.4909999999998], [1760.4909999999998, 1773.8409999999997], [1773.8409999999997, 1787.2009999999996], [1787.2009999999996, 1797.3709999999996], [1797.3709999999996, 1810.1309999999996], [1810.1309999999996, 1824.1309999999996], [1824.1309999999996, 1837.1709999999996], [1837.1709999999996, 1847.6109999999996], [1847.6109999999996, 1858.1909999999996], [1858.1909999999996, 1869.2109999999996], [1869.2109999999996, 1882.3009999999995], [1882.3009999999995, 1893.1309999999994], [1893.1309999999994, 1903.6109999999994], [1903.6109999999994, 1917.0309999999995], [1917.0309999999995, 1930.3509999999994], [1930.3509999999994, 1940.9709999999993], [1940.9709999999993, 1951.0909999999992], [1951.0909999999992, 1965.9909999999993], [1965.9909999999993, 1979.9109999999994], [1979.9109999999994, 1992.9309999999994], [1992.9309999999994, 2004.4609999999993], [2004.4609999999993, 2015.2309999999993], [2015.2309999999993, 2025.4509999999993], [2025.4509999999993, 2038.1309999999994], [2038.1309999999994, 2051.9609999999993], [2051.9609999999993, 2062.7319999999995], [2062.7319999999995, 2073.8999999999996], [2073.8999999999996, 2086.1009999999997], [2086.1009999999997, 2096.6289999999995], [2096.6289999999995, 2108.4389999999994], [2108.4389999999994, 2119.3789999999995], [2119.3789999999995, 2132.5489999999995], [2132.5489999999995, 2145.1489999999994], [2145.1489999999994, 2157.888999999999], [2157.888999999999, 2171.5789999999993], [2171.5789999999993, 2184.6089999999995], [2184.6089999999995, 2196.5989999999993], [2196.5989999999993, 2207.1889999999994], [2207.1889999999994, 2217.9879999999994], [2217.9879999999994, 2230.2989999999995], [2230.2989999999995, 2242.3789999999995], [2242.3789999999995, 2254.1889999999994], [2254.1889999999994, 2268.0189999999993], [2268.0189999999993, 2279.2089999999994], [2279.2089999999994, 2290.0189999999993], [2290.0189999999993, 2301.8589999999995], [2301.8589999999995, 2312.5689999999995], [2312.5689999999995, 2327.0989999999997], [2327.0989999999997, 2339.189], [2339.189, 2353.859], [2353.859, 2364.899], [2364.899, 2375.589], [2375.589, 2388.739], [2388.739, 2398.969], [2398.969, 2415.009], [2415.009, 2427.669], [2427.669, 2440.499], [2440.499, 2452.649], [2452.649, 2463.379], [2463.379, 2474.1349999999998], [2474.1349999999998, 2484.1949999999997], [2484.1949999999997, 2496.5849999999996], [2496.5849999999996, 2508.9549999999995], [2508.9549999999995, 2520.5349999999994], [2520.5349999999994, 2530.8449999999993], [2530.8449999999993, 2542.1049999999996], [2542.1049999999996, 2553.0549999999994], [2553.0549999999994, 2566.1849999999995], [2566.1849999999995, 2576.3649999999993], [2576.3649999999993, 2587.1249999999995], [2587.1249999999995, 2597.5749999999994], [2597.5749999999994, 2607.5949999999993], [2607.5949999999993, 2619.6449999999995], [2619.6449999999995, 2630.7549999999997], [2630.7549999999997, 2642.4649999999997], [2642.4649999999997, 2653.8949999999995], [2653.8949999999995, 2668.1449999999995], [2668.1449999999995, 2679.6949999999997], [2679.6949999999997, 2693.6549999999997], [2693.6549999999997, 2708.8549999999996], [2708.8549999999996, 2721.6249999999995], [2721.6249999999995, 2735.0549999999994], [2735.0549999999994, 2746.7649999999994], [2746.7649999999994, 2758.4049999999993], [2758.4049999999993, 2773.644999999999], [2773.644999999999, 2784.034999999999], [2784.034999999999, 2797.218999999999], [2797.218999999999, 2809.3289999999993], [2809.3289999999993, 2821.0789999999993], [2821.0789999999993, 2831.428999999999], [2831.428999999999, 2841.8089999999993], [2841.8089999999993, 2855.5279999999993], [2855.5279999999993, 2867.1089999999995], [2867.1089999999995, 2878.4189999999994], [2878.4189999999994, 2889.4689999999996], [2889.4689999999996, 2902.8789999999995], [2902.8789999999995, 2914.6289999999995], [2914.6289999999995, 2925.1889999999994], [2925.1889999999994, 2937.638999999999], [2937.638999999999, 2948.508999999999], [2948.508999999999, 2960.168999999999], [2960.168999999999, 2971.108999999999], [2971.108999999999, 2983.738999999999], [2983.738999999999, 2997.638999999999], [2997.638999999999, 3011.8689999999992], [3011.8689999999992, 3022.9589999999994], [3022.9589999999994, 3034.7189999999996], [3034.7189999999996, 3045.6289999999995], [3045.6289999999995, 3055.7189999999996], [3055.7189999999996, 3057.3899999999994]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [126, 665, 967, 1431, 2090, 2466, 2790, 3057]}
{"example_id": "mit153@@MITRES6_012S18_L07_300k", "text": [" In this last lecture of this unit, we continue with some of  our earlier themes, and then introduce one new notion, the  notion of independence of random variables. ", "We will start by elaborating a bit more on the subject of  conditional probability mass functions.  We have already discussed the case where we condition a  random variable on an event. ", "Here we will talk about conditioning a random variable  on another random variable, and we will develop yet  another version of the total probability and total ", "expectation theorems.  There are no new concepts here, just new notation.  I should say, however, that notation is important, because ", "it guides you on how to think about problems in the most  economical way.  The one new concept that we will introduce is the notion ", "of independence of random variables.  It is actually not an entirely new concept.  It is defined more or less the same way as independence of  events, and has a similar intuitive interpretation. ", "Two random variables are independent if information  about the value of one of them does not change your model or  beliefs about the other. ", "On the mathematical side, we will see that independence  leads to some additional nice properties  of means and variances.   We will conclude this lecture and this unit on discrete ", "random variables by considering a rather difficult  problem, the hat problem.  We will see that by being systematic and using some of  the tricks that we have learned, we can calculate the ", "mean and variance of a rather complicated random variable.    We have already introduced the concept of the conditional PMF  of a random variable, X, given an event A. We will now ", "consider the case where we condition on the value of  another random variable Y. That is, we let A be the event  that some other random variable, Y, takes on a ", "specific value, little y.  In this case, we're talking about a conditional  probability of the form shown here. ", "The conditional probability--  that X takes on a specific value, given that the random  variable Y takes on another specific value.  And we use this notation to indicate those conditional ", "probabilities.  As usual, the subscripts indicate the situation that  we're dealing with.  That is, we're dealing with the distribution of the random  variable X and we're conditioning on values of the ", "other random variable, Y.  Using the definition now of conditional probabilities this  can be written as the probability that both events ", "happen divided by the probability of the  conditioning event.  ", "We can turn this expression into PMF notation.  And this leads us to this definition  of conditional PMFs.  The conditional PMF is defined to be the ratio ", "of the joint PMF--  this is the probability that we have here--  by the corresponding marginal PMF.  And this is the probability that we have here.  Now, remember that conditional probabilities are only defined ", "when the conditioning event has a positive probability,  when this denominator is positive.  Similarly, the conditional PMF will only be defined for those ", "little y that have positive probability of occurring.  Now, the conditional PMF is a function of two arguments, ", "little x and little y.  But the best way of thinking about the conditional PMF is  that we fix the value, little y, and then view this ", "expression here as a function of x.  As a function of x, it gives us the probabilities of the  different x's that may occur in the conditional universe. ", "And these probabilities must, of course, sum to 1.  Again, we're keeping y fixed.  We live in a conditional universe where y takes on a  specific value. ", "And here we have the probabilities of the different  x's in that universe.  And these sum to 1.   Note that if we change the value of little y, we will, of ", "course, get a different conditional PMF for the random  variable X. So what we're really dealing with in this  instance is that we have a family of conditional PMFs, ", "one conditional PMF for every possible value of little y.  And for every possible value of little y, we have a  legitimate PMF who's values add to 1. ", "Let's look at an example.  Consider the joint PMF given in this table.  Let us condition on the event that Y is equal to 2, which ", "corresponds to this row in the diagram.   We need to know the value of the marginal at this point, so ", "we start by calculating the probability of Y at value 2.  And this is found by adding the entries in  this row of the table. ", "And we find that this is 5 over 20.  Then we can start calculating entries of  the conditional PMF.  So for example, the probability that X takes on ", "the value of 1 given that Y takes the value of 2, it is  going to be this entry, which is 0, divided by 5/20, which ", "gives us 0.  We can find the next entry, the probability of X taking  the value of 2, given that Y takes the value of 2 will be ", "this entry, 1/20 divided by 5/20.  So it's going to be 1/5.   And we can continue with the other two entries. ", "And we can actually even plot the result once we're done.  And what we have is that at 1, we have a probability of 0. ", "At 2, we have a probability of 1/5.   At 3, we have a probability of 3/20 divided ", "5/20, which is 3/5.  And at 4, we have, again, a probability of 1/5. ", " So what we have plotted here is the conditional PMF.  It's a PMF in the variable x, where x ranges over the ", "possible values, but where we have fixed the value of y to  be equal to 2.  Now, we could have found this conditional PMF even faster ", "without doing any divisions by following the intuitive  argument that we have used before.  We live in this conditional universe.  We have conditioned on Y being equal to 2. ", "The conditional probabilities will have the same proportions  as the original probabilities, except that they needed to be  scaled so that they add to 1.  So they should be in the proportions of 0, 1, 3, 1. ", "And for these to add to 1, we need to put everywhere a  denominator of 5.  So the proportions are indeed 0, 1, 3, and 1. ", "Pictorially, the conditional PMF has the same form as the  corresponding slice of the joint PMF, except, again, that ", "the entries of that slice are renormalized so that the  entries add to 1.  And finally, an observation--  we can take the definition of the conditional PMF and turn ", "it around by moving the denominator to the other side  and obtain a formula, which is a version of the  multiplication rule. ", "The probability that X takes a value little x and Y takes a  value little y is the product or the probability that Y  takes this particular value times the conditional ", "probability that X takes on the particular value little x,  given that Y takes on the particular value little y.  We also have a symmetrical relationship if we interchange ", "the roles of X and Y. As we discussed earlier in this  course, the multiplication rule can be used to specify  probability models. ", "One way of modeling two random variables is by  specifying the joint PMF.  But we now have an alternative, indirect, way  using the multiplication rule. ", "We can first specify the distribution of Y and then  specify the conditional PMF of X for any given  value of little y. ", "And this completely determines the joint PMF, and so we have  a full probability model.  We can also provide similar definitions of conditional ", "PMFs for the case where we're dealing with more than two  random variables.  In this case, notation is pretty self-explanatory.  By looking at this expression here, you can probably guess ", "that this stands for the probability that random  variable X takes on a specific value, conditional on the  random variables Y and Z taking on some ", "other specific values.  Using the definition of conditional probabilities,  this is the probability that all events happen divided by ", "the probability of the conditioning event, which, in  our case, is the event that Y takes on a specific value and  simultaneously, Z takes another specific value. ", "In PMF notation, this is the ratio of the joint PMF of the  three random variables together, divided by the joint ", "PMF of the two random variables Y and Z. As another  example, we could have an expression like this, which, ", "again, stands for the probability that these two  random variables take on specific values, conditional ", "on this random variable taking on another value.  Finally, we can have versions of the multiplication rule for  the case where we're dealing with more ", "than two random variables.  Recall the usual multiplication rule.  For three events happening simultaneously, let's apply  this multiplication rule for the case where the event, A, ", "stands for the event that the random variable X takes on a  specific value.  Let B be the event that Y takes on a specific value, and ", "C be the event that the random variable Z takes  on a specific value.  Then we can take this relation, the multiplication  rule, and translate it into PMF notation. ", "The probability that all three events happen is equal to the  product of the probability that the first event happens.  Then we have the conditional probability that the second ", "event happens given that the first happened, times the  conditional probability that the third event happens--  this one-- given that the first  two events have happened. ", "  We will now talk about conditional expectations of  one random variable given another.  As we will see, there will be nothing new here, except for ", "older results but given in new notation.  Any PMF has an associated expectation.  And so conditional PMFs also have associated expectations, ", "which we call conditional expectations.  We have already seen them for the case where we condition on  an event, A.  The case where we condition on random variables ", "is exactly the same.  We let the event, A, be the event that Y takes on a  specific value. ", "And then we calculate the expectation using the relevant  conditional probabilities, those that are given by the  conditional PMF.  So the conditional expectation of X given that Y takes on a ", "certain value is defined as the usual expectation, except  that we use the conditional probabilities that apply given  that Y takes on a specific value little y. ", "Recall now the expected value rule for ordinary  expectations.  And also the Expected Value Rule for conditional  expectations given an event, something that we ", "have already seen.  Now, in PMF notation, the expected value rule takes a  similar form.  The event, A is replaced by the specific event that Y ", "takes on a specific value.  And in that case, the conditional PMF given the  event A is just the conditional PMF given that  random variable Y takes on a specific value, little y. ", "For the case where we condition on events, we also  developed a version of the total probability theorem and  the total expectation theorem. ", "We can do the same when we condition on random variables.  So suppose that the sample space has been partitioned  into n, disjoint scenarios. ", "The total probability theorem tells us that the probability  of the event that random variable X takes on a value ", "little x, can be found by taking the probabilities of  this event under each one of the possible scenarios.  And then weighing those probabilities according to the ", "probabilities of the different scenarios.  Now, suppose that we are dealing with a random variable  that takes values in a set consisting of n elements. ", " And let us consider scenarios Ai, the i-th scenario is the ", "event that the random variable Y takes on the  i-th possible value.  We can apply the total probability  theorem to this situation. ", "We can find the probability that the random variable X  takes on a certain value, little x, by considering the  probability of this event happening under each possible ", "scenario, where a scenario is that Y took on a specific  value, and then weigh those probabilities according to the ", "probabilities of the different scenarios.   The story with the total  expectation theorem is similar.  We know that an expectation can be found by taking the ", "conditional expectations under each one of the scenarios and  weighing them according to the probabilities of  the different scenarios.  Again, let the event that Y takes on a specific value be a ", "different scenario.  And with this correspondence we obtain the following  version of the total expectation theorem. ", "We have a sum of different terms.  And each term in the sum is the probability of a given  scenario times the expected value of X under this ", "particular scenario.   At this point, I have to add a comment of a more  mathematical flavor.  We have been talking about a partition of the sample space ", "into finitely many scenarios.  But if Y takes on values in a discrete but infinite set, for ", "example, if Y can take on any integer value, the argument  that we have given is not quite complete.  Fortunately, the total probability theorem and the ", "total expectation theorem, they both remain true, even  for the case where Y ranges over an infinite set as long ", "as the random variable X has a well-defined expectation.  For the total probability theorem, the proof for the  general case can be carried out without a lot of ", "difficulty, just using the countable additivity axiom.  However, for the total expectation theorem, it takes  some harder mathematical work. ", "And this is beyond our scope.  But we will just take this fact for granted, that the  total expectation theorem carries over to the case where  we're adding over an infinite sequence of possible values of ", "Y.  In the rest of the course we will often use the total  expectation theorem, including in cases where Y ranges over  an infinite discrete set. ", "In fact, we will see that this theorem is an extremely useful  tool that can be used to divide and  conquer complicated models.  ", " We now come to a very important concept, the concept  of independence of random variables.  We are already familiar with the notion of independence of  two events. ", "We have the mathematical definition, and the  interpretation is that conditional probabilities are  the same as unconditional ones.  Intuitively, when you are told that B occurred, this does not ", "change your beliefs about A, and so the conditional  probability of A is the same as the unconditional  probability.  We have a similar definition of independence of a random ", "variable and an event A. The mathematical definition is  that event A and the event that X takes on a specific ", "value, that these two events are independent in the  ordinary sense.  So the probability of both of these events happening is the  product of their individual probabilities. ", "But we require this to be true for all values of little x.  Intuitively, if I tell you that A occurred, this is not ", "going to change the distribution of the random  variable x.   This is one interpretation of what independence means in ", "this context.  And this has to be true for all values of little x, that  is, when [the]  event occurs, the probabilities of any ", "particular little x [are]  going to be the same as the original unconditional  probabilities.  We also have a symmetrical interpretation.  If I tell you the value of X, then the conditional ", "probability of event A is not going to change.  It's going to be the same as the unconditional probability.  And again, this is going to be the case for all values of X. ", "So, no matter what they tell you about X, your beliefs  about A are not going to change.  We can now move and define the notion of independence of two ", "random variables.  The mathematical definition is that the event that X takes on  a value little x and the event that Y takes on a value little ", "y, these two events are independent, and this is true  for all possible values of little x and little y.  In PMF notation, this relation here can be ", "written in this form.  And basically, the joint PMF factors out as a product of  the marginal PMFs of the two random variables. ", "Again, this relation has to be true for all possible little x  and little y.  What does independence mean?  When I tell you the value of y, and no matter what value I ", "tell you, your beliefs about X will not change.  So that the conditional PMF of X given Y is going to be the ", "same as the unconditional PMF of X. And this has to be true  for any values of the arguments of these PMFs. ", " There is also a symmetric interpretation, which is that  the conditional PMF of Y given X is going to be the same as ", "the unconditional PMF of Y. We have the symmetric  interpretation because, as we can see from this definition,  X and Y have symmetric roles. ", "Finally, we can define the notion of independence of  multiple random variables by a similar relation.  Here, the definition is for the case of three random ", "variables, but you can imagine how the definition for any  finite number of random variables will go.  Namely, the joint PMF of all the random variables can be ", "expressed as the product of the  corresponding marginal PMFs.  What is the intuitive interpretation of  independence here?  It means that information about some of the random ", "variables will not change your beliefs, the probabilities,  about the remaining random variables.  Any conditional probabilities and any conditional PMFs will ", "be the same as the unconditional ones.  In the real world, independence models situations  where each of the random variables is generated in a ", "decoupled manner, in a separate probabilistic  experiment.  And these probabilistic experiments do not interact  with each other and have no common sources of uncertainty. ", "  Let us now consider a simple example.  Let random variables X and Y be described by a joint PMF  which is the one shown in this table. ", "Question--  are X and Y independent?  We can try to answer this question by using the  definition of independence.  But it is actually more instructive to proceed in a ", "somewhat more intuitive way.  We look at this table, and we observe that the value of one  is possible for X. In particular, the probability ", "that X takes the value of one, this is the marginal  probability, this can be found by adding the probabilities of  all of the outcomes in this column, which, in this case, ", "is 3 over 20.  Suppose now that somebody tells you the value of Y. For  example, I tell you that Y happens to be equal to one, in ", "which case you are transported into this universe.  In this universe, the conditional probability that X  takes a value of one, given that Y takes a value of one, ", "what is it?  In this universe, there's zero probability  associated to this outcome.  So this probability is zero, which is  different than 3 over 20. ", "And since these two numbers are different, this means that  information from Y changes our beliefs about what's going to  happen to X. And so, we do not have independence. ", "So again, intuitively, in the beginning, we thought that X  equal to one was possible.  But information given by Y, namely that Y is equal to one, ", "tells us that, actually, X equals to one is impossible.  Information about Y changed our beliefs about X, so X and  Y are dependent. ", " Now, when we first introduced the notion of independence  some time ago, we also introduced the notion of  conditional independence.  And we said that conditional independence is the same as ", "ordinary independence, except that it would be applied to a  conditional universe.  Something similar can be done for the case of random ", "variables as well.  So suppose, for example, that someone tells us that the  outcome of the experiment was such that it belongs ", "to this blue set.  This is the set where X is less than or equal to 2, and Y  is larger than or equal to three.  So we're given this information, and this is now ", "our new conditional model.  The question is, within this new conditional model are  random variables X and Y independent? ", "Let's just right down the conditional model, where I'm  only showing the four possible outcomes that are allowed in  the conditional model.  All the others, of course, will have zero probability in ", "the conditional model.  So in the conditional model, probabilities will keep the  same proportions as in the unconditional model--  and the proportions are 1, 2, 2, 4-- ", "but then they need to be scaled, or normalized, so that  they add to 1.  And to make them add to 1, we need to divide them all by 9. ", "In this conditional model, this is the joint PMF of the  two random variables X and Y. Let us find the marginal PMFs.  To find the marginal PMF of X, we add the ", "entries in this column.  And we get here 1/3, and here 2/3.  And to find the marginal PMF of y, we add the  entries in this [row] ", "to find 2/3.  And we adds the entries in that [row]  to find 1/3.  So this is the marginal PMF of x.  That's the marginal PMF of Y. And now we notice that this ", "entry of the joint PMF is 1/3 times 1/3, the  product of the marginals.  This entry is the product of 1/3 times 2/3, the product of  the marginals, and so on for the remaining entries. ", "So each entry of the joint PMF is equal to the product of the  corresponding entries of the marginal PMFs.  And this is the definition of independence. ", "So in this conditional blue universe, we do have  independence.  And the way that this was established was to check that  the joint PMF factors as a product of marginal PMFs. ", "  When we have independence, does anything interesting  happen to expectations?  We know that, in general, the expected value of a function  of random variables is not the same as applying the function ", "to the expected values.  And we also know that there are some exceptions where we  do get equality.  This is the case where we are dealing with linear functions ", "of one or more random variables.  Note that this last property is always true and does not ", "require any independence assumptions.  When we have independence, there is one additional  property that turns out to be true. ", "The expected value of the product of two independent  random variables is the product of  their expected values.  Let us verify this relation. ", "We are dealing here with the expected value of a function  of random variables, where the function is defined to be the ", "product function.   So to calculate this expected value, you can use the  expected value rule. ", "And we are going to get the sum over all x, the sum over  all y, of g of xy, but in this case, g of xy is x times y. ", "And then we weigh all those values according to the  probabilities as given by the joint PMF.  Now, using independence, this sum can be changed into the ", "following form--  the joint PMF is the product of the marginal PMFs.   And now when we look at the inner sum over all values of ", "y, we can take outside the summation those terms that do  not depend on y, and so this term and that term. ", "And this is going to yield a summation over x of x times  the marginal PMF of X, and then the summation over all y ", "of y times the marginal PMF of Y. But now we recognize that  here we have just the expected value of Y. And then we will ", "be left with another expression, which is the  expected value of X. And this completes the argument. ", "Now, consider a function of X and another function of Y. X  and Y are independent. ", "Intuitively, the value of X does not give you any new  information about Y, so the value of g of X does not to  give you any new information about h of Y. So on the basis ", "of this intuitive argument, the functions g of X and h of  Y are also independent of each other.  Therefore, we can apply the fact that we have already ", "proved, but with g of X in the place of X and h of Y in the  place of Y. And this gives us this more general fact that ", "the expected value of the product of two functions of  independent random variables is equal to the product of the  expectations of these functions. ", "We could also prove this property directly without  relying on the intuitive argument.  We could just follow the same steps as in this derivation. ", "Wherever there is an X, we would write g of X, and  wherever there is a Y, we would write h of Y. And the  same algebra would go through, and we would end up with the ", " Let us now revisit the variance and see what happens  in the case of independence.  Variances have some general properties that we have  already seen. ", "However, since we often add random variables, we would  like to be able to say something about the variance  of the sum of two random variables.  Unfortunately, the situation is not so simple, and in ", "general, the variance of the sum is not the same as the sum  of the variances.  We will see an example shortly.  On the other hand, when X and Y are independent, the ", "variance of the sum is equal to the sum of the variances,  and this is a very useful fact.  Let us go through the derivation of this property. ", "But to keep things simple, let us assume just for the sake of  the derivation, that the two random variables have 0 mean.  ", "So in that case, the variance over the sum is just the  expected value of the square of the sum.  ", "And we can expand the quadratic and write this as  the expectation of X squared plus 2 X Y plus Y squared. ", "Then we use linearity of expectations to write this as  the expected value of X squared plus twice the  expected value of X times Y and then plus the expected ", "value of Y squared.  Now, the first term is just the variance of X because we  have assumed that we have 0 mean. ", " The last term is similarly the variance of Y. How about the  middle term? ", "Because of independence, the expected value of the product  is the same as the product of the expected values, and the ", "expected values are 0 in our case.  So this term, because of independence, is going to be  equal to 0.  In particular, what we have is that the expected value of XY ", "equals the expected value of X times the expected value of Y,  equal to 0.  And so we have verified that indeed the variance of the sum ", "is equal to the sum of the variances.  Let us now look at some examples.   Suppose that X is the same random variable as Y. Clearly, ", "this is a case where independence fails to hold.  If I tell you the value of X, then you know the value of Y.  So in this case, the variance of the sum is the same as the ", "variance of twice X. Since X is the same as Y, X plus Y is  2 times X. And then using this property for the variance, ", "what happens when we multiply by a constant?  This is going to be 4 times the variance of X.  In another example, suppose that X is the negative of Y. ", "In that case, X plus Y is identically equal to 0.  So we're dealing with a random variable that  takes a constant value.  In particular, it is always equal to its mean, and so the ", "difference from the mean is always equal to 0, and so the  variance will also evaluate to 0.  So we see that the variance of the sum can take quite ", "different values depending on the sort of interrelation that  we have between the two random variables.  So these two examples indicate that knowing the variance of ", "each one of the random variables is not enough to say  much about the variance of the sum.  The answer will generally depend on how the two random  variables are related to each other and what kind of ", "dependencies they have.  As a last example, suppose now that X and Y are independent.  X is independent from Y, and therefore X is also ", "independent from minus 3Y.  Therefore, this variance is equal to the sum of the  variances of X and of minus 3Y. ", "And using the facts that we already know, this is going to  be equal to the variance of X plus 9 times the variance of ", "Y.  As an illustration of the usefulness of the property of  the variance that we have just established, we will now use ", "it to calculate the variance of a binomial random variable.  Remember that a binomial with parameters n and p corresponds  to the number of successes in n independent trials. ", " We use indicator variables.  This is the same trick that we used to calculate the expected  value of the binomial.  So the random variable X sub i is equal to 1 if the i-th ", "trial is a success and is a 0 otherwise.  And as we did before, we note that X, the total number of ", "successes, is the sum of those indicator variables.  Each success makes one of those variables equal to 1, so  by adding those indicator variables, we're just counting ", "the number of successes.  The key point to note is that the assumption of independence  that we're making is essentially the assumption ", "that these random variables Xi are independent of each other.  So we're dealing with a situation where we have a sum ", "of independent random variables, and according to  what we have shown, the variance of X is going to be  the sum of the variances of the Xi's. ", " Now, the Xi's all have the same distribution so all these ", "variances will be the same.  It suffices to consider one of them.  Now, X1 is a Bernoulli random variable with parameter p.  We know what its variance is-- ", "it is p times 1 minus p.  And therefore, this is the formula for the variance of a ", "binomial random variable.    We will now study a problem which is quite difficult to ", "approach in a direct brute force manner but becomes  tractable once we break it down into simpler pieces using ", "several of the tricks that we have learned so far.  And this problem will also be a good opportunity for  reviewing some of the tricks and techniques  that we have developed. ", "The problem is the following.  There are n people.  And let's say for the purpose of illustration that we have 3  people, persons 1, 2, and 3. ", " And each person has a hat.  They throw their hats inside a box.  And then each person picks a hat at random out of that box. ", "So here are the three parts.   And one possible outcome of this experiment is that person ", "1 ends up with hat number 2, person 2 ends up with hat  number 1, person 3 ends up with hat number 3.  We could indicate the hats that each person got by noting ", "here the numbers associated with each  person, the hat numbers.  And notice that this sequence of numbers, which is a ", "description of the outcome of the experiment, is just a  permutation of the numbers 1, 2, 3 of the hats.  So we permute the hat numbers so that we can place them next ", "to the person that got each one of the hats.  In particular, we have n factorial possible outcomes.  This is the number of possible permutations. ", "What does it mean to pick hats at random?  One interpretation is that every  permutation is equally likely.  And since we have n factorial permutations, each permutation ", "would have a probability of 1 over n factorial.  But there's another way of describing our model, which is  the following. ", "Person 1 gets a hat at random out of the three available.  Then person 2 gets a hat at random out of  the remaining hats. ", "Then person 3 gets the remaining hat.  Each time that there is a choice, each one of the  available hats is equally likely to be picked  as any other hat. ", "Let us calculate the probability, let's say, that  this particular permutation gets materialized.  The probability that person 1 gets hat number 2 is 1/3. ", "Then we're left with two hats.   Person 2 has 2 hats to choose from.  The probability that it picks this particular hat ", "is going to be 1/2.  And finally, person 3 has only 1 hat available, so it will be  picked with probability 1.  So the probability of this particular permutation is one ", "over 3 factorial.  But you can repeat this argument and consider any  other permutation, and you will always be getting the  same answer. ", "Any particular permutation has the same probability, one over  3 factorial.  The same argument goes through for the case of general n, n  people and n hats. ", "And we will find that any permutation will have the same  probability, 1/n factorial.  Therefore, the process of picking one hat at a time is ", "probabilistically identical to a model in which we simply  state that all permutations are equally likely.   Now that we have described our model and our process and the ", "associated probabilities, let us consider the question we  want to answer.  Let X be the number of people who get their own hat back. ", "For example, for the outcome that we have drawn here, the  only person who gets their own hat back is person 3.  And so in this case X happens to take the value of 1. ", "What we want to do is to calculate the expected value  of the random variable X. The problem is difficult because  if you try to calculate the PMF of the random variable X ", "and then use the definition of the expectation to calculate  this sum, you will run into big difficulties. ", "Calculating this quantity, the PMF of X, is difficult.  And it is difficult because there is no simple expression  that describes it. ", "So we need to do something more intelligent, find some  other way of approaching the problem.  The trick that we will use is to employ indicator variables. ", "Let Xi be equal to one 1 if person i selects their own hat  and 0 otherwise.  So then, each one of the Xi's is 1 whenever a person has ", "selected their own hat.  And by adding all the 1's that we may get, we obtain the  total number of people who have selected their own hats. ", "This makes things easier, because now to calculate the  expected value of X it's sufficient to calculate the  expected value of each one of those terms and add the  expected values, which we're allowed to ", "do because of linearity.  So let's look at the typical term here.  What is the expected value of Xi?  If you consider the first description or our model, all ", "permutations are equally likely, this description is  symmetric with respect to all of the persons.  So the expected value of Xi should be the same as the ", "expected value of X1.   Now, to calculate the expected value of X1, we will consider ", "the sequential description of the process in which 1 is the  first person to pick a hat.  Now, since X1 is a Bernoulli random variable that takes  values 0 or 1, the expected value of X1 is just the ", "probability that X1 is equal to 1.  And if person 1 is the first one to choose a hat, that  person has probability 1/n of obtaining the correct hat. ", "So each one of these random variables has an expected  value of 1/n.   The expected value of X by linearity is going to be the ", "sum of the expected values.   There is n of them.  Each expected value is 1/n. ", " And so the final answer is 1.  This is the expected value of the random variable X. ", "Let us now move and try to calculate a more difficult  quantity, namely, the variance of X. How shall we proceed? ", "Things would be easiest if the random variables Xi were  independent.  Because in that case, the variance of X would be the sum ", "of the variances of the Xi's.  But are the Xi's independent?  Let us consider a special case.  Suppose that we only have two persons and that I tell you ", "that the first person got their own hat back.  In that case, the second person must have also gotten  their own hat back. ", "If, on the other hand, person 1 did not to get their own hat  back, then person 2 will not get their own hat back either.  Because in this scenario, person 1 gets hat 2, and that ", "means that person 2 gets hat 1.  So we see that knowing the value of the random variable  X1 tells us a lot about the value of the  random variable X2. ", "And that means that the random variables  X1 and X2 are dependent.  More generally, if I were to tell you that the first n  minus 1 people got their own hats back, then the last ", "remaining person will have his or her own hat  available to be picked.  That's going to be the only available hat.  And then person n we also get their hat back. ", "So we see that the information about some of the Xi's gives  us information about the remaining Xn.  And again, this means that the random  variables are dependent. ", "Since we do not have independence, we cannot find  the variance by just adding the variances of the different  random variables.  But we need to do a lot more work in that direction. ", "In general, whenever we need to calculate variances, it is  usually simpler to carry out the calculation using this  alternative form for the variance. ", "So let us start towards a calculation of the expected  value of X squared.  Now the random variable X squared, by simple algebra, is ", "this expression times itself.  And by expanding the product we get all  sorts of cross terms.  Some of these cross terms will be of the type X1 times Xi or ", "X2 times X2.  These will be terms of this form, and there is n of them.  And then we get cross terms, such as X1 times X2, X1 times ", "X3, X2 times X1, and so on.  How many terms do we have here?  Well, if we have n terms multiplying n other terms we ", "have a total of n squared terms.  n are already here, so the remaining terms, which are the  cross terms, will be n squared minus n. ", "Or, in a simpler form, it's n times n minus 1.  So now how are we going to calculate the expected value ", "of X squared?  Well, we will use linearity of expectations.  So we need to calculate the expected value of Xi squared,  and we also need to calculate the expected value of Xi Xj ", "when i is different from j.  Let us start with Xi squared.   First, if we use the symmetric description of our model, all ", "permutations are equally likely, then all persons play  the same role.  There's symmetry in the problem.  So Xi squared has the same distribution as X1 squared. ", " Then, X1 is a 0-1 random variable, a  Bernoulli random variable.  So X1 squared will always take the same numerical value as ", "the random variable X1.   This is a very special case which happens only because a  random variable takes values in {0, 1}. ", "And 0 squared is the same as 0.  1 squared is the same as 1.  This expected value is something that we have already  calculated, and it is 1/n. ", " Let us now move to the calculation of the expectation  of a typical term inside the sum. ", "So let i be different than j, and look at the  expected value of Xi Xj.  Once more, because of the symmetry of the probabilistic  model, it doesn't matter which i and j we are considering. ", "So we might as well consider the product of X1 with X2.   Now, X1 and X2 take values 0 and 1. ", "And the product of the two also takes values 0 and 1.  So this is a Bernoulli random variable, and so the  expectation of that random variable is just the  probability that this random variable is equal to 1. ", " But for the product to be equal to 1, the only way that  this can happen is if both of these random variables happen ", "to be equal to 1.   Let us now turn to the sequential  description of the model. ", "The probability that the first person gets their own hat back  and the second person gets their own hat back is the  probability that the first one gets their own hat back, and ", "then multiplied by the conditional probability that  the second person gets their own hat back, given that the  first person got their own hat back. ", "What are these probabilities?  The probability that a person gets their  own hat back is 1/n.   Given that person 1 got their own hat back, person 2 is ", "faced with a situation where there are n  minus 1 available hats.  And one of those is that person's hat.  So the probability that person 2 will also pick his or her ", "own hat is 1 over n minus 1.   Now we are in a position to calculate the expected value ", "of X squared.  The expected value of X squared consists of the sum of ", "n expected values, each one of which is equal to 1/n plus so ", "many expected values, because we have so many terms, each  one of which, by this calculation, is 1/n times 1 ", "over n minus 1.  And we see that we get cancellations here.  And we obtain 1 plus 1, which is equal to 2.  ", "On the other hand we have this term that we need to subtract.  We found previously that the expected value of  X is equal to 1.  So we need to subtract 1. ", "And the final answer to our problem is that the variance  of X is also equal to 1.  ", "So what we saw in this problem is that we can deal with quite  complicated models, but by breaking them down into more  manageable pieces, first break down the random variable X as ", "a sum of different random variables, then taking the  square of this and break it down into a number of  different terms, and then by considering one term at a ", "time, we can often end up with the solutions or the answers  to problems that would have been  otherwise quite difficult.  "], "vid_duration": [11.48, 12.23, 10.71, 10.65, 10.12, 13.92, 10.98, 12.55, 12.53, 13.259, 13.78, 10.741, 13.06, 13.009, 10.711, 11.82, 12.45, 12.899, 11.011, 10.48, 12.59, 11.42, 11.18, 12.5, 12.54, 11.47, 11.31, 13.14, 10.57, 13.83, 11.09, 12.86, 13.0, 13.38, 13.639, 10.466, 12.395, 10.5, 12.589, 14.011, 11.31, 12.169, 12.641, 10.17, 11.63, 12.88, 10.25, 11.05, 11.25, 11.03, 14.39, 14.45, 11.89, 13.01, 10.72, 12.28, 10.84, 12.34, 11.97, 11.73, 12.66, 12.18, 10.65, 12.204, 12.31, 11.3, 11.12, 13.41, 14.91, 11.02, 13.95, 15.29, 11.36, 10.0, 10.28, 12.68, 14.125, 10.555, 11.0, 10.77, 10.3, 12.96, 15.07, 11.18, 10.37, 11.45, 10.31, 12.86, 10.89, 13.14, 10.62, 13.21, 11.28, 10.576, 11.19, 14.58, 11.23, 11.61, 11.32, 13.51, 13.29, 11.82, 13.89, 13.82, 10.84, 10.08, 13.24, 11.02, 15.44, 11.56, 11.135, 15.355, 11.3, 10.79, 11.34, 12.96, 12.28, 12.51, 10.39, 11.261, 12.5, 10.68, 12.58, 11.85, 13.08, 12.5, 12.59, 11.76, 10.63, 12.51, 10.98, 11.2, 11.74, 10.66, 11.73, 12.45, 10.77, 11.99, 10.09, 12.79, 13.17, 11.6, 13.27, 12.712, 11.64, 11.16, 10.51, 13.09, 10.71, 12.92, 12.72, 19.0, 12.32, 13.01, 15.39, 11.58, 13.55, 10.7, 13.26, 10.93, 10.36, 10.49, 10.45, 11.13, 11.01, 13.23, 12.19, 10.61, 15.61, 14.56, 11.96, 17.74, 10.01, 10.95, 10.98, 14.21, 12.12, 11.55, 10.67, 11.36, 12.47, 12.28, 10.21, 11.02, 12.52, 11.82, 15.0, 11.36, 10.86, 11.48, 14.015, 10.235, 11.6, 11.77, 10.73, 11.973, 11.397, 12.71, 10.68, 10.172, 10.32, 11.17, 11.135, 14.945, 13.079, 14.241, 10.38, 11.55, 11.69, 12.95, 11.96, 11.13, 10.95, 12.65, 10.33, 13.563, 10.017, 11.17, 10.92, 14.02, 11.22, 13.13, 14.32, 10.22, 10.97, 11.25, 12.13, 11.97, 12.87, 13.55, 10.16, 10.14, 14.19, 15.05, 11.86, 11.61, 15.05, 12.0, 11.57, 13.67, 11.28, 13.229, 11.221, 13.65, 11.34, 13.12, 12.56, 11.01, 13.28, 11.91, 11.87, 10.33, 11.95, 11.23, 11.8, 13.52, 11.85, 13.86, 10.83, 10.47, 10.45, 13.1, 11.6, 13.775, 11.405, 10.43, 11.9, 11.27, 11.47, 12.39, 12.21, 11.57, 10.93, 12.38, 14.96, 10.5, 12.25, 15.4, 10.57, 10.485], "stet": [[0, 11.48], [11.48, 23.71], [23.71, 34.42], [34.42, 45.07], [45.07, 55.19], [55.19, 69.11], [69.11, 80.09], [80.09, 92.64], [92.64, 105.17], [105.17, 118.429], [118.429, 132.209], [132.209, 142.95], [142.95, 156.01], [156.01, 169.019], [169.019, 179.73000000000002], [179.73000000000002, 191.55], [191.55, 204.0], [204.0, 216.899], [216.899, 227.91], [227.91, 238.39], [238.39, 250.98], [250.98, 262.4], [262.4, 273.58], [273.58, 286.08], [286.08, 298.62], [298.62, 310.09000000000003], [310.09000000000003, 321.40000000000003], [321.40000000000003, 334.54], [334.54, 345.11], [345.11, 358.94], [358.94, 370.03], [370.03, 382.89], [382.89, 395.89], [395.89, 409.27], [409.27, 422.909], [422.909, 433.375], [433.375, 445.77], [445.77, 456.27], [456.27, 468.859], [468.859, 482.87], [482.87, 494.18], [494.18, 506.349], [506.349, 518.99], [518.99, 529.16], [529.16, 540.79], [540.79, 553.67], [553.67, 563.92], [563.92, 574.9699999999999], [574.9699999999999, 586.2199999999999], [586.2199999999999, 597.2499999999999], [597.2499999999999, 611.6399999999999], [611.6399999999999, 626.0899999999999], [626.0899999999999, 637.9799999999999], [637.9799999999999, 650.9899999999999], [650.9899999999999, 661.7099999999999], [661.7099999999999, 673.9899999999999], [673.9899999999999, 684.8299999999999], [684.8299999999999, 697.17], [697.17, 709.14], [709.14, 720.87], [720.87, 733.53], [733.53, 745.7099999999999], [745.7099999999999, 756.3599999999999], [756.3599999999999, 768.5639999999999], [768.5639999999999, 780.8739999999998], [780.8739999999998, 792.1739999999998], [792.1739999999998, 803.2939999999998], [803.2939999999998, 816.7039999999997], [816.7039999999997, 831.6139999999997], [831.6139999999997, 842.6339999999997], [842.6339999999997, 856.5839999999997], [856.5839999999997, 871.8739999999997], [871.8739999999997, 883.2339999999997], [883.2339999999997, 893.2339999999997], [893.2339999999997, 903.5139999999997], [903.5139999999997, 916.1939999999996], [916.1939999999996, 930.3189999999996], [930.3189999999996, 940.8739999999996], [940.8739999999996, 951.8739999999996], [951.8739999999996, 962.6439999999996], [962.6439999999996, 972.9439999999995], [972.9439999999995, 985.9039999999995], [985.9039999999995, 1000.9739999999996], [1000.9739999999996, 1012.1539999999995], [1012.1539999999995, 1022.5239999999995], [1022.5239999999995, 1033.9739999999995], [1033.9739999999995, 1044.2839999999994], [1044.2839999999994, 1057.1439999999993], [1057.1439999999993, 1068.0339999999994], [1068.0339999999994, 1081.1739999999995], [1081.1739999999995, 1091.7939999999994], [1091.7939999999994, 1105.0039999999995], [1105.0039999999995, 1116.2839999999994], [1116.2839999999994, 1126.8599999999994], [1126.8599999999994, 1138.0499999999995], [1138.0499999999995, 1152.6299999999994], [1152.6299999999994, 1163.8599999999994], [1163.8599999999994, 1175.4699999999993], [1175.4699999999993, 1186.7899999999993], [1186.7899999999993, 1200.2999999999993], [1200.2999999999993, 1213.5899999999992], [1213.5899999999992, 1225.4099999999992], [1225.4099999999992, 1239.2999999999993], [1239.2999999999993, 1253.1199999999992], [1253.1199999999992, 1263.9599999999991], [1263.9599999999991, 1274.039999999999], [1274.039999999999, 1287.279999999999], [1287.279999999999, 1298.299999999999], [1298.299999999999, 1313.739999999999], [1313.739999999999, 1325.299999999999], [1325.299999999999, 1336.434999999999], [1336.434999999999, 1351.789999999999], [1351.789999999999, 1363.089999999999], [1363.089999999999, 1373.879999999999], [1373.879999999999, 1385.219999999999], [1385.219999999999, 1398.179999999999], [1398.179999999999, 1410.459999999999], [1410.459999999999, 1422.969999999999], [1422.969999999999, 1433.359999999999], [1433.359999999999, 1444.620999999999], [1444.620999999999, 1457.120999999999], [1457.120999999999, 1467.800999999999], [1467.800999999999, 1480.380999999999], [1480.380999999999, 1492.2309999999989], [1492.2309999999989, 1505.3109999999988], [1505.3109999999988, 1517.8109999999988], [1517.8109999999988, 1530.4009999999987], [1530.4009999999987, 1542.1609999999987], [1542.1609999999987, 1552.7909999999988], [1552.7909999999988, 1565.3009999999988], [1565.3009999999988, 1576.2809999999988], [1576.2809999999988, 1587.4809999999989], [1587.4809999999989, 1599.2209999999989], [1599.2209999999989, 1609.880999999999], [1609.880999999999, 1621.610999999999], [1621.610999999999, 1634.060999999999], [1634.060999999999, 1644.830999999999], [1644.830999999999, 1656.820999999999], [1656.820999999999, 1666.910999999999], [1666.910999999999, 1679.7009999999989], [1679.7009999999989, 1692.870999999999], [1692.870999999999, 1704.4709999999989], [1704.4709999999989, 1717.7409999999988], [1717.7409999999988, 1730.4529999999988], [1730.4529999999988, 1742.092999999999], [1742.092999999999, 1753.252999999999], [1753.252999999999, 1763.762999999999], [1763.762999999999, 1776.852999999999], [1776.852999999999, 1787.562999999999], [1787.562999999999, 1800.482999999999], [1800.482999999999, 1813.202999999999], [1813.202999999999, 1832.202999999999], [1832.202999999999, 1844.522999999999], [1844.522999999999, 1857.532999999999], [1857.532999999999, 1872.922999999999], [1872.922999999999, 1884.502999999999], [1884.502999999999, 1898.052999999999], [1898.052999999999, 1908.752999999999], [1908.752999999999, 1922.012999999999], [1922.012999999999, 1932.942999999999], [1932.942999999999, 1943.302999999999], [1943.302999999999, 1953.792999999999], [1953.792999999999, 1964.242999999999], [1964.242999999999, 1975.3729999999991], [1975.3729999999991, 1986.3829999999991], [1986.3829999999991, 1999.6129999999991], [1999.6129999999991, 2011.8029999999992], [2011.8029999999992, 2022.412999999999], [2022.412999999999, 2038.022999999999], [2038.022999999999, 2052.582999999999], [2052.582999999999, 2064.542999999999], [2064.542999999999, 2082.282999999999], [2082.282999999999, 2092.292999999999], [2092.292999999999, 2103.242999999999], [2103.242999999999, 2114.222999999999], [2114.222999999999, 2128.432999999999], [2128.432999999999, 2140.552999999999], [2140.552999999999, 2152.102999999999], [2152.102999999999, 2162.7729999999992], [2162.7729999999992, 2174.1329999999994], [2174.1329999999994, 2186.602999999999], [2186.602999999999, 2198.8829999999994], [2198.8829999999994, 2209.0929999999994], [2209.0929999999994, 2220.1129999999994], [2220.1129999999994, 2232.6329999999994], [2232.6329999999994, 2244.4529999999995], [2244.4529999999995, 2259.4529999999995], [2259.4529999999995, 2270.8129999999996], [2270.8129999999996, 2281.673], [2281.673, 2293.153], [2293.153, 2307.1679999999997], [2307.1679999999997, 2317.403], [2317.403, 2329.0029999999997], [2329.0029999999997, 2340.7729999999997], [2340.7729999999997, 2351.5029999999997], [2351.5029999999997, 2363.4759999999997], [2363.4759999999997, 2374.8729999999996], [2374.8729999999996, 2387.5829999999996], [2387.5829999999996, 2398.2629999999995], [2398.2629999999995, 2408.4349999999995], [2408.4349999999995, 2418.7549999999997], [2418.7549999999997, 2429.9249999999997], [2429.9249999999997, 2441.06], [2441.06, 2456.005], [2456.005, 2469.0840000000003], [2469.0840000000003, 2483.3250000000003], [2483.3250000000003, 2493.7050000000004], [2493.7050000000004, 2505.2550000000006], [2505.2550000000006, 2516.9450000000006], [2516.9450000000006, 2529.8950000000004], [2529.8950000000004, 2541.8550000000005], [2541.8550000000005, 2552.9850000000006], [2552.9850000000006, 2563.9350000000004], [2563.9350000000004, 2576.5850000000005], [2576.5850000000005, 2586.9150000000004], [2586.9150000000004, 2600.4780000000005], [2600.4780000000005, 2610.4950000000003], [2610.4950000000003, 2621.6650000000004], [2621.6650000000004, 2632.5850000000005], [2632.5850000000005, 2646.6050000000005], [2646.6050000000005, 2657.8250000000003], [2657.8250000000003, 2670.9550000000004], [2670.9550000000004, 2685.2750000000005], [2685.2750000000005, 2695.4950000000003], [2695.4950000000003, 2706.465], [2706.465, 2717.715], [2717.715, 2729.8450000000003], [2729.8450000000003, 2741.815], [2741.815, 2754.685], [2754.685, 2768.235], [2768.235, 2778.395], [2778.395, 2788.535], [2788.535, 2802.725], [2802.725, 2817.775], [2817.775, 2829.635], [2829.635, 2841.2450000000003], [2841.2450000000003, 2856.2950000000005], [2856.2950000000005, 2868.2950000000005], [2868.2950000000005, 2879.8650000000007], [2879.8650000000007, 2893.5350000000008], [2893.5350000000008, 2904.815000000001], [2904.815000000001, 2918.044000000001], [2918.044000000001, 2929.265000000001], [2929.265000000001, 2942.915000000001], [2942.915000000001, 2954.255000000001], [2954.255000000001, 2967.375000000001], [2967.375000000001, 2979.935000000001], [2979.935000000001, 2990.945000000001], [2990.945000000001, 3004.2250000000013], [3004.2250000000013, 3016.135000000001], [3016.135000000001, 3028.005000000001], [3028.005000000001, 3038.335000000001], [3038.335000000001, 3050.2850000000008], [3050.2850000000008, 3061.515000000001], [3061.515000000001, 3073.315000000001], [3073.315000000001, 3086.835000000001], [3086.835000000001, 3098.685000000001], [3098.685000000001, 3112.545000000001], [3112.545000000001, 3123.375000000001], [3123.375000000001, 3133.8450000000007], [3133.8450000000007, 3144.2950000000005], [3144.2950000000005, 3157.3950000000004], [3157.3950000000004, 3168.9950000000003], [3168.9950000000003, 3182.7700000000004], [3182.7700000000004, 3194.1750000000006], [3194.1750000000006, 3204.6050000000005], [3204.6050000000005, 3216.5050000000006], [3216.5050000000006, 3227.7750000000005], [3227.7750000000005, 3239.2450000000003], [3239.2450000000003, 3251.635], [3251.635, 3263.8450000000003], [3263.8450000000003, 3275.4150000000004], [3275.4150000000004, 3286.3450000000003], [3286.3450000000003, 3298.7250000000004], [3298.7250000000004, 3313.6850000000004], [3313.6850000000004, 3324.1850000000004], [3324.1850000000004, 3336.4350000000004], [3336.4350000000004, 3351.8350000000005], [3351.8350000000005, 3362.4050000000007], [3362.4050000000007, 3372.890000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [110, 758, 1128, 1436, 1719, 1981, 2410, 3379]}
{"example_id": "mit153@@MITRES6_012S18_L08_300k", "text": [" In this lecture, we start our discussion of continuous  random variables.  We will focus on the case of a single continuous random  variable, and we'll describe its distribution using a ", "so-called probability density function, an object that will  replace the PMFs from the discrete case. ", "We will then proceed to define the expectation and the  variance of a continuous random variable, and we'll see  that their basic properties remain unchanged. ", "There will be one new concept--  the cumulative distribution function, which will allow us  to describe, in a unified manner, both discrete and ", "continuous random variables, even so-called mixed random  variables that have both a discrete and  a continuous component. ", "In the course of this lecture, we will also introduce some of  the most common continuous random variables--  uniform, exponential, and normal. ", "We will pay special attention to the normal distribution and  the ways that we can calculate the associated probabilities.    In this segment, we introduce the concept of continuous ", "random variables and their characterization in terms of  probability density functions, or PDFs for short.  Let us first go back to discrete random variables.  A discrete random variable takes values ", "in a discrete set.  There is a total of one unit of probability assigned to the  possible values.  And the PMF tells us exactly how much of this probability ", "is assigned to each value.  So we can think of the bars in the PMF as point masses with  positive weight that sit on top of each ", "possible numerical value.  And we can calculate the probability that the random  variable falls inside an interval by adding all the  masses that sit on top of that interval. ", "So for example, if we're looking at the interval from a  to b, the probability of this interval is equal to the sum  of the probabilities of these three masses that fall inside ", "this interval.  On the other hand, a continuous random variable  will be taking values over a continuous range--  for example, the real line or an interval on the real line. ", "In this case, we still have one total unit of probability  mass that is assigned to the possible values of the random  variable, except that this unit of mass is spread all ", "over the real line.  But it is not spread in a uniform manner.  Some parts of the real line have more  mass per unit length.  Some have less. ", "How much mass exactly is sitting on top of each part of  the real line is described by the probability density  function, this function plotted here, which we denote ", "with this notation.  The letter f will always indicate that we are dealing  with a PDF.  And the subscript will indicate which random variable  we're talking about. ", "We use the probability density function to calculate the  probability that X lies in a certain interval--  let's say the interval from a to b. ", "And we calculate it by finding the area under the PDF that  sits on top of that interval.  So this area here, the shaded area, is the probability that ", "X stakes values in this interval.  Think of probability as snow fall.  There is one pound of snow that has fallen on  top of the real line. ", "The PDF tells us the height of the snow accumulated over a  particular point.  We then find the weight of the overall amount of snow sitting ", "on top of an interval by calculating the area under  this curve.  Of course, mathematically, area under the curve is just  an integral. ", "So the probability that X takes values in this interval  is the integral of the PDF over this particular interval. ", "What properties should the PDF have?  By analogy with the discrete case, a PDF must be  non-negative, because we do not want to get negative ", "probabilities.  In the discrete case, the sum of the PMF entries has to be  equal to 1.  In the continuous case, X is certain to lie in the interval ", "between minus infinity and plus infinity.  So letting a be minus infinity and b plus infinity, we should  get a probability of 1. ", "So the total area under the PDF, when we integrate over  the entire real line, should be equal to 1.  These two conditions are all that we need in order to have ", "a legitimate PDF.  We can now give a formal definition of what a  continuous random variable is.  A continuous random variable is a random variable whose ", "probabilities can be described by a PDF according to a  formula of this type.  An important point-- ", "the fact that a random variable takes values on a  continuous set is not enough to make it what we call a  continuous random variable.  For a continuous random variable, we're ", "asking for a bit more--  that it can be described by a PDF, that a formula of this  type is valid.   Now, once we have the probabilities of intervals as ", "given by a PDF, we can use of additivity to calculate the  probabilities of more complicated sets.  For example, if you're interested in the probability ", "that X lies between 1 and 3 or that X lies between 4 and 5-- ", "so this is the probability that X falls in a region that  consists of two disjoint intervals.  We find the probability of the union of these two intervals, ", "by additivity, by adding the probabilities of the two  intervals, since these intervals are disjoint.  And then we can use the PDF to calculate the probabilities of ", "each one of these intervals according to this formula.   At this point, you may be wondering what happened to the  sample space in all this discussion. ", "Well, there is still an underlying sample space  lurking in the background.   And different outcomes in the sample space result in ", "different numerical values for the  random variable of interest.   And when we talk about the probability that X takes ", "values between some numbers a and b, what we really mean is  the probability of those outcomes for which the ", "resulting value of X lies inside  this particular interval.  So that's what probability means.  On the other hand, once we have a PDF in our hands, we ", "can completely forget about the underlying sample space.  And we can carry out any calculations we may be  interested in by just working with the PDF. ", "So as we move on in this course, the sample space will  be moved offstage.  There will be less and less mention of it.  And we will be working just directly with PDFs or with ", "PMFs if we are dealing with discrete random variables.  Let us now build a little bit on our understanding of what  PDFs really are by looking at ", "probabilities of small intervals.  Let us look at an interval that starts at some a and goes  up to some number a plus delta. ", "So here, delta is a positive number.  But we're interested in the case where  delta is very small.  Let us look at the probability that X falls in this interval. ", "The probability that X lies inside this interval is the  area of this region.  ", "On the other hand, as long as f does not change too much  over this little interval, which will be the case if we  have a continuous density f, then we can approximate the ", "area we have of this region by the area of a rectangle where  we keep the height constant.  The area of this rectangle is equal to the height, which is ", "the value of the PDF at the point a, times the base of the  rectangle, which is equal to delta.  So this gives us an interpretation of PDFs in ", "terms of probabilities of small intervals.  If we take this factor of delta and send it to the other  side in this approximate equality, we see that the ", "value of the PDF can be interpreted as probability per  unit length.  So PDFs are not probabilities.  They are densities. ", "Their units are probability per unit length.  Now, if the probability per unit length is finite and the  length delta is sent to 0, we will get 0 probability. ", "More formally, if we look at this integral and we let b to  be the same as a, then we obtain the probability that X ", "is equal to a.  And on that side, we get an integral  over a 0 length interval.  And that integral is going to be 0. ", "So we obtain that the probability that X takes a  value equal to a specific, particular point--  that probability is going to be equal to 0. ", "So for a continuous random variable, any particular point  has 0 probability.  Yet somehow, collectively, the infinitely many points in an ", "interval together will have positive probablility.  Is this a puzzle?  Not really.  That's exactly what happens, also, with the  ordinary notion of length. ", "Single points have 0 length, yet by putting together lots  of points, we can create a set that has a positive length. ", "And a final consequence of the fact that individual points  have 0 length.  Using the additivity axiom, the probability that our ", "random variable takes values inside an interval is equal to  the probability that our random variable takes a value  of a plus the probability that our random variable takes a ", "value of b plus the probability that our random  variable is strictly between a and b.  According to our discussion, this term is equal to 0. ", "And this term is equal to 0.  And so we conclude that the probability of a closed  interval is the same as the  probability of an open interval.  When calculating probabilities, it does not ", "matter whether we include the endpoints or not.    Let us now give an example of a continuous random variable--  the uniform random variable.  It is patterned after the discrete random variable. ", "Similar to the discrete case, we will have a range of  possible values.  In the discrete case, these values would be the integers  between a and b. ", "In the continuous case, any real number between a and b  will be possible.  In the discrete case, these values were equally likely.  In the continuous case, at all points, we have the same ", "height for the probability density function.  And as a consequence, if we take two intervals that have  the same length, then these two intervals will be assigned ", "the same probability.  Intuitively, uniform random variables model  the following situation.  We know that the numerical value of the random variable  will be between a and b. ", "But we know nothing more.  We have no reason to believe that certain locations are  more likely than others.  And in this sense, the uniform random variable models a  situation of complete ignorance. ", "By the way, since probabilities must add to 1,  the area of this rectangle must be equal to 1.  And therefore, the height of this rectangle has to be 1 ", "over b minus a, so that we have a height of 1  over b minus a.  We have a length of b minus a.  So the product of the two, which is the  area, is equal to 1. ", "Finally, here's a more general PDF, which  is piecewise constant.  One thing to notice is that this, in particular, tells us  that PDFs do not have to be continuous functions. ", "They can have discontinuities.  Of course, for this to be a legitimate PDF, the total area  under the curve, which is the sum of the areas of the ", "rectangles that we have here, must be equal to 1.  With a piecewise constant PDF, we can calculate probabilities  of events fairly easy.  For example, if you wish to find the probability of this ", "particular interval, which is going to be the area under the  curve, that area really consists of two pieces.  We find the areas of these two rectangles, add them up, and ", "this gives us the total probability of  this particular interval.  So at this point, our agenda, moving  forward, will be twofold. ", "First, we will introduce some interesting  continuous random variables.  We just started with the presentation of the uniform  random variable.  And then, we will also go over all of the concepts and ", "results that we have developed for discrete random variables  and develop them again for their continuous counterparts.   ", "We now start with our agenda of developing continuous  counterparts of everything we have done for  discrete random variables.  Let us look at the concept of expectation. ", "In the discrete case, we have defined expectation as a  weighted average of the values X of the random variable,  weighted according to their corresponding probabilities. ", "In the continuous case, we define expectation in a  similar way--  as a weighted average over the possible values of X, weighted  according to the corresponding value of the density. ", "Points where the density is higher--  for example, here--  will receive a higher weight in this calculation.  But of course, since we are averaging over a continuous ", "set, the summation will have to be replaced by an integral.  This will be a recurrent theme in this unit.  Definitions or formulas for the continuous case look ", "exactly like the discrete ones, except that PMFs are  replaced by densities, as here.  The PMF is replaced by a density.  And summations are replaced by integrals. ", "The intuition is usually the same in both the discrete and  the continuous case.  However, the intuition is usually much clearer, much  easier to visualize in the discrete case. ", "So the best strategy is to make sure to understand fully  the intuition for the discrete case and just rely on it.  At this point, let me add some fine print-- ", "a mathematical side point.  This integral or the expectation will not be always  well defined.  For this integral to make sense, we will need to make ", "the assumption that the integral of the absolute value  of little x, weighted according to the density,  gives us a finite result.  Unless we explicitly say something different, we will ", "always assume that we're dealing with random variables  that satisfy this condition.  And so the expectation is well defined mathematically.  Coming back to the big picture, regarding ", "expectations, the intuition remains the same as in the  discrete case-- that the expectation represents the  average of the values we expect to see in a very large  number of independent repetitions of the experiment. ", "In fact, there are also theorems to this effect, but  these will have to wait until later in this class when we  study limit theorems.  Another intuitive interpretation that is true ", "for both the discrete and the continuous case is that the  expectation corresponds to the center of gravity of the  probability distribution.  So in this diagram, it might be somewhere around here. ", "And similarly, for the continuous diagram, the center  of gravity might be somewhere around here.  And if it happens that the distribution, the PMF or the ", "PDF, happens to be symmetric around a certain point, then  that point will be equal to the expectation.  Expectations of continuous random variables have all the ", "properties you might expect.  For example, non-negative random variables have  non-negative expectations.  Random variables that lie inside an interval have ", "average values or expectations that also lie  inside the same interval.  The derivation is exactly the same as for the discrete case.  There is also an expected value rule. ", "In the discrete case, it took on this form.  In the continuous case, we obtain an analogous form in  which the summation is replaced by [an] integral. ", "And instead of weighing according to the PMF, we now  weigh according to the density function.  The derivation of the expected value rule for the continuous ", "case is a little more complicated than the one that  we gave for the discrete case.  But it's sufficient for us to know that it is true and that ", "it has an intuitive meaning that runs along the same lines  as the intuitive meaning that we had for the discrete case.  As an instance of how we might apply the expected value rule, ", "if you wish to calculate the expected value of the square  of a continuous random variable, you  would proceed as follows.  You would integrate over the entire real line the value of ", "the function, which is X squared in our case, weighted  according to the density.   Finally, a most important property of ", "expectations, is linearity.  Linearity is still true for continuous random  variables as well.  And the way it is derived is exactly the same as in the ", "discrete case.  Namely, we apply the expected value rule to this function of  the random variable X and separate  out the various terms. ", "The story regarding variances is exactly the same as in the  discrete case.  We define variances using the same definition.  And of course, here, mu stands for the expected value of the ", "random variable X.  To calculate the variance, we can use the expected value  rule, which takes this form in the continuous case.  And we apply the expected value rule for the case where ", "we're dealing with the expected value of this  particular function, so that in this instance, the  functions g of x is x minus mu squared. ", "So by applying the expected value rule, we obtain the  integral from minus infinity to infinity, the functions g  of x, weighted according to the density, and then we carry ", "out the integration.  We also define the standard deviation--  same way as in the discrete case.  We have a property about a variance of linear functions, ", "of a random variable, namely, that if we add a constant to a  random variable, this has no effect on the variance.  But if we multiply a random variable by a constant, the ", "variance gets multiplied by the square of that constant.  Finally, when calculating the variance, it is often  convenient to use this alternative formula in which ", "the variance is calculated by finding the expected value of  the square of the random variable and also using the  expected value of the random variable, but squared and ", "subtracted from the first term.  This relation and this relation are both derived  exactly the same way as in the discrete case. ", "And there's no reason to repeat those derivations.    As an example of a mean-variance calculation, we  will now consider the continuous uniform random ", "variable which we have introduced a little earlier.  This is the continuous analog of the discrete uniform, for  which we have already seen formulas for the corresponding  mean and variance. ", "So let us now calculate the mean or expected value for the  continuous case.  The mean is defined as an integral that ranges over the  entire real line. ", "On the other hand, we recognize that the density is  equal to 0 outside the interval from a to b, and  therefore, there is going to be no contribution to the ", "integral from those x's outside that interval.  This means that we can integrate just over the  interval from a to b. ", "And inside that interval, the value of the density is 1  over b minus a.  We can carry out this integration and find an answer  equal to a plus b over 2, which, interestingly, also ", "happens to be the same as in the discrete case.  In fact, we could find this answer without having to run  this integration.  We could just recognize that this PDF is symmetric around ", "the midpoint of the interval, and the midpoint is  a plus b over 2.  We now continue with what is involved in the calculation of ", "the expected value of the square of the random variable.  Using the expected value rule, this is the integral of x  squared times the density, but because of the same argument ", "as before, we only need to integrate from a to b.  We can evaluate this integral, and the answer turns out to be  1 over (b minus a) times (b cube over 3 ", "minus a cube over 3).  The reason why these cubic terms appear is that the  integral of the x square function is x ", "cube divided by 3.  Now that we have this quantity available, we're ready to  calculate the variance using this alternative formula, ", "which, as we have often discussed, usually provides us  a quicker way to carry out the calculation.  We take this term, insert it here. ", "We take the square of this term, insert it here.  Carry out some algebra, and eventually we find an answer  which is equal to b minus a squared over 12. ", "And this is the formula for the variance of a uniform  random variable.  We can take the square root of this expression to find the ", "standard deviation, and the standard deviation is going to  be b minus a divided by the square root of 12.  A few observations. ", "First, the formula looks quite similar to the formula for the  variance that we had in the discrete case, except that in  the discrete case, we have this extra  additive factor of 2. ", "More interestingly, and perhaps more important, is  that the standard deviation is proportional to the width of  this uniform.  The wider it is, the larger the standard ", "deviation will be.  And this conforms to our intuition that the standard  deviation captures the width of a particular distribution.  And the variance, of course, becomes larger when ", "the width is larger.  And as far as the variance is concerned, it increases with  the square of the length of the interval over which we  have our distribution.  ", " We now introduce a new of random variable, the  exponential random variable.  It has a probability density function that is determined by  a single parameter lambda, which is a positive number. ", "And the form of the PDF is as shown here.  Note that the PDF is equal to 0 when x is negative, which  means that negative values of X will not occur. ", "They have zero probability.  And so our random variable is a  non-negative random variable.  The shape of the PDF is as shown in this diagram.  It's 0 for negative values, and then for positive values, ", "it starts off, it starts off at a value equal to lambda.  This is because if you plug in x equal to 0 in this  expression, you get lambda times e to the 0, which leaves ", "you just with lambda.  So it starts off with lambda, and then it decays  at the rate of lambda.  Notice that when lambda is small, the initial value of ", "the PDF is small.  But then the decay rate is also small, so that the PDF  extends over a large range of x's.  On the other hand, when lambda is large, then the PDF starts ", "large, so there's a fair amount of probability in the  vicinity of 0.  But then it decays pretty fast, so there's much less  probability for larger values of x. ", "Another observation to make is that the shape of this  exponential PDF is quite similar to the shape of the  geometric PDF that we have seen before, the only  difference being that here we have a discrete distribution, ", "but here we have a continuous analog of that distribution.   Let's now carry out a calculation.  Let us fix some positive number a, and let us calculate ", "the probability that our random variable takes a value  larger than or equal to a.  So what we're trying to do is to calculate the probability  that the random variable falls inside this ", "interval from a to infinity.  Whenever we have a PDF, we can calculate the probability of  falling inside an interval by integrating over that interval ", "the value of the PDF.   Therefore, we have to calculate  this particular integral.  And at this point, we can recall a fact from calculus, ", "namely that the integral of the function e to the ax is 1  over a times e to the ax. ", "We can use this fact by making the correspondence between a  and minus lambda.  ", "And using this correspondence, we can now continue the  calculation of our integral.  We have a factor of lambda.  And then a factor of 1 over a, where a ", "stands for minus lambda.  So we get the minus 1 over lambda.  And then the same exponential function, e to the  minus lambda x. ", "And because the range of integration is from a to  infinity, we need to evaluate the integral at a and infinity  and take the difference. ", "Now, this lambda cancels that lambda.  We're left with a minus sign.  And from the upper limit, we get e to the minus lambda  times infinity. ", "And then from the second term, we have a minus sign that  cancels with that minus sign and gives us a plus term, plus  e to the minus lambda a. ", "Now, e to the minus infinity is 0.  And so we're left just with the last term.  And the answer is e to the minus lambda a. ", "So this gives us the tail probability for an exponential  random variable.  It tells us that the probability of falling higher ", "than a certain number falls off exponentially with that  certain number.  An interesting additional observation--  if we let a equal to 0 in this calculation, we obtain the ", "integral of the PDF over the entire range of x's.  And in that case, this probability becomes e to the  minus lambda 0, which is equal to 1. ", "So we have indeed verified that the integral of this PDF  is equal to 1, as it should be.  ", "Now, let's move to the calculation of the expected  value of this random variable.  We can use the definition.  Since the PDF is non-zero only for positive values of x, we ", "only need to integrate from 0 to infinity.  We integrate x times the PDF.   And this is an integral that you may have encountered at ", "some point before.  It is evaluated by using integration by parts.  And the final answer turns out to be 1 over lambda. ", "Regarding the calculation of the expected value of the  square of the random variable, we need to write down a  similar integral, except that now we ", "will have here x squared.   This is just another integration by parts, only a  little more tedious. ", "And the answer turns out to be 2 over lambda squared.  Finally, to calculate the variance, we use the handy ", "formula that we have.   And the expected value of X squared is this term. ", "The expected value of X is this term.  When we square it, it becomes similar to this term, but we  have here a 2.  There we have a 1.  And so we're left with just 1 over lambda squared. ", "And this is the variance of the  exponential random variable.  Notice that when lambda is small, the PDF, as we  discussed before, falls off very slowly, which means that ", "large x's are also quite possible.  And so the average of this random variable will be on the  higher side.  The PDF extends over a large range, and that translates ", "into having a large mean.  And because when that happens, the PDF actually spreads, the  variance also increases.  And this is reflected in this formula for the variance. ", " The exponential random variable is, in many ways,  similar to the geometric.  For example, the expression for the mean, which is 1 over ", "lambda, can be contrasted with the expression for the mean of  the geometric, which is 1 over p.  ", "And the relationship between these two distributions, the  discrete and the continuous analog, is a theme that we  will revisit several times.  At this point, let me just say that the exponential random ", "variable is used to model many important  and real world phenomena.  Generally, it models the time that we have to wait until  something happens. ", "In the discrete case, the geometric random variable  models the time until we see a success for the first time.  In the continuous case, an exponential can be used to ", "model the time until a customer arrives, the time  until a light bulb burns out, the time until a machine  breaks down, the time until you receive an email, or maybe ", "the time until a meteorite falls on your house.    We have seen that several properties, such as, for  example, linearity of expectations, are common for  discrete and continuous random variables. ", "For this reason, it would be nice to have a way of talking  about the distribution of all kinds of random variables  without having to keep making a distinction between the  different types-- ", "discrete or continuous.  This leads us to describe the distribution of a random  variable in a new way, in terms of a so-called  cumulative distribution function or CDF for short. ", "A CDF is defined as follows.  The CDF is a function of a single argument, which we  denote by little x in this case.  And it gives us the probability that the random ", "variable takes a value less than or equal to this  particular little x.  We will always use uppercase Fs to indicate CDFs.  And we will always have some subscripts that indicate which ", "random variable we're talking about.  The beauty of the CDF is that it just involves a  probability--  a concept that is well defined, no matter what kind  of random variable we're dealing with. ", "So in particular, if X is a continuous random variable,  the probability that X is less than or equal  to a certain number--  this is just the integral of the PDF over that range from ", "minus infinity up to that number.  As a more concrete example, let us consider a uniform  random variable that ranges between a and b, and let us ", "just try to plot the corresponding CDF.  The CDF is a function of little x.  And the form that it takes depends on what kind of x  we're talking about. ", "If little x falls somewhere here to the left of a, and we  ask for the probability that our random variable takes  values in this interval, then this probability will be 0 ", "because all of the probability of this uniform is  between a and b.  Therefore, the CDF is going to be 0 for values of x less than ", "or equal to a.  How about the case where x lies somewhere  between a and b?  In that case, the probability that our random variable falls ", "to the left of here--  this is whatever mass there is under the PDF when we consider  the integral up to this particular point. ", "So we're looking at the area under the PDF up to this  particular point x.  This area is of the form the base of the rectangle, which ", "is x minus a, times the height of the rectangle, which is 1  over b minus a.  This is a linear function in x that takes the value of 0 when ", "x is equal to a, grows linearly, and when x reaches a  value of b, it becomes equal to 1.  ", "How about the case where x lies to the right of b?  We're talking about the probability that our random  variable takes values less than or equal to this  particular x. ", "But this includes the entire probability  mass of this uniform.  We have unit mass on this particular interval, so the  probability of falling to the left of here is equal to 1. ", "And this is the shape of the CDF for the case of a uniform  random variable.  It starts at 0, eventually it rises, and eventually it  reaches a value of 1 and stays constant. ", "Coming back to the general case, CDFs are very useful,  because once we know the CDF of a random variable, we have  enough information to calculate anything we might ", "want to calculate.  For example, consider the following calculation.  Let us look at the range of numbers from minus infinity to ", "3 and then up to 4.  If we want to calculate the probability that X is less  than or equal to 4, we can break it down as the ", "probability that X is less than or equal to 3--  this is one term--  plus the probability that X falls between 3 and 4, which ", "would be this event here.  So this equality is true because of the additivity  property of probabilities. ", "This event is broken down into two possible events.  Either x is less than or equal to 3 or x is bigger than 3 but  less than or equal to 4.  But now we recognize that if we know the CDF of the random ", "variable, then we know this quantity.  We also know this quantity, and this allows us to  calculate this quantity.  So we can calculate the probability of a  more general interval. ", "So in general, the CDF contains all available  probabilistic information about a random variable.  It is just a different way of describing the probability  distribution.  From the CDF, we can recover any quantity we ", "might wish to know.  And for continuous random variables, the CDF actually  has enough information for us to be able to recover the PDF.  How can we do that? ", "Let's look at this relation here, and let's take  derivatives of both sides.  On the left, we obtain the derivative of the CDF.  And let's evaluate it at a particular point x. ", "What do we get on the right?  By basic calculus results, the derivative of an integral,  with respect to the upper limit of the integration, is ", "just the integrand itself.  So it is the density itself.   So this is a very useful formula, which tells us that ", "once we have the CDF, we can calculate the PDF.  And conversely, if we have the PDF, we can find the CDF by  integrating.  Of course, this formula can only be correct at those ", "places where the CDF has a derivative.  For example, at this corner here, the derivative of the  CDF is not well defined.  We would get a different value if we differentiate from the ", "left, a different value when we differentiate from the  right, so we cannot apply this formula.  But at those places where the CDF is differentiable, at  those places we can find the corresponding ", "value of the PDF.  For instance, in this diagram, at this point the CDF is  differentiable.  The derivative is equal to the slope, which is this quantity. ", "And this quantity happens to be exactly the same as the  value of the PDF.  So indeed, here, we see that the PDF can be found by taking ", "the derivative of the CDF.  Now, as we discussed earlier, CDFs are relevant to all types  of random variables.  So in particular, they are also relevant to discrete ", "random variables.  For a discrete random variable, the CDF is, of  course, defined the same way, except that we calculate this  probability by adding the probabilities of all possible ", "values of the random variable that are less than  [or equal to]  the particular little x that we're considering.  So we have a summation instead of an integral. ", "Let us look at an example.  This is an example of a discrete random variable  described by a PMF.  And let us try to calculate the corresponding CDF.  The probability of falling to the left of this number, for ", "example, is equal to 0.  And all the way up to 1, there is 0 probability of getting a  value for the random variable less than that. ", "But now, if we let x to be equal to 1, then we're talking  about the probability that the random variable takes a value ", "less than or equal to 1.  And because this includes the value of 1, this probability  would be equal to 1/4.  This means that once we reach this point, the value of the ", "CDF becomes 1/4.  At this point, the CDF makes a jump.  At 1, the value of the CDF is equal to 1/4. ", "Just before 1, the value of the CDF was equal to 0.  Now what's the probability of falling to the left  of, let's say, 2?  This probability is again 1/4. ", "There's no change in the probability as we keep moving  inside this interval.  So the CDF stays constant, until at some point we reach  the value of 3. ", "And at that point, the probability that the random  variable takes a value less than or equal to 3 is going to  be the probability of a 3 plus the probability of a 1 which ", "becomes 3 over 4.   For any other x in this interval, the probability that ", "the random variable takes a value less than this number  will stay at 1/4 plus 1/2, so the CDF stays constant.  And at this point, the probability of being less than ", "or equal to 4, this probability becomes 1.  And so the CDF jumps once more to a value of 1. ", "Again, at the places where the CDF makes a jump, which one of  the two is the correct value?  The correct value is this one.  And this is because the CDF is defined by using a less than ", "or equal sign in the probability involved here.  So in the case of discrete random variables, the CDF  takes the form of a staircase function. ", "It starts at 0.  It ends up at 1.  It has a jump at those points where the PMF assigns a  positive mass.  And the size of the jump is exactly equal to the ", "corresponding value of the PMF.  Similarly, the size of the PMF here is 1/4, and so the size  of the corresponding jump at the CDF will ", "also be equal to 1/4.  CDFs have some general properties, and we have seen a  hint of those properties in what we have done so far. ", "So the CDF is, by definition, the probability of obtaining a  value less than or equal to a certain number little x.  It's the probability of this interval. ", "If I were to take a larger interval, and go up to some  larger number y, this would be the  probability of a bigger interval.  So that probability would only be bigger. ", "And this translates into the fact that the CDF is an  non-decreasing function.  If y is larger than or equal to x, as in this picture, then ", "the value of the CDF evaluated at that point y is going to be  larger than or equal to the CDF evaluated at that  point little x. ", "Other properties that the CDF has is that as x goes to  infinity, we're talking about the probability essentially of  the entire real line. ", "And so the CDF will converge to 1.  On the other hand, if x tends to minus infinity, so we're  talking about the probability of an interval to the left of ", "a point that's all the way out, further and further out.  That probability has to diminish, and eventually  converge to 0.  So in general, CDFs asymptotically start at 0. ", "They can never go down.  They can only go up.  And in the limit, as x goes to infinity, the CDF has to  approach 1. ", "Actually in the examples that we saw earlier, it reaches the  value of 1 after a certain finite point.  But in general, for general random variables, it might ", "only reach the value 1 asymptotically    We now introduce normal random variables, which are also  often called Gaussian random variables. ", "Normal random variables are perhaps the most important  ones in probability theory.  They play a key role in the theory of the subject, as we  will see later in this class in the context of the central ", "limit theorem.  They're also prevalent in applications for two reasons.  They have some nice analytical properties, and they're are ", "also the most common model of random noise.  In general, they are a good model of noise or randomness  whenever that noise is due to the addition of many small ", "independent noise terms, and this is a very common  situation in the real world.   We define normal random variables by specifying their ", "PDFs, and we start with the simplest case of the so-called  standard normal.  The standard normal is indicated with this shorthand  notation, and we will see shortly why this notation is ", "being used.  It is defined in terms of a PDF.  This PDF is defined for all values of x. x  can be any real number.  So this random variable can take values ", "anywhere on the real line.  And the formula for the PDF is this one.  Let us try to understand this formula.  So we have the exponential of negative x squared over 2. ", "Now, if we are to plot the x squared over 2 function, it  has a shape of this form, and it is centered at zero. ", "But then we take the negative exponential of this function.  Now, when you take the negative exponential, whenever  this thing is big, the negative exponential is going ", "to be small.  So the negative exponential would be equal to 1 when x is  equal to 0.  But then as x increases, because x squared also ", "increases, the negative exponential will fall off.  And so we obtain a shape of this kind, and symmetrically  on the other side as well. ", "And finally, there is this constant.  Where [is] this constant coming from?  Well there's a nice and not completely straightforward  calculus exercise that tells us that the integral from ", "minus infinity to plus infinity of e to the negative  x squared over 2, dx, is equal to the square root of 2 pi. ", "Now, we need a PDF to integrates to 1.  And so for this to happen, this is the constant that we  need to put in front of this expression so that the ", "integral becomes 1, and that explains the presence of this  particular constant.  What is the mean of this random variable?  Well, x squared is symmetric around 0, and for this reason, ", "the PDF itself is symmetric around 0.  And therefore, by symmetry, the mean has to be equal to 0.  And that explains this entry here. ", "How about the variance?  Well, to calculate the variance, you need to solve a  calculus problem again.  You need to integrate by parts.  ", "And after you carry out the calculation, then you find  that the variance is equal to 1, and that explains this  entry here in the notation that we have been using. ", "Let us now define general normal random variables.  General normal random variables are once more  specified in terms of the corresponding PDF, but this ", "PDF is a little more complicated, and it involves  two parameters--  mu and sigma squared, where sigma is a  given positive parameter. ", "Once more, it will have a bell shape, but this bell is no  longer symmetric around 0, and there is some control over the  width of it. ", "Let us understand the form of this PDF by focusing first on  the exponent, exactly as we did for the  standard normal case.  The exponent is a quadratic, and that quadratic is centered ", "at x equal to mu.  So it vanishes when x is equal to mu, and  becomes positive elsewhere.  Then we take the negative exponential of this quadratic, ", "and we obtain a function which is largest at x equal to mu,  and falls off as we go further away from mu. ", " What is the mean of this random variable?  Since this term is symmetric around mu, the PDF is also ", "symmetric around mu, and therefore, the mean is also  equal to mu.  How about the variance?  It turns out--  and this is a calculus exercise that we will omit-- ", "that the variance of this PDF is equal to sigma squared.  And this explains this notation here.  We're dealing with a normal that has a mean of mu and a  variance of sigma squared. ", "To get a little bit of understanding of the role of  sigma in the form of this PDF, let us consider the case where  sigma is small, and see how the ", "picture is going to change.  When sigma is small, and we plot the quadratic, sigma  being small means that this quadratic becomes larger, so ", "it rises faster, so we get a narrower quadratic.  And in that case, the negative exponential is going to fall ", "off much faster.  So when sigma is small, the PDF that we get is a narrower  PDF, and that reflects itself into the property that the ", "variance will also be smaller.   An important property of normal random variables is  that they behave very nicely when you form linear ", "functions of them.  And this is one of the reasons why they're analytically  tractable and analytically very convenient.  Here is what I mean.  Let us start with a normal random variable with a given ", "mean and variance, and let us form a linear function of that  random variable.  What is the mean of Y?  Well, we know what it is.  We have a linear function of a random variable. ", "The mean is going to be a times the expected value of X,  which is mu plus b.  What is the variance of Y?  We know what is the variance of a linear function of a ", "random variable.  It is a squared times the variance of X, which in our  case is sigma squared.  So there's nothing new so far, but there is an additional ", "important fact.  The random variable Y, of course, has the mean and  variance that we know it should have, but there is an  additional fact-- ", "namely, that Y is a normal random variable.  So normality is preserved when we form linear functions. ", "There's one special case that's we need to pay some  attention to.  Suppose that a is equal to 0.  In this case, the random variable Y is just equal to b. ", "It's a constant random variable.  It does not have a PDF.  It is a degenerate discrete random variable.  So could this fact be correct that Y is also normal? ", "Well, we'll adopt this as [a] convention.  When we have a discrete random variable, which is constant,  it takes a constant value. ", "We can think of this as a special degenerate case of the  normal with mean equal to b and with variance equal to 0. ", "Even though it is discrete, not continuous, we will still  think of it as a degenerate type of a normal random  variable, and by adopting this convention, then it will ", "always be true that a linear function of a normal random  variable is normal, even if a is equal to 0.  Now that we have the definition and some properties ", "of normal random variables, the next question is whether  we can calculate probabilities associated with  normal random variables.  This will be the subject of the next segment. ", "  We have claimed that normal random variables are very  important, and therefore we would like to be able to  calculate probabilities associated with them. ", "For example, given a normal random variable, what is the  probability that it takes a value less than 5?  Unfortunately, there are no closed form expressions that  can help us with this. ", "In particular, the CDF, the Cumulative Distribution  Function of normal random variables, is not given in  closed form.  But fortunately, we do have tables for the standard normal ", "random variable.  These tables, which take the form shown here, give us the  following information.  If we have a normal random variable, which is a standard ", "normal, they tell us the values of the cumulative  distribution function for different values of little y. ", "In terms of a picture, if this is the PDF of a standard  normal and I give you a value little y, I'm interested in  the corresponding value of the CDF, which is the ", "area under the curve.  Well, that value, the area under this curve, is exactly  what this table is giving to us.  And there's a shorthand notation for referring to the ", "CDF of the standard normal, which is just phi of y.  Let us see how we use this table.  Suppose we're interested in phi of 0. ", "Which is the probability that our standard normal takes a  value less than or equal to 0?  Well, by symmetry since the PDF is symmetric around 0, we  know that this probability should be 0.5. ", "Let's see what the table tells us.  0 corresponds to this entry, which is indeed 0.5.  Let us look up the probability that our standard normal takes ", "a value less than, let's say, 1.16.  How do we find this information?  1 is here.  And 1.1 is here. ", "1.1, and then we have a 6 in the next decimal place, which  leads us to this entry.  And so this value is 0.8770. ", "Similarly, we can calculate the probability that the  normal is less than 2.9.  How do we look up this information?  2.9 is here. ", "We do not have another decimal digit, so we're looking at  this column.  And we obtain this value, which is 0.9981. ", "And by looking at this number we can actually tell that a  standard normal random variable has extremely low  probability of being bigger than 2.9. ", "Now notice that the table specifies phi of y for y being  non-negative.  What if we wish to calculate the value, for example, of phi ", "of minus 2?  In terms of a picture, this is a standard normal.  Here is minus 2. ", "And we wish to calculate this probability.  There's nothing in the table that gives us this probability  directly, but we can argue as follows.  The normal PDF is symmetric. ", "So if we look at 2, then this probability here, which is phi  of minus 2, is the same as that probability  here, of that tail. ", "What is the probability of that tail?  It's 1, which is the overall area under the curve, minus  the area under the curve when you go up to the value of 2. ", " So this quantity is going to be the same as phi of minus 2.  And this one we can now get from the tables. ", "It's 1 minus--  let us see, 2 is here.  It's 1 minus 0.9772. ", "The standard normal table gives us probabilities  associated with a standard normal random variable.  What if we're dealing with a normal random variable that ", "has a mean and a variance that are different from those of  the standard normal?  What can we do?  Well, there's a general trick that you can do to a random ", "variable, which is the following.  Let us define a new random variable Y in this fashion.  Y measures how far away is X from the mean value. ", "But because we divide by sigma, the standard deviation,  it measures this distance in standard deviations.  So if Y is equal to 3 it means that X is 3 standard ", "deviations away from the mean.  In general, Y measures how many deviations away from the  mean are you.  What properties does this random variable have? ", "The expected value of Y is going to be equal to 0,  because we have X and we're subtracting the mean of X. So  the expected value of this term is equal to 0. ", "How about the variance of Y?  Whenever we multiply a random variable by a constant, the  variance gets multiplied by the square of that constant. ", "So we get this expression.  But the variance of X is sigma squared.  So this is equal to 1.  So starting from X, we have obtained a closely related ", "random variable Y that has the property that it has 0 mean  and unit variance.  If it also happens that X is a normal random variable, then Y ", "is going to be a standard normal random variable.  So we have managed to relate X to a standard  normal random variable.  And perhaps you can rewrite this expression in this form, ", "X equals to mu plus sigma Y where Y is  now a standard normal.  So, instead of doing calculations having to do with ", "X, we can try to calculate in terms of Y. And for Y we do  have available tables.  Let us look at an example of how this is done. ", "The way to calculate probabilities associated with  general normal random variables is to take the event  whose probability we want calculated and express it in ", "terms of standard normal random variables.  And then use the standard normal tables.  Let us see how this is done in terms of an example.  Suppose that X is normal with mean 6 and variance 4, so that ", "the standard deviation sigma is equal to 2.  And suppose that we want to calculate the probability that  X lies between 2 and 8. ", " Here's how we can proceed.  This event is the same as the event that X minus 6 takes a ", "value between 2 minus 6 and 8 minus 6.  This event is the same as the original event we were  interested in.  We can also divide both sides of this inequality by the ", "standard deviation.  And the event of interest has now been  expressed in this form.  But at this point we recognize that this is of the form X ", "minus mu over sigma.  So this random variable here is a standard  normal random variable.  ", "So the probability that X lies between 2 and 8 is the same as ", "the probability that a standard normal random  variable, call it Y, falls between these numbers minus 4  divided by 2, that's minus 2. ", "Then Y less than 1.   And now we can use the standard normal tables to  calculate this probability. ", "We have here 1 and here we have minus 2.  And we want to find the probability that our standard  normal falls inside this range.  This is the probability that it is less than 1. ", "But we need to subtract the probability of that tail so  that we're left just with this intermediate area.  So this is the probability that Y is less than 1 minus ", "the probability that Y is less than minus 2.  And finally, as we discussed earlier, the probability that  Y is less than minus 2, this is 1 minus the probability ", "that Y is less than or equal to 2.  And now we can go to the normal tables, identify the  values that we're interested in, the probability that Y is ", "less than 1, the probability that Y is less than 2, and  plug these in.  And this gives us the desired probability.  Again, the key step is to take the event of interest and by ", "subtracting the mean and dividing by the standard  deviation express that same event in an equivalent form,  but which now involves a standard  normal random variable. ", " And then finally, use the standard normal tables.  "], "vid_duration": [12.28, 10.01, 11.32, 11.05, 10.28, 10.189, 11.4, 11.81, 10.28, 10.92, 12.27, 12.26, 11.27, 12.59, 10.28, 11.709, 12.81, 10.371, 12.74, 11.2, 12.689, 10.531, 10.07, 10.27, 13.18, 10.44, 13.46, 13.13, 11.629, 11.011, 13.33, 10.279, 11.531, 13.74, 16.049, 13.281, 12.74, 11.789, 10.13, 11.881, 11.02, 11.48, 10.42, 11.76, 13.41, 11.9, 13.87, 15.28, 12.76, 10.4, 10.79, 15.66, 11.79, 10.6, 12.42, 11.06, 11.77, 11.98, 10.35, 13.4, 16.25, 11.31, 12.208, 11.39, 12.73, 11.36, 11.95, 11.39, 11.56, 12.17, 12.24, 10.61, 12.57, 12.22, 10.1, 13.74, 10.375, 10.93, 11.83, 13.48, 12.6, 10.88, 14.1, 10.73, 13.02, 11.0, 12.19, 10.98, 13.25, 11.43, 12.25, 10.71, 10.86, 11.58, 11.73, 10.46, 10.3, 10.529, 12.311, 13.4, 10.86, 10.01, 11.45, 11.56, 13.02, 10.01, 15.31, 12.81, 10.49, 11.96, 11.17, 10.94, 11.815, 10.28, 10.371, 10.57, 10.549, 15.07, 12.7, 11.28, 16.381, 14.76, 10.96, 11.389, 11.101, 13.56, 10.059, 11.28, 12.611, 11.98, 11.77, 11.145, 10.74, 10.77, 13.23, 12.94, 10.08, 13.43, 11.369, 13.721, 13.769, 12.111, 11.5, 12.479, 12.891, 10.18, 10.639, 10.98, 10.101, 10.86, 10.57, 13.009, 10.261, 14.594, 10.345, 12.82, 14.95, 12.171, 10.059, 10.141, 10.96, 10.929, 12.941, 13.539, 13.25, 12.02, 10.841, 11.44, 11.489, 12.401, 10.98, 10.349, 13.451, 12.158, 10.48, 12.509, 11.94, 13.161, 12.16, 15.62, 10.79, 10.75, 12.32, 10.639, 11.671, 11.72, 11.06, 10.01, 14.56, 11.78, 12.19, 11.26, 10.85, 11.02, 12.169, 18.531, 10.08, 13.11, 11.32, 12.53, 11.33, 12.92, 10.67, 11.01, 12.58, 11.74, 11.79, 11.91, 10.58, 11.769, 12.261, 10.259, 14.051, 10.699, 10.741, 12.6, 12.63, 12.44, 12.85, 12.79, 12.42, 14.26, 11.93, 14.12, 11.06, 15.32, 12.56, 10.92, 10.7, 11.96, 11.199, 10.731, 10.5, 11.54, 14.33, 10.16, 10.19, 11.109, 11.831, 10.26, 11.74, 11.03, 13.19, 13.02, 12.56, 14.44, 11.31, 11.28, 12.529, 14.211, 12.43, 10.77, 13.65, 12.26, 12.35, 13.91, 10.64, 12.319, 11.301, 17.356, 12.924, 10.1, 11.11, 12.07, 11.079, 12.981, 12.579, 10.081, 16.03, 12.32, 11.93, 11.66, 11.75, 10.1, 10.37, 10.58, 11.17, 14.75, 11.08, 10.099, 12.061, 11.84, 10.24, 11.646, 10.93, 10.75, 12.97, 11.31, 13.01, 11.74, 11.15, 13.04, 13.61, 13.98, 15.89, 11.2, 12.05, 13.49, 11.42, 11.05, 10.86, 11.29, 12.51, 13.04, 12.6, 10.15, 10.88, 12.83, 13.16, 10.84, 11.86, 11.41, 11.2, 11.49, 12.41, 11.64, 11.26, 11.84, 14.86, 10.55, 15.59, 11.75, 12.94, 10.26, 10.44, 10.56, 11.12, 13.21, 12.55, 15.39, 11.3, 14.79, 10.21, 6.953], "stet": [[0, 12.28], [12.28, 22.29], [22.29, 33.61], [33.61, 44.66], [44.66, 54.94], [54.94, 65.12899999999999], [65.12899999999999, 76.529], [76.529, 88.339], [88.339, 98.619], [98.619, 109.539], [109.539, 121.809], [121.809, 134.069], [134.069, 145.339], [145.339, 157.929], [157.929, 168.209], [168.209, 179.918], [179.918, 192.728], [192.728, 203.09900000000002], [203.09900000000002, 215.83900000000003], [215.83900000000003, 227.03900000000002], [227.03900000000002, 239.728], [239.728, 250.25900000000001], [250.25900000000001, 260.329], [260.329, 270.599], [270.599, 283.779], [283.779, 294.219], [294.219, 307.679], [307.679, 320.80899999999997], [320.80899999999997, 332.438], [332.438, 343.449], [343.449, 356.779], [356.779, 367.058], [367.058, 378.589], [378.589, 392.329], [392.329, 408.378], [408.378, 421.659], [421.659, 434.399], [434.399, 446.188], [446.188, 456.318], [456.318, 468.19899999999996], [468.19899999999996, 479.21899999999994], [479.21899999999994, 490.69899999999996], [490.69899999999996, 501.11899999999997], [501.11899999999997, 512.879], [512.879, 526.289], [526.289, 538.189], [538.189, 552.059], [552.059, 567.3389999999999], [567.3389999999999, 580.0989999999999], [580.0989999999999, 590.4989999999999], [590.4989999999999, 601.2889999999999], [601.2889999999999, 616.9489999999998], [616.9489999999998, 628.7389999999998], [628.7389999999998, 639.3389999999998], [639.3389999999998, 651.7589999999998], [651.7589999999998, 662.8189999999997], [662.8189999999997, 674.5889999999997], [674.5889999999997, 686.5689999999997], [686.5689999999997, 696.9189999999998], [696.9189999999998, 710.3189999999997], [710.3189999999997, 726.5689999999997], [726.5689999999997, 737.8789999999997], [737.8789999999997, 750.0869999999996], [750.0869999999996, 761.4769999999996], [761.4769999999996, 774.2069999999997], [774.2069999999997, 785.5669999999997], [785.5669999999997, 797.5169999999997], [797.5169999999997, 808.9069999999997], [808.9069999999997, 820.4669999999996], [820.4669999999996, 832.6369999999996], [832.6369999999996, 844.8769999999996], [844.8769999999996, 855.4869999999996], [855.4869999999996, 868.0569999999997], [868.0569999999997, 880.2769999999997], [880.2769999999997, 890.3769999999997], [890.3769999999997, 904.1169999999997], [904.1169999999997, 914.4919999999997], [914.4919999999997, 925.4219999999997], [925.4219999999997, 937.2519999999997], [937.2519999999997, 950.7319999999997], [950.7319999999997, 963.3319999999998], [963.3319999999998, 974.2119999999998], [974.2119999999998, 988.3119999999998], [988.3119999999998, 999.0419999999998], [999.0419999999998, 1012.0619999999998], [1012.0619999999998, 1023.0619999999998], [1023.0619999999998, 1035.2519999999997], [1035.2519999999997, 1046.2319999999997], [1046.2319999999997, 1059.4819999999997], [1059.4819999999997, 1070.9119999999998], [1070.9119999999998, 1083.1619999999998], [1083.1619999999998, 1093.8719999999998], [1093.8719999999998, 1104.7319999999997], [1104.7319999999997, 1116.3119999999997], [1116.3119999999997, 1128.0419999999997], [1128.0419999999997, 1138.5019999999997], [1138.5019999999997, 1148.8019999999997], [1148.8019999999997, 1159.3309999999997], [1159.3309999999997, 1171.6419999999996], [1171.6419999999996, 1185.0419999999997], [1185.0419999999997, 1195.9019999999996], [1195.9019999999996, 1205.9119999999996], [1205.9119999999996, 1217.3619999999996], [1217.3619999999996, 1228.9219999999996], [1228.9219999999996, 1241.9419999999996], [1241.9419999999996, 1251.9519999999995], [1251.9519999999995, 1267.2619999999995], [1267.2619999999995, 1280.0719999999994], [1280.0719999999994, 1290.5619999999994], [1290.5619999999994, 1302.5219999999995], [1302.5219999999995, 1313.6919999999996], [1313.6919999999996, 1324.6319999999996], [1324.6319999999996, 1336.4469999999997], [1336.4469999999997, 1346.7269999999996], [1346.7269999999996, 1357.0979999999997], [1357.0979999999997, 1367.6679999999997], [1367.6679999999997, 1378.2169999999996], [1378.2169999999996, 1393.2869999999996], [1393.2869999999996, 1405.9869999999996], [1405.9869999999996, 1417.2669999999996], [1417.2669999999996, 1433.6479999999997], [1433.6479999999997, 1448.4079999999997], [1448.4079999999997, 1459.3679999999997], [1459.3679999999997, 1470.7569999999996], [1470.7569999999996, 1481.8579999999997], [1481.8579999999997, 1495.4179999999997], [1495.4179999999997, 1505.4769999999996], [1505.4769999999996, 1516.7569999999996], [1516.7569999999996, 1529.3679999999997], [1529.3679999999997, 1541.3479999999997], [1541.3479999999997, 1553.1179999999997], [1553.1179999999997, 1564.2629999999997], [1564.2629999999997, 1575.0029999999997], [1575.0029999999997, 1585.7729999999997], [1585.7729999999997, 1599.0029999999997], [1599.0029999999997, 1611.9429999999998], [1611.9429999999998, 1622.0229999999997], [1622.0229999999997, 1635.4529999999997], [1635.4529999999997, 1646.8219999999997], [1646.8219999999997, 1660.5429999999997], [1660.5429999999997, 1674.3119999999997], [1674.3119999999997, 1686.4229999999998], [1686.4229999999998, 1697.9229999999998], [1697.9229999999998, 1710.4019999999998], [1710.4019999999998, 1723.293], [1723.293, 1733.473], [1733.473, 1744.1119999999999], [1744.1119999999999, 1755.0919999999999], [1755.0919999999999, 1765.193], [1765.193, 1776.0529999999999], [1776.0529999999999, 1786.6229999999998], [1786.6229999999998, 1799.6319999999998], [1799.6319999999998, 1809.8929999999998], [1809.8929999999998, 1824.4869999999999], [1824.4869999999999, 1834.8319999999999], [1834.8319999999999, 1847.6519999999998], [1847.6519999999998, 1862.6019999999999], [1862.6019999999999, 1874.773], [1874.773, 1884.8319999999999], [1884.8319999999999, 1894.973], [1894.973, 1905.933], [1905.933, 1916.862], [1916.862, 1929.803], [1929.803, 1943.342], [1943.342, 1956.592], [1956.592, 1968.612], [1968.612, 1979.453], [1979.453, 1990.893], [1990.893, 2002.382], [2002.382, 2014.7830000000001], [2014.7830000000001, 2025.7630000000001], [2025.7630000000001, 2036.112], [2036.112, 2049.563], [2049.563, 2061.721], [2061.721, 2072.201], [2072.201, 2084.71], [2084.71, 2096.65], [2096.65, 2109.811], [2109.811, 2121.971], [2121.971, 2137.591], [2137.591, 2148.381], [2148.381, 2159.131], [2159.131, 2171.451], [2171.451, 2182.09], [2182.09, 2193.761], [2193.761, 2205.4809999999998], [2205.4809999999998, 2216.5409999999997], [2216.5409999999997, 2226.551], [2226.551, 2241.111], [2241.111, 2252.891], [2252.891, 2265.081], [2265.081, 2276.3410000000003], [2276.3410000000003, 2287.1910000000003], [2287.1910000000003, 2298.2110000000002], [2298.2110000000002, 2310.38], [2310.38, 2328.911], [2328.911, 2338.991], [2338.991, 2352.101], [2352.101, 2363.4210000000003], [2363.4210000000003, 2375.9510000000005], [2375.9510000000005, 2387.2810000000004], [2387.2810000000004, 2400.2010000000005], [2400.2010000000005, 2410.8710000000005], [2410.8710000000005, 2421.8810000000008], [2421.8810000000008, 2434.4610000000007], [2434.4610000000007, 2446.2010000000005], [2446.2010000000005, 2457.9910000000004], [2457.9910000000004, 2469.9010000000003], [2469.9010000000003, 2480.481], [2480.481, 2492.25], [2492.25, 2504.511], [2504.511, 2514.77], [2514.77, 2528.821], [2528.821, 2539.52], [2539.52, 2550.261], [2550.261, 2562.861], [2562.861, 2575.491], [2575.491, 2587.931], [2587.931, 2600.781], [2600.781, 2613.571], [2613.571, 2625.991], [2625.991, 2640.251], [2640.251, 2652.181], [2652.181, 2666.301], [2666.301, 2677.361], [2677.361, 2692.681], [2692.681, 2705.241], [2705.241, 2716.161], [2716.161, 2726.861], [2726.861, 2738.821], [2738.821, 2750.02], [2750.02, 2760.751], [2760.751, 2771.251], [2771.251, 2782.791], [2782.791, 2797.121], [2797.121, 2807.281], [2807.281, 2817.471], [2817.471, 2828.58], [2828.58, 2840.411], [2840.411, 2850.6710000000003], [2850.6710000000003, 2862.411], [2862.411, 2873.4410000000003], [2873.4410000000003, 2886.6310000000003], [2886.6310000000003, 2899.6510000000003], [2899.6510000000003, 2912.2110000000002], [2912.2110000000002, 2926.6510000000003], [2926.6510000000003, 2937.9610000000002], [2937.9610000000002, 2949.2410000000004], [2949.2410000000004, 2961.7700000000004], [2961.7700000000004, 2975.981], [2975.981, 2988.411], [2988.411, 2999.181], [2999.181, 3012.831], [3012.831, 3025.0910000000003], [3025.0910000000003, 3037.4410000000003], [3037.4410000000003, 3051.351], [3051.351, 3061.991], [3061.991, 3074.31], [3074.31, 3085.611], [3085.611, 3102.967], [3102.967, 3115.891], [3115.891, 3125.991], [3125.991, 3137.101], [3137.101, 3149.1710000000003], [3149.1710000000003, 3160.2500000000005], [3160.2500000000005, 3173.2310000000007], [3173.2310000000007, 3185.810000000001], [3185.810000000001, 3195.891000000001], [3195.891000000001, 3211.921000000001], [3211.921000000001, 3224.2410000000013], [3224.2410000000013, 3236.171000000001], [3236.171000000001, 3247.831000000001], [3247.831000000001, 3259.581000000001], [3259.581000000001, 3269.681000000001], [3269.681000000001, 3280.051000000001], [3280.051000000001, 3290.6310000000008], [3290.6310000000008, 3301.801000000001], [3301.801000000001, 3316.551000000001], [3316.551000000001, 3327.6310000000008], [3327.6310000000008, 3337.730000000001], [3337.730000000001, 3349.791000000001], [3349.791000000001, 3361.631000000001], [3361.631000000001, 3371.871000000001], [3371.871000000001, 3383.517000000001], [3383.517000000001, 3394.447000000001], [3394.447000000001, 3405.197000000001], [3405.197000000001, 3418.167000000001], [3418.167000000001, 3429.4770000000008], [3429.4770000000008, 3442.487000000001], [3442.487000000001, 3454.2270000000008], [3454.2270000000008, 3465.377000000001], [3465.377000000001, 3478.417000000001], [3478.417000000001, 3492.027000000001], [3492.027000000001, 3506.007000000001], [3506.007000000001, 3521.897000000001], [3521.897000000001, 3533.0970000000007], [3533.0970000000007, 3545.147000000001], [3545.147000000001, 3558.6370000000006], [3558.6370000000006, 3570.0570000000007], [3570.0570000000007, 3581.107000000001], [3581.107000000001, 3591.967000000001], [3591.967000000001, 3603.257000000001], [3603.257000000001, 3615.767000000001], [3615.767000000001, 3628.807000000001], [3628.807000000001, 3641.407000000001], [3641.407000000001, 3651.557000000001], [3651.557000000001, 3662.4370000000013], [3662.4370000000013, 3675.267000000001], [3675.267000000001, 3688.427000000001], [3688.427000000001, 3699.267000000001], [3699.267000000001, 3711.1270000000013], [3711.1270000000013, 3722.537000000001], [3722.537000000001, 3733.737000000001], [3733.737000000001, 3745.2270000000008], [3745.2270000000008, 3757.6370000000006], [3757.6370000000006, 3769.2770000000005], [3769.2770000000005, 3780.5370000000007], [3780.5370000000007, 3792.377000000001], [3792.377000000001, 3807.237000000001], [3807.237000000001, 3817.787000000001], [3817.787000000001, 3833.3770000000013], [3833.3770000000013, 3845.1270000000013], [3845.1270000000013, 3858.0670000000014], [3858.0670000000014, 3868.3270000000016], [3868.3270000000016, 3878.7670000000016], [3878.7670000000016, 3889.3270000000016], [3889.3270000000016, 3900.4470000000015], [3900.4470000000015, 3913.6570000000015], [3913.6570000000015, 3926.2070000000017], [3926.2070000000017, 3941.5970000000016], [3941.5970000000016, 3952.8970000000018], [3952.8970000000018, 3967.6870000000017], [3967.6870000000017, 3977.8970000000018], [3977.8970000000018, 3984.8500000000017]], "labels": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [73, 742, 914, 1330, 1565, 2054, 2822, 3376, 3986]}
{"example_id": "mit153@@MITRES6_012S18_L18_300k", "text": [" In this lecture, we develop the weak law of large numbers.  Loosely speaking, the weak law of large numbers says that if  we have a sequence of independent random variables ", "with the same distribution, then the average of these  random variables, which is called the sample mean,  approaches the expected value of the distribution. ", "In this sense, it reinforces our interpretation of the  expected value as some kind of overall average.  The weak law of large numbers is the ", "reason why polling works.  By asking many people about the value of some attribute,  and by taking the average of the responses, we can get a  good estimate of the average over the entire population. ", "On the mathematical side, in order to derive the weak law  of large numbers, we will first need to develop some  inequalities, namely the Markov and Chebyshev  inequalities. ", "Both of them tell us something about tail probabilities.  Suppose that a is a number.  Then it is reasonable to expect that the probability ", "that the random variable exceeds a will be small when a  is very large.  But how small?  The Markov and Chebyshev inequalities give us some ", "answers to this question, based only on knowledge of the  mean and the variance of the distribution.  Finally, we will have to deal with a technical issue. ", "The weak law of large numbers talks about the convergence of  a random variable to a number.  For this to make sense, we need to define an appropriate  notion of convergence. ", "We will introduce one such notion that goes under the  name of convergence in probability.  And we will see that in many respects, it is similar to the  common notion of convergence of numbers. ", "  In this segment, we derive and discuss the Markov inequality,  a rather simple but quite useful and powerful fact about  probability distributions. ", "The basic idea behind the Markov inequality as well as  many other inequalities and bounds in probability theory  is the following.  We may be interested in saying something about the ", "probability of an extreme event.  By extreme event, we mean that some random variable takes a  very large value.  If we can calculate that probability exactly, then, of ", "course, everything is fine.  But suppose that we only have a little bit of information  about the probability distribution at hand.  For example, suppose that we only know the expected value ", "associated with that distribution.  Can we say something?  Well, here's a statement, which is quite intuitive.  If you have a non-negative random variable, and I tell  you that the average or the expected value is rather ", "small, then there should be only a very small probability  that the random variable takes a very large value.  This is an intuitively plausible statement, and the ", "Markov inequality makes that statement precise.  Here is what it says.  If we have a random variable that's non-negative and you  take any positive number, the probability that the random ", "variable exceeds that particular number is bounded  by this ratio.  If the expected value of X is very small, then the ", "probability of exceeding that value of a will also be small.  Furthermore, if a is very large, the probability of  exceeding that very large value drops down because this ", "ratio becomes smaller.  So that's what the Markov inequality says.  Let us now proceed with a derivation.  Let's start with the formula for the expected value of X, ", "and just to keep the argument concrete, let us assume that  the random variable is continuous so that the  expected value is given by an integral.  The argument would be exactly the same as in the discrete ", "case, but in the discrete case, we would be using a sum.  Now since the random variable is non-negative, this integral  only ranges from 0 to infinity. ", "Now, we're interested, however, in values of X larger  than or equal to a, and that tempts us to consider just the  integral from a to infinity of the same quantity. ", "How do these two quantities compare to each other?  Since we're integrating a non-negative quantity, if  we're integrating over a smaller range, the resulting ", "integral will be less than or equal to this integral here,  so we get an inequality that goes in this direction. ", "Now let us look at this integral here.  Over the range of integration that we're considering, X is  at least as large as a.  Therefore, the quantity that we're integrating from a to ", "infinity is at least as large as a times the density of X.  And now we can take this a, which is a constant, pull it ", "outside the integral.  And what we're left with is the integral of the density  from a to infinity, which is nothing but the probability  that the random variable takes a value larger ", "than or equal to a.  And now if you compare the two sides of this inequality,  that's exactly what the Markov inequality is telling us. ", "Now it is instructive to go through a second derivation of  the Markov inequality.  This derivation is essentially the same conceptually as the  one that we just went through except that it is more ", "abstract and does not require us to write down any explicit  sums or integrals.  Here's how it goes.  Let us define a new random variable Y, which is equal to ", "0 if the random variable X happens to be less than a and  it is equal to a if X happens to be larger  than or equal to a. ", "How is Y related to X?  If X takes a value less than a, it will still be a  non-negative value, so X is going to be at least as large ", "as the value of 0.  that Y takes.  If X is larger than or equal to a, Y will be a, so X will  again be at least as large. ", "So no matter what, we have the inequality that Y is always  less than or equal to X. And since this is always the case, ", "this means that the expected value of Y will be less than  or equal to the expected value of X.  But now what is the expected value of Y?  Since Y is either 0 or a, the expected value is equal to a ", "times the probability of that event, which is a times the  probability that X is larger than or equal to a. ", "And by comparing the two sides of this inequality, what we  have is exactly the Markov inequality.  Let us now go through some simple examples. ", "Suppose that X is exponentially distributed with  parameter or equal to 1 so that the expected value of X  is also going to be equal to 1, and in that case, we obtain ", "a bound of 1 over a.  To put this result in perspective, note that we're  trying to bound a probability.  We know that the probability lies between 0 and 1. ", "There's a true value for this probability, and in this  particular example because we have an exponential  distribution, this probability is equal to e to the minus a. ", "The Markov inequality gives us a bound.  In this instance, the bound takes the form of 1 over a,  and the inequality tells us that the true value is  somewhere to the left of here. ", "A bound will be considered good or strong or useful if  that bound turns out to be quite close to the correct  value so that it also serves as a fairly accurate estimate. ", "Unfortunately, in this example, this is not the case  because the true value falls off exponentially with a,  whereas the bound that we obtained falls off at a much  slower rate of 1 over a. ", "For this reason, one would like to have even better  bounds than the Markov inequality, and this is one  motivation for the Chebyshev inequality that we will be  considering next. ", "But before we move there, let us consider one more example.  Suppose that X is a uniform random variable on the  interval from minus 4 to 4, and we're interested in saying ", "something about the probability that X is larger  than or equal to 3.  So we're interested in this event here. ", "So the value of the density, because we have a range of  length 8, the value of the density is 1/8.  So we know that this probability has a true value ", "of 1 over 8, which we can indicate on a diagram here.  Probabilities are between 0 and 1.  We have a true value of 1 over 8. ", "Lets us see what the Markov inequality is  going to give us.  There's one difficulty that X is not a non-negative random  variable, so we cannot apply the Markov ", "inequality right away.  However, the event that X is larger than or equal to 3 is  smaller than the event that the absolute value of X is ", "larger than or equal to 3.  That is, we take this blue event and we also add this  green event, and we say that the probability of the blue ", "event is less than or equal to the probability of the blue  together with the green event, which is the event that the  absolute value of X is larger than or equal to 3. ", "So now we have a random variable, which is  non-negative, and we can apply the Markov inequality and  write that this is less than or equal to the expected value  of the absolute value of X divided by 3. ", "What is this expectation of the absolute value of X?  X is uniform on this range.  The absolute value of X will be taking values only  between 0 and 4. ", "And because the original distribution was uniform, the  absolute value of X will also be uniform on the  range from 0 to 4.  And for this reason, the expected value is going to be ", "equal to 2, and we get a bound of 2/3.  This is a pretty bad bound.  It is true, of course, but it is quite far ", "from the true answer.  Could we improve this bound?  In this particular example, we can.  Because of symmetry, we know that the probability of being ", "larger than or equal to 3 is equal to the probability of  being less than or equal to minus 3.  Or the probability of this event, which is the blue and ", "the green, is twice the probability of  just the blue event.  Or to put it differently, this probably here is equal to 1/2 ", "of the probability that the absolute value of x is larger  than or equal to 3, and therefore, by using the same  bound as here, we will obtain and answer of 1/3. ", "So by being a little more clever and exploiting the  symmetry of this distribution around 0, we get a somewhat  better bound of 1/3, which is, again, a true bound. ", "It is more informative than the original bound, but still  it is quite far away from the true answer.    Mathematically speaking, the Chebyshev inequality is just a ", "simple application of the Markov inequality.  However, it contains a somewhat different message.  Consider a random variable that has a  certain mean and variance.  What the Chebyshev inequality says is that if the variance ", "is small, then the random variable is unlikely to fall  too far off from the mean.  If the variance is small, we have little randomness. ", "And so X cannot be too far from the mean.  In more precise terms, we have the following inequality.  The probability that the distance from the mean is  larger than or equal to a certain number is, at most, ", "the variance divided by the square of that number.  So if the variance is small, the probability of falling far  from the mean is also going to be small. ", "And if the number c is large, so that we're talking about a  large distance from the mean, then the probability of this  event happening falls off at a rate at ", "least 1 over c squared.  By the way, I should add here that c is assumed to be a  positive number.  If c was negative, then the probability that we're looking ", "at would be equal to 1 anyway.  And there isn't any point in trying obtain a bound for it.  To prove the Chebyshev inequality, we will apply the  Markov equality as follows. ", "The probability of interest is the same as the probability  that the square of this quantity is larger than or ", "equal to the square of c.  But now, here we have a non-negative random variable.  And we can apply the Markov inequality with X replaced by ", "this random variable and with a replaced by c squared.  So this gives us the expected value of the random variable  of interest divided by c squared. ", "But we recognize that the  numerator is just the variance.  And this is the Chebyshev inequality that we claimed. ", "As an application of the Chebyshev inequality, let us  look at the probability of this event that the distance  from the mean is at least k standard deviations, where k ", "is some positive number.  Using the Chebyshev inequality with c replaced by k times  sigma, we obtain sigma squared over c squared, which in our ", "case is k squared times sigma squared,  which is 1 over k squared.  So what this is saying is that if you take, for example, k ", "equal to 3, the probability that you fall three standard  deviations away from the mean or more, that probability is  going to be less than or equal to 1 over 9. ", "And this is true no matter what kind of  distribution you have.  Let us now revisit our earlier example, where X is an  exponential random variable. ", "And we're interested in the probability that the random  variable takes a value larger than or equal to a.  The Markov inequality gave us a bound of 1 over a. ", "And as we recall, the exact answer to this probability was  e to the minus a.  Let us see what we can get using the Chebyshev ", "inequality.  Now, our random variable has a mean of 1.  Let us assume that a is bigger than 1, so that we're ", "considering an event that we fall far away from the mean by  a distance of at least a minus 1.  That is we write the probability that X is larger ", "than or equal to a as the probability that the distance  of X from the mean is larger than or equal to a minus 1. ", "And now, this event is smaller than the event that the  absolute value of X minus 1 is larger than a minus 1. ", "This is because if this event is true, then that event will  also be true.  And now, we can apply the Chebyshev inequality.  Here we have the distance of X from the mean. ", "So the Chebyshev inequality applied to the random variable  X will have up here the variance of X,  which is equal to 1.  And in the denominator, we will have a minus 1 squared. ", " Notice that if a is a large number, this quantity here  behaves like 1 over a squared, which falls off much faster ", "than 1 over a.  So at least for large a's, the Chebyshev bound is going to  give us a smaller bound and, therefore, more informative ", "than what we obtained from the Markov inequality.  In most cases, the Chebyshev inequality is, indeed,  stronger and more informative than the Markov inequality. ", "And one of the reasons is that it exploits more information  about the distribution of the random variable X. That is it  uses knowledge, not just about the mean ", "of the random variable.  But it also uses some information about the variance  of the random variable.    In this segment, we derive and discuss the weak ", "law of large numbers.  It is a rather simple result, but plays a central role  within probability theory.  The setting is as follows.  We start with some probability distribution that has a ", "certain mean and variance, which we assume to be finite.  We then draw independent random variables out of this  distribution so that these Xi's are independent and ", "identically distributed, i.i.d.  for short.  What's going on here is that we're carrying out a long  experiment during which all of these random ", "variables are drawn.  Once we have drawn all of these random variables, we can  calculate the average of the values that have been  obtained, and this gives us the so-called sample mean. ", "Notice that the sample mean is a random variable because it  is a function of random variables.  It should be distinguished from the true mean, mu, which ", "is the expected value of the Xi's, which is a number.  It is not random.  And mu is some kind of average over all the possible outcomes ", "of the random variable Xi.  The sample mean is the simplest and most natural way  for trying to estimate the true mean, and the weak law of  large numbers will provide some support to this notion. ", "Let us now look at the properties of the sample mean.  Let us calculate its expectation.  By the way, this object here involves two different kinds ", "of averaging.  The sample mean averages over the values observed during one  long experiment, whereas the expectation averages over all ", "possible outcomes of this experiment.  The expectation is some kind of theoretical average because  we do not get to observe all the possible outcomes of this ", "experiment, but the sample mean is something that we  actually calculate on the basis of our observations.  In any case, the expected value of the sample mean, by ", "linearity, it is the expected value of the numerator divided  by the denominator.  Using linearity once more, the expected value of the sum is ", "the sum of the expected values, and since each one of  those expected values is equal to mu, we obtain n times mu  divided by n, which leaves us with mu. ", "So the theoretical average, the expected value of the  sample mean, is equal to the true mean.  Let us now calculate the variance of the sample mean. ", "The variance of a random variable divided by a number  is the variance of that random variable divided by the square ", "of that number.   Now, since the Xi's are independent, the variance is  the sum of the variances. ", "And therefore, we obtain n times the variance  of each one of them.  And after we simplify, this leaves us with sigma  squared over n. ", "We're now in a position to apply the Chebyshev  inequality.  The Chebyshev inequality tells us that the distance of a  random variable from its mean, being larger than a certain ", "number, has a probability that's bounded above by the  variance of the random variable of interest divided  by the square of the number that we have here. ", "We have already calculated the variance, and so this quantity  is sigma squared over n times epsilon squared. ", "And now, if we consider epsilon as a fixed number and  let n go to infinity, then what we obtain is a limiting  value of 0. ", " So the probability of falling far from the mean diminishes  to zero as we draw more and more samples. ", "That's exactly what the weak law of large numbers tells us.  If we fix any particular epsilon, which is a positive  constant, the probability that the sample mean falls away ", "from the true mean by more than epsilon, that probability  becomes smaller and smaller and converges to 0 as n goes  to infinity. ", "Let us now interpret the weak law of large numbers.  As I already hinted, we have to think in terms of one long ", "experiment, and during that experiment, we draw several  independent random variables drawn from the same  distribution.  One way of thinking about those random variables is that ", "each one of them is equal to the mean, the true mean, plus  some measurement noise, which is a term that has zero  expected value. ", "And all of these noises are independent.  So we have a collection of noisy measurements, and then  we take those measurements and form the average of them. ", "What the weak law of large numbers tells us is that the  sample mean is unlikely to be far off from the true mean.  And by far off, we mean at least epsilon distance away. ", "So the sample mean is, in some ways, a good way of estimating  the true mean.  If n is large enough, then we have high confidence that the ", "sample mean gives us a value that's close to the true mean.  As a special case let us consider a probabilistic model  in which we repeat independently many times the ", "same experiment.  There's a certain event A associated with that  experiment that has a certain probability, and each time  that we carry out the experiment, we use an ", "indicator variable to indicate whether the outcome was inside  the event or outside the event.  So Xi is 1 if A occurs, and it is 0 otherwise. ", " The expected value of the Xi's, the true mean in this  case, is equal to the number p.  ", "In this particular example, the sample mean just counts  how many times the event A occurred out of the n  experiments that we carried out, so it's the frequency ", "with which the event A has occurred.  And we call it the empirical frequency of event A. What the  weak law of large numbers tells us is that the empirical ", "frequency will be close to the probability of that event.  In this sense, it reinforces or justifies the  interpretation of probabilities as frequencies. ", "  We will now consider a very practical application of the  weak law of large numbers, and the calculations  associated with it.  The application has to do with polling. ", "There's a certain referendum that's going to take place.  We're close enough to the day of the referendum so that  voters have made up their minds, and there is a fraction  p of the population that represents the voters that are ", "going to vote yes.  But the referendum has not yet taken place, and you want to  find out, to predict or estimate what p actually is. ", "What you do is that you go ahead, and you select at  random a number of people out of the population.  And for each person, you record their answer, whether ", "they intend to vote yes, or whether they  intend to vote no.  When we say that the people are randomly selected, what we  mean is that we choose them uniformly from the population. ", "And since there's a fraction p that will vote yes, this means  that this random variable will be 1 with probability p, and  therefore, the expected value of Xi is equal to p. ", "In addition, we assume that we select those people  independently.   Now note that if we select people independently, there's ", "always a chance that the first person polled will be the same  as the second person polled, something that we do not  really want to happen.  However, if we assume that the population is very large, or ", "even idealize the situation by assuming that the population  is infinite, then this is never going to happen, and  this will not be a concern.  So how do we proceed? ", "We look at the results that we got from the  people that we polled.  We count how many said yes, divide by n, and this gives us  the fraction of yeses in the sample that we have obtained. ", "And this is a pretty reasonable estimate for the  unknown fraction p, the fraction of yeses in the  overall population. ", "Now perhaps your boss has asked you to find out the  exact value of p.  What should your response be?  Well, there is no way to calculate p exactly on the ", "basis of a finite and random poll.  Therefore, there is going to be some error in our  estimation of p.  Then, perhaps your boss comes back and says, OK, then try to ", "give me an estimate of p which is very accurate.  I would like you to come up with an estimate which is  correct within one percentage point. ", "Can you do this for me?  Your answer might be, OK, let me try polling 10,000 people,  and see if I can guarantee for you such a small error. ", "But after you think about the situation a little more, you  realize that there is no way of guaranteeing such a small  error with certainty.  What if your unlucky, and the people that you poll happen to ", "be not representative of the true population?  So you come back to your boss and you say, I cannot  guarantee with certainty that the error is going to be ", "small, but perhaps I can guarantee for you that the  error that I get is small with high probability.  Or alternatively, I'm going to guarantee for you that the ", "probability that we get an error that's bigger than that  is very small.  So how small is it going to be?  Let's try to derive a bound on this probability of an error ", "larger than one percentage point.  Using the calculations that we carried out when we derived  the weak law of large numbers, we know that this probability ", "of a large error is bounded above by this quantity.  What is this quantity?  Sigma squared is the variance of the random variable that ", "we're sampling.  And since this is Bernoulli, this variance is p times 1  minus p, and then we divide by n, which in our case is 10 to ", "the fourth times epsilon squared.  Epsilon is 10 to the minus 2, so here we have 10  to the minus 4.  OK, but now, what is this quantity? ", "This quantity depends on p, and we do not know what p is.  However, if you take this expression, and plot it as a  function of p, what you obtain is a plot of this type. ", "And the maximum happens when p is equal to 1/2, in which case  we get a value of 1/4.  That is, the variance of the Bernoulli is, at most, 1/4. ", "And therefore, we obtain this bound here where the  denominator terms have disappeared because they're  equal to 1.  So you tell your boss, if I sample 10,000 people, then the ", "probability of an error more than the one percentage point  is going to be less than 25%.  At which point, your boss might reply and say, well, a ", "probability of a large error of 25% is too big.  This is unacceptable.  I would like you to have a probability of error that's ", "less than 5%.  So suppose now that we want to change this, and make it only  a 5% error-- ", "5% or less.  How are you going to proceed?  Well, you have this quantity here, this upper bound, which  we know to be less than or equal to 1/4 divided by n ", "times epsilon squared, which is, in our case, 10  to the minus 4.  We would like this quantity to be less than or equal to 5%, ", "which is 5/10 to the second power.  And after you solve this inequality, you find that this  is equivalent to taking n larger than or equal ", "to 10 to the sixth.  And then the five together with that four gives us a  denominator of 20.  And this number is equal to 50,000. ", "So at this point, you can go back to your boss and tell  them that one way of guaranteeing that the  probability of a large error is less than or equal to 5% is ", "to take n equal to 50,000.  So 50,000 will suffice to achieve the desired specs.  Notice that the desired specs have two parameters. ", "One is the accuracy that you want, and the other is the  confidence with which the accuracy  is going to be achieved. ", "Now 50,000 is a pretty large number.  If you notice the results of polls, the way that they are  presented in newspapers, they usually tell you that there's ", "an accuracy of plus or minus three percentage points, not  one percentage point.  That helps things a little.  It means that you can do with a somewhat ", "smaller sample size.  And then, there's another effect.  Our calculation here was based on this inequality, which is  the Chebyshev inequality. ", "But the Chebyshev inequality is not that accurate.  It turns out that if we use more accurate estimates of  this probability, we will find that actually much smaller ", "values of n will be enough for our purposes.    We will now take a step towards abstraction, and  discuss the issue of  convergence of random variables. ", "Let us look at the weak law of large numbers.  It tells us that with high probability, the sample mean  falls close to the true mean as n goes to infinity. ", "We would like to interpret this statement by saying that  the sample mean converges to the true mean.  However, before we can make such a statement, we should  first define carefully the word \"converges.\" And we need ", "a notion of convergence that refers to convergence of  random variables.  Here's a definition.  Suppose that we have a sequence of random variables ", "that are not necessarily independent.  We say that this sequence of random variables converges in  probability--  that's a particular notion of convergence we're defining. ", "It converges to a certain number if the  following is true--  no matter what epsilon is, as long as it is a positive  number, the probability that the random variable falls far ", "from this number--  that is, epsilon or further away from that number--  that probability converges to 0 as n increases. ", "That is, as n increases, there is higher and higher  probability that Yn will be close to this  particular number a.  This is the notion of convergence ", "that we have defined.  And notice that this notion of convergence corresponds  exactly to what is happening in the weak  law of large numbers.  And so in particular, we can describe the weak law of large ", "numbers as saying that Mn, the sample mean, converges to mu  as n goes to infinity, but in a particular sense-- ", "in the sense of convergence in probability.  Let us now try to understand a little better what convergence  in probability really amounts to. ", "And we will do that by making a comparison with the ordinary  notion of convergence of real numbers.  When we're dealing with convergence of numbers, we  start with a sequence of numbers, and we are interested ", "in the statement that this sequence converges to a  certain limit.  What does that mean?  What we mean is that the elements of the sequence ", "eventually--  that is, when n is large enough--  will get and stay arbitrarily close to this particular  number a, which is the limit. ", "In terms of a picture, here is a, the limit.  Here is n.  We take a small band around this number a. ", "And what we require is that the elements of the sequence  eventually get within this band around the number a. ", "They might get outside the band, get inside again.  But eventually--  that is, after some time--  the elements of the sequence will only  stay inside this band. ", "Now to translate this into a more formal mathematical  statement, which is the mathematical definition of the  notion of convergence, we have the following--  if I give you some epsilon, epsilon could be ", "a very small number.  I form a band around a that goes from a minus epsilon to a  plus epsilon. ", "What I want is that there exists a certain time, n0--  in this picture, n0 would be here--  such that for all times after n0, our sequence stays within ", "epsilon from a.  That is, our sequence stays inside this band.  Now let us move to the case of random variables, and see what  convergence in probability is talking about. ", "Here, instead of a sequence of numbers, we have a sequence of  random variables.  And we're interested in the meaning of the convergence of  the sequence of random variables to ", "a particular number.  In words, what this means is that if I fix a certain  epsilon, as in this picture, then the probability that the ", "random variable falls outside this band converges to 0.  So the picture would be as follows.  ", "We have, again, our limit.  We fix some epsilon, which could be an  arbitrarily small number.  For any fixed choice of epsilon, we take this band, ", "and for any given n, we look into the probability that our  random variable falls inside that band.  So if I am to draw the distribution of our random ", "variable, a distribution might be something like this--  so there is a certain probability that it falls  outside this band.  But when n becomes large, this probability of falling outside ", "this band becomes very small.  So the probability of falling outside the band becomes tiny.  So the bulk of the distribution-- ", "that is, most of the probability--  is concentrated inside this band.  And this is true, no matter how small epsilon is.  If I take a much narrower band around a, I still want all of ", "the probability to be eventually  concentrated inside that band.  Of course, it might take longer.  It might take a larger value of n, but I want that when n ", "is very large, the bulk of the distribution is, again,  concentrated inside this narrow band.  So in words, convergence in probability means that almost ", "all of the probability mass of the random variable Yn, when n  is large, that probability mass get concentrated within a ", "narrow band around the limit of the random variable.  We finally point out a few useful properties of  convergence in probability that parallel well-known ", "properties of convergence of sequences.  Suppose that we have a sequence of random variables  that converges in probability to a certain number a, and  another sequence that converges in probability to ", "some other number b.  We do not make any assumptions about independence.  We do not assume the Xn's are independent of each other.  We do not assume that the sequence of Xn's is ", "independent of Yn.  We then have the following properties--  if g is a continuous function, then the function of the ", "random variables converges to the function of the number.  So for example, the sequence of random variables Xn squared  is going to converge to a squared. ", "Another fact is that the sum of these two random variables  converges to the sum of their limits.  Both of these properties are analogous to what happens with ", "ordinary convergence of numbers.  And they tell us that, in some sense, convergence in  probability is not a very different notion.  We will not prove those properties at this point, but ", "they're useful to know.  However, there's an important caveat.  Xn might converge to a certain number in probability.  However, the expected value of Xn does not necessarily ", "converge to that same limit.  So convergence of random variables does not imply  convergence of expectations.  And we will be seeing an example where this convergence ", "does not take place.    We will now go through two examples of convergence in  probability.  Our first example is quite trivial.  We're dealing with a sequence of random variables Yn that ", "are discrete.  Most of the probability is concentrated at 0.  But there is also a small probability of a large value.  Because the bulk of the probability mass is ", "concentrated at 0, it is a good guess that this sequence  converges to 0.  Do we have, indeed, convergence in  probability to 0?  We need to check the definition. ", "So we fix some epsilon, which is a positive number.  And we look at the probability of the event that our random  variable is epsilon or more away than what we think is the ", "limit of that sequence.  We look at that probability.  And in this example, it is equal to 1 over n, which goes  to 0 as n goes to infinity. ", "And this verifies that, indeed, in this example, Yn  converges to 0, as n goes to infinity in probability.  ", "Now, we make the following observation.  If we are to calculate the expected value of this random  variable, what we get is the following.  We get a value of 0 with this probability, no contribution ", "to the expectation.  But we also get a value of n squared with  probability 1 over n.  And so the expected value is equal to n, which, actually, ", "goes to infinity, as n goes to infinity.  So we have a situation where the sequence of the random  variables converges to 0. ", "But the expectation does not converge to 0.  In fact, it goes to infinity.  And this example serves to make the point that  convergence in probability does not imply convergence of ", "expectations.  The reason is that convergence in probability has to do with  the bulk of the distribution.  It only cares that the tail of the distribution has small ", "probability.  On the other hand, the expectation is highly  sensitive to the tail of the distribution.  It might be that the tail only has a small probability. ", "But if that probability is assigned to a very large  value, then the expectation will be strongly affected and  can be quite different from the limit  of the random variable. ", "Our second example is going to be less trivial and more  interesting.  Consider random variables that are independent and  identically distributed and whose common distribution is ", "uniform on the unit interval, so that the  PDF takes this form.  Are these random variables convergent to something? ", "The answer is no.  And the reason is that as i increases, the distribution  does not change.  And it does not to get concentrated  around a certain number. ", "The distribution remains spread out over the entire  unit interval.  But let us look now at some related random variables.  Let us define Yn to be the minimum of the first n of the ", "X's that we get.  So if n is equal to 4, and we obtain these four values, Yn  would be equal to this value.  Notice that if we draw more values, then the new values ", "might be above the minimum, in which case the minimum does  not change.  But we might also get a value that's below the minimum, in  which case the minimum moves down. ", "The only thing that can happen is that the minimum goes down.  It cannot go up.  And this gives us this inequality.  So the random variables Yn tends to go down. ", "How far down?  If n is very large, we expect that we will obtain some X's  whose value happens to be very close to 0, which means that ", "Yn will go down to values that are very close to 0.  And this leads us to conjecture that, perhaps, Yn  does converge to 0. ", "This is always the first step when dealing with convergence  in probability.  The first step is to make an educated guess about what the  limit might be.  And then we want to verify that this is, indeed, the ", "correct limit.  To verify that, what we do is we fix some positive epsilon.  And we look for the probability that the distance ", "of the random variable Yn from the conjectured limit has a  magnitude that's larger than or equal to epsilon.  And what we need to show is that this quantity converges ", "to 0 as n goes to infinity, no matter what epsilon is.  Now, because Yn is a non-negative random variable,  this is the same as the probability that Yn is larger ", "than or equal to epsilon.  Now, let us distinguish between two cases.  If epsilon is bigger than 1, we're asking for the  probability that Yn is larger than or equal to a certain ", "number epsilon that's out there.  But this probability is 0.  There's no way that the minimum of these uniforms will  take a value that's larger than some epsilon that's ", "larger than 1.  So in that case, this quantity is equal to zero.  And we are done.  But we need to check that this quantity becomes small no  matter what epsilon is. ", "So now, let us consider taking a small epsilon that is some  number that's less than or equal to 1.  For that case, let us continue with the calculation. ", "The minimum is going to be at least epsilon, if, and only  if, all of the random variables  are at least epsilon.  ", "So this is an equivalent way of writing this particular  event here.  Now, because of independence, this is the product of the  probabilities that each one of the random variables is larger ", "than or equal to epsilon.  The probability that X1 is larger than or equal to  epsilon can be found as follows.  If we have here epsilon, the probability of being larger ", "than or equal to epsilon is the probability  of this event here.  So it's the area of this rectangle.  The base of that rectangle is 1 minus epsilon.  And so we obtain 1 minus epsilon for this first term. ", "But because the Xi's are identically distributed, all  the other terms that we multiply are also the same.  And so the answer is this expression here. ", "Now, epsilon is a positive number.  So 1 minus epsilon is strictly less than 1.  And when we take higher powers of a number that's less than ", "1, we obtain something that converges to 0  as n goes to infinity.  And that's what we needed to verify.  Since this is the case for any epsilon, we conclude that the ", "random variables Yn converge to zero in the sense that we  have defined, in probability.  ", "Generalizing from this example, when we want to show  convergence in probability, the first step is to make a  guess as to what is the value that the ", "sequence converges to.  In this example, that value was equal to 0.  Once we have made that conjecture, then we write down  an expression for the probability of being epsilon ", "away from the conjectured limit.  And then we calculate that probability either exactly, as  in this example.  Or we try to bound it somehow and still show ", "that it goes to 0.    The purpose of this segment is to give you a little bit of  the bigger picture.  We did discuss some inequalities, we did discuss  convergence of the sample mean-- ", "that's the weak law of large numbers-- and we did discuss a  particular notion of convergence of random  variables, convergence in probability.  How far can we take those topics? ", "Let's start with the issue of inequalities.  Here, one would like to obtain bounds and approximations on  tail probabilities that are better than the Markov and  Cherbyshev inequalities that we have seen. ", "This is indeed possible.  For example, there is a so-called Chernoff bound that  takes the following form.  The Chernoff bound tells us that the probability that the ", "sample mean is away from the true mean by at least a, where  a is a positive number, this probability is bounded above ", "by a function that falls exponentially with n and where  the exponent depends on the particular number, a, that we  are considering.  But in any case, this term in the exponent ", "is a positive quantity.  Notice that this is much better, much stronger than  what we obtained from the Cherbyshev inequality because ", "in the Cherbyshev inequality, we only obtain an inequality  for this probability that falls off as the  rate of 1 over n.  So this falls much faster, and so it tells us that this ", "probability is indeed much smaller than what the  Cherbyshev inequality might predict.  However, this inequality requires some additional  assumptions on the random variables involved. ", "Another type of approximation on this tail probability can  be obtained through the central limit theorem, which  will actually be the next topic  that we will be studying. ", "Very loosely speaking, the central limit theorem tells us  that the random variable M sub n, which is the sample mean, ", "behaves as if it were a normal random variable with the mean  and the variance that it should have.  We know that this is the mean and the variance of the sample ", "mean, but the central limit theorem tells us that in  addition to that, we can also pretend that the sample mean  is normal and carry out approximations as if this were ", "a normal random variable.  Now, this statement that I'm making here is  only a loose statement.  It is not mathematically completely accurate. ", "We will see later a more accurate statement of the  central limit theorem.  In a different direction, we can talk about different types  of convergence. ", "We did define convergence in probability, but that's not  the only notion of convergence that's  relevant to random variables.  There's an alternative notion, which is convergence with ", "probability one.  Here is what it means.  We have a single probabilistic experiment.  And within that the experiment, we have a sequence ", "of random variables and another random variable, and  we want to talk about this random variable converging to  that random variable. ", "What do we mean by that?  We consider a typical outcome of the experiment, that is,  some omega.  Look at the values of the random variable Yn under that ", "particular omega, and look at that sequence of values, the  values of the different random variables under that  particular outcome.  Under that particular outcome, Y also has a certain numerical ", "value, and we're interested in whether this convergence takes  place as n goes to infinity.  Now for some outcomes, omega, this will happen. ", "For some, it will not happen.  We will say that we have convergence with probability  one if this event has probability equal to 1. ", "That is, there is probability one, that is, essential  certainty, that when an outcome of the experiment is  obtained, the resulting sequence of values of the ", "random variables Yn will converge to the value of the  random variable Y.  Now, this definition is easy to write down, but to actually  understand what it really means and the ways it is ", "different from convergence in probability is not so easy.  It does take some conceptual effort, and we will not  discuss it any further at this point. ", "Let me just say that this is a stronger notion of  convergence.  If you have convergence with probability one, you also gets  convergence in probability.  And it turns out that the law of large numbers also holds ", "under this stronger notion of convergence.  That is, we have that the sample mean converges to the  true mean with probability one. ", "This is the so-called strong law of large numbers, and  because this is a stronger notion of convergence, a more  demanding one, that's why this is called the strong law. ", "Incidentally, at this point, you might be quite uncertain  and confused as to what is really the difference between  these two notions of convergence. ", "The definitions do look different, but what is the  real difference?  This is quite subtle, and it does take  quite a bit of thinking.  It's not supposed to be something that is obvious. ", "So the purpose of this discussion is only to point  out these further directions but without, at this point,  going into it in any depth.  Finally, there is another notion of convergence in which ", "we're looking at the distributions of the random  variables involved.  So we may have a sequence of random variables.  Each one of them has a certain distribution described by a ", "CDF, and we can ask the question, does this sequence  of CDFs converge to a limiting CDF?  If that happens, then we say that we have convergence in ", "distribution, and this is more or less the type of  convergence that shows up when we deal with the central limit  theorem because this is really a statement about ", "distributions, that the distribution of the sample  mean in some sense starts to approach the distribution of a  normal random variable.  "], "vid_duration": [11.95, 10.61, 10.99, 15.18, 11.42, 10.25, 10.6, 11.2, 11.54, 12.0, 12.336, 11.39, 10.31, 10.89, 12.67, 11.12, 10.78, 10.12, 12.72, 11.6, 11.629, 11.221, 13.69, 13.04, 10.84, 14.06, 12.43, 11.97, 11.87, 12.31, 11.88, 11.509, 10.211, 10.52, 12.52, 15.61, 11.01, 10.59, 10.7, 12.17, 11.65, 12.42, 11.7, 11.74, 10.32, 15.09, 10.0, 11.789, 13.141, 10.41, 12.62, 13.42, 10.85, 12.79, 11.569, 10.96, 10.52, 10.691, 11.12, 10.87, 13.38, 12.57, 11.77, 13.21, 10.96, 14.76, 11.29, 11.17, 13.17, 12.24, 15.94, 11.06, 13.609, 11.281, 12.21, 12.59, 10.72, 12.87, 10.27, 11.24, 11.24, 12.52, 12.84, 10.05, 14.7, 12.23, 13.57, 14.81, 12.57, 12.14, 10.39, 10.528, 10.531, 13.979, 10.291, 14.56, 10.55, 12.44, 14.31, 10.39, 14.85, 10.52, 11.42, 13.5, 11.53, 11.54, 10.94, 12.02, 12.369, 12.52, 13.081, 11.96, 11.2, 12.75, 11.66, 10.95, 10.11, 11.44, 10.3, 10.9, 15.14, 11.22, 11.19, 10.15, 17.88, 12.039, 11.671, 11.17, 12.99, 12.026, 13.33, 10.69, 11.7, 14.201, 13.969, 10.93, 13.94, 12.09, 12.49, 10.46, 12.72, 14.54, 10.22, 12.83, 12.25, 10.13, 13.151, 12.389, 10.45, 11.201, 10.439, 10.53, 15.96, 12.48, 12.65, 11.89, 10.25, 11.85, 15.02, 11.3, 13.161, 13.68, 12.05, 12.97, 12.159, 10.65, 11.981, 10.719, 13.23, 11.891, 11.51, 14.82, 10.93, 11.601, 13.859, 10.871, 11.6, 12.279, 10.63, 11.261, 14.19, 11.14, 11.27, 15.25, 10.86, 11.96, 13.93, 10.06, 16.579, 14.16, 11.8, 11.45, 11.28, 12.79, 11.77, 15.841, 11.889, 16.131, 11.15, 13.899, 11.54, 12.681, 11.699, 12.31, 10.55, 11.531, 13.29, 12.179, 14.091, 10.96, 13.254, 10.949, 10.67, 13.651, 11.46, 12.509, 12.73, 11.571, 10.589, 11.291, 11.748, 10.892, 13.119, 11.781, 11.1, 10.859, 13.93, 13.62, 10.54, 12.321, 11.15, 10.819, 12.221, 11.029, 10.991, 12.639, 12.92, 10.81, 11.29, 10.89, 13.03, 12.87, 12.341, 12.989, 10.53, 10.07, 13.081, 11.179, 11.27, 13.0, 10.96, 11.471, 11.69, 11.51, 11.61, 11.08, 11.4, 10.79, 11.929, 12.431, 10.7, 10.57, 13.12, 11.219, 10.681, 10.2, 10.409, 10.13, 11.071, 13.37, 13.28, 12.51, 14.349, 11.511, 12.29, 10.21, 15.0, 11.29, 12.15, 10.719, 13.051, 13.64, 10.04, 11.03, 10.239, 8.164], "stet": [[0, 11.95], [11.95, 22.56], [22.56, 33.55], [33.55, 48.73], [48.73, 60.15], [60.15, 70.4], [70.4, 81.0], [81.0, 92.2], [92.2, 103.74000000000001], [103.74000000000001, 115.74000000000001], [115.74000000000001, 128.07600000000002], [128.07600000000002, 139.466], [139.466, 149.776], [149.776, 160.666], [160.666, 173.33599999999998], [173.33599999999998, 184.456], [184.456, 195.236], [195.236, 205.356], [205.356, 218.076], [218.076, 229.676], [229.676, 241.30499999999998], [241.30499999999998, 252.52599999999998], [252.52599999999998, 266.216], [266.216, 279.25600000000003], [279.25600000000003, 290.096], [290.096, 304.156], [304.156, 316.586], [316.586, 328.55600000000004], [328.55600000000004, 340.42600000000004], [340.42600000000004, 352.73600000000005], [352.73600000000005, 364.61600000000004], [364.61600000000004, 376.12500000000006], [376.12500000000006, 386.33600000000007], [386.33600000000007, 396.85600000000005], [396.85600000000005, 409.37600000000003], [409.37600000000003, 424.98600000000005], [424.98600000000005, 435.99600000000004], [435.99600000000004, 446.586], [446.586, 457.286], [457.286, 469.456], [469.456, 481.106], [481.106, 493.526], [493.526, 505.226], [505.226, 516.966], [516.966, 527.2860000000001], [527.2860000000001, 542.3760000000001], [542.3760000000001, 552.3760000000001], [552.3760000000001, 564.1650000000001], [564.1650000000001, 577.306], [577.306, 587.716], [587.716, 600.336], [600.336, 613.756], [613.756, 624.606], [624.606, 637.396], [637.396, 648.9649999999999], [648.9649999999999, 659.925], [659.925, 670.4449999999999], [670.4449999999999, 681.136], [681.136, 692.256], [692.256, 703.126], [703.126, 716.506], [716.506, 729.076], [729.076, 740.846], [740.846, 754.056], [754.056, 765.0160000000001], [765.0160000000001, 779.7760000000001], [779.7760000000001, 791.066], [791.066, 802.236], [802.236, 815.406], [815.406, 827.646], [827.646, 843.586], [843.586, 854.646], [854.646, 868.255], [868.255, 879.536], [879.536, 891.746], [891.746, 904.336], [904.336, 915.056], [915.056, 927.926], [927.926, 938.196], [938.196, 949.436], [949.436, 960.676], [960.676, 973.196], [973.196, 986.0360000000001], [986.0360000000001, 996.086], [996.086, 1010.7860000000001], [1010.7860000000001, 1023.0160000000001], [1023.0160000000001, 1036.586], [1036.586, 1051.396], [1051.396, 1063.966], [1063.966, 1076.106], [1076.106, 1086.496], [1086.496, 1097.0240000000001], [1097.0240000000001, 1107.555], [1107.555, 1121.534], [1121.534, 1131.825], [1131.825, 1146.385], [1146.385, 1156.935], [1156.935, 1169.375], [1169.375, 1183.685], [1183.685, 1194.075], [1194.075, 1208.925], [1208.925, 1219.445], [1219.445, 1230.865], [1230.865, 1244.365], [1244.365, 1255.895], [1255.895, 1267.435], [1267.435, 1278.375], [1278.375, 1290.395], [1290.395, 1302.764], [1302.764, 1315.2839999999999], [1315.2839999999999, 1328.3649999999998], [1328.3649999999998, 1340.3249999999998], [1340.3249999999998, 1351.5249999999999], [1351.5249999999999, 1364.2749999999999], [1364.2749999999999, 1375.935], [1375.935, 1386.885], [1386.885, 1396.995], [1396.995, 1408.435], [1408.435, 1418.735], [1418.735, 1429.635], [1429.635, 1444.775], [1444.775, 1455.9950000000001], [1455.9950000000001, 1467.1850000000002], [1467.1850000000002, 1477.3350000000003], [1477.3350000000003, 1495.2150000000004], [1495.2150000000004, 1507.2540000000004], [1507.2540000000004, 1518.9250000000004], [1518.9250000000004, 1530.0950000000005], [1530.0950000000005, 1543.0850000000005], [1543.0850000000005, 1555.1110000000006], [1555.1110000000006, 1568.4410000000005], [1568.4410000000005, 1579.1310000000005], [1579.1310000000005, 1590.8310000000006], [1590.8310000000006, 1605.0320000000006], [1605.0320000000006, 1619.0010000000007], [1619.0010000000007, 1629.9310000000007], [1629.9310000000007, 1643.8710000000008], [1643.8710000000008, 1655.9610000000007], [1655.9610000000007, 1668.4510000000007], [1668.4510000000007, 1678.9110000000007], [1678.9110000000007, 1691.6310000000008], [1691.6310000000008, 1706.1710000000007], [1706.1710000000007, 1716.3910000000008], [1716.3910000000008, 1729.2210000000007], [1729.2210000000007, 1741.4710000000007], [1741.4710000000007, 1751.6010000000008], [1751.6010000000008, 1764.7520000000009], [1764.7520000000009, 1777.1410000000008], [1777.1410000000008, 1787.5910000000008], [1787.5910000000008, 1798.7920000000008], [1798.7920000000008, 1809.231000000001], [1809.231000000001, 1819.7610000000009], [1819.7610000000009, 1835.721000000001], [1835.721000000001, 1848.201000000001], [1848.201000000001, 1860.851000000001], [1860.851000000001, 1872.7410000000011], [1872.7410000000011, 1882.9910000000011], [1882.9910000000011, 1894.841000000001], [1894.841000000001, 1909.861000000001], [1909.861000000001, 1921.161000000001], [1921.161000000001, 1934.322000000001], [1934.322000000001, 1948.002000000001], [1948.002000000001, 1960.052000000001], [1960.052000000001, 1973.022000000001], [1973.022000000001, 1985.1810000000012], [1985.1810000000012, 1995.8310000000013], [1995.8310000000013, 2007.8120000000013], [2007.8120000000013, 2018.5310000000013], [2018.5310000000013, 2031.7610000000013], [2031.7610000000013, 2043.6520000000014], [2043.6520000000014, 2055.1620000000016], [2055.1620000000016, 2069.982000000002], [2069.982000000002, 2080.9120000000016], [2080.9120000000016, 2092.5130000000017], [2092.5130000000017, 2106.3720000000017], [2106.3720000000017, 2117.2430000000018], [2117.2430000000018, 2128.8430000000017], [2128.8430000000017, 2141.1220000000017], [2141.1220000000017, 2151.7520000000018], [2151.7520000000018, 2163.0130000000017], [2163.0130000000017, 2177.203000000002], [2177.203000000002, 2188.3430000000017], [2188.3430000000017, 2199.6130000000016], [2199.6130000000016, 2214.8630000000016], [2214.8630000000016, 2225.723000000002], [2225.723000000002, 2237.683000000002], [2237.683000000002, 2251.6130000000016], [2251.6130000000016, 2261.6730000000016], [2261.6730000000016, 2278.2520000000018], [2278.2520000000018, 2292.4120000000016], [2292.4120000000016, 2304.212000000002], [2304.212000000002, 2315.6620000000016], [2315.6620000000016, 2326.942000000002], [2326.942000000002, 2339.732000000002], [2339.732000000002, 2351.5020000000018], [2351.5020000000018, 2367.3430000000017], [2367.3430000000017, 2379.232000000002], [2379.232000000002, 2395.3630000000016], [2395.3630000000016, 2406.5130000000017], [2406.5130000000017, 2420.4120000000016], [2420.4120000000016, 2431.9520000000016], [2431.9520000000016, 2444.6330000000016], [2444.6330000000016, 2456.3320000000017], [2456.3320000000017, 2468.6420000000016], [2468.6420000000016, 2479.192000000002], [2479.192000000002, 2490.723000000002], [2490.723000000002, 2504.0130000000017], [2504.0130000000017, 2516.192000000002], [2516.192000000002, 2530.2830000000017], [2530.2830000000017, 2541.2430000000018], [2541.2430000000018, 2554.4970000000017], [2554.4970000000017, 2565.4460000000017], [2565.4460000000017, 2576.116000000002], [2576.116000000002, 2589.7670000000016], [2589.7670000000016, 2601.2270000000017], [2601.2270000000017, 2613.7360000000017], [2613.7360000000017, 2626.4660000000017], [2626.4660000000017, 2638.0370000000016], [2638.0370000000016, 2648.6260000000016], [2648.6260000000016, 2659.9170000000017], [2659.9170000000017, 2671.665000000002], [2671.665000000002, 2682.5570000000016], [2682.5570000000016, 2695.6760000000017], [2695.6760000000017, 2707.4570000000017], [2707.4570000000017, 2718.5570000000016], [2718.5570000000016, 2729.4160000000015], [2729.4160000000015, 2743.3460000000014], [2743.3460000000014, 2756.9660000000013], [2756.9660000000013, 2767.506000000001], [2767.506000000001, 2779.827000000001], [2779.827000000001, 2790.977000000001], [2790.977000000001, 2801.796000000001], [2801.796000000001, 2814.017000000001], [2814.017000000001, 2825.046000000001], [2825.046000000001, 2836.037000000001], [2836.037000000001, 2848.6760000000013], [2848.6760000000013, 2861.5960000000014], [2861.5960000000014, 2872.4060000000013], [2872.4060000000013, 2883.6960000000013], [2883.6960000000013, 2894.586000000001], [2894.586000000001, 2907.6160000000013], [2907.6160000000013, 2920.4860000000012], [2920.4860000000012, 2932.827000000001], [2932.827000000001, 2945.816000000001], [2945.816000000001, 2956.3460000000014], [2956.3460000000014, 2966.4160000000015], [2966.4160000000015, 2979.4970000000017], [2979.4970000000017, 2990.6760000000017], [2990.6760000000017, 3001.9460000000017], [3001.9460000000017, 3014.9460000000017], [3014.9460000000017, 3025.9060000000018], [3025.9060000000018, 3037.3770000000018], [3037.3770000000018, 3049.067000000002], [3049.067000000002, 3060.577000000002], [3060.577000000002, 3072.187000000002], [3072.187000000002, 3083.267000000002], [3083.267000000002, 3094.667000000002], [3094.667000000002, 3105.457000000002], [3105.457000000002, 3117.3860000000022], [3117.3860000000022, 3129.8170000000023], [3129.8170000000023, 3140.517000000002], [3140.517000000002, 3151.0870000000023], [3151.0870000000023, 3164.207000000002], [3164.207000000002, 3175.426000000002], [3175.426000000002, 3186.1070000000022], [3186.1070000000022, 3196.307000000002], [3196.307000000002, 3206.716000000002], [3206.716000000002, 3216.8460000000023], [3216.8460000000023, 3227.917000000002], [3227.917000000002, 3241.287000000002], [3241.287000000002, 3254.5670000000023], [3254.5670000000023, 3267.0770000000025], [3267.0770000000025, 3281.4260000000027], [3281.4260000000027, 3292.9370000000026], [3292.9370000000026, 3305.2270000000026], [3305.2270000000026, 3315.4370000000026], [3315.4370000000026, 3330.4370000000026], [3330.4370000000026, 3341.7270000000026], [3341.7270000000026, 3353.8770000000027], [3353.8770000000027, 3364.5960000000027], [3364.5960000000027, 3377.6470000000027], [3377.6470000000027, 3391.2870000000025], [3391.2870000000025, 3401.3270000000025], [3401.3270000000025, 3412.3570000000027], [3412.3570000000027, 3422.5960000000027], [3422.5960000000027, 3430.760000000003]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [116, 737, 1093, 1544, 2036, 2543, 3027, 3430]}
{"example_id": "mit153@@MITRES6_012S18_L23_300k", "text": [" In this lecture, we look in some depth into various  properties of Poisson processes.  These properties would be quite hard to study if one ", "were to proceed just analytically by  manipulating formulas.  However, by using memorylessness and our  intuitive understanding of what the Poisson process ", "really is, they become quite simple.  And the mathematical manipulations can be avoided  almost entirely.  We will start by arguing that the sum of independent Poisson ", "random variables is Poisson.  But we will then establish the much stronger statement that  if we merge two independent Poisson processes, we, again, ", "obtain a Poisson process.  We will see that we can exploit this fact to solve  some problems that would be quite difficult otherwise.  Once more, intuitive reasoning is the key. ", "Finally, we will spend some time discussing a phenomenon  that goes under the name of random incidence.  The Poisson process has been running.  You show up at a certain time. ", "You look at the size of the inter-arrival interval during  which you show up.  It turns out that this inter-arrival interval that  you get to observe is not a typical one. ", "It tends to be larger than the typical  inter-arrival interval.  We will understand what exactly is going on, build  some intuition, and realize that this is a general ", "phenomenon that also shows up in many other contexts.    In this segment, we consider the sum of independent Poisson  random variables, and we establish a remarkable fact, ", "namely that the sum is also Poisson.  This is a fact that we can establish  by using the convolution formula.  The PMF of the sum of independent random variables ", "is the convolution of their PMFs.  So we can take two Poisson PMFs, convolve them, carry out  the algebra, and find out that in the end,  you obtain again a Poisson PMF. ", "However, such a derivation is completely unintuitive,  and does not give you any insight.  Instead, we will derive this fact  by using our intuition about what ", "Poisson random variables really represent.  We will work with a Poisson process  of rate lambda equal to 1.  But let us remind ourselves of the general Poisson PMF ", "if we have a more general rate lambda.  This is the PMF of the number of arrivals  in a Poisson process with rate lambda during a time ", "interval of length tau.  And this Poisson PMF has a mean equal to lambda tau.  And you can think of lambda tau as being  the parameter of this Poisson PMF. ", "So we say that this is a Poisson PMF with parameter  equal to lambda times tau.  Now, let us consider two consecutive time intervals ", "in this processes that have length mu and nu.  ", "And let us consider the numbers of arrivals  during each one of these intervals.  So we have M arrivals here and N arrivals there.  Of course, M and N are random variables. ", "What kind of random variables are they?  Well, the number of arrivals in the Poisson process of rate 1,  over a period of duration mu is going ", "to have a Poisson PMF in which lambda is one, tau,  the time interval is equal to mu,  so it's going to be a Poisson random variable with parameter, ", "or mean, equal to mu.  Similarly for N, it's going to be a Poisson random variable  with parameter equal to nu. ", "Are these two random variables independent?  Of course they are.  In a Poisson process, the numbers  of arrivals in disjoint time intervals  are independent random variables. ", "What kind of random variable is their sum?  Their sum is the total number of arrivals  during an interval of length mu plus nu, ", "and therefore this is a Poisson random variable  with mean equal to mu plus nu.  So, what do we have here? ", "We have the sum of two independent Poisson random  variables, and that sum turns out also  to be a Poisson random variable.  More generally, if somebody gives you ", "two independent Poisson random variables,  you can always think of them as representing numbers  of arrivals in disjoint time intervals,  and therefore by following this argument, ", "their sum is going to be a Poisson random variable.  And this is the conclusion that we wanted to establish.  It's a remarkable fact.  It's similar to the fact that we had established ", "for normal random variables.  The sum of independent normal random variables  is also normal, so Poisson and normal distributions  are special in this respect. ", "This is a property that most other distributions do not   We will now study what happens when  we merge independent Poisson processes. ", "The story as well as the final conclusion  is going to be similar to what happened for the case  where we merged independent Bernoulli processes.  In particular, we will see that the merged process will also ", "be Poisson.  What is the story?  Suppose that you have two light bulbs.  One of them is red and flashes at random times that ", "are described according to a Poisson process  with a certain rate, lambda1.  The other light bulb is green, flashes also as a Poisson  process with a certain rate. ", "Furthermore, we assume that the two light bulbs  are independent of each other.  If you're color blind so that the only thing that you see  is flashes but without being able to tell the color, ", "what kind of process are you going to see?  Well, you will see a Poisson process also,  and at this point, you can probably  guess what the arrival rate is going ", "to be for this Poisson process.  It should be the sum of these two arrival  rates of the processes that you started with.  So this will be our final conclusion, ", "but we want to verify that this is indeed  the correct conclusion.  So let us look at the situation in some more detail.  We have the two processes, two arrival processes-- the red one ", "and the green one-- and the merged process  is formed by recording an arrival at any time where  either of the two processes that you ", "started with records an arrival.  Let us now look at the time interval  and think about the number of arrivals in the merged process ", "during this time interval.  What is that the number?  That number is equal to the number of arrivals  that you have in the first process plus ", "the number of arrivals that you have in the second process.  Let's call those numbers N1 and N2 so that what we have here ", "is N1 plus N2.  Now, N1 is a Poisson random variable  because this is a Poisson process.  Similarly, N2 is a Poisson random variable. ", "We assume that these two processes are independent.  Therefore, N1 plus N2 is the sum of independent Poisson  random variables, and therefore, N1 plus N2  is also a Poisson random variable. ", "This is reassuring.  It's a good piece of evidence that the blue process  is a Poisson process, but this is not enough.  To argue that it is a Poisson process,  we need to check the defining properties of a Poisson ", "process.  One defining property is the independence property.  If we take disjoint intervals, the number of arrivals  here is independent, or should be independent, ", "from the number of arrivals there.  The argument here is exactly the same as for the Bernoulli case,  so we will not go through it in any detail. ", "We just notice that whatever happens during that time  has to do with whatever happens during those times in the two  processes that we started with. ", "And similarly, what happens in these times  has to do with what happens in these two processes  during those times.  Because for each one of the two processes that we start with, ", "we have the Poisson assumption so that this interval  is independent from that interval in the sense  that arrivals here and arrivals there are independent.  So because of this, whatever happens during those ", "times has nothing to do with whatever  happens in those times, so number of arrivals  here is independent from the number of arrivals there.  The other property that we need to check ", "is that the probability of recording an arrival  during a small time interval of length delta,  that this probability has the right scaling ", "properties, that it is linear in delta,  in the length of this interval, and that the probability of two  or more arrivals here is negligible.  To see what happens during a typical interval in the merged ", "process, we need to consider what  is going to happen during that typical interval  in the other two processes and consider  all the possible combinations. ", "During a little interval, the red process  is going to have zero arrivals with this probability,  one arrival with this probability,  and two or more arrivals with this probability, which ", "is negligible.  Actually here, we're ignoring terms of order delta squared.  These are the correct expressions  if we only focus on terms that are either constants or linear ", "in delta.  We are ignoring terms that are of order delta  square or higher.  And similarly for the green process,  we have these probabilities for the number of arrivals  that may happen during a small interval. ", "For the merged process, we will have zero arrivals if and only  if we have zero arrivals in the red process  and zero arrivals in the green process. ", "The probability of these two events happening,  because we assume that the two processes that we started with  are independent, is going to be the product  of the probabilities of zero arrivals in one process times ", "zero arrivals in the other process.  We multiply those two terms, and if we throw away  the term delta squared, which is negligible, ", "we see that this event is going to happen with probability 1  minus lambda1 plus lambda2 times delta.  ", "What's the probability that we get one arrival?  This is an event that can happen in two ways.  We could have one arrival in the red process ", "and zero arrivals in the green process,  and this combination happens with this probability.  Alternatively, we could have one arrival in the green process ", "and zero arrivals in the red process.  This is this event and it happens with this probability.  Having one arrival in the blue process  can happen either this way or that way, ", "so the probability of one arrival  will be the sum of these two probabilities.  And if we throw away terms that are  order of delta squared, what we're left with ", "is just lambda1 plus lambda2 times delta.  ", "Finally, there's the possibility that the blue process  is going to have two or more arrivals.  This happens if we have one red and one green arrival, ", "which happens with this probability,  or if anyone of the processes has two or more arrivals, which  would be terms here, here, and these would be the scenarios. ", "But we notice that each one of these scenarios  has probability that's order of delta squared.  This term also has probability of order delta squared,  so overall, the possibility that the blue process has ", "two or more arrivals-- this is something that has probability  that's of order delta squared.  So during a typical small interval, ", "there is probability proportional  to the length of the interval of having one arrival,  and lambda1 plus lambda2 is the factor of this proportionality, ", "and the remaining probability is assigned to the event  that there are zero arrivals.  There's essentially negligible probability  of having two or more arrivals, but this ", "together with the independence assumption  is exactly what comes in the definition of a Poisson process  with an arrival rate equal to this number. ", "And so we have established that the merged process  is a Poisson process whose rate is   As before, we have a red Poisson process and a green Poisson ", "process.  We merge these two processes, and we only  observe the merged process.  Here's an interesting question.  This is an arrival of the merged process. ", "Where did it come from?  Is it red, or is it green?  We cannot know, but can we tell what is the probability that it  came from the red stream? ", "The way to answer this question is  to look at the table of all the things  that can happen during a little interval  around that particular time in which we had an arrival. ", "We are told that there was an arrival at time t or an arrival  during an interval, a small interval around time t.  This means that we're told that this event here has happened. ", "Given this information, what is the conditional probability  that actually this event here occurred?  This is just the fraction of this probability divided ", "by the total probability of the conditioning event.  So the answer is lambda 1 divided  by lambda 1 plus lambda 2.  Does this answer make sense? ", "Well, suppose that lambda 1 and lambda 2 were equal.  In that case, by symmetry, when an arrival comes,  it should be equally likely to have come either from the red ", "or from the green stream.  And this is consistent with this answer.  We can reason similarly for a slightly different question. ", "You wait until the kth arrival, let's say the third arrival.  Where did that arrival come from?  Well, that case, arrival occurred  during a specific little time interval and conditioning ", "on it having occurred during that particular time interval,  we can then repeat the reasoning that we had here and argue  that given that we had an arrival-- it just happens ", "to be the third arrival during that time interval--  there's going to be this particular conditional  probability that it came from the red stream.  So we obtained the same answer once more. ", "Now, this arrival came from one of the two streams  with some probabilities.  This arrival came from one of the two streams  with some probabilities. ", "Does the origin of this arrival affect or depend  on the origin of that arrival?  Because we have assumed independence  across time for each one of the processes ", "that we started with-- and therefore, we also  have the same thing for the merged process-- whatever  has to do with events during this interval  is independent from anything that ", "has to do with events in that interval.  And because of this, one could argue formally--  but hopefully, this is intuitive enough--  that the origin of this arrival and the origin of that arrival ", "are independent events.  And now that we have this property,  we can answer questions such as the following. ", "We've had 10 arrivals so far.  What is the probability that exactly four out of these 10  are red?  ", "Each one of those arrivals has this probability of being red.  The origin of different arrivals are independent of each other. ", "So essentially, we're dealing with 10 Bernoulli trials,  each of which has two possible outcomes, red or green,  and is red with this particular probability. ", "Therefore, the answer is going to be  given by the binomial probabilities, which  is the probability of having four successes in 10 trials. ", "And we obtain lambda 1 over lambda 1 plus lambda 2.  That's the probability of a red to the number of red arrivals. ", "And then the remaining probability,  1 minus that, which is lambda 2 over lambda 1  plus lambda 2 to the remaining power, which is equal to 6. ", "So to summarize.  Each one of the arrivals in the merged process  has a certain probability of being  a red arrival or a green arrival. ", "Which one of the two is the case?  We can think of it as an outcome of Bernoulli trial,  and the Bernoulli trials associated  with different arrivals are independent of each other ", "as a consequence of the independence of Poisson   We will now go through a beautiful example, in which we  approach the same question in a number of different ways ", "and see that by reasoning based on the intuitive  properties of a Poisson process, we  can arrive quickly to the right answer.  The problem is as follows.  We have three lightbulbs, and each light bulb ", "is being lit at time zero, it starts working,  and the light bulb lasts for a certain amount  of time, which is random.  So this light bulb lasts so long, this one lasts so long, ", "this one lasts that long.  The lifetime of a light bulb, the time until it burns out,  will be a random variable, and we  make the following assumptions. ", "The lifetimes of the three light bulbs,  which we denote by X, Y, and Z, will  be independent random variables, each of which  is an exponential random variable with the parameter ", "lambda.  We're interested in the question of calculating  the expected time until a light bulb burns out  for the first time.  So in this picture, the light bulb that burned out first ", "is the second light bulb, and this quantity  is the time until the first burnout.  How do we calculate this quantity?  The time until a first light bulb burns out ", "is the minimum of the times at which each one of them  burns out.  So we're interested in the expected  value of this quantity. ", "It's a random variable, which is a function of three  random variables.  How do we calculate the expected value  of a function of random variables?  We can use the expected value rule. ", "Let us take the function of interest,  which is the minimum of three numbers.  Then we need to multiply by the joint PDF or these three ", "random variables X, Y and Z. Now,  because these three random variables are independent,  the joint PDF is the product of their individual PDFs,  which are all exponential. ", "And so we obtain this expression for the joint PDF.  And we need to integrate this over all x's, y's, and z's. ", "So it's going to be an integral that  goes for each one of the three variables from 0 to infinity.  And here we have dx, dy, dz. ", "So this is one approach that can give us  the answer if you're able to manipulate and keep  track of everything that happens in this three-dimensional ", "integral.  But this is too tedious and this is not a good way to go.  Let us try to think of an alternative way.  Can we figure out the distribution ", "of this random variable?  It's a function of three random variables, so in some sense,  it's a derived distribution problem,  so we can try to calculate the cumulative distribution ", "function of the minimum of the three.  So for the cumulative, we would be looking at the probability  that the minimum of these three random variables is less than ", "or equal to a certain number.  It turns out that the calculations  are a little faster if we look at the probability  that this is larger than or equal to a certain number. ", "What is this event?  The minimum is larger than or equal to t,  if, and only if, all three of them  are larger than or equal to t. ", "So the probability of this event is the same as the probability  that X is larger than or equal to t,  Y larger than or equal to t, and Z larger than or equal to t.  But now X, Y, and Z are independent, ", "so we need to multiply the probability that X  is larger than or equal to t, which  for an exponential random variable  is e to the minus lambda t, then the probability ", "of the second event which is again e to the minus lambda t,  and, finally, the probability of the third event, which  is, again, e to the minus lambda t,  which is e to the minus 3 lambda t. ", " Now, we look at this expression for the probability  that the random variable is larger than or equal  to t and recognize that this is the expression that we have ", "when we have an exponential random variable with parameter  equal to 3 lambda.  If you want to do it formally, subtract this quantity from 1 ", "to find the CDF, take the derivative,  and you will find an exponential PDF.  So the conclusion is that this random variable  is exponential with parameter 3 lambda. ", " And since it's an exponential with parameter 3 lambda,  then we know what the expected value is.  It is going to be 1 over 3 lambda. ", "And this is the answer to the question  that we were interested in.  Now, the fact that this is an exponential random variable,  but with a different parameter, is a pretty clean fact, ", "and so it should have a good explanation.  Let us now try to think about a good explanation for this fact. ", "Whenever we deal with an exponential random variable,  one way of thinking about it is that  this exponential random variable is the first time in a Poisson ", "process.  So imagine that there's a Poisson process that  runs forever, and X is the first arrival time.  For this light bulb, we can think the same way, ", "and since X and Y are assumed to be independent,  we can assume that here we have an independent Poisson  process, independent from the first one,  it has its own arrival times, and Y is the first arrival ", "time in this Poisson process.  And finally, we have a third independent Poisson process,  and the random variable Z is the first arrival  time in that Poisson process. ", "So X, Y and Z are interpreted as first arrivals  in three independent Poisson processes.  Now, let us take these three Poisson processes  and merge them. ", "If we merge these three processes, what we obtain  is a merged process, which is Poisson with parameter  equal to the sum of the rates or parameters of each one ", "of the processes, so it's a Poisson process  with parameter 3 lambda.  Now, how can we interpret the random variable of interest,  the first burnout time, in terms of the merged process? ", "So the merged process has an arrival  whenever one of those three processes has an arrival.  The first arrival in the merged process  will happen the first time that one of these three processes ", "is going to have an arrival.  Therefore, we can interpret the random variable  of interest, the first burnout time,  as the first arrival time in a merged process. ", "But now the merged process is Poisson with parameter 3  lambda, therefore, this random variable  is going to be an exponential random variable with parameter ", "3 lambda.  And from this, we also obtain the expected value  of that random variable.  The beauty of this last approach for coming up with the answer ", "by reasoning in terms of merged Poisson processes  is that we didn't have to do any calculations at all, just  use the intuitive understanding of Poisson processes ", "and, especially, the interpretation  of an exponential random variable as the first arrival  time in a Poisson process.  Let us now try to solve a somewhat harder problem. ", "Let us try to calculate the expected time  until all the light bulbs burn out.  So one light bulb will burn out, then another one will burn out, ", "and, finally, the third one will burn out.  We want to find the expected time until this happens.  Once more, we will be thinking of these burnout times ", "as the first arrival times in Poisson processes.   The total time until the third burnout ", "can be split into different periods.  There's a time until one light bulb burns out.  And the expected value of this period ", "here is going to be 1 over 3 lambda.   What happens at this time?  The second light bulb has burned out, so we can forget about it, ", "take it out of the picture.  We have two lightbulbs.  Let us look at the time it will take  until one of these two light bulbs burns out. ", "So we're interested in this period of time.  Now, the Poisson process starts fresh at this time.  After this time, whatever happens ", "is just an ordinary Poisson process  as if it were starting at this time.  So this is going to be an exponential random variable  starting from this time. ", "And this is going to be another exponential random variable.  So the time until the next light bulb burns out in this case  is going to be the minimum of two  exponential random variables. ", "We can think again about merging these two Poisson  processes to obtain a Poisson process with total rate 2  lambda, and the time until one of these two turns out ", "is going to be the first arrival time in that merged process.  And so the expected time until the first arrival  of the merged process is going to be 1 over 2 lambda. ", "And finally, once this burnout has happened,  we can forget about this light bulb.  We're left just with one light bulb, and starting from here, ", "we wait until that light bulb burns out.  Once more, because of the fresh start property of the Poisson  process, starting from here until it burns out  is going to be a random variable, which ", "is an exponential random variable.  And in this case, an exponential random variable with rate  just lambda.  And by adding these three quantities,  we get the expected time until all three have burned out. ", "This is a problem that would have  been quite hard to solve in a more analytical way.  We're dealing with a random variable, which is now  the maximum of X, Y, and Z. And the distribution ", "of this random variable is not so simple to write down.  So that would not be a very good approach  for going about this problem.  But we managed to find the expected value ", "of this random variable without having to write down  its distribution, by breaking this random variable  into a sum of three particular random variables, each of which ", "had a nice intuitive interpretation.   In this segment, we discuss splitting a Poisson process ", "into two different streams.  So we have a Poisson process with some arrival rate lambda,  and whenever there is an arrival,  we decide to send it either to one or another stream. ", "And for example, this arrival might be sent to that stream,  this arrival might be sent to this stream,  this arrival might be sent to this stream,  that arrival might be sent to that stream. ", "How do we decide where to send these arrivals?  We make those decisions using independent coin  flips with a coin that has a certain fixed bias equal to q. ", "So when this arrival comes, there's  probability q that it will be sent that direction  or probability 1 minus q that it will  be sent in the other direction. ", "All of these coin flips are independent,  so the decision on where to send the second arrival  is going to be independent from the decision of where ", "to send the first arrival.  And furthermore, we make one more assumption  that these coin flips are independent from everything  else.  They're independent from the time history ", "of the original Poisson process.  For example, the coin flip that decides the destination  of this first arrival can not depend ", "on how long it took for this arrival to occur.  We will argue now that this stream is a Poisson process  and by symmetry, therefore, this stream ", "is also a Poisson process.  We need to verify two assumptions.  One has to do with independence.  The argument here is entirely analogous to arguments ", "that we have already carried out in the past,  namely disjoint time intervals in the original process  are independent.  Coin flips that happened during those disjoint time intervals ", "are also independent of each other,  and for this reason, whatever happens during disjoint time  intervals in that stream will also be independent. ", "The other property that we need to verify  has to do with probabilities of small intervals.  If we take a little interval here of length delta, ", "what is going to happen during that interval?  Well, we look at what happens during the corresponding  interval in the original stream.  In the original stream, the probability ", "of having two or more arrivals-- this probability is order  of delta squared, so there's no way  of having two or more arrivals during that little interval, ", "or to be more precise, the probability  of two or more arrivals here is going to be negligible,  order of delta squared.  What is the probability of having one arrival ", "during that little interval?  We will have one arrival here if we've  had one arrival in this time interval, which ", "happens with probability lambda times delta,  and also the coin flip sent the arrival ", "in this direction, which is something  that happens with probability q, and the remaining probability  is assigned to the event of having  zero arrivals during that interval. ", "So the probability of two or more arrivals is negligible,  and the probability of one arrival  is proportional to delta.  And that's what we need in order to have a Poisson process. ", "The factor of proportionality that multiplies delta  is equal to lambda times q.  Therefore, this is a Poisson process with parameter,  or arrival rate, equal to lambda times q. ", "And by a similar argument, this process here  is going to be a Poisson process with parameter  equal to lambda times 1 minus q.  So by splitting a Poisson process using independent coin ", "flips, we obtain two different Poisson streams.  Are these Poisson streams independent?  For the case of the Bernoulli process,  we had seen that the resulting streams were not independent. ", "The reason for the Bernoulli process  was that if I tell you that at a certain slot  we had an arrival in this stream,  that would tell you that in the corresponding time ", "slot of the other process you could not have an arrival  and that was a source of dependence.  It turns out that for the Poisson process,  because it runs in continuous time, ", "telling you that we had an arrival at this particular time  instant does not give you any substantial or any  nontrivial information about the other process, ", "and the two processes remain independent.  This result is surprising in some ways, but it is true.  A mathematical derivation proceeds ", "along a line that's a little different from the intuitive  argument that I just outlined.  And we will not go through that derivation,  ", "In this segment, we discuss the so-called \"random incidence\"  paradox for the Poisson process.  It's a paradox because it involves  a somewhat counterintuitive phenomenon. ", "However, we will understand exactly what's going on,  and in the end, it will cease to be a paradox  and we will have an intuitive understanding  of what exactly is happening. ", "So consider a Poisson process that has been running forever,  or think of it as a Poisson process that  started a very long time back in the past. ", "To make things concrete, suppose that the arrival rate  is 4 arrivals per hour so that the expected interarrival time  is one fourth, in hours, or that would ", "be the same as 15 minutes.   For example, suppose that the bus company in your town  claims that buses arrive to your stop ", "according to a Poisson process with this particular rate.  But you don't really believe that your bus company is  telling the truth and you decide to investigate. ", "So what you do is the following.  You show up at some time at your bus stop  and wait until the next arrival comes ", "and also ask someone who lives near the bus  stop, what time was the last arrival?  And they tell you the last arrival  happened at that time instant. ", "And you measure this amount of time,  which is the interarrival time, record what it is,  repeat this experiment on many days, and calculate an average. ", "What you're likely to see turns out  to be something around 30 minutes.  At this point, you could go to the bus company ", "and challenge them.  You claim an arrival rate of 4 arrivals per hour, which  would translate into interarrivals of 15 minutes,  but every day I go and check the interarrival time ", "and I find that they are close to 30 minutes.  What's the explanation?  What's going on?  Is it that the belief or the claim of the bus company  is incorrect, or is there something more complicated? ", "So let us try to understand what's  going on by being very precise and careful.  You show up at the bus station at some time-- ", "let's call that time t star.  You ask someone who has been at the station,  when was the last arrival time, and they tell you, ", "and it is some number U. You wait until the next bus,  and the next bus arrives at some future time capital  V. You are interested in the interarrival time ", "that you're observing, which is the difference  between these two random variables V minus U.  Now this difference-- let us split it into two pieces. ", "There's one piece from t star until V,  which is V minus t star.  And there's another piece, which is the first interval, ", "and this is t star minus U. Now t star, the time at which you  arrive, is just a constant. ", "Suppose that you arrive at the bus station at exactly 12 noon.  There's nothing random about it.  However, V and U are random variables.  What kind of random variable is this? ", "You show up at 12 noon and you wait until the first arrival.  Because a Poisson process starts fresh at any given time-- ", "so after 12 noon it starts fresh-- this  is the time until the first arrival in a Poisson process  with rate lambda, so this is a random variable  which is exponential with parameter lambda. ", "Now let us understand what this random variable is.   One way of thinking about it is to think  of the Poisson process running backwards in time, ", "so you live time backwards.  You show up at 12 noon, and then time runs backwards,  and you wait until you see the first arrival coming ", "in this backwards universe.  So we're dealing here with the time  until an arrival in a Poisson process  that runs backwards in time. ", "What kind of process is a backwards Poisson process?   If you take a Poisson process in reverse time,  the independence assumption is not affected. ", "Disjoint time intervals are independent.  Even if you reverse time, disjoints time intervals  still remain independent.  Any given time interval of small length delta ", "will have certain probabilities of an arrival  or of two arrivals, and these will be the same  whether time goes forward or time goes backward. ", "So the conclusion from this discussion  is that the backwards running Poisson process  is also a Poisson process, and so this time  until the first arrival in the backwards process ", "is just like the time until the first arrival in a Poisson  process.  So this also is an exponential random variable  with parameter lambda. ", "Even more than that, these two random variables  are independent of each other.  Why are they independent?  The length of this time interval has ", "to do with the history of the Poisson process  after time t star.  The length of this time interval has  to do with the history of the Poisson process  before time t star, but in the Poisson process because ", "of the independence property, the past and the future  are independent, and therefore, this random variable  is independent from that random variable. ", "In any case, the expected value of the interarrival interval  that you see, the expected value of this random variable,  is going to be the expected value of one exponential, which ", "is 1 over lambda, plus the expected  value of another exponential, which is 1 over lambda,  and we get a result of 2 over lambda. ", "And that's why when you actually carried out the experiment,  you saw interarrival intervals that  had a length of 30 minutes as opposed to the 15 minutes ", "that you were expecting in the first place.  Now how can this be?  Since the interarrival times in a Poisson process  have expected value 1 over lambda, ", "how can it be that the expected length  of the interarrival times that you see  have an expected value of 2 over lambda?  Well, the resolution of this paradox has to do [with] ", "what exactly we mean when we use the words an interarrival time.  There's one interpretation which is the first interarrival time, ", "the second one, the hundredth interarrival time--  each one of these actually has an expected  value of 1 over lambda. ", "But this is a different kind of interarrival time.  It's not the first or the second or  some specific k-th interarrival time.  It's the interarrival time that you selected to watch. ", "When you show up at a certain time, like 12 noon,  you're more likely to fall inside a large interarrival  interval rather than a smaller interarrival interval. ", "So just the fact that you're showing up  at a certain time that's uncoordinated  with the rest of the process makes  you more likely to be biased towards longer ", "rather than shorter intervals.  And this bias is what causes this factor of 2.   So it's an issue really about how you sample ", "or how you choose the interarrival time  that you're going to watch, and this particular sampling  method has a bias towards longer intervals.  As we will see, this is not something ", "that's specific to the Poisson process.  In general, in many occasions there  are different ways of sampling which give you  different answers, and we will go through a number of examples ", "that will give you some intuition about the source  of the discrepancy between these two answers.    In this segment, we go through another random incidence ", "example, one that does not involve the Poisson process,  but a much simpler arrival process.  We do this for two reasons.  One is because of the simplicity of the example, ", "perhaps the intuition will be a little more transparent.  And the second reason is to illustrate  that we're dealing with a phenomenon that's  not specific to the Poisson process,  but is much more general. ", "The example is as follows.  We have an arrival process, in which  arrivals happen at random.  And the consecutive interarrival times  are independent, identically distributed, random variables. ", "However, unlike the Poisson process,  these interarrival times are not exponential random variables.  But instead, we assume that they are either  5 or 10 minutes with equal probability. ", "So we have an arrival.  The next arrival may happen five minutes later.  The next arrival may again happen five minutes later.  Then maybe we get an interarrival interval of length ", "10, then maybe another interarrival interval of length  10, followed by one of five, and so on.  ", "What is the expected value of the kth interarrival time?  Well, an interarrival time is with probability 1/2 of length ", "five and with probability 1/2 of length 10.  So the average interarrival time is 7.5. ", "Now, you show up at a random time.  And by random we mean a time that's  completely uncoordinated with the arrival process. ", "You show up at some point in time,  and you look at the interarrival interval in which you fall.  And you're interested in the length  of that particular interarrival interval. ", "What is the probability that you fall inside a five minute  interarrival interval?   Since intervals of length five are as likely ", "as intervals of length 10, in the long run,  there's going to be roughly as many five minute intervals  as there will be 10 minute intervals.  On the other hand, the 10 minute intervals ", "occupy twice as much space on the real line.  And for this reason, it is 2 times more likely  that you will fall in a 10 minute interval rather  than a five minute interval. ", "In other words, the probability of falling in a five minute  interval is going to be 1/3.  Whereas the probability of following in a 10 minute  interval is going to be 2/3. ", "For this reason, the expected length  of the interarrival interval that you  get to see when you arrive is equal to, with probability 1/3,  you see a five. ", "And with probability 2/3, you see a 10.  And this number evaluates approximately to 8.3,  which is indeed larger than 7.5. ", "The conclusion from this example is similar to the one  that we had for the Poisson process.  Although the average interarrival time  is 7.5, when you show up at a random time ", "you are more likely to fall in a larger interval.  And for that reason, on the average,  you will be seeing longer interarrival intervals.  The calculations that we carried through in that simple example ", "can be generalized for more general arrival  processes, called renewal processes.  In a renewal process, once more the consecutive interarrival  times are independent, identically distributed, ", "random variables.  But they have a general distribution.  For this case, there's a formula again  that tells us the length or the expected  length of the interarrival interval that you get to see. ", "But the main message from this example  is that it does make a difference how you sample,  how you choose what to watch and what to measure. ", "It makes a difference whether you  decide to measure the kth interarrival time and it's  average value or to decide to measure  an interarrival time that's chosen ", "by showing up at a random time.  The two methods of sampling give you different results.  And we will see next a few examples  that have this particular flavor. ", "  In this segment, we want to reinforce the message  that how you choose to sample can give different results,  and the choice of sampling is important. ", "Suppose you're interested in measuring the average family  size in some population.  Suppose that there are families that are small  and have just one person in them, ", "and there's also a family that has many people in it.  What does it mean to measure the average family size? ", "One possibility is to pick at random a family, each family  being chosen with equal probability,  and talk about the expected value that you get, ", "or the average value if you sample that way.  In this particular example with probability 1/4,  you get a 1, with probability 1/4, you get a 1 ", "with probability 1/4, you get a 1.  So the answer would be with probability 3/4 you get a 1,  and with probability 1/4, you get a 6. ", "But suppose that instead, you pick a person at random  and you ask for that person, how big is your family?  What's the expected value of the answer you're going to get? ", "Here we have nine people.  Out of those nine people, 3 of them  will give you an answer my family has size one,  and six of those people will give you an answer, ", "my family has a size of six.  And this number is going to be larger  than the previous number.  You're going to get different answers. ", "So it is possible to have a situation where  you can make a statement such as the following.  The average family size is three,  but the average person lives in a family of size four. ", "There is no contradiction between these two statements  because we're measuring different things.  Another example of the same flavor.  You're interested in the average bus occupancy. ", "You're interested in whether buses are crowded or not  in your city.  One way of carrying out this calculation  is to pick buses at random, each bus ", "is equally likely to be picked, and see  how many people are riding this bus.  Another possibility is to take a typical passenger,  a random passenger, and ask them, how crowded was your bus? ", "Take an extreme case.  Suppose that half of the buses have 0 people in them,  and half of the buses have 50 people in them. ", "If you look at random buses, then the average occupancy  would be 25.  But if you ask passengers, all of the passengers ", "would report 50, and it would be, again, a different answer.  A similar situation is if you're talking about average class  sizes. ", "One method is to look at all the classes,  see how many students there are in each class,  and take the average.  Another method would be to ask a typical student, ", "how large is your class?  Because more students are in large classes, when  you pick a student at random, you  are likely to get a higher answer, as opposed ", "to when you look at a random class.  The moral from all these examples  is that it is very important to be  careful about what you choose to sample. ", "When you pick at random, what exactly  are you picking at random?  And you need to be aware that different sampling  methods measure different things,  and will generally give you different results. ", ""], "vid_duration": [10.03, 10.62, 12.5, 11.5, 14.17, 12.07, 11.92, 11.43, 11.401, 12.26, 11.75, 11.37, 14.2, 11.09, 12.69, 12.92, 10.67, 13.22, 11.04, 12.94, 11.889, 12.861, 11.66, 10.66, 11.4, 12.36, 12.45, 11.7, 12.179, 11.36, 10.95, 11.21, 12.5, 10.87, 10.71, 13.01, 10.84, 12.21, 12.88, 11.2, 10.12, 12.81, 11.84, 10.78, 10.16, 10.29, 10.629, 12.991, 10.46, 10.46, 13.57, 11.15, 11.77, 11.89, 12.39, 11.62, 12.94, 11.37, 12.13, 11.28, 12.13, 12.02, 10.61, 11.96, 13.09, 13.45, 12.7, 11.44, 10.28, 10.23, 10.41, 14.863, 11.261, 11.67, 13.649, 15.63, 13.811, 11.65, 10.799, 10.551, 14.62, 11.67, 13.36, 10.2, 11.78, 12.0, 13.599, 10.08, 10.221, 10.52, 12.03, 11.62, 10.03, 13.46, 11.48, 11.92, 13.812, 12.929, 12.01, 11.13, 11.54, 11.11, 11.33, 10.36, 10.81, 11.0, 11.86, 10.14, 12.281, 11.719, 10.62, 10.33, 12.841, 11.399, 10.44, 13.111, 10.139, 11.37, 13.17, 10.891, 12.579, 12.01, 13.111, 10.55, 10.439, 11.811, 12.509, 10.6, 11.25, 11.96, 13.921, 13.969, 11.261, 11.449, 12.17, 10.69, 13.23, 11.35, 10.18, 10.06, 11.279, 13.241, 12.311, 11.329, 10.99, 11.44, 10.08, 13.28, 10.47, 11.81, 16.43, 14.01, 12.48, 12.721, 10.389, 13.871, 10.25, 10.939, 10.48, 10.27, 10.15, 10.12, 11.811, 10.859, 11.79, 10.45, 11.23, 10.351, 11.906, 10.433, 10.711, 10.589, 12.431, 10.329, 11.55, 12.991, 12.319, 10.431, 11.35, 11.56, 10.75, 13.092, 11.169, 10.451, 10.449, 14.591, 13.0, 12.099, 11.58, 10.98, 13.991, 10.009, 12.721, 14.12, 11.17, 11.389, 13.981, 10.159, 10.721, 11.08, 11.77, 10.46, 13.829, 12.97, 10.88, 12.241, 12.75, 11.54, 10.989, 12.38, 12.01, 11.71, 12.59, 10.77, 12.93, 11.71, 12.17, 13.02, 11.951, 11.159, 10.58, 15.471, 13.17, 10.759, 12.809, 12.112, 12.099, 11.848, 11.07, 11.36, 12.55, 12.08, 12.64, 10.701, 10.719, 11.84, 10.52, 11.1, 11.259, 12.101, 12.14, 10.29, 10.971, 13.169, 13.351, 12.689, 12.09, 13.66, 11.76, 11.66, 11.228, 10.688, 12.71, 12.361, 11.56, 10.38, 12.17, 13.06, 13.81, 10.69, 15.15, 11.18, 12.15, 14.89, 10.15, 10.279, 10.561, 11.58, 11.85, 11.02, 12.57, 0.718], "stet": [[0, 10.03], [10.03, 20.65], [20.65, 33.15], [33.15, 44.65], [44.65, 58.82], [58.82, 70.89], [70.89, 82.81], [82.81, 94.24000000000001], [94.24000000000001, 105.641], [105.641, 117.90100000000001], [117.90100000000001, 129.651], [129.651, 141.02100000000002], [141.02100000000002, 155.221], [155.221, 166.311], [166.311, 179.001], [179.001, 191.921], [191.921, 202.59099999999998], [202.59099999999998, 215.81099999999998], [215.81099999999998, 226.85099999999997], [226.85099999999997, 239.79099999999997], [239.79099999999997, 251.67999999999998], [251.67999999999998, 264.541], [264.541, 276.201], [276.201, 286.86100000000005], [286.86100000000005, 298.261], [298.261, 310.62100000000004], [310.62100000000004, 323.071], [323.071, 334.771], [334.771, 346.95], [346.95, 358.31], [358.31, 369.26], [369.26, 380.46999999999997], [380.46999999999997, 392.96999999999997], [392.96999999999997, 403.84], [403.84, 414.54999999999995], [414.54999999999995, 427.55999999999995], [427.55999999999995, 438.3999999999999], [438.3999999999999, 450.6099999999999], [450.6099999999999, 463.4899999999999], [463.4899999999999, 474.6899999999999], [474.6899999999999, 484.8099999999999], [484.8099999999999, 497.6199999999999], [497.6199999999999, 509.45999999999987], [509.45999999999987, 520.2399999999999], [520.2399999999999, 530.3999999999999], [530.3999999999999, 540.6899999999998], [540.6899999999998, 551.3189999999998], [551.3189999999998, 564.3099999999998], [564.3099999999998, 574.7699999999999], [574.7699999999999, 585.2299999999999], [585.2299999999999, 598.8], [598.8, 609.9499999999999], [609.9499999999999, 621.7199999999999], [621.7199999999999, 633.6099999999999], [633.6099999999999, 645.9999999999999], [645.9999999999999, 657.6199999999999], [657.6199999999999, 670.56], [670.56, 681.93], [681.93, 694.06], [694.06, 705.3399999999999], [705.3399999999999, 717.4699999999999], [717.4699999999999, 729.4899999999999], [729.4899999999999, 740.0999999999999], [740.0999999999999, 752.06], [752.06, 765.15], [765.15, 778.6], [778.6, 791.3000000000001], [791.3000000000001, 802.7400000000001], [802.7400000000001, 813.0200000000001], [813.0200000000001, 823.2500000000001], [823.2500000000001, 833.6600000000001], [833.6600000000001, 848.5230000000001], [848.5230000000001, 859.7840000000001], [859.7840000000001, 871.4540000000001], [871.4540000000001, 885.1030000000001], [885.1030000000001, 900.7330000000001], [900.7330000000001, 914.5440000000001], [914.5440000000001, 926.1940000000001], [926.1940000000001, 936.993], [936.993, 947.5440000000001], [947.5440000000001, 962.1640000000001], [962.1640000000001, 973.8340000000001], [973.8340000000001, 987.1940000000001], [987.1940000000001, 997.3940000000001], [997.3940000000001, 1009.1740000000001], [1009.1740000000001, 1021.1740000000001], [1021.1740000000001, 1034.7730000000001], [1034.7730000000001, 1044.853], [1044.853, 1055.074], [1055.074, 1065.594], [1065.594, 1077.624], [1077.624, 1089.244], [1089.244, 1099.274], [1099.274, 1112.734], [1112.734, 1124.214], [1124.214, 1136.134], [1136.134, 1149.946], [1149.946, 1162.875], [1162.875, 1174.885], [1174.885, 1186.015], [1186.015, 1197.555], [1197.555, 1208.665], [1208.665, 1219.995], [1219.995, 1230.3549999999998], [1230.3549999999998, 1241.1649999999997], [1241.1649999999997, 1252.1649999999997], [1252.1649999999997, 1264.0249999999996], [1264.0249999999996, 1274.1649999999997], [1274.1649999999997, 1286.4459999999997], [1286.4459999999997, 1298.1649999999997], [1298.1649999999997, 1308.7849999999996], [1308.7849999999996, 1319.1149999999996], [1319.1149999999996, 1331.9559999999994], [1331.9559999999994, 1343.3549999999993], [1343.3549999999993, 1353.7949999999994], [1353.7949999999994, 1366.9059999999995], [1366.9059999999995, 1377.0449999999994], [1377.0449999999994, 1388.4149999999993], [1388.4149999999993, 1401.5849999999994], [1401.5849999999994, 1412.4759999999994], [1412.4759999999994, 1425.0549999999994], [1425.0549999999994, 1437.0649999999994], [1437.0649999999994, 1450.1759999999995], [1450.1759999999995, 1460.7259999999994], [1460.7259999999994, 1471.1649999999995], [1471.1649999999995, 1482.9759999999994], [1482.9759999999994, 1495.4849999999994], [1495.4849999999994, 1506.0849999999994], [1506.0849999999994, 1517.3349999999994], [1517.3349999999994, 1529.2949999999994], [1529.2949999999994, 1543.2159999999994], [1543.2159999999994, 1557.1849999999995], [1557.1849999999995, 1568.4459999999995], [1568.4459999999995, 1579.8949999999995], [1579.8949999999995, 1592.0649999999996], [1592.0649999999996, 1602.7549999999997], [1602.7549999999997, 1615.9849999999997], [1615.9849999999997, 1627.3349999999996], [1627.3349999999996, 1637.5149999999996], [1637.5149999999996, 1647.5749999999996], [1647.5749999999996, 1658.8539999999996], [1658.8539999999996, 1672.0949999999996], [1672.0949999999996, 1684.4059999999995], [1684.4059999999995, 1695.7349999999994], [1695.7349999999994, 1706.7249999999995], [1706.7249999999995, 1718.1649999999995], [1718.1649999999995, 1728.2449999999994], [1728.2449999999994, 1741.5249999999994], [1741.5249999999994, 1751.9949999999994], [1751.9949999999994, 1763.8049999999994], [1763.8049999999994, 1780.2349999999994], [1780.2349999999994, 1794.2449999999994], [1794.2449999999994, 1806.7249999999995], [1806.7249999999995, 1819.4459999999995], [1819.4459999999995, 1829.8349999999994], [1829.8349999999994, 1843.7059999999994], [1843.7059999999994, 1853.9559999999994], [1853.9559999999994, 1864.8949999999995], [1864.8949999999995, 1875.3749999999995], [1875.3749999999995, 1885.6449999999995], [1885.6449999999995, 1895.7949999999996], [1895.7949999999996, 1905.9149999999995], [1905.9149999999995, 1917.7259999999994], [1917.7259999999994, 1928.5849999999994], [1928.5849999999994, 1940.3749999999993], [1940.3749999999993, 1950.8249999999994], [1950.8249999999994, 1962.0549999999994], [1962.0549999999994, 1972.4059999999995], [1972.4059999999995, 1984.3119999999994], [1984.3119999999994, 1994.7449999999994], [1994.7449999999994, 2005.4559999999994], [2005.4559999999994, 2016.0449999999994], [2016.0449999999994, 2028.4759999999994], [2028.4759999999994, 2038.8049999999994], [2038.8049999999994, 2050.3549999999996], [2050.3549999999996, 2063.3459999999995], [2063.3459999999995, 2075.6649999999995], [2075.6649999999995, 2086.0959999999995], [2086.0959999999995, 2097.4459999999995], [2097.4459999999995, 2109.0059999999994], [2109.0059999999994, 2119.7559999999994], [2119.7559999999994, 2132.8479999999995], [2132.8479999999995, 2144.0169999999994], [2144.0169999999994, 2154.4679999999994], [2154.4679999999994, 2164.9169999999995], [2164.9169999999995, 2179.5079999999994], [2179.5079999999994, 2192.5079999999994], [2192.5079999999994, 2204.6069999999995], [2204.6069999999995, 2216.1869999999994], [2216.1869999999994, 2227.1669999999995], [2227.1669999999995, 2241.1579999999994], [2241.1579999999994, 2251.1669999999995], [2251.1669999999995, 2263.8879999999995], [2263.8879999999995, 2278.0079999999994], [2278.0079999999994, 2289.1779999999994], [2289.1779999999994, 2300.5669999999996], [2300.5669999999996, 2314.548], [2314.548, 2324.707], [2324.707, 2335.428], [2335.428, 2346.508], [2346.508, 2358.278], [2358.278, 2368.738], [2368.738, 2382.567], [2382.567, 2395.537], [2395.537, 2406.417], [2406.417, 2418.658], [2418.658, 2431.408], [2431.408, 2442.948], [2442.948, 2453.937], [2453.937, 2466.317], [2466.317, 2478.327], [2478.327, 2490.0370000000003], [2490.0370000000003, 2502.6270000000004], [2502.6270000000004, 2513.3970000000004], [2513.3970000000004, 2526.327], [2526.327, 2538.0370000000003], [2538.0370000000003, 2550.2070000000003], [2550.2070000000003, 2563.2270000000003], [2563.2270000000003, 2575.1780000000003], [2575.1780000000003, 2586.3370000000004], [2586.3370000000004, 2596.9170000000004], [2596.9170000000004, 2612.3880000000004], [2612.3880000000004, 2625.5580000000004], [2625.5580000000004, 2636.3170000000005], [2636.3170000000005, 2649.1260000000007], [2649.1260000000007, 2661.2380000000007], [2661.2380000000007, 2673.337000000001], [2673.337000000001, 2685.185000000001], [2685.185000000001, 2696.255000000001], [2696.255000000001, 2707.615000000001], [2707.615000000001, 2720.1650000000013], [2720.1650000000013, 2732.2450000000013], [2732.2450000000013, 2744.885000000001], [2744.885000000001, 2755.586000000001], [2755.586000000001, 2766.305000000001], [2766.305000000001, 2778.1450000000013], [2778.1450000000013, 2788.6650000000013], [2788.6650000000013, 2799.7650000000012], [2799.7650000000012, 2811.0240000000013], [2811.0240000000013, 2823.1250000000014], [2823.1250000000014, 2835.2650000000012], [2835.2650000000012, 2845.555000000001], [2845.555000000001, 2856.526000000001], [2856.526000000001, 2869.695000000001], [2869.695000000001, 2883.046000000001], [2883.046000000001, 2895.735000000001], [2895.735000000001, 2907.825000000001], [2907.825000000001, 2921.485000000001], [2921.485000000001, 2933.2450000000013], [2933.2450000000013, 2944.905000000001], [2944.905000000001, 2956.133000000001], [2956.133000000001, 2966.8210000000013], [2966.8210000000013, 2979.5310000000013], [2979.5310000000013, 2991.892000000001], [2991.892000000001, 3003.452000000001], [3003.452000000001, 3013.8320000000012], [3013.8320000000012, 3026.0020000000013], [3026.0020000000013, 3039.0620000000013], [3039.0620000000013, 3052.872000000001], [3052.872000000001, 3063.5620000000013], [3063.5620000000013, 3078.7120000000014], [3078.7120000000014, 3089.892000000001], [3089.892000000001, 3102.0420000000013], [3102.0420000000013, 3116.932000000001], [3116.932000000001, 3127.0820000000012], [3127.0820000000012, 3137.3610000000012], [3137.3610000000012, 3147.9220000000014], [3147.9220000000014, 3159.5020000000013], [3159.5020000000013, 3171.352000000001], [3171.352000000001, 3182.372000000001], [3182.372000000001, 3194.9420000000014], [3194.9420000000014, 3195.660000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [99, 342, 843, 1142, 1826, 2132, 2681, 2957, 3196]}
{"example_id": "mit153@@MITRES6_012S18_L26_300k", "text": [" In this final lecture, we will first  review the various properties of a nice Markov chain, which  ensures steady state behavior, and go over some of the notions  in more detail with some examples. ", "Providing some insights on how good an approximation  we have when we use steady state probabilities  to characterize the behavior of a Markov chain, which  has run for a long time, but not an infinite amount of time. ", "We will then consider a classical application  of Markov chains, which has to do with the design of a phone  system.  This is a famous problem, which was posed, analyzed, and solved ", "by a Danish engineer by the name Erlang.  It was more than 100 years ago when phones just  started to exist, but we will see  that this methodology remains relevant to design ", "similar systems in today's world.  We will then make use of all what  we have learned so far in order to calculate  some interesting short term behaviors of Markov  chains having more than one recurrent classes. ", "We will introduce the notion of absorbing states,  and we will show how to calculate  the probability of ending up in such a state,  as well as related quantities such as the expected time it ", "takes to do so.  As a classical example, we will look  at the gambler continuously playing  a simple game of chance, say a lottery,  until he either accumulates a given amount of money ", "or loses all his money.  Both of these states are absorbing.  What are their corresponding probabilities?  After this lecture, you will be able to answer such questions. ", "  So we have reached the final lecture  of this class which will also conclude  our study of discrete time, finite state space  Markov chains. ", "We will first review the steady-state behavior  of Markov chains.  Then, we are going to talk about a classical application  of Markov chains to analyze the design of a phone system. ", "And finally, we will see how we can calculate  some interesting quantities that have  to do with the behavior of Markov chains  over a finite time horizon as opposed to in the long run. ", " So let us first review the steady state  behavior of Markov chains.  Consider again the following example.  This chain has some recurrent states, some transient states, ", "and a single recurrent class.  So for example, state 9 is recurrent.  State 3 is recurrent.  State 5 is recurrent. ", "And why are they recurrent?  Because whenever you are in 9, no matter where you go,  there's always a way to come back.  You can go to 3 and come back, go 5 and come back. ", "And actually, this is a recurrent class.   And this is a recurrent class, because all  these recurrent states communicate between each other. ", "What about the other states-- well they are not recurrent.  So for example, state 1-- and once you are here,  there is a possibility that you go there,  and you will never come back.  So it can not be recurrent. ", "So it's transient.  What about 4?  4 also has the possibility at one point to go there.  And then from there, it will never come back.  So 4 is also transient.  As for 2, no matter where it goes, well, ", "it's going to reach or touch a transient state.  So by definition, it will be also transient.  So they have three transient states  and three recurrent states.  Also, this recurrent class is not periodic. ", "So it's aperiodic.  And why is it not periodic?  Well, here, there is a simple way to tell.  We have the existence of a self-transition probability. ", "And that's enough to show that this recurrent class is not  periodic.  So this is one of the nicest possible Markov  chains in the sense that they have the following property-- ", "the probability that you find yourself  at some particular state j.  At time n, when n is very large, it  converges to a steady-state value  that we denote by pi of j. ", "There are two aspects to this property.  First, the limit exists, so the probability of state j  does not fluctuate.  It settles to something in the long run. ", "And furthermore, that probability  is not affected by i.  Now, if we don't know where the chain started, and we  want to know the unconditional probability of being in state j ", "in the long run, when n is large,  then either we are given an initial distribution ", "over the states, or we can choose  any initial distribution.  For example, we can assume that all initial states are equally  likely-- or any other type of distributions. ", "And then you can condition over all the initial states,  use the total probability theorem,  and you're going to get the same answer, pi of j, in the limit.  Let's see how to do that. ", "So this is the summation of all i.  So you condition on that state i.  So it's Rij of n times the initial probability ", "distribution of your choosing.  So this is the total probability theorem.  Now, in the limits, when n goes to infinity,  this goes to pi of j, independent of i. ", "So you can take this expression, the limit,  and take it out of the summation.  And then you have the summation of-- probability of x0  equals 1. ", "These are probabilities, so they sum to 1.   So in the end, you have that converges to pi of j. ", "So the conditional probability, given the initial state,  is in the limit, the same as the unconditional probability ", "when n is large.  And in that sense, it tells us that x of n and x of 0  are approximately independent. ", "They become independent in the limit as n goes to infinity.  So if the Markov chain has run for a long time,  and you are asked the question, \"Where is the chain now,\" ", "then your answer should be, I don't know.  It's random.  But it's going to be in a particular j  with that particular probability, pi of j. ", "So in that sense, the steady-state probabilities  are valuable information.  So how do we compute them?  Well, for transient states, like these, they are 0. ", "So pi of 1 is 0.  Pi of 2 is 0.  And pi of 4 is 0.  And why is that?  Well, if your initial state were one of the states here, ", "the probability of being in here is 0, no matter what.  But even if you started here initially,  in one of these states, you might, for a while,  fluctuate and turn around like that. ", "But eventually, after a finite amount of time,  you will go to that class and never come back to 1.  So in the long run, the probability  of finding yourself in state 1 will be 0. ", "And this is the same for 2 and 4.  Now, how do we calculate these?  Well, for these states in the recurrent class,  we compute them by solving a linear system of equations, ", "which are called the balance equation-- these--  together with an extra condition.  The normalization equation here has  to be satisfied, because these are probabilities, ", "and they have to sum up to 1.  And we have seen that the system of m plus 1 equation  provides a unique solution to this kind of system ", "for the recurrent class.  So you would apply that to that recurrent class.  And in that example, you have three states,  so you would choose m equals 3 for that example. ", "And you would solve the system to get the pi j.  Now, what if we had multiple recurrent classes?  Consider this chain. ", "It is an expanded version of the previous one  with additional states.  Some of these are recurrent, and one is transient.  But now we have two recurrent classes. ", "And that was our 1 class, so class 1.  And now we have a second recurrent class, class 2. ", "So what happens in the long run, when  you have situations like that?  Well, in the long run, if you start from here,  you're going stay here. ", "And in some sense, the study of that recurrent class  is the same as the study of that recurrent class.  And in order to find the steady-state probabilities  of these states, assuming that you started in one of these, ", "will be exactly the same as before.  So you will use the same system, with m equals 3 here.  Now, if you had started here instead, ", "again, this is a recurrent class,  and you have m equals 2 states here.  And in order to find what is the steady-state probabilities  of these two states, you could use the same kind of result ", "here, but you apply it with m equals 2 in isolation.  So you just concentrate on that.  If, on the other hand, your Markov chain started from here, ", "for example, for that specific example,  you're guaranteed that the next transition you'll end up here.  And then you can do the same thing as before.  We still know that the steady-state probability of 8 ", "will be 0 and 0 and 0 and 0.  Now, what would happen if you started from here,  from one of these states?  Well again, for a while, you might ", "travel throughout this system here.  But eventually, you're going to move away from that.  And you will either go through a transition going  into that recurrent class via this transition ", "or via this transition.  And once you're in there, essentially, the chain  will remain there.  And so you do the same calculation as before.  And if, on the other hand, you transition away from that class ", "and arrived in this recurrent class,  then you would apply the result that you had here.  So in some sense, conditional on the fact that you left ", "the states and you arrived there--  in that conditional world, you can isolate yourself and really  solve the problem for that class-- and the same  from that class.  Now, of course, this raises the question, if I start from here, ", "how do I know whether I'm going to get here or here?  Well, we don't know.  It's random.  So we will be interested in calculating the probabilities ", "that eventually you end up here versus here.  And this is something that we are  going to do towards the end of today's lecture.  ", " As a warm-up, just to see how to use steady-state probabilities,  let us look at our familiar example.  This is a two-state Markov chain,  and we did write down the complete balance equations ", "for this chain, and found the steady-state probabilities  before.  Notice that we can find these by using the trick which  we introduced for birth and death processes. ", "You cut the chain along this line,  and argue that the frequency of transition of this type  has to be the same as the frequency of transition ", "of this type.  So if you have pi 1 here and pi 2 here,  what it means is pi 1 times 0.5, which represent ", "the frequency of these kind of transitions,  has to be equal to pi 2 times 0.2,  which is this kind of transition, plus pi 1 ", "plus pi 2, the normalization equation.  And by solving the system of equations,  you obtain the same thing as what we obtained before,  which is the steady-state probabilities of state 1 ", "and of state 2.  Let us now try to calculate some related quantities.  Suppose that you start at state 1,  and you want to calculate this particular probability. ", "So you start at state 1, and you want  to know what is the probability that next time you  will be in state 1, and 100 times step later, you are still  in state 1. ", "Now, the conditional probabilities  of two things happening is the conditional probability  of the first one happening, x1 equals  1, given x0 equals 1, and given that the first one happens, ", "the probability that the second one happened-- x100 equals 1,  given x1 equals 1, and x0 equals 1.  So what is this? ", "This first one is the transition probability from state 1  to state 1, p 1 1.  How about the second probability?  Because of the Markov property, that information is irrelevant, ", "and so that probability is r 1 1 in 99 steps.  Now, 99 is possibly a big number, ", "and so we approximate this quantity,  and we are going to use the steady-state probability  of state 1 for doing that.  And that gives us an approximation, p 1 1, ", "times pi of 1, which, then, is 0.5 times 2 over 7.  Now, how about this expression? ", "Given that you start in state 1, what  is the probability that at time step 100, you are in 1,  and time step 101 you are in 2. ", "By doing the same technique gives  the conditional probability of the first thing happening,  and then, given that thing happening,  the probability that the second one happen. ", "x101 equals 2, given x100 equals 1, and x0 equals 1.  And again, here what we have is r 1 1 of 100, ", "and times-- again, the Markov property  tells us that we can forget about this one--  and this is the probability transition from 1 to 2, pi 1 2. ", "And again, here, if n equals 100 is large enough,  we can approximate that by pi 1 times p 1 2. ", "And this, then, 2 over 7 times 0.5 again.  Finally, let's calculate this third expression, where,  again, we start at state 1, and now we are asking, ", "what is probability that after time step 100, you are in 1,  and 100 steps later, you are again in 1?  We use the same trick as before, this probability ", "that the first thing happened, and given that,  the probability of the second one happened.  ", "Again, this is r 1 1 of 100, and this one,  for the same reason as before, we can forget this term. ", "From 100 to 200, you have 100 time steps, r 1 1 of 100.  And 100 is big enough, so we're going ", "to approximate both by the same values,  and we get pi 1 square, which is 2 over 7 square.  ", "Now, in this calculation, we assume that n equals 99,  or n equals 100 were big enough-- big  enough so that the limit has taken effect. ", "But how do we know that our approximation is good?  In other words, is n equals 99 or 100 large enough?  ", "Well, this has something to do with the mixing time  scale of our Markov chain, and by mixing time scale,  I mean, how long does it take for the initial states  to be forgotten? ", "So how can you see that here?  Well, you can first try a simulation.   So using any of your favorite software, simulate. ", "If you calculate, and you look at, as a function of n,  and you draw r 1 1 of n, at n equals 0, this is 1. ", "n equals 1, then you have 5, et cetera.  At 1, this is going to be p 1 1, and p 1 1 was 0.5,  so already it's here.  So initially it was here, here. ", "And 2 over 7, so this is 0.5.  2 over 7 is here.  And what we know is that when n goes to infinity,  these things goes to 2 over 7. ", "And if you simulate, you will see that it goes very fast.  So with you, I'm just joining points,  and we will see that n equals 5 already. ", "You are very, very close to 2 over 7.  So you have really an exponential decrease here.   In fact, if you look at the simulation result, ", "and you look at n equals 5 already,  here you have two correct decimal already.  And for n equals 10, it's correct up to five decimals. ", " Or, if you do not want to have simulation, but simply  think in terms of order of magnitude-- so here ", "it would be another approach would  be order of magnitude type of argument--  and in order to do that, starting here,  on average, how many trials, or how many time steps ", "would it take in order for you to observe such a transition  here?  Well, you use the geometric, random variable,  and this is the amount of time, on average, ", "until you have success.  And it is 1 over the probability here,  so it takes an average two time steps to go from here to here.  And to go from here to here, it takes, on average, ", "1 over 0.2, which is about five time steps.  So as an order of magnitude, given  you started here in state 1, after, on average, ", "about 10 iterations, there will be some randomness.  There is a high likelihood, on average,  that you will go there and come here.  And then if you do n equals 100, which ", "is 10 times that, in terms of order of magnitude,  it looks like n is large enough.  So that would be a back to the envelope calculation.  Now, this kind of calculation is useful in general, not just ", "here.  So for example, let's do it again.  Assume that instead of 0.5 here, the probability that you had  was 0.999.  And maybe here, instead of 0.8, it was 0.998. ", "Now, in order to observe such a transition,  it will take, on average, since this number here  would become 0.001, it would take,  on average, about 1,000 time steps ", "in order to observe one such transition.  So if you look at time steps of that order,  it will not be enough if your chain were of this type.  After n equals 100, the likelihood ", "would be that you will still be here,  so the initial state, or the initial condition,  would matter still.  So you would take about 1,000 to get there,  and then here it would have 0.002. ", "That means that, on average, from here you  would take about 500 iterations before you observe  that for the first time, so the same order of magnitude.  So in order to get enough randomness here, ", "a good rule would be to multiply this 1,000 by 10.  So maybe with n equals 10,000, you  would feel confident enough, in that specific case, ", "in order to use this kind of approximation  that we have used here.  And finally, for those interested,  you can study that by theory.  And here there is an entire field ", "that try to study how fast a Markov chain converges  to steady state, and the so-called mixing time.  And it turns out that for these Markov chain, ", "you can say that the convergence, or the rate  of convergence, is of the order c  at the power n, where c is a number that is between 0 and 1. ", "And the closer c is to 1, the slower the convergence is.  And the closer c is to 0, the faster the convergence is.  And for example, here, for our initial case, ", "the c was 0.3, so that was the first case  for the second chain.  With these kind of probabilities, 0.99 and 0.998, ", "the c would be 0.997.    In this video, we will consider a classical application  of Markov chains, which has to do with the design of a phone ", "system.  This is a classical problem, which was posed, analyzed,  and solved by a Danish engineer by the name of Erlang.  ", "It was more than 100 years ago when phones just  started to exist, but the technique  remains relevant today to design systems of a similar nature. ", "As for Erlang, he was trying to figure out  how to design the capacity of a phone system.  That is, how many lines should we  set up for a group of people, say, in a village, ", "to be able to communicate to the outside world?  So here is a cartoon of the problem, where  these are the phone lines, and we  need to decide how many of these lines to set up, let's say, ", "B. How to do that?  Well, we don't want B to be too large, much more than needed,  because too many lines would be expensive. ", "On the other hand, we want to have enough lines  so that if a reasonable number of people place phone  calls during the same period, they  will be able to talk and not get busy signals. ", "So if B is 10 and 15 people want to talk at the same time,  then 5 would get a busy signal, and that's  probably not what you want as an acceptable level of service. ", "So we would like B to be just large enough so that there  is a high probability that no one is  going to get a busy signal. ", "So how do we go about modeling a situation like this?  Well, we need two pieces of information,  one describing how phone calls get  initiated, and once a phone call gets started, how long does it ", "take until it ends?  We're going to make some very simple but somewhat plausible  assumptions.  We will assume that phone calls originate as a Poisson process. ", "We will assume that out of that population,  there is no coordination.  At completely random times, people pick up their phone  independent of each other's.  Also, there is nothing special about the various times, ", "and different times are independent.  So a Poisson model is a reasonable way  of modeling a situation under these assumptions.  We also assume that the rate lambda ", "is known or has been estimated.  Now, it might be the case that during the night,  the rate would be different than during the day.  In that case, you would design the system  to meet the largest rate of the two. ", "For the phone calls themselves, we  are going to assume that the duration of a phone call  is a random variable that has an exponential distribution  with a certain parameter mu. ", "So 1/mu is the mean duration of a phone call.  Duration of phone calls are independent between each other.  So here, again, we assume that the parameter mu ", "has been estimated.  For example, the mean duration 1/mu could be 3 minutes.  Now, is the exponential assumption a good assumption? ", "So here is the PDF of an exponential random variable  with parameter 1 over three.  That means that the mean duration is about three minutes  here. ", "So if you look at this PDF, it means  that most phone calls will be kind of short.  There is going to be a fraction of phone calls  that are going to be larger, and then ", "a very small fraction of phone calls  that are going to be even larger.  So it sounds reasonable.  However, it's not exactly realistic in some situations. ", "Typically, phone calls that last a very short time are not  that common as opposed to what an exponential distribution  would indicate here.  ", "So some other distribution might be better, like this one,  for example, here, where during a very small period of time  the wait corresponding to this very short period of time ", "are kind of small as well.  There are many distributions of this type.  I've just provided here one simple example.  This one is the Erlang of parameter 2 and 2/3. ", "What it means is that it is the sum of two  independent exponential random variables,  and each one of them of parameter 2/3.  So the mean duration associated with this distribution ", "is also 3 minutes.  So this might fit better some practical situation.  But here we will keep the simple assumption associated  with an exponential distribution. ", "All right.  So let's try now to come up with the models  that we can decide how many lines, B, do we want to set up.  The Poisson process run in continuous time. ", "And call durations being exponential random variables  are also continuous random variables.  So it seems that we are in a continuous time universe.  Here is a cartoon of the evolution of the system. ", "So here I have in blue when phone calls get initiated.  So this is called 1, a second one, a third, a fourth,  and a fifth one. ", "And also, I have represented here the duration of the call.  So call 1 lasted that long, call 2 lasted long  until here, 3 up to here, 4 here, et cetera. ", "So when you look at this kind of system in that way,  and you run through time in a continuous manner,  and here you have 0 line busy.  You have 1 line used, 0, 1, then 2 becomes busy, ", "3, 2, 1, and 0, and so on and so forth.  Also note that if I look at that system at any time t,  because of our assumptions of a Poisson process ", "and an exponential duration for phone calls,  and a memoryless property associated  with these processes, it means that the past really  has no information about the future. ", "And so, in some sense, the Markov property is valid.  So it looks like a continuous time Markov  process would be needed here.  And this is indeed an option, but we have not ", "studied those in this class.  So we will discretize time instead  and work with a Markov chain.  We are discretizing time in the familiar way, the way we did it ", "when we studied the Poisson process.  We are going to take the time axis  and split it into little discrete time  slots, each of duration delta. ", "And delta is supposed to be a very, very small number.  So now under this discretization,  by the definition of the Poisson process ", "the probability that we'll see 1 arrival during any time  slots of duration delta will be lambda times delta.  ", "Also, if at any time, like here we have 1 simple call active,  the probability that this call will end during any future time  slot of duration delta is mu delta, like here. ", " Indeed, as we have seen in Unit 9,  an exponential random variable can  be thought of as representing the time ", "until the first arrival of a Poisson process with rate mu.  What if you have i busy calls at the same time?  Then the probability of having 1 call ending ", "in a time slot of duration delta will be i mu delta.  Like, for example here, this one could correspond to something  as 2 mu delta. ", "Indeed, each of the Poisson processes associated  with these calls with rate mu can  be combined into a merged Poisson process of rate i times ", "mu.  And a call completion will correspond to the time  until the first arrival of this merged Poisson process.  For example, if I go back here in my situation here at time t, ", "there were still 3 phone calls active.  And I represent here the call number 2, call number 3,  and call number 4 and their remaining duration.  And if you look at these and you combine these 3 ", "associated Poisson processes into 1,  you get a merged Poisson process.  And if you look now at the time arrival of the first event,  which would correspond to here, it ", "would be an exponential random variable.  The duration here would correspond  to an exponential random variable of parameter 3 mu.  So in that case, if you go back to that representation here, ", "the probability of a departure would  be 3 times mu times delta.  OK?  So let us continue with our discrete time  approximation of our system.  Again, we have the village, and the lines, the B ", "that we would like to decide.  We have discretized the time steps.  We have made some approximation.  And we know that during any of these time slots here, ", "the probability that you would get a new call  is about lambda times delta.  Lambda is the rate of the Poisson process.  And given that you have i calls, the probability ", "that one of these calls ends will be i times mu times delta.  OK.  If we want to propose a Markov chain model for this system,  we need to specify the states and the transition ", "probabilities.  What are the states of the system?  If you look at the system at any particular time,  the minimum relevant information to collect  would be the number of busy lines, ", "something like these 2 lines are busy, or all of them are busy,  or none of them are used.  Now, because of our assumptions, again, about the Poisson ", "process arrivals and exponential duration  of calls and their memoryless property,  that information is enough to fully describe  the state of our system in such a way ", "that we get a Markov chain.  So the states are numbers from 0 to B. 0 corresponds  to a state in which all the phone lines are free. ", "No one is talking.  B corresponds to a case where all the phone lines are busy.  And then you've got states in between.  Now, let us look at the transition probabilities. ", "Suppose that right now, you are in that state.  What can happen next?  Well, a new phone call gets placed, in which case  the state moves up by 1. ", "Or an existing call terminates, in which case  the state goes down by 1.  Or none of the two happens, in which case  the state stays the same. ", "Well, it is also possible that a phone call gets terminated,  and a new phone call gets placed in the same time period.  But when the duration of the time slots  are very, very small, the delta here, ", "this event is going to have a negligible probability,  order of delta squared.  So we ignore it, as we ignore the fact ", "that more than one new call can happen,  or more than one call can be terminated during a given slot.  So what is the probability of an upward transition? ", "That's the probability that the Poisson process has an arrival  during the slots of duration delta.  And as we have seen, this is lambda times delta.  So each one of these upward transitions ", "has the same probability of lambda times delta.   How about phone call terminations?  If we have i phone calls that are currently active, ", "the probability that one of them terminates becomes i mu delta.  So here it would be mu delta, and here B mu delta. ", "Now, let us analyze this chain.  It has the birth and death form that we  discussed in the previous lecture.  So instead of writing down the balance equation  in a general form, we think in terms ", "of frequency of transitions across some particular cut  in this diagram, so for example here.   The frequency with which transition of this kind ", "happen or are observed has to be the same  as the frequency of transition of this kind.  The frequency of transition of this type  will be, if you look at pi i here and pi of i minus 1 here, ", "this transition here will happen with pi i times i mu delta.  And the transition of this type here ", "will be pi i minus 1 times lambda times delta.  And the frequency of these transitions  have to be the same as the frequency of these transitions, ", "so we have that equals that.  And then we can cancel the delta in both,  and we are left with this equation here.  ", "So this equation expresses pi of i in terms of pi of i minus 1.  So if we knew pi of 0, then we can calculate pi of 1, ", "and then in turn calculate pi of 2, and so on and so forth.  And the general formula that comes out of this,  after some algebra, is given by this expression, ", "which involves pi of 0.   Now, what is pi 0?  Well, we can find it by using the normalization equation, ", "the summation of pi i equals 1.  You use this normalization, replace each pi  i by their quantities as a function of pi 0, ", "and then we obtain this equation for pi 0.  So here, again, we use that normalization.  We replaced pi i by their value. ", "We sum to 1, and we obtain pi of 0.  And then in turn, from this pi of 0,  you can replace the pi of 0 in pi of i,  and you obtain a pi of i as a function of B, lambda, and mu. ", "So if we know B and lambda and mu,  we can set up this Markov chain, and we can calculate pi 0,  and then pi of i for all i's. ", "We can then answer a question like this.  After the chain has run for a long time,  how likely is it that at any given random time,  you will find the system with i busy lines? ", "Well, it will be pi of i.  And also, we can interpret the steady-state probabilities  as frequencies.  So once I found pi of i, it also tells me ", "what fraction of the time I will have i busy lines.  And you can answer that question for every possible i.  Now, we were initially interested in the probability ", "that the entire system is busy at any point in time,  in other words, in that state here.  So if a new phone call gets placed,  it is going to find the system in a random state. ", "That random state is described in steady-state  by the probability pi's.  And the probability that the entire system is busy  is going to be given by pi of B, and this is the probability ", "that we would like to be small in a well-engineered system.  So again, given lambda, mu, the design question  is to find B so that this probability is small. ", "Could we figure out a good value for B by doing  a back-of-the-envelope calculation?  Well, let's suppose that lambda is 30 calls per minute. ", "And let's assume that mu is 1/3 so  that the mean duration is 3 minutes.  So on average, a call lasts for 3 minutes, ", "and you get 30 calls on average per minute.  Then how many calls would be active on the average?  If a call lasted exactly 1 minute, then at any time  you would have 30 calls being active. ", "Now, a call lasts, on the average, for 3 minutes.  So by thinking in terms of averages,  you would expect that, at any time,  there would be about 90 calls that are active, 3 times 30. ", "And if 90 calls are active on the average,  you could say, OK, I'm going to set up my B to be 90.  But that's not very good, because if the average number ", "of phone calls that want to happen is, on the average, 90,  sometimes you are going to have 85,  and sometimes you'll get 95.  And to be sure that the phone calls will go through, ", "you probably want to choose your B  to be a number a little larger than 90.  How much larger than 90?  Well, this is a question that you can answer numerically. ", "By looking at these formulas, if you  decide that your acceptable level of service, pi of B,  has to be less than 1%, then you will ", "find that the B that you need to design is to be at least 106.  So you actually need some margin to protect against a situation ", "if suddenly, by chance, more people  want to talk than on an average day.  And if you want to have a good guarantee  that an incoming person will have a very small probability  of finding a busy system, here 1%, ", "then you will need about 106 phone lines.  So that's the calculation and the argument  that Erlang went through a long time ago.  It's actually interesting that Erlang did this calculation ", "before Markov chains were invented.    In this video, we are going to calculate  interesting quantities that have to do  with the short-term behavior of Markov chains as opposed ", "to those dealing with long-term steady-state behaviors.  But first, let us introduce the notion of absorbing state.  As indicated in this definition, an absorbing state is ", "a recurrent state from which you cannot escape once you get  to it.  The transition probabilities from k to k is 1.  So in some sense, you get absorbed by the state. ", "For example, consider this transition probability graph.  States 4 and 5 are both absorbing states.  Indeed, when you get to 4, you stay in 4. ", "Or when you get to 5, you stay in 5.  State 1, 2, and 3 are transient states.  So if the Markov chain initially started in 4, then ", "it will stay in 4 forever.  If it started in 5, it's going to stay in 5 forever.  But what if the Markov chain started in either 1, 2, or 3? ", "Eventually, after some moving around,  you will either make that transition to state 4  and get absorbed by it, or you're  going to do that transition and get to 5 ", "and get absorbed by the state 5.  So the question is, are you going to end up in 4,  or are you going to end up in 5?  Well, we don't know for sure. ", "These correspond to random events.  But can we say anything about their probabilities?  Well, let us try to calculate the probability that you end up  in 4 as an example. ", "First, it seems plausible that this probability of ending in 4  will depend on where you started.  If you start in 2, you probably have more chances ", "of getting to 4 than if you started from 3.  Because if you start from 2, at the next step  you have immediately the chance of getting to 4.  But if you start from 3, there is some chance ", "that you will go to 5 and never go to 4,  or you will have to go through 2 in order to get to 4 anyway.  So it looks like the probability of reaching 4, ", "given you started from 2, will be bigger  than if you started from 3.  Now, from 1, it's unclear.  Let us be systematic then.  Let us consider all possible probabilities to end up ", "in 4 depending on the initial state.  So let us ask this question, what  is the probability, a of i, that the chain eventually  settles in 4 given that it started in i? ", "So in other words, a of i is the probability  that you end up in 4 given that you started in i.  Now, the answer to that question is very easy for some cases. ", "If you start in 4, the probability  that you end up in 4 is 1.  And if you start in 5, the probability  that you end up in 4 is 0. ", "There is no way that you can go from 5 to 4.  What about the other cases?  Well, it's not so clear.  Let us consider, for example, that you started from 2. ", "What could happen next?  Well, from state 2, let's build a tree.  You can either, with a probability 0.2, go to 4.  Or with a probability 0.8, you will go to 1. ", "Now, in the first case, you're done.  You reach 4.  But in the second case, you arrive in 1.  And what happens next?  You don't know.  But what you know is that from that state, ", "either eventually you go and get trapped in 5,  or you go and eventually get trapped in 4.  What are the probabilities of these events? ", "Well, we don't know.  But one of them has been defined before.  This represents the probability of ending up  in 4 given that you start in 1, and that has been defined here. ", "This is nothing else than a1.  So the overall probability of interest for us,  which is a of 2, using the total probability theorem, ", "you can enumerate all options.  It's with probability 0.2 you will go to 4.  And then the probability of going  to 4 given that you started in 4 is a4 plus 0.8 times a1. ", "Now, a of 4 is, of course, 1, as we have discussed before.  So we get the relation between a2 and a of 1.  Now, of course, you can do the same thing for the other state. ", "For example, if you started from 1, what can happen next?  Well, you can go to 2 with a probability 0.6.  Once you're in 2, you're asking yourself, ", "what is the probability of reaching 4?  Well, by definition, it's a2.  Or from 1, you go to 3 with a probability 0.4. ", "And given that you have done that,  what is the probability that eventually you reach 4?  It's a3.  If initially you start with a3, what can happen next?  Again, with probability 0.3, you will end up in state 2. ", "And there, a of 2 is the probability of interest.  Or with a probability 0.5, you go to state 1.  And in that case, you get a of 1. ", "And finally, with a probability 0.2, you get trapped in 5.  All right?  You can write if you want, but 0.2, and you get trapped in 5.  But we know that a of 5 is 0, so this term will disappear. ", "So in the end, you get a system here.  After you replace a4 by 1 and a5 by 0,  you get a system of three linear equations with three unknown. ", "And it is easy to solve.  I will not do that.  You can do it yourself.  But here are the results.  You will get a of 1 equals 18/28, a of 2 will be 20/28, ", "and a of 3 will be 15/28.   Now I expressed them so that we can compare them easily.  And as a sanity check, you can verify ", "that indeed the probability starting from 2  will be larger than the probability starting from 3.  And it turns out that a of 1 will  be in between the other two. ", "So these probabilities are consistent  with our previous intuitions.  As an aside, note that you could have written a system of five  linear equations with five unknown, the five ", "unknown corresponding to the five states possible.  In fact, we had our five equations here.  Here was one, another one here, and 1, 2, 3, so 3 plus 2, 5. ", "Of course, this one was easy.  It was a4 equals 1 and a5 equals 0 that you can replace then  there, and you get a limited or restricted or smaller system ", "of three equations with three unknown.  Now, what if you had been interested instead in finding  the probability b of i that the chain eventually ", "settles in 5 given you started in i.  How to do that?  Well, you can repeat exactly all this calculation  that we have done, but looking at 5 as the state of interest. ", "But of course, you don't have to do this.  For any state i, given that you started in i,  you will eventually with probability 1  end up in either 4 or 5. ", "So you have a of i plus b of i equals 1 for all possible i.  So once you have calculated a1, a2, a3, a4, and a5, ", "you get b1, b2, b3, b4, and b5 by using this formula.  To sum up, in general, the calculation ", "of the probabilities to reach a given absorbing state  s starting from any state i of a general Markov  chain with m states-- so let's assume ", "that you have m states-- will be the unique solution of a system  of m equations with m unknowns, with the additional conditions ", "that a of s equals 1 and a of s prime  equals 0 for the other absorbing states. ", " Now, going back to the following question  that we posed at the end of the review ", "on steady-state behavior, we had this diagram,  and we wanted to know which recurrent class this chain  would end up if it started in one of these transient states. ", "Well, we can now answer this question.  For the purpose of this calculation,  the trick is simply to think of a recurrent class as one  big absorbing state and go through the calculation ", "as we have done here.  So think about this class, for example, as being one  big state, an absorbing state.  And now forget about the inside and calculate the probability ", "that you end up in this class as the probability of reaching  this absorbing state given that you started in 1, 2, and 4,  and you do the same kind of calculation. ", "  In this video, let us look at a second quantity of interest  that has to do with absorbing states.  Now that we know how to calculate  the probability of getting to a given absorbing state, ", "we would like to know how long it would take to get to it.  Let us first deal with that question  when we have only one absorbing state.  Let us consider the following Markov chain, which ", "is a little simpler than the one that we  had in the previous video.  We have transient states.  One, two, and three are transient states.  And we have one recurrent state, four. ", "And that recurrent state four is an absorbing state,  because once you get to it you stay there forever.  So in this simple example, the absorption probability to four ", "is trivially one.  No matter where you start, with probability one  you're guaranteed that eventually you will reach four.  But the question of interest is to know ", "how long would it take to get to four.  In other words, how many transitions  would you have to do until you reach four?  Of course we don't know.  It is a random variable. ", "In fact, it's more than one random variable.  It would depend probably on where you started.  Starting from two, one, or three, or four, ", "would lead to different random variables.  We are going to be interested in looking  at their expectation, or the expected value  of these random variables.  More precisely, let us define exactly what we want to do, ", "which is to find the expected number of transitions--  that we're going to call him Mu of i--  until reaching four, which is our absorbing state,  given that the initial state is i, one of these four states. ", "First as a warm up, let's do some quick calculation.  If you didn't have this part here, and instead  we were looking just at this portion here. ", "Make this one disappear like this,  and replace it by a loop of probability 0.8.  So now if you start from state two, with probability 0.2 ", "you will go to four, or with probability 0.8  you will remain in two.  And now you ask yourself, what is the number  of trials you have to do until you reach four? ", "Well we know what it is.  This is a geometric random variable  with the probability of success, which  is a success being going to four, of 0.2.  So the expected number of trials, starting from two, ", "that you will have to go through until you reach four,  will be 1 over this probability.  So 1/0.2, which is 5. ", "Now that we have done this quick calculation,  it should be clear that if we go back to the previous Markov  chain that we had here, the expected time, Mu 2,  would probably be bigger than 5. ", "Since from two, not only you have the probability  of going to four, but you might have  some chance of traveling there.  So probably the number of times until you reach four  would be bigger than 5. ", "Let's see.  Well, first of all, if you start at four, the expected  number of transitions until reaching four  would obviously be zero.  So here, for i equals 4, you indeed get zero. ", "What about for the others?  Well again, this is what we would like to calculate.  How are we going to do that?  Well, the argument is going to be  of the same nature as the one that we used before. ", "We are going to think in terms of tree,  and consider possible options starting from a given state.  So let's do this calculation from two.  So you are in two, and we're going to build that tree here. ", "So you are in state two.  What could happen next?  Well, you can either transition to four  with the probability 0.2. ", "Or with probability 0.8, you end up in one.  And you have done one transition here.  So plus one transition.  So you are interested in calculating Mu 2. ", "After one transition you either end up in four, in that case  you stop, you're done.  In other words the resulting value  here would be Mu 4, which we know is 0. ", " Or you are in one.  And now, given that you are in one,  you want to find the expected number of transitions  until reaching four, which is exactly defined here. ", "So here what you have is Mu 1.  And now you can use the total expectation theorem  to put all of these things together.  What it means is that Mu 2 will be 1, ", "and you have one transition.  And then after you do that transition with probability  0.2, you know that you're going to be in four.  And the expected value then will be ", "Mu 4 plus 0.8, which is the probability that  end up in state one.  And conditional on that, the remaining expected iterations ", "until reaching four will be Mu 1.  Now this one is of course 0, so what you end up with  is 1 plus 0.8 Mu 1. ", "So you get a relation between Mu 2 and Mu 1.   Now you can do the same thing if you start from one  or start from three. ", "So let's do it again from one.  So you're interested in one.  After one transition, so plus one, what happened?  Well, with the probability 0.6, you end up in two. ", "And with the probability 0.4, you end up in three.  And from three, if you start in state three,  after one transition what happened? ", "Well, with the probability 0.5 you would end up in state one.  And then the expected number of transitions from state one ", "until reaching four will be Mu 1.  Or with probability 0.5, you end up in two.  So again here, if you look at these three here, ", "this is a system of three equations,  three linear equations with three unknowns.  It has a unique solution.  I will let you do the calculation,  let me give you the result. ", "What you obtain is Mu 1 will be 110/8.  And the reason I'm writing it this way  is so that we can compare them. ", "Mu 2 will be 96/8, which is 12.  And Mu 3 is 111/8.  ", "So here again, a quick sanity check,  the number that we get here, 12, is indeed bigger than the five  that we have obtained when we restricted ourselves  to this set. ", "So we do have Mu 2 greater than 5.  Now as the relative value between Mu 1, Mu 2, and Mu 3,  it sort of makes sense. ", "Mu 2, the state two, is the one closest to four,  it is the one actually linked to four.  So in some sense, the expected number  of transitions to reach four will always ", "be the smallest one, because starting from the other states,  you will have to go to two before going to four.  And in general, if you have a general Markov chain ", "with transient states and one absorbing state,  and you're asking yourself, what is the expected time  to absorption to that unique absorbing state, ", "it will be the unique solution from the system of equations  given here.  Where the pij are the transition probabilities of your Markov ", "chain.  Now we have seen how to solve this problem when  we have one unique absorbing state.  What happens if you have more than one absorbing state? ", "Like for example, in this case.  Well, first of all, a quick note.  You realize here that you have one, two, and three, three  transition states. ", "And indeed here, you have four as an absorbing state,  it's a recurrent state, and once you get to it  you stay there forever.  And five is also a recurrent state, and once you get to five ", "you stay there forever.  So four and five are both absorbing states.  And in a previous video, we had seen  how to calculate the probability of ending up in four, ", "as opposed to ending up in five.  What we know is that the probability of ending up  in four plus the probability of ending up in five will be 1.  But since the probability of ending up in four is not 1, ", "trying to find the expected number of steps  until you reach four specifically  does not make much sense.  That expectation of that random variable is a random variable, ", "but that expectation will be infinity.  Why?  Because there is a positive probability  that you will end up in five.  And if you end up in five, once you get there,  the number of steps to go to four will be infinity. ", "So it makes more sense to think about what  is the expected time to any absorbing state.  So to either four or five.  Now If you're interested in that quantity, ", "one trick in order to solve that problem using the technique  that we have seen so far, is to combine four and five into one  mega state, call it whatever, six. ", "Right?  And six is a combination of four and five.  It's a big absorbing state.  And once you're in six, you stay in six.  And now you just have to define exactly what ", "is the probability of transition from one, two,  and three, to that mega state.  Well here from two, you had, originally, two arcs.  You're going to combine these two into one arc, ", "and you're going to sum these probabilities.  So you had 0.3 and 0.2.  You put in here 0.5.  And on this arc you had only one arc, so you maintain that arc. ", "And you have that probability that you had,  which I believe was 0.2.  Now you go back, if you look at the situation now, ", "it's very close to the one that we have here.  All right?  See this four that you have here is the six.  Now of course, you have another arc here like that,  but that's fine.  You can stay add the arc here and put it as 0.2. ", "And then you reduce this one to 0.3  to make it square with here.  But the idea on how to solve that is identical to this one.  You would have to change a little bit of this,  but this is the same technique. ", "So in the end, we have seen a technique  to find the expected time to absorptions whenever  you have absorbing states in a given Markov chain.  ", " In this video, we continue our exploration  of quantities of interest associated  with the short-term behavior of Markov chain.  This time, we suppose that we have a Markov chain composed ", "of a single recurrent class, such as this one.  Here, we have our recurrent class.  And these are transient states.  We also assume that we're interested ", "in a specific recurrent state-- let's say 9.  So this is my state s.  And we will assume that the Markov chain starts  from a given initial state, state i, ", "and assume that i is 1.  Now the question we ask is, given that you started in 1,  how long is it going to take to reach 9 for the first time? ", "We know this is a recurrent class,  so we know that the Markov chain eventually  will come to that class and circulate here.  So you know that the Markov chain will get to that state 9. ", "You are interested in knowing when  it does so for the first time.  Of course, we don't know for sure.  This is random.  It is a random variable.  And let's try to calculate the expected value ", "of this random variable.  More precisely, this is what we would like to do.  We would like to find the mean first passage time from i  to s, from any starting state i. ", "Here, we're going to illustrate that with 1.  And mathematically, this is what we have here.  So here again, what you have is that the Markov chain  started in state i, at time 0. ", "And now you are looking at this set here.  And the set records all the time n such  that your Markov chain, Xn, is in the state s of interest. ", "So out of this set, you're looking at the minimum, n,  that verifies that.  So this is going to be a random variable.  And you take the expected value of that. ", "And this is what we call the mean first passage time from i  to s.  Again, this is the expected number of steps  in order to get from i to s for the first time. ", "So how do we go about calculating such a quantity?  Well, let us think a little bit.  We are looking at the event that you  will visit 9 from 1 for the first time. ", "What happened after visiting 9 is  of no relevance in our calculation.  In other words, our calculation will never involve this arc  and will not involve this arc either. ", "Because in order for the Markov chain  to traverse this arc or this one,  it would have to visit 9 first.  So what it means is that we can forget about this arc, ", "and we can forget about this arc-- in a sense,  that they don't matter in the calculation  of the mean first passage time to s.  Now, removing these arcs entirely ", "means that you would have to increase  the probability of that self transition from 0.2 to 1.  So what do you get?  Well, you get this following graph. ", "We have removed these arcs, and we  have increased the probability 0.2 here to 1.  And again, we have argued that calculating  the mean first passage time from i to s in this graph ", "is the same as doing the same thing for this graph.  But here, we have a very special structure.  We have only one recurrent state left, which is state 9. ", "And that state is an absorbing state.  All the other state-- this one was  transient, transient, transient.  This one becomes a transient state.  And this one is also a transient state in this new transition ", "probability diagram.  So we get a situation where we have one single absorbing  state, and we are interested in calculating  the probability starting from i to reach that absorbing state ", "and also the number of steps it takes  to do that, which is what we did in the previous video.  So let us repeat what we had seen before. ", "So this is going to be the unique solution to this system.  t of s equals 0, of course.  Since you start from s, you are in s.  And so the amount of time it takes to get to s is 0. ", "And otherwise, for all the other states that are not s,  this is the resulting system of equation that we have.  And the unique solution of this system  gives you the result of finding the expected amount of time ", "to go to the absorbing state s.  So using this simple trick, we've  been able to use the previous calculation  to calculate something else. ", "Let us consider a related question, which  we called the mean recurrence time of s.  Here, let's go back to the original graph.  And this is our state s. ", "And now the question is the following--  given that you are in s, what is the amount of time  it will take for the Markov chain  to return to s for the first time? ", "So for this question, the Markov chain is currently in 9.  And you ask yourself, how long is it  going to take, once you leave 9, to return to 9? ", "Here again, we don't know for sure.  It's a random variable.  And we are interested in the expectation  of that random variable-- in other words,  in the expected number of steps it takes in order ", "to get back to 9 once you are in 9.  And this is what we mean by the mean recurrence time of s.  And mathematically, this is what it is.  It is almost the same formula as the one that you had here, ", "except that here you have n greater than/equal  to 1 as opposed to n greater than/equal to 0.  It simply means that you're not interested in the first time ", "that you're in s, because you start from s.  So you want to have n greater than or equal to 1. n  equals 0 would not work. ts star would have been 0.  So how would you solve that problem? ", "Well, here again, you use the same trick that we used before.  And think in terms of tree.  Let's look at the Markov chain in state 9.  What can happen next? ", "From 9, it can go to 3 or it can go to 5.  ", "Or it can jump on itself.  So this is with a probability 0.2.  This is with a probability 0.2.  And this is with a probability of 0.6. ", "And now, after you make one transmission--  so let's-- you are in 3 now-- what is the time to get to 9?  Well, it's exactly t3-- where the t ", "is, the solution here of that previous system.  What about from 5?  t5.  And what about from 9?  Well, t9. ", "And t9 was 0.  So from that tree, what you have is  t9 star will be 0.2 times t3 plus 0.6 times t5 plus 0.2 ", "times t9 plus, of course, 1, because you  have done one transition.  Where, again, this value of t3, t5, and t9 are the ones ", "corresponding to this solution here.  So of course, t9 is 0.  So what we have shown here, that in general,  this is actually what you would have. ", "And this is exactly what we have written here.  ts star is 1 plus the summation of psj of t of j, where t of j ", "is the solution to this system.  So again, you started from 9.  You have to do a transition first.  You can do a transition unto yourself. ", "You can go to 3 or you can go to 6.  After that transition, which stands for the number  1 here, what happens is you're trying  to find the solution to this system, which ", "is the mean first passage time, from the current state where  you are, to 9.  And then when you put these two things together,  ", "In this last video, we illustrate  how to use the techniques we have recently  learned in order to answer some questions  about the following classical problem-- ", "consider a gambler putting a bet of $1  in a game that has a pay off of one dollar if she wins.  We assume that this is a fair game, ", "so the probability of winning $1 on each play of the game  is one-half.  And so the probability of losing the bet is also one-half.  Suppose that she starts with i dollars ", "and continues to play the game until either she  reaches a goal of n dollars, or she has no money left, whatever  comes first. ", "Let us consider a first question, which  is the following-- what is the probability that she ends up  with having her goal of n dollars? ", "Now, how to go about solving this problem?  Can we think of a Markov chain representation  for this problem?  But in that case, what would be good choices ", "for the definition of the states?  Let us think.  At any point in time, the only relevant information  is the amount of money the gambler has available. ", "How she got to that amount in the past is irrelevant.  And if this amount is neither zero nor n,  then she will play again. ", "And the next state will be a number  which will be increased or decreased by one unit,  depending on winning or losing the next bet.  So we can represent the possible evolution of this game ", "with the following probability transition graph.  So we have n plus 1 states.  This is the state where she loses all her money.  This is the state where she has i amount of money ", "before the next betting.  And here, this is the state n where she reaches her goal  and she can leave.  In terms of the transition probability,  assuming that you are at a given time in that state, ", "that means that you have i money in your pocket,  and you play the next bet.  With a probability one-half, you will gain or win.  And so your amount of money is i plus 1. ", "Or you lose and your money is i minus 1.  And you keep repeating until you reach either n or zero.  And then you stop. ", "So this is a Markov chain, and that state 0 and that state n  are absorbing states.  Once you reach them, you stay there forever. ", "So what this question is asking is the probability a  of i of-- starting from i, what is the probability that you  will end up in that absorbing state? ", "And we have done this calculation previously.  So let us repeat the technique very briefly.  Clearly here, if you start with 0 dollars, ", "you will never reach that.  So it's going to be 0.  On the other hand, if you start with your desired goal,  you don't play anymore.  So your probability is 1. ", "Now of course, what is of interest  is if i is strictly between 0 and n.  And now the question is how to calculate that probability.  And we have seen that the way to do ", "that is to look at the situation,  and say let's assume that you are in that state i.  And what happens next?  Well with a probability 0.5, you will move to that state. ", "And now you are in that level with i plus 1 amount of money.  And what is the probability that, given that you're here,  you're going to end up in n?  It's going to be a i plus one. ", "So it's a i plus one.  Plus the other alternative is that you  are going to lose money and end up in that state.  And there, the remaining probability to reach the time n ", "is a i minus 1.  So you have this kind of equation.  This is valid for all i between 0 and n.  And this is a system of equations that you can solve. ", "It's not very difficult to solve.  Actually, you can look in the textbook.  There will be some trick to do that.  There are many, many ways to do that.  We're not going to spend our time going into details, ", "but essentially if you solve that system,  you will see that the answer will be that a of i  is i over n.  So if you start with i amount of money, ", "the probability that you're going to reach your goal here  is i over n.  So here clearly, if you're extremely greedy,  and you have a very, very, very high goal, ", "that means n is very, very large--  so large that compared to your initial amount i,  n can be considered to be infinity.  Then the probability that you're going to reach your high goal ", "will go to 0, where n goes to infinity.  So again, if you are extremely greedy,  no matter how much your fixed amount of initial money is, ", "the probability that you will stop the game reaching  your goal is going to be increasingly small.  And since the other state is 1 minus this one, ", "the priority that you're going to get ruined  is going to be closer to 1.  All right, so we have that answer here.  What about the next question? ", "Next question is the following-- what  would be the expected wealth at the end?  Again, this is a Markov chain where  there are two absorbing states.  All the others are transient. ", "You're guaranteed with probability 1  that you will reach either 0 or n.  So it's a valid question to know once you reach either 0  or n, what is the expected wealth at the end? ", "Well, if you arrive here, it's going to be 0.  And if you arrive here, it's going to be n.  So the expected value of that wealth  will be 0 times the probability of ending in that, plus n times ", "the probability of getting there.  So it's going to be that expression-- 0 times  1 minus a of i, plus n times a of i.  And here what we then get is n times i over n, which is i. ", "Which is quite interesting.  This is exactly how you started.  So in some sense, in expectation there is no free lunch here.  The next question is-- how long does the gambler ", "expect to stay in the game?  We know that eventually, he will either reach 0  or n with probability 1.  The question is-- how long is it going to take? ", "Again, we have seen in a previous video  that this is essentially calculating the expectation  to absorption.  And we know how to do that.  So let's recap what we had said. ", "If you define mu of i to be the expected number of plays  starting from i, what do you have?  Well, for i equal to 0 or i equals n, ", "either way-- if you start from here,  or you start from here-- the expected number of plays  is 0, right?  Because you're done.  And otherwise, you use the same kind of derivation that we had. ", "If you start at i between 1 and n,  then you will see that mu of i, after one transition, plus 1, ", "you will either be in state i plus 1-- in that case,  this expectation will be mu i plus 1 --  or you will be in state i minus 1. ", "In that case, the expectation is mu i minus 1.  So this is an equation that you have,  which is almost the same as this one,  except that you have a plus 1 in it. ", "And as we had discussed before, in general  this is the kind of formula that you have.  Now you can solve the system.  I will let you do that. ", "There are many ways to do this.  But the solution that you're going to have  is that mu i will be equals to i times n minus i. ", "This is the result.   Finally what would be the case if you  didn't have a fair game-- for example, unfair to the gambler ", "or unfair to the casino?  What we mean here is that the probability p  is different from 0.5. ", "So here, instead of 0.5, you have p everywhere.  And here, of course, you have 1 minus p  everywhere on this side. ", "So you have a probability p of winning,  and probability 1 minus p of losing each bet.  So you might ask the same question-- well,  for the probability a of i, you still have 0 here. ", "You still have 1 here.  The formula that you would write here,  instead of writing it this way, it  would be-- you start from here with a probability p.  You end up here.  And with a probability of 1 minus p, you end up there. ", "And the expression that you get for a of i--  if you define r to be 1 minus p over p-- you will see  that a of i is going to be 1 minus r to the power of i ", "over 1 minus r to the power n.  And what would be the expected amount of time she will play?  Instead of that equation, if you solve it, ", "you would have mu of i equals r plus 1 divided  by r minus 1 times i minus n times 1 minus r to the i ", "divided by 1 minus r to the power n.  Because you would have here again p, and 1 minus p here.  ", "And you can see that when p is strictly less than one-half--  in other words, it's even worse for this gambler--  then a of i-- which is the probability of getting ", "to this favorable state-- will also go to 0  when n goes to infinity.  And in the case where p is strictly greater than 0.5-- ", "that means that she has some favored odd on her favor--  then in that case, this number r to the power n will go to zero.  And 1 minus r of i will represent the probability ", "that she would become infinitely rich.  In other words, being very greedy and n going to infinity.  This will go to 0 and 1 minus r to the power of i ", "is the probability that she would get infinitely rich.  "], "vid_duration": [12.09, 14.43, 11.61, 11.45, 13.55, 11.56, 13.04, 11.36, 11.683, 12.98, 14.17, 11.43, 10.56, 13.63, 12.05, 10.264, 12.376, 13.3, 13.0, 13.29, 13.61, 11.87, 12.63, 10.17, 11.47, 10.22, 11.47, 13.71, 10.42, 12.38, 10.15, 10.57, 12.04, 10.98, 11.7, 12.56, 11.11, 13.15, 13.1, 12.35, 10.56, 11.32, 10.08, 12.12, 12.54, 10.6, 11.58, 11.31, 12.289, 10.601, 11.29, 10.43, 11.9, 12.67, 11.89, 13.84, 10.58, 10.524, 13.33, 10.43, 10.06, 11.869, 12.071, 12.179, 13.101, 10.303, 10.477, 10.7, 14.649, 10.561, 10.709, 10.221, 10.3, 12.489, 11.811, 11.81, 11.44, 12.88, 11.84, 15.65, 10.09, 10.875, 11.225, 10.97, 15.32, 11.13, 11.41, 11.079, 12.681, 12.91, 12.6, 12.4, 14.52, 10.414, 12.986, 10.13, 12.399, 11.73, 10.5, 11.811, 15.4, 12.62, 12.76, 12.4, 12.319, 10.44, 11.661, 10.76, 11.52, 12.98, 10.06, 12.269, 10.37, 10.16, 11.451, 13.019, 10.53, 11.411, 12.399, 10.321, 14.82, 12.9, 12.759, 10.75, 12.591, 11.22, 10.91, 10.139, 10.211, 11.909, 11.811, 11.309, 12.421, 12.899, 12.071, 11.449, 10.52, 13.761, 10.87, 13.46, 13.559, 12.29, 11.74, 11.901, 11.29, 11.98, 11.339, 11.411, 13.68, 12.009, 12.091, 11.859, 10.18, 12.12, 13.821, 11.569, 10.48, 12.351, 10.12, 11.539, 12.12, 10.35, 11.101, 10.54, 12.219, 11.5, 11.45, 10.791, 12.149, 11.26, 10.971, 12.39, 12.139, 11.14, 11.71, 12.12, 15.09, 14.45, 12.891, 12.58, 11.92, 11.12, 11.695, 11.075, 10.3, 17.14, 13.179, 12.331, 10.78, 11.25, 12.619, 13.881, 14.77, 13.59, 11.239, 12.631, 13.99, 11.93, 11.41, 11.99, 11.37, 10.529, 11.971, 11.91, 11.608, 11.87, 14.3, 12.12, 13.02, 10.76, 12.22, 10.62, 10.98, 10.7, 11.6, 10.12, 11.82, 12.64, 12.16, 10.41, 11.56, 15.61, 12.15, 11.38, 11.68, 10.65, 15.765, 12.945, 11.41, 10.75, 15.02, 11.11, 14.79, 13.16, 15.93, 11.26, 10.89, 13.22, 12.21, 10.96, 10.84, 13.66, 11.87, 13.07, 10.27, 12.35, 14.18, 13.24, 10.96, 12.24, 12.25, 13.65, 11.507, 12.659, 10.76, 11.88, 12.94, 11.27, 11.26, 10.16, 14.64, 13.12, 12.97, 12.03, 13.37, 14.51, 14.04, 12.96, 11.79, 12.23, 11.81, 13.27, 11.24, 11.73, 11.35, 13.44, 12.79, 13.77, 11.52, 10.35, 10.92, 15.42, 13.21, 10.32, 13.82, 11.05, 10.54, 12.37, 11.25, 11.39, 10.46, 11.54, 10.12, 10.48, 11.14, 11.12, 11.01, 11.92, 11.52, 11.35, 13.27, 11.72, 13.5, 12.46, 12.37, 13.86, 11.24, 14.36, 11.73, 10.288, 13.06, 11.71, 11.35, 13.95, 10.88, 11.69, 11.44, 12.81, 11.68, 10.53, 12.1, 14.0, 12.0, 12.54, 10.49, 12.43, 13.76, 12.61, 11.46, 13.3, 10.24, 12.15, 13.9, 10.53, 11.87, 11.6, 11.54, 11.48, 13.55, 10.48, 12.41, 11.4, 10.92, 11.96, 12.78, 10.87, 21.86, 13.05, 12.0, 10.72, 10.54, 11.92, 12.799, 10.98, 11.07, 12.83, 10.8, 11.89, 10.78, 11.53, 11.58, 13.74, 13.58, 13.6, 12.95, 10.76, 11.43, 11.6, 11.24, 10.48, 10.44, 13.73, 12.46, 13.04, 14.5, 10.42, 12.65, 12.91, 10.97, 10.22, 11.27, 12.25, 11.99, 12.37, 11.99, 16.65, 12.53, 10.66, 12.39, 10.33, 12.05, 10.55, 11.97, 12.38, 10.06, 11.72, 10.9, 10.42, 12.47, 13.07, 13.88, 14.47, 13.68, 13.34, 12.05, 11.97, 11.51, 13.6, 10.87, 6.816], "stet": [[0, 12.09], [12.09, 26.52], [26.52, 38.129999999999995], [38.129999999999995, 49.58], [49.58, 63.129999999999995], [63.129999999999995, 74.69], [74.69, 87.72999999999999], [87.72999999999999, 99.08999999999999], [99.08999999999999, 110.773], [110.773, 123.753], [123.753, 137.923], [137.923, 149.353], [149.353, 159.913], [159.913, 173.543], [173.543, 185.59300000000002], [185.59300000000002, 195.85700000000003], [195.85700000000003, 208.23300000000003], [208.23300000000003, 221.53300000000004], [221.53300000000004, 234.53300000000004], [234.53300000000004, 247.82300000000004], [247.82300000000004, 261.43300000000005], [261.43300000000005, 273.30300000000005], [273.30300000000005, 285.93300000000005], [285.93300000000005, 296.10300000000007], [296.10300000000007, 307.5730000000001], [307.5730000000001, 317.7930000000001], [317.7930000000001, 329.26300000000015], [329.26300000000015, 342.9730000000001], [342.9730000000001, 353.39300000000014], [353.39300000000014, 365.77300000000014], [365.77300000000014, 375.9230000000001], [375.9230000000001, 386.4930000000001], [386.4930000000001, 398.53300000000013], [398.53300000000013, 409.51300000000015], [409.51300000000015, 421.21300000000014], [421.21300000000014, 433.77300000000014], [433.77300000000014, 444.88300000000015], [444.88300000000015, 458.03300000000013], [458.03300000000013, 471.13300000000015], [471.13300000000015, 483.4830000000002], [483.4830000000002, 494.0430000000002], [494.0430000000002, 505.36300000000017], [505.36300000000017, 515.4430000000002], [515.4430000000002, 527.5630000000002], [527.5630000000002, 540.1030000000002], [540.1030000000002, 550.7030000000002], [550.7030000000002, 562.2830000000002], [562.2830000000002, 573.5930000000002], [573.5930000000002, 585.8820000000002], [585.8820000000002, 596.4830000000002], [596.4830000000002, 607.7730000000001], [607.7730000000001, 618.2030000000001], [618.2030000000001, 630.1030000000001], [630.1030000000001, 642.773], [642.773, 654.663], [654.663, 668.503], [668.503, 679.0830000000001], [679.0830000000001, 689.6070000000001], [689.6070000000001, 702.9370000000001], [702.9370000000001, 713.3670000000001], [713.3670000000001, 723.427], [723.427, 735.296], [735.296, 747.3670000000001], [747.3670000000001, 759.546], [759.546, 772.647], [772.647, 782.95], [782.95, 793.427], [793.427, 804.1270000000001], [804.1270000000001, 818.7760000000001], [818.7760000000001, 829.3370000000001], [829.3370000000001, 840.046], [840.046, 850.267], [850.267, 860.567], [860.567, 873.056], [873.056, 884.8670000000001], [884.8670000000001, 896.677], [896.677, 908.1170000000001], [908.1170000000001, 920.9970000000001], [920.9970000000001, 932.8370000000001], [932.8370000000001, 948.4870000000001], [948.4870000000001, 958.5770000000001], [958.5770000000001, 969.4520000000001], [969.4520000000001, 980.6770000000001], [980.6770000000001, 991.6470000000002], [991.6470000000002, 1006.9670000000002], [1006.9670000000002, 1018.0970000000002], [1018.0970000000002, 1029.5070000000003], [1029.5070000000003, 1040.5860000000002], [1040.5860000000002, 1053.2670000000003], [1053.2670000000003, 1066.1770000000004], [1066.1770000000004, 1078.7770000000003], [1078.7770000000003, 1091.1770000000004], [1091.1770000000004, 1105.6970000000003], [1105.6970000000003, 1116.1110000000003], [1116.1110000000003, 1129.0970000000004], [1129.0970000000004, 1139.2270000000005], [1139.2270000000005, 1151.6260000000004], [1151.6260000000004, 1163.3560000000004], [1163.3560000000004, 1173.8560000000004], [1173.8560000000004, 1185.6670000000004], [1185.6670000000004, 1201.0670000000005], [1201.0670000000005, 1213.6870000000004], [1213.6870000000004, 1226.4470000000003], [1226.4470000000003, 1238.8470000000004], [1238.8470000000004, 1251.1660000000004], [1251.1660000000004, 1261.6060000000004], [1261.6060000000004, 1273.2670000000005], [1273.2670000000005, 1284.0270000000005], [1284.0270000000005, 1295.5470000000005], [1295.5470000000005, 1308.5270000000005], [1308.5270000000005, 1318.5870000000004], [1318.5870000000004, 1330.8560000000004], [1330.8560000000004, 1341.2260000000003], [1341.2260000000003, 1351.3860000000004], [1351.3860000000004, 1362.8370000000004], [1362.8370000000004, 1375.8560000000004], [1375.8560000000004, 1386.3860000000004], [1386.3860000000004, 1397.7970000000005], [1397.7970000000005, 1410.1960000000004], [1410.1960000000004, 1420.5170000000003], [1420.5170000000003, 1435.3370000000002], [1435.3370000000002, 1448.2370000000003], [1448.2370000000003, 1460.9960000000003], [1460.9960000000003, 1471.7460000000003], [1471.7460000000003, 1484.3370000000002], [1484.3370000000002, 1495.5570000000002], [1495.5570000000002, 1506.4670000000003], [1506.4670000000003, 1516.6060000000002], [1516.6060000000002, 1526.8170000000002], [1526.8170000000002, 1538.7260000000003], [1538.7260000000003, 1550.5370000000003], [1550.5370000000003, 1561.8460000000002], [1561.8460000000002, 1574.2670000000003], [1574.2670000000003, 1587.1660000000002], [1587.1660000000002, 1599.237], [1599.237, 1610.6860000000001], [1610.6860000000001, 1621.2060000000001], [1621.2060000000001, 1634.967], [1634.967, 1645.837], [1645.837, 1659.297], [1659.297, 1672.856], [1672.856, 1685.146], [1685.146, 1696.886], [1696.886, 1708.787], [1708.787, 1720.077], [1720.077, 1732.057], [1732.057, 1743.396], [1743.396, 1754.807], [1754.807, 1768.487], [1768.487, 1780.496], [1780.496, 1792.587], [1792.587, 1804.446], [1804.446, 1814.626], [1814.626, 1826.7459999999999], [1826.7459999999999, 1840.5669999999998], [1840.5669999999998, 1852.1359999999997], [1852.1359999999997, 1862.6159999999998], [1862.6159999999998, 1874.9669999999999], [1874.9669999999999, 1885.0869999999998], [1885.0869999999998, 1896.6259999999997], [1896.6259999999997, 1908.7459999999996], [1908.7459999999996, 1919.0959999999995], [1919.0959999999995, 1930.1969999999997], [1930.1969999999997, 1940.7369999999996], [1940.7369999999996, 1952.9559999999997], [1952.9559999999997, 1964.4559999999997], [1964.4559999999997, 1975.9059999999997], [1975.9059999999997, 1986.6969999999997], [1986.6969999999997, 1998.8459999999995], [1998.8459999999995, 2010.1059999999995], [2010.1059999999995, 2021.0769999999995], [2021.0769999999995, 2033.4669999999996], [2033.4669999999996, 2045.6059999999995], [2045.6059999999995, 2056.7459999999996], [2056.7459999999996, 2068.4559999999997], [2068.4559999999997, 2080.5759999999996], [2080.5759999999996, 2095.6659999999997], [2095.6659999999997, 2110.1159999999995], [2110.1159999999995, 2123.0069999999996], [2123.0069999999996, 2135.5869999999995], [2135.5869999999995, 2147.5069999999996], [2147.5069999999996, 2158.6269999999995], [2158.6269999999995, 2170.3219999999997], [2170.3219999999997, 2181.3969999999995], [2181.3969999999995, 2191.6969999999997], [2191.6969999999997, 2208.8369999999995], [2208.8369999999995, 2222.0159999999996], [2222.0159999999996, 2234.3469999999998], [2234.3469999999998, 2245.127], [2245.127, 2256.377], [2256.377, 2268.996], [2268.996, 2282.877], [2282.877, 2297.647], [2297.647, 2311.237], [2311.237, 2322.476], [2322.476, 2335.107], [2335.107, 2349.0969999999998], [2349.0969999999998, 2361.0269999999996], [2361.0269999999996, 2372.4369999999994], [2372.4369999999994, 2384.426999999999], [2384.426999999999, 2395.796999999999], [2395.796999999999, 2406.325999999999], [2406.325999999999, 2418.296999999999], [2418.296999999999, 2430.206999999999], [2430.206999999999, 2441.814999999999], [2441.814999999999, 2453.684999999999], [2453.684999999999, 2467.984999999999], [2467.984999999999, 2480.104999999999], [2480.104999999999, 2493.124999999999], [2493.124999999999, 2503.8849999999993], [2503.8849999999993, 2516.104999999999], [2516.104999999999, 2526.724999999999], [2526.724999999999, 2537.704999999999], [2537.704999999999, 2548.404999999999], [2548.404999999999, 2560.0049999999987], [2560.0049999999987, 2570.1249999999986], [2570.1249999999986, 2581.944999999999], [2581.944999999999, 2594.5849999999987], [2594.5849999999987, 2606.7449999999985], [2606.7449999999985, 2617.1549999999984], [2617.1549999999984, 2628.7149999999983], [2628.7149999999983, 2644.3249999999985], [2644.3249999999985, 2656.4749999999985], [2656.4749999999985, 2667.8549999999987], [2667.8549999999987, 2679.5349999999985], [2679.5349999999985, 2690.1849999999986], [2690.1849999999986, 2705.9499999999985], [2705.9499999999985, 2718.8949999999986], [2718.8949999999986, 2730.3049999999985], [2730.3049999999985, 2741.0549999999985], [2741.0549999999985, 2756.0749999999985], [2756.0749999999985, 2767.1849999999986], [2767.1849999999986, 2781.9749999999985], [2781.9749999999985, 2795.1349999999984], [2795.1349999999984, 2811.0649999999982], [2811.0649999999982, 2822.3249999999985], [2822.3249999999985, 2833.2149999999983], [2833.2149999999983, 2846.434999999998], [2846.434999999998, 2858.644999999998], [2858.644999999998, 2869.604999999998], [2869.604999999998, 2880.4449999999983], [2880.4449999999983, 2894.104999999998], [2894.104999999998, 2905.974999999998], [2905.974999999998, 2919.0449999999983], [2919.0449999999983, 2929.3149999999982], [2929.3149999999982, 2941.664999999998], [2941.664999999998, 2955.844999999998], [2955.844999999998, 2969.0849999999978], [2969.0849999999978, 2980.044999999998], [2980.044999999998, 2992.2849999999976], [2992.2849999999976, 3004.5349999999976], [3004.5349999999976, 3018.1849999999977], [3018.1849999999977, 3029.6919999999977], [3029.6919999999977, 3042.350999999998], [3042.350999999998, 3053.110999999998], [3053.110999999998, 3064.990999999998], [3064.990999999998, 3077.930999999998], [3077.930999999998, 3089.200999999998], [3089.200999999998, 3100.4609999999984], [3100.4609999999984, 3110.6209999999983], [3110.6209999999983, 3125.260999999998], [3125.260999999998, 3138.380999999998], [3138.380999999998, 3151.350999999998], [3151.350999999998, 3163.380999999998], [3163.380999999998, 3176.750999999998], [3176.750999999998, 3191.260999999998], [3191.260999999998, 3205.300999999998], [3205.300999999998, 3218.260999999998], [3218.260999999998, 3230.050999999998], [3230.050999999998, 3242.280999999998], [3242.280999999998, 3254.090999999998], [3254.090999999998, 3267.360999999998], [3267.360999999998, 3278.600999999998], [3278.600999999998, 3290.330999999998], [3290.330999999998, 3301.6809999999978], [3301.6809999999978, 3315.120999999998], [3315.120999999998, 3327.910999999998], [3327.910999999998, 3341.6809999999978], [3341.6809999999978, 3353.2009999999977], [3353.2009999999977, 3363.5509999999977], [3363.5509999999977, 3374.4709999999977], [3374.4709999999977, 3389.890999999998], [3389.890999999998, 3403.100999999998], [3403.100999999998, 3413.420999999998], [3413.420999999998, 3427.240999999998], [3427.240999999998, 3438.2909999999983], [3438.2909999999983, 3448.8309999999983], [3448.8309999999983, 3461.200999999998], [3461.200999999998, 3472.450999999998], [3472.450999999998, 3483.840999999998], [3483.840999999998, 3494.300999999998], [3494.300999999998, 3505.840999999998], [3505.840999999998, 3515.960999999998], [3515.960999999998, 3526.440999999998], [3526.440999999998, 3537.580999999998], [3537.580999999998, 3548.7009999999977], [3548.7009999999977, 3559.710999999998], [3559.710999999998, 3571.630999999998], [3571.630999999998, 3583.150999999998], [3583.150999999998, 3594.500999999998], [3594.500999999998, 3607.770999999998], [3607.770999999998, 3619.4909999999977], [3619.4909999999977, 3632.9909999999977], [3632.9909999999977, 3645.4509999999977], [3645.4509999999977, 3657.8209999999976], [3657.8209999999976, 3671.6809999999978], [3671.6809999999978, 3682.9209999999975], [3682.9209999999975, 3697.2809999999977], [3697.2809999999977, 3709.0109999999977], [3709.0109999999977, 3719.2989999999977], [3719.2989999999977, 3732.3589999999976], [3732.3589999999976, 3744.0689999999977], [3744.0689999999977, 3755.4189999999976], [3755.4189999999976, 3769.3689999999974], [3769.3689999999974, 3780.2489999999975], [3780.2489999999975, 3791.9389999999976], [3791.9389999999976, 3803.3789999999976], [3803.3789999999976, 3816.1889999999976], [3816.1889999999976, 3827.8689999999974], [3827.8689999999974, 3838.3989999999976], [3838.3989999999976, 3850.4989999999975], [3850.4989999999975, 3864.4989999999975], [3864.4989999999975, 3876.4989999999975], [3876.4989999999975, 3889.0389999999975], [3889.0389999999975, 3899.5289999999973], [3899.5289999999973, 3911.958999999997], [3911.958999999997, 3925.7189999999973], [3925.7189999999973, 3938.3289999999974], [3938.3289999999974, 3949.7889999999975], [3949.7889999999975, 3963.0889999999977], [3963.0889999999977, 3973.3289999999974], [3973.3289999999974, 3985.4789999999975], [3985.4789999999975, 3999.3789999999976], [3999.3789999999976, 4009.908999999998], [4009.908999999998, 4021.7789999999977], [4021.7789999999977, 4033.3789999999976], [4033.3789999999976, 4044.9189999999976], [4044.9189999999976, 4056.3989999999976], [4056.3989999999976, 4069.948999999998], [4069.948999999998, 4080.428999999998], [4080.428999999998, 4092.8389999999977], [4092.8389999999977, 4104.238999999998], [4104.238999999998, 4115.158999999998], [4115.158999999998, 4127.118999999998], [4127.118999999998, 4139.898999999998], [4139.898999999998, 4150.7689999999975], [4150.7689999999975, 4172.628999999997], [4172.628999999997, 4185.678999999997], [4185.678999999997, 4197.678999999997], [4197.678999999997, 4208.398999999998], [4208.398999999998, 4218.938999999998], [4218.938999999998, 4230.858999999998], [4230.858999999998, 4243.657999999998], [4243.657999999998, 4254.637999999997], [4254.637999999997, 4265.707999999997], [4265.707999999997, 4278.537999999997], [4278.537999999997, 4289.337999999997], [4289.337999999997, 4301.227999999997], [4301.227999999997, 4312.007999999997], [4312.007999999997, 4323.537999999997], [4323.537999999997, 4335.117999999997], [4335.117999999997, 4348.8579999999965], [4348.8579999999965, 4362.4379999999965], [4362.4379999999965, 4376.037999999997], [4376.037999999997, 4388.987999999997], [4388.987999999997, 4399.747999999997], [4399.747999999997, 4411.177999999997], [4411.177999999997, 4422.7779999999975], [4422.7779999999975, 4434.017999999997], [4434.017999999997, 4444.497999999997], [4444.497999999997, 4454.9379999999965], [4454.9379999999965, 4468.667999999996], [4468.667999999996, 4481.127999999996], [4481.127999999996, 4494.167999999996], [4494.167999999996, 4508.667999999996], [4508.667999999996, 4519.087999999996], [4519.087999999996, 4531.737999999996], [4531.737999999996, 4544.647999999996], [4544.647999999996, 4555.617999999996], [4555.617999999996, 4565.837999999996], [4565.837999999996, 4577.1079999999965], [4577.1079999999965, 4589.3579999999965], [4589.3579999999965, 4601.347999999996], [4601.347999999996, 4613.717999999996], [4613.717999999996, 4625.707999999996], [4625.707999999996, 4642.357999999996], [4642.357999999996, 4654.887999999995], [4654.887999999995, 4665.547999999995], [4665.547999999995, 4677.937999999996], [4677.937999999996, 4688.2679999999955], [4688.2679999999955, 4700.317999999996], [4700.317999999996, 4710.867999999996], [4710.867999999996, 4722.837999999996], [4722.837999999996, 4735.217999999996], [4735.217999999996, 4745.277999999997], [4745.277999999997, 4756.997999999997], [4756.997999999997, 4767.8979999999965], [4767.8979999999965, 4778.317999999997], [4778.317999999997, 4790.787999999997], [4790.787999999997, 4803.8579999999965], [4803.8579999999965, 4817.737999999997], [4817.737999999997, 4832.207999999997], [4832.207999999997, 4845.887999999997], [4845.887999999997, 4859.227999999997], [4859.227999999997, 4871.2779999999975], [4871.2779999999975, 4883.247999999998], [4883.247999999998, 4894.757999999998], [4894.757999999998, 4908.357999999998], [4908.357999999998, 4919.227999999998], [4919.227999999998, 4926.043999999998]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [100, 139, 691, 1325, 2435, 3032, 3721, 4244, 4927]}
{"example_id": "mit002@@ocw-18_02-f07-lec23_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  Today I am going to tell you about flux of a vector field for ", "a curve. In case you have seen flux in  physics, probably you have seen flux in  space, and we are going to come to  that in a couple of weeks, but for now we are still doing  everything in the plane. So bear with me if you have ", "seen a more complicated version of flux.  We are going to do the easy one first.  What is flux? Well, flux is actually another ", "kind of line integral. Let's say that I have a plane ", "curve and a vector field in the plane.  Then the flux of F across a curve C is, by definition, ", "a line integral, but I will use notation F dot n  ds. I have to explain to you what ", "it means, but let me first box that because that is the  important formula to remember. That is the definition. ", "What does that mean? First, mostly I have to tell  you what this little n is. The notation suggests it is a ", "normal vector, so what does that mean?  I have a curve in the plane and I have a vector field. ", "Let's see. The vector field will be yellow  today. And I will want to integrate ", "along the curve the dot product of F with the normal vector to  the curve, a unit normal vector to the curve.  That means a vector that is at every point of the curve ", "perpendicular to the curve and has length one.  N everywhere will be the unit normal vector to the curve C ", "pointing 90 degrees clockwise from T. ", "What does that mean? That means I have two normal  vectors, one that is pointing this way, one that is pointing  that way. I have to choose a convention.  And the convention is that the normal vector that I take goes ", "to the right of the curve as I am traveling along the curve.  You mentioned that you were walking along this curve,  then you look to your right, that is that direction. ", "What we will do is just, at every point along the curve,  the dot product between the vector field and the normal  vector. And we will sum that along the ", "various pieces of the curve. What this notation means is  that if we actually break C into small pieces of length delta(s) ", "then the flux will be the limit, as the pieces become smaller  and smaller, of the sum of F dot n delta S. ", "I take each small piece of my curve, I do the dot product  between F and n and I multiply by the length of a piece.  And then I add these together. That is what the line integral ", "means. Of course that is,  again, not how I will compute it.  Just to compare this with work, conceptually it is similar to ", "the line integral we did for work except the line integral ", "for work -- Work is the line integral of F dot dr, ", "which is also the line integral of F dot T ds.  That is how we reformulated it. That means we take our curve ", "and we figure out at each point how big the tangent component --  I guess I should probably take the same vector field as before. ", "Let's see. My field was pointing more like  that way. What I do at any point is  project F to the tangent direction, I figure out how much ", "F is going along my curve and then I sum these things  together. I am actually summing -- -- the ", "tangential component of my field F. ", "Roughly-speaking the work measures, you know,  when I move along my curve, how much I am going with or  against F. Flux, on the other hand,  measures, when I go along the curve, roughly how much the ", "field is going to across the curve.  Counting positively what goes to the right,  negatively what goes to the left.  Flux is integral F dot n ds, and that one corresponds to ", "summing the normal component of a vector field.  But apart from that conceptually it is the same kind ", "of thing. Just the physical  interpretations will be very different,  but for a mathematician these are two line integrals that you ", "set up and compute in pretty much the same way.  Let's see. I should probably tell you what ", "it means. Why do we make this definition?  What does it correspond to? Well, the interpretation for  work made a lot of sense when F was representing a force. ", "The line integral was actually the work done by the force.  The interpretation for flux makes more sense if you think of  F as a velocity field. What is the interpretation? ", "Let's say that for F is a velocity field.  That means I am thinking of some fluid that is moving, ", "maybe water or something, and it is moving at a certain  speed. And my vector field represents  how things are moving at every point of the plane. ", "I claim that flux measures how much fluid passes through -- -- ", "the curve C per unit time. If you imagine that maybe you ", "have a river and you are somehow building a damn here,  a damn with holes in it so that the water still passes through,  then this measures how much water passes through your ", "membrane per unit time. Let's try to figure out why  this is true. Why does this make sense?  Let's look at what happens on a small portion of our curve C. ", "I am zooming in on my curve C. I guess I need to zoom further. ", "That is a little piece of my curve, of length delta S,  and there is a fluid flow. On my picture things are  flowing to the right. Here I am drawing a constant ", "vector field because if you zoom in enough then your vectors will  pretty much be the same everywhere.  If you enlarge the picture enough then things will be ", "pretty much a uniform flow. Now, how much stuff goes  through this little piece of curve per unit time?  Well, what happens over time is the fluid is moving while my ", "curve is staying the same place so it corresponds to something  like this. I claim that what goes through ", "C in unit time is actually going to be a parallelogram.  Here is a better picture. I claim that what will be going ", "through C is this shaded parallelogram to the left of C.  Let's see. If I move for unit time it ", "works. That is the stuff that goes  through my curve, for a small portion of curve in  unit time. And, of course,  I would need to add all of these together to get the entire ", "curve. Let's try to understand how big  this parallelogram is. To know how big this  parallelogram is I would like to use base times height or ", "something like that. And maybe I want to actually  flip my picture so that the base and the height make more sense  to me. Let me actually turn it this ", "way. And, in case you have trouble  reading the rotated picture, let me redo it on the board. ", "What passes through a portion of C in unit time is the ", "contents of a parallelogram whose base is on C.  So it has length delta s. That is a piece of C. ", "And the other side is going to be given by my velocity vector ", "F. And to find the height of this  thing, I need to know what actually the normal component of ", "this vector is. If I call n the unit normal  vector to the curve then the area is base times height. ", "The base is delta S and the height is the normal component  of F, so it is F dot n. And so you see that when you ", "sum these things together you get, what I said,  flux. Now, if you are worried about  the fact that actually -- If your unit time is too long then ", "of course things might start changing as it flows.  You have to take the time unit and the length unit that are  sufficiently small so that really this approximation where ", "C is a straight line and where flow is at constant speed are  valid. You want to take maybe a  segment here that is a few micrometers.  And the time unit might be a few nanoseconds or whatever, ", "and then it is a good approximation.  What I mean by per unit time is, well, actually,  that works, but you want to think of a really, ", "really small time. And then the amount of matter  that passes in that really, really small time is the flux  times the amount of time. Let's be a tiny bit more ", "careful. And what I am saying is the  amount of stuff that passes through C depends actually on  whether n is going this way or the opposite way.  Actually, what is implicit in this ", "explanation is that I am counting positively all the  stuff that flows across C in the direction of n and negatively ", "what flows in the opposite direction.  What flows to the right of C, well, across C from left to ", "right is counted positively. While what flows right to left ", "is counted negatively. So, in fact,  it is the net flow through C per unit time. ", "Any questions about the definition or the interpretation  or things like that? Yes? ", "Well, you can have both not in the same small segment.  But it could be that, well, imagine that my vector  field accidentally goes in the opposite direction then this ", "part of the curve, while things are flowing to the  left, contributes negatively to flux.  And here maybe the field is tangent so the normal component ", "becomes zero. And then it becomes positive  and this part of the curve contributes positively.  For example, if you imagine that you have a ", "round tank in which the fluid is rotating and you put your dam  just on a diameter across then things are going one way on one  side, the other way on the other  side, and actually it just evens out. ", "We don't have complete information.  It is just the total net flux. OK.  If there are no other questions then I guess we will need to ", "figure out how to compute this guy and how to actually do this  line integral. Well, let's start with a couple ", "of easy examples. Let's say that C is a circle of ", "radius (a) centered at the origin going counterclockwise. ", "And let's say that our vector field is xi yj.  What does that look like? Remember, xi plus yj is a ", "vector field that is pointing radially away from the origin.  Because at every point it is equal to the vector from the ", "origin to that point. Now, if we have a circle and  let's say we are going counterclockwise. ", "Actually, I have a nicer picture.  Let me do it here. That is my curve and my vector ", "field. And the normal vector, see,  when you go counterclockwise in a closed curve,  this convention that a normal vector points to the right of ", "curve makes it point out. The usual convention,  when you take flux for a closed curve, is that you are counting  the flux going out of the region enclosed by the curve. ", "And, of course, if you went clockwise it would  be the other way around. You choose to do it the way you  want, but the most common one is to count flux going out of the ", "region. Let's see what happens.  Well, if I am anywhere on my circle, see, the normal vector  is sticking straight out of the circle. ", "That is a property of the circle that the radial direction  is perpendicular to the circle. Actually, let me complete this ", "picture. If I take a point on the  circle, I have my normal vector that is pointing straight out so ", "it is parallel to F. Along C we know that F is  parallel to n, so F dot n will be equal to the ", "magnitude of F times, well, the magnitude of n,  but that is one. Let me put it anywhere, ", "but that is the unit normal vector.  Now, what is the magnitude of this vector field if I am at a  point x, y? Well, it is square root of x  squared plus y squared, which is the same as the ", "distance from the origin. So if this distance,  if this radius is a then the magnitude of F will just be a. ", "In fact, F dot n is constant, always equal to a.  So the line integral will be pretty easy because all I have ", "to do is the integral of F dot n ds becomes the integral of a ds.  (a) is a constant so I can take it out. ", "And integral ds is just a length of C which is 2pi a,  so I will get 2pi a squared. And that is positive, ", "as we expected, because stuff is flowing out of  the circle. Any questions about that? ", "No. OK.  Just out of curiosity, let's say that we had taken our  other favorite vector field. Let's say that we had the same ", "C, but now the vector field .  Remember, that one goes counterclockwise around the ", "origin. If you remember what we did  several times, well, along the circle that  vector field now is tangent to the circle. ", "If it is tangent to the circle it doesn't have any normal  component. The normal component is zero.  Things are not flowing into the circle or out of it.  They are just flowing along the circle around and around so the ", "flux will be zero. F now is tangent to C.  F dot n is zero and, therefore, the flux will be ", "zero. These are examples where you  can compute things geometrically.  And I would say, generally speaking,  with flux, well, if it is a very complicated ", "field then you cannot. But, if a field is fairly  simple, you should be able to get some  general feeling for whether your answer should be positive,  negative or zero just by thinking about which way is my ", "flow going. Is it going across the curve  one way or the other way? Still no questions about these ", "examples? The next thing we need to know  is how we will actually compute these things because here,  yeah, it works pretty well, but what if you don't have a ", "simple geometric interpretation. What if I give you a really  complicated curve and then you have trouble finding the normal  vector? It is going to be annoying to ", "set up things this way. Actually, there is a better way  to do it in coordinates. Just as we do work,  when we compute this line integral, usually we don't do it ", "geometrically like this. Most of the time we just  integrate M dx plus N dy in coordinates.  That is a similar way to do it because it is, ", "again, a line integral so it should work the same way.  Let's try to figure that out.  ", "How do we do the calculation in coordinates, or I should say ", "using components? That is the general method of  calculation when we don't have something geometric to do. ", "Remember, when we were doing things for work we said this  vector dr, or if you prefer T ds, we said just becomes ", "symbolically dx and dy. When you do the line integral  of F dot dr you get line integral of n dx plus n dy. ", "Now let's think for a second about how we would express n ds.  Well, what is n ds compared to T ds? ", "Well, M is just T rotated by 90 degrees, so n ds is T ds rotated  by 90 degrees. That might sound a little bit  outrageous because these are really symbolic notations but it ", "works. I am not going to spend too  much time trying to convince you carefully.  But if you go back to where we wrote this and how we tried to ", "justify this and you work your way through it,  you will see that n ds can be analyzed the same way.  N is T rotated 90 degrees clockwise. ", "That tells us that n ds is -- How do we rotate a vector by 90  degrees? Well, we swept the two  components and we put a minus sign. ", "You have dy and dx. And you have to be careful  where to put the minus sign. Well, if you are doing it  clockwise, it is in front of dx.  ", "Well, actually, let me just convince you  quickly. Let's say we have a small piece  of C. If we do T delta S, ", "that is also vector delta r. That is going to be just the  vector that goes along the curve given by this. ", "Its components will be indeed the change in x,  delta x, and the change in y, delta y. ", "And now, if I want to get n delta S, well,  I claim now that it is perfectly valid and rigorous to ", "just rotate that by 90 degrees. If I want to rotate this by 90  degrees clockwise then the x component will become the same ", "as the old y component. And the y component will be  minus delta x. Then you take the limit when  the segment becomes shorter and shorter, and that is how you can ", "justify this. That is the key to computing  things in practice. It means, actually,  you already know how to compute line integrals for flux. ", "Let me just write it explicitly. Let's say that our vector field ", "has two components. And let me just confuse you a  little bit and not call them M and N for this time just to  stress the fact that we are doing a different line integral. ", "Let me call them P and Q for now.  Then the line integral of F dot n ds will be the line integral ", "of dot product .  That will be the integral of - Q dx P dy. ", "Well, I am running out of space here.  It is integral along C of negative Q dx plus P dy. ", "And from that point onwards you just do it the usual way.  Remember, here you have two variables x and y but you are  integrating along a curve. If you are integrating along a ", "curve x and y are related. They depend on each other or  maybe on some other parameter like T or theta or whatever.  You express everything in terms of a single variable and then ", "you do a usual single integral. Any questions about that?  I see a lot of confused faces so maybe I shouldn't have called ", "my component P and Q.  ", "If you prefer, if you are really sentimentally ", "attached to M and N then this new line integral becomes the ", "integral of - N dx M dy. If a problem tells you compute  flux instead of saying compute work, ", "the only thing you change is instead of doing M dx plus N dy  you do minus N dx plus M dy. And I am sorry to say that I  don't have any good way of helping you remember which one ", "of the two gets the minus sign, so you just have to remember  this formula by heart. That is the only way I know.  Well, you can try to go through this argument again, ", "but it is really best if you just remember that formula.  I am not going to do an example because we already know how to ", "do line integrals. Hopefully you will get to see  one at least in recitation on Monday.  That is all pretty good. Let me tell you now what if I ", "have to compute flux along a closed curve and I don't want to  compute it? Well, remember in the case of ", "work we had Green's theorem. We saw yesterday Green's  theorem. Let's us replace a line  integral along a closed curve by a double integral.  Well, here it is the same. We have a line integral along a ", "curve. If it is a closed curve,  we should be able to replace it by a double integral.  There is a version of Green's theorem for flux. ", "And you will see it is not scarier than the other one.  It is perhaps less scarier or perhaps just as scary or just  not as scary, depending on how you feel about ", "it, but it works pretty much the same way.  What does Green's theorem for flux say?  It says if C is a curve that encloses a region R ", "counterclockwise and if I have a vector field that is defined ", "everywhere, not just on C but also inside,  so also on R. Well, maybe I should give names ", "to the components. If you will forgive me for a  second, I will still use P and Q for now.  You will see why. It is defined and ", "differentiable in R. Then I can actually -- --  replace the line integral for flux by a double integral over R ", "of some function. And that function is called the  divergence of F dA. This is the divergence of F. ", "And I have to define for you what this guy is. ", "The divergence of a vector field with components P and Q is  just P sub x Q sub y. This one is actually easier to ", "remember than curl because you just take the x component,  take its partial with respect to x,  take the y component, take its partial with respect  to y and add them together. No signs. ", "No switching things around. This one is pretty  straightforward. The picture again is if I have ", "my curve C going counterclockwise around a region  R and I want to find the flux of some vector field F that is ", "everywhere in here. Maybe some parts of C will  contribute positively and some parts will contribute  negatively. Just to reiterate what I said, ", "positively here means, because we are going  counterclockwise, the normal vector points out of  the region. This guy here is the flux out ", "of R through C. That is the formula.  Any questions about what the statement says or how to use it ", "concretely? No.  OK. It is pretty similar to Green's  theorem for work. Actually, I should say -- This ", "is called Green's theorem in normal form also.  Not that the other one is abnormal, but just that the old ", "one for work was, you could say,  in tangential form. That just means, ", "well, Green's theorem, as seen yesterday was for the  line integral F dot T ds, integrating the tangent  component of F. The one today is for ", "integrating the normal component of F.  OK. Let's prove this. Good news.  It is much easier to prove than the one we did yesterday because ", "we are just going to show that it is the same thing just using  different notations.  ", "How do I prove it? Well, maybe actually it would  help if first, before proving it, ", "I actually rewrite what it means in components.  We said the line integral of F dot n ds is actually the line ", "integral of - Q dx P dy. And we want to show that this  is equal to the double integral of P sub x Q sub y dA. ", "This is really one of the features of Green's theorem.  No matter which form it is, it relates a line integral to a  double integral. Let's just try to see if we can ", "reduce it to the one we had yesterday.  Let me forget what these things mean physically and just focus  on the math. On the math it is a line ", "integral of something dx plus something dy.  Let's call this guy M and let's call this guy N. ", "Let M equal negative Q and N equal P.  Then this guy here becomes integral of M dx plus N dy. ", "And I know from yesterday what this is equal to,  namely using the tangential form of Green's theorem.  Green for work. This is the double integral of ", "curl of this guy. That is Nx minus My dA.  But now let's think about what this is in terms of M and N. ", "Well, we said that M is negative Q so this is negative  My. And we said P is the same as N, ", "so this is Nx. Just by renaming the  components, I go from one form to the other one.  So it is really the same theorem.  That's why it is also called Green's theorem. ", "But the way we think about it when we use it is different,  because one of them computes the work done by a force along a  closed curve, the other one computes the flux ", "maybe of a velocity field out of region.  Questions? Yes? ", "That is correct. If you are trying to compute a  line integral for flux, wait, where did I put it?  A line integral for flux just becomes this. ", "And once you are here you know how to compute that kind of  thing. The double integral side does  not even have any kind of renaming to do.  You know how to compute a double integral of a function. ", "This is just a particular kind of function that you get out of  a vector field, but it is like any function.  The way you would evaluate these double integrals is just ", "the usual way. Namely, you have a function of  x and y, you have a region and you set up the bounds for the ", "isolated integral. The way you would evaluate the  double integrals is really the usual way,  by slicing the region and setting up the bounds for  iterated integrals in dx, dy or dydx or maybe rd, ", "rd theta or whatever you want. In fact, in terms of computing  integrals, we just have two sets of skills.  One is setting up and evaluating double integrals. ", "The other one is setting up and evaluating line integrals.  And whether these line integrals or double integrals  are representing work, flux, integral of a curve, ", "whatever, the way that we actually  compute them is the same. Let's do an example. ", "Oh, first. Sorry. This renaming here, see,  that is why actually I call my components P and Q because the ", "argument would have gotten very messy if I had told you now I  call M ,N and I call N minus M and so on.  But, now that we are through with this,  if you still like M and N better, ", "you know, what this says -- The formulation of Green's theorem ", "in this language is just integral of minus N dx plus M dy ", "is the double integral over R of Mx plus Ny dA. ", "Now let's do an example. Let's look at this picture  again, the flux of xi plus yj out of the circle of radius A. ", "We did the calculation directly using geometry,  and it wasn't all that bad. But let's see what Green's  theorem does for us here.  ", "Example. Let's take the same example as  last time. F equals xi yj.  C equals circle of radius a counterclockwise. ", "How do we set up Green's theorem.  Well, let's first figure out the divergence of F. ", "The divergence of this field, I take the x component,  which is x, and I take its partial respect to x.  And then I do the same with the y component, and I will get one ", "plus one equals two. So, the divergence of this  field is two. Now, Green's theorem tells us  that the flux out of this region is going to be the double ", "integral of 2 dA. What is R now?  Well, R is the region enclosed by C.  So if C is the circle, R is the disk of radius A. ", "Of course, we can compute it, but we don't have to because  double integral of 2dA is just twice the double integral of dA  so it is twice the area of R. And we know the area of a ", "circle of radius A. That is piA2.  So, it is 2piA2. That is the same answer that we ", "got directly, which is good news.  Now we can even do better. Let's say that my circle is not  at the origin. Let's say that it is out here. ", "Well, then it becomes harder to calculate the flux directly.  And it is harder even to guess exactly what will happen because  on this side here the vector field will go into the region so ", "the contribution to flux will be negative here.  Here it will be positive because it is going out of the  region. There are positive and negative  terms. Well, it looks like positive ", "should win because here the vector field is much larger than  over there. But, short of computing it,  we won't actually know what it is. ", "If you want to do it by direct calculation then you have to  parametize this circle and figure out what the line  integral will be. But if you use Green's theorem, ", "well, we never used the fact that it is the circle of radius  A at the origin. It is true actually for any  closed curve that the flux out of it is going to be twice the ", "area of the region inside. It still will be 2piA2 even if  my circle is anywhere else in the plane.  If I had asked you a trick question where do you want to ", "place this circle so that that the flux is the largest?  Well, the answer is it doesn't matter. ", "Now, let's just finish quickly by answering a question that  some of you, I am sure, must have,  which is what does divergence mean and what does it measure? ", "I mean, we said for curl, curl measures how much things  are rotating somehow. What does divergence mean?  Well, the answer is divergence measures how much things are ", "diverging. Let's be more explicit. ", "Interpretation of divergence. You can think of it, ", "you know, what do I want to say first?  If you take a vector field that is a constant vector field where  everything just translates then there is no divergence involved ", "because the derivatives will be zero.  If you take the guy that rotates things around you will  also compute and find zero for divergence.  This is not sensitive to translation motions where ", "everything moves together or to rotation motions,  but instead it is sensitive to explaining motions.  A possible answer is that it measures how much the flow is ", "expanding areas. If you imagine this flow that  we have here on the picture, things are moving away from the ", "origin and they fill out the plane.  If we mention this fluid flowing out there,  it is occupying more and more space.  And so that is what it means to have positive divergence. ", "If you took the opposite vector field that contracts everything  to the origin that will have negative divergence.  That is a good way to think about it if you are thinking of ", "a gas maybe that can expand to fill out more volume.  If you thinking of water, well, water doesn't really  shrink or expand. The fact that it is taking more  and more space actually means that there is more and more ", "water. The other way to think about it  is divergence is the source rate, ", "it is the amount of fluid that is being inserted into the  system, that is being pumped into the ", "system per unit time per unit area. ", "What div F equals two here means is that here you actually  have matter being created or being pumped into the system so  that you have more and more water filling more and more ", "space as it flows. But, actually,  divergence is not two just at the origin.  It is two everywhere. So, in fact,  to have this you need to have a system of pumps that actually is ", "in something water absolutely everywhere uniformly.  That is the only way to do this. I mean if you imagine that you  just have one spring at the origin then,  sure, water will flow out, but as you go further and ", "further away it will do so more and more slowly.  Well, here it is flowing away faster and faster.  And that means everywhere you are still pumping more water  into it. So, that is what divergence ", "measures. "], "vid_duration": [11.0, 11.0, 15.0, 11.0, 17.0, 11.0, 12.0, 11.0, 15.0, 12.0, 16.0, 22.0, 11.0, 11.0, 12.0, 11.0, 18.0, 16.0, 10.0, 14.0, 11.0, 10.0, 10.0, 13.0, 12.0, 17.0, 12.0, 12.0, 19.0, 12.0, 13.0, 11.0, 10.0, 19.0, 10.0, 14.0, 17.0, 10.0, 12.0, 14.0, 14.0, 12.0, 11.0, 13.0, 12.0, 12.0, 11.0, 11.0, 10.0, 11.0, 17.0, 10.0, 18.0, 17.0, 11.0, 18.0, 13.0, 12.0, 11.0, 13.0, 11.0, 13.0, 12.0, 11.0, 21.0, 15.0, 13.0, 16.0, 12.0, 11.0, 12.0, 13.0, 15.0, 14.0, 10.0, 12.0, 14.0, 10.0, 11.0, 18.0, 13.0, 10.0, 16.0, 11.0, 11.0, 10.0, 11.0, 10.0, 12.0, 14.0, 11.0, 10.0, 17.0, 12.0, 16.0, 13.0, 11.0, 14.0, 21.0, 12.0, 12.0, 17.0, 11.0, 10.0, 11.0, 12.0, 49.0, 17.0, 11.0, 16.0, 12.0, 10.0, 12.0, 10.0, 18.0, 14.0, 21.0, 10.0, 12.0, 12.0, 15.0, 16.0, 13.0, 11.0, 10.0, 11.0, 15.0, 15.0, 15.0, 13.0, 14.0, 11.0, 25.0, 10.0, 13.0, 10.0, 12.0, 15.0, 11.0, 14.0, 10.0, 12.0, 18.0, 13.0, 17.0, 12.0, 20.0, 12.0, 17.0, 18.0, 10.0, 12.0, 11.0, 12.0, 15.0, 12.0, 21.0, 14.0, 13.0, 19.0, 11.0, 11.0, 11.0, 33.0, 10.0, 13.0, 17.0, 13.0, 10.0, 10.0, 17.0, 12.0, 10.0, 14.0, 12.0, 12.0, 17.0, 10.0, 11.0, 10.0, 13.0, 12.0, 12.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 10.0, 14.0, 28.0, 24.0, 14.0, 11.0, 17.0, 13.0, 13.0, 10.0, 11.0, 12.0, 11.0, 10.0, 10.0, 13.0, 10.0, 10.0, 12.0, 13.0, 15.0, 12.0, 12.0, 11.0, 21.0, 10.0, 10.0, 10.0, 12.0, 10.0, 16.0, 15.0, 12.0, 10.0, 11.0, 11.0, 1.65], "stet": [[0, 11.0], [11.0, 22.0], [22.0, 37.0], [37.0, 48.0], [48.0, 65.0], [65.0, 76.0], [76.0, 88.0], [88.0, 99.0], [99.0, 114.0], [114.0, 126.0], [126.0, 142.0], [142.0, 164.0], [164.0, 175.0], [175.0, 186.0], [186.0, 198.0], [198.0, 209.0], [209.0, 227.0], [227.0, 243.0], [243.0, 253.0], [253.0, 267.0], [267.0, 278.0], [278.0, 288.0], [288.0, 298.0], [298.0, 311.0], [311.0, 323.0], [323.0, 340.0], [340.0, 352.0], [352.0, 364.0], [364.0, 383.0], [383.0, 395.0], [395.0, 408.0], [408.0, 419.0], [419.0, 429.0], [429.0, 448.0], [448.0, 458.0], [458.0, 472.0], [472.0, 489.0], [489.0, 499.0], [499.0, 511.0], [511.0, 525.0], [525.0, 539.0], [539.0, 551.0], [551.0, 562.0], [562.0, 575.0], [575.0, 587.0], [587.0, 599.0], [599.0, 610.0], [610.0, 621.0], [621.0, 631.0], [631.0, 642.0], [642.0, 659.0], [659.0, 669.0], [669.0, 687.0], [687.0, 704.0], [704.0, 715.0], [715.0, 733.0], [733.0, 746.0], [746.0, 758.0], [758.0, 769.0], [769.0, 782.0], [782.0, 793.0], [793.0, 806.0], [806.0, 818.0], [818.0, 829.0], [829.0, 850.0], [850.0, 865.0], [865.0, 878.0], [878.0, 894.0], [894.0, 906.0], [906.0, 917.0], [917.0, 929.0], [929.0, 942.0], [942.0, 957.0], [957.0, 971.0], [971.0, 981.0], [981.0, 993.0], [993.0, 1007.0], [1007.0, 1017.0], [1017.0, 1028.0], [1028.0, 1046.0], [1046.0, 1059.0], [1059.0, 1069.0], [1069.0, 1085.0], [1085.0, 1096.0], [1096.0, 1107.0], [1107.0, 1117.0], [1117.0, 1128.0], [1128.0, 1138.0], [1138.0, 1150.0], [1150.0, 1164.0], [1164.0, 1175.0], [1175.0, 1185.0], [1185.0, 1202.0], [1202.0, 1214.0], [1214.0, 1230.0], [1230.0, 1243.0], [1243.0, 1254.0], [1254.0, 1268.0], [1268.0, 1289.0], [1289.0, 1301.0], [1301.0, 1313.0], [1313.0, 1330.0], [1330.0, 1341.0], [1341.0, 1351.0], [1351.0, 1362.0], [1362.0, 1374.0], [1374.0, 1423.0], [1423.0, 1440.0], [1440.0, 1451.0], [1451.0, 1467.0], [1467.0, 1479.0], [1479.0, 1489.0], [1489.0, 1501.0], [1501.0, 1511.0], [1511.0, 1529.0], [1529.0, 1543.0], [1543.0, 1564.0], [1564.0, 1574.0], [1574.0, 1586.0], [1586.0, 1598.0], [1598.0, 1613.0], [1613.0, 1629.0], [1629.0, 1642.0], [1642.0, 1653.0], [1653.0, 1663.0], [1663.0, 1674.0], [1674.0, 1689.0], [1689.0, 1704.0], [1704.0, 1719.0], [1719.0, 1732.0], [1732.0, 1746.0], [1746.0, 1757.0], [1757.0, 1782.0], [1782.0, 1792.0], [1792.0, 1805.0], [1805.0, 1815.0], [1815.0, 1827.0], [1827.0, 1842.0], [1842.0, 1853.0], [1853.0, 1867.0], [1867.0, 1877.0], [1877.0, 1889.0], [1889.0, 1907.0], [1907.0, 1920.0], [1920.0, 1937.0], [1937.0, 1949.0], [1949.0, 1969.0], [1969.0, 1981.0], [1981.0, 1998.0], [1998.0, 2016.0], [2016.0, 2026.0], [2026.0, 2038.0], [2038.0, 2049.0], [2049.0, 2061.0], [2061.0, 2076.0], [2076.0, 2088.0], [2088.0, 2109.0], [2109.0, 2123.0], [2123.0, 2136.0], [2136.0, 2155.0], [2155.0, 2166.0], [2166.0, 2177.0], [2177.0, 2188.0], [2188.0, 2221.0], [2221.0, 2231.0], [2231.0, 2244.0], [2244.0, 2261.0], [2261.0, 2274.0], [2274.0, 2284.0], [2284.0, 2294.0], [2294.0, 2311.0], [2311.0, 2323.0], [2323.0, 2333.0], [2333.0, 2347.0], [2347.0, 2359.0], [2359.0, 2371.0], [2371.0, 2388.0], [2388.0, 2398.0], [2398.0, 2409.0], [2409.0, 2419.0], [2419.0, 2432.0], [2432.0, 2444.0], [2444.0, 2456.0], [2456.0, 2467.0], [2467.0, 2478.0], [2478.0, 2489.0], [2489.0, 2501.0], [2501.0, 2513.0], [2513.0, 2525.0], [2525.0, 2535.0], [2535.0, 2549.0], [2549.0, 2577.0], [2577.0, 2601.0], [2601.0, 2615.0], [2615.0, 2626.0], [2626.0, 2643.0], [2643.0, 2656.0], [2656.0, 2669.0], [2669.0, 2679.0], [2679.0, 2690.0], [2690.0, 2702.0], [2702.0, 2713.0], [2713.0, 2723.0], [2723.0, 2733.0], [2733.0, 2746.0], [2746.0, 2756.0], [2756.0, 2766.0], [2766.0, 2778.0], [2778.0, 2791.0], [2791.0, 2806.0], [2806.0, 2818.0], [2818.0, 2830.0], [2830.0, 2841.0], [2841.0, 2862.0], [2862.0, 2872.0], [2872.0, 2882.0], [2882.0, 2892.0], [2892.0, 2904.0], [2904.0, 2914.0], [2914.0, 2930.0], [2930.0, 2945.0], [2945.0, 2957.0], [2957.0, 2967.0], [2967.0, 2978.0], [2978.0, 2989.0], [2989.0, 2990.65]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [968, 1863, 2991]}
{"example_id": "mit002@@ocw-18_02-f07-lec13_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.   Last time we saw things about gradients and directional  derivatives. Before that we studied how to ", "look for minima and maxima of functions of several variables.  And today we are going to look again at min/max problems but in  a different setting, namely, one for variables that ", "are not independent. And so what we will see is you  may have heard of Lagrange multipliers.  And this is the one point in the term when I can shine with ", "my French accent and say Lagrange's name properly.  OK. What are Lagrange multipliers  about? Well, the goal is to minimize ", "or maximize a function of several variables.  Let's say, for example, f of x, y, z,  but where these variables are no longer independent. ", "", "They are not independent. That means that there is a  relation between them. The relation is maybe some  equation of the form g of x, y, z equals some constant. ", "You take the relation between x, y, z, you call that g and  that gives you the constraint. And your goal is to minimize f ", "only of those values of x, y, z that satisfy the  constraint. What is one way to do that?  Well, one to do that, if the constraint is very  simple, we can maybe solve for one of the variables. ", "Maybe we can solve this equation for one of the  variables, plug it back into f, and then we have a usual  min/max problem that we have seen how to do. ", "The problem is sometimes you cannot actually solve for x,  y, z in here because this condition is too complicated and  then we need a new method. That is what we are going to do. ", "Why would we care about that? Well, one example is actually  in physics. Maybe you have seen in  thermodynamics that you study quantities about gases,  and those quantities that involve pressure, ", "volume and temperature. And pressure,  volume and temperature are not independent of each other.  I mean you know probably the equation PV = NRT.  And, of course, there you could actually solve ", "to express things in terms of one or the other.  But sometimes it is more convenient to keep all three  variables but treat them as constrained.  It is just an example of a situation where you might want ", "to do this. Anyway, we will look mostly at  particular examples, but just to point out that this  is useful when you study guesses in physics. ", "The first observation is we cannot use our usual method of  looking for critical points of f.  Because critical points of f typically will not satisfy this  condition and so won't be good solutions. ", "We need something else. Let's look at an example,  and we will see how that leads us to the method. ", "For example, let's say that I want to find ", "the point closest to the origin -- -- on the hyperbola xy equals ", "3 in the plane. That means I have this  hyperbola, and I am asking myself what is the point on it  that is the closest to the origin? ", "I mean we can solve this by elementary geometry,  we don't need actually Lagrange multipliers,  but we are going to do it with Lagrange multipliers because it  is a pretty good example. What does it mean? ", "Well, it means that we want to minimize distance to the origin.  What is the distance to the origin?  If I have a point, at coordinates (x, ", "y) and then the distance to the origin is square root of x  squared plus y squared. Well, do we really want to  minimize that or can we minimize something easier? ", "Yeah. Maybe we can minimize the  square of a distance. Let's forget this guy and  instead -- Actually, we will minimize f of x, ", "y equals x squared plus y squared,  that looks better, subject to the constraint xy = ", "3. And so we will call this thing  g of x, y to illustrate the general method. ", "Let's look at a picture. Here you can see in yellow the  hyperbola xy equals three. And we are going to look for ", "the points that are the closest to the origin.  What can we do? Well, for example,  we can plot the function x squared plus y squared, ", "function f. That is the contour plot of f  with a hyperbola on top of it. Now let's see what we can do  with that. Well, let's ask ourselves, ", "for example, if I look at points where f  equals 20 now. I think I am at 20 but you  cannot really see it. That is a circle with a point ", "whose distant square is 20. Well, can I find a solution if  I am on the hyperbola? Yes, there are four points at  this distance. Can I do better?  Well, let's decrease for distance. ", "Yes, we can still find points on the hyperbola and so on.  Except if we go too low then there are no points on this  circle anymore in the hyperbola. If we decrease the value of f ", "that we want to look at that will somehow limit value beyond  which we cannot go, and that is the minimum of f.  We are trying to look for the smallest value of f that will ", "actually be realized on the hyperbola.  When does that happen? Well, I have to backtrack a  little bit. It seems like the limiting case ", "is basically here. It is when the circle is  tangent to the hyperbola. That is the smallest circle  that will hit the hyperbola. If I take a larger value of f, ", "I will have solutions. If I take a smaller value of f,  I will not have any solutions anymore.  So, that is the situation that we want to solve for. ", "How do we find that minimum? Well, a key observation that is  valid on this picture, and that actually remain true  in the completely general case, is that when we have a minimum ", "the level curve of f is actually tangent to our hyperbola.  It is tangent to the set of points where x, ", "y equals three, to the hyperbola.  Let's write that down. We observe that at the minimum ", "the level curve of f is tangent to the hyperbola. ", "Remember, the hyperbola is given by the equal g equals  three, so it is a level curve of g.  We have a level curve of f and a level curve of g that are ", "tangent to each other. And I claim that is going to be  the general situation that we are interested in.  How do we try to solve for points where this happens? ", "", "How do we find x, y where the level curves of f  and g are tangent to each other? Let's think for a second. ", "If the two level curves are tangent to each other that means  they have the same tangent line. That means that the normal ", "vectors should be parallel. Let me maybe draw a picture  here. This is the level curve maybe f  equals something. And this is the level curve g ", "equals constant. Here my constant is three.  Well, if I look for gradient vectors, the gradient of f will  be perpendicular to the level curve of f. ", "The gradient of g will be perpendicular to the level curve  of g. They don't have any reason to  be of the same size, but they have to be parallel to  each other. Of course, they could also be ", "parallel pointing in opposite directions.  But the key point is that when this happens the gradient of f ", "is parallel to the gradient of g.  Well, let's check that. Here is a point. ", "And I can plot the gradient of f in blue.  The gradient of g in yellow. And you see,  in most of these places, somehow the two gradients are  not really parallel. Actually, I should not be ", "looking at random points. I should be looking only on the  hyperbola. I want points on the hyperbola  where the two gradients are parallel.  Well, when does that happen? Well, it looks like it will ", "happen here. When I am at a minimum,  the two gradient vectors are parallel.  It is not really proof. It is an example that seems to  be convincing. So far things work pretty well. ", "How do we decide if two vectors are parallel?  Well, they are parallel when they are proportional to each  other. You can write one of them as a ", "constant times the other one, and that constant usually one  uses the Greek letter lambda. I don't know if you have seen ", "it before. It is the Greek letter for L.  And probably, I am sure, it is somebody's  idea of paying tribute to Lagrange by putting an L in ", "there. Lambda is just a constant.  And we are looking for a scalar lambda and points x and y where  this holds. In fact, ", "what we are doing is replacing min/max problems in two  variables with a constraint between them by a set of  equations involving, you will see, three variables. ", "We had min/max with two variables x, y,  but no independent. We had a constraint g of x, ", "y equals constant. And that becomes something new.  That becomes a system of equations where we have to ", "solve, well, let's write down what it means for gradient f to  be proportional to gradient g. That means that f sub x should ", "be lambda times g sub x, and f sub y should be lambda  times g sub y. Because the gradient vectors ", "here are f sub x, f sub y and g sub x,  g sub y. If you have a third variable z  then you have also an equation f sub z equals lambda g sub z. ", "Now, let's see. How many unknowns do we have in  these equations? Well, there is x,  there is y and there is lambda. We have three unknowns and have ", "only two equations. Something is missing.  Well, I mean x and y are not actually independent.  They are related by the equation g of x, ", "y equals c, so we need to add the constraint g equals c.  And now we have three equations involving three variables. ", "Let's see how that works. Here remember we have f equals ", "x squared y squared and g = xy. What is f sub x?  It is going to be 2x equals lambda times, ", "what is g sub x, y.  Maybe I should write here f sub x equals lambda g sub x just to  remind you. Then we have f sub y equals ", "lambda g sub y. F sub y is 2y equals lambda  times g sub y is x. And then our third equation g ", "equals c becomes xy equals three.  So, that is what you would have to solve.  Any questions at this point? No. ", "Yes? How do I know the direction of ", "a gradient? Do you mean how do I know that  it is perpendicular to a level curve?  Oh, how do I know if it points in that direction on the ", "opposite one? Well, that depends.  I mean we'd seen in last time, but the gradient is  perpendicular to the level and points towards higher values of  a function. So it could be -- Wait. ", "What did I have? It could be that my gradient  vectors up there actually point in opposite directions.  It doesn't matter to me because it will still look the same in ", "terms of the equation, just lambda will be positive or  negative, depending on the case. I can handle both situations.  It's not a problem. I can allow lambda to be ", "positive or negative. Well, in this example,  it looks like lambda will be positive.  If you look at the picture on the plot.  Yes? Well, because actually they are ", "not equal to each other. If you look at this point where  the hyperbola and the circle touch each other,  first of all, I don't know which circle I am ", "going to look at. I am trying to solve,  actually, for the radius of the circle.  I am trying to find what the minimum value of f is.  And, second, at that point, ", "the value of f and the value of g are not equal.  g is equal to three because I want the hyperbola x equals  three. The value of f will be the  square of a distance, whatever that is. ", "I think it will end up being 6, but we will see.  So, you cannot really set them equal because you don't know  what f is equal to in advance. Yes? ", "Not quite. Actually, here I am just using  this idea of finding a point closest to the origin to  illustrate an example of a min/max problem. ", "The general problem we are trying to solve is minimize f  subject to g equals constant. And what we are going to do for  that is we are really going to say instead let's look at places ", "where gradient f and gradient g are parallel to each other and  solve for equations of that. I think we completely lose the  notion of closest point if we just look at these equations. ", "We don't really say anything about closest points anymore.  Of course, that is what they mean in the end.  But, in the general setting, there is no closest point  involved anymore. OK. ", "Yes? Yes.  It is always going to be the case that, ", "at the minimum, or at the maximum of a function  subject to a constraint, the level curves of f and the  level curves of g will be tangent to each other.  That is the basis for this method. ", "I am going to justify that soon. It could be minimum or maximum.  In three-dimensions it could even be a saddle point.  And, in fact, I should say in advance,  this method will not tell us whether it is a minimum or a ", "maximum. We do not have any way of  knowing, except for testing values.  We cannot use second derivative tests or anything like that.  I will get back to that. Yes? ", "Yes. Here you can set y equals to  favor x. Then you can minimize x squared  plus nine over x squared. In general, if I am trying to  solve a more complicated problem, I might not be able to ", "solve. I am doing an example where,  indeed, here you could solve and remove one variable,  but you cannot always do that. And this method will still work.  The other one won't. OK. ", "I don't see any other questions. Are there any other questions?  No. OK.  I see a lot of students stretching and so on, ", "so it is very confusing for me. How do we solve these equations?  Well, the answer is in general we might be in deep trouble. ", "There is no general method for solving the equations that you  get from this method. You just have to think about  them. Sometimes it will be very easy. ", "Sometimes it will be so hard that you cannot actually do it  without the computer. Sometimes it will be just hard  enough to be on Part B of this week's problem set.  ", "I claim in this case we can actually do it without so much  trouble, because actually we can think of this as a two by two ", "linear system in x and y. Well, let me do something.  Let me rewrite the first two equations as 2x - lambda y = 0. ", "And lambda x - 2y = 0. And xy = 3. ", "That is what we want to solve. Well, I can put this into  matrix form. Two minus lambda, ", "lambda minus two times x, y equals 0,0.  Now, how do I solve a linear system matrix times x, ", "y equals zero? Well, I always have an obvious  solution. X and y both equal to zero.  Is that a good solution? No, because zero times zero is ", "not three. We want another solution,  the trivial solution. 0,0 does not solve the ", "constraint equation xy equals three, so we want another  solution. When do we have another ", "solution? Well, when the determinant of a  matrix is zero. We have other solutions that ", "exist only if determinant of a matrix is zero.  M is this guy. Let's compute the determinant. ", "Well, that seems to be negative four plus lambda squared.  That is zero exactly when lambda squared equals four, ", "which is lambda is plus or minus two.  Already you see here it is a the level of difficulty that is ", "a little bit much for an exam but perfectly fine for a problem  set or for a beautiful lecture like this one.  How do we deal with -- Well, we have two cases to look at. ", "Lambda equals two or lambda equals minus two.  Let's start with lambda equals two.  If I set lambda equals two, what does this equation become? ", "Well, it becomes x equals y. This one becomes y equals x.  Well, they seem to be the same. x equals y. ", "And then the equation xy equals three becomes,  well, x squared equals three. I have two solutions.  One is x equals root three and, therefore, y equals root three ", "as well, or negative root three and negative root three.  Let's look at the other case. If I set lambda equal to ", "negative two then I get 2x equals negative 2y.  That means x equals negative y. The second one, ", "2y equals negative 2x. That is y equals negative x.  Well, that is the same thing. And xy equals three becomes  negative x squared equals three. Can we solve that? ", "No. There are no solutions here.  Now we have two candidate points which are these two ", "points, root three, root three or negative root  three, negative root three. OK. ", "Let's actually look at what we have here.  Maybe you cannot read the coordinates, but the point that  I have here is indeed root three, root three. ", "How do we see that lambda equals two?  Well, if you look at this picture, the gradient of f,  that is the blue vector, is indeed twice the yellow  vector, gradient g. That is where you read the ", "value of lambda. And we have the other solution  which is somewhere here. Negative root three,  negative root there. And there, again, ", "lambda equals two. The two vectors are  proportional by a factor of two. Yes? ", "No, solutions are not quite guaranteed to be absolute minima  or maxima. They are guaranteed to be  somehow critical points end of a constraint.  That means if you were able to solve and eliminate the variable ", "that would be a critical point. When you have the same problem,  as we have critical points, are they maxima or minima?  And the answer is, well, we won't know until we ", "check. More questions?  No. Yes? ", "What is a Lagrange multiplier? Well, it is this number lambda  that is called the multiplier here.  It is a multiplier because it is what you have to multiply ", "gradient of g by to get gradient of f.  It multiplies.  ", "Let's try to see why is this method valid?  Because so far I have shown you pictures and have said see they ", "are tangent. But why is it that they have to  be tangent in general? Let's think about it. ", "Let's say that we are at constrained min or max.  What that means is that if I move on the level g equals ", "constant then the value of f should only increase or only  decrease. But it means,  in particular, to first order it will not ", "change. At an unconstrained min or max,  partial derivatives are zero. In this case,  derivatives are zero only in the allowed directions.  And the allowed directions are those that stay on the levels of ", "this g equals constant. In any direction along the ", "level set g = c the rate of change of f must be zero. ", "That is what happens at minima or maxima.  Except here, of course, we look only at the  allowed directions. Let's say the same thing in ", "terms of directional derivatives.  ", "That means for any direction that is tangent to the ", "constraint level g equal c, we must have df over ds in the ", "direction of u equals zero. I will draw a picture. ", "Let's say now I am in three variables just to give you  different examples. Here I have a level surface g  equals c. I am at my point. ", "And if I move in any direction that is on the level surface,  so I move in the direction u tangent to the level surface, ", "then the rate of change of f in that direction should be zero.  Now, remember what the formula is for this guy. ", "Well, we have seen that this guy is actually radiant f dot u. ", "That means any such vector u must be perpendicular to the ", "gradient of f. That means that the gradient of  f should be perpendicular to anything that is tangent to this ", "level. That means the gradient of f  should be perpendicular to the level set.  That is what we have shown.  ", "But we know another vector that is also perpendicular to the  level set of g. That is the gradient of g. ", "We conclude that the gradient of f must be parallel to the  gradient of g because both are perpendicular to the level set ", "of g. I see confused faces,  so let me try to tell you again where that comes from.  We said if we had a constrained minimum or maximum,  if we move in the level set of g, f doesn't change. ", "Well, it doesn't change to first order.  It is the same idea as when you are looking for a minimum you  set the derivative equal to zero.  So the derivative in any direction, tangent to g equals ", "c, should be the directional derivative of f,  in any such direction, should be zero.  That is what we mean by critical point of f. ", "And so that means that any vector u, any unit vector  tangent to the level set of g is going to be perpendicular to the ", "gradient of f. That means that the gradient of  f is perpendicular to the level set of g.  If you want, that means the level sets of f ", "and g are tangent to each other. That is justifying what we have  observed in the picture that the two level sets have to be  tangent to each other at the prime minimum or maximum. ", "Does that make a little bit of sense?  Kind of. I see at least a few faces  nodding so I take that to be a positive answer. ", "Since I have been asked by several of you,  how do I know if it is a maximum or a minimum?  Well, warning, the method doesn't tell whether ", "a solution is a minimum or a maximum. ", "How do we do it? Well, more bad news.  We cannot use the second derivative test. ", "And the reason for that is that we care actually only about  these specific directions that are tangent to variable of g.  And we don't want to bother to try to define directional second ", "derivatives. Not to mention that actually it  wouldn't work. There is a criterion but it is  much more complicated than that. Basically, the answer for us is ", "that we don't have a second derivative test in this  situation. What are we left with?  Well, we are just left with comparing values.  Say that in this problem you found a point where f equals ", "three, a point where f equals nine, a point where f equals 15.  Well, then probably the minimum is the point where f equals  three and the maximum is 15. Actually, in this case, ", "where we found minima, these two points are tied for  minimum. What about the maximum?  What is the maximum of f on the hyperbola? ", "Well, it is infinity because the point can go as far as you  want from the origin. But the general idea is if we  have a good reason to believe that there should be a minimum, ", "and it's not like at infinity or something weird like that,  then the minimum will be a solution of the Lagrange  multiplier equations. We just look for all the ", "solutions and then we choose the one that gives us the lowest  value. Is that good enough?  Let me actually write that down. ", "", "To find the minimum or the maximum, we compare values of f ", "at the various solutions -- -- to Lagrange multiplier ", "equations.  ", "I should say also that sometimes you can just conclude  by thinking geometrically. In this case,  when it is asking you which point is closest to the origin ", "you can just see that your answer is the correct one.  Let's do an advanced example. Advanced means that -- Well, ", "this one I didn't actually dare to put on top of the other  problem sets. Instead, I am going to do it. ", "What is this going to be about? We are going to look for a  surface minimizing pyramid. Let's say that we want to build ", "a pyramid with a given triangular base -- -- and a ", "given volume. Say that I have maybe in the x,  y plane I am giving you some triangle. ", "And I am going to try to build a pyramid.  Of course, I can choose where to put the top of a pyramid. ", "This guy will end up being behind now.  And the constraint and the goal is to minimize the total surface ", "area. The first time I taught this  class, it was a few years ago, was just before they built the  Stata Center. And then I used to motivate  this problem by saying Frank Gehry has gone crazy and has ", "been given a triangular plot of land he wants to put a pyramid.  There needs to be the right amount of volume so that you can  put all the offices in there. And he wants it to be,  actually, covered in solid gold. ", "And because that is expensive, the administration wants him to  cut the costs a bit. And so you have to minimize the  total size so that it doesn't cost too much. ", "We will see if MIT comes up with a triangular pyramid  building. Hopefully not.  It could be our next dorm, you never know. ", "Anyway, it is a fine geometry problem.  Let's try to think about how we can do this.  The natural way to think about it would be -- Well, ", "what do we have to look for first?  We have to look for the position of that top point.  Remember we know that the volume of a pyramid is one-third ", "the area of base times height. In fact, fixing the volume,  knowing that we have fixed the area of a base, ", "means that we are fixing the height of the pyramid.  The height is completely fixed. What we have to choose just is  where do we put that top point? Do we put it smack in the ", "middle of a triangle or to a side or even anywhere we want?  Its z coordinate is fixed. Let's call h the height. ", "What we could do is something like this.  We say we have three points of a base.  Let's call them p1 at (x1, y1,0); p2 at (x2, ", "y2,0); p3 at (x3, y3,0).  This point p is the unknown point at (x, y,  h). We know the height. ", "And then we want to minimize the sum of the areas of these  three triangles. One here, one here and one at  the back. And areas of triangles we know ", "how to express by using length of cross-product.  It becomes a function of x and y.  And you can try to minimize it. Actually, it doesn't quite work. ", "The formulas are just too complicated.  You will never get there. What happens is actually maybe ", "we need better coordinates. Why do we need better  coordinates? That is because the geometry is  kind of difficult to do if you use x, y coordinates. ", "I mean formula for cross-product is fine,  but then the length of the vector will be annoying and just  doesn't look good. Instead, let's think about it ", "differently.  ", "I claim if we do it this way and we express the area as a  function of x, y, well, actually we can't ", "solve for a minimum. Here is another way to do it.  Well, what has worked pretty well for us so far is this ", "geometric idea of base times height.  So let's think in terms of the heights of side triangles. ", "I am going to use the height of these things.  And I am going to say that the area will be the sum of three ", "terms, which are three bases times three heights.  Let's give names to these quantities. ", "Actually, for that it is going to be good to have the point in  the xy plane that lives directly below p.  Let's call it q. P is the point that coordinates ", "x, y, h. And let's call q the point that  is just below it and so it' coordinates are x, ", "y, 0. Let's see.  Let me draw a map of this thing. p1, p2, p3 and I have my point ", "q in the middle. Let's see.  To know these areas, I need to know the base.  Well, the base I can decide that I know it because it is ", "part of my given data. I know the sides of this  triangle. Let me call the lengths a1,  a2, a3. I also need to know the height, ", "so I need to know these lengths.  How do I know these lengths? Well, its distance in space,  but it is a little bit annoying.  But maybe I can reduce it to a distance in the plane by looking ", "instead at this distance here. Let me give names to the  distances from q to the sides. Let's call u1, ", "u2, u3 the distances from q to the sides. ", "", "Well, now I can claim I can find, actually,  sorry. I need to draw one more thing.  I claim I have a nice formula for the area, ", "because this is vertical and this is horizontal so this  length here is u3, this length here is h.  So what is this length here? It is the square root of u3 ", "squared plus h squared. And similarly for these other  guys. They are square roots of a u ", "squared plus h squared. The heights of the faces are  square root of u1 squared times h squared. ", "And similarly with u2 and u3. So the total side area is going  to be the area of the first faces, ", "one-half of base times height, plus one-half of a base times a ", "height plus one-half of the third one.  It doesn't look so much better. But, trust me, ", "it will get better. Now, that is a function of  three variables, u1, u2, u3. ", "And how do we relate u1, u2, u3 to each other?  They are probably not independent.  Well, let's cut this triangle here into three pieces like ", "that. Then each piece has side --  Well, let's look at it the piece of the bottom.  It has base a3, height u3. Cutting base into three tells ", "you that the area of a base is one-half of a1,  u1 plus one-half of a2, u2 plus one-half of a3, ", "u3. And that is our constraint.  My three variables, u1, u2, u3, are constrained in  this way. The sum of this figure must be ", "the area of a base. And I want to minimize that guy.  So that is my g and that guy here is my f.  Now we try to apply our Lagrange multiplier equations. ", "Well, partial f of a partial u1 is -- Well,  if you do the calculation, you will see it is one-half a1,  u1 over square root of u1^2 plus h^2 equals lambda, ", "what is partial g, partial a1?  That one you can do, I am sure. It is one-half a1.  Oh, these guys simplify. If you do the same with the ", "second one -- -- things simplify again.  And the same with the third one. Well, you will get, ", "after simplifying, u3 over square root of u3  squared plus h squared equals lambda.  Now, that means this guy equals this guy equals this guy. ", "They are all equal to lambda. And, if you think about it,  that means that u1 = u2 = u3. See, it looked like scary ", "equations but the solution is very simple.  What does it mean? It means that our point q  should be equidistant from all three sides.  That is called the incenter. Q should be in the incenter. ", "The next time you have to build a golden pyramid and don't want  to go broke, well, you know where to put the top.  If that was a bit fast, sorry. Anyway, it is not completely ", "crucial. But go over it and you will see  it works. Have a nice weekend.  "], "vid_duration": [10.0, 13.0, 14.0, 14.0, 14.0, 14.0, 11.0, 10.0, 12.0, 11.0, 13.0, 12.0, 11.0, 18.0, 13.0, 11.0, 10.0, 10.0, 14.0, 12.0, 12.0, 12.0, 12.0, 18.0, 16.0, 11.0, 12.0, 11.0, 12.0, 12.0, 12.0, 11.0, 13.0, 10.0, 14.0, 12.0, 14.0, 12.0, 17.0, 17.0, 10.0, 13.0, 16.0, 19.0, 10.0, 14.0, 12.0, 12.0, 13.0, 15.0, 11.0, 14.0, 15.0, 11.0, 13.0, 15.0, 11.0, 14.0, 13.0, 12.0, 14.0, 10.0, 13.0, 12.0, 13.0, 12.0, 13.0, 13.0, 11.0, 15.0, 15.0, 11.0, 10.0, 11.0, 10.0, 15.0, 18.0, 10.0, 12.0, 12.0, 23.0, 10.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 15.0, 12.0, 14.0, 15.0, 12.0, 11.0, 25.0, 13.0, 15.0, 12.0, 11.0, 11.0, 10.0, 12.0, 10.0, 13.0, 24.0, 14.0, 10.0, 12.0, 10.0, 10.0, 18.0, 11.0, 11.0, 14.0, 12.0, 10.0, 10.0, 13.0, 12.0, 11.0, 10.0, 13.0, 10.0, 12.0, 20.0, 14.0, 10.0, 14.0, 11.0, 16.0, 12.0, 19.0, 14.0, 29.0, 12.0, 14.0, 11.0, 11.0, 13.0, 10.0, 10.0, 14.0, 12.0, 27.0, 20.0, 10.0, 12.0, 12.0, 12.0, 12.0, 11.0, 14.0, 15.0, 22.0, 12.0, 17.0, 13.0, 10.0, 11.0, 12.0, 10.0, 13.0, 11.0, 11.0, 26.0, 12.0, 11.0, 22.0, 10.0, 14.0, 16.0, 15.0, 16.0, 14.0, 15.0, 21.0, 11.0, 11.0, 11.0, 16.0, 12.0, 19.0, 10.0, 13.0, 23.0, 17.0, 10.0, 11.0, 11.0, 10.0, 10.0, 13.0, 17.0, 12.0, 11.0, 12.0, 14.0, 10.0, 15.0, 11.0, 15.0, 10.0, 12.0, 14.0, 14.0, 11.0, 12.0, 10.0, 16.0, 10.0, 13.0, 11.0, 11.0, 11.0, 10.0, 13.0, 18.0, 14.0, 10.0, 14.0, 15.0, 17.0, 17.0, 10.0, 12.0, 13.0, 11.0, 6.02], "stet": [[0, 10.0], [10.0, 23.0], [23.0, 37.0], [37.0, 51.0], [51.0, 65.0], [65.0, 79.0], [79.0, 90.0], [90.0, 100.0], [100.0, 112.0], [112.0, 123.0], [123.0, 136.0], [136.0, 148.0], [148.0, 159.0], [159.0, 177.0], [177.0, 190.0], [190.0, 201.0], [201.0, 211.0], [211.0, 221.0], [221.0, 235.0], [235.0, 247.0], [247.0, 259.0], [259.0, 271.0], [271.0, 283.0], [283.0, 301.0], [301.0, 317.0], [317.0, 328.0], [328.0, 340.0], [340.0, 351.0], [351.0, 363.0], [363.0, 375.0], [375.0, 387.0], [387.0, 398.0], [398.0, 411.0], [411.0, 421.0], [421.0, 435.0], [435.0, 447.0], [447.0, 461.0], [461.0, 473.0], [473.0, 490.0], [490.0, 507.0], [507.0, 517.0], [517.0, 530.0], [530.0, 546.0], [546.0, 565.0], [565.0, 575.0], [575.0, 589.0], [589.0, 601.0], [601.0, 613.0], [613.0, 626.0], [626.0, 641.0], [641.0, 652.0], [652.0, 666.0], [666.0, 681.0], [681.0, 692.0], [692.0, 705.0], [705.0, 720.0], [720.0, 731.0], [731.0, 745.0], [745.0, 758.0], [758.0, 770.0], [770.0, 784.0], [784.0, 794.0], [794.0, 807.0], [807.0, 819.0], [819.0, 832.0], [832.0, 844.0], [844.0, 857.0], [857.0, 870.0], [870.0, 881.0], [881.0, 896.0], [896.0, 911.0], [911.0, 922.0], [922.0, 932.0], [932.0, 943.0], [943.0, 953.0], [953.0, 968.0], [968.0, 986.0], [986.0, 996.0], [996.0, 1008.0], [1008.0, 1020.0], [1020.0, 1043.0], [1043.0, 1053.0], [1053.0, 1065.0], [1065.0, 1077.0], [1077.0, 1089.0], [1089.0, 1101.0], [1101.0, 1112.0], [1112.0, 1124.0], [1124.0, 1139.0], [1139.0, 1151.0], [1151.0, 1165.0], [1165.0, 1180.0], [1180.0, 1192.0], [1192.0, 1203.0], [1203.0, 1228.0], [1228.0, 1241.0], [1241.0, 1256.0], [1256.0, 1268.0], [1268.0, 1279.0], [1279.0, 1290.0], [1290.0, 1300.0], [1300.0, 1312.0], [1312.0, 1322.0], [1322.0, 1335.0], [1335.0, 1359.0], [1359.0, 1373.0], [1373.0, 1383.0], [1383.0, 1395.0], [1395.0, 1405.0], [1405.0, 1415.0], [1415.0, 1433.0], [1433.0, 1444.0], [1444.0, 1455.0], [1455.0, 1469.0], [1469.0, 1481.0], [1481.0, 1491.0], [1491.0, 1501.0], [1501.0, 1514.0], [1514.0, 1526.0], [1526.0, 1537.0], [1537.0, 1547.0], [1547.0, 1560.0], [1560.0, 1570.0], [1570.0, 1582.0], [1582.0, 1602.0], [1602.0, 1616.0], [1616.0, 1626.0], [1626.0, 1640.0], [1640.0, 1651.0], [1651.0, 1667.0], [1667.0, 1679.0], [1679.0, 1698.0], [1698.0, 1712.0], [1712.0, 1741.0], [1741.0, 1753.0], [1753.0, 1767.0], [1767.0, 1778.0], [1778.0, 1789.0], [1789.0, 1802.0], [1802.0, 1812.0], [1812.0, 1822.0], [1822.0, 1836.0], [1836.0, 1848.0], [1848.0, 1875.0], [1875.0, 1895.0], [1895.0, 1905.0], [1905.0, 1917.0], [1917.0, 1929.0], [1929.0, 1941.0], [1941.0, 1953.0], [1953.0, 1964.0], [1964.0, 1978.0], [1978.0, 1993.0], [1993.0, 2015.0], [2015.0, 2027.0], [2027.0, 2044.0], [2044.0, 2057.0], [2057.0, 2067.0], [2067.0, 2078.0], [2078.0, 2090.0], [2090.0, 2100.0], [2100.0, 2113.0], [2113.0, 2124.0], [2124.0, 2135.0], [2135.0, 2161.0], [2161.0, 2173.0], [2173.0, 2184.0], [2184.0, 2206.0], [2206.0, 2216.0], [2216.0, 2230.0], [2230.0, 2246.0], [2246.0, 2261.0], [2261.0, 2277.0], [2277.0, 2291.0], [2291.0, 2306.0], [2306.0, 2327.0], [2327.0, 2338.0], [2338.0, 2349.0], [2349.0, 2360.0], [2360.0, 2376.0], [2376.0, 2388.0], [2388.0, 2407.0], [2407.0, 2417.0], [2417.0, 2430.0], [2430.0, 2453.0], [2453.0, 2470.0], [2470.0, 2480.0], [2480.0, 2491.0], [2491.0, 2502.0], [2502.0, 2512.0], [2512.0, 2522.0], [2522.0, 2535.0], [2535.0, 2552.0], [2552.0, 2564.0], [2564.0, 2575.0], [2575.0, 2587.0], [2587.0, 2601.0], [2601.0, 2611.0], [2611.0, 2626.0], [2626.0, 2637.0], [2637.0, 2652.0], [2652.0, 2662.0], [2662.0, 2674.0], [2674.0, 2688.0], [2688.0, 2702.0], [2702.0, 2713.0], [2713.0, 2725.0], [2725.0, 2735.0], [2735.0, 2751.0], [2751.0, 2761.0], [2761.0, 2774.0], [2774.0, 2785.0], [2785.0, 2796.0], [2796.0, 2807.0], [2807.0, 2817.0], [2817.0, 2830.0], [2830.0, 2848.0], [2848.0, 2862.0], [2862.0, 2872.0], [2872.0, 2886.0], [2886.0, 2901.0], [2901.0, 2918.0], [2918.0, 2935.0], [2935.0, 2945.0], [2945.0, 2957.0], [2957.0, 2970.0], [2970.0, 2981.0], [2981.0, 2987.02]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1593, 2219, 2987]}
{"example_id": "mit002@@ocw-18_02-f07-lec29_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  OK, so remember we left things with this statement of the  divergence theorem. So, the divergence theorem ", "gives us a way to compute the flux of a vector field for a  closed surface. OK, it says if I have a closed  surface, s, bounding some region, D, ", "and I have a vector field defined in space,  so that I can try to compute the flux of my vector field ", "through my surface. Double integral of F.dS or  F.ndS if you want, and to set this up,  of course, I need to use the geometry of the surface ", "depending on what the surface is.  We've seen various formulas for how to set up the double  integral. But, we've also seen that if  it's a closed surface, and if a vector field is ", "defined everywhere inside, then we can actually reduce  that to a calculation of the triple integral of the ", "divergence of F inside, OK?  So, concretely, if I use  coordinates, let's say that the coordinates  of my vector field are, sorry, the components are P, ", "Q, and R dot ndS, then that will become the  triple integral of, well, so, divergence is P sub x ", "plus Q sub y plus R sub z. OK, so by the way,  how to remember this formula for divergence, ", "and other formulas for other things as well.  Let me just tell you quickly about the del notation. ", "So, this guy usually pronounced as  del, rather than as pointy triangle  going downwards or something like that, ", "it's a symbolic notation for an operator.  So, you're probably going to complain about putting these ", "guys into a vector. But, let's think of partial  with respect to x, with respect to y,  and with respect to z as the components of some formal  vector. Of course, it's not a real ", "vector. These are not like anything.  These are just symbols. But, so see for example,  the gradient of function, well, if you multiply this ", "vector by scalar, which is a function,  then you will get partial, partial x of f,  partial, partial y of f, partial, partial z, f, ", "well, that's the gradient. That seems to work.  So now, the interesting thing about divergence is I can think  of divergence as del dot a vector field. ", "See, if I do the dot product between this guy and my vector  field P, Q, R, well, it looks like I will ", "indeed get partial, partial x of P plus partial Q  partial y plus partial R partial z. ", "That's the divergence. and of course, similarly, ", "when we have two variables only, x and y,  we could have thought of the same notation,  just with a two component vector,  partial, partial x, partial, partial y. ", "So, now, this is like of slightly limited usefulness so  far. It's going to become very handy  pretty soon because we are going to see curl.  And, the formula for curl in the plane was kind of ", "complicated. But, if you thought about it in  terms of this, it was actually the determinant  of del and f. And now, in space,  we are actually going to do del cross f. ", "But, I'm getting ahead of things.  So, let's not do anything with that.  Curl will be for next week. Just getting you used to the ", "notation, especially since you might be using it in physics  already. So, it might be worth doing.  OK, so the other thing I wanted to say is, what does this ", "theorem say physically? How should I think of this  statement? So, I think I said that very  quickly at the end of last time, but not very carefully. ", "So, what's the physical interpretation of a divergence  field? So, ", "I want to claim that the divergence of a vector field  corresponds to what I'm going to call the source rate,  which is somehow the amount of flux generated per unit volume. ", "So, to understand what that means, let's think of what's  called an incompressible fluid. OK, so an incompressible fluid  is something like water, for example, ", "where a fixed mass of it always occupies the same amount of  volume. So, guesses are compressible.  Liquids are incompressible, basically. ", "So, if you have an incompressible fluid flow -- -- ", "well, so, again, what that means is really, ", "given mass occupies always a fixed volume. ", "Then, well, let's say that we have such a fluid with velocity  given by our vector field. OK, so we're thinking of F as ", "the velocity and maybe something containing water,  a pipe, or something. So, what does the divergence ", "theorem say? It says that if I take a region  in space, let's call it D, ", "sorry, D is the inside, and S is the surface around it,  well, so if I sum the divergence in D,  well, I'm going to get the flux going out through this surface, ", "S. I should have mentioned it  earlier. The convention in the  divergence theorem is that we orient the surface with a normal  vector pointing always outwards. OK, so now, we know what flux ", "means. Remember, we've been  describing, flux means how much fluid is passing through this  surface. So, that's the amount of fluid ", "that's leaving the region, D, per unit time. ", "And, of course, when I'm saying that,  it means I'm counting everything that's going out of D  minus everything that's coming into D.  That's what the flux measures. So, now, if there is stuff ", "coming into D or going out of D, well, it must come from  somewhere. So, one possibility would be  that your fluid is actually being compressed or expanded. ", "But, I've said, no, I'm looking at something  like water that you cannot squish into smaller volume.  So, in that case, the only explanation is that  there is something it here that actually is sucking up water or ", "producing more water. And so, integrating the  divergence gives you the total amount of sources minus the  amount of syncs that are inside this region. ", "So, the divergence itself measures basically the amount of  sources or syncs per unit volume in a given place. ", "And now, if you think about it that way,  well, it's basically the divergence  theorem is just stating something completely obvious ", "about all the matter that is leaving this region must come  from somewhere. So, that's basically how we ", "think about it. Now, of course,  if you're doing 8.02, then you might actually have  seen the divergence theorem already being used for things  that are more like force fields, say, electric fields and so on. ", "Well, I'll try to say a few things about that during the  last week of classes. But, then this kind of  interpretation doesn't quite work.  OK, any questions, generally speaking, ", "before we move on to the proof and other applications?  Yes? Oh, not the gradient. ", "So, yeah, the divergence of F measures the amount of sources  or syncs in there. Well, what makes it happen?  If you want, in a way, it's this theorem.  Or, in another way, if you think about it, ", "try to look at your favorite vector fields and compute their  divergence. And, if you take a vector field  where maybe everything is rotating,  a flow that's just rotating about some axis, ", "then you'll find that its divergence is zero.  If you, sorry? No, divergence is not equal to  the gradient. Sorry, there's a dot here that ", "maybe is not very big, but it's very important.  OK, so you take the divergence of a vector field.  Well, you take the gradient of a function.  So, if the gradient of a function is a vector, ", "the divergence of a vector field is a function.  So, somehow these guys go back and forth between.  So, I should have said, with new notations comes new ", "responsibility. I mean,  now that we have this nice, nifty notation that will let us  do gradient divergence and later curl in a unified way, ", "if you choose this notation you have to be really,  really careful what you put after it because otherwise it's  easy to get completely confused. OK, so divergence and gradients ", "are completely different things. The only thing they have in  common is that both are what's called a first order  differential operator. That means it involves the  first partial derivatives of whatever you put into it. ", "But, one of them goes from functions to vectors.  That's gradient. The other one goes from vectors  to functions. That's divergence.  And, curl later will go from vectors to vectors. ", "But, that will be later. Let's see, more questions? ", "No? OK, so let's see,  so how are we going to actually prove this theorem? ", "Well, if you remember how we prove Green's theorem a while  ago, the answer is we're going to do it exactly the same way.  So, if you don't remember, then I'm going to explain. ", "OK, so the first thing we need to do is actually a  simplification. So, instead of proving the  divergence theorem, namely, the equality up there, ", "I'm going to actually prove something easier.  I'm going to prove that the flux of a vector field that has ", "only a z component is actually equal to the triple integral of,  well, the divergence of this is just R sub z dV. ", "OK, now, how do I go back to the general case?  Well, I will just prove the same thing for a vector field  that has only an x component or only a y component.  And then, I will add these things together. ", "So, if you think carefully about what happens when you  evaluate this, you will have some formula for  ndS, and when you do the dot  product, you'll end up with the sum,  P times something plus Q times something plus R times ", "something. And basically,  we are just dealing with the last term, R times something,  and showing that it's equal to what it should be.  And then, we the three such terms together.  We'll get the general case. OK, so then we get the general ", "case by summing one such identity for each component. ", "I should say three such identities, one for each  component, whatever. Now, let's make a second ", "simplification because I'm still not feeling confident I can  prove this right away for any surface.  I'm going to do it first or what's called a vertically ", "simple region. OK, so vertically simple means  it will be something which I can setup an integral over the z  variable first easily. So, it's something that has a ", "bottom face, and a top face, and then some vertical sides.  OK, so let's say first what happens if the given region, ", "D, is vertically simple. So, vertically simple means it  looks like this. It has top. ", "It has a bottom. And, it has some vertical sides.  So, if you want, if I look at it from above, ", "it projects to some region in the xy plane.  Let's call that R. And, it lives between the top ", "face and the bottom face. Let's say the top face is z  equals z2 of (x, y).  Let's say the bottom face is z equals z1(x, y). ", "OK, and I don't need to know actual formulas.  I'm just going to work with these and prove things  independently of what the formulas will be for these  functions. OK, so anyway, ", "a vertically simple region is something that lives above a  part of the xy plane, and is between two graphs of  two functions. So, let's see what we can do in ", "that case. So, the right-hand side of this  equality, so that's the triple integral, let's start computing ", "it. OK, so of course we will not be  able to get a number out of it because we don't know,  actually, formulas for anything.  But at least we can start simplifying because the way this ", "region looks like, I should say this is D,  tells me that I can start setting up the triple integral  at least in the order where I integrate first over z. ", "OK, so I can actually do it as a triple integral with Rz dz  dxdy or dydx, doesn't matter. ", "So, what are the bounds on z? See, this is actually good  practice to remember how we set up triple integrals.  So, remember, when we did it first over z,  we start by fixing a point, x and y, ", "and for that value of x and y, we look at a small vertical  slice and see from where to where we have to go.  Well, we start at z equals whatever the value is at the ", "bottom, so, z1 of x and y. And, we go up to the top face,  z2 of x and y. Now, for x and y, ", "I'm not going to actually set up bounds because I've already  called R the quantity that I'm integrating.  So let me change this to, let's say, U or something like ", "that. If you already have an R,  I mean, there's not much risk for confusion,  but still. OK, so we're going to call U  the shadow of my region instead. So, now I want to integrate ", "over all values of x and y that are in the shadow of my region.  That means it's a double integral over this region,  U, which I haven't described to you.  So, I can't actually set up bounds for x and y. ", "But, I'm going to just leave it like this.  OK, now you see,  if you look at how you would start evaluating this, ", "well, the inner integral certainly is not scary because  you're integrating the derivative of R with respect to  z, integrating that with respect  to z. So, you should get R back. ", "OK, so triple integral over D of Rz dV becomes,  well, we'll have a double integral over U of,  so, the inner integral becomes R at the point on the top. ", "So, that means, remember, R is a function of x,  y, and z. And, in fact,  I will plug into it the value of z at the top, ", "so, z of xy minus the value of R at the point on the bottom, ", "x, y, z1 of x, y.  OK, any questions about this? No? ", "Is it looking vaguely believable?  Yeah? OK. So, now, let's compute the  other side because here we are stuck.  We won't be able to do anything else. ", "So, let's look at the flux integral.  OK, we have to look at the flux of this vector field through the  entire surface, S, which is the whole boundary ", "of D. So, that consists of a lot of  pieces, namely the top, bottom, and the sides. ", "OK, so the other side -- So, let me just remind you,  S is bottom plus top plus side of this vector field, ", "dot ndS equals, OK, so what do we have?  So first, we have to look at the bottom.  No, let's start with the top actually. ", "Sorry. OK, so let's start with the top. ", "So, just remind you, let's do all of them.  So, let's look at the top first. So, we need to set up the flux ", "integral for a vector field dot ndS.  We need to know what ndS is. Well, fortunately for us,  we know that the top face is going to be the graph of some  function of x and y. So, we've seen a formula for ", "ndS in this kind of situation, OK?  We have seen that ndS, sorry, so, just to remind you  this is the graph of a function z equals z2 of x, ", "y. So, we've seen ndS for that is  negative partial derivative of this function with respect to x, ", "negative partial z2 with respect to y,  one, dxdy. OK, and, well,  we can't compute these guys, but it's not a big deal because ", "if we do the dot product with   dot ndS, that will give us,  well, if you dot this with zero, zero, R,  these terms go away. You just have R dxdy. ", "So, that means that the double integral for flux through the  top of R vector field dot ndS becomes double integral of the ", "top of R dxdy. Now, how do we evaluate that,  actually? Well, so R is a function of x,  y, z. But we said, ", "we have only two variables that we're going to use.  We're going to use x and y. We're going to get rid of z.  How do we get rid of z? Well, if we are on the top  surface, z is given by this formula, z2 of x, ", "y. So, I plug z equals z2 of x,  y into the formula for R, whatever it may be.  Then, I integrate dxdy. And, what's the range for x and ", "y? Well, my surface sits exactly  above this region U in the xy plane.  So, it's double integral over U, OK? ", "Any questions about how I set up this flux integral?  No? OK, let me close the door, ", "actually. OK, so we've got one of the two  terms that we had over there. Let's try to get the others. ", "", "[LAUGHTER] No comment. OK, so, we need to look,  also, at the other parts of our surface for the flux integral. ", "So, the bottom, well, it will work pretty much  the same way, right, because it's the graph  of a function, z equals z1 of x, ", "y. So, we should be able to get  ndS using the same method, negative partial with respect ", "to x, negative partial with respect to y,  one dxdy. Now, there's a small catch.  OK, we have to think of it carefully about orientations. ", "So, remember, when we set up the  divergence theorem, we need the normal vectors to  point out of our region, which means that on the top ", "surface, we want n pointing up.  But, on the bottom face, we want n pointing down.  So, in fact, we shouldn't use this formula ", "here because that one corresponds to the other  orientation. Well, we could use it and then  subtract, but I was just going to say that ndS is actually the ", "opposite of this. So, I'm going to switch all my  signs. OK, that's the other side of  the formula when you orient your graph with n pointing downwards. ", "Now, if I do things the same way as before,  I will get that <0,0, R> dot ndS will be negative ", "R dxdy. And so,  when I do the double integral over the bottom, ", "I'm going to get the double integral over the bottom of  negative R dxdy, which, if I try to evaluate  that, well, I actually will have to ", "integrate. Sorry, first I'll have to  substitute the value of z. The value of z that I will want  to plug into R will be given by, now, z1 of x, ", "y. And, the bounds of integration  will be given, again, by the shadow of our  surface, which is, again, this guy, ", "U. OK, so we seem to be all set,  except we are still missing one part of our surface,  S, because we also need to look at the sides.  Well, what about the sides? Well, our vector field, ", ", is actually vertical.  It's parallel to the z axis. OK, so my vector field does  something like this everywhere. And, why that makes it very ", "interesting on the top and bottom, that means that on the  sides, really not much is going on.  No matter is passing through the vertical sides. ", "So, the side -- The sides are vertical. ", "So, <0,0, R> is tangent to the side,  and therefore, the flux through the sides is ", "just going to be zero. OK, no calculation needed.  That's because, of course, that's the reason why a ", "simplified first things so that my vector field would only have  a z component, well, not just that but that's  the main place where it becomes very useful. ", "So, now, if I compare my double integral and,  sorry, my triple integral and my flux integral,  I get that they are, indeed, the same.  ", "Well, that's the statement of the theorem we are trying to  prove. I shouldn't erase it, OK? ", "[LAUGHTER] So, just to recap,  we've got a formula for the triple integral of R sub z dV. ", "It's up there at the very top. And, we got formulas for the  flux through the top and the bottom, and the sides.  And, when you add them together,  you get indeed the same formula, ", "top plus bottom -- -- plus sides of, ", "OK, and so we have, actually, completed the proof for this  part. Now, well, that's only for a  vertically simple region, OK? ", "So, if D is not vertically simple, what do we do? ", "Well, we cut it into vertically simple pieces. ", "OK so, concretely, I wanted to integrate over a  solid doughnut. Then, that's not vertically  simple because here in the middle, I have not only does top ", "in this bottom, but I have this middle face.  So, the way I would cut my doughnut would be probably I  would slice it not in the way that you'd usually slice the ", "doughnut or a bagel, but at it's probably more  spectacular if you think that it's a bagel.  Then, a mathematician's way of slicing it is like this into ", "five pieces, OK? And, that's not very convenient  for eating, but that's convenient for  integrating over it because now each of these pieces has a  well-defined top and bottom face, ", "and of course you've introduced some vertical sides for two  reasons. One is that we've said the flux  through them is zero anyway. So, who cares? ", "Why bother? But, also, if you sum the flux  through the surface of each little piece,  well, you will see that you will be integrating twice over ", "each of these vertical cuts. Once, when you do this piece,  you will be taking the flux through this red guy with normal  vector pointing to the right, and once, when you take this ", "middle little piece, you will be taking the flux  through that cut surface again, but now with normal vector  pointing the other way around. So, in fact,  you'll be summing the flux through these guys twice with ", "opposite orientations. They cancel out.  Well, and again, because of what you are doing  actually, the integral was just zero anyway.  So, it didn't matter. But, even if it hadn't ", "simplified, that would do it for us.  OK, so that's how we do it with the general region.  And then, as I said at the beginning,  when we can do it for a vector field that has only a z ", "component, well, we can also do it for a  vector field that has only an x or only a y component.  And then, we sum together and we get the general case.  So, that's the end of the proof. OK, so you see, ", "the idea is really the same as for Green's theorem.  Yes? Oh, there's only four pieces,  thank you. Yes, there's three kinds of ", "mathematicians: those who know how to count,  and those who don't. Well, OK. ", "So, OK, now I hope that you can see already the interest of this  theorem for the divergence theorem for computing flux  integrals just for the sake of computing flux integrals like ", "might happen on the problem set or on the next test.  But let me tell you also why it's important physically to  understand equations that had been observed empirically well ", "before they were actually understood in terms of how  things go. So, let's look at something  called the diffusion equation. So, let me explain to you what ", "it does. So, the diffusion equation is  something that governs, well, what's called diffusion.  Diffusion is when you have a fluid in which you are  introducing some substance, and you want to figure out how ", "that thing is going to spread out,  the technical term is diffuse, into the ambient fluid.  So, for example, that governs the motion of, ", "say, smoke in the air, or if you put dye in the  solution or things like that. That will tell you, ", "say that you drop some ink into a glass of water.  Well, you can imagine that obviously it will get diluted  into there. And, that equation will tell ", "you how exactly over time this thing is going to spread out and  start filling the entire glass. So, what's the equation? ", "Well, we need, first, to know what the unknown  will be. So, it's a partial differential  equation, OK? So the unknown is a function,  and the equation will relate the partial derivatives of that ", "function to each other. So, u, the unknown,  will be the concentration at a given point. ", "And, of course, that depends on the point where  you are. So, that depends on x,  y, z, the location where you are.  But, since the goal is also to understand how things spread  over time, it should also depend on time. ", "Otherwise, we're not going to get very far.  And, in fact, what the equation will give us  is the derivative of u with respect to t.  It will tell us how the concentration at a given point ", "varies over time in terms of how the concentration varied in  space. So, it will relate partial u  partial t to partial derivatives with respect to x, ", "y, and z.  ", "[APPLAUSE] OK, [LAUGHTER]  so what's the equation? The equation is partial u  partial t equals some constant. Let me call it constant k times ", "something I will call del squared u, which is also called  the Laplacian of u, and what is that? ", "Well, that means,  OK, so just to scare you, del squared is this,  which means it's the divergence of gradient u that we've used ", "this notation for gradient. OK, so if you actually expand  it in terms of variables, that becomes partial u over  partial x squared plus partial squared u over partial y squared ", "plus partial squared u over partial z squared.  OK, so the equation is this equals that. ", "OK, so that's a weird looking equation.  And, I'm going to have to explain to you,  where does it come from? OK, but before I do that,  well, let me point out actually that the equation is not just ", "the diffusion equation. It's also known as the heat  equation. And, that's because exactly the ", "same equation governs how temperature changes over time  when you have, again, so, sorry I should have ", "been actually more careful. I should have said this is in  air that's not moving, OK?  OK, and same thing with the solution.  If you drop some ink into your glass of water, ", "well, if you start stirring, obviously it will mix much  faster than if you don't do anything.  OK, so that's the case where we don't actually,  the fluid is not moving. And, the heat equation now does ", "the same, but for temperature in a fluid that's at rest,  that's not moving. It tells you how the heat goes  from the warmest parts to the coldest parts, ", "and eventually temperatures should somehow even out.  So, in the heat equation, that would just be, ", "this u would just measure the temperature for temperature of  your fluid at a given point. Actually, it doesn't have to be ", "a fluid. It could be a solid for that  heat equation. So, for example,  say that you have a big box made of metal or something, ", "and you do some heating at one side.  You want to know how quickly is the other side going to get hot?  Well, you can use the equation to figure out,  you know, say that you have a metal bar, and you keep one side ", "at 400ÔøΩ because it's in your oven.  How quickly will the other side get warm?  OK, so it's the same equation for both phenomena even though ", "they are, of course, different phenomena.  Well, the physical reason why they're the same is actually  that phenomena are different, but not all that much.  They involve, actually, how the atoms and ", "molecules are actually moving, and hitting each other inside  this medium. OK, so anyway,  what's the explanation for this? ", "So, to understand the explanation, and given what  we've been doing, we should have a vector field  in there. So, I'm going to think of the  flow of, well, let's imagine that we are doing ", "motion of smoke in air. So, that's the flow of the  smoke: that means at every point, it's a vector whose  direction tells me in which direction the smoke is actually ", "moving. And, its magnitude tells me how  fast it's moving, and also what amount of smoke  is moving. So, there's two things to ", "understand. One is how the disparities in  the concentration between different points causes the flow ", "to be there, how smoke will flow from the  regions where there's more smoke to the regions where there's  less smoke. And, that's actually physics. ", "But, in a way, it's also common sense.  So, physics and common sense tell us that the smoke will flow ", "from high concentration towards low concentration regions. ", "OK, so if we think of this function, U,  that measures concentration, that means we are always going  to go in the direction where the concentration decreases the ", "fastest. Well, what's that?  That's negative the gradient. So, F is directed along minus ", "gradient u. Now, how big is F going to be?  Well, they are, you have to come up with some ", "intuition for how the two are related.  And, the easiest relation I can think of is that they might be  just proportional. So, the steeper the differences  in concentration, the faster the flow will be, ", "or the more there will be flow. And, if you try to think about  it as molecules moving in random directions, you will see it  makes actually complete sense. Anyway, it should be part of  your physics class, not part of what I'm telling ", "you. So, I'm just going to accept  that the flow is just proportional to the gradient of ", "u. So, if you want,  the differences between concentrations of different  points are very small, then the flow will be very  gentle. And, if on the other hand you ", "have huge disparities, then things will try to even  out faster. OK, so that's the first part.  Now, we need to understand the second part, which is once we ", "know how flow is going, how does that affect the  concentration? If smoke is going that way,  then it means the concentration here should be decreasing.  And there, it should be increasing. ", "So, that's the relation between F and partial u partial t. ", "At that part is actually math, namely, the divergence theorem.  So, let's try to understand that part more carefully. ", "So, let's take a small piece of a small region in space,  D, bounded by a surface, S.  So, I want to figure out what's going on in here. ", "So, let's look at the flux out of D through S.  Well, we said that this flux would be given by double ", "integral on S of F dot n dS. So, this flux measures how much  smoke is passing through S per unit time. ", "That's the amount of smoke through S per unit time.  But now, how can I compute that differently? ", "Well, I can compute it just by looking at the total amount of  smoke in this region, and seeing how much it changes.  If I'm gaining or losing smoke, it means it must be going up ", "there. Well, unless I have a smoker in  here, but that's not part of the data.  So, that should be, sorry, ", "that's the same thing as the derivative with respect to t of  the total amount of smoke in the region,  which is given by the triple integral of u.  If I integrate the concentration of smoke, ", "which means the amount of smoke per unit volume over d,  I will get the total amount of smoke in d,  except, well, ", "let's see. This flux is counted positively  if we go out of d. So, actually,  it's minus the derivative. This is the amount of smoke ", "that we are losing per unit time.  OK, so now we are almost there. Well, let me actually -- ", "Because we know yet another way to compute this guy using the  divergence theorem. Right, so this part here is ", "just common sense and thinking about what it means.  The divergence theorem tells me this is also equal to the triple ", "integral, d, of div f dV. So, what I got is that the  triple integral over d of div F dV equals this derivative. ", "Well, let's think a bit about this derivative so,  see, you are integrating function over x,  y, and z. And then, you are  differentiating with respect to t.  I claim that you can actually switch the order in which you do ", "things. So, when we think about it,  is, here, you are taking the total amount of smoke and then  see how that changes over time. So, you're taking the  derivative of the sum of all the small amounts of smoke ", "everywhere. Well, that will be the sum of  the derivatives of the amounts of smoke inside each little box.  So, we can actually move the derivatives into the integral. ", "So, let's see, I said minus d dt of triple  integral over d udV. And, now I'm saying this is the ", "same as the triple integral in d of du dt dv.  And the reason why this is going to work is you should ", "think of it as d dt of a sum of u of some values.  You plug in the values of your points at that given time times ", "the small volume. You sum them,  and then you take the derivative.  And now, you see, the derivative of this sum is ", "the sum of the derivatives. yi, zi, t, so,  if you think about what the integral measures, ", "that's actually pretty easy. And it's because this variable  here is not the same as the variables on which we are  integrating. That's why we can do it. ", "OK, so now, if we have this for any region, d. ", "So, we have a function of x, y, z, t, and we have another  function here. And whenever we integrate them  anywhere, we get the same answer. ", "Well, that must mean they're the same.  Just think of what happens if you just take d to be a tiny  little box. You will get roughly the value  of div f at that point times the volume of the box. ", "Or, you will get roughly the value of du dt at that point  times the value of a little box. So, the values must be the same.  Well, let me actually explain that a tiny bit better. ", "So, what I get is that one over, let me divide by the  volume of D, sorry. I promise, I'm done in a minute. ", "Is the same thing as one over volume D of negative du dt,  dV. So, that means the average ", "value, OK, maybe that's the best way  of telling it, the average of div f in D is  equal to the average of minus partial u partial t in D. ", "And, that's true for any region, D, not just for some  regions, but for, really, any region I can think  of. So, the outcome is that ", "actually the divergence of f is equal to minus du dt.  And, that's another way to think about what divergence ", "means. The divergence,  we said, is how much stuff is actually expanding,  flowing out. That's how much we're losing.  And so, now, if you combine this with that, ", "you will get that du dt is minus divergence f,  which is plus K del squared u. OK, so you combine this guy ", "with that guy, and you get the diffusion  equation. "], "vid_duration": [11.0, 14.0, 12.0, 12.0, 13.0, 10.0, 14.0, 12.0, 10.0, 12.0, 10.0, 10.0, 11.0, 13.0, 14.0, 13.0, 13.0, 10.0, 10.0, 10.0, 12.0, 11.0, 13.0, 11.0, 10.0, 13.0, 26.0, 10.0, 11.0, 11.0, 10.0, 10.0, 13.0, 11.0, 10.0, 17.0, 12.0, 13.0, 11.0, 11.0, 10.0, 12.0, 12.0, 10.0, 11.0, 11.0, 11.0, 12.0, 14.0, 11.0, 13.0, 10.0, 10.0, 10.0, 11.0, 11.0, 12.0, 10.0, 14.0, 15.0, 10.0, 11.0, 11.0, 14.0, 12.0, 11.0, 23.0, 17.0, 12.0, 10.0, 13.0, 17.0, 16.0, 11.0, 10.0, 12.0, 10.0, 11.0, 17.0, 12.0, 13.0, 12.0, 12.0, 12.0, 11.0, 13.0, 14.0, 10.0, 10.0, 14.0, 16.0, 14.0, 10.0, 13.0, 10.0, 10.0, 10.0, 16.0, 11.0, 12.0, 15.0, 13.0, 13.0, 14.0, 14.0, 19.0, 16.0, 10.0, 12.0, 13.0, 14.0, 13.0, 10.0, 13.0, 12.0, 10.0, 11.0, 13.0, 12.0, 10.0, 10.0, 11.0, 11.0, 10.0, 12.0, 11.0, 10.0, 13.0, 15.0, 10.0, 12.0, 17.0, 12.0, 13.0, 24.0, 14.0, 15.0, 15.0, 16.0, 11.0, 10.0, 15.0, 13.0, 11.0, 12.0, 11.0, 14.0, 10.0, 10.0, 12.0, 13.0, 12.0, 15.0, 13.0, 25.0, 12.0, 12.0, 16.0, 14.0, 12.0, 13.0, 10.0, 10.0, 11.0, 16.0, 11.0, 12.0, 11.0, 32.0, 13.0, 10.0, 15.0, 15.0, 13.0, 14.0, 13.0, 10.0, 10.0, 12.0, 11.0, 10.0, 11.0, 12.0, 13.0, 13.0, 10.0, 10.0, 13.0, 13.0, 13.0, 10.0, 11.0, 23.0, 16.0, 11.0, 18.0, 10.0, 12.0, 13.0, 12.0, 10.0, 13.0, 10.0, 13.0, 21.0, 14.0, 16.0, 16.0, 14.0, 10.0, 12.0, 11.0, 10.0, 10.0, 21.0, 15.0, 12.0, 15.0, 13.0, 12.0, 15.0, 12.0, 12.0, 11.0, 12.0, 11.0, 10.0, 10.0, 10.0, 10.0, 13.0, 14.0, 10.0, 17.0, 10.0, 10.0, 11.0, 10.0, 4.55], "stet": [[0, 11.0], [11.0, 25.0], [25.0, 37.0], [37.0, 49.0], [49.0, 62.0], [62.0, 72.0], [72.0, 86.0], [86.0, 98.0], [98.0, 108.0], [108.0, 120.0], [120.0, 130.0], [130.0, 140.0], [140.0, 151.0], [151.0, 164.0], [164.0, 178.0], [178.0, 191.0], [191.0, 204.0], [204.0, 214.0], [214.0, 224.0], [224.0, 234.0], [234.0, 246.0], [246.0, 257.0], [257.0, 270.0], [270.0, 281.0], [281.0, 291.0], [291.0, 304.0], [304.0, 330.0], [330.0, 340.0], [340.0, 351.0], [351.0, 362.0], [362.0, 372.0], [372.0, 382.0], [382.0, 395.0], [395.0, 406.0], [406.0, 416.0], [416.0, 433.0], [433.0, 445.0], [445.0, 458.0], [458.0, 469.0], [469.0, 480.0], [480.0, 490.0], [490.0, 502.0], [502.0, 514.0], [514.0, 524.0], [524.0, 535.0], [535.0, 546.0], [546.0, 557.0], [557.0, 569.0], [569.0, 583.0], [583.0, 594.0], [594.0, 607.0], [607.0, 617.0], [617.0, 627.0], [627.0, 637.0], [637.0, 648.0], [648.0, 659.0], [659.0, 671.0], [671.0, 681.0], [681.0, 695.0], [695.0, 710.0], [710.0, 720.0], [720.0, 731.0], [731.0, 742.0], [742.0, 756.0], [756.0, 768.0], [768.0, 779.0], [779.0, 802.0], [802.0, 819.0], [819.0, 831.0], [831.0, 841.0], [841.0, 854.0], [854.0, 871.0], [871.0, 887.0], [887.0, 898.0], [898.0, 908.0], [908.0, 920.0], [920.0, 930.0], [930.0, 941.0], [941.0, 958.0], [958.0, 970.0], [970.0, 983.0], [983.0, 995.0], [995.0, 1007.0], [1007.0, 1019.0], [1019.0, 1030.0], [1030.0, 1043.0], [1043.0, 1057.0], [1057.0, 1067.0], [1067.0, 1077.0], [1077.0, 1091.0], [1091.0, 1107.0], [1107.0, 1121.0], [1121.0, 1131.0], [1131.0, 1144.0], [1144.0, 1154.0], [1154.0, 1164.0], [1164.0, 1174.0], [1174.0, 1190.0], [1190.0, 1201.0], [1201.0, 1213.0], [1213.0, 1228.0], [1228.0, 1241.0], [1241.0, 1254.0], [1254.0, 1268.0], [1268.0, 1282.0], [1282.0, 1301.0], [1301.0, 1317.0], [1317.0, 1327.0], [1327.0, 1339.0], [1339.0, 1352.0], [1352.0, 1366.0], [1366.0, 1379.0], [1379.0, 1389.0], [1389.0, 1402.0], [1402.0, 1414.0], [1414.0, 1424.0], [1424.0, 1435.0], [1435.0, 1448.0], [1448.0, 1460.0], [1460.0, 1470.0], [1470.0, 1480.0], [1480.0, 1491.0], [1491.0, 1502.0], [1502.0, 1512.0], [1512.0, 1524.0], [1524.0, 1535.0], [1535.0, 1545.0], [1545.0, 1558.0], [1558.0, 1573.0], [1573.0, 1583.0], [1583.0, 1595.0], [1595.0, 1612.0], [1612.0, 1624.0], [1624.0, 1637.0], [1637.0, 1661.0], [1661.0, 1675.0], [1675.0, 1690.0], [1690.0, 1705.0], [1705.0, 1721.0], [1721.0, 1732.0], [1732.0, 1742.0], [1742.0, 1757.0], [1757.0, 1770.0], [1770.0, 1781.0], [1781.0, 1793.0], [1793.0, 1804.0], [1804.0, 1818.0], [1818.0, 1828.0], [1828.0, 1838.0], [1838.0, 1850.0], [1850.0, 1863.0], [1863.0, 1875.0], [1875.0, 1890.0], [1890.0, 1903.0], [1903.0, 1928.0], [1928.0, 1940.0], [1940.0, 1952.0], [1952.0, 1968.0], [1968.0, 1982.0], [1982.0, 1994.0], [1994.0, 2007.0], [2007.0, 2017.0], [2017.0, 2027.0], [2027.0, 2038.0], [2038.0, 2054.0], [2054.0, 2065.0], [2065.0, 2077.0], [2077.0, 2088.0], [2088.0, 2120.0], [2120.0, 2133.0], [2133.0, 2143.0], [2143.0, 2158.0], [2158.0, 2173.0], [2173.0, 2186.0], [2186.0, 2200.0], [2200.0, 2213.0], [2213.0, 2223.0], [2223.0, 2233.0], [2233.0, 2245.0], [2245.0, 2256.0], [2256.0, 2266.0], [2266.0, 2277.0], [2277.0, 2289.0], [2289.0, 2302.0], [2302.0, 2315.0], [2315.0, 2325.0], [2325.0, 2335.0], [2335.0, 2348.0], [2348.0, 2361.0], [2361.0, 2374.0], [2374.0, 2384.0], [2384.0, 2395.0], [2395.0, 2418.0], [2418.0, 2434.0], [2434.0, 2445.0], [2445.0, 2463.0], [2463.0, 2473.0], [2473.0, 2485.0], [2485.0, 2498.0], [2498.0, 2510.0], [2510.0, 2520.0], [2520.0, 2533.0], [2533.0, 2543.0], [2543.0, 2556.0], [2556.0, 2577.0], [2577.0, 2591.0], [2591.0, 2607.0], [2607.0, 2623.0], [2623.0, 2637.0], [2637.0, 2647.0], [2647.0, 2659.0], [2659.0, 2670.0], [2670.0, 2680.0], [2680.0, 2690.0], [2690.0, 2711.0], [2711.0, 2726.0], [2726.0, 2738.0], [2738.0, 2753.0], [2753.0, 2766.0], [2766.0, 2778.0], [2778.0, 2793.0], [2793.0, 2805.0], [2805.0, 2817.0], [2817.0, 2828.0], [2828.0, 2840.0], [2840.0, 2851.0], [2851.0, 2861.0], [2861.0, 2871.0], [2871.0, 2881.0], [2881.0, 2891.0], [2891.0, 2904.0], [2904.0, 2918.0], [2918.0, 2928.0], [2928.0, 2945.0], [2945.0, 2955.0], [2955.0, 2965.0], [2965.0, 2976.0], [2976.0, 2986.0], [2986.0, 2990.55]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [703, 1908, 2991]}
{"example_id": "mit002@@ocw-18_02-f07-lec18_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  OK, so far we've learned how to do double integrals in terms of  xy coordinates, also how to switch to polar ", "coordinates. But, more generally,  there's a lot of different changes of variables that you  might want to do. OK, so today we're going to see ", "how to change variables, if you want,  how to do substitutions in double integrals.  ", "OK, so let me start with a simple example.  Let's say that we want to find the area of an ellipse with ", "semi-axes a and b. OK, so that means an ellipse is  just like a squished circle. And so, there's a and there's b. ", "And, the equation of that ellipse is x over a squared plus  y over b squared equals one. That's the curve, ", "and the inside region is where this is less than one.  OK, so it's just like a circle that where you have rescaled x  and y differently. So, let's say we want to find ", "the area of it. Maybe you know what the area is.  But let's do it as a double integral. ", "So, you know, if you find that the area is  too easy, you can integrate any function other than ellipse,  if you prefer. But, let's do it just with area. ", "So, we know that we want to integrate just the area element,  let's say, dx dy over the origin inside the ellipse.  That's x over a2 plus y over b2 less than 1. ", "Now, we can try to set this up in terms of x and y coordinates,  you know, set up the bounds by solving for first four x as a  function of y if we do it this order and, ", "well, do the usual stuff. That doesn't look very  pleasant, and it's certainly not the best way to do it.  OK, if this were a circle, we would switch to polar  coordinates. Well, we can't quite do that ", "yet. But, you know,  an ellipse is just a squished circle.  So, maybe we want to actually first rescale x and y by a and  b. So, to do that, ", "what we'd like to do is set x over a to be u,  and y over b be v. So, we'll have two new ", "variables, u and v, and we'll try to redo our  integral in terms of u and v. So, how do we do the  substitution? So, in terms of u and v, ", "the condition, the region that we are  integrating on will become u^2 v^2 is less than 1,  which is arguably nicer than the ellipse.  That's why we are doing it. But, we need to know what to do ", "with dx and dy. Well, here, the answer is  pretty easy because we just change x and y separately.  We do two independent substitutions.  OK, so if we set u equals x over a, that means du is one ", "over adx. And here, dv is one over bdy.  So, it's very tempting to write, and here we actually can ", "write, in this particular case, that dudv is (1/ab)dxdy,  OK? So, let me rewrite that. ", "OK, so I get dudv equals (1/ab)dxdy, or equivalently dxdy ", "is ab times dudv. OK, so in my double integral, ", "I'm going to write (ab)dudv. OK, so now, my double integral ", "becomes, well, the double integral of a  constant in terms of u and v. So, I can take the constant out.  I will get ab times double integral over u^2 v^2<1 of du ", "dv. And, that is an integral that  we know how to do. Well, it's just the area of a  unit circle. So, we can just say,  this is ab times the area of the unit disk, ", "which we know to be pi, or if somehow you had some  function to integrate, then you could have somehow  switched to polar coordinates, you know, setting u equals r  times cos(theta), v equals r times sin(theta), ", "and then doing it in polar coordinates.  OK, so here the substitution worked pretty easy.  The question is, if we do a change of variables ", "where the relation between x and y and u and v is more  complicated, what can we do? Can we still do this,  or do we have to be more careful?  And, actually, we have to be more careful.  So, that's what we are going to see next. ", "Any question about this, first? No?  OK. OK, so, see the general problem ", "when we try to do this is to figure out what is the scale  factor? What's the relation between ", "dxdy and dudv? We need to find the scaling  factor. So, we need to find dxdy versus ", "dudv. So, let's do another example  that's still pretty easy, but a little bit less easy. ", "OK, so let's say that for some reason, we want to do the change  of variables: u equals 3x-2y,  and v equals x y. Why would we want to do that? ", "Well, that might be to simplify the integrand because we are  integrating a function that happens to be actually involving  these guys rather than x and y. Or, it might be to simplify the ", "bounds because maybe we are integrating over a region whose  equation in xy coordinates is very hard to write down.  But, it becomes much easier in terms of u and v.  And then, the bounds would be much easier to set up with u and ", "v. Anyway, so, whatever the reason  might be, typically it would be to simplify the integrant or the ", "bounds. Well, how do we convert dxdy to  dudv? So, we want to understand,  what's the relation between, let's call dA the area element ", "in xy coordinates. So, dA is dxdy,  maybe dydx depending on the order.  And, the area element in uv coordinates, let me call that dA ", "prime just to make it look different.  So, that would just be dudv, or dvdu depending on which ", "order I will want to set it up in.  So, to find this relation, it's probably best to draw a ", "picture to see what happens. Let's consider a small piece of  the xy plane with area delta(A) corresponding to just a box with ", "sides delta(y) and delta(x). OK, and let's try to figure out  what it will look like in terms of u and v.  And then, we'll say, well, when we integrate, ", "we're really summing the value of the function of a lot of  small boxes times their area. But, the problem is that the  area of the box in here is not the same as the area of the box ", "in uv coordinates. There, maybe it will look like,  actually, if you see that these are  linear changes of variables, you know that the rectangle ", "will become a parallelogram after the change of variables.  So, the area of a parallelogram delta(A) prime,  well, we will have to figure out how they are related so that ", "we can decide what conversion factor,  what's the exchange rate between these two currencies for  area? OK, any questions at this point? ", "No? Still with me mostly? I see a lot of tired faces.  Yes? Why is delta(A) prime a ", "parallelogram? That's a very good question.  Well, see, if I look at the side of a rectangle,  say there's a vertical side, it means I'm going to increase ", "y, keeping x the same. If I look at the formulas for u  and v, they are linear formulas in terms of x and y.  So, if I just increase y, see that u is going to decrease ", "at a rate of two. v is going to increase at a  rate of one at constant rates. And, it doesn't matter whether  I was looking at this site or at that site.  So, basically straight lines become straight lines. ", "And if they are parallel, they stay parallel.  So, if you just look at what the transformation,  from xy to uv does, it does this kind of thing.  Actually, this transformation here you can express by a ", "matrix. And, remember,  we've seen what matrices do the pictures.  We just take straight lines to straight lines.  They keep the notion of being parallel, but of course they ", "mess up lengths, angles, and all that.  OK, so let's see. So, let's try to figure out,  what is the area of this guy? Well, in fact, ", "what I've been saying about this transformation being  linear, and transforming all of the  vertical lines in the same way, all the horizontal lines in the ", "same way, it tells me,  also, I should have a constant scaling factor,  right, because how much I've scaled my rectangle doesn't  depend on where my rectangle is. If I move my rectangle to ", "somewhere else, I have a rectangle of the same  size, same shape, it will become a parallelogram  of the same size, same shape somewhere else.  So, in fact, I can just take the simplest ", "rectangle I can think of and see how its area changes.  And, if you don't believe me, then try with any other  rectangle. You will see it works exactly  the same way. OK, so I claim that the area ", "scaling factor -- -- here in this case doesn't depend on the ", "choice of the rectangle. And I should say that because ", "we are actually doing a linear change of variables -- So, ", "you know, somehow, the exchange rate between uv  and xy is going to be the same everywhere.  So, let's try to see what happens to the simplest  rectangle I can think of, namely, just the unit square. ", "And, you know, if you don't trust me,  then while I'm doing this one, do it with a different  rectangle. Do the same calculation,  and see that you will get the same conversion ratio. ", "So, let's say that I take a unit square -- -- so,  something that goes from zero to one both in x and y ", "directions. OK, and let's try to figure out  what it looks like on the other side.  So, here the area is one. Let's try to draw it in terms ", "of u and v coordinates, OK?  So, here we have x equals 0, y equals 0.  Well, that tells us u and v are going to be 0. ", "Next, let's look at this corner. Well, in xy coordinates,  this is one zero. If you plug x equals 1,  y equals 0, you get u equals 3; v equals 1. ", "So, that goes somewhere here. And so, this edge of the square ", "will become this line here, OK?  Next, let's look at that point. So that point here was (0,1). ", "If I plug x equals zero y equals one I will get (-2,1). ", "So, this edge goes here. Then, if you put x equals one, ", "y equals one, you will get u equals 1,  v equals 2. So, I want (1,2). ", "And, these edges will go to these edges here.  And, you see, it does look like a  parallelogram. OK, so now what the area of ", "this parallelogram? Well, we can get that by taking  the determinant of these two vectors.  So, one of them is , and the other one is ", ". That will be 3 2.  That's 5. OK, this parallelogram is  apparently five times the size of this square. ", "Here, it looks like it's less because I somehow changed my  scale. I mean, my unit length is  smaller here than here. But, it should be a lot bigger ", "than that. OK,  and if you do the same calculations not with zero and  one, but with x and x plus delta x,  and so on, you will still find that the  area has been multiplied by five. ", "So, that tells us, actually for any other  rectangle, area is also multiplied by five. ", "So, that tells us that dA prime, the area element in uv  coordinate is worth five times more than the area element in ", "the xy coordinate.  ", "So, that means du dv is worth five times dx dy.  What's so funny? What? ", "Oh. [LAUGHTER] OK, rectangle. ", "OK, is that OK now? Did I misspell other words?  No? OK, it's really hard to see  when you are up close. It's much easier from a ", "distance. OK, so yeah,  so we've said our transformation multiplies areas ", "by five. And so, dudv is five times dxdy.  So, if I'm integrating some function, dx dy,  then when I switch to uv coordinates, I will have to ", "replace that by one fifth dudv. OK, and of course I would also,  here my function would probably involve x and y.  I will replace them by u's and v's. ", "And, the bounds, well, the shape of my origin in  the xy coordinates I will have to switch to some shape in the  uv coordinates. And, that's also something that  might be easy or might be tricky depending on what origin we are ", "looking at. So, usually we will do changes  of variables to actually simplify the region so it  becomes easier to set up the bounds. ", "So, anyway, so this is kind of an illustration of a general  case. And, why is that?  Well, here it looks very easy. We are just using linear ", "formulas, and somehow the relation between dx dy and du dv  is the same everywhere. If you take actually more  complicated changes of variables that's not true because usually ", "you will expect that there are some places where the rescaling  is enlarging things, and some of other places where  things are shrunk, so, certainly the exchange rate ", "between dudv and dxdy will fluctuate from point to point.  It's the same as if you're trying to change dollars to  euros. It depends on where you do it.  You will get a better rate or a worse one. ", "So, of course, we'll get a formula where  actually this scaling factor depends on x and y or on u and  v. But, if you fix a point, ", "then we have linear approximation.  And, linear approximation tells us, oh, we can do as if our  function is just a linear function of x and y.  So then, we can do it the same way we did here. ", "OK, so let's try to think about that. ", "So, in the general case, well, that means we will  replace x and y by new coordinates, u and v.  And, u and v will be some functions of x and y. ", "So, well, we'll have an approximation  formula which tells us that the change in u,  if I change x or y a little bit, ", "will be roughly (u sub x times change in x) (u sub y times  change in y). And, the change in v will be ", "roughly (v sub x delta x) (v sub y delta y).  Or, the other way to say it, if you want in matrix form is ", "delta u delta v is, sorry, approximately equal to  matrix |u sub x, u sub y, v sub x,  v sub y| times matrix |delta x, delta y|, ", "OK? So, if we look at that,  what it tells us, in fact, is that if we take a small ", "rectangle in xy coordinates, so that means we have a certain  point, x, y, and then we have a certain ", "width. This is going to be too small.  Well, so, I have my width, delta x. ", "I have my height, delta y. This is going to correspond to ", "a small uv parallelogram. And, what the shape and the  size of the parallelogram are depends on the partial ", "derivatives of u and v. So, in particular,  it depends on at which point we are.  But still, at a given point, it's a bit like that. ", "And, so if we do the same argument as before,  what we will see is that the scaling factor is actually the ", "determinant of this transformation.  So, that's one thing that maybe we didn't emphasize enough when  we did matrices at the beginning of a semester. ", "But, when you have a linear transformation between  variables, the determinant of that transformation represents  how it scales areas. OK, so one way to think about ", "it is just to try it and see what happens.  Take this side. This side in x,  y coordinates corresponds to delta x and zero. ", "And, now, if you take the image of that, if you see what happens  to delta u and delta v, that will be basically u sub x  delta x and v sub x delta x. There's no delta y. ", "For the other side, OK, so maybe I should do it  actually. So, you know,  if we move in the x, y coordinates by delta x and ", "zero, then delta u and delta v will  be approximately u sub x delta x, ", "and v sub x delta x. And, on the other hand, ", "if you move in the other direction along the other side  of your rectangle, zero and delta y,  then the change in u and the change in v will correspond to, ", "well, how does u change? That's u sub y delta y,  and v changes by v sub y delta y.  And so, now, if you take the determinant of  these two vectors, OK, so these are the sides of ", "your parallelogram up here. And, if you take these sides to  get the area of the parallelogram,  you'll need to take the determinant.  And, the determinant will be the determinant of this matrix ", "times delta x times delta y. So, the area in uv coordinates  will be the determinant of a matrix times delta x, ", "delta y. And so,  what I'm trying to say is that when you have a general change  of variables, du dv versus dx dy is given by ", "the determinant of this matrix of partial derivatives.  It doesn't matter in which order you write it.  I mean, you can put in rows or columns. ", "If you transpose a matrix, that doesn't change the  determinant. It's just any sensible matrix  that you can write will have the correct determinant.  ", "OK, so what we need to know is the following thing.  So, we define something called the  Jacobian of a change of variables and used the letter J, ", "or maybe a more useful notation is partial of u,  v over partial of x, y.  That's a very strange notation. I mean, that doesn't mean that ", "we are actually taking the partial derivatives of anything.  OK, it's just a notation to remind us that this has to do  with the ratio between dudv and dxdy. ", "And, it's obtained using the partial derivatives of u and v  with respect to x and y. So, it's the determinant of the ", "matrix |u sub x, u sub y, v sub x,  v sub y|, the matrix that I had up there. ", "OK, and what we need to know is that du dv is equal to the  absolute value of J dx dy. Or, if you prefer to see it in ", "the easier to remember version, it's (absolute value of d of  (u, v) over partial xy) times dx dy. ", "OK, so this is just what you need to remember,  and it says that the area in uv coordinates is worth, ", "well, the ratio to the xy coordinates is given by this  Jacobian determinant except for one small thing.  It's given by, actually, the absolute value of ", "this guy. OK, so what's going on here?  What's going on here is when we are saying the determinant of  the transformation tells us how the area is multiplied, ", "there's a small catch. Remember, the determinants are  equal to areas up to sine. Sometimes, the determinant is  negative because of reversing the orientation of things. ", "But, the area is still the same. Area is always positive.  So, the area elements are actually related by the absolute  value of this guy. OK, so if you find -10 as your ", "answer, then du dv is still ten times dx dy.  OK, so I didn't put it all together because then you would ", "have two sets of vertical bars. See, this is a vertical bar for  absolute value. This is vertical bar for  determinant. They're not the same.  That's the one thing to remember. ", "OK, any questions about this? No?  OK. So, actually let's do our first ", "example of that. Let's check what we had for  polar coordinates. Last time I told you if we have ", "dx dy we could switch it to r dr d theta.  And, we had some argument for that by looking at the area of a  small circular sector. But, let's check again using ", "this new method. So, in polar coordinates I'm  setting x equals r cosine theta, y equals r sine theta. ", "So, the Jacobian for this change of variables,  so let's say I'm trying to find the partial derivatives of x, ", "y with respect to r, theta.  Well, what is, OK, let me actually write them ", "here again for you. And, so what does that become?  Partial x over partial r is just cosine theta. ", "Partial x over partial theta is negative r sine theta.  Sorry, I guess I'm going to run out of space here. ", "So, let me do it underneath. So, we said x sub r is cosine  theta; x sub theta is negative r sine  theta. y sub r is sine; ", "y sub theta is r cosine. And now, if we compute this  determinant, we'll get (r cosine squared theta) (r sine squared ", "theta). And, that simplifies to r.  So, dx dy is, well, absolute value of r dr d ", "theta. But, remember that r is always  positive. So, it's r dr d theta. ", "OK, so that's another way to justify how we did double  integrals in polar coordinates. OK, any questions on that? ", "Where? Yeah, OK. ", "Yeah, so this one seems to be switching.  Well, it depends what you do. So, OK, actually here's an  important thing that I didn't quite say. ", "So, I said, you know, we are going to switch from xy  to uv. We can also switch from uv to  xy. And, this conversion ratio,  the Jacobian, works both ways. ", "Once you have found the ratio between du dv and dx dy,  then it works one way or it works the other way.  I mean, here, of course, we get the answer in ", "terms of r. So, this would let us switch  from xy to r theta. But, we can also switch from r  theta to xy. Just, we'd write dr d theta ", "equals (1 over r) times dx dy. And then we'd have,  of course, to replace r by its formula in xy coordinates.  Usually, we don't do that. Usually, we actually start with ", "xy and switch to polar. But,  so in general, when you have this formula  relating du dv with dx dy, you can use it both ways, ", "either to switch from du dv to dx dy or the other way around.  And, the thing that I'm not telling you that now I should ", "probably tell you is I could define two Jacobians because if  I solve for xy in terms of uv instead of uv in terms of xy,  then I can compute two different Jacobians. ", "I can compute partial uv over partial xy, or I can compute  partial xy over partial uv if I have the formulas both ways.  Well, the good news is these guys are the inverse of each ", "other. So, the two formulas that you  might get are consistent.  ", "OK, so useful remark -- So, say that you can compute both ", "-- -- these guys. Well, then actually,  the product will just be 1. So, they are the inverse of ", "each other. So, it doesn't matter which one  you compute. You can compute whichever one  is the easiest to compute no matter which one of the two you ", "need. And, one way to see that is  that, in fact, we're looking at the  determinant of these matrices that tell us the relation in  variables. So, if one of them tells you ", "how delta u delta v relate to delta x delta y,  the other one does the opposite thing.  It means they are the inverse matrices.  And, the determinant of the inverse matrix is the inverse of ", "the determinant. So, they are really  interchangeable. I mean, you can just compute  whichever one is easiest. So here, if you wanted, ", "dr d theta in terms of dx dy, it's easier to do this and then  move the r over there than to first solve for r and theta as ", "functions of x and y and then do the entire thing again.  But, you can do it if you want. I mean, it works. ", "Oh yeah, the other useful remark, so, I mentioned it,  but let me emphasize again. So, now, the ratio between du  dv and dx dy, it's not a constant anymore,  although there it used to be five. ", "But now, it's become r, or anything.  In general, it will be a function that depends on the  variables. So, it's not true that you can  just say, oh, I'll put a constant times du ", "dv. Yes? ", "It would still work the same. You could imagine drawing a  picture where r and theta are the Cartesian coordinates,  and your picture would be completely messed up.  It would be a very strange thing to do to try to draw, ", "you know, I'm going to do it, but don't take notes on that.  You could try to draw picture like that, and then a circle  would start looking like, you know, a disk would look  like that. It would be very  counterintuitive. But, you could do it. ", "And that would be equivalent to what we did with a previous  change of variables. So, in this case,  certainly you would never draw a picture like that. ", "But, you could do it. OK, so now let's do a complete ", "example to see how things fit together, how we do everything.  So, let's say that we want to compute, so I have to warn you, ", "it's going to be a very silly example.  It's an example where it's much easier to compute things without  the change of variables. But, you know,  it's good practice in the sense that we're going to make it so ", "complicated that if we can do this one, then we can do that  one. So, let's say that we want to  compute this. And, of course,  it's very easy to compute it directly. ", "But let's say that for some evil reason we want to do that  by changing variables to u equals x and v equals xy. ", "OK, that's a very strange idea, but let's do it anyway.  I mean, normally, you would only do this kind of  substitution if either it simplifies a lot the function ", "you are integrating, or it simplifies a lot the  region on which you are integrating.  And here, neither happens. But anyway, so the first thing ", "we have to do here is figure out what we are going to be  integrating. OK, so to do that,  we should figure out what dx dy will become in terms of u and v. ", "So, that's what we've just seen using the Jacobian.  OK, so the first thing to do is find the area element.  And, for that, we use the Jacobian. ", "So, well, let's see, the one that we can do easily  is partials of u and v with respect to x and y.  I mean, the other one is not very hard because here you can  solve easily. But, the one that's given to ", "you is partial of u and v with respect to x and y,  so partial u partial x is one. Partial u partial y is zero. ", "Partial v partial x is y. And partial v partial y is x.  So that's just x. So, that means that du dv is x ", "dx dy. Well, it would be absolute  value of x, but x is positive in our origin.  So, at least we don't have to worry about that. ", "OK, so now that we have that, we can try to look at the ", "integrand in terms of u and v. OK, so we were integrating x ", "squared y dx dy. So, let's switch it.  Well, let's first switch the dx dy that becomes one over x du ", "dv. So, that's actually xy du dv.  And, what is xy in terms of u and v?  Well, here at least we had a little bit of luck. ", "xy is just v. So, that's v du dv.  So, in fact, what we'll be computing is a ", "double integral over some mysterious region of v du dv.  Now, last but not least, we'll have to find what are the ", "bounds for u and v in the new integral so that we know how to  evaluate this.  ", "In fact, well, we could do it du dv or dv du.  We don't know yet. Oh, amazing.  It went all the way down this time. ", "OK, so it could be dv du if that's easier. ", "So, let's try to find the bounds.  In this case, that's the hardest part.  OK, so let me draw a picture in xy coordinates and try to ", "understand things using that. OK, so x and y go from zero to  one. The region that we want to  integrate over was just this square. ", "Let's try to figure out how u and v vary there.  So, let's say that we're going to do it du dv. ", "OK, so What we want to understand is how u and v vary  in here. What's going to happen? ", "So, the way we can think about it is we try to figure out how  we are slicing our origin. OK, so here,  we are integrating first over u. ", "That means we start by keeping u constant, no,  by keeping v constant as u changes.  OK, so u changes as v is constant. ", "What does it mean that I'm keeping v constant.  Well, what is v? v is xy.  So, that means I keep xy equals constant. ", "What does the curve xy equals constant look like?  Well, it's just a hyperbola. y equals constant over x.  So, if I look at the various values of v that I can take, ", "for each value of v, if I fix a value of v,  I will be moving on one of these red curves. ", "OK, and u, well, u is the same thing as x.  So, that means u will increase. Here, maybe it will be 0.1 and  it will increase all the way to one here. ", "OK, so we are just traveling on each of these slices.  Now, so the question we must answer here is for a given value ", "of v, what are the bounds for u? So, I'm traveling on my curve,  v equals constant, and trying to figure out,  when do I enter my origin? When do I leave it? ", "Well, I enter it when I go through this side.  So, the question is, what's the value of u here? ", "Well, we don't know that very easily until we look at these  formulas. So, u equals x,  OK, but we don't know what x is at that point. ", "v equals x and v equals xy. What do we go here?  Well, we don't know x, but we know y certainly.  OK, so let's forget about trying to find u. ", "And, let's say, for now, we know y equals one.  Well, if we set y equals one, that tells us that u and v are  both equal to x. So, in terms of u and v, ", "the equation of this uv coordinate is u equals v.  OK, I mean, the other way to do it is, say that you know you ", "want y equals one. You want to know what is y in  terms of u and v. Well, it's easy.  y is v over u. So, let me actually add an ", "extra step in case that's, so, we know that y is v over u  equals one. So, that means u=v is my  equation. OK, so when I'm here, ", "when I'm entering my region, the value of u at this point is  just v, u equals v. That's the hard part. ", "Now, we need to figure out, so, we started u equals v.  u increases, increases, increases.  Where does it exit? It exits one when we are here.  What's the value of u here? One. That one is easier, right? ", "This side here, so, this side here is x equals  one. That means u equals one.  So, we start at u equals one. Now, we've done the inner ", "integral. What about the outer?  So, we have to figure out, what is the first and what is  the last value of v that we'll want to consider? ", "Well, if you look at all these hyperbola's, xy equals constant.  What's the smallest value of xy that we'll ever want to look at  in here? Zero, OK.  Let me actually, where's my yellow chalk? ", "Is it, no, ah. So, this one here,  that's actually v=0. So, we'll start at v equals ", "zero. And, what's the last hyperbola  we want to look at? Well, it's the one that's right  there in the corner. It's this one here.  And, that's v equals one. So, v goes from zero to one. ", "OK, and now, we can compute this.  I mean, it's not particularly easier than that one,  but it's not harder either. How else could we have gotten ", "these bounds, because that was quite evil.  So, I would like to recommend that you try this way in case it  works well. Just try to picture,  what are the slices in terms of u and v, and how you travel on ", "them, where you enter, where you leave,  staying in the xy picture. If that somehow doesn't work  well, another way is to draw the picture in the uv coordinates. ", "So, switch to a uv picture. So, what do I mean by that?  Well, we had here a picture in xy coordinates where we had our ", "sides. And, we are going to try to  draw what it looks like in terms of u and v.  So, here we said this is x equals one.  That becomes u equals one. So, we'll draw u equals one. ", "This side we said is y equals one becomes u equals v.  That's what we've done over there.  OK, so u equals v. Now, we have the two other ", "sides to deal with. Well, let's look at this one  first. So, that was x equals zero.  What happens when x equals zero? Well, both u and v are zero.  So, this side actually gets squished in the change of ", "variables. It's a bit strange,  but it's a bit the same thing as when you switch to polar  coordinates at the origin, r is zero but theta can be  anything. It's not always one point is ", "one point. So anyway, this is the origin,  and then the last side, y equals zero,  and x varies just becomes v equals zero. ", "So, somehow, in the change of variables,  this square becomes this triangle.  And now, if we want to integrate du dv,  it means we are going to slice by v equals constant. ", "So, we are going to integrate over slices like this,  and you see for each value of v, we go from u equals v to u  equals one. And, v goes from zero to one. ", "OK, so you get the same bounds just by drawing a different  picture. So, it's up to you to decide  whether you prefer to think on this picture or draw that one ", "instead. It depends on which problems  you're doing. "], "vid_duration": [10.0, 12.0, 18.0, 19.0, 17.0, 11.0, 12.0, 10.0, 12.0, 14.0, 12.0, 10.0, 12.0, 13.0, 12.0, 14.0, 20.0, 16.0, 16.0, 12.0, 11.0, 10.0, 16.0, 19.0, 12.0, 12.0, 12.0, 12.0, 10.0, 19.0, 11.0, 13.0, 11.0, 15.0, 15.0, 15.0, 12.0, 11.0, 11.0, 17.0, 11.0, 11.0, 12.0, 13.0, 15.0, 14.0, 11.0, 11.0, 10.0, 11.0, 12.0, 13.0, 11.0, 10.0, 10.0, 15.0, 13.0, 12.0, 12.0, 14.0, 11.0, 15.0, 13.0, 15.0, 11.0, 14.0, 11.0, 12.0, 10.0, 11.0, 16.0, 15.0, 11.0, 11.0, 12.0, 20.0, 10.0, 14.0, 19.0, 10.0, 14.0, 11.0, 15.0, 13.0, 13.0, 12.0, 12.0, 11.0, 10.0, 12.0, 11.0, 12.0, 12.0, 12.0, 10.0, 10.0, 13.0, 17.0, 12.0, 12.0, 12.0, 10.0, 14.0, 10.0, 11.0, 12.0, 12.0, 11.0, 12.0, 12.0, 10.0, 12.0, 11.0, 12.0, 16.0, 12.0, 13.0, 10.0, 46.0, 14.0, 11.0, 10.0, 13.0, 12.0, 15.0, 10.0, 11.0, 10.0, 11.0, 11.0, 13.0, 10.0, 13.0, 20.0, 10.0, 15.0, 13.0, 10.0, 10.0, 13.0, 10.0, 14.0, 17.0, 10.0, 10.0, 16.0, 13.0, 13.0, 12.0, 10.0, 11.0, 10.0, 11.0, 10.0, 11.0, 12.0, 32.0, 17.0, 10.0, 19.0, 11.0, 10.0, 11.0, 10.0, 15.0, 12.0, 10.0, 10.0, 12.0, 11.0, 10.0, 12.0, 11.0, 14.0, 11.0, 14.0, 12.0, 11.0, 11.0, 10.0, 12.0, 10.0, 22.0, 18.0, 10.0, 10.0, 14.0, 11.0, 12.0, 12.0, 30.0, 17.0, 12.0, 17.0, 11.0, 12.0, 13.0, 10.0, 17.0, 10.0, 15.0, 10.0, 13.0, 12.0, 11.0, 10.0, 12.0, 13.0, 14.0, 11.0, 12.0, 13.0, 14.0, 12.0, 15.0, 12.0, 17.0, 11.0, 15.0, 11.0, 12.0, 20.0, 11.0, 15.0, 15.0, 12.0, 12.0, 12.0, 15.0, 11.0, 10.0, 3.0], "stet": [[0, 10.0], [10.0, 22.0], [22.0, 40.0], [40.0, 59.0], [59.0, 76.0], [76.0, 87.0], [87.0, 99.0], [99.0, 109.0], [109.0, 121.0], [121.0, 135.0], [135.0, 147.0], [147.0, 157.0], [157.0, 169.0], [169.0, 182.0], [182.0, 194.0], [194.0, 208.0], [208.0, 228.0], [228.0, 244.0], [244.0, 260.0], [260.0, 272.0], [272.0, 283.0], [283.0, 293.0], [293.0, 309.0], [309.0, 328.0], [328.0, 340.0], [340.0, 352.0], [352.0, 364.0], [364.0, 376.0], [376.0, 386.0], [386.0, 405.0], [405.0, 416.0], [416.0, 429.0], [429.0, 440.0], [440.0, 455.0], [455.0, 470.0], [470.0, 485.0], [485.0, 497.0], [497.0, 508.0], [508.0, 519.0], [519.0, 536.0], [536.0, 547.0], [547.0, 558.0], [558.0, 570.0], [570.0, 583.0], [583.0, 598.0], [598.0, 612.0], [612.0, 623.0], [623.0, 634.0], [634.0, 644.0], [644.0, 655.0], [655.0, 667.0], [667.0, 680.0], [680.0, 691.0], [691.0, 701.0], [701.0, 711.0], [711.0, 726.0], [726.0, 739.0], [739.0, 751.0], [751.0, 763.0], [763.0, 777.0], [777.0, 788.0], [788.0, 803.0], [803.0, 816.0], [816.0, 831.0], [831.0, 842.0], [842.0, 856.0], [856.0, 867.0], [867.0, 879.0], [879.0, 889.0], [889.0, 900.0], [900.0, 916.0], [916.0, 931.0], [931.0, 942.0], [942.0, 953.0], [953.0, 965.0], [965.0, 985.0], [985.0, 995.0], [995.0, 1009.0], [1009.0, 1028.0], [1028.0, 1038.0], [1038.0, 1052.0], [1052.0, 1063.0], [1063.0, 1078.0], [1078.0, 1091.0], [1091.0, 1104.0], [1104.0, 1116.0], [1116.0, 1128.0], [1128.0, 1139.0], [1139.0, 1149.0], [1149.0, 1161.0], [1161.0, 1172.0], [1172.0, 1184.0], [1184.0, 1196.0], [1196.0, 1208.0], [1208.0, 1218.0], [1218.0, 1228.0], [1228.0, 1241.0], [1241.0, 1258.0], [1258.0, 1270.0], [1270.0, 1282.0], [1282.0, 1294.0], [1294.0, 1304.0], [1304.0, 1318.0], [1318.0, 1328.0], [1328.0, 1339.0], [1339.0, 1351.0], [1351.0, 1363.0], [1363.0, 1374.0], [1374.0, 1386.0], [1386.0, 1398.0], [1398.0, 1408.0], [1408.0, 1420.0], [1420.0, 1431.0], [1431.0, 1443.0], [1443.0, 1459.0], [1459.0, 1471.0], [1471.0, 1484.0], [1484.0, 1494.0], [1494.0, 1540.0], [1540.0, 1554.0], [1554.0, 1565.0], [1565.0, 1575.0], [1575.0, 1588.0], [1588.0, 1600.0], [1600.0, 1615.0], [1615.0, 1625.0], [1625.0, 1636.0], [1636.0, 1646.0], [1646.0, 1657.0], [1657.0, 1668.0], [1668.0, 1681.0], [1681.0, 1691.0], [1691.0, 1704.0], [1704.0, 1724.0], [1724.0, 1734.0], [1734.0, 1749.0], [1749.0, 1762.0], [1762.0, 1772.0], [1772.0, 1782.0], [1782.0, 1795.0], [1795.0, 1805.0], [1805.0, 1819.0], [1819.0, 1836.0], [1836.0, 1846.0], [1846.0, 1856.0], [1856.0, 1872.0], [1872.0, 1885.0], [1885.0, 1898.0], [1898.0, 1910.0], [1910.0, 1920.0], [1920.0, 1931.0], [1931.0, 1941.0], [1941.0, 1952.0], [1952.0, 1962.0], [1962.0, 1973.0], [1973.0, 1985.0], [1985.0, 2017.0], [2017.0, 2034.0], [2034.0, 2044.0], [2044.0, 2063.0], [2063.0, 2074.0], [2074.0, 2084.0], [2084.0, 2095.0], [2095.0, 2105.0], [2105.0, 2120.0], [2120.0, 2132.0], [2132.0, 2142.0], [2142.0, 2152.0], [2152.0, 2164.0], [2164.0, 2175.0], [2175.0, 2185.0], [2185.0, 2197.0], [2197.0, 2208.0], [2208.0, 2222.0], [2222.0, 2233.0], [2233.0, 2247.0], [2247.0, 2259.0], [2259.0, 2270.0], [2270.0, 2281.0], [2281.0, 2291.0], [2291.0, 2303.0], [2303.0, 2313.0], [2313.0, 2335.0], [2335.0, 2353.0], [2353.0, 2363.0], [2363.0, 2373.0], [2373.0, 2387.0], [2387.0, 2398.0], [2398.0, 2410.0], [2410.0, 2422.0], [2422.0, 2452.0], [2452.0, 2469.0], [2469.0, 2481.0], [2481.0, 2498.0], [2498.0, 2509.0], [2509.0, 2521.0], [2521.0, 2534.0], [2534.0, 2544.0], [2544.0, 2561.0], [2561.0, 2571.0], [2571.0, 2586.0], [2586.0, 2596.0], [2596.0, 2609.0], [2609.0, 2621.0], [2621.0, 2632.0], [2632.0, 2642.0], [2642.0, 2654.0], [2654.0, 2667.0], [2667.0, 2681.0], [2681.0, 2692.0], [2692.0, 2704.0], [2704.0, 2717.0], [2717.0, 2731.0], [2731.0, 2743.0], [2743.0, 2758.0], [2758.0, 2770.0], [2770.0, 2787.0], [2787.0, 2798.0], [2798.0, 2813.0], [2813.0, 2824.0], [2824.0, 2836.0], [2836.0, 2856.0], [2856.0, 2867.0], [2867.0, 2882.0], [2882.0, 2897.0], [2897.0, 2909.0], [2909.0, 2921.0], [2921.0, 2933.0], [2933.0, 2948.0], [2948.0, 2959.0], [2959.0, 2969.0], [2969.0, 2972.0]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1713, 2193, 2972]}
{"example_id": "mit002@@ocw-18_02-f07-lec01_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  So let's start right away with stuff that we will need to see  before we can go on to more advanced things.  So, hopefully yesterday in recitation, you heard a bit  about vectors. How many of you actually knew ", "about vectors before that? OK, that's the vast majority.  If you are not one of those people, well,  hopefully you'll learn about vectors right now. ", "I'm sorry that the learning curve will be a bit steeper for  the first week. But hopefully,  you'll adjust fine. If you have trouble with ", "vectors, do go to your recitation instructor's office  hours for extra practice if you feel the need to.  You will see it's pretty easy. So, just to remind you, ", "a vector is a quantity that has both a direction and a magnitude  of length. ", "", "So -- So, concretely the way you draw a vector is by some  arrow, like that, OK?  And so, it has a length, and it's pointing in some ", "direction. And, so, now,  the way that we compute things with vectors,  typically, as we introduce a coordinate system. ", "So, if we are in the plane, x-y-axis, if we are in space,  x-y-z axis. So, usually I will try to draw  my x-y-z axis consistently to look like this. ", "And then, I can represent my vector in terms of its  components along the coordinate axis.  So, that means when I have this row, I can ask,  how much does it go in the x direction? ", "How much does it go in the y direction?  How much does it go in the z direction?  And, so, let's call this a vector A. ", "So, it's more convention. When we have a vector quantity,  we put an arrow on top to remind us that it's a vector.  If it's in the textbook, then sometimes it's in bold ", "because it's easier to typeset. If you've tried in your  favorite word processor, bold is easy and vectors are  not easy. So, the vector you can try to ", "decompose terms of unit vectors directed along the coordinate  axis. So, the convention is there is ", "a vector that we call ***amp***lt;i***amp***gt;  hat that points along the x axis and has length one.  There's a vector called ***amp***lt;j***amp***gt; ", "hat that does the same along the y axis,  and the ***amp***lt;k***amp***gt;  hat that does the same along the z axis.  And, so, we can express any vector in terms of its ", "components. So, the other notation is  ***amp***lt;a1, a2, a3 ***amp***gt;  between these square brackets. Well, in angular brackets. ", "So, the length of a vector we denote by, if you want,  it's the same notation as the absolute value. ", "So, that's going to be a number, as we say,  now, a scalar quantity. OK, so, a scalar quantity is a  usual numerical quantity as opposed to a vector quantity. ", "And, its direction is sometimes called dir A, ", "and that can be obtained just by scaling the vector down to  unit length, for example,  by dividing it by its length. So -- Well, there's a lot of ", "notation to be learned. So, for example,  if I have two points, P and Q, then I can draw a ", "vector from P to Q. And, that vector is called  vector PQ, OK? So, maybe we'll call it A.  But, a vector doesn't really have, necessarily, ", "a starting point and an ending point.  OK, so if I decide to start here and I go by the same  distance in the same direction, this is also vector A.  It's the same thing. So, a lot of vectors we'll draw ", "starting at the origin, but we don't have to.  So, let's just check and see how things went in recitation. ", "So, let's say that I give you the vector  ***amp***lt;3,2,1***amp***gt;. And so, what do you think about ", "the length of this vector? OK, I see an answer forming. ", "So, a lot of you are answering the same thing.  Maybe it shouldn't spoil it for those who haven't given it yet.  OK, I think the overwhelming vote is in favor of answer ", "number two. I see some sixes, I don't know.  That's a perfectly good answer, too, but hopefully in a few  minutes it won't be I don't know anymore. ", "So, let's see. How do we find -- -- the length  of a vector three, two, one? ", "Well, so, this vector, A, it comes towards us along  the x axis by three units. It goes to the right along the ", "y axis by two units, and then it goes up by one unit  along the z axis. OK, so, it's pointing towards  here. That's pretty hard to draw. ", "So, how do we get its length? Well, maybe we can start with  something easier, the length of the vector in the  plane. So, observe that A is obtained ", "from a vector, B, in the plane.  Say, B equals three (i) hat plus two (j) hat.  And then, we just have to, still, go up by one unit, ", "OK? So, let me try to draw a  picture in this vertical plane that contains A and B.  If I draw it in the vertical plane,  so, that's the Z axis, that's not any particular axis, ", "then my vector B will go here, and my vector A will go above ", "it. And here, that's one unit.  And, here I have a right angle. So, I can use the Pythagorean ", "theorem to find that length A^2 equals length B^2 plus one.  Now, we are reduced to finding the length of B. ", "The length of B, we can again find using the  Pythagorean theorem in the XY plane because here we have the  right angle. Here we have three units,  and here we have two units. OK, so, if you do the ", "calculations, you will see that,  well, length of B is square root of (3^2 2^2),  that's 13. So, the square root of 13 -- -- ", "and length of A is square root of length B^2 plus one (square  it if you want) which is going to be square root of 13 plus one ", "is the square root of 14, hence, answer number two which  almost all of you gave. OK, so the general formula, ", "if you follow it with it, in general if we have a vector  with components a1, a2, a3, ", "then the length of A is the square root of a1^2 plus a2^2  plus a3^2. OK, any questions about that? ", "Yes? Yes.  So, in general, we indeed can consider vectors  in abstract spaces that have any number of coordinates. ", "And that you have more components.  In this class, we'll mostly see vectors with  two or three components because they are easier to draw,  and because a lot of the math that we'll see works exactly the ", "same way whether you have three variables or a million  variables. If we had a factor with more  components, then we would have a lot of trouble drawing it.  But we could still define its length in the same way, ", "by summing the squares of the components.  So, I'm sorry to say that here, multi-variable,  multi will mean mostly two or three.  But, be assured that it works just the same way if you have ", "10,000 variables. Just, calculations are longer.  OK, more questions? So, what else can we do with ", "vectors? Well, another thing that I'm  sure you know how to do with vectors is to add them to scale  them. So, vector addition, ", "so, if you have two vectors, A and B, then you can form,  their sum, A plus B. How do we do that? ", "Well, first, I should tell you,  vectors, they have this double life.  They are, at the same time, geometric objects that we can  draw like this in pictures, and there are also ", "computational objects that we can represent by numbers.  So, every question about vectors will have two answers,  one geometric, and one numerical.  OK, so let's start with the geometric. ", "So, let's say that I have two vectors, A and B,  given to me. And, let's say that I thought  of drawing them at the same place to start with. ", "Well, to take the sum, what I should do is actually  move B so that it starts at the end of A, at the head of A.  OK, so this is, again, vector B. So, observe, ", "this actually forms, now, a parallelogram,  right? So, this side is,  again, vector A. And now, if we take the ", "diagonal of that parallelogram, this is what we call A plus B,  OK, so, the idea being that to move along A plus B, ", "it's the same as to move first along A and then along B,  or, along B, then along A. A plus B equals B plus A.  OK, now, if we do it numerically, ", "then all you do is you just add the first component of A with  the first component of B, the second with the second, ", "and the third with the third. OK, say that A was  ***amp***lt;a1, a2, a3***amp***gt;  B was ***amp***lt;b1, b2, b3***amp***gt;, ", "then you just add this way. OK, so it's pretty  straightforward. So, for example,  I said that my vector over there, its components are three, ", "two, one. But, I also wrote it as 3i 2j k.  What does that mean? OK, so I need to tell you first  about multiplying by a scalar. So, this is about addition. ", "So, multiplication by a scalar, it's very easy.  If you have a vector, A, then you can form a vector  2A just by making it go twice as far in the same direction. ", "Or, we can make half A more modestly.  We can even make minus A, and so on. ", "So now, you see, if I do the calculation,  3i 2j k, well, what does it mean?  3i is just going to go along the x axis, but by distance of ", "three instead of one. And then, 2j goes two units  along the y axis, and k goes up by one unit.  Well, if you add these together, you will go from the ", "origin, then along the x axis, then parallel to the y axis,  and then up. And, you will end up,  indeed, at the endpoint of a vector. ", "OK, any questions at this point? Yes? ", "Exactly. To add vectors geometrically,  you just put the head of the first vector and the tail of the  second vector in the same place. And then, it's head to tail ", "addition. Any other questions?  Yes? That's correct. ", "If you subtract two vectors, that just means you add the  opposite of a vector. So, for example,  if I wanted to do A minus B, I would first go along A and  then along minus B, which would take me somewhere ", "over there, OK? So, A minus B,  if you want, would go from here to here.  OK, so hopefully you've kind of seen that stuff either before in ", "your lives, or at least yesterday.  So, I'm going to use that as an excuse to move quickly forward. ", "So, now we are going to learn a few more operations about  vectors. And, these operations will be  useful to us when we start trying to do a bit of geometry. ", "So, of course, you've all done some geometry.  But, we are going to see that geometry can be done using  vectors. And, in many ways,  it's the right language for that, ", "and in particular when we learn about functions we really will  want to use vectors more than, maybe, the other kind of  geometry that you've seen before. ", "I mean, of course, it's just a language in a way.  I mean, we are just reformulating things that you  have seen, you already know since childhood.  But, you will see that notation somehow helps to make it more ", "straightforward. So, what is dot product?  Well, dot product as a way of multiplying two vectors to get a  number, a scalar. And, well, let me start by ", "giving you a definition in terms of components.  What we do, let's say that we have a vector,  A, with components a1, a2, a3, vector B with ", "components b1, b2, b3.  Well, we multiply the first components by the first  components, the second by the second, the third by the third. ", "If you have N components, you keep going.  And, you sum all of these together.  OK, and important: this is a scalar. ", "OK, you do not get a vector. You get a number.  I know it sounds completely obvious from the definition  here, but in the middle of the action  when you're going to do complicated problems, ", "it's sometimes easy to forget. So, that's the definition.  What is it good for? Why would we ever want to do ", "that? That's kind of a strange  operation. So, probably to see what it's  good for, I should first tell you what it is geometrically. ", "OK, so what does it do geometrically?  ", "Well, what you do when you multiply two vectors in this  way, I claim the answer is equal to  the length of A times the length of B times the cosine of the ", "angle between them. So, I have my vector, A,  and if I have my vector, B, and I have some angle between ", "them, I multiply the length of A  times the length of B times the cosine of that angle.  So, that looks like a very artificial operation.  I mean, why would want to do that complicated multiplication? ", "Well, the basic answer is it tells us at the same time about  lengths and about angles. And, the extra bonus thing is  that it's very easy to compute if you have components, ", "see, that formula is actually pretty easy.  So, OK, maybe I should first tell you, how do we get this ", "from that? Because, you know,  in math, one tries to justify everything to prove theorems.  So, if you want, that's the theorem.  That's the first theorem in 18.02.  So, how do we prove the theorem? How do we check that this is, ", "indeed, correct using this definition?  So, in more common language, what does this geometric ", "definition mean? Well, the first thing it means,  before we multiply two vectors, let's start multiplying a  vector with itself. That's probably easier. ", "So, if we multiply a vector, A, with itself,  using this dot product, so, by the way,  I should point out, we put this dot here.  That's why it's called dot product. ", "So, what this tells us is we should get the same thing as  multiplying the length of A with itself, so, squared, ", "times the cosine of the angle. But now, the cosine of an  angle, of zero, cosine of zero you all know is ", "one. OK, so that's going to be  length A^2. Well, doesn't stand a chance of  being true? Well, let's see.  If we do AdotA using this formula, we will get a1^2 a2^2 ", "a3^2. That is, indeed,  the square of the length. So, check. ", "That works. OK, now, what about two  different vectors? Can we understand what this  says, and how it relates to that? ", "So, let's say that I have two different vectors,  A and B, and I want to try to understand what's going on. ", "So, my claim is that we are going to be able to understand  the relation between this and that in terms of the law of  cosines. So, the law of cosines is ", "something that tells you about the length of the third side in  the triangle like this in terms of these two sides,  and the angle here. OK, so the law of cosines, ", "which hopefully you have seen before, says that,  so let me give a name to this side.  Let's call this side C, and as a vector, ", "C is A minus B. It's minus B plus A. ", "So, it's getting a bit cluttered here.  So, the law of cosines says that the length of the third ", "side in this triangle is equal to length A2 plus length B2.  Well, if I stopped here, that would be Pythagoras, ", "but I don't have a right angle. So, I have a third term which  is twice length A, length B, cosine theta, ", "OK? Has everyone seen this formula  sometime? I hear some yeah's.  I hear some no's. Well, it's a fact about,  I mean, you probably haven't seen it with vectors, ", "but it's a fact about the side lengths in a triangle.  And, well, let's say, if you haven't seen it before,  then this is going to be a proof of the law of cosines if ", "you believe this. Otherwise, it's the other way  around. So, let's try to see how this ", "relates to what I'm saying about the dot product.  So, I've been saying that length C^2, that's the same ", "thing as CdotC, OK?  That, we have checked. Now, CdotC, well,  C is A minus B. So, it's A minus B, ", "dot product, A minus B.  Now, what do we want to do in a situation like that?  Well, we want to expand this into a sum of four terms. ", "Are we allowed to do that? Well, we have this dot product  that's a mysterious new operation.  We don't really know. Well, the answer is yes,  we can do it. You can check from this ", "definition that it behaves in the usual way in terms of  expanding, vectoring, and so on.  So, I can write that as AdotA minus AdotB minus BdotA plus ", "BdotB. So, AdotA is length A^2.  Let me jump ahead to the last term.  BdotB is length B^2, and then these two terms, ", "well, they're the same. You can check from the  definition that AdotB and BdotA are the same thing.  ", "Well, you see that this term, I mean, this is the only  difference between these two formulas for the length of C. ", "So, if you believe in the law of cosines, then it tells you  that, yes, this a proof that AdotB equals length A length B  cosine theta. Or, vice versa, ", "if you've never seen the law of cosines, you are willing to  believe this. Then, this is the proof of the  law of cosines. So, the law of cosines, ", "or this interpretation, are equivalent to each other.  OK, any questions? Yes? ", "So, in the second one there isn't a cosine theta because I'm  just expanding a dot product. OK, so I'm just writing C  equals A minus B, and then I'm expanding this ", "algebraically. And then, I get to an answer  that has an A.B. So then, if I wanted to express  that without a dot product, then I would have to introduce  a cosine. And, I would get the same as ", "that, OK? So, yeah, if you want,  the next step to recall the law of cosines would be plug in this  formula for AdotB. And then you would have a ", "cosine. OK, let's keep going. ", "OK, so what is this good for? Now that we have a definition,  we should figure out what we can do with it.  So, what are the applications of dot product? ", "Well, will this discover new applications of dot product  throughout the entire semester,but let me tell you at  least about those that are readily visible.  So, one is to compute lengths and angles, especially angles. ", "So, let's do an example. Let's say that,  for example, I have in space, ", "I have a point, P, which is at (1,0,0).  I have a point, Q, which is at (0,1,0). ", "So, it's at distance one here, one here.  And, I have a third point, R at (0,0,2),  so it's at height two. And, let's say that I'm ", "curious, and I'm wondering what is the angle here?  So, here I have a triangle in space connect P,  Q, and R, and I'm wondering, what is this angle here? ", "OK, so, of course, one solution is to build a  model and then go and measure the angle.  But, we can do better than that. We can just find the angle  using dot product. So, how would we do that? ", "Well, so, if we look at this formula, we see,  so, let's say that we want to find the angle here. ", "Well, let's look at the formula for PQdotPR.  Well, we said it should be length PQ times length PR times ", "the cosine of the angle, OK?  Now, what do we know, and what do we not know?  Well, certainly at this point we don't know the cosine of the  angle. That's what we would like to ", "find. The lengths,  certainly we can compute. We know how to find these  lengths. And, this dot product we know  how to compute because we have an easy formula here. ", "OK, so we can compute everything else and then find  theta. So, I'll tell you what we will  do is we will find theta -- -- in this way. ", "We'll take the dot product of PQ with PR, and then we'll  divide by the lengths.  ", "OK, so let's see. So, we said cosine theta is ", "PQdotPR over length PQ length PR.  So, let's try to figure out what this vector,  PQ, well, to go from P to Q, ", "I should go minus one unit along the x direction plus one  unit along the y direction. And, I'm not moving in the z  direction. So, to go from P to Q, ", "I have to move by ***amp***lt;-1,1,0***amp***gt;.  To go from P to R, I go -1 along the x axis and 2 ", "along the z axis. So, PR, I claim, is this.  OK, then, the lengths of these vectors, well,(-1)^2 (1)^2 ", "(0)^2, square root, and then same thing with the  other one. OK, so, the denominator will ", "become the square root of 2, and there's a square root of 5.  What about the numerator? Well, so, remember, ", "to do the dot product, we multiply this by this,  and that by that, that by that.  And, we add. Minus 1 times minus 1 makes 1 ", "plus 1 times 0, that's 0.  Zero times 2 is 0 again. So, we will get 1 over square ", "root of 10. That's the cosine of the angle.  And, of course if we want the actual angle,  well, we have to take a calculator, find the inverse ", "cosine, and you'll find it's about 71.5¬∞.  Actually, we'll be using mostly radians, but for today, ", "that's certainly more speaking. OK, any questions about that?  No? OK, so in particular, ", "I should point out one thing that's really neat about the  answer. I mean, we got this number.  We don't really know what it means exactly because it mixes  together the lengths and the angle. ", "But, one thing that's interesting here,  it's the sign of the answer, the fact that we got a positive  number. So, if you think about it,  the lengths are always positive. ", "So, the sign of a dot product is the same as a sign of cosine  theta. So, in fact, ", "the sign of AdotB is going to be positive if the angle is less ", "than 90¬∞. So, that means geometrically,  my two vectors are going more or less in the same direction.  They make an acute angle. It's going to be zero if the ", "angle is exactly 90¬∞, OK, because that's when the  cosine will be zero. And, it will be negative if the ", "angle is more than 90¬∞. So, that means they go,  however, in opposite directions.  So, that's basically one way to think about what dot product ", "measures. It measures how much the two  vectors are going along each other.  OK, and that actually leads us to the next application. ", "So, let's see, did I have a number one there?  Yes. So, if I had a number one,  I must have number two. The second application is to ", "detect orthogonality. It's to figure out when two  things are perpendicular. OK, so orthogonality is just a  complicated word from Greek to say things are perpendicular. ", "So, let's just take an example. Let's say I give you the  equation x 2y 3z = 0. OK, so that defines a certain ", "set of points in space, and what do you think the set  of solutions look like if I give you this equation? ", "So far I see one, two, three answers,  OK. So, I see various competing ", "answers, but, yeah, I see a lot of people  voting for answer number four. I see also some I don't knows, ", "and some other things. But, the majority vote seems to  be a plane. And, indeed that's the correct  answer. So, how do we see that it's a ", "plane?  ", "So, I should say, this is the equation of a  plane. So, there's many ways to see  that, and I'm not going to give you all of them. ", "But, here's one way to think about it.  So, let's think geometrically about how to express this  condition in terms of vectors. So, let's take the origin O, ", "by convention is the point (0,0,0).  And, let's take a point, P, that will satisfy this  equation on it, so, at coordinates x, ", "y, z. So, what does this condition  here mean? Well, it means the following  thing. So, let's take the vector, OP. ", "OK, so vector OP, of course, has components x,  y, z. Now, we can think of this as  actually a dot product between OP and a mysterious vector that ", "won't remain mysterious for very long,  namely, the vector one, two, three.  OK, so, this condition is the same as OP.A equals zero, ", "right? If I take the dot product  OPdotA I get x times one plus y times two plus z times three. ", "But now, what does it mean that the dot product between OP and A  is zero? Well, it means that OP and A ", "are perpendicular. OK, so I have this vector, A.  I'm not going to be able to draw it realistically.  Let's say it goes this way. Then, a point, ", "P, solves this equation exactly when the vector from O to P is  perpendicular to A. And, I claim that defines a  plane. For example,  if it helps you to see it, take a vertical vector. ", "What does it mean to be perpendicular to the vertical  vector? It means you are horizontal.  It's the horizontal plane. Here, it's a plane that passes ", "through the origin and is perpendicular to this vector,  A. OK, so what we get is a plane ", "through the origin perpendicular to A. ", "And, in general, what you should remember is  that two vectors have a dot product equal to zero if and ", "only if that's equivalent to the cosine of the angle between them  is zero. That means the angle is 90¬∞. ", "That means A and B are perpendicular.  So, we have a very fast way of checking whether two vectors are ", "perpendicular. So, one additional application  I think we'll see actually tomorrow is to find the  components of a vector along a certain direction. ", "So, I claim we can use this intuition I gave about dot  product telling us how much to vectors go in the same direction  to actually give a precise meaning to the notion of  component for vector, not just along the x, ", "y, or z axis, but along any direction in  space. So, I think I should probably  stop here. But, I will see you tomorrow at ", "2:00 here, and we'll learn more about that and about cross  products. "], "vid_duration": [12.0, 11.0, 10.0, 14.0, 11.0, 13.0, 10.0, 10.0, 11.0, 11.0, 10.0, 10.0, 14.0, 10.0, 11.0, 10.0, 17.0, 10.0, 11.0, 10.0, 18.0, 11.0, 11.0, 16.0, 15.0, 15.0, 12.0, 13.0, 11.0, 14.0, 13.0, 14.0, 10.0, 14.0, 12.0, 11.0, 11.0, 11.0, 12.0, 11.0, 18.0, 13.0, 13.0, 16.0, 13.0, 11.0, 11.0, 15.0, 15.0, 11.0, 13.0, 10.0, 12.0, 10.0, 14.0, 10.0, 12.0, 13.0, 10.0, 12.0, 13.0, 18.0, 14.0, 11.0, 12.0, 11.0, 11.0, 14.0, 11.0, 11.0, 11.0, 16.0, 15.0, 11.0, 10.0, 10.0, 13.0, 14.0, 11.0, 11.0, 12.0, 12.0, 10.0, 10.0, 11.0, 13.0, 13.0, 12.0, 13.0, 10.0, 13.0, 14.0, 11.0, 11.0, 10.0, 11.0, 14.0, 11.0, 13.0, 13.0, 12.0, 15.0, 12.0, 10.0, 16.0, 11.0, 11.0, 12.0, 13.0, 11.0, 11.0, 12.0, 10.0, 11.0, 22.0, 12.0, 19.0, 10.0, 11.0, 12.0, 14.0, 12.0, 12.0, 12.0, 15.0, 13.0, 22.0, 11.0, 11.0, 12.0, 13.0, 12.0, 12.0, 12.0, 10.0, 11.0, 14.0, 43.0, 13.0, 12.0, 10.0, 10.0, 13.0, 12.0, 10.0, 11.0, 10.0, 13.0, 10.0, 11.0, 10.0, 11.0, 10.0, 13.0, 14.0, 12.0, 11.0, 12.0, 10.0, 14.0, 15.0, 11.0, 14.0, 12.0, 10.0, 15.0, 12.0, 14.0, 12.0, 11.0, 12.0, 15.0, 10.0, 10.0, 13.0, 13.0, 11.0, 18.0, 11.0, 10.0, 11.0, 11.0, 13.0, 12.0, 12.0, 6.03], "stet": [[0, 12.0], [12.0, 23.0], [23.0, 33.0], [33.0, 47.0], [47.0, 58.0], [58.0, 71.0], [71.0, 81.0], [81.0, 91.0], [91.0, 102.0], [102.0, 113.0], [113.0, 123.0], [123.0, 133.0], [133.0, 147.0], [147.0, 157.0], [157.0, 168.0], [168.0, 178.0], [178.0, 195.0], [195.0, 205.0], [205.0, 216.0], [216.0, 226.0], [226.0, 244.0], [244.0, 255.0], [255.0, 266.0], [266.0, 282.0], [282.0, 297.0], [297.0, 312.0], [312.0, 324.0], [324.0, 337.0], [337.0, 348.0], [348.0, 362.0], [362.0, 375.0], [375.0, 389.0], [389.0, 399.0], [399.0, 413.0], [413.0, 425.0], [425.0, 436.0], [436.0, 447.0], [447.0, 458.0], [458.0, 470.0], [470.0, 481.0], [481.0, 499.0], [499.0, 512.0], [512.0, 525.0], [525.0, 541.0], [541.0, 554.0], [554.0, 565.0], [565.0, 576.0], [576.0, 591.0], [591.0, 606.0], [606.0, 617.0], [617.0, 630.0], [630.0, 640.0], [640.0, 652.0], [652.0, 662.0], [662.0, 676.0], [676.0, 686.0], [686.0, 698.0], [698.0, 711.0], [711.0, 721.0], [721.0, 733.0], [733.0, 746.0], [746.0, 764.0], [764.0, 778.0], [778.0, 789.0], [789.0, 801.0], [801.0, 812.0], [812.0, 823.0], [823.0, 837.0], [837.0, 848.0], [848.0, 859.0], [859.0, 870.0], [870.0, 886.0], [886.0, 901.0], [901.0, 912.0], [912.0, 922.0], [922.0, 932.0], [932.0, 945.0], [945.0, 959.0], [959.0, 970.0], [970.0, 981.0], [981.0, 993.0], [993.0, 1005.0], [1005.0, 1015.0], [1015.0, 1025.0], [1025.0, 1036.0], [1036.0, 1049.0], [1049.0, 1062.0], [1062.0, 1074.0], [1074.0, 1087.0], [1087.0, 1097.0], [1097.0, 1110.0], [1110.0, 1124.0], [1124.0, 1135.0], [1135.0, 1146.0], [1146.0, 1156.0], [1156.0, 1167.0], [1167.0, 1181.0], [1181.0, 1192.0], [1192.0, 1205.0], [1205.0, 1218.0], [1218.0, 1230.0], [1230.0, 1245.0], [1245.0, 1257.0], [1257.0, 1267.0], [1267.0, 1283.0], [1283.0, 1294.0], [1294.0, 1305.0], [1305.0, 1317.0], [1317.0, 1330.0], [1330.0, 1341.0], [1341.0, 1352.0], [1352.0, 1364.0], [1364.0, 1374.0], [1374.0, 1385.0], [1385.0, 1407.0], [1407.0, 1419.0], [1419.0, 1438.0], [1438.0, 1448.0], [1448.0, 1459.0], [1459.0, 1471.0], [1471.0, 1485.0], [1485.0, 1497.0], [1497.0, 1509.0], [1509.0, 1521.0], [1521.0, 1536.0], [1536.0, 1549.0], [1549.0, 1571.0], [1571.0, 1582.0], [1582.0, 1593.0], [1593.0, 1605.0], [1605.0, 1618.0], [1618.0, 1630.0], [1630.0, 1642.0], [1642.0, 1654.0], [1654.0, 1664.0], [1664.0, 1675.0], [1675.0, 1689.0], [1689.0, 1732.0], [1732.0, 1745.0], [1745.0, 1757.0], [1757.0, 1767.0], [1767.0, 1777.0], [1777.0, 1790.0], [1790.0, 1802.0], [1802.0, 1812.0], [1812.0, 1823.0], [1823.0, 1833.0], [1833.0, 1846.0], [1846.0, 1856.0], [1856.0, 1867.0], [1867.0, 1877.0], [1877.0, 1888.0], [1888.0, 1898.0], [1898.0, 1911.0], [1911.0, 1925.0], [1925.0, 1937.0], [1937.0, 1948.0], [1948.0, 1960.0], [1960.0, 1970.0], [1970.0, 1984.0], [1984.0, 1999.0], [1999.0, 2010.0], [2010.0, 2024.0], [2024.0, 2036.0], [2036.0, 2046.0], [2046.0, 2061.0], [2061.0, 2073.0], [2073.0, 2087.0], [2087.0, 2099.0], [2099.0, 2110.0], [2110.0, 2122.0], [2122.0, 2137.0], [2137.0, 2147.0], [2147.0, 2157.0], [2157.0, 2170.0], [2170.0, 2183.0], [2183.0, 2194.0], [2194.0, 2212.0], [2212.0, 2223.0], [2223.0, 2233.0], [2233.0, 2244.0], [2244.0, 2255.0], [2255.0, 2268.0], [2268.0, 2280.0], [2280.0, 2292.0], [2292.0, 2298.03]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [900, 1523, 2298]}
{"example_id": "mit002@@ocw-18_02-f07-lec17_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  Yesterday we saw how to define double integrals and how to  start computing them in terms of x and y coordinates. ", "We have defined the double integral over a region R and  plane of a function f of x, y dA. ", "You cannot hear me? Is the sound working?  Can you hear me in the back now? Can we make the sound louder? ", "Does this work? People are not hearing me in  the back. Is it better?  People are still saying make it louder. ", "Is it better? OK.  Great. Thanks.  That's not a reason to start chatting with your friends. ", "Thanks. When we have a region in the x,  y plane and we have a function of x and y,  we are defining the double integral of f over this region ", "by taking basically the sum of the values of a function  everywhere in here times the area element.  And the definition, actually, is we split the region into ", "lots of tiny little pieces, we multiply the value of a  function at the point times the area of a little piece and we  sum that everywhere. And we have seen, ", "actually, how to compute these things as iterated integrals.  First, integrating over dy and then over dx, ", "or the other way around. One example that we did,  in particular, was to compute the double ", "integral of a quarter of a unit disk.  That was the region where x squared plus y squared is less ", "than one and x and y are positive, of one minus x squared  minus y squared dA. Well, hopefully,  I kind of convinced you that we can do it using enough trig and ", "substitutions and so on, but it is not very pleasant.  And the reason for that is that using x and y coordinates here  does not seem very appropriate. In fact, we can use polar ", "coordinates instead to compute this double integral. ", "Remember that polar coordinates are about replacing x and y as  coordinates for a point on a plane by instead r, ", "which is the distance from the origin to a point,  and theta, which is the angle measured  counterclockwise from the positive x-axis. ", "In terms of r and theta, you have x equals r cosine  theta, y equals r sine theta. The claim is we are able, ", "actually, to do double integrals in polar coordinates.  We just have to learn how to. Just to draw a quick picture -- ", "When we were integrating in x, y coordinates,  in rectangular coordinates, we were slicing our region by ", "gridlines that were either horizontal or vertical.  And we used that to set up the iterated integral.  And we said dA became dx dy or dy dx. ", "Now we are going to actually integrate, in terms of the polar  coordinates, r and theta. Let's say we will integrate in ", "the order with r first and then theta.  That is the order that makes the most sense usually when you  do polar coordinates. What does that mean? ", "It means that we will first focus on a slice where we fix  the value of theta and we will let r vary.  That means we fix a direction, we fix a ray out from the ", "origin in a certain direction. And we will travel along this  ray and see which part of it, which values of r are in our  region. Here it will be actually pretty ", "easy because r will just start at zero, and you will have to  stop when you exit this quarter disk. ", "Well, what is the equation of this circle in polar  coordinates? It is just r equals one.  So, we will stop when r reaches one. ", "But what about theta? Well, the first ray that we  might want to consider is the one that goes along the x-axis.  That is when theta equals zero. And we will stop when theta ", "reaches pi over two because we don't care about the rest of the  disk. We only care about the first  quadrant. We will stop at pi over two. ", "Now, there is a catch, though, which is that dA is not  dr d theta. Let me explain to you why. ", "Let's say that we are slicing. What it means is we are cutting  our region into little pieces that are the elementary,  you know, what corresponds to a small ", "rectangle in the x, y coordinate system,  here would be actually a little piece of circle between a given ", "radius r and r plus delta r. And given between an angle  theta and theta plus delta theta.  I need to draw, actually, a bigger picture of ", "that because it makes it really hard to read.  Let's say that I fix an angle theta and a slightly different ", "one where I have added delta theta to it.  And let's say that I have a radius r and I add delta r to ", "it. Then I will have a little piece  of x, y plane that is in here. And I have to figure out what  is its area? What is delta A for this guy? ", "Well, let's see. This guy actually,  you know, if my delta r and delta theta are small enough,  it will almost look like a rectangle.  It is rotated, but it is basically a ", "rectangle. I mean these sides,  of course, are curvy, but they are short enough and  it is almost straight. The area here should be this ", "length times that length. Well, what is this length?  That one is easy. It is delta r. ", "What about that length? Well, it is not delta theta.  It is something slightly different.  It is a piece of a circle of radius r corresponding to angle ", "delta theta, so it is r delta theta.  So, times r delta theta. That means now, ", "even if we shrink things and take smaller and smaller  regions, dA is going to be r dr d theta. ", "That is an important thing to remember.  When you integrate in polar coordinates, you just set up  your bounds in terms of r and theta, but you replace dA by r ", "dr d theta, not just dr d theta. And then, of course,  we have some function that we are integrating.  Let's say that I call that thing f then it is the same f ", "that I put up here. Concretely, how do I do it here?  Well, my function f was given as one minus x squared minus y ", "squared. And I would like to switch that  to polar coordinates. I want to put r and theta in  there. Well, I have formulas for x and  y in polar coordinates so I could just replace x squared by ", "r squared cosine squared theta, y squared by r squared sine  squared theta. And that works just fine.  But maybe you can observe that this is x squared plus y ", "squared. It is just the square of a  distance from the origin, so that is just r squared.  That is a useful thing. You don't strictly need it,  but it is much faster if you see this right away. ", "It saves you writing down a sine and a cosine. ", "Now we just end up with the integral from zero to pi over  two, integral from zero to one of one minus r squared r dr d ", "theta. Now, if I want to compute this  integral, so let's first do the inner integral. ", "If I integrate r minus r cubed, I will get r squared over two  minus r squared over four between zero and one. ", "And then I will integrate d theta.  What is this equal to? Well, for r equals one you get  one-half minus one-quarter, which is going to be just ", "one-quarter. And when you plug in zero you  get zero. So, it is the integral from  zero to pi over two of one-quarter d theta.  And that just integrates to one-quarter times pi over two, ", "which is pi over eight. That is a lot easier than the  way we did it yesterday. Well, here we were lucky. ", "I mean usually you will switch to polar coordinates either  because the region is easier to set up.  Here it is indeed easier to set up because the bounds became  very simple. We don't have that square root ", "of one minus x squared anymore. Or because the integrant  becomes much simpler. Here our function,  well, it is not very complicated in x,  y coordinates, but it is even simpler in r ", "theta coordinates. Here we were very lucky.  In general, there is maybe a trade off.  Maybe it will be easier to set up bounds but maybe the function  will become harder because it will have all these sines and ", "cosines in it. If our function had been just  x, x is very easy in x, y coordinates.  Here it becomes r cosine theta. That means you will have a ", "little bit of trig to do in the integral.  Not a very big one, not a very complicated  integral, but imagine it could get potentially much harder. ", "Anyway, that is double integrals in polar coordinates.  And the way you set up the bounds in general,  well, in 99% of the cases you will integrate over r first. ", "What you will do is you will look for a given theta what are  the bounds of r to be in the region.  What is the portion of my ray that is in the given region?  And then you will put bounds for theta. ", "But conceptually it is the same as before.  Instead of slicing horizontally or vertically,  we slice radially. We will do more examples in a ", "bit. Any questions about this or the  general method? Yes? ", "That is a very good question. Why do I measure the length  inside instead of outside? Which one do I want?  This one. Here I said this side is r ", "delta theta. I could have said,  actually, r delta theta is the length here.  Here it is slightly more, r plus delta r times delta  theta. But, if delta r is very small  compared to r, then that is almost the same ", "thing. And this is an approximation  anyway. I took this one because it  gives me the simpler formula. If you take the limit as delta ", "r turns to zero then the two things become the same anyway.  The length, whether you put r or r plus delta r in here,  doesn't matter anymore. If you imagine that this guy is ", "infinitely small then, really, the lengths become the  same. We will also see another proof  of this formula, using changes of variables, ", "next week. But, I mean,  hopefully this is at least slightly convincing.  More questions? No. ", "OK. Let's see.  We have seen how to compute double integrals.  I have to tell you what they are good for as well. ", "The definition we saw yesterday and the motivation was in terms  of finding volumes, but that is not going to be our  main preoccupation. Because finding volumes is fun ", "but that is not all there is to life.  I mean, you are doing single integrals.  When you do single integrals it is usually not to find the area  of some region of a plane. It is for something else ", "usually. The way we actually think of  the double integral is really as summing the values of a function  all around this region. We can use that to get  information about maybe the region or about the average ", "value of a function in that region and so on.  Let's think about various uses of double integrals. ", "The first one that I will mention is actually something  you thought maybe you could do with a single integral,  but it is useful very often to do it as a double integral. ", "It is to find the area of a given region r.  I give you some region in the plane and you want to know just ", "its area. In various cases,  you could set this up as a single integral,  but often it could be useful to set it up as a double integral. ", "How do you express the area as a double integral?  Well, the area of this region is the sum of the areas of all  the little pieces. It means you want to sum one dA ", "of the entire region. The area R is the double  integral over R of a function one. ", "One way to think about it, if you are really still  attached to the idea of double integral as a volume,  what this measures is the volume below the graph of a  function one. The graph of a function one is ", "just a horizontal plane at height one.  What you would be measuring is the volume of a prism with base ", "r and height one. And the volume of that would  be, of course, base times height.  It would just be the area of r again.  But we don't actually need to think about it that way. ", "Really, what we are doing is summing dA over the entire  region. A related thing we can do, ", "imagine that, actually, this is some physical  object. I mean, it has to be a flat  object because we are just dealing with things in the plane ", "so far. But you have a flat metal plate  or something and you would like to know its mass.  Well, its mass is the sum of the masses of every single ", "little piece. You would get that by  integrating the density. The density for a flat object  would be the mass per unit area. So, you can get the mass of a ", "flat object with density. Let's use delta for density, ", "which is the mass per unit area.  Each little piece of your object will have a mass, ", "which will be just the density, times its area for each small  piece. And you will get the total mass ", "by summing these things. The mass will be the double  integral of the density times the area element. ", "Now, if it has constant density,  if it is always the same material then,  of course, you could just take the density  out and you will get density times the total area if you know ", "that it is always the same material.  But if, actually, it has varying density maybe  because it is some metallic thing with various metals or ", "with varying thickness or something then you can still get  the mass by integrating the density.  Of course, looking at flat objects might be a little bit  strange. That is because we are only ", "doing double integrals so far. In a few weeks,  we will be triple integrals. And then we will be able to do  solids in space, but one thing at a time.  ", "Another useful application is to find the average value of ", "some quantity in a region. What does it mean to take the  average value of some function f in this region r? ", "Well, you know what the average of a finite set of data is.  For example, if I asked you to compute your  average score on 18.02 problem sets,  you would just take the scores, add them and divide by the ", "number of problem sets. What if there are infinitely  many things? Say I ask you to find the  average temperature in this room.  Well, you would have to measure the temperature everywhere.  And then add all of these together and divide by the ", "number of data points. But, depending on how careful  you are, actually, there are potentially  infinitely many points to look at.  The mathematical way to define the average of a continuous set ", "of data is that you actually integrate the function over the  entire set of data, and then you divide by the size  of the sample, which is just the area of the ", "region. In fact, the average of f,  the notation we will use usually for that is f with a bar ", "on top to tell us it is the average f.  We say we will take the integral of f and we will divide ", "by the area of the region. You can really think of it as  the sum of the values of f everywhere divided by the number ", "of points everywhere. And so that is an average where  everything is, actually, equally likely.  That is a uniform average where all the points on the region, ", "all the little points of the region are equally likely.  But maybe if want to do, say, an average of some solid  with variable density or if you want to somehow give more ", "importance to certain parts than to others then you can actually  do a weighted average. What is a weighted average?  Well, in the case of taking the ", "average your problem sets, if I tell you problem set one  is worth twice as much as the others,  then you would count twice that score in the sum and then you  would count it as two, of course, when you divide. ", "The weighted average is the sum of the values,  but each weighted by a certain coefficient.  And then you will divide by the sum of the weight. ", "It is a bit the same idea as when we replace area by some  mass that tells you how important a given piece. ", "We will actually have a density. Let's call it delta again.  We will see what we divide by, but what we will take is the ", "integral of a function times the density times the area element.  Because this would correspond to the mass element telling us ", "how to weight the various points of our region.  And then we would divide by the total weight,  which is the mass of a region, as defined up there. ", "If a density is uniform then, of course, the density gets out  and you can simplify and reduce to that if all the points are ", "equally likely. Why is that important?  Well, that is important for various applications.  But one that you might have seen in physics,  we care about maybe where is the center of mass of a given ", "object? The center of mass is basically  a point that you would say is right in the middle of the  object. But, of course,  if the object has a very strange shape or if somehow part ", "of it is heavier than the rest then that takes a very different  meaning. Strictly speaking,  the center of mass of a solid is the point where you would ", "have to concentrate all the mass if you wanted it to behave  equivalently from a point of view of mechanics,  if you are trying to do translations of that object. ", "If you are going to push that object that would be really  where the equivalent point mass would lie. ", "The other way to think about it,  if I had a flat object then the center of mass would basically  be the point where I would need to hold it so it is perfectly  balanced. And, of course, ", "I cannot do this. Well, you get the idea.  And the center of mass of this eraser is somewhere in the  middle. And so, in principle,  that is where I would have to put my finger for it to stay. ", "Well, it doesn't work. But that is where the center of  mass should be. I think it should be in the ", "middle. Maybe I shouldn't call this  three. I should call this 2a,  because it is really a special case of the average value. ", "How do we find the center of mass of a flat object with ", "density delta. If you have your object in the ", "x, y plane then its center of mass  will be at positions that are actually just the coordinates of  a center of mass, will just be weighted averages ", "of x and y on the solid. So, the center of mass will be  a position that I will call x bar, y bar.  And these are really just the averages, the average values of ", "x and of y in the solid. Just to give you the formulas  again, x bar would be one over the mass times the double ", "integral of x times density dA. And the same thing with y.  y bar is the weighted average of a y coordinate in your ", "region. You see, if you take a region  that is symmetric and has uniform density that will just  give you the center of the region.  But if the region has a strange shape or if a density is not ", "homogeneous, if parts of it are heavier then  you will get whatever the weighted average will be.  And that will be the point where this thing would be ", "balanced if you were trying to balance it on a pole or on your  finger.  ", "Any questions so far? Yes. ", "No. Here I didn't set this up as a  iterated integral yet. The function that I am ", "integrating is x times delta where density will be given to  me maybe as a function of x and y.  And then I will integrate this dA. ", "And dA could mean dx over dy, it could mean dy over dx,  it could be mean r dr d theta. I will choose how to set it up  depending maybe on the shape of the region. ", "If my solid is actually just going to be round then I might  want to use polar coordinates. If it is a square,  I might want to use x, y coordinates.  If it is more complicated, well, I will choose depending ", "on how I feel about it. Yes?  Delta is the density. In general, it is a function of  x and y. If you imagine that your solid ", "is not homogenous then its density will depend on which  piece of it you are looking at. Of course, to compute this,  you need to know the density. If you have a problem asking ", "you to find the center of mass of something and you have no  information about the density, assume it is uniform.  Take the density to be a constant.  Even take it to be a one. That is even easier. ", "I mean it is a general fact of math.  We don't care about units. If density is constant,  we might as well take it to be one.  That just means our mass unit becomes the area unit. ", "Yes? That is a good question. ", "No, I don't think we could actually find the center of mass  in polar coordinates by finding the average of R or the average  of theta. For example,  take a disk center at the origin, well, ", "the center of mass should be at the origin.  But the average of R is certainly not zero because R is  positive everywhere. So, that doesn't work.  You cannot get the polar coordinates of a center of mass ", "just by taking the average of R and the average of theta.  By the way, what is the average of theta?  If you take theta to from zero to 2pi, the average theta will  be pi. If you take it to go from minus ", "pi to pi, the average theta will be zero.  So, there is a problem there. That actually just doesn't  work, so we really have to compute x bar and y bar. ", "But still we could set this up and then switch to polar  coordinates to evaluate this integral.  But we still would be computing the average values of x and y. ", "We are basically re-exploring mechanics and motion of solids  here. The next thing is moment of ", "inertia. Just to remind you or in case  you somehow haven't seen it in physics yet,  the moment of inertia is basically to rotation of a solid ", "where the mass is to translation.  In the following sense, the mass of a solid is what  makes it hard to push it. How hard it is to throw ", "something is related to its mass.  How hard it is to spin something, on the other hand,  is given by its moment of inertia. ", "Maybe I should write this down. Mass is how hard it is to  impart a translation motion to a solid. ", "I am using fancy words today. And the moment of inertia --  The difference with a mass is that the moment of inertia is ", "defined about some axis. You choose an axis.  Then you would try to measure how hard it is to spin your  object around that axis. For example,  you can try to measure how hard it is to spin this sheet of ", "paper about an axis that is in the center of it.  We would try to spin it light that and see how much effort I  would have to make. Well, for a sheet of paper not ", "very much. That would measure the same  thing but it would be rotation motion about that axis. ", "Maybe some of you know the definition but I am going to try  to derive it again. I am sorry but it won't be as  quite as detailed as the way you have probably seen it in  physics, but I am not trying to replace your physics teachers. ", "I am sure they are doing a great job.  What is the idea for the definition to find a formula for ", "moment of inertia? The idea is to think about  kinetic energy. Kinetic energy is really when  you push something or when you try to make it move and you have  to put some inertia to it. Then it has kinetic energy. ", "And then, if you have the right device, you can convert back  that kinetic energy into something else.  If you try to look at the kinetic energy of a point mass, ", "so you have something with mass m going at the velocity v,  well, that will be one-half of a mass times the square of the ", "speed. I hope you have all seen that  formula some time before. Now, let's say instead of just  trying to push this mass, I am going to make it spin ", "around something. Instead of just somewhere,  maybe I will have the origin, and I am trying to make it go ", "around the origin in a circle at a certain angular velocity.  For a mass m at distance r, let's call r this distance. ", "And angular velocity, let's call the angular velocity  omega. I think that is what physicists ", "call it. Remember angular velocity is  just the rate of the change of the angle over time.  It is d theta dt, if you want. Well, what is the kinetic ", "energy now? Well, first we have to find out  what the speed is. What is the speed?  Well, if we are going on a circle of  radius r at angular velocity omega that means that in unit ", "time we rotate by omega and we go by a distance of r times  omega. The actual speed is the radius ", "times angular velocity. And so the kinetic energy is  one-half mv squared, which is one-half m r squared ", "omega squared. And so,  by similarity with that formula,  the coefficient of v squared is the mass, ", "and here we will say the coefficient of omega squared,  so this thing is the moment of inertia.  That is how we define moment of inertia. ", "Now, that is only for a point mass.  And it is kind of fun to spin just a small bowl,  but maybe you would like to spin actually a larger solid and ", "try to define this moment of inertia.  Well, the moment inertia of a solid will be just the sum of  the moments of inertia of all the little pieces. ", "What we will do is just cut our solid into little chunks and  will sum this thing for each little piece. ", "For a solid with density delta, each little piece has mass  which is the density times the amount of area. ", "This is equal actually. And the moment of inertia of  that small portion of a solid will be delta m,  the small mass, times r squared, ", "the square of a distance to the center of the axis along which I  am spinning. That means if I sum these ", "things together, well, it has moment of inertia  delta m times r squared, which is r squared times the ", "density times delta A. And so I will be summing these  things together. And so, the moment of inertia ", "about the origin will be the double integral of r squared  times density times dA.  ", "The final formula for the moment of inertia about the  origin is the double integral of a region of r squared density ", "dA. If you are going to do it in x,  y coordinates, of course, r squared becomes x  squared plus y squared, it is the square of the ", "distance from the origin. When you integrate this,  that tells you how hard it is to spin that solid about the  origin. The motion that we try to do -- ", "We keep this fixed and then we just rotate around the origin.  Sorry. That is a pretty bad picture, ", "but hopefully you know what I mean.  And the name we use for that is I0.  And then the rotational kinetic energy is one-half times this ", "moment of inertia times the square of the angular velocity.  So that shows as that this replaces the mass for rotation ", "motions. OK.  What about other kinds of rotations?  In particular, we have been rotating things ", "about just a point in the plane. What you could imagine also is  instead you have your solid. What I have done so far is I ", "have skewered it this way, and I am rotating around the  axis. Instead, I could skewer it  through, say, the horizontal axis.  And then I could try to spin about the horizontal axis so ", "then it would rotate in space in that direction like that. ", "Let's say we do rotation about the x-axis.  Well, the idea would still be the same.  The moment of inertia for any small piece of a solid would be ", "its mass element times the square of a distance to the x  axes because that will be the radius of a trajectory.  If you take this point here, it is going to go in a circle ", "like that centered on the x-axis.  So the radius will just be this distance here.  Well, what is this distance? It is just y, ", "or maybe absolute value of y. Distance to x-axis is absolute ", "value of y. What we actually care about is  the square of a distance, so it will just be y squared. ", "The moment of inertia about the x-axis is going to be obtained  by integrating y squared times the mass element. ", "It is slightly strange but I have y in inertia about the  x-axis. But, if you think about it,  y tells me how far I am from the x-axis, so how hard it will ", "be to spin around the x-axis. And I could do the same about  any axis that I want. Just I would have to sum the ", "square of a distance to the axis of rotation.  Maybe I should do an example. Yes? ", "Same thing as above, distance to the x-axis,  because that is what we care about.  For the moment of inertia, we want the square of a ", "distance to the axis of rotation.  Let's do an example. Let's try to figure out if we ", "have just a uniform disk how hard it is to spin it around its  center. That shouldn't be very hard to ", "figure out. Say that we have a disk of  radius a and we want to rotate it about its center. ", "And let's say that it is of uniform density.  And let's take just the density to be a one so that we don't  really care about the density. What is the moment of inertia ", "of that? Well, we have to integrate of  our disk r squared times the density, which is one, ", "times dA. What is r squared?  You have here to resist the urge to say the radius is just  a. We know the radius is a.  No, it is not a because we are looking at rotation of any point ", "inside this disk. And, when you are inside the  disk, the distance to the origin is not a.  It is less than a. It is actually anything between  zero and a. Just to point out a pitfall, ", "r here is really a function on this disk.  And we are going to integrate this function.  Don't plug r equals a just yet. What coordinates do we use to ", "compute this integral? They are probably polar  coordinates, unless you want a repeat of what happened already  with x and y. That will tell us we want to ", "integrate r squared time r dr d theta.  And the bounds for r, well, r will go from zero to a.  No matter which direction I go from the origin, ", "if I fixed it, r goes from zero to r equals a.  The part of this ray that lives inside the disk is always from ", "zero to a. And theta goes from,  well, zero to 2 pi for example. And now you can compute this  integral. Well, I will let you figure it ", "out. But the inner integral becomes  a to the four over four and the outer multiplies things by 2pi, ", "so you get pi a to the four over two.  OK. That is how hard it is to spin  this disk. Now, what about instead of ", "spinning it about the center we decided to spin it about a point  on a second point. For example, think of a Frisbee.  A Frisbee has this rim so you can actually try to make it ", "rotate around the point on the circumference by holding it near  the rim and spinning it there. How much harder is that than  around the center? Well, we will try to compute ", "now the moment of inertia about this point.  We have two options. One is we keep the system of  coordinates centers here. But then the formula for ", "distance to this point becomes harder.  The other option, which is the one I will choose,  is to change the coordinate so that this point become the  origin. Let's do that. ", "", "About a point on the circumference,  what I would have to do maybe is set up my region like that. ", "I have moved the origin so that it is on the circumference of a  disk, and I will again try to find  the moment of inertia of this disk about the origin. ", "It is still, for the the double integral of  r squared dA. But now I want to find out how  to set up the integral. I could try to use x, ", "y coordinates and it would work.  Or I can use polar coordinates, and it works a little bit  better that way. But both are doable. ", "Let's say I do it this way. I have to figure out how to set  up my bounds. What are the bounds for r?  Well, if I fix a value for theta, which means I chose an ", "angle here, now I am shooting a ray from the origin in that  direction. I enter my region at r equals ", "zero. That hasn't changed.  The question is where do I exit the region?  What is that distance? Maybe you have seen it in ", "recitation, maybe not. Let's see.  Actually, I should have written down the radius of a circle is  a. So this distance here is 2a. ", "If you draw this segment in here, you know that here you  have a right angle. You have a right triangle.  The hypotenuse here has length 2a. ", "This angle is theta. Well, this length is 2a cosine  theta. The polar coordinates equation ", "of this circle passing through the origin is r equals 2a cosine  theta. So, r will go from zero to 2a ", "cosine theta. That is the distance here.  Now, what are the bounds for theta? ", "It is not quite zero to 2pi because, actually,  you see in this direction, if I shoot a ray in this  direction I will never meet my region.  We have to actually think a bit more. ", "Well, the directions in which I will actually hit my circle are  all the directions in the right half of a plane.  I mean, of course, if I shoot very close to the ", "axis, you might think, oh, I won't be in there.  But, actually, that is not true because here  the circle is tangent to the axis.  No matter which direction I take, I will still have a little ", "tiny piece. The angle actually goes from  minus pi over two to pi over two.  If you compute that you will get, ", "well, the inner integral will be r to the four over four  between zero and 2a cosine theta,  which will turn out to be 4a to the four cosine to the four ", "theta. And now you will integrate that  for minus pi over two to pi over two.  And that is, again, the evil integral that ", "we had yesterday. Either we remember the method  from yesterday or we remember from yesterday that actually  there are formulas in the notes to help you.  On homework, you can use these formulas. ", "In the notes at the beginning of section 3b there are formulas  for these particular kinds of integrals. ", "And that will end up being three-halves of pi a to the  four. In case you wanted to know,  it is three times harder to spin a Frisbee about a point on ", "a circumference than around the center.  We got three times the moment of inertia about the center.  OK. That is it.  Have a nice weekend. "], "vid_duration": [11.0, 12.0, 12.0, 12.0, 13.0, 14.0, 12.0, 11.0, 15.0, 11.0, 10.0, 13.0, 16.0, 12.0, 12.0, 12.0, 14.0, 12.0, 10.0, 12.0, 13.0, 12.0, 13.0, 12.0, 10.0, 12.0, 11.0, 14.0, 10.0, 11.0, 10.0, 12.0, 10.0, 13.0, 15.0, 11.0, 13.0, 10.0, 13.0, 13.0, 11.0, 13.0, 16.0, 12.0, 12.0, 14.0, 12.0, 11.0, 13.0, 10.0, 13.0, 11.0, 17.0, 12.0, 11.0, 12.0, 12.0, 10.0, 13.0, 16.0, 12.0, 10.0, 22.0, 13.0, 12.0, 10.0, 13.0, 11.0, 14.0, 15.0, 11.0, 13.0, 13.0, 13.0, 12.0, 15.0, 10.0, 12.0, 18.0, 10.0, 11.0, 11.0, 10.0, 10.0, 12.0, 19.0, 14.0, 11.0, 11.0, 11.0, 11.0, 10.0, 11.0, 27.0, 13.0, 11.0, 11.0, 12.0, 12.0, 12.0, 11.0, 14.0, 13.0, 11.0, 11.0, 15.0, 12.0, 10.0, 10.0, 14.0, 11.0, 16.0, 10.0, 14.0, 12.0, 10.0, 11.0, 11.0, 10.0, 11.0, 16.0, 12.0, 16.0, 10.0, 12.0, 12.0, 12.0, 20.0, 12.0, 10.0, 41.0, 16.0, 11.0, 10.0, 10.0, 13.0, 12.0, 10.0, 11.0, 12.0, 12.0, 12.0, 13.0, 10.0, 10.0, 20.0, 12.0, 13.0, 11.0, 10.0, 15.0, 14.0, 11.0, 11.0, 23.0, 11.0, 10.0, 13.0, 14.0, 11.0, 10.0, 13.0, 20.0, 10.0, 12.0, 14.0, 10.0, 12.0, 13.0, 25.0, 10.0, 10.0, 15.0, 16.0, 11.0, 11.0, 13.0, 10.0, 36.0, 18.0, 10.0, 13.0, 11.0, 17.0, 17.0, 12.0, 13.0, 17.0, 10.0, 12.0, 14.0, 12.0, 10.0, 10.0, 13.0, 10.0, 10.0, 14.0, 16.0, 10.0, 11.0, 21.0, 11.0, 11.0, 14.0, 11.0, 12.0, 11.0, 12.0, 11.0, 12.0, 11.0, 12.0, 13.0, 12.0, 10.0, 11.0, 27.0, 23.0, 14.0, 13.0, 12.0, 14.0, 10.0, 17.0, 14.0, 12.0, 15.0, 13.0, 10.0, 10.0, 11.0, 11.0, 11.0, 14.0, 13.0, 11.0, 10.0, 10.0, 11.03], "stet": [[0, 11.0], [11.0, 23.0], [23.0, 35.0], [35.0, 47.0], [47.0, 60.0], [60.0, 74.0], [74.0, 86.0], [86.0, 97.0], [97.0, 112.0], [112.0, 123.0], [123.0, 133.0], [133.0, 146.0], [146.0, 162.0], [162.0, 174.0], [174.0, 186.0], [186.0, 198.0], [198.0, 212.0], [212.0, 224.0], [224.0, 234.0], [234.0, 246.0], [246.0, 259.0], [259.0, 271.0], [271.0, 284.0], [284.0, 296.0], [296.0, 306.0], [306.0, 318.0], [318.0, 329.0], [329.0, 343.0], [343.0, 353.0], [353.0, 364.0], [364.0, 374.0], [374.0, 386.0], [386.0, 396.0], [396.0, 409.0], [409.0, 424.0], [424.0, 435.0], [435.0, 448.0], [448.0, 458.0], [458.0, 471.0], [471.0, 484.0], [484.0, 495.0], [495.0, 508.0], [508.0, 524.0], [524.0, 536.0], [536.0, 548.0], [548.0, 562.0], [562.0, 574.0], [574.0, 585.0], [585.0, 598.0], [598.0, 608.0], [608.0, 621.0], [621.0, 632.0], [632.0, 649.0], [649.0, 661.0], [661.0, 672.0], [672.0, 684.0], [684.0, 696.0], [696.0, 706.0], [706.0, 719.0], [719.0, 735.0], [735.0, 747.0], [747.0, 757.0], [757.0, 779.0], [779.0, 792.0], [792.0, 804.0], [804.0, 814.0], [814.0, 827.0], [827.0, 838.0], [838.0, 852.0], [852.0, 867.0], [867.0, 878.0], [878.0, 891.0], [891.0, 904.0], [904.0, 917.0], [917.0, 929.0], [929.0, 944.0], [944.0, 954.0], [954.0, 966.0], [966.0, 984.0], [984.0, 994.0], [994.0, 1005.0], [1005.0, 1016.0], [1016.0, 1026.0], [1026.0, 1036.0], [1036.0, 1048.0], [1048.0, 1067.0], [1067.0, 1081.0], [1081.0, 1092.0], [1092.0, 1103.0], [1103.0, 1114.0], [1114.0, 1125.0], [1125.0, 1135.0], [1135.0, 1146.0], [1146.0, 1173.0], [1173.0, 1186.0], [1186.0, 1197.0], [1197.0, 1208.0], [1208.0, 1220.0], [1220.0, 1232.0], [1232.0, 1244.0], [1244.0, 1255.0], [1255.0, 1269.0], [1269.0, 1282.0], [1282.0, 1293.0], [1293.0, 1304.0], [1304.0, 1319.0], [1319.0, 1331.0], [1331.0, 1341.0], [1341.0, 1351.0], [1351.0, 1365.0], [1365.0, 1376.0], [1376.0, 1392.0], [1392.0, 1402.0], [1402.0, 1416.0], [1416.0, 1428.0], [1428.0, 1438.0], [1438.0, 1449.0], [1449.0, 1460.0], [1460.0, 1470.0], [1470.0, 1481.0], [1481.0, 1497.0], [1497.0, 1509.0], [1509.0, 1525.0], [1525.0, 1535.0], [1535.0, 1547.0], [1547.0, 1559.0], [1559.0, 1571.0], [1571.0, 1591.0], [1591.0, 1603.0], [1603.0, 1613.0], [1613.0, 1654.0], [1654.0, 1670.0], [1670.0, 1681.0], [1681.0, 1691.0], [1691.0, 1701.0], [1701.0, 1714.0], [1714.0, 1726.0], [1726.0, 1736.0], [1736.0, 1747.0], [1747.0, 1759.0], [1759.0, 1771.0], [1771.0, 1783.0], [1783.0, 1796.0], [1796.0, 1806.0], [1806.0, 1816.0], [1816.0, 1836.0], [1836.0, 1848.0], [1848.0, 1861.0], [1861.0, 1872.0], [1872.0, 1882.0], [1882.0, 1897.0], [1897.0, 1911.0], [1911.0, 1922.0], [1922.0, 1933.0], [1933.0, 1956.0], [1956.0, 1967.0], [1967.0, 1977.0], [1977.0, 1990.0], [1990.0, 2004.0], [2004.0, 2015.0], [2015.0, 2025.0], [2025.0, 2038.0], [2038.0, 2058.0], [2058.0, 2068.0], [2068.0, 2080.0], [2080.0, 2094.0], [2094.0, 2104.0], [2104.0, 2116.0], [2116.0, 2129.0], [2129.0, 2154.0], [2154.0, 2164.0], [2164.0, 2174.0], [2174.0, 2189.0], [2189.0, 2205.0], [2205.0, 2216.0], [2216.0, 2227.0], [2227.0, 2240.0], [2240.0, 2250.0], [2250.0, 2286.0], [2286.0, 2304.0], [2304.0, 2314.0], [2314.0, 2327.0], [2327.0, 2338.0], [2338.0, 2355.0], [2355.0, 2372.0], [2372.0, 2384.0], [2384.0, 2397.0], [2397.0, 2414.0], [2414.0, 2424.0], [2424.0, 2436.0], [2436.0, 2450.0], [2450.0, 2462.0], [2462.0, 2472.0], [2472.0, 2482.0], [2482.0, 2495.0], [2495.0, 2505.0], [2505.0, 2515.0], [2515.0, 2529.0], [2529.0, 2545.0], [2545.0, 2555.0], [2555.0, 2566.0], [2566.0, 2587.0], [2587.0, 2598.0], [2598.0, 2609.0], [2609.0, 2623.0], [2623.0, 2634.0], [2634.0, 2646.0], [2646.0, 2657.0], [2657.0, 2669.0], [2669.0, 2680.0], [2680.0, 2692.0], [2692.0, 2703.0], [2703.0, 2715.0], [2715.0, 2728.0], [2728.0, 2740.0], [2740.0, 2750.0], [2750.0, 2761.0], [2761.0, 2788.0], [2788.0, 2811.0], [2811.0, 2825.0], [2825.0, 2838.0], [2838.0, 2850.0], [2850.0, 2864.0], [2864.0, 2874.0], [2874.0, 2891.0], [2891.0, 2905.0], [2905.0, 2917.0], [2917.0, 2932.0], [2932.0, 2945.0], [2945.0, 2955.0], [2955.0, 2965.0], [2965.0, 2976.0], [2976.0, 2987.0], [2987.0, 2998.0], [2998.0, 3012.0], [3012.0, 3025.0], [3025.0, 3036.0], [3036.0, 3046.0], [3046.0, 3056.0], [3056.0, 3067.03]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [848, 1831, 3067]}
{"example_id": "mit002@@ocw-18_02-f07-lec02_300k", "text": ["visit MIT OpenCourseWare at OCW.mit.edu.  Thank you. Let's continue with vectors and  operations of them. Remember we saw the topic ", "yesterday was dot product. And remember the definition of  dot product, well, the dot product of two ", "vectors is obtained by multiplying the first component  with the first component, the second with the second and  so on and summing these and you get the scalar. ", "And the geometric interpretation of that is that  you can also take the length of A,  take the length of B multiply them and multiply that by the ", "cosine of the angle between the two vectors.  We have seen several applications of that. ", "One application is to find lengths and angles. ", "For example, you can use this relation to  give you the cosine of the angle between two vectors is the dot ", "product divided by the product of the lengths.  Another application that we have is to detect whether two ", "vectors are perpendicular. To decide if two vectors are  perpendicular to each other, all we have to do is compute ", "our dot product and see if we get zero.  And one further application that we did not have time to ", "discuss yesterday that I will mention very quickly is to find  components of, let's say, a vector A along a ", "direction u. So some unit vector.  Let me explain. Let's say that I have some ", "direction. For example,  the horizontal axis on this blackboard.  But it could be any direction in space.  And, to describe this direction, maybe I have a unit ", "vector along this axis. Let's say that I have any of a  vector A and I want to find out what is the component of A along ", "u. That means what is the length  of this projection of A to the given direction? ", "This thing here is the component of A along u. ", "Well, how do we find that? Well, we know that here we have  a right angle. So this component is just ", "length A times cosine of the angle between A and u.  But now that means I should be able to compute it very easily ", "because that's the same as length A times length u times  cosine theta because u is a unit vector.  It is a unit vector. That means this is equal to one. ", "And so that's the same as the dot product between A and u.  That is very easy. And, of course, ", "the most of just cases of that is say, for example,  we want just to find the component along i hat,  the unit vector along the x axis. ", "Then you do the dot product with i hat, which is 100.  What you get is the first component.  And that is, indeed, the x component of a  vector. Similarly, say you want the z ", "component you do the dot product with k that gives you the last  component of your vector. But the same works with a unit ", "vector in any direction. So what is an application of  that? Well, for example, ", "in physics maybe you have seen situations where you have a  pendulum that swings. You have maybe some mass at the ", "end of the string and that mass swings back and forth on a  circle. And to analyze this  mechanically you want to use, of course, ", "Newton's Laws of Mechanics and you want to use forces and so  on, but I claim that components of  vectors are useful here to understand what happens ", "geometrically. What are the forces exerted on  this pendulum? Well, there is its weight, ", "which usually points downwards, and there is the tension of the ", "string. And these two forces together  are what explains how this pendulum is going to move back  and forth. Now, you could try to ", "understand the equations of motion using x,  y coordinates or x, z or whatever you want to call  them, let's say x, y.  But really what causes the pendulum to swing back and forth ", "and also to somehow stay a constant distance are phenomenal  relative to this circular trajectory.  For example, maybe instead of taking ", "components along the x and y axis, we want to look at two  other unit vectors. We can look at a vector, ", "let's call it T, that is tangent to the  trajectory. Sorry. Can you read that?  It's not very readable. T is tangent to the trajectory. ", "And, on the other hand, we can introduce another  vector. Let's call that N.  And that one is normal, perpendicular to the ", "trajectory. And so now if you think about  it you can look at the components of the weight along ", "the tangent direction and along the normal direction.  And so the component of F along the tangent direction is what ", "causes acceleration in the direction along the trajectory.  It is what causes the pendulum to swing back and forth. ", "", "And the component along N, on the other hand.  That is the part of the weight that tends to pull our mass away ", "from this point. It is what is going to be  responsible for the tension of the string.  It is why the string is taut and not actually slack and with ", "things moving all over the place.  That one is responsible for the tension of a string. ", "And now, of course, if you want to compute things,  well, maybe you will call this angle theta and then you will  express things explicitly using sines and cosines and you will  solve for the equations of motion. ", "That would be a very interesting physics problem.  But, to save time, we are not going to do it.  I'm sure you've seen that in 8.01 or similar classes. ", "And so to find these components we will just do dot products.  Any questions? No. ", "OK. Let's move onto our next topic.  Here we have found things about lengths, angles and stuff like ", "that. One important concept that we  have not understood yet in terms of vectors is area. ", "Let's say that we want to find the area of this pentagon.  Well, how do we compute that using vectors? ", "Can we do it using vectors? Yes we can.  And that is going to be the goal.  The first thing we should do is probably simplify the problem. ", "We don't actually need to bother with pentagons.  All we need to know are triangles because,  for example, you can cut that in three  triangles and then sum the areas of the triangles. ", "Perhaps easier, what is the area of a triangle?  Let's start with a triangle in the plane. ", "Well, then we need two vectors to describe it,  say A and B here. How do we find the area of a  triangle? Well, we all know base times ", "height over two. What is the base?  What is the height? The area of this triangle is  going to be one-half of the base, which is going to be the ", "length of A. And the height,  well, if you call theta this angle, then this is length B ", "sine theta. Now, that looks a lot like the  formula we had there, except for one little catch.  This is a sine instead of a cosine. ", "How do we deal with that? Well, what we could do is first  find the cosine of the angle. We know how to find the cosine ", "of the angle using dot products. Then solve for sine using sine  square plus cosine square equals one. ", "And then plug that back into here.  Well, that works but it is kind of a very complicated way of  doing it. So there is an easier way.  And that is going to be determinants, ", "but let me explain how we get to that maybe still doing  elementary geometry and dot products first. ", "Let's see. What we can do is instead of  finding the sine of theta, well, ", "we're not good at finding sines of angles but we are very good  now at finding cosines of angles.  Maybe we can find another angle whose cosine is the same as the ", "sine of theta. Well, you have already heard  about complimentary angles and how I take my vector A,  my vector B here and I have an angle theta. ", "Well, let's say that I rotate my vector A by 90 degrees to get  a new vector A prime. A prime is just A rotated by 90 ", "degrees. Then the angle between these  two guys, let's say theta prime, well, theta prime is 90 degrees ", "or pi over two gradients minus theta.  So, in particular, cosine of theta prime is equal ", "to sine of theta. In particular,  that means that length A, length B, sine theta, ", "which is what we would need to know in order to find the area  of this triangle is equal to, well, A and A prime have the  same length so let me replace that by length of A prime. ", "I am not changing anything, length B, cosine theta prime.  And now we have something that is much easier for us. ", "Because that is just A prime dot B.  That looks like a very good plan.  There is only one small thing which is we don't know yet how ", "to find this A prime. Well, I think it is not very  hard. Let's see.  Actually, why don't you guys do the hard work? ", "Let's say that I have a plane vector A with two components a1,  a2. And I want to rotate it  counterclockwise by 90 degrees. It looks like maybe we should ", "change some signs somewhere. Maybe we should do something  with the components. Can you come up with an idea of ", "what it might be? I see a lot of people answering ", "three. I see some other answers,  but the majority vote seems to be number three.  Minus a2 and a1. I think I agree, so let's see. ", "Let's say that we have this vector A with components a1. ", "So a1 is here. And a2. So a2 is here.  Let's rotate this box by 90 degrees counterclockwise. ", "This box ends up there. It's the same box just flipped  on its side. This thing here becomes a1 and  this thing here becomes a2. And that means our new vector A ", "prime is going to be -- Well, the first component looks like  an a2 but it is pointing to the left when a2 is positive.  So, actually, it is minus a2. And the y component is going to ", "be the same as this guy, so it's going to be a1.  If you wanted instead to rotate clockwise then you would do the  opposite. You would do a2 minus a1. ", "Is that reasonably clear for everyone?  OK. Let's continue the calculation ", "there. A prime, we have decided,  is minus a2, a1 dot product with let's call ", "b1 and b2, the components of B. Then that will be minus a2,  b1 plus a1, b2 plus a1, b2. ", "Let me write that the other way around, a1, b2 minus a2,  b1. And that is a quantity that you ", "may already know under the name of determinant of vectors A and  B, which we write symbolically using this notation. ", "We put A and B next to each other inside a two-by-two table  and we put these verticals bars. And that means the determinant ", "of these numbers, this guy times this guy minus  this guy times this guy. That is called the determinant. ", "And geometrically what it measures is the area,  well, not of a triangle because we did not divide by two,  but of a parallelogram formed by A and B. ", "It measures the area of the parallelogram with sides A and  B. And, of course, ", "if you want the triangle then you will just divide by two.  The triangle is half the parallelogram.  There is one small catch. The area usually is something ", "that is going to be positive. This guy here has no reason to  be positive or negative because, in fact, well, ", "if you compute things you will see that where it is supposed to  go negative it depends on whether A and B are clockwise or  counterclockwise from each other. ", "I mean the issue that we have -- Well,  when we say the area is one-half length A,  length B, sine theta that was assuming  that theta is positive, that its sine is positive. ", "Otherwise, if theta is negative maybe we need to take the  absolute value of this. Just to be more truthful, ", "I will say the determinant is either plus or minus the area.  Any questions about this? Yes. ", "Sorry. That is not a dot product.  That is the usual multiplication.  That is length A times length B times sine theta. ", "What does that equal? And so that is equal to the  area of a parallelogram. Sorry.  Let me explain that again. If I have two vectors A and B, ", "I can form a parallelogram with them or I can form a triangle.  And so the area of a parallelogram is equal to length ", "A, length B, sine theta, is equal to the determinant of  A and B. While the area of a triangle is ", "one-half of that.  ", "And, again, to be truthful, I should say these things can  be positive or negative. Depending on whether you count  the angle positively or negatively, you will get either ", "the area or minus the area. The area is actually the  absolute value of these quantities.  Is that clear? OK. ", "Yes. If you want to compute the  area, you will just take the absolute value of the ", "determinant.  ", "I should say the area of a parallelogram so that it is  completely clear. Sorry. Do you have a question? ", "Explain again, sorry, was the question how a  determinant equals the area of a parallelogram?  OK. The area of a parallelogram is  going to be the base times the height. ", "Let's take this guy to be the base.  The length of a base will be length of A and the height will  be obtained by taking B but only looking at the vertical part. ", "That will be length of B times the sine of theta.  That is how I got the area of a parallelogram as length A,  length B, sine theta. And then I did this ", "manipulation and this trick of rotating to find a nice formula.  Yes. You are asking ahead of what I ", "am going to do in a few minutes. You are asking about magnitude  of A cross B. We are going to learn about  cross products in a few minutes. And the answer is yes,  but cross product is for vectors in space. ", "Here I was simplifying things by doing things just in the  plane. Just bear with me for five more  minutes and we will do things in space. ", "Yes. That is correct. The way you compute this in  practice is you just do this. That is how you compute the ", "determinant. Yes.  What about three dimensions? Three dimensions we are going  to do now. More questions? ", "Should we move on? OK. Let's move to space. ", "There are two things we can do in space.  And you can look for the volume of solids or you can look for ", "the area of surfaces. Let me start with the easier of  the two. Let me start with volumes of  solids. And we will go back to area, ", "I promise. I claim that there is also a  notion of determinants in space. And that is going to tell us ", "how to find volumes. Let's say that we have three  vectors A, B and C. And then the definition of ", "their determinants going to be, the notation for that in terms  of the components is the same as over there. ", "We put the components of A, the components of B and the  components of C inside verticals bars. ", "And, of course, I have to give meaning to this.  This will be a number. And what is that number?  Well, the definition I will take is that this is a1 times ", "the determinant of what I get by looking in this lower right  corner. The two-by-two determinant b2, ", "b3, c2, c3. Then I will subtract a2 times  the determinant of b1, b3, c1, c3. ", "And then I will add a3 times the determinant b1,  b2, c1, c2. And each of these guys means, ", "again, you take b2 times c3 minus c2 times b3 and this times  that minus this time that and so on.  In fact, there is a total of six terms in here.  And maybe some of you have already seen a different formula ", "for three-by-three determinants where you directly have the six  terms. It is the same definition.  How to remember the structure of this formula? ", "Well, this is called an expansion according to the first  row. So we are going to take the  entries in the first row, a1, a2, a3 And for each of them ", "we get the term. Namely we multiply it by a  two-by-two determinant that we get by deleting the first row  and the column where we are. Here the coefficient next to ", "a1, when we delete this column and this row,  we are left with b2, b3, c2, c3.  The next one we take a2, we delete the row that is in it ", "and the column that it is in. And we are left with b1,  b3, c1, c3. And, similarly,  with a3, we take what remains, which is b1, ", "b2, c1, c2. Finally, last but not least,  there is a minus sign here for the second guy. ", "It looks like a weird formula. I mean it is a little bit weird. ", "But it is a formula that you should learn because it is  really, really useful for a lot of things.  I should say if this looks very artificial to you and you would  like to know more there is more in the notes, ", "so read the notes. They will tell you a bit more  about what this means, where it comes from and so on.  If you want to know a lot more then some day you should take  18.06, Linear Algebra where you will ", "learn a lot more about determinants in N dimensional  space with N vectors. And there is a generalization  of this in arbitrary dimensions. In this class, ", "we will only deal with two or three dimensions.  Yes. Why is the negative there?  Well, that is a very good question.  It has to be there so that this will actually equal, ", "well, what I am going to say right now is that this will give  us the volume of [a box?] with sides A,  B, C. And the formula just doesn't  work if you don't put the negative. ", "There is a more fundamental reason which has to do with  orientation of space and the fact that if you switch two  coordinates in space then basically you change what is ", "called the handedness of the coordinates.  If you look at your right hand and your left hand,  they are not actually the same. They are mirror images.  And, if you squared two coordinate axes,  that is what you get. That is the fundamental reason ", "for the minus. Again, we don't need to think  too much about that. All we need in this class is ", "the formula. Why do we care about this  formula? It is because of the theorem ", "that says that geometrically the determinant of the three vectors  A, B, C is, again, plus or minus. ", "This determinant could be positive or negative.  See those minuses and all sorts of stuff.  Plus or minus the volume of the parallelepiped. ", "That is just a fancy name for a box with parallelogram sides,  in case you wonder, with sides A, ", "B and C. You take the three vectors A,  B and C and you form a box whose sides are all ", "parallelograms. And when its volume is going to  be the determinant. Other questions? ", "I'm sorry. I cannot quite hear you. ", "Yes. We are going to see how to do  it geometrically without a determinant,  but then you will see that you actually need a determinant to  compute it no matter what. We are going to go back to this ", "and see another formula for volume, but you will see that  really I am cheating. I mean somehow computationally  the only way to compute it is really to use a determinant.  ", "That is correct. In general, I mean,  actually, I could say if you look at the two-by-two  determinant, see, you can also explain it in  terms of this extension. If you take a1 and multiply by ", "this one-by-one determinant b2, then you take a2 and you  multiply it by this one-by-one determinant b1 but you put a  minus sign. And in general,  indeed, when you expand, you would stop putting plus, ", "minus, plus, minus alternating.  More about that in 18.06. Yes.  There is a way to do it based on other rows as well, ", "but then you have to be very careful with the sign vectors.  I will refer you to the notes for that.  I mean you could also do it with a column,  by the way. I mean be careful about the ", "sign rules. Given how little we will use  determinants in this class, I mean we will use them in a  way that is fundamental, but we won't compute much.  Let's say this is going to be enough for us for now. ", "After determinants now I can tell you about cross product.  And cross product is going to be the answer to your question  about area.  ", "OK. Let me move onto cross product. ", "Cross product is something that you can apply to two vectors in  space. And by that I mean really in ", "three-dimensional space. This is something that is  specific to three dimensions. The definition A cross B -- It  is important to really do your multiplication symbol well so ", "that you don't mistake it with a dot product.  Well, that is going to be a vector. ", "That is another reason not to confuse it with dot product.  Dot product gives you a number. Cross product gives you a  vector. They are really completely  different operations. They are both called product ", "because someone could not come up with a better name,  but they are completely different operations.  What do we do to do the cross product of A and B? ", "Well, we do something very strange.  Just as I have told you that a determinant is something where  we put numbers and we get a number, I am going to violate my  own rule. I am going to put together a ", "determinant in which -- Well, the last two rows are the  components of the vectors A and B but the first row strangely ", "consists for unit vectors i, j, k.  What does that mean? Well, that is not a determinant  in the usual sense. If you try to put that into ", "your calculator, it will tell you there is an  error. I don't know how to put vectors  in there. I want numbers.  What is means is it is symbolic notation that helps you remember ", "what the formula is. The actual formula is,  well, you use this definition. And, if you use that  definition, you see that it is i hat times some number. ", "Let me write it as determinant of a2, a3, b2,  b3 times i hat minus determinant a1, ", "a3, b1, b3, j hat plus a1, a2, b1, b2, k hat.  And so that is the actual definition in a way that makes ", "complete sense, but to remember this formula  without too much trouble it is much easier to think about it in  these terms here. That is the definition and it ", "gives you a vector. Now, as usual with definitions,  the question is what is it good for?  What is the geometric meaning of this very strange operation?  Why do we bother to do that? Here is what it does ", "geometrically. Remember a vector has two  different things. It has a length and it has a  direction. Let's start with the length. ", "A length of a cross product is the area of the parallelogram in ", "space formed by the vectors A and B.  Now, if you have a parallelogram in space, ", "you can find its area just by doing this calculation when you  know the coordinates of the points.  You do this calculation and then you take the length.  You take this squared plus that squared plus that squared, ", "square root. It looks like a very  complicated formula but it works and, actually,  it is the simplest way to do it.  This time we don't actually need to put plus or minus ", "because the length of a vector is always positive.  We don't have to worry about that.  And what is even more magical is that not only is the length ", "remarkable but the direction is also remarkable.  The direction of A cross B is perpendicular to the plane of a ", "parallelogram. Our two vectors A and B  together in a plane. What I am telling you is that ", "for vector A cross B will point, will stick straight out of that ", "plane perpendicularly to it. In fact, I would have to be  more precise. There are two ways that you can  be perpendicular to this plane. You can be perpendicular ", "pointing up or pointing down. How do I decide which?  Well, there is something called the right-hand rule. ", "What does the right-hand rule say?  Well, there are various versions for right-hand rule  depending on which country you learn about it.  In France, given the culture, you even learn about it in ", "terms of a cork screw and a wine bottle.  I will just use the usual version here.  You take your right hand. If you are left-handed,  remember to take your right hand and not the left one. ", "The other right, OK? Then place your hand to point  in the direction of A. Let's say my right hand is  going in that direction. Now, curl your fingers so that ", "they point towards B. Here that would be kind of into  the blackboard. Don't snap any bones.  If it doesn't quite work then rotate your arms so that you can ", "actually physically do it. Then get your thumb to stick  straight out. Well, here my thumb is going to  go up. And that tells me that A cross ", "B will go up. Let me write that down while  you experiment with it. Again, try not to enjoy  yourselves.  ", "First, your right hand points parallel to vector A.  Then your fingers point in the direction of B. ", "Then your thumb, when you stick it out,  is going to point in the direction of A cross B. ", "Let's do a quick example. Where is my quick example? Here. ", "Let's take i cross j.  ", "I see most of you going in the right direction.  If you have it pointing in the wrong direction, ", "it might mean that you are using your left hand,  for example. Example, I claim that i cross j ", "equals k. Let's see. I points towards us.  J point to our right. I guess this is your right. ", "I think. And then your thumb is going to  point up. That tells us it is roughly  pointing up. And, of course,  the length should be one because if you take the unit ", "square in the x, y plane, its area is one.  And the direction should be vertical.  Because it should be perpendicular to the x, ", "y plane. It looks like i cross j will be  k. Well, let's check with the  definition i, j, k.  What is i? I is one, zero, zero. J is zero, one, zero. ", "The coefficient of i will be zero times zero minus zero times  one. That is zero.  The coefficient of j will be one time zero minus zero times ", "zero, that is a zero, minus zero j.  It doesn't matter. And the coefficient of k will  be one times one, that is one, ", "minus zero times zero, so one k.  So we do get i cross j equals k both ways.  In this case, it is easier to do it ", "geometrically. If I give you no complicated  vectors, probably you will actually want to do the  calculation. Any questions? Yes. ", "The coefficient of k, remember I delete the first row  and the last column so I get this two-by-two determinant.  And that two-by-two determinant is one times one minus zero ", "times zero so that gives me a one.  That is what you do with two-by-two determinants.  Similarly for [UNINTELLIGIBLE], but [UNINTELLIGIBLE]  turn out to be zero. More questions? ", "Yes. Let me repeat how I got the one  in front of k. Remember the definition of a  determinant I expand according to the entries in the first row. ", "When I get to k what I do is delete the first row and I  delete the last column, the column that contains k.  I delete these guys and these guys and I am left with this ", "two-by-two determinant. Now, a two-by-two determinant,  you multiply according to this downward diagonal and then minus ", "this times that. One times one,  let me see here, I got one k because that is one  times one minus zero times zero equals one. ", "Sorry. That is really hard to read.  Maybe it will be easier that way. ", "Yes. Let's try.  If I do the same for i, I think I will also get zero. ", "Let's do the same for i. I take i, I delete the first  row, I delete the first column, I get this two-by-two ", "determinant here and I get zero times zero,  that is zero, minus zero times one.  That is the other trick question. ", "Zero times one is zero as well. So that zero minus zero is  zero. I hope on Monday you should get  more practice in recitation about how to compute ", "determinants. Hopefully, it will become very  easy for you all to compute this next.  I know the first time it is kind of a shock because there  are a lot of numbers and a lot of things to do. ", "", "Let me return to the question that you asked a bit earlier  about how do you find actually volume if I don't want to know ", "about determinants? Well, let's have another look ", "at the volume. Let's say that I have three  vectors. Let me put them this way, ", "A, B and C. And let's try to see how else I  could think about the volume of this box. ", "Probably you know that the volume of a parallelepiped is  the area of a base times the height.  Sorry. The volume is the area of a ", "base times the height. How do we do that in practice?  Well, what is the area of a base? ", "The base is a parallelogram in space with sides B and C.  How do we find the area of the parallelogram in space?  Well, we just discovered that. We can do it by taking that ", "cross product. The area of a base,  well, we take the cross product of B and C.  That is not quite it because this is a vector.  We would like a number while we take its length. ", "That is pretty good. What about the height?  Well, the height is going to be the component of A in the  direction that is perpendicular to the base. ", "Let's take a direction that is perpendicular to the base.  Let's call that N, a unit vector in that  direction. Then we can get the height by  taking A dot n. That is what we saw at the ", "beginning of class that A dot n will tell me how much A goes in  the direction of n. Are you still with me? ", "OK. Let's keep going.  Let's think about this vector n.  How do I get it? Well, I can get it by actually ", "using cross product as well. Because I said the direction  perpendicular to two vectors I can get by taking that cross  product and looking at that direction. ", "This is still B cross C length. And this one is,  so I claim, n can be obtained by taking D cross C. ", "Well, that comes in the right direction but it is not a unit  vector. How do I get a unit vector?  I divide by the length. Thanks. ", "I take B cross C and I divide by length B cross C.  Well, now I can probably simplify between these two guys. ", "And so what I will get -- What I get out of this is that my ", "volume equals A dot product with vector B cross C. ", "But, of course, I have to be careful in which  order I do it. If I do it the other way  around, A dot B, I get a number.  I cannot cross that. I really have to do the cross  product first. I get the new vector. ", "Then my dot product. The fact is that the  determinant of A, B, C is equal to this so-called ", "triple product. Well, that looks good  geometrically. Let's try to check whether it  makes sense with the formulas, just one small thing. ", "We saw the determinant is a1 times determinant b2,  b3, c2, c3 minus a2 times something plus a3 times ", "something. I will let you fill in the  numbers. That is this guy.  What about this guy? Well, dot product, ", "we take the first component of A, that is a1,  we multiply by the first component of B cross C.  What is the first component of B cross C?  Well, it is this determinant b2, b3, c2, c3. ", "If you put B and C instead of A and B into there you will get  the i component is this guy plus a2 times the second component  which is minus some determinant plus a3 times the third ", "component which is, again, a determinant.  And you can check. You get exactly the same  expression, so everything is fine.  There is no contradiction in math just yet. ", "On Tuesday we will continue with this and we will start  going into matrices, equations of planes and so on. ", "Meanwhile, have a good weekend and please start working on your  Problem Sets so that you can ask lots of questions to your TAs on  Monday. "], "vid_duration": [15.0, 14.0, 10.0, 15.0, 18.0, 14.0, 11.0, 15.0, 14.0, 13.0, 18.0, 10.0, 12.0, 11.0, 10.0, 13.0, 12.0, 11.0, 15.0, 10.0, 10.0, 11.0, 10.0, 10.0, 11.0, 10.0, 14.0, 11.0, 11.0, 12.0, 14.0, 12.0, 10.0, 24.0, 17.0, 10.0, 13.0, 10.0, 15.0, 13.0, 11.0, 16.0, 11.0, 11.0, 16.0, 10.0, 11.0, 11.0, 14.0, 14.0, 16.0, 11.0, 12.0, 12.0, 11.0, 12.0, 12.0, 12.0, 11.0, 10.0, 10.0, 13.0, 16.0, 11.0, 11.0, 13.0, 12.0, 10.0, 12.0, 15.0, 12.0, 14.0, 10.0, 15.0, 12.0, 13.0, 17.0, 16.0, 13.0, 14.0, 10.0, 12.0, 10.0, 13.0, 10.0, 21.0, 12.0, 11.0, 11.0, 12.0, 10.0, 11.0, 10.0, 26.0, 12.0, 14.0, 14.0, 14.0, 14.0, 10.0, 18.0, 10.0, 16.0, 17.0, 13.0, 13.0, 11.0, 14.0, 11.0, 14.0, 12.0, 11.0, 15.0, 10.0, 13.0, 10.0, 17.0, 12.0, 12.0, 10.0, 11.0, 14.0, 11.0, 13.0, 11.0, 12.0, 14.0, 13.0, 12.0, 10.0, 10.0, 13.0, 12.0, 10.0, 13.0, 10.0, 10.0, 12.0, 12.0, 10.0, 15.0, 16.0, 10.0, 11.0, 24.0, 12.0, 10.0, 22.0, 11.0, 12.0, 12.0, 10.0, 19.0, 45.0, 13.0, 11.0, 15.0, 12.0, 12.0, 10.0, 14.0, 12.0, 10.0, 11.0, 15.0, 15.0, 13.0, 12.0, 21.0, 13.0, 14.0, 12.0, 13.0, 12.0, 12.0, 20.0, 17.0, 10.0, 11.0, 14.0, 10.0, 12.0, 12.0, 10.0, 11.0, 19.0, 17.0, 13.0, 29.0, 11.0, 11.0, 10.0, 11.0, 12.0, 10.0, 17.0, 13.0, 10.0, 10.0, 17.0, 13.0, 17.0, 13.0, 13.0, 10.0, 13.0, 11.0, 12.0, 10.0, 10.0, 12.0, 12.0, 55.0, 11.0, 11.0, 13.0, 12.0, 15.0, 11.0, 13.0, 12.0, 11.0, 13.0, 13.0, 12.0, 11.0, 16.0, 10.0, 14.0, 18.0, 15.0, 10.0, 13.0, 11.0, 10.0, 11.0, 17.0, 13.0, 14.0, 11.0, 7.01], "stet": [[0, 15.0], [15.0, 29.0], [29.0, 39.0], [39.0, 54.0], [54.0, 72.0], [72.0, 86.0], [86.0, 97.0], [97.0, 112.0], [112.0, 126.0], [126.0, 139.0], [139.0, 157.0], [157.0, 167.0], [167.0, 179.0], [179.0, 190.0], [190.0, 200.0], [200.0, 213.0], [213.0, 225.0], [225.0, 236.0], [236.0, 251.0], [251.0, 261.0], [261.0, 271.0], [271.0, 282.0], [282.0, 292.0], [292.0, 302.0], [302.0, 313.0], [313.0, 323.0], [323.0, 337.0], [337.0, 348.0], [348.0, 359.0], [359.0, 371.0], [371.0, 385.0], [385.0, 397.0], [397.0, 407.0], [407.0, 431.0], [431.0, 448.0], [448.0, 458.0], [458.0, 471.0], [471.0, 481.0], [481.0, 496.0], [496.0, 509.0], [509.0, 520.0], [520.0, 536.0], [536.0, 547.0], [547.0, 558.0], [558.0, 574.0], [574.0, 584.0], [584.0, 595.0], [595.0, 606.0], [606.0, 620.0], [620.0, 634.0], [634.0, 650.0], [650.0, 661.0], [661.0, 673.0], [673.0, 685.0], [685.0, 696.0], [696.0, 708.0], [708.0, 720.0], [720.0, 732.0], [732.0, 743.0], [743.0, 753.0], [753.0, 763.0], [763.0, 776.0], [776.0, 792.0], [792.0, 803.0], [803.0, 814.0], [814.0, 827.0], [827.0, 839.0], [839.0, 849.0], [849.0, 861.0], [861.0, 876.0], [876.0, 888.0], [888.0, 902.0], [902.0, 912.0], [912.0, 927.0], [927.0, 939.0], [939.0, 952.0], [952.0, 969.0], [969.0, 985.0], [985.0, 998.0], [998.0, 1012.0], [1012.0, 1022.0], [1022.0, 1034.0], [1034.0, 1044.0], [1044.0, 1057.0], [1057.0, 1067.0], [1067.0, 1088.0], [1088.0, 1100.0], [1100.0, 1111.0], [1111.0, 1122.0], [1122.0, 1134.0], [1134.0, 1144.0], [1144.0, 1155.0], [1155.0, 1165.0], [1165.0, 1191.0], [1191.0, 1203.0], [1203.0, 1217.0], [1217.0, 1231.0], [1231.0, 1245.0], [1245.0, 1259.0], [1259.0, 1269.0], [1269.0, 1287.0], [1287.0, 1297.0], [1297.0, 1313.0], [1313.0, 1330.0], [1330.0, 1343.0], [1343.0, 1356.0], [1356.0, 1367.0], [1367.0, 1381.0], [1381.0, 1392.0], [1392.0, 1406.0], [1406.0, 1418.0], [1418.0, 1429.0], [1429.0, 1444.0], [1444.0, 1454.0], [1454.0, 1467.0], [1467.0, 1477.0], [1477.0, 1494.0], [1494.0, 1506.0], [1506.0, 1518.0], [1518.0, 1528.0], [1528.0, 1539.0], [1539.0, 1553.0], [1553.0, 1564.0], [1564.0, 1577.0], [1577.0, 1588.0], [1588.0, 1600.0], [1600.0, 1614.0], [1614.0, 1627.0], [1627.0, 1639.0], [1639.0, 1649.0], [1649.0, 1659.0], [1659.0, 1672.0], [1672.0, 1684.0], [1684.0, 1694.0], [1694.0, 1707.0], [1707.0, 1717.0], [1717.0, 1727.0], [1727.0, 1739.0], [1739.0, 1751.0], [1751.0, 1761.0], [1761.0, 1776.0], [1776.0, 1792.0], [1792.0, 1802.0], [1802.0, 1813.0], [1813.0, 1837.0], [1837.0, 1849.0], [1849.0, 1859.0], [1859.0, 1881.0], [1881.0, 1892.0], [1892.0, 1904.0], [1904.0, 1916.0], [1916.0, 1926.0], [1926.0, 1945.0], [1945.0, 1990.0], [1990.0, 2003.0], [2003.0, 2014.0], [2014.0, 2029.0], [2029.0, 2041.0], [2041.0, 2053.0], [2053.0, 2063.0], [2063.0, 2077.0], [2077.0, 2089.0], [2089.0, 2099.0], [2099.0, 2110.0], [2110.0, 2125.0], [2125.0, 2140.0], [2140.0, 2153.0], [2153.0, 2165.0], [2165.0, 2186.0], [2186.0, 2199.0], [2199.0, 2213.0], [2213.0, 2225.0], [2225.0, 2238.0], [2238.0, 2250.0], [2250.0, 2262.0], [2262.0, 2282.0], [2282.0, 2299.0], [2299.0, 2309.0], [2309.0, 2320.0], [2320.0, 2334.0], [2334.0, 2344.0], [2344.0, 2356.0], [2356.0, 2368.0], [2368.0, 2378.0], [2378.0, 2389.0], [2389.0, 2408.0], [2408.0, 2425.0], [2425.0, 2438.0], [2438.0, 2467.0], [2467.0, 2478.0], [2478.0, 2489.0], [2489.0, 2499.0], [2499.0, 2510.0], [2510.0, 2522.0], [2522.0, 2532.0], [2532.0, 2549.0], [2549.0, 2562.0], [2562.0, 2572.0], [2572.0, 2582.0], [2582.0, 2599.0], [2599.0, 2612.0], [2612.0, 2629.0], [2629.0, 2642.0], [2642.0, 2655.0], [2655.0, 2665.0], [2665.0, 2678.0], [2678.0, 2689.0], [2689.0, 2701.0], [2701.0, 2711.0], [2711.0, 2721.0], [2721.0, 2733.0], [2733.0, 2745.0], [2745.0, 2800.0], [2800.0, 2811.0], [2811.0, 2822.0], [2822.0, 2835.0], [2835.0, 2847.0], [2847.0, 2862.0], [2862.0, 2873.0], [2873.0, 2886.0], [2886.0, 2898.0], [2898.0, 2909.0], [2909.0, 2922.0], [2922.0, 2935.0], [2935.0, 2947.0], [2947.0, 2958.0], [2958.0, 2974.0], [2974.0, 2984.0], [2984.0, 2998.0], [2998.0, 3016.0], [3016.0, 3031.0], [3031.0, 3041.0], [3041.0, 3054.0], [3054.0, 3065.0], [3065.0, 3075.0], [3075.0, 3086.0], [3086.0, 3103.0], [3103.0, 3116.0], [3116.0, 3130.0], [3130.0, 3141.0], [3141.0, 3148.01]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [573, 1432, 1938, 3148]}
{"example_id": "mit002@@ocw-18_02-f07-lec15_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  Let me start by basically listing the main things we have  learned over the past three weeks or so.  And I will add a few complements of information about  that because there are a few small details that I didn't ", "quite clarify and that I should probably make a bit clearer,  especially what happened at the very end of yesterday's class. ", "Here is a list of things that should be on your review sheet  for the exam. The first thing we learned ", "about, the main topic of this unit is about functions of  several variables. We have learned how to think of ", "functions of two or three variables in terms of plotting  them. In particular,  well, not only the graph but also the contour plot and how to  read a contour plot. And we have learned how to ", "study variations of these functions using partial ", "derivatives. Remember, we have defined the  partial of f with respect to some variable,  say, x to be the rate of change with respect to x when we hold ", "all the other variables constant.  If you have a function of x and y, this symbol means you  differentiate with respect to x treating y as a constant. ", "And we have learned how to package partial derivatives into  a vector,the gradient vector. For example, ", "if we have a function of three variables, the vector whose  components are the partial derivatives.  And we have seen how to use the gradient vector or the partial ", "derivatives to derive various things such as approximation  formulas. The change in f, ", "when we change x, y, z slightly,  is approximately equal to, well, there are several terms. ", "And I can rewrite this in vector form as the gradient dot  product the amount by which the position vector has changed. ", "Basically, what causes f to change is that I am changing x,  y and z by small amounts and how sensitive f is to each  variable is precisely what the partial derivatives measure. ", "And, in particular, this approximation is called  the tangent plane approximation because it tells us,  in fact, it amounts to identifying the ", "graph of the function with its tangent plane.  It means that we assume that the function depends more or  less linearly on x, y and z. ", "And, if we set these things equal, what we get is actually,  we are replacing the function by its linear approximation.  We are replacing the graph by its tangent plane. ", "Except, of course, we haven't see the graph of a  function of three variables because that would live in  4-dimensional space. So, when we think of a graph,  really, it is a function of two variables. ", "That also tells us how to find tangent planes to level  surfaces.  ", "Recall that the tangent plane to a surface,  given by the equation f of x, y, z equals z, ", "at a given point can be found by looking first for its normal  vector. And we know that the normal ", "vector is actually, well,  one normal vector is given by the gradient of a function  because we know that the gradient is actually pointing  perpendicularly to the level sets towards higher values of a ", "function. And it gives us the direction  of fastest increase of a function.  OK. Any questions about these ", "topics? No.  OK. Let me add, actually,  a cultural note to what we have seen so far about partial ", "derivatives and how to use them, which is maybe something I  should have mentioned a couple of weeks ago.  Why do we like partial derivatives? ", "Well, one obvious reason is we can do all these things.  But another reason is that, really,  you need partial derivatives to do physics and to understand  much of the world that is around you because a lot of things ", "actually are governed by what is called partial differentiation  equations.  ", "So if you want a cultural remark about what this is good  for. A partial differential equation ", "is an equation that involves the partial derivatives of a  function. So you have some function that  is unknown that depends on a bunch of variables.  And a partial differential equation is some relation ", "between its partial derivatives. Let me see.  These are equations involving the partial derivatives -- -- of ", "an unknown function. Let me give you an example to  see how that works. For example, ", "the heat equation is one example of a partial  differential equation. It is the equation -- Well, ", "let me write for you the space version of it.  It is the equation partial f over partial t equals some ", "constant times the sum of the second partials with respect to  x, y and z. So this is an equation where we ", "are trying to solve for a function f that depends,  actually, on four variables, x, y, z, t. ", "And what should you have in mind?  Well, this equation governs temperature.  If you think that f of x, y, z, t will be the temperature at a ", "point in space at position x, y, z and at time t,  then this tells you how temperature changes over time.  It tells you that at any given point, ", "the rate of change of temperature over time is given  by this complicated expression in the partial derivatives in  terms of the space coordinates x, y, z. ", "If you know, for example, the initial distribution of  temperature in this room, and if you assume that nothing  is generating heat or taking heat away,  so if you don't have any air conditioning or heating going ", "on, then it will tell you how the  temperature will change over time and eventually stabilize to  some final value. Yes? ", "Why do we take the partial derivative twice?  Well, that is a question, I would say,  for a physics person. But in a few weeks we will  actually see a derivation of where this equation comes from ", "and try to justify it. But, really,  that is something you will see in a physics class.  The reason for that is basically physics of how heat is ", "transported between particles in fluid, or actually any medium.  This constant k actually is called the heat conductivity. ", "It tells you how well the heat flows through the material that  you are looking at. Anyway, I am giving it to you  just to show you an example of a real life problem where, ", "in fact, you have to solve one of these things.  Now, how to solve partial differential equations is not a  topic for this class. It is not even a topic for  18.03 which is called Differential Equations, ", "without partial, which means there actually you  will learn tools to study and solve these equations but when  there is only one variable involved.  And you will see it is already quite hard. ", "And, if you want more on that one, we have many fine classes  about partial differential equations.  But one thing at a time. I wanted to point out to you ", "that very often functions that you see in real life satisfy  many nice relations between the partial derivatives. ", "That was in case you were wondering why on the syllabus  for today it said partial differential equations.  Now we have officially covered the topic.  That is basically all we need to know about it. ", "But we will come back to that a bit later.  You will see. OK.  If there are no further questions, let me continue and ", "go back to my list of topics. Oh, sorry.  I should have written down that this equation is solved by ", "temperature for point x, y, z at time t.  OK. And there are, actually, ", "many other interesting partial differential equations you will  maybe sometimes learn about the wave equation that governs how  waves propagate in space, about the diffusion equation, ", "when you have maybe a mixture of two fluids,  how they somehow mix over time and so on.  Basically, to every problem you might want to consider there is ", "a partial differential equation to solve.  OK. Anyway. Sorry. Back to my list of topics.  One important application we have seen of partial derivatives ", "is to try to optimize things, try to solve minimum/maximum  problems.  ", "Remember that we have introduced the notion of  critical points of a function. A critical point is when all ", "the partial derivatives are zero.  And then there are various kinds of critical points.  There is maxima and there is minimum, but there is also ", "saddle points. And we have seen a method using  second derivatives -- -- to decide which kind of critical ", "point we have. I should say that is for a  function of two variables to try to decide whether a given ", "critical point is a minimum, a maximum or a saddle point.  And we have also seen that actually that is not enough to  find the minimum of a maximum of a function because the minimum ", "of a maximum could occur on the boundary.  Just to give you a small reminder,  when you have a function of one variables,  if you are trying to find the minimum and the maximum of a ", "function whose graph looks like this,  well, you are going to tell me, quite obviously,  that the maximum is this point up here.  And that is a point where the first derivative is zero. ", "That is a critical point. And we used the second  derivative to see that this critical point is a local  maximum. But then, when we are looking  for the minimum of a function, well, it is not at a critical ", "point. It is actually here at the  boundary of the domain, you know, the range of values  that we are going to consider. Here the minimum is at the ", "boundary. And the maximum is at a  critical point. Similarly, when you have a ", "function of several variables, say of two variables,  for example, then the minimum and the  maximum will be achieved either at a critical point.  And then we can use these methods to find where they are. ", "Or, somewhere on the boundary of a set of values that are  allowed. It could be that we actually  achieve a minimum by making x and y as small as possible. ", "Maybe letting them go to zero if they had to be positive or  maybe by making them go to infinity.  So, we have to keep our minds open and look at various ", "possibilities. We are going to do a problem  like that. We are going to go over a  practice problem from the practice test to clarify this. ", "Another important cultural application of minimum/maximum  problems in two variables that we have seen in class is the  least squared method to find the best fit line, ", "or the best fit anything, really,  to find when you have a set of data points what is the best ", "linear approximately for these data points.  And here I have some good news for you.  While you should definitely know what this is about, ", "it will not be on the test.  ", "[APPLAUSE] That doesn't mean that you  should forget everything we have seen about it, ", "OK? Now what is next on my list of ", "topics? We have seen differentials.  Remember the differential of f, by definition, ", "would be this kind of quantity. At first it looks just like a  new way to package partial derivatives together into some  new kind of object. Now, what is this good for? ", "Well, it is a good way to remember approximation formulas.  It is a good way to also study how variations in x,  y, z relate to variations in f. In particular, ", "we can divide this by variations,  actually, by dx or by dy or by dz in any situation that we  want, or by d of some other variable ", "to get chain rules. The chain rule says,  for example, there are many situations. ", "But, for example, if x, y and z depend on some  other variable, say of variables maybe even u ", "and v, then that means that f becomes  a function of u and v. And then we can ask ourselves,  how sensitive is f to a value of u? ", "Well, we can answer that. The chain rule is something  like this. And let me explain to you again ", "where this comes from. Basically, what this quantity  means is if we change u and keep v constant, what happens to the ", "value of f? Well, why would the value of f  change in the first place when f is just a function of x,  y, z and not directly of you? Well, it changes because x,  y and z depend on u. First we have to figure out how ", "quickly x, y and z change when we change u.  Well, how quickly they do that is precisely partial x over  partial u, partial y over partial u, partial z over  partial u. These are the rates of change ", "of x, y, z when we change u. And now, when we change x,  y and z, that causes f to change.  How much does f change? Well, partial f over partial x ", "tells us how quickly f changes if I just change x.  I get this. That is the change in f caused  just by the fact that x changes when u changes. ", "But then y also changes. y changes at this rate.  And that causes f to change at that rate.  And z changes as well, and that causes f to change at  that rate. And the effects add up together. ", "Does that make sense? OK. ", "And so, in particular, we can use the chain rule to do  changes of variables. If we have, say,  a function in terms of polar coordinates on theta and we like ", "to switch it to rectangular coordinates x and y then we can  use chain rules to relate the partial derivatives. ", "And finally, last but not least,  we have seen how to deal with non-independent variables. ", "When our variables say x, y, z related by some equation.  One way we can deal with this is to solve for one of the ", "variables and go back to two independent variables,  but we cannot always do that. Of course, on the exam,  you can be sure that I will make sure that you cannot solve  for a variable you want to remove because that would be too ", "easy. Then when we have to look at  all of them, we will have to take into account this relation,  we have seen two useful methods. ", "One of them is to find the minimum of a maximum of a  function when the variables are not independent,  and that is the method of Lagrange multipliers. ", "", "Remember, to find the minimum or the maximum of the function  f, subject to the constraint g ", "equals constant, well, we write down equations  that say that the gradient of f is actually proportional to the ", "gradient of g. There is a new variable here,  lambda, the multiplier. And so, for example,  well, I guess here I had functions of three variables, ", "so this becomes three equations.  f sub x equals lambda g sub x, f sub y equals lambda g sub y,  and f sub z equals lambda g sub z. ", "And, when we plug in the formulas for f and g,  well, we are left with three equations involving the four  variables, x, y, z and lambda.  What is wrong? Well, we don't have actually ", "four independent variables. We also have this relation,  whatever the constraint was relating x, y and z together. ", "Then we can try to solve this. And, depending on the  situation, it is sometimes easy. And it sometimes it is very  hard or even impossible. But on the test, ", "I haven't decided yet, but it could well be that the  problem about Lagrange multipliers just asks you to  write the equations and not to solve them.  [APPLAUSE] Well, I don't know yet. ", "I am not promising anything. But, before you start solving,  check whether the problem asks you to solve them or not.  If it doesn't then probably you shouldn't. ", "", "Another topic that we solved just yesterday is constrained  partial derivatives. And I guess I have to ", "re-explain a little bit because my guess is that things were not  extremely clear at the end of class yesterday. ", "Now we are in the same situation.  We have a function, let's say, f of x,  y, z where variables x, y and z are not independent but ", "are constrained by some relation of this form.  Some quantity involving x, y and z is equal to maybe zero  or some other constant. And then, what we want to know, ", "is what is the rate of change of f with respect to one of the  variables, say, x, y or z when I keep the ", "others constant? Well, I cannot keep all the  other constant because that would not be compatible with ", "this condition. I mean that would be the usual  or so-called formal partial derivative of f ignoring the  constraint. To take this into account means ", "that if we vary one variable while keeping another one fixed  then the third one, since it depends on them,  must also change somehow. And we must take that into ", "account. Let's say, for example,  we want to find -- I am going to do a different example from  yesterday. So, if you really didn't like ", "that one, you don't have to see it again.  Let's say that we want to find the partial derivative of f with  respect to z keeping y constant. What does that mean? ", "That means y is constant, z varies and x somehow is  mysteriously a function of y and z for this equation. ", "And then, of course because it depends on y,  that means x will vary. Sorry, depends on y and z and z  varies. Now we are asking ourselves ", "what is the rate of change of f with respect to z in this  situation?  ", "And so we have two methods to do that.  Let me start with the one with differentials that hopefully you ", "kind of understood yesterday, but if not here is a second  chance. Using differentials means that ", "we will try to express df in terms of dz in this particular  situation. What do we know about df in  general? Well, we know that df is f sub ", "x dx plus f sub y dy plus f sub z dz.  That is the general statement. But, of course,  we are in a special case. We are in a special case where ", "first y is constant. y is constant means that we can ", "set dy to be zero. This goes away and becomes zero.  The second thing is actually we don't care about x. ", "We would like to get rid of x because it is this dependent  variable. What we really want to do is  express df only in terms of dz. What we need is to relate dx ", "with dz. Well, to do that,  we need to look at how the variables are related so we need  to look at the constraint g. Well, how do we do that? ", "We look at the differential g. So dg is g sub x dx plus g sub  y dy plus g sub z dz. And that is zero because we are ", "setting g to always stay constant.  So, g doesn't change. If g doesn't change then we  have a relation between dx, dy and dz. ", "Well, in fact, we say we are going to look  only at the case where y is constant.  y doesn't change and this becomes zero.  Well, now we have a relation between dx and dz. ", "We know how x depends on z. And when we know how x depends  on z, we can plug that into here and get how f depends on z. ", "Let's do that.  ", "Again, saying that g cannot change and keeping y constant  tells us g sub x dx plus g sub z dz is zero and we would like to ", "solve for dx in terms of dz. That tells us dx should be  minus g sub z dz divided by g sub x. ", "If you want, this is the rate of change of x  with respect to z when we keep y constant.  In our new terminology this is partial x over partial z with y ", "held constant. This is the rate of change of x  with respect to z. Now, when we know that, ", "we are going to plug that into this equation.  And that will tell us that df is f sub x times dx. ", "Well, what is dx? dx is now minus g sub z over g  sub x dz plus f sub z dz. So that will be minus fx g sub ", "z over g sub x plus f sub z times dz.  And so this coefficient here is the rate of change of f with ", "respect to z in the situation we are considering.  This quantity is what we call partial f over partial z with y ", "held constant. That is what we wanted to find.  Now, let's see another way to do the same calculation and then ", "you can choose which one you prefer.  ", "The other method is using the chain rule. ", "We use the chain rule to understand how f depends on z  when y is held constant. Let me first try the chain rule ", "brutally and then we will try to analyze what is going on.  You can just use the version that I have up there as a ", "template to see what is going on, but I am going to explain it  more carefully again.  ", "That is the most mechanical and mindless way of writing down the  chain rule. I am just saying here that I am ", "varying z, keeping y constant, and I want to know how f  changes. Well, f might change because x  might change, y might change and z might  change. Now, how quickly does x change? ", "Well, the rate of change of x in this situation is partial x,  partial z with y held constant. If I change x at this rate then ", "f will change at that rate. Now, y might change,  so the rate of change of y would be the rate of change of y  with respect to z holding y constant. ", "Wait a second. If y is held constant then y  doesn't change. So, actually,  this guy is zero and you didn't really have to write that term.  But I wrote it just to be systematic. ", "If y had been somehow able to change at a certain rate then  that would have caused f to change at that rate.  And, of course, if y is held constant then ", "nothing happens here. Finally, while z is changing at  a certain rate, this rate is this one and that  causes f to change at that rate. And then we add the effects ", "together. See, it is nothing but the  good-old chain rule. Just I have put these extra  subscripts to tell us what is held constant and what isn't. ", "Now, of course we can simplify it a little bit more.  Because, here, how quickly does z change if I  am changing z? Well, the rate of change of z, ", "with respect to itself, is just one.  In fact, the really mysterious part of this is the one here,  which is the rate of change of x with respect to z. ", "And, to find that, we have to understand the  constraint. How can we find the rate of  change of x with respect to z? Well, we could use  differentials, like we did here, ", "but we can also keep using the chain rule.  ", "How can I do that? Well, I can just look at how g  would change with respect to z when y is held constant.  I just do the same calculation with g instead of f. ", "But, before I do it, let's ask ourselves first what  is this equal to. Well, if g is held constant  then, when we vary z keeping y constant and changing x, ", "well, g still doesn't change. It is held constant.  In fact, that should be zero. But, if we just say that, ", "we are not going to get to that.  Let's see how we can compute that using the chain rule.  Well, the chain rule tells us g changes because x, ", "y and z change. How does it change because of x?  Well, partial g over partial x times the rate of change of x.  How does it change because of y? Well, partial g over partial y ", "times the rate of change of y. But, of course,  if you are smarter than me then you don't need to actually write  this one because y is held constant. ", "And then there is the rate of change because z changes.  And how quickly z changes here, of course, is one. ", "Out of this you get, well, I am tired of writing  partial g over partial x. We can just write g sub x times ", "partial x over partial z y constant plus g sub z.  And now we found how x depends on z. ", "Partial x over partial z with y held constant is negative g sub  z over g sub x. Now we plug that into that and ", "we get our answer. It goes all the way up here.  And then we get the answer. I am not going to, ", "well, I guess I can write it again.  ", "There was partial f over partial x times this guy,  minus g sub z over g sub x, plus partial f over partial z. ", "And you can observe that this is exactly the same formula that  we had over here. In fact, let's compare this to  make it side by side. I claim we did exactly the same ", "thing, just with different notations.  If you take the differential of f and you divide it by dz in  this situation where y is held constant and so on, ", "you get exactly this chain rule up there.  That chain rule up there is this guy, df,  divided by dz with y held constant. ", "And the term involving dy was replaced by zero on both sides  because we knew, actually, that y is held  constant. Now, the real difficulty in ", "both cases comes from dx. And what we do about dx is we  use the constant. Here we use it by writing dg  equals zero. Here we write the chain rule ", "for g, which is the same thing, just divided by dz with y held  constant. This formula or that formula  are the same, just divided by dz with y held ", "constant. And then, in both cases,  we used that to solve for dx. And then we plugged into the  formula of df to express df over dz, or partial f, ", "partial z with y held constant. So, the two methods are pretty  much the same. Quick poll.  Who prefers this one? Who prefers that one? ", "OK. Majority vote seems to be for  differentials, but it doesn't mean that it is  better. Both are fine.  You can use whichever one you want.  But you should give both a try. OK. Any questions? ", "Yes? Yes. Thank you.  I forgot to mention it. Where did that go? ", "I think I erased that part. We need to know -- --  directional derivatives. Pretty much the only thing to ", "remember about them is that df over ds,  in the direction of some unit vector u,  is just the gradient f dot product with u. ", "That is pretty much all we know about them.  Any other topics that I forgot to list?  No. Yes? ", "Can I erase three boards at a time?  No, I would need three hands to do that.  ", "I think what we should do now is look quickly at the practice  test. I mean, given the time,  you will mostly have to think about it yourselves. ", "Hopefully you have a copy of the practice exam.  The first problem is a simple problem. ", "Find the gradient. Find an approximation formula.  Hopefully you know how to do that.  The second problem is one about writing a contour plot.  And so, before I let you go for the weekend, I want to make sure ", "that you actually know how to read a contour plot.  One thing I should mention is this problem asks you to ", "estimate partial derivatives by writing a contour plot.  We have not done that, so that will not actually be on  the test. We will be doing qualitative  questions like what is the sine of a partial derivative. ", "Is it zero, less than zero or more than zero?  You don't need to bring a ruler to estimate partial derivatives  the way that this problem asks you to.  ", "[APPLAUSE] Let's look at problem 2B.  Problem 2B is asking you to find the point at which h equals  2200, partial h over partial x equals ", "zero and partial h over partial y is less than zero.  Let's try and see what is going on here.  A point where f equals 2200, well, that should be probably ", "on the level curve that says 2200.  We can actually zoom in. Here is the level 2200. ", "Now I want partial h over partial x to be zero.  That means if I change x, keeping y constant,  the value of h doesn't change. Which points on the level curve ", "satisfy that property? It is the top and the bottom.  If you are here, for example, and you move in the x ", "direction, well, you see,  as you get to there from the left,  the height first increases and then decreases.  It goes for a maximum at that point. ", "So, at that point, the partial derivative is zero  with respect to x. And the same here.  Now, let's find partial h over partial y less than zero. ", "That means if we go north we should go down.  Well, which one is it, top or bottom?  Top. Yes. Here, if you go north, ", "then you go from 2200 down to 2100.  This is where the point is. Now, the problem here was also ", "asking you to estimate partial h over partial y.  And if you were curious how you would do that,  well, you would try to figure out how long it takes before you ", "reach the next level curve. To go from here to here,  to go from Q to this new point, say Q prime, ", "the change in y, well, you would have to read  the scale, which was down here,  would be about something like 300. ", "What is the change in height when you go from Q to Q prime?  Well, you go down from 2200 to 2100.  That is actually minus 100 exactly. ", "OK? And so delta h over delta y is  about minus one-third, well, minus 100 over 300 which ", "is minus one-third. And that is an approximation  for partial derivative. So, that is how you would do it. ", "Now, let me go back to other things.  If you look at this practice exam, basically there is a bit  of everything and it is kind of fairly representative of what ", "might happen on Tuesday. There will be a mix of easy  problems and of harder problems. Expect something about  computing gradients, approximations,  rate of change. Expect a problem about reading ", "a contour plot. Expect one about a min/max  problem, something about Lagrange  multipliers, something about the chain rule  and something about constrained partial derivatives. ", "I mean pretty much all the topics are going to be there. "], "vid_duration": [12.0, 14.0, 13.0, 11.0, 15.0, 11.0, 14.0, 15.0, 13.0, 13.0, 10.0, 14.0, 11.0, 14.0, 13.0, 10.0, 11.0, 12.0, 14.0, 15.0, 10.0, 14.0, 12.0, 10.0, 10.0, 13.0, 13.0, 10.0, 14.0, 22.0, 12.0, 12.0, 12.0, 11.0, 10.0, 13.0, 12.0, 11.0, 11.0, 12.0, 11.0, 10.0, 10.0, 11.0, 11.0, 13.0, 11.0, 10.0, 12.0, 10.0, 12.0, 10.0, 10.0, 14.0, 11.0, 15.0, 14.0, 13.0, 15.0, 11.0, 13.0, 12.0, 11.0, 12.0, 15.0, 12.0, 11.0, 12.0, 10.0, 11.0, 11.0, 11.0, 11.0, 23.0, 11.0, 10.0, 12.0, 12.0, 11.0, 14.0, 10.0, 14.0, 14.0, 15.0, 13.0, 13.0, 11.0, 11.0, 12.0, 12.0, 12.0, 11.0, 11.0, 12.0, 10.0, 12.0, 12.0, 12.0, 16.0, 12.0, 14.0, 13.0, 13.0, 11.0, 12.0, 13.0, 13.0, 12.0, 36.0, 11.0, 10.0, 11.0, 13.0, 10.0, 10.0, 11.0, 13.0, 11.0, 14.0, 15.0, 10.0, 21.0, 13.0, 11.0, 13.0, 12.0, 10.0, 12.0, 19.0, 12.0, 13.0, 11.0, 11.0, 11.0, 18.0, 11.0, 14.0, 20.0, 10.0, 14.0, 14.0, 11.0, 11.0, 12.0, 32.0, 12.0, 10.0, 10.0, 21.0, 11.0, 13.0, 10.0, 11.0, 12.0, 10.0, 13.0, 12.0, 10.0, 13.0, 11.0, 21.0, 16.0, 11.0, 14.0, 11.0, 12.0, 10.0, 14.0, 13.0, 13.0, 13.0, 10.0, 13.0, 12.0, 11.0, 10.0, 13.0, 11.0, 11.0, 12.0, 14.0, 12.0, 17.0, 12.0, 18.0, 10.0, 15.0, 18.0, 12.0, 11.0, 15.0, 10.0, 10.0, 34.0, 11.0, 11.0, 12.0, 15.0, 10.0, 10.0, 15.0, 12.0, 12.0, 10.0, 14.0, 13.0, 14.0, 13.0, 16.0, 13.0, 12.0, 12.0, 2.03], "stet": [[0, 12.0], [12.0, 26.0], [26.0, 39.0], [39.0, 50.0], [50.0, 65.0], [65.0, 76.0], [76.0, 90.0], [90.0, 105.0], [105.0, 118.0], [118.0, 131.0], [131.0, 141.0], [141.0, 155.0], [155.0, 166.0], [166.0, 180.0], [180.0, 193.0], [193.0, 203.0], [203.0, 214.0], [214.0, 226.0], [226.0, 240.0], [240.0, 255.0], [255.0, 265.0], [265.0, 279.0], [279.0, 291.0], [291.0, 301.0], [301.0, 311.0], [311.0, 324.0], [324.0, 337.0], [337.0, 347.0], [347.0, 361.0], [361.0, 383.0], [383.0, 395.0], [395.0, 407.0], [407.0, 419.0], [419.0, 430.0], [430.0, 440.0], [440.0, 453.0], [453.0, 465.0], [465.0, 476.0], [476.0, 487.0], [487.0, 499.0], [499.0, 510.0], [510.0, 520.0], [520.0, 530.0], [530.0, 541.0], [541.0, 552.0], [552.0, 565.0], [565.0, 576.0], [576.0, 586.0], [586.0, 598.0], [598.0, 608.0], [608.0, 620.0], [620.0, 630.0], [630.0, 640.0], [640.0, 654.0], [654.0, 665.0], [665.0, 680.0], [680.0, 694.0], [694.0, 707.0], [707.0, 722.0], [722.0, 733.0], [733.0, 746.0], [746.0, 758.0], [758.0, 769.0], [769.0, 781.0], [781.0, 796.0], [796.0, 808.0], [808.0, 819.0], [819.0, 831.0], [831.0, 841.0], [841.0, 852.0], [852.0, 863.0], [863.0, 874.0], [874.0, 885.0], [885.0, 908.0], [908.0, 919.0], [919.0, 929.0], [929.0, 941.0], [941.0, 953.0], [953.0, 964.0], [964.0, 978.0], [978.0, 988.0], [988.0, 1002.0], [1002.0, 1016.0], [1016.0, 1031.0], [1031.0, 1044.0], [1044.0, 1057.0], [1057.0, 1068.0], [1068.0, 1079.0], [1079.0, 1091.0], [1091.0, 1103.0], [1103.0, 1115.0], [1115.0, 1126.0], [1126.0, 1137.0], [1137.0, 1149.0], [1149.0, 1159.0], [1159.0, 1171.0], [1171.0, 1183.0], [1183.0, 1195.0], [1195.0, 1211.0], [1211.0, 1223.0], [1223.0, 1237.0], [1237.0, 1250.0], [1250.0, 1263.0], [1263.0, 1274.0], [1274.0, 1286.0], [1286.0, 1299.0], [1299.0, 1312.0], [1312.0, 1324.0], [1324.0, 1360.0], [1360.0, 1371.0], [1371.0, 1381.0], [1381.0, 1392.0], [1392.0, 1405.0], [1405.0, 1415.0], [1415.0, 1425.0], [1425.0, 1436.0], [1436.0, 1449.0], [1449.0, 1460.0], [1460.0, 1474.0], [1474.0, 1489.0], [1489.0, 1499.0], [1499.0, 1520.0], [1520.0, 1533.0], [1533.0, 1544.0], [1544.0, 1557.0], [1557.0, 1569.0], [1569.0, 1579.0], [1579.0, 1591.0], [1591.0, 1610.0], [1610.0, 1622.0], [1622.0, 1635.0], [1635.0, 1646.0], [1646.0, 1657.0], [1657.0, 1668.0], [1668.0, 1686.0], [1686.0, 1697.0], [1697.0, 1711.0], [1711.0, 1731.0], [1731.0, 1741.0], [1741.0, 1755.0], [1755.0, 1769.0], [1769.0, 1780.0], [1780.0, 1791.0], [1791.0, 1803.0], [1803.0, 1835.0], [1835.0, 1847.0], [1847.0, 1857.0], [1857.0, 1867.0], [1867.0, 1888.0], [1888.0, 1899.0], [1899.0, 1912.0], [1912.0, 1922.0], [1922.0, 1933.0], [1933.0, 1945.0], [1945.0, 1955.0], [1955.0, 1968.0], [1968.0, 1980.0], [1980.0, 1990.0], [1990.0, 2003.0], [2003.0, 2014.0], [2014.0, 2035.0], [2035.0, 2051.0], [2051.0, 2062.0], [2062.0, 2076.0], [2076.0, 2087.0], [2087.0, 2099.0], [2099.0, 2109.0], [2109.0, 2123.0], [2123.0, 2136.0], [2136.0, 2149.0], [2149.0, 2162.0], [2162.0, 2172.0], [2172.0, 2185.0], [2185.0, 2197.0], [2197.0, 2208.0], [2208.0, 2218.0], [2218.0, 2231.0], [2231.0, 2242.0], [2242.0, 2253.0], [2253.0, 2265.0], [2265.0, 2279.0], [2279.0, 2291.0], [2291.0, 2308.0], [2308.0, 2320.0], [2320.0, 2338.0], [2338.0, 2348.0], [2348.0, 2363.0], [2363.0, 2381.0], [2381.0, 2393.0], [2393.0, 2404.0], [2404.0, 2419.0], [2419.0, 2429.0], [2429.0, 2439.0], [2439.0, 2473.0], [2473.0, 2484.0], [2484.0, 2495.0], [2495.0, 2507.0], [2507.0, 2522.0], [2522.0, 2532.0], [2532.0, 2542.0], [2542.0, 2557.0], [2557.0, 2569.0], [2569.0, 2581.0], [2581.0, 2591.0], [2591.0, 2605.0], [2605.0, 2618.0], [2618.0, 2632.0], [2632.0, 2645.0], [2645.0, 2661.0], [2661.0, 2674.0], [2674.0, 2686.0], [2686.0, 2698.0], [2698.0, 2700.03]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [2368, 2700]}
{"example_id": "mit002@@ocw-18_02-f07-lec06_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  So, if you remember last time, we looked at parametric  equations -- -- as a way of describing the motion of a point ", "that moves in the plane or in space as a function of time of  your favorite parameter that will tell you how far the motion ", "has progressed. And, I think we did it in  detail the example of the cycloid, which is the curve ", "traced by a point on a wheel that's rolling on a flat  surface. So, we have this example where ", "we have this wheel that's rolling on the x-axis,  and we have this point on the wheel.  And, as it moves around, it traces a trajectory that ", "moves more or less like this. OK, so I'm trying a new color.  Is this visible from the back? So, no more blue. ", "OK, so remember, in general, we are trying to  find the position, so, x of t, y of t, ", "maybe z of t if we are in space -- -- of a moving point along a ", "trajectory. And, one way to think about  this is in terms of the position vector. ", "So, position vector is just the vector whose components are  coordinates of a point, OK, so if you prefer, ", "that's the same thing as a vector from the origin to the  moving point. So, maybe our point is here, P. ", "So, this vector here -- This vector here is vector OP. ", "And, that's also the position vector r of t. ", "So, just to give you, again, that example -- -- if I ", "take the cycloid for a wheel of radius 1, ", "and let's say that we are going at unit speed so that the angle  that we used as a parameter of time is the same thing as time ", "when the position vector, in this case,  we found to be, just to make sure that they ", "have it right, .  OK, that's a formula that you should have in your notes from ", "last time, except we had theta instead of t because we were  using the angle. But now I'm saying,  we are moving at unit speed, so time and angle are the same ", "thing. So, now, what's interesting  about this is we can analyze the motion in more detail. ", "OK, so, now that we know the position of the point as a  function of time, we can try to study how it  varies in particular things like the speed and acceleration. ", "OK, so let's start with speed. Well, in fact we can do better  than speed. Let's not start with speed.  So, speed is a number. It tells you how fast you are ", "going along your trajectory. I mean, if you're driving in a  car, then it tells you how fast you are going.  But, unless you have one of these fancy cars with a GPS,  it doesn't tell you which direction you're going. ", "And, that's useful information, too, if you're trying to figure  out what your trajectory is. So, in fact,  there's two aspects to it. One is how fast you are going,  and the other is in what direction you're going. ", "That means actually we should use a vector maybe to think  about this. And so, that's called the ", "velocity vector. And, the way we can get it,  so, it's called usually V, so, V here stands for velocity ", "more than for vector. And, you just get it by taking  the derivative of a position vector with respect to time.  Now, it's our first time writing this kind of thing with ", "a vector. So, the basic rule is you can  take the derivative of a vector quantity just by taking the  derivatives of each component. OK, so that's just dx/dt, ", "dy/dt, and if you have z component, dz/dt. ", "So, let me -- OK, so -- OK, so let's see what it ", "is for the cycloid. So, an example of a cycloid, ", "well, so what do we get when we take the derivatives of this ", "formula there? Well, so, the derivative of t  is 1- cos(t). The derivative of 1 is 0. ", "The derivative of -cos(t) is sin(t).  Very good. OK, that's at least one thing  you should remember from single variable calculus. ", "Hopefully you remember even more than that.  OK, so that's the velocity vector.  It tells us at any time how fast we are going, ", "and in what direction. So, for example, observe.  Remember last time at the end of class we were trying to  figure out what exactly happens near the bottom point, ", "when we have this motion that seems to stop and go backwards.  And, we answered that one way. But, let's try to understand it  in terms of velocity. What if I plug t equals 0 in ", "here? Then, 1- cos(t) is 0,  sin(t) is 0. The velocity is 0.  So, at the time,at that particular time, ", "our point is actually not moving.  Of course, it's been moving just before, and it starts  moving just afterwards. It's just the instant,  at that particular instant, the speed is zero. ", "So, that's especially maybe a counterintuitive thing,  but something is moving. And at that time,  it's actually stopped. Now, let's see, ", "so that's the vector. And, it's useful.  But, if you want just the usual speed as a number,  then, what will you do? Well, you will just take ", "exactly the magnitude of this vector.  So, speed, which is the scalar quantity is going to be just the ", "magnitude of the vector, V.  OK, so, in this case, while it would be square root ", "of (1- cost)^2 sin^2(t), and if you expand that,  you will get, let me take a bit more space, ", "it's going to be square root of 1 - 2cos(t) cos^2(t) sin^2(t). ", "It seems to simplify a little bit because we have cos^2 plus  sin^2. That's 1.  So, it's going to be the square root of 2 - 2cos(t). ", "So, at this point, if I was going to ask you,  when is the speed the smallest or the largest?  You could answer based on that. See, at t equals 0, ", "well, that turns out to be zero.  The point is not moving. At t equals pi,  that ends up being the square root of 2 plus 2,  which is 4. So, that's 2. ", "And, that's when you're truly at the top of the arch,  and that's when the point is moving the fastest.  In fact, they are spending twice as fast as the wheel  because the wheel is moving to the right at unit speed, ", "and the wheel is also rotating. So, it's moving to the right  and unit speed relative to the center so that the two effects  add up, and give you a speed of 2. ", "Anyway, that's a formula we can get.  OK, now, what about acceleration? ", "So, here I should warn you that there is a serious discrepancy  between the usual intuitive notion of acceleration, ", "the one that you are aware of when you drive a car and the one  that we will be using. So, you might think  acceleration is just the directive of speed. ", "If my car goes 55 miles an hour on the highway and it's going a  constant speed, it's not accelerating.  But, let's say that I'm taking a really tight turn. ", "Then, I'm going to feel something.  There is some force being exerted.  And, in fact, there is a sideways  acceleration at that point even though the speed is not ", "changing. So, the definition will take  effect. The acceleration is,  as a vector, and the acceleration vector is ", "just the derivative of a velocity vector.  So, even if the speed is constant, that means, ", "even if a length of the velocity vector stays the same,  the velocity vector can still rotate.  And, as it rotates, it uses acceleration. ", "OK, and so this is the notion of acceleration that's relevant  to physics when you find F=ma; that's the (a) that you have in ", "mind here. It's a vector.  Of course, if you are moving in a straight line,  then the two notions are the same.  I mean, acceleration is also going to be along the line, ", "and it's going to has to do with the derivative of speed.  But, in general, that's not quite the same.  So, for example, let's look at the cycloid. ", "If we take the example of the cycloid, well,  what's the derivative of one minus cos(t)?  It's sin(t). And, what's the derivative of ", "sin(t)? cos(t), OK.  So, the acceleration vector is . ", "So, in particular, let's look at what happens at  time t equals zero when the point is not moving.  Well, the acceleration vector there will be zero from one. ", "So, what that means is that if I look at my trajectory at this  point, that the acceleration vector is pointing in that ", "direction. It's the unit vector in the  vertical direction. So, my point is not moving at  that particular time. But, it's accelerating up. ", "So, that means that actually as it comes down,  first it's slowing down. Then it stops here,  and then it reverses going back up. ", "OK, so that's another way to understand what we were saying  last time that the trajectory at that point has a vertical ", "tendency because that's the direction in which the motion is  going to occur just before and just after time zero. ", "OK, any questions about that? No. ", "OK, so I should insist maybe on one thing,  which is that, so, we can differentiate ", "vectors just component by component,  OK, and we can differentiate vector expressions according to  certain rules that we'll see in a moment. ", "One thing that we cannot do, it's not true that the length  of dr dt, which is the speed, is equal to the length of dt. ", "OK, this is completely false. And, they are really not the  same. So, if you have to  differentiate the length of a vector, but basically you are in ", "trouble. If you really,  really want to do it, well, the length of the vector  is the square root of the sums of the squares of the  components, and from that you can use the  formula for the derivative of the square root, ", "and the chain rule, and various other things.  And, you can get there. But, it will not be a very nice  expression. There is no simple formula for  this kind of thing. Fortunately, ", "we almost never have to compute this kind of thing because,  after all, it's not a very relevant quantity.  What's more relevant might be this one.  This is actually the speed. This one, I don't know what it ", "means. OK. ", "So, let's continue our exploration.  So, the next concept that I want to define is that of arc ", "length. So, arc length is just the  distance that you have traveled along the curve,  OK? So, if you are in a car,  you know, it has mileage counter that tells you how far ", "you've gone, how much fuel you've used if it's a fancy car.  And, what it does is it actually integrates the speed of  the time to give you the arc length along the trajectory of ", "the car. So, the usual notation that we  will have is (s) for arc length. I'm not quite sure how you get ", "an (s) out of this, but it's the usual notation.  OK, so, (s) is for distance traveled along the trajectory. ", "And, so that makes sense, of course, we need to fix a  reference point. Maybe on the cycloid,  we'd say it's a distance starting on the origin.  In general, maybe you would say you start at time, ", "t equals zero. But, it's a convention.  If you knew in advance, you could have,  actually, your car's mileage counter to count backwards from ", "the point where the car will die and start walking.  I mean, that would be sneaky-freaky,  but you could have a negative arc length that gets closer and ", "closer to zero, and gets to zero at the end of  a trajectory, or anything you want.  I mean, arc length could be positive or negative.  Typically it's negative what you are before the reference ", "point, and positive afterwards. So, now, how does it relate to  the things we've seen there? Well, so in particular, ", "how do you relate arc length and time?  Well, so, there's a simple relation, which is that the rate ", "of change of arc length versus time,  well, that's going to be the speed at which you are moving,  OK, because the speed as a scalar quantity tells you how ", "much distance you're covering per unit time.  OK, and in fact, to be completely honest,  I should put an absolute value here because there is examples ", "of curves maybe where your motion is going back and forth  along the same curve. And then, you don't want to  keep counting arc length all the time. ", "Actually, maybe you want to say that the arc length increases  and then decreases along the curve.  I mean, you get to choose how you count it.  But, in this case, if you are moving back and  forth, it would make more sense to have the arc length first ", "increase, then decrease,  increase again, and so on. ", "So -- So if you want to know really what the arc length is,  then basically the only way to do it is to integrate speed ", "versus time. So, if you wanted to know how  long an arch of cycloid is, you have this nice-looking  curve; how long is it? ", "Well, you'd have to basically integrate this quantity from t  equals zero to 2 pi.  ", "And, to say the truth, I don't really know how to  integrate that. So, we don't actually have a  formula for the length at this point. ", "However, we'll see one later using a cool trick,  and multi-variable calculus. So, for now, ", "we'll just leave the formula like that, and we don't know how  long it is. Well, you can put that into  your calculator and get the numerical value. ", "But, that's the best I can offer. ", "Now, another useful notion is the unit vector to the ", "trajectory. So, the usual notation is T hat.  It has a hat because it's a unit vector, and T because it's ", "tangent. Now, how do we get this unit  vector? So, maybe I should have pointed  out before that if you're moving along some trajectory, ", "say you're going in that direction, then when you're at  this point, the velocity vector is going to  be tangential to the trajectory. It tells you the direction of ", "motion in particular. So, if you want a unit vector  that goes in the same direction, all you have to do is rescale  it, so, at its length becomes one. ", "So, it's v divided by a magnitude of v.  ", "So, it seems like now we have a lot of different things that  should be related in some way. So, let's see what we can say. ", "Well, we can say that dr by dt, so, that's the velocity vector, ", "that's the same thing as if I use the chain rule dr/ds times  ds/dt. OK, so, let's think about this ", "things. So, this guy here we've just  seen. That's the same as the speed, ", "OK? So, this one here should be v  divided by its length. So, that means this actually ", "should be the unit vector. OK, so, let me rewrite that.  It's T ds/dt. So, maybe if I actually stated ", "directly that way, see, I'm just saying the  velocity vector has a length and a direction.  The length is the speed. The direction is tangent to the ", "trajectory.  ", "So, the speed is ds/dt, and the vector is T hat.  And, that's how we get this. So, let's try just to see why ", "dr/ds should be T. Well, let's think of dr/ds.  dr/ds means position vector r means you have the origin,  which is somewhere out there, and the vector r is here. ", "So, dr/ds means we move by a small amount,  delta s along the trajectory a certain distance delta s.  And, we look at how the position vector changes. ", "Well, we'll have a small change. Let me call that vector delta r  corresponding to the size, corresponding to the length ", "delta s. And now, delta r should be  essentially roughly equal to, well, its direction will be ", "tangent to the trajectory. If I take a small enough  interval, then the direction will be  almost tensioned to the trajectory times the length of ", "it will be delta s, the distance that I have  traveled. OK, sorry, maybe I should  explain that on a separate board. ", "OK, so, let's say that we have that amount of time,  delta t. So, let's zoom into that curve. ", "So, we have r at time t. We have r at time t plus delta ", "t. This vector here I will call  delta r. The length of this vector is ", "delta s. And, the direction is  essentially that of a vector. OK, so, delta s over delta t, ", "that's the distance traveled divided by the time.  That's going to be close to the speed. ", "And, delta r is approximately T times delta s. ", "So, now if I divide both sides by delta t, I get this.  And, if I take the limit as delta t turns to zero, ", "then I get the same formula with the derivatives and with an  equality. It's an approximation.  The approximation becomes better and better if I go to  smaller intervals.  ", "OK, are there any questions about this?  Yes? Yes, that's correct. ", "OK, so let's be more careful, actually.  So, you're asking about whether the delta r is actually strictly ", "tangent to the curve. Is that -- That's correct.  Actually, delta r is not strictly tangent to anything.  So, maybe I should draw another picture. ", "If I'm going from here to here, then delta r is going to be  this arc inside the curve while the vector will be going in this ", "direction, OK? So, they are not strictly  parallel to each other. That's why it's only  approximately equal. Similarly, this distance,  the length of delta r is not exactly the length along the ", "curve. It's actually a bit shorter.  But, if we imagine a smaller and smaller portion of the  curve, then this effect of the curve  being a curve and not a straight line becomes more and more ", "negligible. If you zoom into the curve  sufficiently, then it looks more and more  like a straight line. And then, what I said becomes  true in the limit. OK? Any other questions? ", "No? OK. So, what happens next? ", "OK, so let me show you a nice example of why we might want to  use vectors to study parametric curves because,  after all, a lot of what's here you can just do in coordinates. ", "And, we don't really need vectors.  Well, and truly, vectors being a language,  you never strictly need it, but it's useful to have a  notion of vectors. So, I want to tell you a bit ", "about Kepler's second law of celestial mechanics. ", "So, that goes back to 1609. So, that's not exactly recent  news, OK? But, still I think it's a very ", "interesting example of why you might want to use vector methods  to analyze motions. So, what happened back then was  Kepler was trying to observe the motion of planets in the sky, ", "and trying to come up with general explanations of how they  move. Before him, people were saying,  well, they cannot move in a circle.  But maybe it's more complicated than that.  We need to add smaller circular motions on top of each other, ", "and so on. They have more and more  complicated theories. And then Kepler came with these  laws that said basically that planets move in an ellipse  around the sun, and that they move in a very ", "specific way along that ellipse. So, there's actually three  laws, but let me just tell you about the second one that has a  very nice vector interpretation. So, what Kepler's second law ", "says is that the motion of planets is, first of all,  they move in a plane. And second, the area swept out ", "by the line from the sun to the planet is swept at constant ", "time. Sorry, is swept at constant  rate. From the sun to the planet, ", "it is swept out by the line at a constant rate. ", "OK, so that's an interesting law because it tells you,  once you know what the orbit of the planet looks like, ", "it tells you how fast it's going to move on that orbit.  ", "OK, so let me explain again. So, this law says maybe the ", "sun, let's put the sun here at the origin, and let's have a  planet. Well, the planet orbits around ", "the sun -- -- in some trajectory.  So, this is supposed to be light blue. ", "Can you see that it's different from white?  No? OK, me neither.  [LAUGHTER] OK, it doesn't really matter.  So, the planet moves on its orbit. ", "And, if you wait for a certain time, then a bit later it would  be here, and then here, and so on.  Then, you can look at the amount of area inside this ", "triangular wedge. And, the claim is that the  amount of area in here is proportional to the time  elapsed. So, in particular,  if a planet is closer to the sun, then it has to go faster. ", "And, if it's farther away from the sun, then it has to go  slower so that the area remains proportional to time.  So, it's a very sophisticated prediction. ", "And, I think the way he came to it was really just by using a  lot of observations, and trying to measure what was  true that wasn't true. But, let's try to see how we ", "can understand that in terms of all we know today about  mechanics. So, in fact,  what happens is that Newton, so Newton was quite a bit ", "later. That was the late 17th century  instead of the beginning of the 17th century. ", "So, he was able to explain this using his laws for gravitational ", "attraction. And, you'll see that if we  reformulate Kepler's Law in terms of vectors, ", "and if we work a bit with these vectors,  we are going to end up with something that's actually  completely obvious to us now. At the time,  it was very far from obvious, but to us now to completely ", "obvious. So, let's try to see,  what does Kepler's law say in terms of vectors? ", "OK, so, let's think of what kinds of vectors we might want  to have in here. Well, it might be good to think ", "of, maybe, the position vector, and maybe its variation.  So, if we wait a certain amount of time, we'll have a vector, ", "delta r, which is the change in position vector a various  interval of time. OK, so let's start with the ", "first step. What's the most complicated  thing in here? It's this area swept out by the  line. How do we express that area in  terms of vectors? Well, I've almost given the ", "answer by drawing this picture, right?  If I take a sufficiently small amount of time,  this shaded part looks like a triangle. ", "So, we have to find the area of the triangle.  Well, we know how to do that now.  So, the area is approximately equal to one half of the area of ", "a parallelogram that I could form from these vectors.  And, the area of a parallelogram is given by the ", "magnitude of a cross product. OK, so, I should say,  this is the area swept in time delta t. ", "You should think of delta t as relatively small.  I mean, the scale of a planet that might still be a few days,  but small compared to the other old trajectory. ", "So, let's remember that the amount by which we moved,  delta r, is approximately equal to v ", "times delta t, OK, and just using the  definition of a velocity vector. So, let's use that. ", "Sorry, so it's approximately equal to r cross v magnitude  times delta t. I can take out the delta t, ", "which is scalar. So, now, what does it mean to  say that area is swept at a constant rate?  It means this thing is proportional to delta t. ", "So, that means, so, the law says,  in fact, that the length of this cross product r cross v ", "equals a constant. OK, r cross v has constant ", "length. Any questions about that?  No? Yes? Yes, let me try to explain that ", "again. So, what I'm claiming is that  the length of the cross products r cross v measures the rate at  which area is swept by the position vector. ", "I should say, with a vector of one half of  this length is the rate at which area is swept.  How do we see that? Well, let's take a small time  interval, delta t. In time, delta t, ", "our planet moves by v delta t, OK?  So, if it moves by v delta t, it means that this triangle up  there has two sides. One is the position vector, ", "r. The other one is v delta t.  So, its area is given by one half of the magnitude of a cross  product. That's the formula we've seen  for the area of a triangle in space. ", "So, the area is one half of the cross product,  r, and v delta t, magnitude of the cross product.  So, to say that the rate at which area is swept is constant ", "means that these two are proportional.  Area divided by delta t is constant at our time.  And so, this is constant. OK, now, what about the other ", "half of the law? Well, it says that the motion  is in a plane, and so we have a plane in which ", "the motion takes place. And, it contains,  also, the sun. And, it contains the  trajectory. So, let's think about that ", "plane. Well, I claim that the position  vector is in the plane. OK, that's what we are saying.  But, there is another vector that I know it is in the plane. ", "You could say the position vector at another time,  or at any time, but in fact,  what's also true is that the velocity vector is in the plane. ", "OK, if I'm moving in the plane, then position and velocity are  in there. So, the plane of motion ", "contains r and v. So, what's the direction of the  cross product r cross v? Well, it's the direction that's ", "perpendicular to this plane. So, it's normal to the plane of ", "motion. And, that means, now,  that actually we've put the two statements in there into a  single form because we are saying r cross v has constant ", "length and constant direction. In fact, in general,  maybe I should say something about this.  So, if you just look at the position vector,  and the velocity vector for any motion at any given time, ", "then together, they determine some plane.  And, that's the plane that contains the origin,  the point, and the velocity vector.  If you want, it's the plane in which the ", "motion seems to be going at the given time.  Now, of course, if your motion is not in a  plane, then that plane will change.  It's, however, instant, if a plane in which ", "the motion is taking place at a given time.  And, to say that the motion actually stays in that plane  forever means that this guy will not change direction. ", "OK, so -- [LAUGHTER] [APPLAUSE]  OK, so, Kepler's second law is actually equivalent to saying ", "that r cross v equals a constant vector, OK? ", "That's what the law says. So, in terms of derivatives,  it means d by dt of r cross v is the zero vector. ", "OK, now, so there's an interesting thing to note,  which is that we can use the usual product rule for  derivatives with vector expressions, ", "with dot products or cross products.  There's only one catch, which is that when we  differentiate a cross product, we have to be careful that the  guy on the left stays on the left. ", "The guy on the right stays on the right.  OK, so, if you know that uv prime equals u prime v plus uv  prime, then you are safe. If you know it as u prime v ", "cross v prime u, then you are not safe.  OK, so it's the only thing to watch for.  So, product rule is OK for taking the derivative of a dot ", "product. There, you don't actually even  need to be very careful about all the things or the derivative  of a cross product. There you just need to be a ", "little bit more careful. OK, so, now that we know that,  we can write this as dr/dt cross v plus r cross dv/dt, ", "OK? Well, let's reformulate things  slightly. So, dr dt already has a name.  In fact, that's v. OK, that's what we call the ", "velocity vector. So, this is v cross v plus r  cross, what is dv/dt? That's the acceleration, ", "a, equals zero. OK, so now what's the next step?  Well, we know what v cross v is because, remember, ", "a vector cross itself is always zero, OK?  So, this is the same r cross a equals zero, ", "and that's the same as saying that the cross product of two  vectors is zero exactly when the parallelogram of the form has no  area. And, the way in which that ", "happens is if they are actually parallel to each other.  So, that means the acceleration is parallel to the position.  OK, so, in fact, what Kepler's second law says ", "is that the acceleration is parallel to the position vector.  And, since we know that acceleration is caused by a ", "force that's equivalent to the fact that the gravitational  force --   -- is parallel to the position vector, that means, ", "well, if you have the sun here at the origin,  and if you have your planets, well, the gravitational force  caused by the sun should go along this line. ", "In fact, the law doesn't even say whether it's going towards  the sun or away from the sun. Well, what we know now is that,  of course, the attraction is towards the sun.  But, Kepler's law would also be true, actually,  if things were going away. So, in particular, ", "say, electric force also has this property of being towards  the central charge. So, actually,  if you look at motion of charged particles in an electric ", "field caused by a point charged particle, it also satisfies  Kepler's law, satisfies the same law.  OK, that's the end for today, thanks. "], "vid_duration": [12.0, 14.0, 13.0, 13.0, 17.0, 13.0, 14.0, 11.0, 16.0, 12.0, 13.0, 12.0, 10.0, 12.0, 10.0, 14.0, 12.0, 10.0, 10.0, 11.0, 12.0, 11.0, 11.0, 10.0, 11.0, 11.0, 13.0, 16.0, 11.0, 15.0, 12.0, 10.0, 14.0, 12.0, 11.0, 12.0, 11.0, 11.0, 15.0, 13.0, 10.0, 13.0, 13.0, 14.0, 12.0, 14.0, 10.0, 10.0, 11.0, 12.0, 16.0, 10.0, 10.0, 10.0, 10.0, 12.0, 11.0, 12.0, 10.0, 10.0, 14.0, 15.0, 12.0, 16.0, 15.0, 11.0, 10.0, 10.0, 10.0, 14.0, 11.0, 13.0, 18.0, 12.0, 10.0, 10.0, 15.0, 11.0, 10.0, 10.0, 11.0, 10.0, 23.0, 11.0, 10.0, 10.0, 11.0, 12.0, 14.0, 16.0, 13.0, 10.0, 11.0, 14.0, 15.0, 10.0, 33.0, 10.0, 13.0, 10.0, 10.0, 11.0, 10.0, 12.0, 13.0, 12.0, 23.0, 12.0, 10.0, 16.0, 11.0, 11.0, 12.0, 11.0, 28.0, 14.0, 14.0, 13.0, 13.0, 12.0, 12.0, 13.0, 10.0, 12.0, 11.0, 13.0, 10.0, 11.0, 10.0, 31.0, 21.0, 13.0, 11.0, 13.0, 12.0, 12.0, 18.0, 17.0, 11.0, 16.0, 12.0, 10.0, 15.0, 12.0, 12.0, 14.0, 19.0, 15.0, 13.0, 10.0, 13.0, 42.0, 10.0, 15.0, 11.0, 10.0, 14.0, 12.0, 11.0, 12.0, 12.0, 17.0, 17.0, 11.0, 11.0, 23.0, 16.0, 15.0, 13.0, 13.0, 10.0, 12.0, 12.0, 10.0, 13.0, 11.0, 16.0, 12.0, 12.0, 15.0, 10.0, 12.0, 13.0, 11.0, 11.0, 12.0, 13.0, 14.0, 13.0, 12.0, 12.0, 12.0, 10.0, 18.0, 11.0, 14.0, 12.0, 11.0, 10.0, 11.0, 25.0, 13.0, 19.0, 12.0, 10.0, 11.0, 18.0, 13.0, 21.0, 11.0, 14.0, 11.0, 15.0, 11.0, 14.0, 10.0, 13.0, 14.0, 12.0, 10.0, 9.02], "stet": [[0, 12.0], [12.0, 26.0], [26.0, 39.0], [39.0, 52.0], [52.0, 69.0], [69.0, 82.0], [82.0, 96.0], [96.0, 107.0], [107.0, 123.0], [123.0, 135.0], [135.0, 148.0], [148.0, 160.0], [160.0, 170.0], [170.0, 182.0], [182.0, 192.0], [192.0, 206.0], [206.0, 218.0], [218.0, 228.0], [228.0, 238.0], [238.0, 249.0], [249.0, 261.0], [261.0, 272.0], [272.0, 283.0], [283.0, 293.0], [293.0, 304.0], [304.0, 315.0], [315.0, 328.0], [328.0, 344.0], [344.0, 355.0], [355.0, 370.0], [370.0, 382.0], [382.0, 392.0], [392.0, 406.0], [406.0, 418.0], [418.0, 429.0], [429.0, 441.0], [441.0, 452.0], [452.0, 463.0], [463.0, 478.0], [478.0, 491.0], [491.0, 501.0], [501.0, 514.0], [514.0, 527.0], [527.0, 541.0], [541.0, 553.0], [553.0, 567.0], [567.0, 577.0], [577.0, 587.0], [587.0, 598.0], [598.0, 610.0], [610.0, 626.0], [626.0, 636.0], [636.0, 646.0], [646.0, 656.0], [656.0, 666.0], [666.0, 678.0], [678.0, 689.0], [689.0, 701.0], [701.0, 711.0], [711.0, 721.0], [721.0, 735.0], [735.0, 750.0], [750.0, 762.0], [762.0, 778.0], [778.0, 793.0], [793.0, 804.0], [804.0, 814.0], [814.0, 824.0], [824.0, 834.0], [834.0, 848.0], [848.0, 859.0], [859.0, 872.0], [872.0, 890.0], [890.0, 902.0], [902.0, 912.0], [912.0, 922.0], [922.0, 937.0], [937.0, 948.0], [948.0, 958.0], [958.0, 968.0], [968.0, 979.0], [979.0, 989.0], [989.0, 1012.0], [1012.0, 1023.0], [1023.0, 1033.0], [1033.0, 1043.0], [1043.0, 1054.0], [1054.0, 1066.0], [1066.0, 1080.0], [1080.0, 1096.0], [1096.0, 1109.0], [1109.0, 1119.0], [1119.0, 1130.0], [1130.0, 1144.0], [1144.0, 1159.0], [1159.0, 1169.0], [1169.0, 1202.0], [1202.0, 1212.0], [1212.0, 1225.0], [1225.0, 1235.0], [1235.0, 1245.0], [1245.0, 1256.0], [1256.0, 1266.0], [1266.0, 1278.0], [1278.0, 1291.0], [1291.0, 1303.0], [1303.0, 1326.0], [1326.0, 1338.0], [1338.0, 1348.0], [1348.0, 1364.0], [1364.0, 1375.0], [1375.0, 1386.0], [1386.0, 1398.0], [1398.0, 1409.0], [1409.0, 1437.0], [1437.0, 1451.0], [1451.0, 1465.0], [1465.0, 1478.0], [1478.0, 1491.0], [1491.0, 1503.0], [1503.0, 1515.0], [1515.0, 1528.0], [1528.0, 1538.0], [1538.0, 1550.0], [1550.0, 1561.0], [1561.0, 1574.0], [1574.0, 1584.0], [1584.0, 1595.0], [1595.0, 1605.0], [1605.0, 1636.0], [1636.0, 1657.0], [1657.0, 1670.0], [1670.0, 1681.0], [1681.0, 1694.0], [1694.0, 1706.0], [1706.0, 1718.0], [1718.0, 1736.0], [1736.0, 1753.0], [1753.0, 1764.0], [1764.0, 1780.0], [1780.0, 1792.0], [1792.0, 1802.0], [1802.0, 1817.0], [1817.0, 1829.0], [1829.0, 1841.0], [1841.0, 1855.0], [1855.0, 1874.0], [1874.0, 1889.0], [1889.0, 1902.0], [1902.0, 1912.0], [1912.0, 1925.0], [1925.0, 1967.0], [1967.0, 1977.0], [1977.0, 1992.0], [1992.0, 2003.0], [2003.0, 2013.0], [2013.0, 2027.0], [2027.0, 2039.0], [2039.0, 2050.0], [2050.0, 2062.0], [2062.0, 2074.0], [2074.0, 2091.0], [2091.0, 2108.0], [2108.0, 2119.0], [2119.0, 2130.0], [2130.0, 2153.0], [2153.0, 2169.0], [2169.0, 2184.0], [2184.0, 2197.0], [2197.0, 2210.0], [2210.0, 2220.0], [2220.0, 2232.0], [2232.0, 2244.0], [2244.0, 2254.0], [2254.0, 2267.0], [2267.0, 2278.0], [2278.0, 2294.0], [2294.0, 2306.0], [2306.0, 2318.0], [2318.0, 2333.0], [2333.0, 2343.0], [2343.0, 2355.0], [2355.0, 2368.0], [2368.0, 2379.0], [2379.0, 2390.0], [2390.0, 2402.0], [2402.0, 2415.0], [2415.0, 2429.0], [2429.0, 2442.0], [2442.0, 2454.0], [2454.0, 2466.0], [2466.0, 2478.0], [2478.0, 2488.0], [2488.0, 2506.0], [2506.0, 2517.0], [2517.0, 2531.0], [2531.0, 2543.0], [2543.0, 2554.0], [2554.0, 2564.0], [2564.0, 2575.0], [2575.0, 2600.0], [2600.0, 2613.0], [2613.0, 2632.0], [2632.0, 2644.0], [2644.0, 2654.0], [2654.0, 2665.0], [2665.0, 2683.0], [2683.0, 2696.0], [2696.0, 2717.0], [2717.0, 2728.0], [2728.0, 2742.0], [2742.0, 2753.0], [2753.0, 2768.0], [2768.0, 2779.0], [2779.0, 2793.0], [2793.0, 2803.0], [2803.0, 2816.0], [2816.0, 2830.0], [2830.0, 2842.0], [2842.0, 2852.0], [2852.0, 2861.02]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [944, 1775, 2861]}
{"example_id": "mit002@@ocw-18_02-f07-lec10_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  So, today we are going to continue looking at critical  points, and we'll learn how to actually  decide whether a typical point is a minimum, ", "maximum, or a saddle point. So, that's the main topic for  today. So, remember yesterday,  we looked at critical points of functions of several variables. ", "And, so a critical point functions, we have two values,  x and y. That's a point where the ", "partial derivatives are both zero.  And, we've seen that there's various kinds of critical ", "points. There's local minima.  So, maybe I should show the function on this contour  plot,there is local maxima, which are like that. ", "And, there's saddle points which are neither minima nor  maxima. And, of course,  if you have a real function, then it would be more ", "complicated. It will have several critical  points. So, this example here,  well, you see on the plot that there is two maxima. ", "And, there is in the middle, between them,  a saddle point. And, actually,  you can see them on the contour plot.  On the contour plot, you see the maxima because the ", "level curves become circles that now down and shrink to the  maximum. And, you can see the saddle  point because here you have this level curve that makes a figure ", "eight. It crosses itself.  And, if you move up or down here, so along the y direction,  the values of the function will decrease. ", "Along the x direction, the values will increase.  So, you can see usually quite easily where are the critical  points just by looking either at the graph or at the contour ", "plots. So, the only thing with the  contour plots is you need to read the values to tell a  minimum from a maximum because the contour plots look the same.  Just, of course, in one case, ", "the values increase, and in another one they  decrease. So, the question -- -- is, ", "how do we decide -- -- between the various possibilities? ", "So, local minimum, local maximum,  or saddle point.  ", "So, and, in fact, why do we care?  Well, the other question is how do we find the global ", "minimum/maximum of a function? So, here what I should point ", "out, well, first of all,  to decide where the function is the largest,  in general you'll have actually to compare the values.  For example, here, if you want to know,  what is the maximum of this function? ", "Well, we have two obvious candidates.  We have this local maximum and that local maximum.  And, the question is, which one is the higher of the  two? Well, in this case, ", "actually, there is actually a tie for maximum.  But, in general, you would have to compute the  function at both points, and compare the values if you  know that it's three at one of them and four at the other. ", "Well, four wins. The other thing that you see  here is if you are looking for the minimum of this function,  well, the minimum is not going to be at any of the critical ", "points. So, where's the minimum?  Well, it looks like the minimum is actually out there on the  boundary or at infinity. So, that's another feature.  The global minimum or maximum doesn't have to be at a critical ", "point. It could also be,  somehow, on the side in some limiting situation where one  variable stops being in the allowed rang of values or goes ", "to infinity. So, we have to actually check  the boundary and the infinity behavior of our function to know ", "where, actually, the minimum and maximum will  be. So, in general,  I should point out, these should occur either at ", "the critical point or on the boundary or at infinity. ", "So, by that, I mean on the boundary of a  domain of definition that we are considering.  And so, we have to try both. OK, but so we'll get back to ", "that. For now, let's try to focus on  the question of, you know, what's the type of  the critical point? So, we'll use something that's ", "known as the second derivative test.  And, in principle, well, the idea is kind of  similar to what you do with the function of one variable, ", "namely, the function of one variable.  If the derivative is zero, then you know that you should  look at the second derivative. And, that will tell you whether  it's curving up or down whether you have a local max and the ", "local min. And, the main problem here is,  of course, we have more possible situations,  and we have several derivatives.  So, we have to think a bit harder about how we'll decide. ", "But, it will again involve the second derivative.  OK, so let's start with just an easy example that will be useful  to us because actually it will provide the basis for the ", "general method. OK, so we are first going to  consider a case where we have a function that's actually just  quadratic. So, let's say I have a ", "function, W of (x,y) that's of the form ax^2 bxy cy^2.  OK, so this guy has a critical point at the origin because if ", "you take the derivative with respect to x,  well, and if you plug x equals y equals zero,  you'll get zero, and same with respect to y. ", "You can also see, if you try to do a linear  approximation of this, well, all these guys are much  smaller than x and y when x and y are small.  So, the linear approximation, the tangent plane to the graph ", "is really just w=0. OK, so, how do we do it?  Well, yesterday we actually did an example.  It was a bit more complicated than that, but let me do it, ", "so remember, we were looking at something  that started with x^2 2xy 3y^2. And, there were other terms. ", "But, let's forget them now. And, what we did is we said,  well, we can rewrite this as (x y)^2 2y^2.  And now, this is a sum of two squares. ", "So, each of these guys has to be nonnegative.  And so, the origin will be a minimum.  Well, it turns out we can do something similar in general no ", "matter what the values of a, b, and c are.  We'll just try to first complete things to a square.  OK, so let's do that. So, in general, ", "well, let me be slightly less general, and let me assume that  a is not zero because otherwise I can't do what I'm going to do. ", "So, I'm going to write this as a times x^2 plus b over axy. ", "And then I have my cy^2. And now this looks like the  beginning of the square of something, OK,  just like what we did over there. ", "So, what is it the square of? Well, you'd start with x plus I  claim if I put b over 2a times y and I square it, ", "then see the cross term two times x times b over 2a y will  become b over axy. Of course, now I also get some ", "y squares out of this. How many y squares do I get?  Well, I get b^2 over 4a^2 times a.  So, I get b2 over 4a y^2. So, and I want, ", "in fact, c times y^2. So, the number of y^2 that I  should add is c minus b^2 over 4a. ", "OK, let's see that again. If I expand this thing,  I will get ax^2 plus a times b over 2a times 2xy. ", "That's going to be my bxy. But, I also get b^2 over 4a^2  y^2 times a. That's b^2 over 4ay^2. ", "And, that cancels out with this guy here.  And then, I will be left with cy^2.  OK, do you see it kind of? OK, if not, well, ", "try expanding this square again.  OK, maybe I'll do it just to convince you.  But, so if I expand this, I will get A times, ", "let me put that in a different color because you shouldn't  write that down. It's just to convince you again.  So, if you don't see it yet, let's expend this thing. ", "We'll get a times x^2 plus a times 2xb over 2ay. ", "Well, the two A's cancel out. We get bxy plus a times the  square of that's going to be b^2 over 4a^2 y^2 plus cy^2 minus ", "b^2 over 4ay^2. Here, the a and the a  simplifies, and now these two terms simplify and give me just ", "cy^2 in the end. OK, and that's kind of  unreadable after I've canceled everything,  but if you follow it, you see that basically I've ", "just rewritten my initial function.  OK, is that kind of OK? I mean, otherwise there's just ", "no substitute. You'll have to do it yourself,  I'm afraid. OK, so, let me continue to play  with this. So, I'm just going to put this ", "in a slightly different form just to clear the denominators.  OK, so, I will instead write this as one over 4a times the ", "big thing. So, I'm going to just put 4a^2  times x plus b over 2ay squared. OK, so far I have the same ", "thing as here. I just introduced the 4a that  cancels out, plus for the other one, I'm just clearing the  denominator. I end up with (4ac-b^2)y^2. ", "OK, so that's a lot of terms. But, what does it look like?  Well, it looks like, so we have some constant  factors, and here we have a square, and here we have a ", "square. So, basically,  we've written this as a sum of two squares, well,  a sum or a difference of two squares.  And, maybe that's what we need to figure out to know what kind ", "of point it is because, see, if you take a sum of two  squares, that you will know that each  square takes nonnegative values. And you will have, ", "the function will always take nonnegative values.  So, the origin will be a minimum.  Well, if you have a difference of two squares that typically  you'll have a saddle point because depending on whether one ", "or the other is larger, you will have a positive or a  negative quantity. OK, so I claim there's various ", "cases to look at. So, let's see.  So, in fact, I claim there will be three ", "cases. And, that's good news for us  because after all, we want to distinguish between  three possibilities. So, let's first do away with ", "the most complicated one. What if 4ac minus b^2 is  negative? Well, if it's negative, ", "then it means what I have between the brackets is,  so the first guy is obviously a positive quantity, ", "while the second one will be something negative times y2.  So, it will be a negative quantity.  OK, so one term is positive. The other is negative. ", "That tells us we actually have a saddle point.  We have, in fact, written our function as a ", "difference of two squares. OK, is that convincing?  So, if you want, what I could do is actually I  could change my coordinates, have new coordinates called u ", "equals x b over 2ay, and v, actually,  well, I could keep y, and that it would look like the  difference of squares directly. OK, so that's the first case. ", "The second case is where 4ac-b^2 = 0. ", "Well, what happens if that's zero?  Then it means that this term over there goes away.  So, what we have is just one square. ", "OK, so what that means is actually that our function  depends only on one direction of things.  In the other direction, it's going to actually be ", "degenerate. So, for example,  forget all the clutter in there.  Say I give you just the function of two variables,  w equals just x^2. So, that means it doesn't ", "depend on y at all. And, if I try to plot the  graph, it will look like, well, x is here.  So, it will depend on x in that way, but it doesn't depend on y ", "at all. So, what the graph looks like  is something like that. OK, basically it's a valley ", "whose bottom is completely flat. So, that means,  actually, we have a degenerate critical point.  It's called degenerate because there is a direction in which ", "nothing happens. And, in fact,  you have critical points everywhere along the y axis. ", "Now, whether the square that we have is x or something else,  namely, x plus b over 2a y, it doesn't matter.  I mean, it will still get this degenerate behavior. ", "But there's a direction in which nothing happens because we  just have the square of one quantity. ", "I'm sure that 300 students means 300 different ring tones,  but I'm not eager to hear all of them, thanks.  [LAUGHTER] OK, so, this is what's called a ", "degenerate critical point, and [LAUGHTER]. ", "OK, so basically we'll leave it here.  We won't actually try to figure out further what happens, ", "and the reason for that is that when you have an actual  function, a general function,  not just one that's quadratic like this,  then there will actually be other terms maybe involving ", "higher powers, maybe x^3 or y^3 or things like  that. And then, they will mess up  what happens in this valley. And, it's a situation where we ", "won't be able, actually, to tell automatically  just by looking at second derivatives what happens.  See, for example, in a function of one variable,  if you have just a function of one variable, ", "say, f of x equals x to the five,  well, if you try to decide what type of point the origin is,  you're going to take the second derivative.  It will be zero, and then you can conclude. ", "Those things depend on higher order derivatives.  So, we just won't like that case.  We just won't try to figure out what's going on here. ", "Now, the last situation is if 4ac-b^2 is positive.  So, then, that means that actually we've written things. ", "The big bracket up there is a sum of two squares.  So, that means that we've written w as one over 4a times ", "plus something squared plus something else squared,  OK? So, these guys have the same ", "sign, and that means that this term here will always be greater  than or equal to zero. And that means that we should ", "either have a maximum or minimum.  How we find out which one it is? Well, we look at the sign of a,  exactly. OK?  So, there's two sub-cases. One is if a is positive, ", "then, this quantity overall will always be nonnegative.  And that means we have a minimum, OK? ", "And, if a is negative on the other hand,  so that means that we multiply this positive quantity by a  negative number, we get something that's always ", "negative. So, zero is actually the  maximum. OK, is that clear for everyone? ", "Yes? Sorry, yeah, ", "so I said in the example w equals x^2, it doesn't depend on  y. So, the more general situation  is w equals some constant. Well, I guess it's a times (x b ", "over 2a times y)^2. So, it does depend on x and y,  but it only depends on this combination.  OK, so if I choose to move in some other perpendicular ", "direction, in the direction where this  remains constant, so maybe if I set x equals  minus b over 2a y, then this remains zero all the ", "time. So, there's a degenerate  direction in which I stay at the minimum or maximum,  or whatever it is that I have. OK, so that's why it's called  degenerate. There is a direction in which ", "nothing happens. OK, yes? ", "Yes, yeah, so that's a very good question.  So, there's going to be the second derivative test.  Why do not have derivatives yet? Well, that's because I've been  looking at this special example where we have a function like ", "this. And, so I don't actually need  to take derivatives yet. But, secretly,  that's because a, b, and c will be the second  derivatives of the function, actually, 2a, ", "b, and 2c. So now, we are going to go to  general function. And there, instead of having  these coefficients a, b, and c given to us,  we'll have to compute them as second derivatives. ", "OK, so here, I'm basically setting the stage  for what will be the actual criterion we'll use using second  derivatives. Yes? ", "So, yeah, so what you have a degenerate critical point,  it could be a degenerate minimum, or a degenerate maximum  depending on the sign of a. But, in general, ", "once you start having functions, you don't really know  what will happen anymore. It could also be a degenerate  saddle, and so on. So, we won't really be able to ", "tell. Yes?  It is possible to have a degenerate saddle point.  For example, if I gave you x^3 y^3, ", "you can convince yourself that if you take x and y to be  negative, it will be negative. If x and y are positive,  it's positive. And, it has a very degenerate  critical point at the origin. So, that's a degenerate saddle ", "point. We don't see it here because  that doesn't happen if you have only quadratic terms like that.  You need to have higher-order terms to see it happen. ", "OK. OK, so let's continue. ", "Before we continue, but see, I wanted to point out  one small thing. So, here, we have the magic  quantity, 4ac minus b^2. You've probably seen that ", "before in your life. Yet, it looks like the  quadratic formula, except that one involves  b^2-4ac. But that's really the same  thing. OK, so let's see, ", "where does the quadratic formula come in here? ", "Well, let me write things differently.  OK, so we've manipulated things, and got into a  conclusion. But, let me just do a different ", "manipulation, and write this now instead as  y^2 times a times x over y squared plus b(x over y) plus c. ", "OK, see, that's the same thing that I had before.  Well, so now this quantity here is always nonnegative. ", "What about this one? Well, of course,  this one depends on x over y. It means it depends on which  direction you're going to move away from the origin, ", "which ratio between x and y you will consider.  But, I claim there's two situations.  One is, so, let's try to reformulate things. ", "So, if a discriminate here is positive, then it means that  these have roots and these have solutions. ", "And, that means that this quantity can be both positive  and negative. This quantity takes positive ", "and negative values. One way to convince yourself is  just to, you know, plot at^2 bt c. ", "You know that there's two roots. So, it might look like this,  or might look like that depending on the sign of a. ", "But, in either case, it will take values of both  signs. So, that means that your  function will take values of both signs.  ", "The value takes both positive and negative values.  And, so that means we have a saddle point, ", "while the other situation, when b^2-4ac is negative -- --  means that this equation is quadratic never takes the value, ", "zero. So, it's always positive or  it's always negative, depending on the sign of a.  So, the other case is if b^2-4ac is negative, ", "then the quadratic doesn't have a solution.  And it could look like this or like that depending on whether a ", "is positive or a is negative. So, in particular,  that means that ax over y2 plus bx over y plus c is always ", "positive or always negative depending on the sign of a.  And then, that tells us that our function, ", "w, will be always positive or always negative.  And then we'll get a minimum or maximum.  ", "OK, we'll have a min or a max depending on which situation we  are in. OK, so that's another way to  derive the same answer. And now, you see here why the ", "discriminate plays a role. That's because it exactly tells  you whether this quadratic quantity has always the same  sign, or whether it can actually ", "cross the value, zero, when you have the root of  a quadratic. OK, so hopefully at this stage ", "you are happy with one of the two explanations,  at least. And now, you are willing to  believe, I hope, that we have basically a way of ", "deciding what type of critical point we have in the special  case of a quadratic function.  ", "OK, so, now what do we do with the general function?  Well, so in general, we want to look at second ", "derivatives. OK, so now we are getting to  the real stuff. So, how many second derivatives  do we have? That's maybe the first thing we ", "should figure out. Well, we can take the  derivative first with respect to x, and then again with respect ", "to x. OK, that gives us something we  denote by partial square f over partial x squared or fxx. ", "Then, there's another one which is fxy, which means you take the  derivative with respect to x, and then with respect to y. ", "Another thing you can do, is do first derivative respect  to y, and then with respect to x.  That would be fyx. Well, good news. ", "These are actually always equal to each other.  OK, so it's the fact that we will admit, it's actually not  very hard to check. So these are always the same. ", "We don't need to worry about which one we do.  That's one computation that we won't need to do.  We can save a bit of effort. And then, we have the last one, ", "namely, the second partial with respect to y and y fyy.  OK, so we have three of them. So, what does the second ", "derivative test say?  ", "It says, say that you have a critical point (x0,  y0) of a function of two variables, f, ", "and then let's compute the partial derivatives.  So, let's call capital A the second derivative with respect ", "to x. Let's call capital B the second  derivative with respect to x and y.  And C equals fyy at this point, OK? ", "So, these are just numbers because we first compute the  second derivative, and then we plug in the values  of x and y at the critical point.  So, these will just be numbers. And now, what we do is we look ", "at the quantity AC-B^2. I am not forgetting the four.  You will see why there isn't one. ", "So, if AC-B^2 is positive, then there's two sub-cases.  If A is positive, then it's local minimum. ", "", "The second case, so, still, if AC-B^2 is  positive, but A is negative, then it's going to be a local ", "maximum. And, if AC-B^2 is negative,  then it's a saddle point, and finally, ", "if AC-B^2 is zero, then we actually cannot  compute. We don't know whether it's ", "going to be a minimum, a maximum, or a saddle.  We know it's degenerate in some way, but we don't know what type  of point it is. OK, so that's actually what you ", "need to remember. If you are formula oriented,  that's all you need to remember about today.  But, let's try to understand why, how this comes out of what ", "we had there. OK, so, I think maybe I  actually want to keep, so maybe I want to keep this ", "middle board because it actually has,  you know, the recipe that we found before the quadratic  function. So, let me move directly over  there and try to relate our old recipe with the new. ", "", "OK, you are easily amused. OK, so first,  let's check that these two things say the same thing in the ", "special case that we are looking at.  OK, so let's verify in the special case where the function ", "was ax^2 bxy cy^2. So -- Well, what is the second ", "derivative with respect to x and x?  If I take the second derivative with respect to x and x,  so first I want to take maybe the derivative with respect to ", "x. But first, let's take the first  partial, Wx. That will be 2ax by, right? ", "So, Wxx will be, well, let's take a partial with  respect to x again. That's 2a.  Wxy, I take the partial respect to y, and we'll get b. ", "OK, now we need, also, the partial with respect  to y. So, Wy is bx 2cy. ", "In case you don't believe what I told you about the mixed  partials, Wyx, well, you can check.  And it's, again, b. So, they are, ", "indeed, the same thing. And, Wyy will be 2c.  So, if we now look at these quantities, that tells us, ", "well, big A is two little a, big B is little b,  big C is two little c. So, AC-B^2 is what we used to ", "call four little ac minus b2. OK, ooh.  [LAUGHTER] So, now you can compare the ", "cases. They are not listed in the same  order just to make it harder. So, we said first,  so the saddle case is when AC-B^2 in big letters is ", "negative, that's the same as 4ac-b2 in lower case is  negative. The case where capital AC-B2 is ", "positive, local min and local max corresponds to this one.  And, the case where we can't conclude was what used to be the ", "degenerate one. OK, so at least we don't seem  to have messed up when copying the formula.  Now, why does that work more generally than that? ", "Well, the answer that is, again, Taylor approximation.  Aww. OK, so let me just do here ", "quadratic approximation. So, quadratic approximation  tells me the following thing. It tells me,  if I have a function, f of xy, and I want to ", "understand the change in f when I change x and y a little bit.  Well, there's the first-order terms. ", "There is the linear terms that by now you should know and be  comfortable with. That's fx times the change in x. ", "And then, there's fy times the change in y.  OK, that's the starting point. But now, of course,  if x and y, sorry, if we are at the critical ", "point, then that's going to be zero at the critical point.  So, that term actually goes away, and that's also zero at ", "the critical point. So, that term also goes away.  OK, so linear approximation is really no good.  We need more terms. So, what are the next terms? ", "Well, the next terms are quadratic terms,  and so I mean, if you remember the Taylor ", "formula for a function of a single variable,  there was the derivative times x minus x0 plus one half of a  second derivative times x-x0^2. And see, this side here is ", "really Taylor approximation in one variable looking only at x.  But of course, we also have terms involving y,  and terms involving simultaneously x and y.  And, these terms are fxy times change in x times change in y ", "plus one half of fyy(y-y0)^2. There's no one half in the  middle because, in fact, you would have two ", "terms, one for xy, one for yx, but they are the  same. And then, if you want to  continue, there is actually cubic terms involving the third  derivatives, and so on, but we are not actually looking ", "at them. And so, now,  when we do this approximation, well, the type of critical  point remains the same when we replace the function by this ", "approximation. And so, we can apply the  argument that we used to deduce things in the quadratic case.  In fact, it still works in the general case using this ", "approximation formula.  ", "So -- The general case reduces to the quadratic case. ", "And now, you see actually why, well, here you see,  again, how this coefficient which we used to call little a ", "is also one half of capital A. And same here:  this coefficient is what we call capital B or little b, ", "and this coefficient here is what we called little c or one  half of capital C. And then, when you replace ", "these into the various cases that we had here,  you end up with the second derivative test.  So, what about the degenerate case? ", "Why can't we just say, well, it's going to be a  degenerate critical point? So, the reason is that this  approximation formula is reasonable only if the higher ", "order terms are negligible. OK, so in fact,  secretly, there's more terms. This is only an approximation.  There would be terms involving third derivatives, ", "and maybe even beyond that. And, so it is not to generate  case, they don't actually matter  because the shape of the function,  the shape of the graph, is actually determined by the ", "quadratic terms. But, in the degenerate case,  see, if I start with this and I add something even very,  very small along the y axis, then that can be enough to bend ", "this very slightly up or slightly down,  and turn my degenerate point in to either a minimum or a saddle  point. And, I won't be able to tell ", "until I go further in the list of derivatives.  So, in the degenerate case, what actually happens depends ", "on the higher order derivatives.  ", "So, we will need to analyze things more carefully.  Well, we're not going to bother with that in this class.  So, we'll just say, well, we cannot compute, ", "OK? I mean, you have to realize  that in real life, you have to be extremely  unlucky for this quantity to end up being exactly 0. ", "[LAUGHTER] Well, if that happens,  then what you should do is maybe try by inspection.  See if there's a good reason why the function should always  be positive or always be negative, or something.  Or, you know, plot it on a computer and see ", "what happens. But, otherwise we can't compute.  OK, so let's do an example. So, probably I should leave ", "this on so that we still have the test with us.  And, instead, OK, so I'll do my example here.  ", "OK, so just an example. Let's look at f of (x, ", "y) = x y 1/xy, where x and y are positive.  So, I'm looking only at the first quadrant.  OK, I mean, I'm doing this because I don't want the ", "denominator to become zero. So, I'm just looking at the  situation. So, let's look first for,  so, the question will be, what are the minimum and ", "maximum of this function? So, the first thing we should  do to answer this question is look for critical points, ", "OK? So, for that,  we have to compute the first derivatives.  OK, so fx is one minus one over x^2y, OK? ", "Take the derivative of one over x, that's negative one over x^2.  And, we'll want to set that equal to zero. ", "And fy is one minus one over xy^2.  And, we want to set that equal to zero. ", "So, what are the equations we have to solve?  Well, I guess x^2y equals one, I mean, if I move this guy over ", "here I get one over x^2y equals one.  That's x^2y equals one, and xy^2 equals one.  What do you get by comparing these two? ", "Well, x and y should both be, OK, so yeah,  I agree with you that one and one is a solution.  Why is it the only one? So, first, if I divide this one  by that one, I get x over y equals one. ", "So, it tells me x equals y. And then, if x equals y,  then if I put that into here, it will give me y^3 equals one, ", "which tells me y equals one, and therefore,  x equals one as well. OK, so, there's only one ", "solution. There's only one critical  point, which is going to be (1,1).  OK, so, now here's where you do a bit of work. ", "What do you think of that critical point?  OK, I see some valid votes. I see some, OK, ", "I see a lot of people answering four.  [LAUGHTER] that seems to suggest that  maybe you haven't completed the second derivative yet.  Yes, I see someone giving the correct answer. ", "I see some people not giving quite the correct answer.  I see more and more correct answers.  OK, so let's see. To figure out what type of ", "point is, we should compute the second partial derivatives.  So, fxx is, what do we get what we take the derivative of this ", "with respect to x? Two over x^3y, OK?  So, at our point, a will be 2. Fxy will be one over x^2y^2. ", "So, B will be one. And, Fyy is going to be two ", "over xy^3. So, C will be two.  And so that tells us, well, AC-B^2 is four minus one. ", "Sorry, I should probably use a different blackboard for that. ", "AC-B2 is two times two minus 1^2 is three.  It's positive. That tells us we are either a  local minimum or local maximum. And, A is positive. ", "So, it's a local minimum. And, in fact,  you can check it's the global minimum.  What about the maximum? Well, if a maximum is not ", "actually at a critical point, it's on the boundary,  or at infinity. See, so we have actually to  check what happens when x and y go to zero or to infinity. ", "Well, if that happens, if x or y goes to infinity,  then the function goes to infinity.  Also, if x or y goes to zero, then one over xy goes to  infinity. So, the maximum, ", "well, the function goes to infinity when x goes to infinity  or y goes to infinity, or x and y go to zero. ", "So, it's not at a critical point.  OK, so, in general, we have to check both the  critical points and the boundaries to decide what  happens. OK, the end. ", "Have a nice weekend. "], "vid_duration": [11.0, 17.0, 15.0, 10.0, 13.0, 13.0, 13.0, 13.0, 11.0, 10.0, 14.0, 11.0, 10.0, 14.0, 21.0, 17.0, 10.0, 11.0, 10.0, 10.0, 11.0, 12.0, 10.0, 10.0, 18.0, 11.0, 12.0, 16.0, 13.0, 12.0, 11.0, 14.0, 14.0, 12.0, 10.0, 13.0, 14.0, 10.0, 12.0, 13.0, 11.0, 13.0, 12.0, 11.0, 14.0, 12.0, 14.0, 11.0, 11.0, 11.0, 14.0, 13.0, 14.0, 10.0, 18.0, 13.0, 13.0, 10.0, 14.0, 13.0, 14.0, 18.0, 10.0, 13.0, 10.0, 12.0, 11.0, 10.0, 11.0, 11.0, 10.0, 17.0, 12.0, 12.0, 15.0, 10.0, 13.0, 11.0, 13.0, 15.0, 14.0, 10.0, 10.0, 10.0, 14.0, 16.0, 10.0, 10.0, 12.0, 10.0, 12.0, 11.0, 11.0, 11.0, 15.0, 12.0, 10.0, 13.0, 19.0, 10.0, 14.0, 11.0, 15.0, 10.0, 12.0, 11.0, 12.0, 10.0, 10.0, 11.0, 13.0, 10.0, 13.0, 10.0, 13.0, 13.0, 11.0, 11.0, 13.0, 10.0, 11.0, 15.0, 12.0, 10.0, 12.0, 13.0, 14.0, 13.0, 11.0, 16.0, 17.0, 15.0, 12.0, 10.0, 14.0, 11.0, 17.0, 11.0, 13.0, 12.0, 10.0, 32.0, 21.0, 10.0, 10.0, 15.0, 11.0, 12.0, 13.0, 13.0, 17.0, 16.0, 11.0, 14.0, 14.0, 19.0, 12.0, 13.0, 11.0, 14.0, 13.0, 11.0, 12.0, 13.0, 12.0, 11.0, 27.0, 14.0, 15.0, 10.0, 12.0, 12.0, 16.0, 11.0, 11.0, 15.0, 16.0, 12.0, 13.0, 10.0, 10.0, 16.0, 20.0, 14.0, 10.0, 11.0, 12.0, 13.0, 11.0, 11.0, 13.0, 19.0, 10.0, 12.0, 13.0, 10.0, 17.0, 14.0, 10.0, 11.0, 10.0, 11.0, 12.0, 10.0, 12.0, 11.0, 10.0, 11.0, 24.0, 14.0, 10.0, 14.0, 17.0, 47.0, 10.0, 12.0, 13.0, 17.0, 22.0, 10.0, 10.0, 11.0, 13.0, 11.0, 11.0, 10.0, 19.0, 16.0, 12.0, 12.0, 13.0, 23.0, 12.0, 14.0, 11.0, 15.0, 12.0, 10.0, 12.0, 14.0, 10.0, 2.01], "stet": [[0, 11.0], [11.0, 28.0], [28.0, 43.0], [43.0, 53.0], [53.0, 66.0], [66.0, 79.0], [79.0, 92.0], [92.0, 105.0], [105.0, 116.0], [116.0, 126.0], [126.0, 140.0], [140.0, 151.0], [151.0, 161.0], [161.0, 175.0], [175.0, 196.0], [196.0, 213.0], [213.0, 223.0], [223.0, 234.0], [234.0, 244.0], [244.0, 254.0], [254.0, 265.0], [265.0, 277.0], [277.0, 287.0], [287.0, 297.0], [297.0, 315.0], [315.0, 326.0], [326.0, 338.0], [338.0, 354.0], [354.0, 367.0], [367.0, 379.0], [379.0, 390.0], [390.0, 404.0], [404.0, 418.0], [418.0, 430.0], [430.0, 440.0], [440.0, 453.0], [453.0, 467.0], [467.0, 477.0], [477.0, 489.0], [489.0, 502.0], [502.0, 513.0], [513.0, 526.0], [526.0, 538.0], [538.0, 549.0], [549.0, 563.0], [563.0, 575.0], [575.0, 589.0], [589.0, 600.0], [600.0, 611.0], [611.0, 622.0], [622.0, 636.0], [636.0, 649.0], [649.0, 663.0], [663.0, 673.0], [673.0, 691.0], [691.0, 704.0], [704.0, 717.0], [717.0, 727.0], [727.0, 741.0], [741.0, 754.0], [754.0, 768.0], [768.0, 786.0], [786.0, 796.0], [796.0, 809.0], [809.0, 819.0], [819.0, 831.0], [831.0, 842.0], [842.0, 852.0], [852.0, 863.0], [863.0, 874.0], [874.0, 884.0], [884.0, 901.0], [901.0, 913.0], [913.0, 925.0], [925.0, 940.0], [940.0, 950.0], [950.0, 963.0], [963.0, 974.0], [974.0, 987.0], [987.0, 1002.0], [1002.0, 1016.0], [1016.0, 1026.0], [1026.0, 1036.0], [1036.0, 1046.0], [1046.0, 1060.0], [1060.0, 1076.0], [1076.0, 1086.0], [1086.0, 1096.0], [1096.0, 1108.0], [1108.0, 1118.0], [1118.0, 1130.0], [1130.0, 1141.0], [1141.0, 1152.0], [1152.0, 1163.0], [1163.0, 1178.0], [1178.0, 1190.0], [1190.0, 1200.0], [1200.0, 1213.0], [1213.0, 1232.0], [1232.0, 1242.0], [1242.0, 1256.0], [1256.0, 1267.0], [1267.0, 1282.0], [1282.0, 1292.0], [1292.0, 1304.0], [1304.0, 1315.0], [1315.0, 1327.0], [1327.0, 1337.0], [1337.0, 1347.0], [1347.0, 1358.0], [1358.0, 1371.0], [1371.0, 1381.0], [1381.0, 1394.0], [1394.0, 1404.0], [1404.0, 1417.0], [1417.0, 1430.0], [1430.0, 1441.0], [1441.0, 1452.0], [1452.0, 1465.0], [1465.0, 1475.0], [1475.0, 1486.0], [1486.0, 1501.0], [1501.0, 1513.0], [1513.0, 1523.0], [1523.0, 1535.0], [1535.0, 1548.0], [1548.0, 1562.0], [1562.0, 1575.0], [1575.0, 1586.0], [1586.0, 1602.0], [1602.0, 1619.0], [1619.0, 1634.0], [1634.0, 1646.0], [1646.0, 1656.0], [1656.0, 1670.0], [1670.0, 1681.0], [1681.0, 1698.0], [1698.0, 1709.0], [1709.0, 1722.0], [1722.0, 1734.0], [1734.0, 1744.0], [1744.0, 1776.0], [1776.0, 1797.0], [1797.0, 1807.0], [1807.0, 1817.0], [1817.0, 1832.0], [1832.0, 1843.0], [1843.0, 1855.0], [1855.0, 1868.0], [1868.0, 1881.0], [1881.0, 1898.0], [1898.0, 1914.0], [1914.0, 1925.0], [1925.0, 1939.0], [1939.0, 1953.0], [1953.0, 1972.0], [1972.0, 1984.0], [1984.0, 1997.0], [1997.0, 2008.0], [2008.0, 2022.0], [2022.0, 2035.0], [2035.0, 2046.0], [2046.0, 2058.0], [2058.0, 2071.0], [2071.0, 2083.0], [2083.0, 2094.0], [2094.0, 2121.0], [2121.0, 2135.0], [2135.0, 2150.0], [2150.0, 2160.0], [2160.0, 2172.0], [2172.0, 2184.0], [2184.0, 2200.0], [2200.0, 2211.0], [2211.0, 2222.0], [2222.0, 2237.0], [2237.0, 2253.0], [2253.0, 2265.0], [2265.0, 2278.0], [2278.0, 2288.0], [2288.0, 2298.0], [2298.0, 2314.0], [2314.0, 2334.0], [2334.0, 2348.0], [2348.0, 2358.0], [2358.0, 2369.0], [2369.0, 2381.0], [2381.0, 2394.0], [2394.0, 2405.0], [2405.0, 2416.0], [2416.0, 2429.0], [2429.0, 2448.0], [2448.0, 2458.0], [2458.0, 2470.0], [2470.0, 2483.0], [2483.0, 2493.0], [2493.0, 2510.0], [2510.0, 2524.0], [2524.0, 2534.0], [2534.0, 2545.0], [2545.0, 2555.0], [2555.0, 2566.0], [2566.0, 2578.0], [2578.0, 2588.0], [2588.0, 2600.0], [2600.0, 2611.0], [2611.0, 2621.0], [2621.0, 2632.0], [2632.0, 2656.0], [2656.0, 2670.0], [2670.0, 2680.0], [2680.0, 2694.0], [2694.0, 2711.0], [2711.0, 2758.0], [2758.0, 2768.0], [2768.0, 2780.0], [2780.0, 2793.0], [2793.0, 2810.0], [2810.0, 2832.0], [2832.0, 2842.0], [2842.0, 2852.0], [2852.0, 2863.0], [2863.0, 2876.0], [2876.0, 2887.0], [2887.0, 2898.0], [2898.0, 2908.0], [2908.0, 2927.0], [2927.0, 2943.0], [2943.0, 2955.0], [2955.0, 2967.0], [2967.0, 2980.0], [2980.0, 3003.0], [3003.0, 3015.0], [3015.0, 3029.0], [3029.0, 3040.0], [3040.0, 3055.0], [3055.0, 3067.0], [3067.0, 3077.0], [3077.0, 3089.0], [3089.0, 3103.0], [3103.0, 3113.0], [3113.0, 3115.01]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1733, 2708, 3115]}
{"example_id": "mit032@@MIT8_01F16_L37_360p", "text": [" Let's consider the motion of a wheel that's  rolling along the ground with some center of mass velocity ", "vcm.  And because the wheel is rotating  it has an angular velocity.  And you can see that that vector is directed  into the plane of the board. ", "Now, what we'd like to do is consider the kinetic energy  of this continuous body.  A little bit later on, that body has moved some distance. ", "And what we want to consider is the fact  that not only is every point in the body moving  with the center of mass speed, but there's  this additional rotational energy ", "that's associated with the fact that every point  in the center of mass reference frame  is undergoing circular motion.  So how do we describe that?  Well, we'll do that by choosing some point in the body. ", "So let's pick a point.  We'll call that mj, with mass mj.  And the velocity of this point, remember, has two components. ", "To simplify it, we'll give ourselves  a little more picture here.  Every single point in the object has the vcm. ", "But because this object is undergoing circular motion,  there is vcmj.  That's the rotational circular tangential velocity. ", "And so the vector sum of these two  is the actual velocity vj of the j-th object.  vj is equal to the center of mass velocity ", "plus the tangential rotational velocity that it has,  because it's undergoing circular motion.  And now what we'd like to do is calculate the kinetic energy ", "of this object.  Well, the kinetic energy is the sum j from 1 to n  of 1/2 mj times the velocity of this j-th particle squared, ", "which we can take as a dot product.  So we can write that as vcm plus vcmj dot vcm plus vcmj. ", " And that's just vj squared.  So when we look at these terms, it looks complicated at first. ", "But there's some nice-- there's going to be vcm dot vcm.  There's two cross terms.  They're identical.  And vcmj dot vcmj.  So let's write out those three terms. ", "We have 1/2 mj.  vcm dot vcm is vcm squared.  Now, every point in the object has the same vcm. ", "So we can pull that one out of the sum.  And now we'll take these cross terms.  So we have the sum over j from 1 to n. ", "There's two cross terms.  So the 2's are going to cancel.  And inside here, we have to remember  to keep our mass element.  That's important. ", "Now, I'm going to write it as mj vcmj vector.  Now, remember, when you dot with vcm,  every single point has the same vcm. ", "Every j-th element has the same vm,  so I can pull that vcm outside.  And finally, I have the last term,  which is the sum over j from 1 to n of 1/2 mj vcmj squared. ", "And that's just the dot product of those two terms.  And so our kinetic energy looks rather complicated,  but let's focus on this term right here.  Because recall from our video on the center of mass ", "that the definition of the center of mass reference frame,  so if you're moving in the center of mass,  that in the center of mass reference frame, the sum of mj ", "vcmj is equal to 0.  So for instance, if you're in the center of mass frame, ", "you're moving with vcm.  The only velocity is this.  And in that frame, the sum of mj vcmj is 0.  And we did a video on that one before. ", "And that's exactly what's in this term.  So this term is 0.  So this, remember, was how we defined the center  of mass reference frame. ", " And therefore, our kinetic energy consists of two pieces.  This first piece is just 1/2 the total mass times vcm squared. ", "And our second piece over here, we'll just write it out now--  1/2 sum over j mj vcmj squared. ", "Now, if you are moving with the center of mass,  then this j-th object is just undergoing circular motion.  And so we have our result that we've ", "used many times is that the velocity,  the tangential rotational velocity,  is just equal to the radius rsj--  so let's introduce that rsj-- ", "times the angular speed omega.   And when we put that into this term,  we see our kinetic energy has two pieces-- ", "m total v center of mass squared plus 1/2 j goes from 1 to n--  I didn't finish that sum there-- ", "mj rsj squared.  Now, just remember that every single point in the object  has the same angular speed, and so we can pull out ", "the omega squared in there.  And because this is a continuous body and we take the limit, ", "as we've done before, as mj goes to 0,  this quantity of mass times distance  squared is just the moment of inertia  about the center of mass of that body. ", "And in conclusion, K is 1/2 m total v center  of mass squared plus 1/2 the moment of inertia  about the center of mass times the angular speed squared. ", "Now, this is the same crucial decomposition  that we've talked about many times.  This first piece is what we call the translational kinetic  energy, because it just represents how ", "the center of mass is moving.  And the second piece is what we call  the rotational kinetic energy, because it's  a representation of just the kinetic energy of rotation. ", "For example, if you were in the center of mass frame,  there would be no translational energy,  and this would be the only kinetic energy.  ", "Let's now consider how to find the velocity  of the center of mass of a wheel that's rolling without slipping  down an inclined plane.  So let's draw a picture. ", "Here is the wheel that starts at t equals 0.  And this is an angle phi.  And at some later time t final, the wheel ", "has dropped a distance h along the incline plane.  And now let's figure out what is the velocity ", "of the center of mass of the wheel  when it gets to the bottom.  And we're now going to apply our energy arguments. ", "Now the first thing we have to realize is a very subtle point  here is that there can be friction.  And we saw that when a wheel is rolling without slipping, ", "there can be static friction at the contact  point between the wheel and the ground.  There is a gravitational force.  And a normal force. ", "Now static friction does no work because the point is always ", "instantaneously at rest and f dot ds is 0  because the object is at rest. ", "And so the ds is 0.  So our static friction does no work.  And therefore, from our energy principle  that the external work equals E final minus E initial, ", "we have no external work and so our energy is constant.  Now how do we analyze our energy?  Well, I've set things up. ", "So I'm going to choose my potential energy to be 0  when it's at the bottom.  And that our initial energy is only equal to potential energy. ", "If the wheel has a mass m, gravitational force down,  the potential energy initially is mgh.  The final energy is only kinetic energy. ", "The wheel is rolling with omega final.  Its center of mass is moving with v center of mass final.  And we just saw that the kinetic energy  has two contributions; the translational kinetic energy, ", "1/2 m--  we'll just call this final squared.  And we'll make that the final just to make it easier.  And it has the kinetic energy of rotation. ", "Now the rolling without slipping condition  is that the translational center of mass speed  is equal to the radius of the wheel,  r, times the angular speed, omega final. ", "So I can write E final as 1/2 of m plus I  cm over r squared times the final squared, where I'm just ", "replacing omega final equals v final over r.  And therefore, that the kinetic energy by the energy principle ", "tells us that E initial equals E final.  So mgh equals 1/2 times m plus I cn  over r squared v final square. ", "So we can find that v final is equal to the square root of 2  mgh divided by m plus 1/2 cm r square. ", "And that is the final speed of the center  of mass translational's velocity of the wheel  ", "We've already talked about kinetic energy  for an object that's rotating and translating.  Let's take, again, a simple object like a wheel.  Center of mass is moving, and we want  to consider this is a bunch of point-like particles, ", "th Jth particle with mass MJ, and a position vector RCMJ.  And now what we'd like to do is, what is the angular momentum ", "of this about some point P?  And we're going to do the same type of decomposition  that we've been doing right along.  Let's draw the vector RJ.  This is the vector from the point P to the object. ", "Here's the vector capital R, and there's the vector RCMJ.  And our same vector addition, R plus RCMJ. ", "j Now let's calculate the angular momentum  about the point P. Now just let's  recall two facts about the center of mass reference frame ", "that we've already used.   The first is that the sum of the velocities, the momentum ", "in the center of mass reference frame is zero,  and if you integrate this equation in just exactly  the same way, if you added up the mass times each ", "of the position vectors, that's MJ,  MJ, in the center of mass frame, that's also zero.  So we've used this when we talked about kinetic energy. ", "Now we're going to consider both of these results.  So recall that angular momentum about a point  is the sum of the vector from the point, cross-product MJ, ", "times the velocity BJ.  Now we can also use our law of addition velocities,  VJ is V plus the VCMJ, and so now ", "we're going to have to do both substitutions.  That's why this calculation is a little bit more complicated.  We have R plus RCMJ, cross MJ times capital ", "D. That is the velocity of the center of mass  with respect to the ground frame plus VCMJ.   Now we have four terms in the cross-product, ", "and this time we'll write them all out.  So the first term is the sum over J of R cross MJ capital D. ", "The second term is, we'll take this one,  and we'll cross with that one.  But because MJ is just a scalar, I'm going to pull it in front.  So that's MJ, RCMJ, and V is the same for every single particle ", "in the object.  Remember, V is just the velocity of one reference frame  with respect to the other.  So I can pull that out, cross V. And you're already noticing ", "that this term will be zero.  The next term is when I take R cross  MJVJ, V center of mass, J, summed over J, ", "that's JR cross MJ, VCMJ.  But again, remember that R is the same vector. ", "It's just from P to the center of mass,  so I didn't need to put the sum here.  I can pull R out of the sum and I have my sum like that. ", "And again, you're probably noticing that this term is zero  and our final term is RCMJ cross MJ VCMJ.  So our final term is sum R, RCMJ cross MJ VCMJ. ", " Now from these two conditions, one and two,  both of these two terms are zero. ", "And that's the power of using the center of mass reference  frame.  So LP, now let's look at the first term.  Here, R is the same for every particle, ", "V is the same for every particle,  when we're summing over the mass,  we're just getting the total mass,  so the first piece is R cross M total V. ", "And this last piece is precisely the definition of the angular  momentum of the Jth particle in the center of mass frame.  So that's the sum over J of LCMJ, ", "because RCM cross MVJ R cross, say whatever speed this  is in the center of mass frame, it could be that sum VCMJ. ", "BJ minus capital V.  This is exactly the angular momentum  of that Jth mass in the center of mass frame,  and when we total all of this up, we have R cross ", "and total V plus LCM.  Now what this first term is, if you treated the whole object ", "as a point mass, M total, moving with V, and here's our point P  and there's R, this is just what we  call the translational angular momentum. ", "It's treating the whole system as a point-like mass,  and just calculate moving with speed V,  and that's just the angular momentum.  We've called this V. ", "And this piece is the angular momentum about center of mass.  So sometimes, we can think of the angular momentum ", "as corresponding to a translational,  it has to do with the actual orbit of the object.  You could call this orbital angular momentum. ", "And this is the fact that the object is rotating.  You could think of this as the spin angular momentum  about the center of mass.  This is the same type of decomposition ", "that we saw with kinetic energy.  There was a translational component of kinetic energy  and a rotational component of kinetic energy.  This is the analogous case for angular momentum about a point ", "P. "], "vid_duration": [10.32, 12.45, 10.44, 11.61, 12.37, 11.72, 11.34, 12.07, 12.77, 11.19, 13.978, 15.095, 10.077, 13.26, 12.15, 11.94, 10.68, 12.66, 18.54, 13.14, 15.16, 11.23, 10.99, 10.24, 16.23, 12.7, 12.29, 14.93, 12.88, 10.89, 14.96, 11.46, 11.49, 16.24, 11.45, 12.54, 10.439, 11.671, 13.35, 10.109, 10.151, 13.129, 11.931, 11.04, 10.06, 14.9, 11.319, 12.231, 12.81, 13.37, 14.66, 13.25, 14.82, 11.969, 11.581, 14.7, 11.892, 12.76, 10.46, 14.16, 10.82, 11.67, 11.44, 11.77, 11.199, 16.911, 14.2, 16.48, 12.71, 13.44, 16.649, 11.191, 10.88, 12.71, 11.34, 15.99, 10.529, 11.231, 10.55, 14.88, 12.84, 14.21, 10.239, 15.271, 13.24, 12.19, 10.33, 10.13, 12.51, 0.628], "stet": [[0, 10.32], [10.32, 22.77], [22.77, 33.21], [33.21, 44.82], [44.82, 57.19], [57.19, 68.91], [68.91, 80.25], [80.25, 92.32], [92.32, 105.08999999999999], [105.08999999999999, 116.27999999999999], [116.27999999999999, 130.25799999999998], [130.25799999999998, 145.35299999999998], [145.35299999999998, 155.42999999999998], [155.42999999999998, 168.68999999999997], [168.68999999999997, 180.83999999999997], [180.83999999999997, 192.77999999999997], [192.77999999999997, 203.45999999999998], [203.45999999999998, 216.11999999999998], [216.11999999999998, 234.65999999999997], [234.65999999999997, 247.79999999999995], [247.79999999999995, 262.96], [262.96, 274.19], [274.19, 285.18], [285.18, 295.42], [295.42, 311.65000000000003], [311.65000000000003, 324.35], [324.35, 336.64000000000004], [336.64000000000004, 351.57000000000005], [351.57000000000005, 364.45000000000005], [364.45000000000005, 375.34000000000003], [375.34000000000003, 390.3], [390.3, 401.76], [401.76, 413.25], [413.25, 429.49], [429.49, 440.94], [440.94, 453.48], [453.48, 463.91900000000004], [463.91900000000004, 475.59000000000003], [475.59000000000003, 488.94000000000005], [488.94000000000005, 499.04900000000004], [499.04900000000004, 509.20000000000005], [509.20000000000005, 522.3290000000001], [522.3290000000001, 534.2600000000001], [534.2600000000001, 545.3000000000001], [545.3000000000001, 555.36], [555.36, 570.26], [570.26, 581.579], [581.579, 593.81], [593.81, 606.6199999999999], [606.6199999999999, 619.9899999999999], [619.9899999999999, 634.6499999999999], [634.6499999999999, 647.8999999999999], [647.8999999999999, 662.7199999999999], [662.7199999999999, 674.689], [674.689, 686.27], [686.27, 700.97], [700.97, 712.8620000000001], [712.8620000000001, 725.6220000000001], [725.6220000000001, 736.0820000000001], [736.0820000000001, 750.2420000000001], [750.2420000000001, 761.0620000000001], [761.0620000000001, 772.7320000000001], [772.7320000000001, 784.1720000000001], [784.1720000000001, 795.9420000000001], [795.9420000000001, 807.1410000000001], [807.1410000000001, 824.0520000000001], [824.0520000000001, 838.2520000000002], [838.2520000000002, 854.7320000000002], [854.7320000000002, 867.4420000000002], [867.4420000000002, 880.8820000000003], [880.8820000000003, 897.5310000000003], [897.5310000000003, 908.7220000000003], [908.7220000000003, 919.6020000000003], [919.6020000000003, 932.3120000000004], [932.3120000000004, 943.6520000000004], [943.6520000000004, 959.6420000000004], [959.6420000000004, 970.1710000000004], [970.1710000000004, 981.4020000000004], [981.4020000000004, 991.9520000000003], [991.9520000000003, 1006.8320000000003], [1006.8320000000003, 1019.6720000000004], [1019.6720000000004, 1033.8820000000003], [1033.8820000000003, 1044.1210000000003], [1044.1210000000003, 1059.3920000000003], [1059.3920000000003, 1072.6320000000003], [1072.6320000000003, 1084.8220000000003], [1084.8220000000003, 1095.1520000000003], [1095.1520000000003, 1105.2820000000004], [1105.2820000000004, 1117.7920000000004], [1117.7920000000004, 1118.4200000000003]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [460, 709, 1118]}
{"example_id": "mit032@@MIT8_01F16_L11_360p", "text": [" Let's examine again an object that's  undergoing circular motion.  And we'll choose our polar coordinates r hat, theta hat. ", "We'll make it cylindrical with a k hat.  Now that we've completed our kinematic description  of the motion, now let's see how we apply Newton's second law ", "to circular motion.  Well, when we write Newton's second law as F  equals ma, that-- remember, we can divide these two sides. ", "This side, the how, is a geometric description  of the motion.  And this side is the why, and this  is the dynamics of the motion. ", "And the dynamics come from analyzing the forces that  are acting on this object.  So when we're applying this mathematically  to circular motion, F equals ma-- this is a vector equation. ", "And so what we need to do is think about each component  separately.  Sometimes I can just distinguish the components  that I'm talking about over here. ", "And so we have that the radial component of the forces--  and that comes from an analysis of the dynamics,  the physics of the problem-- and this side is mass times ", "the radial component of the acceleration, ar.  Now these are very different things.  And it's by the second law that we're  equating in quantity these two components. ", "Now if we wrote that equation-- this side out in a little bit  more detail-- we'll save ourselves  a little space when we handle the tangential direction--  the forces come from analysis of free body force diagrams. ", "And over here, we know the acceleration is always inward.  And I'll choose to write this as r omega squared.  And so this will be our starting point ", "for analyzing the radial motion for an object that's  undergoing circular motion.  Now remember, there could be a tangential motion, too. ", "And in the tangential direction, the tangential forces  are equal to ma tangential.  And as we saw, this is again the second law, ", "equating two different things.  We have that we can write the tangential force as r  d squared theta dt squared. ", "And sometimes we've been writing that as r alpha z.  But this equation here is what we're  going to apply for the tangential forces. ", "If the tangential forces are 0, then there's  no angular-- there's no tangential acceleration.  We know that for circular motion,  the radial force can never be zero, ", "because this term is always non-zero  and points radially inward.  And now we'll look at a variety of examples  ", "Let's consider the motion of a car on a circular track,  and the track is frictionless.  And it's also banked.  So this is the overhead view of our circular track. ", "It has radius, r.  And here's our car moving at a constant velocity.  Now, from the side view when we want to look at that bank  turn-- let's draw a side view. ", "So here's our side view, and the car is moving with a velocity  into the plane of the figure. ", "Now this surface here is frictionless.  And what we'd like to do is find out  what speed the car can move such that it doesn't slide ", "up or down the inclined plane.  So how should we analyze that?  Well our approach will be to apply Newton's second laws.  Now what's very important to realize  is this is circular motion. ", "And for circular motion we know that the car  is accelerating towards the center of the circle.  Now from the side view, towards the center of the circle ", "is in this direction.  So the car is accelerating radially inward.  And that will guide how we choose our coordinate system.  And so we can then write our free body force diagram. ", "So let's begin with the analysis.  So we don't need to see the overhead view anymore.  So I'll just remove that, and then we can start drawing. ", "This is what we can refer to as our acceleration diagram.  And now let's draw the force diagram  on the car as our choice of system. ", "So here's our angle, phi.  Because the acceleration was inward  we're going to choose a radially outward coordinate  and a vertical coordinate, K hat up.  Notice that this is different than just a mass ", "on a fixed incline plane where we used unit  vectors up and down the inclined plane.  The reason we choose our unit vectors  like that-- to emphasize it again,  is we already know this is constrain motion. ", "It's circular motion.  Now what is the free body-- what are the forces on the car?  Well there is the normal force, the plane on the car,  and the gravitational force. ", "Now here-- whenever you're doing problems like this  remember that the trig is crucial to get  these angles right.  So that's phi, and that's phi, and that's our free body force ", "diagrams.  And now we can write down Newton's second law.  So we'll start out with our usual approach,  and we have two directions that we have to consider. ", "So in the radial direction there is an inward component  of the normal force, like that.  And that's opposite the angle, so it's pointing ", "opposite our direction.  So we have minus n sine phi.  The gravitational force is only in the negative K hat  direction.  And we know that the acceleration is inward, ", "and so there's a minus sign.  We have the mass, and the constraint for circular motion  is that that's phi squared over r.  Where r was the radius of that circle, ", "this can be thought of as the central point.  Now for the k hat direction, we have  a component of the normal force that's pointing up.  I'll just draw that. ", "That's adjacent to the angle, so we have plus and cosine phi.  And we have the gravitational force downward, minus mg. ", "And as far as the vertical direction  goes, because the car is going in a circle,  there is no acceleration up or down in the vertical direction.  Again, that's a constraint in this problem. ", "That's equal to 0.  So in this problem, this is the side that we know,  and we're trying to figure out up to the speed, v. Now, ", "how do we analyze this problem?  Well you can see that if I write my two equations,  this n sine phi equals mv squared over r.  And cosine phi equals mg. ", "We have two equations.  We have two unknowns, v and n.  Many times people just solve for n  and try to find the equation-- and then substitute in,  but you're also allowed to divide two equations, ", "and that's much easier.  The masses cancel and we get the relationship, that tan phi is v  squared over rg. ", "And so we have our result that the speed that the car can  travel on a frictionless inclined plane ", "and maintain uniform circular motion  is exactly the square root of rg tan phi.  And that's how we analyze the motion  of this car on a banked turn. ", " What we would now like to think about  is what would happen if you're traveling faster  or slower than this speed.  So suppose we have the prime bigger than the speed. ", "Now, what that means is that the car is going faster  and the new equilibrium-- if you asked what would the radius be ", "such that traveling at v primed the car  undergoes circular motion, the prime  would be equal to r prime g tan phi. ", "And so in order to go with this speed  you have to go at a greater radius.  Now what does that mean?  Well, that means that if the car is traveling at v, ", "so it's in this circular motion, and now the driver increases  the speed to v prime, the car will  start to slide up the inclined plane-- remember, ", "it's frictionless-- until it reaches  a-- as it starts slide up the inclined plane  it will get to this new radius, r prime, ", "but because a car will have a little inertia it will  overshoot that speed, that radius,  and then it will start to come back down the inclined plane,  and it will oscillate about that point. ", "It won't be sinusoidal oscillations,  but they'll be a periodic oscillation  about this new radius, r prime.  The same thing, too, if we have the double prime less than d, ", "then the double prime is equal to r double prime G tan phi.  Now remember, this double prime is not two derivatives.  I'm just using that as a notation  to indicate different speeds. ", "So if the car is going along at speed, v, and slows  down, what would happen is the new equilibrium  radius is smaller so the car slides down the inclined plane ", "until it gets to r double prime.  It turns out that it will overshoot that a little bit,  and then start to move up.  And, again, it will oscillate around this new equilibrium  length. ", "So on a frictionless inclined plane  if you go faster then this speed the car slides up.  If you go slower than this speed, the car slides down. "], "vid_duration": [14.16, 10.27, 13.25, 11.9, 15.14, 10.99, 12.04, 14.75, 13.04, 10.71, 10.18, 10.53, 10.21, 13.15, 11.04, 13.848, 13.44, 11.75, 11.26, 11.89, 12.149, 10.381, 11.67, 12.3, 10.669, 11.681, 12.78, 10.38, 11.82, 12.709, 10.351, 12.289, 12.681, 10.78, 12.539, 10.61, 11.071, 13.33, 14.3, 10.26, 10.8, 10.72, 15.65, 12.86, 10.25, 12.049, 12.161, 10.52, 12.29, 14.45, 11.36, 12.42, 10.1, 8.912], "stet": [[0, 14.16], [14.16, 24.43], [24.43, 37.68], [37.68, 49.58], [49.58, 64.72], [64.72, 75.71], [75.71, 87.75], [87.75, 102.5], [102.5, 115.53999999999999], [115.53999999999999, 126.25], [126.25, 136.43], [136.43, 146.96], [146.96, 157.17000000000002], [157.17000000000002, 170.32000000000002], [170.32000000000002, 181.36], [181.36, 195.20800000000003], [195.20800000000003, 208.64800000000002], [208.64800000000002, 220.39800000000002], [220.39800000000002, 231.65800000000002], [231.65800000000002, 243.548], [243.548, 255.697], [255.697, 266.078], [266.078, 277.748], [277.748, 290.048], [290.048, 300.717], [300.717, 312.39799999999997], [312.39799999999997, 325.17799999999994], [325.17799999999994, 335.55799999999994], [335.55799999999994, 347.37799999999993], [347.37799999999993, 360.08699999999993], [360.08699999999993, 370.43799999999993], [370.43799999999993, 382.7269999999999], [382.7269999999999, 395.4079999999999], [395.4079999999999, 406.1879999999999], [406.1879999999999, 418.72699999999986], [418.72699999999986, 429.3369999999999], [429.3369999999999, 440.4079999999999], [440.4079999999999, 453.7379999999999], [453.7379999999999, 468.0379999999999], [468.0379999999999, 478.2979999999999], [478.2979999999999, 489.0979999999999], [489.0979999999999, 499.8179999999999], [499.8179999999999, 515.468], [515.468, 528.328], [528.328, 538.578], [538.578, 550.627], [550.627, 562.7879999999999], [562.7879999999999, 573.3079999999999], [573.3079999999999, 585.5979999999998], [585.5979999999998, 600.0479999999999], [600.0479999999999, 611.4079999999999], [611.4079999999999, 623.8279999999999], [623.8279999999999, 633.9279999999999], [633.9279999999999, 642.8399999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [191, 643]}
{"example_id": "mit032@@MIT8_01F16_L09_360p", "text": [" When we analyzed how the position vector changed,  we know that the velocity for circular motion ", "is given by the radius times the rate  that the angle is changing.  And it points tangential to the circle.  So let's draw a few characteristic arrows  to show that. ", "At this point, we'll draw these pictures with d theta dt  positive.  So the velocity points like that.  It points like this.  It points like that. ", "And these are all the velocity vectors at different times.  Notice that if we make-- consider the special case ", "in which d theta dt is a constant, in that instance,  the magnitude of the velocity, v, ", "is given by r magnitude of d theta dt.  And that is also a constant.  But the velocity vector is changing direction. ", "And we know by definition that the acceleration  is the derivative of velocity.  And so what we see here is where we  have a vector that's constant in magnitude but changing ", "direction.  And we now want to calculate the derivative  in this special case.  We refer to this case as uniform circular motion.  So this special case is often called uniform circular motion. ", " OK.  How do we calculate the derivative of the velocity?  Well, recall that the velocity vector, r d theta ", "dt-- those are all constants-- because it's in the theta hat  direction, once again, will decompose theta hat  into its Cartesian components.  You see it has a minus i hat component and a plus j hat ", "component.  The i hat component is opposite the angle.  So we have minus sine theta of t i hat plus cosine  theta of t j hat. ", "So when I differentiate the velocity in time,  this piece is constant, so I'm only again applying the chain  rule to these two functions. ", "So I have r, d theta dt.  And I differentiate sine.  I get cosine with a minus sign.  So I have minus cosine theta.  I'll keep the function of t, just so that you can ", "see that-- d theta dt i hat.  Over here, the derivative of cosine  is minus sine d theta dt.  That's the chain rule-- sign of theta dt, d theta dt, j hat. ", "And now I have this common d theta dt term,  and I can pull it out.  And I'll square it.  Now whether do you think that dt is positive or negative, ", "the square is always positive, so this quantity  is always positive.  And inside I have-- I'm also going  to pull the minus sign out. ", "And I have cosine theta of t i hat plus sine theta of t j hat.  Now what we have here is the unit vector r hat t. ", "r hat has a cosine adjacent in the i hat direction and a sine  component in the H Hut direction.  So our acceleration-- ", "", " For a particle that's moving in a circle,  we found that when it's moving at a constant rate of d theta ", "dt--- and let's recall what we meant by theta of t--  and here's our particle, and we introduced our polar  coordinates r hat and theta hat, then we found that the velocity ", "was r d theta dt theta hat.  And so let's assume that this quantity is positive,  in which case the velocity is pointing in the positive theta ", "direction.  And that means that everywhere in the circle,  the velocity is tangential to the circle,  and the magnitude is a constant. ", "So for this case of uniform circular motion,  we calculated that the acceleration  was equal to minus r d theta dt quantity squared r hat, which ", "means that at every point, the acceleration vector is pointing  towards the center.   Now we can write that acceleration vector ", "as a component a of r-- r hat-- where this component is given  by r times d theta dt squared.  It it's always negative, because when you square this quantity, ", "it's always a positive quantity.  The minus sign, just to remember-- that  means that the acceleration is pointing inward.  Now how can we think about that?  Well, if we look at the velocity vector, what's happening here ", "is the velocity is not changing magnitude  but changing direction.  And if you compare two points-- and let's  just pick two arbitrary points.  So let's remove this acceleration for a moment ", "and consider two arbitrary points-- say, a time t1 and t2.  So our velocity vectors are tangent.  The length of these vectors are the same. ", "And if we move them tail to tail-- [? Vt2-- ?]  and take the difference, delta v, where ", "delta v is equal to v of t2 minus V of t1,  then we can get an understanding why the acceleration  is pointing inward, because recall ", "that acceleration by definition is  a limit as delta t goes to 0.  That means as this point approaches  that point of the change in velocity over time. ", "And so when we look at this limit  as we shrink down our time interval between t2 and t1,  then this vector will point towards the center ", "of the circle.  And that's why the direction of a  is in the minus r hat direction.  Again, let's just recall that this is the case ", "for we called uniform circular motion, which  is defined by the condition that d theta dt is a constant. ", ""], "vid_duration": [10.79, 10.3, 11.31, 11.76, 11.06, 10.61, 12.88, 14.32, 10.69, 12.85, 11.4, 12.02, 11.46, 13.98, 10.46, 11.23, 12.731, 11.339, 13.001, 15.84, 13.99, 12.0, 13.84, 14.68, 12.64, 13.64, 14.3, 13.24, 11.85, 12.549, 11.771, 12.75, 11.85, 11.31, 12.63, 1.929], "stet": [[0, 10.79], [10.79, 21.09], [21.09, 32.4], [32.4, 44.16], [44.16, 55.22], [55.22, 65.83], [65.83, 78.71], [78.71, 93.03], [93.03, 103.72], [103.72, 116.57], [116.57, 127.97], [127.97, 139.99], [139.99, 151.45000000000002], [151.45000000000002, 165.43], [165.43, 175.89000000000001], [175.89000000000001, 187.12], [187.12, 199.851], [199.851, 211.19], [211.19, 224.191], [224.191, 240.031], [240.031, 254.02100000000002], [254.02100000000002, 266.021], [266.021, 279.861], [279.861, 294.541], [294.541, 307.181], [307.181, 320.82099999999997], [320.82099999999997, 335.121], [335.121, 348.361], [348.361, 360.211], [360.211, 372.76], [372.76, 384.531], [384.531, 397.281], [397.281, 409.13100000000003], [409.13100000000003, 420.44100000000003], [420.44100000000003, 433.071], [433.071, 435.0]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [224, 435]}
{"example_id": "mit032@@MIT8_01F16_L13_360p", "text": [" OK.  Well, I like to lay in the hammock in the summer.  And this is our version of that hammock.  So we're having one rope, or perhaps two ropes, ", "hanging between two trees here.  And they span an angle theta on each side here.  And we want to know what is the tension in this rope ", "at the midpoint and here, right where  it is attached to the tree.  And here we already have the free-body diagram.  I just drew this piece of the rope here ", "that's hanging on this tree here.  And we made an imaginary cut.  We just cut it in the middle, which  means gravity is obviously acting on it. ", "It's hanging through.  But it does so with m/2 here for our half rope.  We know that there is a tension here at the midpoint, Tmid. ", "And up here, we have a tension at that end point  that goes under this angle here.  I just use an ordinary Cartesian coordinate system ", "with the i-hat direction going in the x direction and j-hat  going in the y direction.  So all we need to do is we need to apply Newton's second law  and do an F equals ma analysis to figure out ", "what these tensions are.  So let's apply Newton's second law,  the F equals ma analysis, to figure out  what the tensions are at the midpoint  and at the end over there. ", "So we have F equals ma.   And we'll have to very carefully separate the components here. ", "Let's start with i-hat.  We have Tmid minus Tend, but of course we ", "have only the projection of Tend,  so this is Tend sine theta.  And since this rope is just hanging there,  the acceleration is 0. ", "In the j-hat direction, we have minus m/2 g and then plus Tend. ", "And here we have the cos theta component, and that is also 0.  So we see from here pretty much immediately ", "that Tend equals m/2 g over cos theta. ", "And we can stick this one here into the i-hat equation.  So we'll get Tmid equals m/2 cos theta g sine theta. ", "And that's nothing else but mg/2 over 2 tangent theta.  ", "We've seen previously that if a rope is under tension  and we approximate the rope is massless  that the tension is then uniform everywhere along the rope,  even if the rope is accelerated. ", "However, if the rope has nonzero mass,  then its tension will vary along its length.  We can see that by looking at this example. ", "Imagine we have a massive rope of length l suspended ", "from a ceiling.   Now, it's easy to see that, at the top of the rope, ", "a little element of rope right at the top  has to support the entire weight of the entire rope.  So if I were to examine just a little piece at the top here, ", "the weight of the entire rope would be acting downwards.  And for the rope to remain stationary,  there has to be a tension upward.  I'll call this t-top, because this is at the top of the rope. ", "And so we see immediately from that  that at the top of the rope, the tension  is just equal to mg, where m is the mass of the entire rope.  Similarly, if we asked what the tension is ", "at the bottom of the rope, an element right  at the bottom of the rope isn't supporting any weight,  because there is no weight below it.  And so at the bottom, the tension ", "is 0, because there is no weight pulling  on the bottom of the rope.  So the tension is going to vary from mg at the top down to 0  at the bottom. ", "And if we wanted to work out at some distance  from the ceiling-- let's call it x--  at some position x-- say here, what the tension is ", "at that point-- one way of figuring that out would just  be imagine we cut the rope at this point  and then asked what tension force  would be necessary to support this bottom part of the rope. ", " This length is l minus x, so the mass  of that fraction of the rope is l minus x over l. ", "And the mass of that fraction of the rope  is that fraction times m.  And so the tension at this point, t at x, ", "is equal to the weight of the length of rope  below that point.  So that's this mass times g.  And I can rewrite that as 1 minus x over l times mg. ", "And this gives me mg if I put in x equals 0,  and it gives me 0 if I put in x equals l.  So that's one way of figuring this out.  I'd like to use this same example, though, ", "to introduce another, more elegant way of analyzing  what the tension as a function of a position on this rope.  The advantage-- so this is going to be a little bit more ", "complicated, but it's a much more powerful method,  and it's one that we can generally  use for any continuous distribution of mass as opposed  to a point mass. ", "So let's consider the same example again of a hanging mass  of rope of length l and mass m.  ", "Here's the length l and the mass m.  And the approach we're going to use  is called differential analysis.  It's a technique from calculus, and it's  applicable to any continuous distribution of mass. ", "What we're going to do is imagine  our continuous distribution of mass  is made up of a whole bunch of little pieces, little elements,  examine f equals ma acting on a single element, ", "and then generalize to the entire mass.  So let's do that here.  What we'll do is we'll examine a piece at some position x. ", "So I'm measuring x from the top.  And let's say I define a little element here,  which is that of position x and which has an extent delta x. ", "So this thickness is delta x, and we'll  call the mass of that little piece, that little element,  delta m.  Now, one thing I want to point out to begin with ", "is that we want to pick an element that's somewhere  in the middle of the distribution,  not at one end or the other.  The endpoints are special cases, so we  want to pick a general case. ", "So choose some x somewhere in the middle of our distribution  which has a finite extent.  That extent is delta x.  In this case, we'll assume that that piece delta x  has a mass delta m.  So let's blow that up here and analyze it. ", "So here is my element.   And it's going to have-- let's analyze what  the forces acting on it are. ", "So there's gravity acting downwards,  which will be delta m times g.  There is a tension acting upwards, ", "exerted by the rope above it.   I'll write that as t of x, because it's at the location x. ", "There's also a tension exerted in the downward direction  by the remainder of the rope below the mass element.   And I'll call that t of x plus delta x. ", "We expect the tension to vary along the rope.  And because this element does have a finite extent,  the tension at the bottom is going  to be slightly different than the tension at the top-  so t of x upwards, t of x plus delta x downwards, ", "and then the weight downwards.  So let's now-- that's our free body diagram.  Let's write down Newton's second law,  f equals ma for that mass element. ", "So in the positive direction, which is downward,  we have t of x plus delta x plus delta mg. ", "And then in the upward or minus direction,  we have minus t of x.  So those are the combined forces.  Now, this rope is suspended.  It's not moving. ", "And so mass object acceleration is just 0.  I'm going to rearrange that.  I can write that as t of x plus delta x minus t of x ", "is equal to minus delta m times g.  And by the way, let me remind you--  if this were a massless rope, then delta n would be 0. ", "And so the right-hand side would be 0,  and the tension would be uniform.  We'd have the same tension above and below.  But because the rope does have mass,  and in particular, this element has a nonzero mass delta m, ", "there is a difference in the tensions.  OK.  Now, our delta m can be represented in terms  of what this length is.  Notice that that mass, delta m-- so note that delta m ", "is just a fraction of the total mass  that's in that particular mass element.  Well, the fraction of the total rope  is just the length of this element, delta x, ", "divided by the length of the entire rope, which is l.  So that's the fraction, and I multiply that  by the total mass.  So that is my mass delta m in terms of the length. ", "So now I can rewrite this equation  as t of x plus delta x minus t of x ", "is equal to minus delta x m over l times g. ", "Now, I'm going to rearrange this by dividing  both sides by delta x.  I'll do that over here.  ", "So we have t of x plus delta x minus t  of x divided by delta x is equal to minus mg over l. ", "This tells us how the tension is varying  over this small but finite-sized mass element, delta x.  Now I'd like to examine what happens ", "if I go to the limit of a small-massed element--  the limit as delta x goes to 0, or in other words,  the limit of an infinitesimally small mass element. ", "So I'm going to take the limit of this equation  as delta x approaches 0.  Now, the left-hand side of this equation should look familiar. ", "It's just an expression for the derivative of the tension  t as a function of position.  So I can write that as dt dx, and that's ", "equal to minus mg over l.  This is an example of a differential equation,  or an equation that involves a derivative. ", "This particular differential equation  can be solved very simply by a technique called  the separation of variables, where I just  take each part of the integral-- the dt and the dx--  and put it on different sides of the equation ", "and then integrate both sides of the equation  to find the solution.  So in this case, I'll multiply both sides of the equation  by dx.  So I get dt on the left-hand side ", "is equal to minus mg over l dx.  And now I want to integrate both sides.  So I'll integrate this side. ", "And remember, mg over l is a constant,  so I can keep it outside the integral.  And I'll integrate this side.  I'm going to do a definite integral  over the continuous distribution that I'm studying. ", "So on the right-hand side, I'm going to start at x equals 0  and go to my position of interest, which is x.  And to avoid confusion, I'm going ", "to call the integration viable dx prime.  This is a dummy variable.  So x prime here represents all the values of position, ", "ranging from my first endpoint 0 up to my other endpoint x.  So x here represents a particular position,  whereas dx prime is a placeholder ", "for all the positions between the two  endpoints in my infinite sum, which is an integral.  So that's on the right-hand side.  On the left-hand side, I'm integrating the tension t, ", "with respect to the tension t.  My limits need to correspond to the limits  on the right-hand side integral.  So on the right-hand side, my lower limit is at x equals 0. ", "So on the left-hand side, I want to have  my lower limit be the tension at that position x equals 0.  So that's t of 0. ", "And then the upper limit of the integral  is the tension at the upper limit of the position integral,  so that's t of x.  And again, to avoid confusion, I'm ", "actually going to call the integration variable dt prime.  This is a dummy variable.  It's a placeholder for all the values  of tension from the tension at x equals 0  to the tension at my position of interest x. ", "And so this integral now tells me  how the tension is varying in a continuous fashion  along this continuous mass distribution.  So now I can evaluate both integrals. ", "On this side, I have the integral  of a constant with respect to the tension.  And so that's just going to give me t of x minus t of 0, ", "and that's equal to minus mg over l.  The interval of dx prime from 0 to x is just x. ", "So this tells me how the tension changes from the endpoint  to some arbitrary position x.  If I want to actually solve for t of x, ", "I need to specify what the tension is at the endpoint.  But we know what the tension is at the endpoint.  We found that earlier.  We solved from the simple argument that at the endpoint, ", "the tension here is just equal to the weight  of the entire length of rope below that point.  ", "So we know that t at x equals 0 is just equal to mg.  And therefore, the tension at position  x is just-- if I bring [INAUDIBLE] of 0 to this side ", "is just mg minus mg x over l. ", "And so I can just write that as mg times 1 minus x over l.  So that tells me what the tension ", "is as a function of position.  Note again that if I put in x equals 0, I just get mg.  If I put in x equals l, I get the tension is 0. ", "And for any point in between, we see that the tension varies  smoothly between mg and 0.  This is exactly the same result we found earlier  by just cutting the rope at x and asking ", "how do we balance the weight of the remaining  rope below that point.  But the advantage of this technique  which is a little bit more complicated,  is that it's a very powerful technique ", "applicable to any continuous distribution of mass.  So in this specific problem, if instead of the uniform density  rope that we had here, imagine we had a clumpy rope where ", "the mass of the rope wasn't distributed smoothly,  but there were clumps, little parts of the rope that  were heavier than others, and so the density varied ", "with position along the rope.  In that case, we would represent that when  we were writing what our mass element delta m is.  Delta m, instead of just being delta x over l times m, ", "where here, delta x over l was the uniform density  of the rope, we would have to put  in some position-dependent density.  So delta n would depend upon position. ", "And then when I did this integral, instead of  a constant out front with my integral of dx prime,  I would have some thing that was a function of x,  and I'd get a different value for the integral. ", "But the technique would still work.  So this differential analysis technique  is applicable to any system where we have a continuous mass  distribution. ", "And we're going to actually use this technique over and over  again in this course.  We'll see it a number of times.  This is just the first instance we're using it.  We wanted to introduce you carefully to the approach. ", " In many problems throughout this class,  we will find it useful to consider  how the mass of an object is distributed  throughout the object.  To do this, we will define a small piece of that object ", "and then consider the mass that's contained  within that small piece.  For an object in one dimension, the differential element  of length is delta l.  And that length contains a certain amount ", "of mass, delta m.  We could also have a linear object  in the shape of an arc or just an arbitrary path.  ", "For an object in two dimensions, we  have an area element, delta A, that contains a mass delta m.  For our volume, we have a volume element, delta V, ", "which contains a certain amount of mass.  In this case, we can write the volume element delta  V as the area A times this delta x. ", " We want to relate the small length, area, or volume element  to delta m, the amount of mass contained within.  In one dimension, this relation is ", "called the linear density, lambda,  which is delta m over delta l.  For a uniform rod of length L and total mass M, ", "lambda is equal to M over L. In two dimensions,  the area element contains an amount of mass sigma times  delta A, where sigma has units of mass over area. ", "Finally, in three dimensions, the volume density rho  connects the small mass, delta m, to the volume, delta V.  ", "So let me summarize what the steps that we've taken  are to do this differential analysis.  So when you're trying to analyze a continuous mass distribution,  the first step is to pick some arbitrary mass element, ", "a small but finite size mass element  somewhere in the middle of the mass distribution.  You don't want to pick one of the endpoints,  because the endpoints are special.  You want to pick an arbitrary point somewhere in the middle ", "and then pick a small mass element at that point, so  a small but finite size.  Analyze the forces acting on that mass element.  So write down Newton's second law, the equation of motion, ", "for that mass element.  That will give you what the forces are on that element.  Then go to the limit of an infinitesimally small element. ", "That will give you a differential equation.  You can then separate the differential equation  and integrate both sides to solve the differential  equation.  And then finally, you can apply a boundary condition, ", "something you know about one or the other of the endpoints.  And that will allow you to solve for the function of interest  at any point along your distribution.  "], "vid_duration": [13.24, 12.2, 12.53, 10.55, 12.225, 12.385, 13.68, 12.09, 12.66, 13.6, 10.73, 13.21, 12.02, 19.05, 21.86, 11.263, 10.43, 10.27, 10.45, 10.4, 12.95, 12.35, 11.51, 14.49, 10.42, 10.14, 12.593, 13.757, 10.97, 17.76, 10.929, 10.541, 10.82, 12.756, 11.92, 12.424, 14.55, 16.75, 10.85, 10.09, 12.35, 10.29, 10.64, 12.02, 13.52, 13.2, 10.95, 12.951, 10.129, 12.289, 12.738, 11.143, 17.54, 13.85, 10.68, 11.37, 12.8, 10.29, 17.26, 11.23, 10.37, 11.39, 11.1, 10.199, 11.771, 10.11, 12.24, 10.88, 10.17, 10.06, 10.39, 10.3, 10.16, 10.24, 10.18, 13.69, 11.48, 12.51, 11.08, 12.31, 10.72, 11.04, 12.8, 10.25, 12.47, 10.85, 13.13, 11.13, 11.94, 11.53, 10.13, 10.319, 10.221, 10.11, 10.881, 11.59, 11.63, 12.25, 11.95, 11.539, 11.27, 10.77, 14.02, 10.823, 13.26, 12.05, 11.06, 11.75, 13.27, 9.774], "stet": [[0, 13.24], [13.24, 25.439999999999998], [25.439999999999998, 37.97], [37.97, 48.519999999999996], [48.519999999999996, 60.745], [60.745, 73.13], [73.13, 86.81], [86.81, 98.9], [98.9, 111.56], [111.56, 125.16], [125.16, 135.89], [135.89, 149.1], [149.1, 161.12], [161.12, 180.17000000000002], [180.17000000000002, 202.03000000000003], [202.03000000000003, 213.29300000000003], [213.29300000000003, 223.72300000000004], [223.72300000000004, 233.99300000000005], [233.99300000000005, 244.44300000000004], [244.44300000000004, 254.84300000000005], [254.84300000000005, 267.79300000000006], [267.79300000000006, 280.1430000000001], [280.1430000000001, 291.6530000000001], [291.6530000000001, 306.1430000000001], [306.1430000000001, 316.5630000000001], [316.5630000000001, 326.7030000000001], [326.7030000000001, 339.2960000000001], [339.2960000000001, 353.0530000000001], [353.0530000000001, 364.02300000000014], [364.02300000000014, 381.78300000000013], [381.78300000000013, 392.7120000000001], [392.7120000000001, 403.2530000000001], [403.2530000000001, 414.0730000000001], [414.0730000000001, 426.82900000000006], [426.82900000000006, 438.7490000000001], [438.7490000000001, 451.17300000000006], [451.17300000000006, 465.72300000000007], [465.72300000000007, 482.47300000000007], [482.47300000000007, 493.3230000000001], [493.3230000000001, 503.41300000000007], [503.41300000000007, 515.763], [515.763, 526.053], [526.053, 536.693], [536.693, 548.713], [548.713, 562.233], [562.233, 575.433], [575.433, 586.383], [586.383, 599.3340000000001], [599.3340000000001, 609.4630000000001], [609.4630000000001, 621.7520000000001], [621.7520000000001, 634.49], [634.49, 645.633], [645.633, 663.173], [663.173, 677.023], [677.023, 687.703], [687.703, 699.073], [699.073, 711.8729999999999], [711.8729999999999, 722.1629999999999], [722.1629999999999, 739.4229999999999], [739.4229999999999, 750.6529999999999], [750.6529999999999, 761.0229999999999], [761.0229999999999, 772.4129999999999], [772.4129999999999, 783.5129999999999], [783.5129999999999, 793.7119999999999], [793.7119999999999, 805.4829999999998], [805.4829999999998, 815.5929999999998], [815.5929999999998, 827.8329999999999], [827.8329999999999, 838.7129999999999], [838.7129999999999, 848.8829999999998], [848.8829999999998, 858.9429999999998], [858.9429999999998, 869.3329999999997], [869.3329999999997, 879.6329999999997], [879.6329999999997, 889.7929999999997], [889.7929999999997, 900.0329999999997], [900.0329999999997, 910.2129999999996], [910.2129999999996, 923.9029999999997], [923.9029999999997, 935.3829999999997], [935.3829999999997, 947.8929999999997], [947.8929999999997, 958.9729999999997], [958.9729999999997, 971.2829999999997], [971.2829999999997, 982.0029999999997], [982.0029999999997, 993.0429999999997], [993.0429999999997, 1005.8429999999996], [1005.8429999999996, 1016.0929999999996], [1016.0929999999996, 1028.5629999999996], [1028.5629999999996, 1039.4129999999996], [1039.4129999999996, 1052.5429999999997], [1052.5429999999997, 1063.6729999999998], [1063.6729999999998, 1075.6129999999998], [1075.6129999999998, 1087.1429999999998], [1087.1429999999998, 1097.273], [1097.273, 1107.5919999999999], [1107.5919999999999, 1117.8129999999999], [1117.8129999999999, 1127.9229999999998], [1127.9229999999998, 1138.8039999999999], [1138.8039999999999, 1150.3939999999998], [1150.3939999999998, 1162.024], [1162.024, 1174.274], [1174.274, 1186.224], [1186.224, 1197.763], [1197.763, 1209.033], [1209.033, 1219.8029999999999], [1219.8029999999999, 1233.8229999999999], [1233.8229999999999, 1244.646], [1244.646, 1257.906], [1257.906, 1269.956], [1269.956, 1281.0159999999998], [1281.0159999999998, 1292.7659999999998], [1292.7659999999998, 1306.0359999999998], [1306.0359999999998, 1315.8099999999997]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [210, 1139, 1198, 1244, 1316]}
{"example_id": "mit032@@MIT8_01F16_L28_360p", "text": [" So far in the course, we've been studying the motion  of collections of particles.  We would know like to consider rigid bodies.  Now, rigid bodies can be translated in space ", "as I move it like this.  Or we can rotate this rigid body about some point.  I can rotate it about the end point. ", "I can rotate it about a point which  we call the center of mass.  So I can rotate it about the center of mass.  I can take the rigid body and I can ", "rotate it about the center of mass,  and also translate it in space.  So there's many types of motions that we  can do with rigid bodies.  Sometimes the motions are quite complicated. ", "If I spin it like that, it is a very more complicated motion.  You can see that it's rotating about this axis.  So what we'd like to do now is analyze ", "how to think about the motion of rigid bodies.  And what we'd like to do is idealize our rigid body.  So even though we looked at a rod here, ", "let's just draw some extended idealized rigid body.  And let's identify two points in that rigid body--  the j-th point and the k-th point. ", "And we'll think of our rigid body  as a bunch of point-like particles mj and mk.  And the important thing that defines a rigid body ", "is the condition that the distance-- and we'll  draw a vector from the k-th particle to the j-th particle. ", "So we'll draw that as rjk.   And actually, I'd like to write it from the k-th particle  to the j-th particle rjk. ", "And our condition is that the magnitude of this vector, which  I'll denote as rjk is constant for all points j and k. ", "Now, what does that mean?  That means the distance between any two  points in the rigid body stays fixed no matter  how the rigid body is moving and no matter what ", "two points I choose.  The distance between any two points is fixed.  So we'll rewrite this as the distance between any two points ", "is fixed.  So that doesn't change.  And that's what we call the rigid body condition.  ", "So we're now beginning to make our complete study  of rigid body motions about fixed axis.  Let's consider something like a bicycle wheel.  Here's the center of mass of the wheel. ", "And our bicycle wheel-- the center of mass  has some velocity.  And here's ground.  And the reference frame is the ground frame. ", "Now if the bicycle wheel is rolling,  then there will be some type of rotational motion of the wheel.  So you can imagine a point on the rim is rotating. ", "And so what we have here is a angular velocity  of this bicycle, which we'll write  like this, our vector omega. ", "And we'll use our right hand rule  to establish that direction for omega.  And now in this reference frame, we  have translational motion of the center of mass. ", "And we have rotational motion around the center of mass.  If we go to the center of mass reference frame-- ", "so if you want just a little cartoon to show that,  here's your observer.  And your observer is moving with VCM.  And so in that frame, the center of mass is at rest, ", "and the only thing we have is rotation  about the center of mass. ", "And so in this picture, our motivation  will be that the total external force causes the center of mass ", "to accelerate.  And that's how we can figure out the center of mass motion.  And in this picture, we no longer  have to consider translational motion.  And what we'll study and learn to analyze ", "is just pure rotation about the center of mass--  so torque will produce angular acceleration.  We can talk about the rotational energy ", "about the center of mass.  And so we'll begin our analysis of rotational motion  of translation and rotation by focusing our interest ", "in the center of mass frame-- so we've just  isolated the rotational motion.   Suppose we have a rigid body, and it's ", "rotating about a fixed axis, and we  know that the angular acceleration, alpha, is given.  Now, it may be a function of time.  And we'd like to find from the angular velocity ", "and how much angle has rotated in some time interval.  So the first thing we have to do is  choose a point in the rigid body,  and introduce a coordinate system. ", "Here we have our angle theta.  And with this point, we have our r hat and our theta hat  direction.  And recall that by the right-hand rule,  the k hat is going out of the plane of the figure. ", "And so we have our coordinate system.  And we wrote alpha as the second derivative of theta  with respect to time k hat.  Now our goal is to find omega, which ", "we'll right as the first derivative of d theta dt k hat,  and also to find theta as a function of time. ", "Now recall that our notation was that alpha z was the omega  z dt equals d squared theta dt squared. ", "And in this notation, omega z was equal to d theta dt.  Now what we're going to do is we're  going to integrate alpha, just like we  did in simple circular motion kinematics ", "for point-like objects.  And so what we have here is that for some time interval,  omega z at time t minus omega z0 is the integral of t ", "prime equals 0 to t of alpha z, which  is our component of the angular acceleration.  We have an integration variable, dt prime. ", "And recall that that implies that omega z t can  have some initial value at time t  equals 0 plus this integral relationship, ", "which is what we want to figure out by direct integration.  Now, this only works when alpha z is some function of time. ", "In order to get the angle, theta of t, we integrate again,  where we have theta t0 is the integral from t  prime equal 0 to t prime equals t of this function omega z. ", "Again, we have some integration variable, t prime, dt prime.  And so we see that theta t can have  some initial value plus this integral relationship, ", "t prime equals t of omega z t prime dt prime.  And this is how we can figure out  how the point p has a component of angular velocity, ", "and what angle the point p sweeps out  in some time interval t. "], "vid_duration": [15.22, 11.2, 10.55, 10.38, 11.82, 10.35, 12.36, 11.61, 10.86, 12.93, 18.28, 12.5, 20.02, 11.124, 10.731, 12.61, 10.45, 10.68, 13.01, 13.05, 16.1, 12.94, 10.5, 12.03, 11.489, 11.49, 10.917, 11.881, 10.559, 15.42, 14.911, 10.48, 11.039, 13.491, 12.36, 11.94, 10.979, 10.081, 14.339, 14.011, 15.349, 5.508], "stet": [[0, 15.22], [15.22, 26.42], [26.42, 36.97], [36.97, 47.35], [47.35, 59.17], [59.17, 69.52], [69.52, 81.88], [81.88, 93.49], [93.49, 104.35], [104.35, 117.28], [117.28, 135.56], [135.56, 148.06], [148.06, 168.08], [168.08, 179.204], [179.204, 189.935], [189.935, 202.54500000000002], [202.54500000000002, 212.995], [212.995, 223.675], [223.675, 236.685], [236.685, 249.735], [249.735, 265.83500000000004], [265.83500000000004, 278.77500000000003], [278.77500000000003, 289.27500000000003], [289.27500000000003, 301.305], [301.305, 312.794], [312.794, 324.284], [324.284, 335.20099999999996], [335.20099999999996, 347.082], [347.082, 357.641], [357.641, 373.06100000000004], [373.06100000000004, 387.97200000000004], [387.97200000000004, 398.45200000000006], [398.45200000000006, 409.49100000000004], [409.49100000000004, 422.982], [422.982, 435.34200000000004], [435.34200000000004, 447.28200000000004], [447.28200000000004, 458.261], [458.261, 468.34200000000004], [468.34200000000004, 482.68100000000004], [482.68100000000004, 496.69200000000006], [496.69200000000006, 512.041], [512.041, 517.5490000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [175, 328, 517]}
{"example_id": "mit032@@MIT8_01F16_L01_360p", "text": [" We will now like to begin our analysis of motion.  And we'll start with one dimensional motion.  Let's just consider a person running along a road. ", "And so here's our runner, and here's our road.  And what we want to do is be able to describe  the position, the velocity, the acceleration of this runner. ", "In order to do that, we need our first mathematical tool,  which is a coordinate system.  What is a coordinate system?  Well, the first thing that we want to choose is an origin. ", "We can pick the origin anywhere we want.  That's a degree of freedom.  So let's choose a point along our road as our origin.  The next thing to do is to choose an axis. ", "Well, the road is naturally defining  an axis for our problem.  And so we'll call this the x-axis.  Now, along with that axis, we want  to divide that up into some type of units ", "so we might divide our axis like this.  And what's important here is to introduce  a positive coordinate direction. ", "And so the way I'll do that, is I'll call this the plus x,  and on this side of the origin x is negative.  Now, the third most important thing ", "is that we're going to talk about vectors and physics.  So we want a choice of unit vector.  Now, because it's only one dimensional motion,  we only need one unit vector. ", "So what that means is a choice of unit vector at every point.  Let's just consider a point here, P1.  So our unit vector I'll call it i hat 1. ", "Now, let's pick another point here.  We'll call this the point P2.  And over here we'll choose a unit vector, i hat 2.  So every single point in space has a unit vector. ", "Now, what's unique about this one  dimensional linear Cartesian coordinate  system is the following, these unit vectors  have the same magnitude-- a unit vector by definition ", "has magnitude 1-- and they're pointing in the same direction.  So if two vectors have the same magnitude  and point in the same direction, they are equal. ", "So what makes this coordinate system unique,  this Cartesian coordinate system,  that every single point, no matter where we are,  the unit vectors point in the positive direction ", "because they have the same magnitude and direction.  All of these unit vectors are equal.  And we call that i hat.  So symbolically, we may draw a picture ", "and indicate our unit vector in the positive x direction.  And this is our coordinate system.  And we can next begin to describe  the position and the velocity of our object ", "as it's moving along this x direction.   Now that we've chosen a coordinate system  for our runner going along the road,  we now want to describe the position function ", "of our coordinate system with respect  to our choice of origin.  Now, the runner is a non-rigid object.  Legs and arms are moving back and forth.  So let's just imagine that there is some fixed  point in the runner at the center, ", "and let's give a vector.  So we're going to draw a vector from above our origin  to that point, and this is what we'll refer to  as our position function. ", "Now, remember, every point here has an x-coordinate,  so we can now introduce our position function,  which we'll call x of t, which is the coordinate location ", "with respect to the origin.  This is a function that will change in time.  And our position vector is r(t) equals the position function  x(t). ", "Now, remember, this is a vector.  The position function is just a quantity  that's describing the location of this point with respect  to the origin, but the unit vector ", "is how we describe this as a vector, and so we write i hat.  Now, x(t) is what we call the component of the position  vector. ", "Remember, a vector has a component and a direction,  and the component is the position function.  And that component x(t) can be positive, ", "as you see in this particular case.  x(t) can also be zero.  That's if you're located at the origin.  And if our runner is on the other side of the origin, ", "x(t) can be negative.  So the component of the position vector  can be positive, zero, or negative,  and the direction of the position vector ", "is the sine of the component times i hat.  If the component is negative, then we have a negative i hat.  The position vector is pointing backwards in the minus x  direction. ", "And if x(t) is positive, positive i hat position  vector as shown in this particular case  is in the positive i hat direction.  So that's our first vector, the position vector, ", "in one-dimensional motion.   Now that we've described the position vector of the runner,  let's try to describe what happens in time ", "as a runner moves along our road.  Suppose at a later time our runner has gone down the road  just a little bit.  And so the runner has moved a little bit. ", "Remember, at time t, we described the position vector  r(t) was equal to the coordinate function ", "x as a function of time i hat.  And this distance here was our x(t).  Now, our position vector a little bit later. ", "So here we are at time t plus delta t.  The runner has moved a little bit.  And we'll now describe the position vector--  because I don't want to overlap it-- ", "that center point is up here.  It's going to point in this direction.  And this is what we call r(t) plus delta t.  In that vector, r(t) plus delta t, ", "the coordinate function is no longer at time t  but t plus delta t i hat.  And we would now like to describe  the displacement vector. ", "So our next step is to describe the displacement vector  for the interval t to t plus delta t. ", "And that displacement vector is defined-- we use the symbol  delta r, and what we mean is the vector r(t)  plus delta t minus the vector r(t). ", "Now, what that vector corresponds to  is the vector right here.  This is our delta r.  And if we now use our two definitions here, ", "then this becomes x(t) plus delta t minus x(t) i hat. ", "And this quantity here we refer to as the component  of the displacement vector.  So delta x is the component of the displacement vector. ", " And as before, the component can be positive,  which would correspond to the person moving ", "a positive component, positive i hat direction,  in the positive x direction as shown in this figure.  If the displacement of vector is zero,  the person could have run forward ", "and come back and at time t plus delta t  be in exactly the same spot as time t.  The displacement vector is zero in that case. ", "The displacement vector could have  a component that's negative.  And what negative means is at the end of this interval-- t  plus delta t-- that the person is to the left of the runner. ", "And so this quantity would be negative.  And so this is our crucial displacement vector that  describes only the difference in positions between the person, ", "between time t plus delta t, and time t.   Now that we've described the displacement of our object-- ", "remember that our displacement vector delta r in this time  interval was x(t) plus t minus x(t) i hat, ", "which we denoted as delta x i hat.  Now, let's just remind ourselves that this distance here, that's  delta x, and this whole distance from here ", "over to there-- that's what we mean by x(t) plus delta t.  And now what we'd like to do is describe  what we call average velocity.  ", "And our average velocity depends on our time intervals.  So this is for the time interval t ", "to t plus delta t while the person has  displaced a certain amount of vector delta r.  And our definition for v average--  it's a vector quantity, so we'll write v average-- ", "will use three bars to indicate a definition.  It is the displacement during a time interval delta t. ", "So, as a vector, we have delta x over delta t i hat.  And this component here is what we call the component ", "of the average velocity.  So this is the component of the average velocity.  ", "And, again as before, this component  can be positive, zero, or negative depending  on the sine of delta x.  And the key point here is that average velocity ", "depends on whatever time interval you're referring to.  So that's our definition of average velocity.  And now what we want to do is consider  what happens in the limit as delta t becomes smaller ", "and smaller and smaller.  And that will enable us to introduce our concept  of instantaneous velocity.   We've now described what we call the average velocity for a time ", "interval between when the runner started at time t  to a later time at t plus delta t.  And we described that as the component  of the displacement vector divided by the time interval ", "times a unit vector, i hat.  Now what we'd like to ask is a separate question.  So our question now is, what do we  mean by the velocity at some specific time, T1? ", "Now in order to understand that, let's just  make a plot of the position function.  So remember we called the component of the position  function x of t. ", "So we're going to plot the component of the position  function with respect to time.  Now let's just say that the runner started  at the origin of time equal 0. ", "So I can make some type of arbitrary plot of that position  function.  And let's indicate in particular, the time T1. ", "So what this represents is x of T1.  And so first I'd like to consider the interval T1  and T1 plus some later time, delta T. ", "So let's make this T1 plus delta t.  This is the time delta t and up here ", "we have our position function at T1 plus delta T.  Then for this time interval, the average velocity,  so for this particular time interval, ", "the average represents delta x over delta t.  So it's just rise over run. ", "It's just the slope of this straight line.  So for this particular interval, the average  is the slope of the line shown here on the figure. ", "Now this is just an average velocity  and now what we would like to do is shrink down  our interval delta T. So now let's make another case where ", "we shrink delta t and let's again calculate  the average velocity.  So for instance, suppose we have a smaller delta t ", "and we draw that line.  Then our average velocity represents that slope.  And again, we keep on taking a limit. ", "So now we have another slope so we have one slope, two slopes,  and now we shrink again to a new delta t  and you can see that the slope is changing. ", "And if we consider the limit as delta t  goes to 0 of this sequence of slopes, ", "then what are we getting, you can see graphically,  that eventually we will get to a line which  is the slope of the tangent line at time T1. ", "And so in this particular case, what  we mean by the instantaneous velocity, v at time T1,  is the limit as delta x goes to 0 i hat here ", "where we're taking, this is the limit,  delta t goes to 0 x at T1 plus delta t minus x1 ", "of t divided by delta t and the whole thing is a vector, i hat.  So what a limit is, is a sequence of numbers. ", "So we take a fixed delta t, we calculate the slope.  We take a smaller delta t, calculate the slope.  And each time we do that, the slopes represent  a sequence of numbers and the limit of that sequence ", "you can see graphically, is the slope  of the tangent line at time t 1.  And so what we say is, v of T1 is the instantaneous velocity ", "at time t equals t1.  And that's how we describe instantaneous velocity  at some specific time. ", "If we were now being a little bit more general,  we could just say that v at any time t  is the limit delta t goes to 0 delta ", "x over delta t ball direction i hat,  and the only thing here is we're no longer considering  T1 but an arbitrary time t. ", "This quantity, the limit, is awkward to write every time.  It has a name.  And that's precisely what we call the derivative  of the position function. ", "So our instantaneous velocity is the time derivative  ", "Let's consider a one dimensional motion that  has a non-uniform acceleration.  What we'd like to do is explore how  do you differentiate position functions,  to get velocity functions, to get acceleration functions. ", "So what we're going to consider is a rocket.  So I'm going to choose a coordinate system y.  And here's my rocket.  And I have a function y of t.  And I'll have a j-hat direction, but this will ", "be a one dimensional motion.  Now I want to express while the rocket is thrusting upwards  and the engine is burning, we can describe a function y of t ", "to be equal to 1/2 a constant a naught  minus the gravitational acceleration, times t squared.  And we're going to have a separate term here, which ", "is minus 1 over 30.  And you'll see where this 30 comes in  as we start to differentiate.  The same constant a naught, t to the 1/6 over t naught ", "to the 1/4.  Now in this expression, a naught is bigger than g.  And also, this is only true, this  holds for the time interval 0 less than ", "or equal to t, less than t naught.  And at time t equals to t naught, the engine shuts off. ", "And at that moment, our expectation  will be that the y component of the acceleration  should just be minus g, for t greater than t naught. ", "So now let's calculate the acceleration  as the velocity and the position as functions of time.  So the velocity-- in each case, we're ", "going to use the polynomial rule.  So the y component of the velocity  is just the derivative of t squared, which is just 2t.  And so we get a naught minus g times t. ", "And when we differentiate t at the 1/6, the 6 over 30  gives us factor 1 over 5.  So we have minus 1 over 5 times a naught, t to the 1/5 ", "over t naught to the 1/4.  And this is a combination of a linear term and a term  that is decreasing by this t to the 1/5 factor.  And finally, we now take the next derivative, ay of t, ", "which is d dy dt.  I'll just keep functions of t, but we don't really need that.  And when we differentiate here, we get a naught minus g. ", "Now you see the 5s are canceling,  and we have minus a naught t to the 1/4 over t naught  to the 1/4.  Now at time t equals t naught, what do we have? ", "Well, ay at t equals t naught.  This is just a factor minus a naught.  Those cancel, and we get minus g, which is what we expected. "], "vid_duration": [12.06, 11.65, 11.94, 11.87, 12.65, 10.99, 12.14, 10.47, 13.28, 12.2, 11.74, 12.02, 11.67, 11.12, 12.27, 12.254, 12.83, 11.89, 11.49, 10.99, 11.07, 11.14, 12.78, 11.64, 10.43, 10.66, 12.81, 10.106, 12.52, 10.0, 10.47, 11.04, 13.26, 10.79, 12.27, 12.86, 12.1, 10.18, 17.5, 10.65, 11.27, 10.79, 14.22, 10.43, 10.389, 11.04, 12.06, 12.87, 11.06, 12.16, 10.48, 10.55, 12.19, 13.71, 13.48, 14.028, 12.371, 18.8, 10.36, 10.48, 11.21, 13.82, 11.14, 11.47, 11.41, 16.99, 11.38, 11.58, 11.79, 12.92, 10.45, 23.27, 14.14, 10.13, 11.76, 13.01, 17.78, 10.29, 10.04, 10.1, 12.05, 11.884, 12.64, 11.88, 11.95, 10.09, 10.17, 11.51, 12.81, 12.08, 10.26, 12.97, 12.63, 13.46, 11.27, 13.7, 10.198], "stet": [[0, 12.06], [12.06, 23.71], [23.71, 35.65], [35.65, 47.519999999999996], [47.519999999999996, 60.169999999999995], [60.169999999999995, 71.16], [71.16, 83.3], [83.3, 93.77], [93.77, 107.05], [107.05, 119.25], [119.25, 130.99], [130.99, 143.01000000000002], [143.01000000000002, 154.68], [154.68, 165.8], [165.8, 178.07000000000002], [178.07000000000002, 190.324], [190.324, 203.15400000000002], [203.15400000000002, 215.04400000000004], [215.04400000000004, 226.53400000000005], [226.53400000000005, 237.52400000000006], [237.52400000000006, 248.59400000000005], [248.59400000000005, 259.73400000000004], [259.73400000000004, 272.514], [272.514, 284.154], [284.154, 294.584], [294.584, 305.244], [305.244, 318.05400000000003], [318.05400000000003, 328.16], [328.16, 340.68], [340.68, 350.68], [350.68, 361.15000000000003], [361.15000000000003, 372.19000000000005], [372.19000000000005, 385.45000000000005], [385.45000000000005, 396.24000000000007], [396.24000000000007, 408.51000000000005], [408.51000000000005, 421.37000000000006], [421.37000000000006, 433.4700000000001], [433.4700000000001, 443.6500000000001], [443.6500000000001, 461.1500000000001], [461.1500000000001, 471.80000000000007], [471.80000000000007, 483.07000000000005], [483.07000000000005, 493.86000000000007], [493.86000000000007, 508.0800000000001], [508.0800000000001, 518.5100000000001], [518.5100000000001, 528.8990000000001], [528.8990000000001, 539.9390000000001], [539.9390000000001, 551.999], [551.999, 564.869], [564.869, 575.929], [575.929, 588.0889999999999], [588.0889999999999, 598.569], [598.569, 609.1189999999999], [609.1189999999999, 621.309], [621.309, 635.019], [635.019, 648.499], [648.499, 662.527], [662.527, 674.898], [674.898, 693.698], [693.698, 704.058], [704.058, 714.538], [714.538, 725.748], [725.748, 739.5680000000001], [739.5680000000001, 750.7080000000001], [750.7080000000001, 762.1780000000001], [762.1780000000001, 773.5880000000001], [773.5880000000001, 790.5780000000001], [790.5780000000001, 801.9580000000001], [801.9580000000001, 813.5380000000001], [813.5380000000001, 825.3280000000001], [825.3280000000001, 838.248], [838.248, 848.6980000000001], [848.6980000000001, 871.9680000000001], [871.9680000000001, 886.1080000000001], [886.1080000000001, 896.238], [896.238, 907.998], [907.998, 921.008], [921.008, 938.788], [938.788, 949.078], [949.078, 959.1179999999999], [959.1179999999999, 969.218], [969.218, 981.2679999999999], [981.2679999999999, 993.1519999999999], [993.1519999999999, 1005.7919999999999], [1005.7919999999999, 1017.6719999999999], [1017.6719999999999, 1029.6219999999998], [1029.6219999999998, 1039.7119999999998], [1039.7119999999998, 1049.8819999999998], [1049.8819999999998, 1061.3919999999998], [1061.3919999999998, 1074.2019999999998], [1074.2019999999998, 1086.2819999999997], [1086.2819999999997, 1096.5419999999997], [1096.5419999999997, 1109.5119999999997], [1109.5119999999997, 1122.1419999999998], [1122.1419999999998, 1135.6019999999999], [1135.6019999999999, 1146.8719999999998], [1146.8719999999998, 1160.572], [1160.572, 1170.77]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [181, 320, 522, 655, 989, 1171]}
{"example_id": "mit032@@MIT8_01F16_L31_360p", "text": [" We now would like to consider the motion  of a rigid body that's undergoing angular  acceleration about some axis.  So let's consider, for simplicity, a disk. ", "And we have an axis that's passing through some point,  as here is the center, but that's not crucial.  And we want to consider the fact that this object-- ", "we'll call this our Z-axis-- K hat unit  vector in that direction.  So it's pointing up.  And this object is undergoing an angular acceleration  where alpha Z is the Z component of the angular acceleration. ", "Now, what we'd like to consider is the torque on the subject.  So the way we'll do it is we'll divide the object  into a bunch of pieces.  And let's identify a piece here as Delta MJ. ", "That's that piece.  And this piece has some force acting on it.  Now, this force can be a vector. ", "But the important thing to realize  is that this force is only the external force,  because we've already got to make  the assumption that all internal torques cancel in pairs. ", "And we'll show that in the video a little bit later.  So we're only considering the external forces that  are acting on this element.  And recall that we have the vector. ", "RS to J is the vector.  From point S to where this mass element is.  And now what we'd like to do is calculate the torque. ", "In general torque is given by the expression--  we'll sum over all the elements.  J goes from 1 to N. And it's the cross-product of our SJ cross ", "FJ external.  Now, our goal here is only to calculate  the Z component of the torque. ", "So we can simplify our understanding  a little bit by writing out this vector F external J ", "as a component in the plane.  And in order to describe that we'll choose some unit vectors.  R hat theta hat going into the plane. ", "We'll make another picture in a moment.  So our vector can have an R component.  And I'll keep the external in there.  It can have a theta hat component. ", "And it can also have a Z component.  But recall that a cross-product is always  perpendicular to either of the elements. ", "So when I cross R with anything in the K direction  then that component will give a component  that's not in the Z direction, and so I can ignore that. ", "So my first simplification is to say that the Z component will  only come from the cross product of RSJ, with these two pieces. ", "So that's cross FJR R hat plus FJ theta theta hat.  Now, again we can make another simplification, ", "and perhaps here it's helpful to have another overhead view.  And here's our mas element, delta NJ. ", "That's our vector from F, from the center, to delta NJ.  We have unit vectors, R hat, and theta hat. ", "And so we see that this vector, RSJ, has some length in the R  hat direction. ", "So we're picking S as the origin of our coordinate system.  This can generalize.  So we don't worry about if the object is not symmetric. ", "So when you take the cross product of R hat verse R hat,  that also is zero.  And so we see our simplification is quite nice, that the Z ", "component of the torque, is only arising from the sum of J  goes from 1 to N of our RSJ.  Well, we've already-- we'll write this all as vectors. ", "R ht cross F J theta theta hat.  Now, again, even if our external force-- by the way, ", "we're dropping external.  We can always say external, but I think, for simplicity, we'll  now drop the external.  And what we're considering is just ", "the component of the force.  We can write that FJ-- this is a little complicated-- theta.  Just the theta hat component of that force. ", "This is the only piece of the force  that matters in contributing to the Z component of the torque.  And this cross-product is very direct  because we've chosen a right handed system, where ", "R hat cross theta hat is K hat.   So we see that this becomes J equals 1 ", "to N of RSJ FJ theta in the K hat direction.  Now, that's just the calculation of the torque. ", "But, as always, it's crucial to understand  where Newton's second law appears in these calculations.  And Newton's second law, for this mass element,  delta MJ, So the second law is telling us ", "that the tangential force is proportional  to the mass element times the tangential acceleration  of that mass element. ", "Now, for this type of rotation about the Z-axis.  So when we're rotating about that Z-axis  we know that AJ theta, so the acceleration ", "of this tangential element, is just proportional  to RJ distance from-- well we've called that our RSJ--  so how far away from the center? ", "And here's the key thing.  It's also proportional to the Z component of the angular  acceleration.  And every mass element in the body has the same alpha Z. ", "And so our sum, for the torque, can now  be written in the following way.  The Z component of the torque-- now,  I'm going to do something here, which ", "is, I'll write J equals 1 to N, a parnetheses mark.  I have one of the RSJs.  I have another RSJ.  A delta MJ. ", "So I have delta MJ RSJ squared.  But every single component has the same alpha Z.  And we're in the K hat direction. ", "Now, because we have a continuous body we have to,  again, consider a limit.  So let's call the limit as delta MJ goes to 0 of this sum, ", "delta MJ RSJ squared.  Well that's an integral over the body of DMRS squared. ", "And we identified that before as the moment of inertia  about the Z-axis.  So the quandary in parentheses is just  a measure of the mass distribution about the axis. ", "You see the R squared, the delta MJ.  And so in conclusion we have that the Z component  of the torque is equal to IS alpha Z K ", "hat, which is now a vector, because that's the vector  alpha.  And this is our crucial result for a body that's ", "rotating about the Z-axis.  This result can generalize to not just  a disk, but any body that's looking at the Z component, ", "for this fixed axis rotation.   We'd like to consider torques on a body.  Let's draw an arbitrary body, and let's consider a point s, ", "that we're about to calculate the torque.  Now, we know that forces on the body  can be both internal and external.  And we'd like to show that all internal torques will  cancel in pairs. ", "The way we'll do that is, suppose we pick an object.  We'll label it with mass mi, and another object,  we'll label that with mass mj. ", "These are small mass elements in the body.  And we'd like to know something about the internal forces.  Now, let's make the assumption-- and this is the key property-- ", "that the force due to this interaction between j  and the i-th particle pointing that way-- and here's  the Newton's third law pair-- that these forces lie-- ", "are directed along the line connecting the two bodies.  With this assumption, we'll now show  that the torque due to these two internal forces, [INAUDIBLE]  Newton's third law pairs will cancel. ", "So let's calculate that out.  So we draw our vector from rsi, and our other vector rsj. ", "And now we're in position to add these two torques.  So we have the torque on s due to this pair is  equal to the sum of rsi cross fji plus ", "rs-- that's an r-- make sure we get that right.  We have rsj cross fij. ", "Now, the third law pair says fji is equal to minus fiji.  And so, if we substitute-- let's put the minus sign over here-- ", "we get rsi minus rsj cross fji.  ", "Now, let's look at this vector in particular.  We can draw it again over here, just to see it.  Here s.  Here is rsi. ", "Here is the vector rs, that's rsj.   And we want to now consider the vector rsi minus rsj. ", "Notice that this vector is directed  along the lines connecting the i-th and the j-th particle.  And we've made an assumption that fji is also ", "along that line.  So these two vectors, in this particular case,  are either parallel or anti-parallel. ", "And hence, the torque due to the sum of these internal  forces cancel in pairs.  And this means we only need to address ", "the torque due to external forces that  are acting on individual elements in a body.   Let's determine the moment of inertia of a big wheel. ", " Here we have a big wheel and on the side it's attached here  at the center .  And there's a string going around here, and on that string ", "is a little mass hanging.  And our disk here has a radius R.  And we now want to in a little experiment ", "what the moment of inertia is of this disk.  And what we have to do is we have  to drop this mass to the ground, and we  need to measure what height is here, ", "and we need to measure how long it takes to drop.  So we need to measure t.   So how are we going to go about that? ", "Well the moment of inertia, that probably  has something to do with the torque of this wheel.  So we have to start doing a torque analysis.  So torque about the center of mass equals moment of inertia ", "about the center of mass times the angular acceleration.  And we need to recall that the torque is  the product of the radius times the perpendicular force, ", "so we're going to have R here, and then  the force that's acting on this wheel  here is actually this tension force here. ", "So we are going to have our RT here.  And now we need to look at how things actually moving  with respect to coordinate system. ", "So if I let this mass drop, to the disk  it's going to spin clockwise.  So we're going to have theta hat going this way. ", "And if theta hat is going clockwise,  my k hat vector is going to go into the board.  And if k hat is going to go there, ", "and it's rotating clockwise, the angular acceleration  is going to go in the k hat direction. ", "And if that is the case, then the torque  is going to follow suit.  So torque also goes into the board.  And so that means here we're going ", "to deal with k hat direction.  And we're going to have Icm and then  alpha Z in the k hat direction.  OK, so we can solve this I RT over alpha Z. OK, ", "well that's pretty good, but we have two unknowns-- the T  and the alpha Z. And we can use some other concepts to actually  get information on those. ", "The T, as you can guess already, plays a role here  in this massless string, so we can do a quick free body  diagram, an F equals ma analysis to get to that tension force. ", "So we have a little mass, m, here gravity is acting on it.  And we have this tension force here.  And we're going to put j hat down. ", "So we're going to get mg minus t, equals ma.  It's only going to go in y direction,  so we can just leave it here. ", "And we can solve this for t.  And then we have mg minus a. ", "OK, good, so we have that.  Now about the angular acceleration.  And whenever there was a string going around a disk then,  we of course, have a constrained condition, ", "because the linear acceleration of this little mass going down  is related to the radius of the disk, times the angular ", "acceleration.  So we can solve this for alpha.  And then we have a over R. So let's put that in here. ", "R, and then we have mg minus a over a,  and then we get another R here.  And we can write that a little bit more compact, mR squared g ", "over a minus 1.  Good, so now we have one last hurdle, namely that a here. ", "That a we can't measure.  I said in the beginning, we want to make an experiment.  Actually we need experiment, because we can't otherwise ", "get to this a, so what we need is  a relation that connects what we can measure, which is the time.  It falls down the height here to the acceleration of this block. ", "And of course, that comes from one dimensional kinematics.  And we know that h equals 1/2 at squared, so we can solve for a. ", "2h over t squared.  And now we can stick that in here.  And we have mR squared, gt squared over 2h minus 1. ", "And let's just write this here again.  And that is our final solution.  So now we have only measurable quantities here. ", "The t we can measure.  We just need a stopwatch.  And the h we can measure, as well.  And this actually already resembles, ", "if you know the theoretical, this already  resembles the theoretical solution,  which of course is for a disk. ", "1/2 mR squared, so that's what one expects for a disk.  And you see that we're very close, so this term here ", "is probably something like 1.5, or should better  come out to be 1.5, because if we subtract 1,  we get to that 1/2 here.  And you can use it to in return-- in return, ", "you can also use it to predict the time  it takes to fall down if you know what the height is  or vice versa.  ", "Let's consider a very famous problem the, Atwood machine.  We have a pulley, A, suspended from a ceiling.  And a rope is wrapped around the pulley. ", "And on each side of the rope, there's different masses.  So here is block 1, and block 2, and we  can say here-- it doesn't matter-- ", "but we'll say that M2 is bigger than M1.  And that gives us some intuition that we  expect block 2 to go down and block 1 to go up.  Now in this problem there is friction ", "between the rope and the pulley, so the rope is not sliding.  And what that means is that the pulley will rotate.  And also the mass of the pulley is not 0. ", "So these were all assumptions we made way back when  were analyzing Newton's second law,  but now we have to take into effect  that there some rotational inertia to make  the pulley start to have angular acceleration. ", "So what we'd like to do is to identify our three objects--  mass 1, the pulley, and mass 2.  And for mass 1 and mass 2, use Newton's second law,  for the pulley, we'll use our torque relationships. ", "So let's begin by drawing our free body  diagrams for object 1.  So we have tension in the rope pulling object 1 up, ", "we have the gravitational force down.  And here it doesn't matter which way  I'm going to choose my unit vectors, because I  have this idea that M2 is bigger than M1. ", "I'm just going to choose j hat 1 up.  Now for block 2, I have M2g.  Now here's the place where lots of people get tripped up. ", "In the past we've been assuming that the tension in the rope  is uniform everywhere.  In this problem, because the rope is not slipping ", "and the pulley is not massless, the tension  is not constant everywhere in the rope.  And we'll see more reasons why that can't be the case, so I'll ", "have to identify a different tension on the other side T2  pulling the rope, pulling the block up.  And I'm going to choose j hat 2 down.  Notice my unit vectors are chosen in opposite directions. ", "The reason for that is that there's a constraint here  that as block 2 goes down, block 1 goes up,  if the acceleration of block 2 is positive, ", "the acceleration of block 1 will also  be positive if I choose unit vector pointing up.  So now I can write Newton's second law for both of these.  So for block 2, positive down, and 2g minus T2 equals M2a. ", "It's the same acceleration in the rope.  a is equal to a1, equal to a2, they're all positive.  And for 2, notice I have positive up ", "minus M1g equals m1a.  So so far, these are my two equations.  I have three unknowns-- T1, T2, and the accelerations, ", "and only two equations.  Now let's analyze the pulley.  So we have our pulley A. And what  are the forces on the pulley?  Well forces and torques are a little bit different, ", "but let's just draw our forces first.  There is a tension holding it up,  we'll call that T3 from this rope pulling it up.  Now here's where we have to be careful. ", "Rope 1 is pulling the pulley down, that's what we called T1,  so we draw a T1 on this side.  And the same rope on the other side ", "is pulling the pulley down.  Notice that it is a different, T2.  Now this brings us to what we called our rotational  coordinate system. ", "I do know expect that the angular  acceleration of the pulley.  So as the pulley rotates in this problem,  I expect that it's rotating in the direction ", "like by the right hand rule, this way.  And so I expect to see the alpha pointing like that. ", "What I'll do is I'll choose a coordinate system for an angle  theta.  And that will make positive direction ", "like that for my rotational coordinate system.  Now when we write torque equals the moment of inertia  of the pulley, times the angular acceleration, ", "we have two torques.  The radius is R, radiuses of R. And if we're  calculating the torque about the center of the pulley, ", "we'll call that point 0, then each of these torques  are in different directions.  So for instance, we would have to take for T1  going down and this vector from origin to where T1 is acting, ", "we can extend that force.  And we see that that torque is pointing in the direction  in-- direction like that. ", "And that's opposite or sign here.  So this torque, minus T1 R is negative.  What about the torque from the other force, T2? ", "Again, we would draw that vector.  Let's draw them over here.  We have T2 pointing down.  The point 0 is there.  The vector from 0 to 2 is pointing like that. ", "We extend that vector.  We put the arrow like that.  And we see that this one is pointing  in our positive direction.  So we have a plus T2R equals IA alpha. ", "Now right away we can see why the tension in the strings  is not the same.  Because if these tensions were the same,  this quantity would be 0, but the tensions  can't be the same because the pulley is rotating. ", "And that rotational inertia of the pulley  is coming from the fact that the two torques are not  the same on both sides.  So we now have our last equation here. ", "T2R minus T1R equals IA alpha.  But notice that I've introduced another variable here, ", "so I guess again, I have four equations and only  three unknowns.  We still have one last constraint.  Because the rope is sliding along the pulley  and the radius is R, we know that a point ", "on the rim of the pulley has acceleration A of the rope.  But the pulley has an alpha angular acceleration,  so our constraint conditioned here is plus R alpha. ", "Now why did I put a plus sign?  Because when the pulley is rotating the direction shown,  alpha will be positive.  This quantity, torque, will be bigger than this one, ", "and so we'll have a positive alpha.  When I chose j hat 1 up and j hat 2 down,  that made all my accelerations positive,  and so I with the plus side. ", "If I had reversed my choice of unit vectors,  then this would be a minus sign.  So you have to be extremely careful by making sure ", "that the directions you chose for the linear force  diagrams that give us A, and the direction we chose  in our rotational coordinate system  are consistent when we choose to relate ", "the constraints between them.  So that's our last condition that a equals our R alpha.  So I now have four equations and four unknowns. ", "And if I want to solve for the acceleration a,  then I have to need a strategy here.  And what I'll do to find a is I'll use this equation  as my backbone. ", "Why did I do that?  Because I have the unknowns T2, T1, and alpha.  And I have separate equations that relate alpha to A,  and T1 to a and T2 to a And so I can solve for T2. ", "And substitution here I'll need a little room.  So I get that T2 is M2g plus M2a. ", "I'm sorry, minus M2a times R. Now T1 is M1a plus M1g times R, ", "and that's equal to times AI alpha, which is a over R.  So I'll now collect all of my a terms over here. ", "And so I get to M2gR minus M1gR, this term and this term, ", "is equal to a times IA over R. Notice  I have 2 plus signs here, so I get M1 plus M2 times R. ", "And I therefore conclude, we'll put it over here,  that the acceleration a of is equal to M2 minus m1gR, divided ", "by IA over R, plus M1 plus M2R.  ", "Now, when I have this result, let's just  check a number of things first.  Notice that if M2 is bigger than M1,  a will be positive, which is what I expected. ", "Dimensionally, we have M2gR, down here, M2R,  so this first term will have dimensions of acceleration g. ", "Now over here, we have IA over R,  but remember moment of inertia is M times R  square, so this also have the dimensions of mass and radius. ", "And so I have confidence dimensionally.  And the sine of A that this is the correct answer.  ", "How do we solve problems involving massive pulleys using  Newton's laws?  As a simple example, let's look at this problem,  consisting of a block of mass m1 hanging ", "from a massive pulley that has a moment of inertia I  and radius r.  We'll find the acceleration of the block, a1,  and the angular acceleration of the massive pulley, alpha. ", "It is critical to remember that the first step in solving  these problems is to define the positive x and y directions  and the positive direction of rotation.  In two-dimensional problems, you're ", "free to find any direction to be positive.  Here, we'll set our positive x and positive y like this.  Once we pick x and y, the direction  of the positive rotation is now also defined ", "by the right-hand rule.  You'll see shortly that defining positive directions  at the beginning will save you from a negative sign nightmare  later on. ", "Now let's break down Newton's laws for the different parts  of the system.  First, for the block, we will write down the linear version  of Newton's second law. ", "For the sum of forces, we have gravity pointing down  and tension pointing up.  According to the convention we just defined, T1 is positive  and m1g is negative. ", "Notice that since the block is accelerating,  T1 minus m1g is not 0 but is equal to m1a1.  Notice that here we've set the signs for tension and weight, ", "but we don't yet know which were the block is accelerating.  So we just start by writing m1a1.  And if, in the end, we get that a1 is negative,  we'll know that it's actually accelerating  in the negative direction. ", "Now let's look at the pulley.  Newton's second law in its rotational form  is tau is equal to I alpha.  For a normal pulley, the string is always ", "tangential to the side of the pulley.  So r and f are perpendicular, so that means  the torque is just T1 times r. ", "What's the sign of this term?  Well, according to the positive direction that we defined,  this torque is positive.  Again, we'll leave the sign of the I alpha term ", "to be positive.  And alpha will turn out to be either positive or negative.  Finally, we need to connect these two equations.  Because the block is connected to the pulley using ", "an ideal, taut, inextensible rope,  a1 is going to be related to alpha.  We just need to figure out exactly how they're related.  In other words, we need to write down the constraint condition. ", "Let's say that the block hypothetically  is moving upwards.  In this case, what's happening to the pulley?  It must be spinning clockwise to pull the rope up ", "as the block goes in, so it has a clockwise angular velocity,  which, according to our convention, is negative.  In fact, if the pulley rotates a full turn ", "in the clockwise negative direction,  the angle changes by negative 2 pi,  and 2 pi times r of the rope will be pulled up.  So we can write that delta y is equal to negative r delta theta ", "or, taking some derivatives, a1 is equal to negative r  times alpha.  After setting the sign conventions, ", "writing Newton's laws for different parts of the system,  and then writing down the constraint condition,  we have three equations and three unknowns  ", "When we used our energy principle,  suppose we have an object that starts at a height h0.  And this object is dropped, and when it gets to the ground, ", "it has some final velocity.  And when we applied our energy principle,  assuming that there was no air resistance, what  we saw was that the change in kinetic energy plus the change ", "of potential energy was 0, so we had 0 was equal to delta  k plus delta u.  And we saw that the kinetic energy  changed by 1/2 mv squared, and the potential energy changed ", "by minus mg h0.  So we can compute the velocity of the object  as it's falling given by square root of 2g h0. ", "Now that we're considering kinetic energy of rotation,  recall that we show that the kinetic energy  of a pure rotation about a fixed axis  was 1/2 the moment of inertia about ", "that axis times the angular speed squared.  We now would like to apply our energy principle  to include rotational kinetic energy along ", "with the translational kinetic energy.  And the example that we want to look at  is something very simple.  Suppose we have a pulley.  Now our pulley has a mass p, and we'll ", "say it has a moment of inertia of the pulley about the fixed  axis passing through the center of the pulley.  And we have a mass 1 and another block 2. ", "And let's suppose that we release this system.  And for the moment let's make this surface frictionless. ", "And suppose that block 2 falls down a certain distance.  So in the final state, block 2 will  have dropped a distance each final ", "from its initial position.  And what we like to consider is find  the velocity final of block 2. ", "So we begin in the same way that we've done this before,  by considering our energy diagrams.  And so we'll have an initial state.  ", "And in our initial state, what we'll do  is we'll just have the initial 1, 2.  And I'm going to choose u equals 0, here's my pulley. ", "And everything is at rest.  And so in the initial state, the initial energy, i  initial, k initial, plus u initial is 0. ", "And in our final state, we have the pulley  is rotating with omega final. ", "Block 1 is moving with a velocity v final 1.  And block 2 is also moving with v2 final. ", "And let's just suppose that this was our u equals 0 position.  And although it's not so clear in the diagram, u final, ", "it has moved down to height h final.  So what is the energy in our final state?  Well, we have to consider all the different pieces. ", "We have block 1, 1/2 m1, v1 final squared.  We have the motion of block 2, 1/2 m2 v2 final squared. ", "And we also have the kinetic energy  of the pulley, which is given by 1/2 I about the pulley  omega final squared. ", "And what about our final potential energy?  Well, we've dropped the height, h final.  So we have block 2 has moved minus m2 gh final. ", "And now we have our two energy states.  And what we'd like to consider is apply the energy principle  just like we applied it for this simple case. ", "But before we do that, there is a constraint condition  that because the rope is fixed in length, as block 1 moves, ", "the pulley is rotating and block 2 is moving.  What we'll have is fixed and not slipping.   So as the rope moves around the pulley, ", "the pulley is moving with the same motion as the rope,  and the rope is moving with the speeds of block 1 and 2,  so we see that v1 final is equal to v2 final. ", "And now what about the pulley?  If this is radius r, we know that the velocity  of a point on the rim of a disk is ", "moving with the speed of the rope, which  is the speed of block 1 and block 2,  So that's our omega final.  And so that makes our final energy, let's now gather terms. ", "The velocities are the same.  So we have 1/2 and 1 plus m2.  And we'll just call this the final for simplicity. ", "1/2 m2 times v final squared.  That accounts for these two terms.  And we have the moment of inertia, kinetic energy ", "associated with the wheel, which is 1/2i omega final squared,  which is v final squared over r squared minus m2 gh final. ", "And so now we can solve our energy principle, which  is because we're assuming everything's frictionless,  we have 0 equals E final minus E initial, ", "implies that E final equals E initial.  And we chose our initial potential energy to be 0.  So of course that's just a choice of constant. ", "So I can now solve this equation by setting E final equal to 0.  That's the same statement.  And then you can see algebraically I ", "can solve for V final.  And what I get is I'm just going to write all these terms over.  I get m2gh final. ", "I'm going to divide by this common coefficient, 1/2 and 1  plus m2 plus the moment of inertia ", "divided by radius squared.  And I now have to take the square root of the whole thing.  And that's how I can find the velocity of block 2 ", "when it's dropped down a certain distance to h final.  So here we've generalized our energy approach  to include rotational kinetic energy. "], "vid_duration": [14.59, 11.75, 13.93, 14.37, 10.11, 11.82, 11.22, 11.85, 16.29, 10.41, 10.41, 12.87, 12.42, 13.24, 12.27, 14.66, 11.445, 11.145, 11.39, 12.84, 11.299, 10.411, 12.05, 13.12, 13.38, 14.19, 11.55, 12.04, 11.83, 15.59, 10.41, 15.87, 10.95, 12.9, 10.11, 11.58, 12.73, 16.25, 12.51, 13.53, 12.93, 11.67, 12.3, 12.973, 10.21, 10.44, 11.28, 11.8, 11.61, 11.81, 15.57, 13.83, 11.72, 13.43, 11.844, 17.776, 12.48, 10.23, 10.53, 11.369, 13.5, 15.39, 12.85, 10.12, 15.14, 12.951, 10.709, 12.191, 12.11, 10.949, 10.031, 10.549, 18.241, 12.529, 18.61, 11.611, 12.46, 10.419, 15.191, 12.839, 11.651, 16.369, 11.07, 11.401, 13.95, 18.54, 20.63, 10.72, 13.259, 11.901, 10.69, 11.49, 11.461, 10.85, 10.83, 14.59, 12.09, 12.519, 12.901, 10.16, 11.04, 11.13, 10.5, 10.5, 13.33, 10.25, 17.52, 11.79, 11.22, 12.61, 12.079, 10.021, 11.34, 13.35, 14.25, 11.14, 13.01, 11.55, 16.14, 12.75, 10.53, 15.07, 15.59, 13.29, 10.11, 11.01, 13.14, 13.8, 10.19, 11.66, 10.1, 10.83, 10.66, 11.03, 13.49, 12.52, 18.3, 12.3, 13.8, 15.36, 17.72, 11.1, 11.27, 10.57, 10.38, 11.832, 10.891, 13.74, 11.74, 11.79, 10.424, 10.316, 11.27, 11.1, 13.15, 11.15, 10.35, 11.01, 11.819, 11.311, 10.409, 11.411, 14.79, 10.25, 14.122, 11.15, 10.74, 12.84, 12.33, 12.96, 11.37, 10.65, 13.89, 10.16, 14.0, 12.26, 12.57, 15.12, 12.33, 10.32, 12.72, 10.2, 10.65, 11.76, 10.2, 12.93, 11.58, 14.15, 10.38, 12.06, 10.05, 14.61, 10.37, 10.51, 14.55, 14.94, 11.1, 10.95, 14.04, 13.99, 13.26, 10.201], "stet": [[0, 14.59], [14.59, 26.34], [26.34, 40.269999999999996], [40.269999999999996, 54.63999999999999], [54.63999999999999, 64.75], [64.75, 76.57], [76.57, 87.78999999999999], [87.78999999999999, 99.63999999999999], [99.63999999999999, 115.92999999999998], [115.92999999999998, 126.33999999999997], [126.33999999999997, 136.74999999999997], [136.74999999999997, 149.61999999999998], [149.61999999999998, 162.03999999999996], [162.03999999999996, 175.27999999999997], [175.27999999999997, 187.54999999999998], [187.54999999999998, 202.20999999999998], [202.20999999999998, 213.65499999999997], [213.65499999999997, 224.79999999999998], [224.79999999999998, 236.19], [236.19, 249.03], [249.03, 260.329], [260.329, 270.74], [270.74, 282.79], [282.79, 295.91], [295.91, 309.29], [309.29, 323.48], [323.48, 335.03000000000003], [335.03000000000003, 347.07000000000005], [347.07000000000005, 358.90000000000003], [358.90000000000003, 374.49], [374.49, 384.90000000000003], [384.90000000000003, 400.77000000000004], [400.77000000000004, 411.72], [411.72, 424.62], [424.62, 434.73], [434.73, 446.31], [446.31, 459.04], [459.04, 475.29], [475.29, 487.8], [487.8, 501.33], [501.33, 514.26], [514.26, 525.93], [525.93, 538.2299999999999], [538.2299999999999, 551.2029999999999], [551.2029999999999, 561.4129999999999], [561.4129999999999, 571.853], [571.853, 583.1329999999999], [583.1329999999999, 594.9329999999999], [594.9329999999999, 606.5429999999999], [606.5429999999999, 618.3529999999998], [618.3529999999998, 633.9229999999999], [633.9229999999999, 647.7529999999999], [647.7529999999999, 659.473], [659.473, 672.9029999999999], [672.9029999999999, 684.747], [684.747, 702.5229999999999], [702.5229999999999, 715.0029999999999], [715.0029999999999, 725.233], [725.233, 735.7629999999999], [735.7629999999999, 747.132], [747.132, 760.632], [760.632, 776.0219999999999], [776.0219999999999, 788.872], [788.872, 798.992], [798.992, 814.132], [814.132, 827.083], [827.083, 837.7919999999999], [837.7919999999999, 849.983], [849.983, 862.093], [862.093, 873.0419999999999], [873.0419999999999, 883.0729999999999], [883.0729999999999, 893.6219999999998], [893.6219999999998, 911.8629999999998], [911.8629999999998, 924.3919999999998], [924.3919999999998, 943.0019999999998], [943.0019999999998, 954.6129999999998], [954.6129999999998, 967.0729999999999], [967.0729999999999, 977.4919999999998], [977.4919999999998, 992.6829999999999], [992.6829999999999, 1005.5219999999999], [1005.5219999999999, 1017.1729999999999], [1017.1729999999999, 1033.542], [1033.542, 1044.6119999999999], [1044.6119999999999, 1056.013], [1056.013, 1069.963], [1069.963, 1088.503], [1088.503, 1109.133], [1109.133, 1119.853], [1119.853, 1133.112], [1133.112, 1145.0130000000001], [1145.0130000000001, 1155.7030000000002], [1155.7030000000002, 1167.1930000000002], [1167.1930000000002, 1178.6540000000002], [1178.6540000000002, 1189.5040000000001], [1189.5040000000001, 1200.334], [1200.334, 1214.924], [1214.924, 1227.014], [1227.014, 1239.533], [1239.533, 1252.434], [1252.434, 1262.594], [1262.594, 1273.634], [1273.634, 1284.7640000000001], [1284.7640000000001, 1295.2640000000001], [1295.2640000000001, 1305.7640000000001], [1305.7640000000001, 1319.094], [1319.094, 1329.344], [1329.344, 1346.864], [1346.864, 1358.654], [1358.654, 1369.874], [1369.874, 1382.484], [1382.484, 1394.5629999999999], [1394.5629999999999, 1404.5839999999998], [1404.5839999999998, 1415.9239999999998], [1415.9239999999998, 1429.2739999999997], [1429.2739999999997, 1443.5239999999997], [1443.5239999999997, 1454.6639999999998], [1454.6639999999998, 1467.6739999999998], [1467.6739999999998, 1479.2239999999997], [1479.2239999999997, 1495.3639999999998], [1495.3639999999998, 1508.1139999999998], [1508.1139999999998, 1518.6439999999998], [1518.6439999999998, 1533.7139999999997], [1533.7139999999997, 1549.3039999999996], [1549.3039999999996, 1562.5939999999996], [1562.5939999999996, 1572.7039999999995], [1572.7039999999995, 1583.7139999999995], [1583.7139999999995, 1596.8539999999996], [1596.8539999999996, 1610.6539999999995], [1610.6539999999995, 1620.8439999999996], [1620.8439999999996, 1632.5039999999997], [1632.5039999999997, 1642.6039999999996], [1642.6039999999996, 1653.4339999999995], [1653.4339999999995, 1664.0939999999996], [1664.0939999999996, 1675.1239999999996], [1675.1239999999996, 1688.6139999999996], [1688.6139999999996, 1701.1339999999996], [1701.1339999999996, 1719.4339999999995], [1719.4339999999995, 1731.7339999999995], [1731.7339999999995, 1745.5339999999994], [1745.5339999999994, 1760.8939999999993], [1760.8939999999993, 1778.6139999999994], [1778.6139999999994, 1789.7139999999993], [1789.7139999999993, 1800.9839999999992], [1800.9839999999992, 1811.5539999999992], [1811.5539999999992, 1821.9339999999993], [1821.9339999999993, 1833.7659999999994], [1833.7659999999994, 1844.6569999999995], [1844.6569999999995, 1858.3969999999995], [1858.3969999999995, 1870.1369999999995], [1870.1369999999995, 1881.9269999999995], [1881.9269999999995, 1892.3509999999994], [1892.3509999999994, 1902.6669999999995], [1902.6669999999995, 1913.9369999999994], [1913.9369999999994, 1925.0369999999994], [1925.0369999999994, 1938.1869999999994], [1938.1869999999994, 1949.3369999999995], [1949.3369999999995, 1959.6869999999994], [1959.6869999999994, 1970.6969999999994], [1970.6969999999994, 1982.5159999999994], [1982.5159999999994, 1993.8269999999993], [1993.8269999999993, 2004.2359999999994], [2004.2359999999994, 2015.6469999999995], [2015.6469999999995, 2030.4369999999994], [2030.4369999999994, 2040.6869999999994], [2040.6869999999994, 2054.8089999999993], [2054.8089999999993, 2065.9589999999994], [2065.9589999999994, 2076.698999999999], [2076.698999999999, 2089.5389999999993], [2089.5389999999993, 2101.8689999999992], [2101.8689999999992, 2114.8289999999993], [2114.8289999999993, 2126.198999999999], [2126.198999999999, 2136.8489999999993], [2136.8489999999993, 2150.738999999999], [2150.738999999999, 2160.898999999999], [2160.898999999999, 2174.898999999999], [2174.898999999999, 2187.158999999999], [2187.158999999999, 2199.7289999999994], [2199.7289999999994, 2214.8489999999993], [2214.8489999999993, 2227.178999999999], [2227.178999999999, 2237.4989999999993], [2237.4989999999993, 2250.218999999999], [2250.218999999999, 2260.418999999999], [2260.418999999999, 2271.068999999999], [2271.068999999999, 2282.8289999999993], [2282.8289999999993, 2293.028999999999], [2293.028999999999, 2305.958999999999], [2305.958999999999, 2317.538999999999], [2317.538999999999, 2331.688999999999], [2331.688999999999, 2342.068999999999], [2342.068999999999, 2354.128999999999], [2354.128999999999, 2364.178999999999], [2364.178999999999, 2378.7889999999993], [2378.7889999999993, 2389.158999999999], [2389.158999999999, 2399.6689999999994], [2399.6689999999994, 2414.2189999999996], [2414.2189999999996, 2429.1589999999997], [2429.1589999999997, 2440.2589999999996], [2440.2589999999996, 2451.2089999999994], [2451.2089999999994, 2465.2489999999993], [2465.2489999999993, 2479.238999999999], [2479.238999999999, 2492.4989999999993], [2492.4989999999993, 2502.6999999999994]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [540, 740, 1175, 1832, 2051, 2503]}
{"example_id": "mit035@@MIT8_04S16_lec05_300k", "text": ["PROFESSOR: Last time, we talked about the Broglie wavelength.  And our conclusion was, at the end of the day,  that we could write the plane wave that corresponded ", "to a matter particle, with some momentum, p, and some energy,  E. So that was our main result last time,  the final form for the wave. ", "So we had psi of x and t that was  e to the i k x minus i omega t. ", "And that was the matter wave with the relations  that p is equal to h bar k.  So this represents a particle with momentum, ", "p, where p is h bar times this number that appears here,  the wave number, and with energy,  E, equal to h bar omega, where omega ", "is that number that appears in the [? term ?] exponential.  Nevertheless, we were talking, or we  could talk, about non-relativistic particles. ", " And this is our focus of attention.  And in this case, E is equal to p squared over 2m. ", "That formula that expresses the kinetic energy  in terms of the momentum, mv.  So this is the wave function for a free particle. ", " And the task that we have today is ", "to try to use this insight, this wave function,  to figure out what is the equation that  governs general wave functions. ", "So, you see, we've been led to this wave function  by postulates of the Broglie and experiments of Davisson, ", "and Germer, and others, that prove  that particles like electrons have wave properties.  But to put this on a solid footing ", "you need to obtain this from some equation, that  will say, OK, if you have a free particle, what  are the solutions.  And you should find this solution. ", "Perhaps you will find more solutions.  And you will understand the problem better.  And finally, if you understand the problem of free particle,  there is a good chance you can generalize this and write ", "the equation for a particle that moves  under the influence of potentials.  So basically, what I'm going to do  by trying to figure out how this wave emerges from an equation, ", "is motivate and eventually give you,  by the middle of this lecture, the Schrodinger equation.  So that's what we're going to try to do.  And the first thing is to try to understand ", "what kind of equation this wave function satisfies.  So you want to think of differential equations  like wave equations. ", "Maybe it's some kind of wave equation.  We'll see it's kind of a variant of that.  But one thing we could say, is that you ", "have this wave function here.  And you wish to know, for example, what is the momentum.  Well you should look at k, the number that multiplies the x ", "here, and multiply by h bar.  And that would give you the momentum.  But another way of doing it would be to do the following.  To say, well, h bar over i d dx of psi of x and t, ", "calculate this thing.  Now, if I differentiate with respect to x,  I get here, i times k going down. ", "The i cancels this i, and I get h bar k.  So, I get h bar k times the exponential.  ", "And that is equal to the value of the momentum times the wave.  So here is this wave actually satisfies a funny equation, ", "not quite the differential equation we're looking for yet,  but you can act with a differential operator. ", "A derivative is something of a differential operator.  It operates in functions, and takes the derivative.  And when it acts on this wave function, ", "it gives you the momentum times the wave function.  And this momentum here is a number.  Here you have an operator. ", " An operator just means something that acts on functions,  and gives you functions. ", "So taking a derivative of a function is still a function.  So that's an operator.  So we are left here to think of this operator  as the operator that reveals for you the momentum ", "of the free particle, because acting on the wave function,  it gives you the momentum times the wave function.  Now it couldn't be that acting on the wave function ", "just gives you the momentum, because the exponential doesn't  disappear after the differential operator acts.  So it's actually the operator acting  on the wave function gives you a number times the wave function. ", "And that number is the momentum.  So we will call this operator, given  that it gives us the momentum, the momentum operator, so ", "momentum operator.  And to distinguish it from p, we'll put a hat, ", "is defined to be h bar over i d dx.   And therefore, for our free particle, ", "you can write what we've just derived in a brief way,  writing p hat acting on psi, where ", "this means the operator acting on psi,  gives you the momentum of this state times psi of x and t. ", "And that's a number.  So this is an operator state, number state.   So we say a few things, this language that we're ", "going to be using all the time.  We call this wave function, this psi, if this is true, ", "this holds, then we say the psi of x and t ", "is an eigenstate of the momentum operator. ", "And that language comes from matrix algebra, linear algebra,  in which you have a matrix and a vector. ", "And when the matrix on a vector gives you  a number times the same vector, we  say that that vector is an eigenvector of the matrix. ", "Here, we call it an eigenstate.  Probably, nobody would complain if you  called it an eigenvector, but eigenstate  would be more appropriate.  So it's an eigenstate of p. ", "So, in general, if you have an operator, A, under a function, ", "phi, such that A acting on phi is alpha phi, ", "we say that phi is an eigenstate of the operator,  and in fact eigenvalue alpha.  So, here is an eigenstate of p with eigenvalue ", "of p, the number p, because acting on the wave function  gives you the number p times that wave function.  Not every wave function will be an eigenstate. ", "Just like, when you have a matrix acting on most vectors,  a matrix will rotate the vector and move it  into something else.  But sometimes, a matrix acting in a vector ", "will give you the same vector up to a constant,  and then you've got an eigenvector.  And here, we have an eigenstate.  So another way of expressing this, ", "is we say that psi of x and t, this psi of x and t,  is a state of definite momentum. ", " It's important terminology, definite momentum means  that if you measured it, you would find the momentum p. ", "And the momentum-- there would be no uncertainty  on this measurement.  You measure, and you always get p.  And that's what, intuitively, we have, ", "because we decided that this was the wave  function for a free particle with momentum, p.  So as long as we just have that, we ", "have that psi is a state of definite momentum.  This is an interesting statement that will apply for many things ", "as we go in the course.  But now let's consider another aspect of this equation.  So we succeeded with that.  And we can ask if there is a similar thing ", "that we can do to figure out the energy of the particle.  And indeed we can do the following.  We can do i h bar d dt of psi. ", " And if we have that, we'll take the derivative.  Now, this time, we'll have i h bar. ", "And when we differentiate that wave function with respect  to time, we get minus i omega times the wave function.  So i times minus i is 1. ", "And you get h bar omega psi.  Success, that was the energy of the particle times psi.  ", "And this looks quite interesting already.  This is a number, again.  And this is a time derivative of the wave function. ", "But we can put more physics into this, because in a sense, well,  this differential equation tells you ", "how a wave function with energy, E,  what the time dependence of that wave function is.  But that wave function already, in our case, ", "is a wave function of definite momentum.  So somehow, the information that is missing there,  is that the energy is p squared over 2m. ", "So we have that the energy is p squared over 2m.  So let's try to think of the energy as an operator. ", "And look, you could say the energy,  well, this is the energy operator acting on the function  gives you the energy.  That this true, but it's too general, not interesting enough ", "at this point.  What is really interesting is that the energy has a formula.  And that's the physics of the particle,  the formula for the energy depends on the momentum. ", "So we want to capture that.  So let's look what we're going to do.  We're going to do a relatively simple thing, which  we are going to walk back this. ", "So I'm going to start with E psi.  And I'm going to invent an operator acting on psi  that gives you this energy. ", " So I'm going to invent an O. ", "So how do we do that?  Well, E is equal to p squared over 2m times psi. ", "It's a number times psi.  But then you say, oh, p, but I remember p.  I could write it as an operator. ", "So if I have p times psi, I could write it  as p over 2m h bar over i d dx of psi. ", "Now please, listen with lots of attention.  I'm going to do a simple thing, but it's very easy  to get confused with the notation. ", "If I make a little typo in what I'm writing  it can confuse you for a long time.  So, so far these are numbers. ", "Number, this is a number times psi.  But this p times psi is p hat psi  which is that operator, there. ", "So I wrote it this way.   I want to make one more-- yes?  AUDIENCE: Should that say E psi?  PROFESSOR: Oh yes, thank you very much. ", " Thank you.   Now, the question is, can I move this p close to the psi. ", " Opinions?   Yes? ", "AUDIENCE: Are you asking if it's just a constant?  PROFESSOR: Correct, p is a constant.  p hat is not a constant.  Derivatives are not.  But p at this moment is a number.  So it doesn't care about the derivatives. ", "And it goes in.  So I'll write it as 1 over 2m h/i d dx,  and here, output p psi, where is that number. ", "But now, p psi, I can write it as whatever it is,  which is h/i d dx, and p psi is again, h/i d dx psi. ", "So here we go.  We have obtained, and let me write the equation  in slightly reversed form.  Minus, because of the two i's, 1 over 2m, two partials ", "derivatives is a second order partial derivative on psi,  h bar squared over 2m d second dx psi. ", "That's the whole right-hand side, is equal to E psi.  ", "So the number E times psi is this.  So we could call this thing the energy operator. ", "", "And this is the energy operator.   And it has the property that the energy operator acting ", "on this wave function is, in fact, equal  to the energy times the wave function.   So this state again is an energy eigenstate. ", "Energy operator on the state is the energy  times the same state.  So psi is an energy eigenstate, or a state of definite energy, ", "or an energy eigenstate with energy,  E. I can make it clear for you that, in fact, this energy  operator, as you've noticed, the only thing ", "that it is is minus h squared over 2m d second dx squared.  But where it came from, it's clear ", "that it's nothing else but 1 over 2m p hat squared,  because p hat is indeed h/i d dx. ", "So if you do this computation.  How much is this?  This is A p hat times p hat, that's p hat squared.  And that's h/i d dx h/i d dx. ", "X And that gives you the answer.  So the energy operator is p hat squared over 2m. ", " All right, so actually, at this moment,  we do have a Schrodinger equation, for the first time. ", "If we combine the top line over there.  I h bar d dt of psi is equal to E psi, ", "but E psi I will write it as minus h squared over 2m d  second dx squared psi. ", " PROFESSOR: This is a wonderful differential equation,  because it carries a lot of information. ", "If you put this psi, it's certainly  going to be a solution.  But more than that, it's going to tell you  the relation between k and omega. ", "So if you try your--  we seem to have gone around in circles.  But you've obtained something very nice.  First, we claim that that's a solution of that equation ", "and has the deep information about it.  So if you try again, psi equal e to the ikx minus i omega t, ", "what do we get?  On the left hand side, we get ih minus i omega psi. ", "And on the right hand side, we get  minus h squared over 2m and two derivatives with respect to x.  And that gives you an ik times and other ik. ", "So ik squared times psi.   And the psis cancel from the two sides of the equation. ", "And what do we get here? h bar omega.  It's equal to h squared k squared over 2m, which  is e equal p squared over 2m. ", " So it does the whole job for you.  That differential equation is quite smart. ", "It admits these as solutions.   Then, this will have definite momentum.  It will have definite energy.  But even more, when you try to see if you solve it, ", "you find the proper relation between the energy  and the momentum that tells you you have a particle.  So this is an infinitely superior version ", "of that claim that that is a plane wave that exists.  Because for example, another thing that you have here  is that this equation is linear. ", "Psi appears linearly, so you can form solutions  by superposition.  So the general solution, now, is not just this. ", "This is a free particle Schrodinger equation.  And you might say, well, the most general solution must ", "be that, those plane waves.  But linearity means that you can compose those plane waves  and add them.  And if you can add plane waves by Fourier theorem, ", "you can create pretty much all the things you want.  And if you have this equation, you  know how to evolve free particles.  Now, you can construct a wave packet of a particle ", "and evolve it with the Schrodinger equation  and see how the wave packet moves and does its thing.  All that is now possible, which was not  possible by just saying, oh, here is another wave. ", "You've worked back to get an equation.  And this is something that happens in physics  all the time.  And we'll emphasize it again in a few minutes. ", "You use little pieces of evidence  that lead you-- perhaps not in a perfectly logical way,  but in a reasonable way-- to an equation. ", "And that equation is a lot smarter  than you and all the information that you put in.  That equation has all kinds of physics.  Maxwell's equations were found after doing a few experiments. ", "Maxwell's equation has everything in it,  all kinds of phenomena that took years and years to find.  So it's the same with this thing.  And the general solution of this equation ", "would be a psi of x and t, which would be  a superposition of those waves.  So you would put an e to the ikx minus i omega t. ", "I will put omega of k because that's what it is.  Omega is a function of k.  And that's what represents our free particles-- omega of kt. ", "And this is a solution.  But so will be any superposition of those solutions.  And the solutions are parametrized by k.  You can choose different momenta and add them. ", "So I can put a wave with one momentum  plus another wave with another momentum,  and that's perfectly OK.  But more generally, we can integrate. ", "And therefore, we'll write dk maybe from minus infinity  to infinity.  And we'll put a phi of k, which can be anything that's not part ", "of the differential equation.  Now, this is the general solution.  You might probably say, wow, how do we know that? ", "Well, I suggest you try it.  If you come here, the ddt will come in.  We'll ignore the k. ", "Ignore this.  And just gives you the omega factor here.  That ddx squared-- we'll ignore, again, all these things,  and give you that.  From the relation omega minus k equals 0, you'll get the 0. ", "And therefore, this whole thing solves  the Schrodinger equation-- solves the Schrodinger  equation.  ", "So this is very general.  And for this, applies what we said yesterday,  talking about the velocity of the waves. ", "And this wave, we proved yesterday,  that moves with a group velocity,  v group, which was equal to d omega dk at some k0, ", "if this is localized at k0.  Otherwise, you can't speak of the group  velocity this thing will not have a definite group velocity. ", "And the omega dk--  And you have this relation between omega and k,  such a to way that this is the evp, as we said yesterday. ", "And this is ddp of b squared over 2m,  which is p over m, which is what we call  the velocity of the particle. ", "So it moves with the proper velocity, the group velocity.  ", "That's actually a very general solution.  We'll exploit it to calculate all kinds of things.  A few remarks that come from this equation.  ", "Remarks.   1, psi cannot be a real.  ", "And you can see that because if psi was real,  the right hand side would be real.  This derivative would be real because the relative  of a real function is a real function. ", "Here you have an imaginary number.  So structurally, it is forbidden to have full wave  functions that are real.  I call these full wave functions because we'll ", "talk sometime later about time independent wave functions.  But the full wave function cannot be real.  Another remark is that this is not the wave ", "equation of the usual type--  not a usual wave equation. ", "And what a usual wave equation is something  like d second phi dx squared minus 1 over v  squared d second phi dt squared equals zero. ", "That's a usual wave equation.  And the problem with that wave equation  is that it has real solutions.  Solutions, phi that go like functions of x minus ", "is vt, plus minus x over vt.  And we cannot have those real solutions.  So we managed to get a wave, but not from a usual wave equation. ", "This, waves also all move with some same velocity,  velocity, v, of the wave.  These waves don't do that.  They have a group velocity. ", "It's a little bit different situation.  And what has happened is that we still  kept the second derivative, with respect to x.  But in time, we replaced it by first derivative. ", "And we put an i.   PROFESSOR: ih bar d psi dt equal E ", "psi where E hat is equal to p squared over 2m, the operator.  That is the Schrodinger equation. ", "The free particle Schrodinger equation--  you should realize it's the same thing as this.  Because p is h bar over i ddx. ", "And now Schrodinger did the kind of obvious thing to do.  He said, well, suppose I have a particle moving in a potential, ", "a potential V of x and t--  potential.   Then the total energy is kinetic energy plus potential energy. ", " So how about if we think of the total energy operator. ", "And here is a guess.  We'll put the just p squared over 2m, what we had before.  That's the kinetic energy of a particle. ", "But now add plus V of x and t, the potential. ", "That is reasonable from your classical intuition.  The total energy is the sum of them.  But it's going to change the Schrodinger equation  quite substantially. ", "Now, most people, instead of calling this  the energy operator, which is a good name, ", "have decided to call this the Hamiltonian.  So that's the most popular name for this thing.  This is called the Hamiltonian H. ", "And in classical mechanics, the Hamiltonian  represents the energy expressed in terms  of position and momenta.  That's what the Hamiltonian is, and that's ", "roughly what we have here.  The energy is [? in ?] [? terms ?] [? of ?] momenta  and position.  And we're going to soon be getting to the position ", "operator, therefore.  So this is going to be the Hamiltonian.  And we'll put the hat as well.  So Schrodinger's inspiration is to say, well, ", "this is going to be H hat.  And I'm going to say that ih bar d psi dt is equal to H hat psi. ", "Or equivalently, ih bar ddt of psi of x and t is equal  to minus h squared over 2m, [? v ?] [? second ?] dx ", "squared--  that's the p squared over 2m--  plus V of x and t, all multiplying psi. ", " This is it.   This is the full Schrodinger equation. ", " So it's a very simple departure.  You see, when you discover the show  that the equation for a free particle, adding the energy ", "was not that difficult. Adding the potential energy was OK.  We just have to interpret this.  And maybe it sounds to you a little surprising ", "that you multiply this by psi.  But that's the only way it could be to be a linear equation.  It cannot be that psi is acted by this derivative, ", "but then you add v.  It would not be a linear equation.  And we've realize that the structure of the Schrodinger  equation is d psi dt is equal to an energy operator times psi. ", "The whole game of quantum mechanics  is inventing energy operators, and then solving  these equations, then see what they are. ", "So in particular, you could invent a potential  and find the equations.  And, you see, it looks funny.  You've made a very simple generalization. ", "And now you have an equation.  And now you can put the potential for the hydrogen atom  and calculate, and see if it works.  And it does.  So it's rather unbelievable how very simple generalizations ", "suddenly produce an equation that  has the full spectrum of the hydrogen atom.  It has square wells, barrier penetration, everything.  All kinds of dynamics is in that equation. ", "So we're going to say a few more things about this equation now.  And I want you to understand that the V, at this moment, ", "can be thought as an operator.  This is an operator, acts on a wave  function to give you a function.  This is a simpler operator. ", "It's a function of x and t.  And multiplying by a function of x and t gives you  a function of x and t.  So it is an operator.  Multiplying by a given function is an operator. ", "It changes all the functions.  But it's a very simple one.  And that's OK, but V of x and t should ", "be thought as an operator.  ", "So, in fact, numbers can be operator.  Multiplication by a number is an operator.  It adds on every function and multiplies it by a number, ", "so it's also an operator.  But x has showed up.  So it's a good time to try to figure out what  x has to do with these things. ", "So that's what we're going to do now.   Let's see what's x have to do with things. ", "OK, so functions of x, V of x and t  multiplied by wave functions, and you think of it  as an operator.  So let's make this formal. ", "Introduce an operator, X hat, which, ", "acting on functions of x, multiplies them by x. ", "So the idea is that if you have the operator X hat acting  on the function f of x, it gives you ", "another function, which is the function x times f of x--  multiplies by x.  And you say, wow, well, why do you ", "have to be so careful in writing something so obvious?  Well, it's a good idea to do that,  because otherwise you may not quite ", "realize there's something very interesting happening  with momentum and position at the same time,  as we will discover now.  So we have already found some operators. ", "We have operators P, x, Hamiltonian,  which is p squared over 2m. ", "And now you could put V of x hat t.  You know, if here you put V of x hat, anyway, ", "whatever x hat does is multiplied by x.  So putting V of x hat here--  you may want to do it, but it's optional.  I think we all know what we mean by this. ", "We're just multiplying by a function of x.  Now when you have operators, operators act on wave functions ", "and give you things.  And we mentioned that operators are associated  or analogs of matrices.  And there's one fundamental property of matrices. ", "The order in which you multiply them makes a difference.  So we've introduced two operators, p and x. ", "And we could ask whether the order of multiplication  matters or not.  And this is the way Heisenberg was lead to quantum mechanics. ", "Schrodinger wrote the wave equation.  Heisenberg looked at operators and commutation relations  between them.  And it's another way of thinking of quantum mechanics ", "that we'll use.  So I want to ask the question, that if you have p and x  and you have two operators acting on a wave function, ", "does the order matter, or it doesn't matter?  We need to know that.  This is the basic relation between p and x.  So what is the question? ", "The question is, if I have--   I'll show it like that--  x and p acting on a wave function, phi, ", "minus px acting on a wave function, do I get 0? ", "Do I get the same result or not?   This is our question. ", "We need to understand these two operators  and see how they are related.  So this is a very good question.  So let's do that computation. ", " It's, again, one of those computation that  is straightforward. ", "But you have to be careful, because at every stage,  you have to know very well what you're doing.  So if you have two operators like a and b ", "acting on a function, the meaning of this  is that you have a acting on what b acting on phi gives you. ", "That's what it means to have two things acting.  Your first act with the thing on the right.  You then act on the other one.  So let's look at this thing--  xp phi minus px phi. ", "So for the first one, you would have  x times p hat on phi minus p hat times x on phi, phi of x and t ", "maybe--  phi of x and t.   OK, now what do we have? ", "We have x hat acting on this.  And this thing, we already know what it is--  h over i ddx of phi of x and t-- ", " minus p hat and x, acting on phi, ", "is little x phi of x and t.   Now this is already a function of x and t. ", "So an x on it will multiply it by x.  So this will be h over i x ddx of phi. ", "It just multiplies it by x at this moment--  minus here we have h bar over i ddx of x phi. ", " And now you see that when this derivative acts on phi, ", "you get a term that cancels this.   But when it acts on x, it gives you an extra term. ddx  of x is minus h over i phi-- ", " or ih phi.  ", "So the derivative acts on x or an phi.  When it acts on phi, gives you this term.  When it acts on x, gives you the thing that is left over.  So actually, let me write this in a more clear way. ", "If you have an operator, a linear operator A  plus B acting on a function phi, that's A phi plus B phi. ", "You have linear operators like that.  And we have these things here.  So this is actually equal to x hat p hat minus p hat ", "x hat on phi.   That's what it means when you have operators here. ", "So look what we got, a very surprising thing.  xp minus px is an operator.  It wants to act on function.  So we put a function here to evaluate it. ", "And that was good.  And when we evaluate it, we got a number times this function.  So I could say-- ", "I could forget about the phi.   I'm simply right that xp minus px is equal to ih bar. ", "And although it looks a little funny, it's perfectly correct.  This is an equality between operators--  equality between operators. ", "On the left-hand side, it's clear that it's an operator.  On the right-hand side, it's also an operator,  because a number acts as an operator on any function it ", "multiplies by it.  So look what you've discovered, this commutator.  And that's a notation that we're going  to use throughout this semester, the notation of the commutator. ", "Let's introduce it here.  ", "So if you have two operators, linear operators,  we define the commutator to be the product ", "in the first direction minus the product in the other direction.  This is called the commutator of A and B. ", "So it's an operator, again, but it shows you  how they are non-trivial, one with respect to the other.  This is the basis, eventually, of the uncertainty principle. ", "x and p having a commutator of this type  leads to the uncertainty principle.  So what did we learn?  We learned this rather famous result, ", "that the commutator of x and p in quantum mechanics is ih bar.  PROFESSOR: This is very important.  This is the beginning of the uncertainty principle, ", "the matrix formulation of quantum mechanics,  and all those things.  I want to just tabulate the information of matrices.  We have an analog, so we have operators. ", " And we think of them as matrices.  ", "Then in addition to operators, we have wave functions.   And we think of them as vectors. ", "The operators act on the wave functions or functions,  and matrices act on vectors.  We have eigenstate sometimes and eigenvectors. ", " So matrices do the same thing. ", "They don't necessarily commute.  There are very many examples of that.  I might as well give you a little example ", "that is famous in the theory of spin, spin 1/2.  There is the Pauli matrices.  Sigma 1 is equal to 1, 1, 0, 0. ", "Sigma 2 is 0 minus i, i 0, and sigma 3 is 1 minus 1, 0, 0. ", "And a preview of things to come--  the spin operator is actually h bar over 2 sigma. ", "And you have to think of sigma as having three components.  That's where it is.  Spins will be like that.  We won't have to deal with spins this semester. ", "But there it is, that spin 1/2.  Somehow these matrices encode spin 1/2.  And you can do simple things, like sigma 1 times sigma 2. ", "0, 1, 1, 0 times 0 minus i, i, 0.  Let's see if I can get this right. ", "i, 0, 0 minus i.  And you can do sigma 2 sigma 1 0 minus i, i 0, 0, 1, 1, ", "0 equals minus i, 0, 0, i, i. ", "So I can go ahead here.  ", "And therefore, sigma 1 commutator with sigma 2  is equal to sigma 1, sigma 2 minus sigma 2, sigma 1. ", "And you can see that they're actually the same up to a sign,  so you get twice.  So you get 2 times i 0, 0 minus i. ", "And this is 2i times 1 minus 1, 0, 0.  And that happens to be the sigma 3 matrix.  So sigma 1 and sigma 2 is equal to 2i sigma 3. ", " These matrices talk to each other.  And you would say, OK, these matrices commute ", "to give you this matrix.  This thing commutes to give you a number so that surely it's  a lot easier.  You couldn't be more wrong. ", "This is complicated, extraordinarily complicated  to understand what this means.  This is very easy.  This is 2 by 2 matrices that you check. ", "In fact, you can write matrices for x and p.  This correspondence is not just an analogy. ", "It's a concrete fact.  You will learn-- not too much in this course, but in 805--  how to write matrices for any operator.  They're called matrix representations. ", "And therefore, you could ask how does the matrix for x look.  How does the matrix for p look?   And the problem is these matrices ", "have to be infinite dimensional.  It's impossible to find two matrices whose  commutator gives you a number.  Something you can prove in math is actually not difficult. ", "You will all prove it through thinking a little bit.  There's no two matrices that commute to give you a number.  On the other hand, very easy to have  matrices that commute to give you another matrix. ", "So this is very strange and profound and interesting,  and this is much simpler.  Spin 1/2 is much simpler. ", "That's why people do quantum computations.  They're working with matrices and simple stuff,  and they go very far.  This is very difficult. x and p is really complicated. ", "But that's OK.  The purpose of this course is getting  familiar with those things.  So I want to now generalize this a little bit more ", "to just give you the complete Schrodinger  equation in three dimensions.  So how do we work in three dimensions,  three-dimensional physics? ", " There's two ways of teaching 804--  it's to just do everything in one dimension, and then  one day, 2/3 of the way through the course-- ", "well, we live in three dimensions,  and we're going to add these things.  But I don't want to do that.  I want to, from the beginning, show you  the three-dimensional thing and have ", "you play with three-dimensional things  and with one-dimensional things so that you don't get  focused on just one dimension.  The emphasis will be in one dimension for a while, ", "but I don't want you to get too focused on that.  So what did we have with this thing?  Well, we had p equal h bar over i d dx. ", "But in three dimensions, that should be the momentum  along the x direction.  We wrote waves like that with momentum along the x direction.  And py should be h bar over i d dy, ", "and pz should be h bar over i d dz--  momentum in the x, y, and z direction. ", "And this corresponds to the idea that if you  have a wave, a de Broglie wave in three dimensions,  you would write this--  e to the i kx minus omega t, i omega t. ", " And the momentum would be equal to h bar k vector, ", "because that's how the plane wave works.  That's what de Broglie really said.  He didn't say it in one dimension.  Now, it may be easier to write this as p1 equal h bar over i d ", "dx1, p2 h bar over i d dx2, and p3 h bar over i d dx3 ", "so that you can say that all these three things are Pi  equals h bar over i d dxi--  and maybe I should put pk, because the i and the i ", "could get you confused--  with k running from 1 to 3.  ", "So that's the momentum.  They're three momenta, they're three coordinates.  In vector notation, the momentum operator ", "will be h bar over i times the gradient.  You know that the gradient is a vector operator because d dx,  d dy, d dz. ", "So there you go.  The x component of the momentum operators,  h bar over i d dx, or d dx1, d dx2, d dx3.  So this is the momentum operator. ", "And if you act on this wave with the momentum operator,  you take the gradient, you get this--  so p hat vector. ", "Now here's a problem.  Where do you put the arrow?  Before or after the hat?  I don't know.  It just doesn't look very nice either way.  The type of notes I think we'll use for vectors ", "is bold symbols so there will be no proliferation of vectors  there.  So anyway, if you have this thing being the gradient acting ", "on this wave function, e to the i kx minus i omega  t, that would be h over i, the gradient, ", "acting on a to the i kx vector minus i omega t.  And the gradient acting on this-- this is a vector-- ", "actually gives you a vector.  So you can do component by component,  but this gives you i k vector times the same wave function. ", " So you get hk, which is the vector momentum times the wave  function.  ", "So the momentum operator has become the gradient.  This is all nice.  So what about the Schrodinger equation ", "and the rest of these things?  Well, it's not too complicated.  ", "We'll say one more thing.  So the energy operator, or the Hamiltonian,  will be equal to p vector hat squared over 2m plus ", "a potential that depends on all the coordinates x and t,  the three coordinates.  Even the potential is radial, like the hydrogen atom, ", "is much simpler.  There are conservation laws.  Angular momentum works nice.  All kinds of beautiful things happen.  If not, you just leave it as x and p. ", "And now what is p hat squared?  Well, p vector hat squared would be h bar over--  well, I'll write this-- p vector hat dotted with p vector hat. ", "And this is h over i gradient dotted with h over i  gradient, which is minus h squared Laplacian. ", " So your Schrodinger equation will  be ih bar d psi dt is equal to the whole Hamiltonian, which ", "will be h squared over 2m.  Now Laplacian plus v of x and t multiplied ", "by psi of x vector and t.   And this is the full three-dimensional Schrodinger ", "equation.   So it's not a new invention.  If you invented the one-dimensional one,  you could have invented the three-dimensional one as well. ", "The only issue was recognizing that the second dx squared now  turns into the full Laplacian, which is a very sensible thing ", "to happen.  Now, the commutation relations that we had here before--  we had x with p is equal to ih bar. ", "Now, px and x failed to commute, because d dx and x,  they interact.  But px will commute with y. ", "y doesn't care about x derivative.  So the p's failed to commute.  They give you a number with a corresponding coordinate.  So you have the i-th component of the x operator and the j-th ", "component of the p operator--  these are the components--  give you ih bar delta ij, where delta ij ", "is a symbol that gives you 1 if i is equal to j  and gives you 0 if i is different from j. ", "So here you go.  X and px is 1 and 1.  Delta 1, 1 is 1.  So you get ih bar.  But if you have x with py or p2, you ", "would have delta 1, 2, and that's 0,  because the two indices are not the same.  So this is a neat way of writing nine equations. ", "Because in principle, I should give you  the commutator of x with px and py and pc,  y with px, py, pc, and z with px, py, pc. ", "You're seeing that, in fact, x just  talks to px, y talks to py, z talks to pz.  So that's it for the Schrodinger equation. ", "Our goal is going to be to understand this equation.  So our next step is to try to figure out  the interpretation of this psi.  We've done very nicely by following these things. ", "We had a de Broglie wave.  We found an equation.  Which invented a free Schrodinger equation.  We invented an interacting Schrodinger equation.  PROFESSOR: interpretation of the wave function. ", " --pretation--   the wave function. ", " So you should look at what the inventor said.  So what did Schrodinger say? ", "Schrodinger thought that psi represents  particles that disintegrate.  You have a wave function.  And the wave function is spread all over space, ", "so the particle has disintegrated completely.  And wherever you find more psi, more of the particle is there. ", "That was his interpretation.   Then came Max Born.  He said, that doesn't look right to me. ", "If I have a particle, but I solve the Schrodinger equation.  Everybody started solving the Schrodinger equation.  So they solved it for a particle that hits a Coulomb potential. ", "And they find that the wave function falls off  like 1 over r.   OK, the wave function falls off like 2 over r.  So is the particle disintegrating? ", "And if you measure, you get a little bit of the particle  here?  No.  Max Born said, we've done this experiment.  The particle chooses some way to go. ", "And it goes one way, and when you measure,  you get the full particle.  The particle never disintegrates.   So Schrodinger hated what Max Born said. ", "Einstein hated it.  But never mind.  Max Born was right.  Max Born said, it represents probabilities. ", "And why did they hate it?  Because suddenly you lose determinism.  You can just talk about probability.  So that was sort of funny.  And in fact, neither Einstein nor Schrodinger ", "ever reconciled themselves with the probabilistic  interpretation.  They never quite liked it.  It's probably said that the whole Schrodinger cat ", "experiment was a way of Schrodinger  to try to say how ridiculous the probability interpretation was.  Of course, it's not ridiculous. ", "It's right.  And the important thing is summarized,  I think, with one sentence here.  I'll write it.  Psi of x and t does not tell how much of the particle-- ", " is at x at time t.  ", "But rather--   what is the probability--   probability-- ", " --bility--   to find it--   at x at time t. ", "So in one sentence, the first clause  is what Schrodinger said, and it's not that.  It's not what fraction of the particle you get, ", "how much of the particle you get.  It's the probability of getting.  But that requires--   a little more precision. ", "Because if a particle can be anywhere,  the probability of being at one point, typically, will be 0.  It's a continuous probability distribution. ", "So the way we think of this is we say, we have a point x.  Around that point x, we construct a little cube.  ", "d cube x.  And the probability-- probability dp,  the little probability to find the particle at xt in the cube, ", "within the cube--   the cube--   is equal to the value of the wave function at that point. ", "Norm squared times the volume d cube x.   So that's the probability to find the particle ", "at that little cube.  You must find the square of the wave function  and multiply by the little element of volume.  So that gives you the probability distribution. ", "And that's, really, what the interpretation means.  So it better be, if you have a single particle-- ", "particle, it better be that the integral all over space--  all over space-- of psi squared of x and t squared ", "must be equal to 1.  Because that particle must be found somewhere.  And the sum of the probabilities to be found everywhere ", "must add up to 1.  So it better be that this is true.  And this poses a set of difficulties ", "that we have to explore.  Because you wrote the Schrodinger equation.  And this Schrodinger equation tells you  how psi evolve in time.  ", "Now, a point I want to emphasize is that the Schrodinger  equation says, suppose you know the wave function  all over space.  You know it's here at some time t0. ", "The Schrodinger equation implies that that determines  the wave function for any time.  Why?  Because if you know the wave function throughout x, ", "you can calculate the right hand side  of this equation for any x.  And then you know how psi changes in time.  And therefore, you can integrate with your computer ", "the differential equation and find the wave function  at a later time all over space, and then at a later time.  So knowing the wave function at one time ", "determines the wave function at all times.   So we could run into a big problem, which is--  suppose your wave function at some time t0 ", "satisfies this at the initial time.  Well, you cannot force the wave function to satisfy it at any  time. ", "Because the wave function now is determined by the Schrodinger  equation.  So you have the possibility that you normalize the wave function  well.  It makes sense at some time. ", "But the Schrodinger equation later, by time evolution,  gives you another thing that doesn't  satisfy this for all times.  So what we will have to understand next time ", "is how the Schrodinger equation does the right thing  and manages to make this consistent.  If it's a probability at some time, at a later time "], "vid_duration": [11.73, 11.16, 13.26, 12.87, 13.29, 13.39, 13.49, 12.69, 11.85, 10.65, 10.74, 11.37, 11.05, 14.79, 16.58, 13.95, 10.78, 10.89, 10.29, 20.03, 11.27, 12.14, 13.09, 10.23, 10.74, 10.482, 10.238, 13.38, 11.15, 13.29, 10.98, 10.01, 16.37, 10.77, 11.36, 11.33, 12.16, 10.5, 12.27, 12.75, 10.45, 13.109, 10.341, 11.78, 16.236, 12.624, 11.01, 14.31, 14.73, 11.28, 11.07, 10.86, 10.352, 10.198, 13.845, 12.255, 11.42, 19.26, 11.22, 13.99, 10.99, 12.63, 16.67, 14.64, 11.46, 10.98, 10.995, 12.452, 13.623, 10.28, 19.372, 10.028, 11.17, 10.16, 11.4, 16.435, 10.915, 11.85, 15.73, 19.07, 16.23, 11.549, 11.871, 12.532, 11.308, 18.76, 16.17, 26.14, 12.78, 10.96, 13.36, 15.23, 11.21, 11.32, 16.08, 11.48, 10.633, 13.27, 11.9, 13.08, 14.47, 11.76, 11.97, 14.47, 10.58, 13.11, 12.92, 14.09, 11.232, 12.428, 10.85, 12.46, 12.51, 13.26, 10.61, 12.08, 14.61, 15.33, 12.91, 12.29, 11.07, 12.66, 11.41, 10.94, 13.45, 11.16, 12.23, 17.16, 10.56, 12.71, 10.97, 13.36, 12.175, 11.915, 10.74, 12.39, 12.9, 11.12, 15.01, 15.69, 14.87, 12.12, 12.78, 12.013, 12.81, 12.26, 14.11, 15.735, 12.805, 10.6, 11.37, 11.47, 10.2, 13.91, 11.7, 11.01, 14.48, 13.41, 15.12, 11.11, 15.215, 11.935, 10.604, 10.516, 17.63, 10.64, 10.01, 15.66, 14.78, 13.04, 10.28, 12.71, 11.67, 14.37, 10.62, 12.85, 14.45, 11.95, 14.53, 23.83, 10.2, 10.75, 12.69, 12.84, 11.57, 11.75, 11.82, 10.5, 13.23, 10.15, 11.86, 10.33, 11.61, 11.47, 13.51, 10.6, 10.77, 11.1, 10.12, 11.15, 14.05, 17.37, 15.395, 11.945, 10.0, 10.81, 15.08, 14.39, 11.326, 10.784, 14.26, 11.1, 13.47, 13.53, 12.65, 17.98, 12.19, 10.08, 18.45, 14.9, 10.32, 15.57, 11.86, 10.61, 15.88, 13.41, 14.52, 12.153, 11.2, 10.72, 12.13, 15.94, 12.49, 10.03, 10.812, 12.638, 10.5, 10.77, 12.99, 10.79, 13.34, 10.8, 18.01, 10.53, 12.09, 15.51, 15.72, 12.01, 11.01, 12.52, 12.37, 11.26, 13.83, 12.24, 11.99, 13.42, 16.67, 10.635, 12.415, 11.64, 10.74, 13.23, 15.84, 11.4, 16.41, 11.06, 16.995, 11.544, 13.261, 11.87, 13.66, 10.85, 12.83, 13.37, 13.74, 13.31, 11.16, 11.79, 12.75, 12.248, 11.482, 20.57, 18.0, 12.22, 10.66, 17.82, 11.11, 15.21, 11.65, 11.221, 13.349, 10.8, 11.6, 10.97, 19.64, 15.51, 10.67, 12.99, 10.196, 10.234, 16.55, 13.8, 12.378, 11.031, 12.21, 12.491, 10.779, 10.5, 11.161, 11.71, 10.149, 12.101, 11.129, 12.431, 10.46, 10.23, 21.109, 11.851, 10.02, 15.609, 11.911, 11.43, 10.82, 11.809, 14.201, 15.91, 10.12, 11.729, 10.651, 19.28, 10.29, 11.29, 11.66, 14.76, 10.83, 12.66, 12.84, 15.27, 10.32, 10.859, 11.16, 9.202], "stet": [[0, 11.73], [11.73, 22.89], [22.89, 36.15], [36.15, 49.019999999999996], [49.019999999999996, 62.309999999999995], [62.309999999999995, 75.69999999999999], [75.69999999999999, 89.18999999999998], [89.18999999999998, 101.87999999999998], [101.87999999999998, 113.72999999999998], [113.72999999999998, 124.37999999999998], [124.37999999999998, 135.11999999999998], [135.11999999999998, 146.48999999999998], [146.48999999999998, 157.54], [157.54, 172.32999999999998], [172.32999999999998, 188.90999999999997], [188.90999999999997, 202.85999999999996], [202.85999999999996, 213.63999999999996], [213.63999999999996, 224.52999999999997], [224.52999999999997, 234.81999999999996], [234.81999999999996, 254.84999999999997], [254.84999999999997, 266.11999999999995], [266.11999999999995, 278.25999999999993], [278.25999999999993, 291.3499999999999], [291.3499999999999, 301.5799999999999], [301.5799999999999, 312.31999999999994], [312.31999999999994, 322.8019999999999], [322.8019999999999, 333.0399999999999], [333.0399999999999, 346.4199999999999], [346.4199999999999, 357.5699999999999], [357.5699999999999, 370.8599999999999], [370.8599999999999, 381.8399999999999], [381.8399999999999, 391.8499999999999], [391.8499999999999, 408.2199999999999], [408.2199999999999, 418.9899999999999], [418.9899999999999, 430.3499999999999], [430.3499999999999, 441.6799999999999], [441.6799999999999, 453.8399999999999], [453.8399999999999, 464.3399999999999], [464.3399999999999, 476.6099999999999], [476.6099999999999, 489.3599999999999], [489.3599999999999, 499.8099999999999], [499.8099999999999, 512.9189999999999], [512.9189999999999, 523.2599999999999], [523.2599999999999, 535.0399999999998], [535.0399999999998, 551.2759999999998], [551.2759999999998, 563.8999999999999], [563.8999999999999, 574.9099999999999], [574.9099999999999, 589.2199999999998], [589.2199999999998, 603.9499999999998], [603.9499999999998, 615.2299999999998], [615.2299999999998, 626.2999999999998], [626.2999999999998, 637.1599999999999], [637.1599999999999, 647.5119999999998], [647.5119999999998, 657.7099999999998], [657.7099999999998, 671.5549999999998], [671.5549999999998, 683.8099999999998], [683.8099999999998, 695.2299999999998], [695.2299999999998, 714.4899999999998], [714.4899999999998, 725.7099999999998], [725.7099999999998, 739.6999999999998], [739.6999999999998, 750.6899999999998], [750.6899999999998, 763.3199999999998], [763.3199999999998, 779.9899999999998], [779.9899999999998, 794.6299999999998], [794.6299999999998, 806.0899999999998], [806.0899999999998, 817.0699999999998], [817.0699999999998, 828.0649999999998], [828.0649999999998, 840.5169999999998], [840.5169999999998, 854.1399999999999], [854.1399999999999, 864.4199999999998], [864.4199999999998, 883.7919999999998], [883.7919999999998, 893.8199999999998], [893.8199999999998, 904.9899999999998], [904.9899999999998, 915.1499999999997], [915.1499999999997, 926.5499999999997], [926.5499999999997, 942.9849999999997], [942.9849999999997, 953.8999999999996], [953.8999999999996, 965.7499999999997], [965.7499999999997, 981.4799999999997], [981.4799999999997, 1000.5499999999997], [1000.5499999999997, 1016.7799999999997], [1016.7799999999997, 1028.3289999999997], [1028.3289999999997, 1040.1999999999998], [1040.1999999999998, 1052.7319999999997], [1052.7319999999997, 1064.0399999999997], [1064.0399999999997, 1082.7999999999997], [1082.7999999999997, 1098.9699999999998], [1098.9699999999998, 1125.11], [1125.11, 1137.8899999999999], [1137.8899999999999, 1148.85], [1148.85, 1162.2099999999998], [1162.2099999999998, 1177.4399999999998], [1177.4399999999998, 1188.6499999999999], [1188.6499999999999, 1199.9699999999998], [1199.9699999999998, 1216.0499999999997], [1216.0499999999997, 1227.5299999999997], [1227.5299999999997, 1238.1629999999998], [1238.1629999999998, 1251.4329999999998], [1251.4329999999998, 1263.3329999999999], [1263.3329999999999, 1276.4129999999998], [1276.4129999999998, 1290.8829999999998], [1290.8829999999998, 1302.6429999999998], [1302.6429999999998, 1314.6129999999998], [1314.6129999999998, 1329.0829999999999], [1329.0829999999999, 1339.6629999999998], [1339.6629999999998, 1352.7729999999997], [1352.7729999999997, 1365.6929999999998], [1365.6929999999998, 1379.7829999999997], [1379.7829999999997, 1391.0149999999996], [1391.0149999999996, 1403.4429999999998], [1403.4429999999998, 1414.2929999999997], [1414.2929999999997, 1426.7529999999997], [1426.7529999999997, 1439.2629999999997], [1439.2629999999997, 1452.5229999999997], [1452.5229999999997, 1463.1329999999996], [1463.1329999999996, 1475.2129999999995], [1475.2129999999995, 1489.8229999999994], [1489.8229999999994, 1505.1529999999993], [1505.1529999999993, 1518.0629999999994], [1518.0629999999994, 1530.3529999999994], [1530.3529999999994, 1541.4229999999993], [1541.4229999999993, 1554.0829999999994], [1554.0829999999994, 1565.4929999999995], [1565.4929999999995, 1576.4329999999995], [1576.4329999999995, 1589.8829999999996], [1589.8829999999996, 1601.0429999999997], [1601.0429999999997, 1613.2729999999997], [1613.2729999999997, 1630.4329999999998], [1630.4329999999998, 1640.9929999999997], [1640.9929999999997, 1653.7029999999997], [1653.7029999999997, 1664.6729999999998], [1664.6729999999998, 1678.0329999999997], [1678.0329999999997, 1690.2079999999996], [1690.2079999999996, 1702.1229999999996], [1702.1229999999996, 1712.8629999999996], [1712.8629999999996, 1725.2529999999997], [1725.2529999999997, 1738.1529999999998], [1738.1529999999998, 1749.2729999999997], [1749.2729999999997, 1764.2829999999997], [1764.2829999999997, 1779.9729999999997], [1779.9729999999997, 1794.8429999999996], [1794.8429999999996, 1806.9629999999995], [1806.9629999999995, 1819.7429999999995], [1819.7429999999995, 1831.7559999999994], [1831.7559999999994, 1844.5659999999993], [1844.5659999999993, 1856.8259999999993], [1856.8259999999993, 1870.9359999999992], [1870.9359999999992, 1886.6709999999991], [1886.6709999999991, 1899.4759999999992], [1899.4759999999992, 1910.075999999999], [1910.075999999999, 1921.445999999999], [1921.445999999999, 1932.915999999999], [1932.915999999999, 1943.115999999999], [1943.115999999999, 1957.0259999999992], [1957.0259999999992, 1968.7259999999992], [1968.7259999999992, 1979.7359999999992], [1979.7359999999992, 1994.2159999999992], [1994.2159999999992, 2007.6259999999993], [2007.6259999999993, 2022.7459999999992], [2022.7459999999992, 2033.855999999999], [2033.855999999999, 2049.070999999999], [2049.070999999999, 2061.005999999999], [2061.005999999999, 2071.6099999999988], [2071.6099999999988, 2082.125999999999], [2082.125999999999, 2099.755999999999], [2099.755999999999, 2110.395999999999], [2110.395999999999, 2120.405999999999], [2120.405999999999, 2136.065999999999], [2136.065999999999, 2150.845999999999], [2150.845999999999, 2163.885999999999], [2163.885999999999, 2174.1659999999993], [2174.1659999999993, 2186.8759999999993], [2186.8759999999993, 2198.5459999999994], [2198.5459999999994, 2212.9159999999993], [2212.9159999999993, 2223.535999999999], [2223.535999999999, 2236.385999999999], [2236.385999999999, 2250.835999999999], [2250.835999999999, 2262.7859999999987], [2262.7859999999987, 2277.315999999999], [2277.315999999999, 2301.145999999999], [2301.145999999999, 2311.3459999999986], [2311.3459999999986, 2322.0959999999986], [2322.0959999999986, 2334.7859999999987], [2334.7859999999987, 2347.625999999999], [2347.625999999999, 2359.195999999999], [2359.195999999999, 2370.945999999999], [2370.945999999999, 2382.765999999999], [2382.765999999999, 2393.265999999999], [2393.265999999999, 2406.495999999999], [2406.495999999999, 2416.6459999999993], [2416.6459999999993, 2428.5059999999994], [2428.5059999999994, 2438.8359999999993], [2438.8359999999993, 2450.4459999999995], [2450.4459999999995, 2461.9159999999993], [2461.9159999999993, 2475.4259999999995], [2475.4259999999995, 2486.0259999999994], [2486.0259999999994, 2496.7959999999994], [2496.7959999999994, 2507.8959999999993], [2507.8959999999993, 2518.015999999999], [2518.015999999999, 2529.1659999999993], [2529.1659999999993, 2543.2159999999994], [2543.2159999999994, 2560.5859999999993], [2560.5859999999993, 2575.9809999999993], [2575.9809999999993, 2587.9259999999995], [2587.9259999999995, 2597.9259999999995], [2597.9259999999995, 2608.7359999999994], [2608.7359999999994, 2623.8159999999993], [2623.8159999999993, 2638.205999999999], [2638.205999999999, 2649.5319999999992], [2649.5319999999992, 2660.3159999999993], [2660.3159999999993, 2674.5759999999996], [2674.5759999999996, 2685.6759999999995], [2685.6759999999995, 2699.1459999999993], [2699.1459999999993, 2712.6759999999995], [2712.6759999999995, 2725.3259999999996], [2725.3259999999996, 2743.3059999999996], [2743.3059999999996, 2755.4959999999996], [2755.4959999999996, 2765.5759999999996], [2765.5759999999996, 2784.0259999999994], [2784.0259999999994, 2798.9259999999995], [2798.9259999999995, 2809.2459999999996], [2809.2459999999996, 2824.816], [2824.816, 2836.676], [2836.676, 2847.286], [2847.286, 2863.166], [2863.166, 2876.576], [2876.576, 2891.096], [2891.096, 2903.249], [2903.249, 2914.4489999999996], [2914.4489999999996, 2925.1689999999994], [2925.1689999999994, 2937.2989999999995], [2937.2989999999995, 2953.2389999999996], [2953.2389999999996, 2965.7289999999994], [2965.7289999999994, 2975.7589999999996], [2975.7589999999996, 2986.5709999999995], [2986.5709999999995, 2999.2089999999994], [2999.2089999999994, 3009.7089999999994], [3009.7089999999994, 3020.4789999999994], [3020.4789999999994, 3033.468999999999], [3033.468999999999, 3044.258999999999], [3044.258999999999, 3057.5989999999993], [3057.5989999999993, 3068.3989999999994], [3068.3989999999994, 3086.4089999999997], [3086.4089999999997, 3096.939], [3096.939, 3109.029], [3109.029, 3124.539], [3124.539, 3140.259], [3140.259, 3152.2690000000002], [3152.2690000000002, 3163.2790000000005], [3163.2790000000005, 3175.7990000000004], [3175.7990000000004, 3188.1690000000003], [3188.1690000000003, 3199.4290000000005], [3199.4290000000005, 3213.2590000000005], [3213.2590000000005, 3225.4990000000003], [3225.4990000000003, 3237.489], [3237.489, 3250.909], [3250.909, 3267.579], [3267.579, 3278.2140000000004], [3278.2140000000004, 3290.6290000000004], [3290.6290000000004, 3302.2690000000002], [3302.2690000000002, 3313.009], [3313.009, 3326.239], [3326.239, 3342.079], [3342.079, 3353.4790000000003], [3353.4790000000003, 3369.889], [3369.889, 3380.949], [3380.949, 3397.944], [3397.944, 3409.488], [3409.488, 3422.749], [3422.749, 3434.6189999999997], [3434.6189999999997, 3448.2789999999995], [3448.2789999999995, 3459.1289999999995], [3459.1289999999995, 3471.9589999999994], [3471.9589999999994, 3485.3289999999993], [3485.3289999999993, 3499.068999999999], [3499.068999999999, 3512.378999999999], [3512.378999999999, 3523.538999999999], [3523.538999999999, 3535.328999999999], [3535.328999999999, 3548.078999999999], [3548.078999999999, 3560.326999999999], [3560.326999999999, 3571.808999999999], [3571.808999999999, 3592.378999999999], [3592.378999999999, 3610.378999999999], [3610.378999999999, 3622.598999999999], [3622.598999999999, 3633.2589999999987], [3633.2589999999987, 3651.078999999999], [3651.078999999999, 3662.188999999999], [3662.188999999999, 3677.398999999999], [3677.398999999999, 3689.048999999999], [3689.048999999999, 3700.269999999999], [3700.269999999999, 3713.6189999999992], [3713.6189999999992, 3724.4189999999994], [3724.4189999999994, 3736.0189999999993], [3736.0189999999993, 3746.988999999999], [3746.988999999999, 3766.628999999999], [3766.628999999999, 3782.138999999999], [3782.138999999999, 3792.8089999999993], [3792.8089999999993, 3805.798999999999], [3805.798999999999, 3815.994999999999], [3815.994999999999, 3826.228999999999], [3826.228999999999, 3842.778999999999], [3842.778999999999, 3856.5789999999993], [3856.5789999999993, 3868.9569999999994], [3868.9569999999994, 3879.9879999999994], [3879.9879999999994, 3892.1979999999994], [3892.1979999999994, 3904.6889999999994], [3904.6889999999994, 3915.4679999999994], [3915.4679999999994, 3925.9679999999994], [3925.9679999999994, 3937.1289999999995], [3937.1289999999995, 3948.8389999999995], [3948.8389999999995, 3958.9879999999994], [3958.9879999999994, 3971.0889999999995], [3971.0889999999995, 3982.2179999999994], [3982.2179999999994, 3994.6489999999994], [3994.6489999999994, 4005.1089999999995], [4005.1089999999995, 4015.3389999999995], [4015.3389999999995, 4036.4479999999994], [4036.4479999999994, 4048.2989999999995], [4048.2989999999995, 4058.3189999999995], [4058.3189999999995, 4073.9279999999994], [4073.9279999999994, 4085.8389999999995], [4085.8389999999995, 4097.268999999999], [4097.268999999999, 4108.088999999999], [4108.088999999999, 4119.897999999999], [4119.897999999999, 4134.098999999999], [4134.098999999999, 4150.008999999999], [4150.008999999999, 4160.128999999999], [4160.128999999999, 4171.857999999999], [4171.857999999999, 4182.508999999999], [4182.508999999999, 4201.788999999999], [4201.788999999999, 4212.078999999999], [4212.078999999999, 4223.368999999999], [4223.368999999999, 4235.028999999999], [4235.028999999999, 4249.788999999999], [4249.788999999999, 4260.618999999999], [4260.618999999999, 4273.278999999999], [4273.278999999999, 4286.118999999999], [4286.118999999999, 4301.388999999999], [4301.388999999999, 4311.708999999999], [4311.708999999999, 4322.567999999999], [4322.567999999999, 4333.727999999999], [4333.727999999999, 4342.929999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1229, 1823, 2898, 3868, 4343]}
{"example_id": "mit035@@MIT8_04S16_lec04_300k", "text": [" BARTON ZWIEBACH: De Broglie, as we discussed last time, we  spoke about waves.  ", "Matter waves.   Because people thought, anyway light ", "is waves so the surprising thing that would  be that matters are waves.  So a free particle with momentum p can be associated to a wave-- ", " to a plane wave, in fact--  plane wave-- with wavelength lambda ", "equals Planck's constant over p.  So this wave is what eventually becomes a famous wave function. ", "So de Broglie was writing the example  or trying to write the example of what eventually would become  wave functions, and the equations for this wave ", "would become the Schrodinger equation.  So really, this is a pillar of quantum mechanics.  You're getting there when you talk about this wave. ", "So Schrodinger's equation is a wave equation for these matter  waves and this plane wave eventually  will become the wave function and there is ", "a Schrodinger equation for it.  ", "So it's a wave of what?  he was asking-- de Broglie had little idea what that wave was. ", "When you have waves, like electromagnetic waves,  you have polarization, you have directional properties,  the electric field points in some direction,  the wave is polarized. ", "Is there a same property for the wave function?  The answer is yes.  We'll have to wait a little in 8.04 to see it, ", "but it has to do with spin.  When the particles have spin, there  are directional properties of the wave  and typically, you use several wave functions ", "that correspond to directional components of this wave.  So photons are spin 1 particle electrons ", "or spin 1/2 particles, so there will be  directional properties to it.  But to begin with, let's consider cases  where this directional properties don't matter ", "so much, and for the case of electrons,  if the electrons have small velocities  or they are inside small magnetic fields  where some of these properties of the spin is important, ", "we can ignore that and work with a wave function that  will be a complex number.  So it will be a wave function-- we'll denote it by the letter ", "psi, capitol psi--  that depends on position and time,  and that's the wave function.  And to begin with, simplicity will be one of them, ", "and it's a complex number.   And it's just one wave function.  And the obvious questions about this wave function are, ", "is it measurable and what it's meaning is?  So is it measurable?  ", "And what is its meaning?   But to understand some of that-- in fact, ", "to get to realize that these waves are no ordinary waves,  we're going to think a little about what  it means to have a wave whose wavelength is inversely ", "proportional to the momentum of a particle.  That's certainly a strange statement  and probably these are strange waves as you will see. ", "And by understanding that these are strange waves,  we are ready to admit later on that the interpretation could  be somewhat surprising as well. ", "And the nature of this number is, again, a little strange  as you will see. ", "So all of that will come by just looking a little more in detail  at this formula of de Broglie and asking  a very simple question-- ", "you have this particle moving with some momentum  and I say, OK, it has this much wavelength.  How about the person?  If one of you is moving relative to me, like you usually ", "do with Einstein, these observers  that are boosted, but let's just do non-relativistic physics,  what is called the Galilean transformation, in which there ", "will be another observer moving with constant velocity  with respect to you and you and that other observer  compare the results on the momentum and the wavelength ", "and see if you find a reasonable agreement or things make sense.  So we're going to try to think of p is h over lambda. ", "And 2 pi's are very useful sometimes.  So you put an h over 2 pi here and a 2 pi ", "over lambda and you rewrite this in terms of quantities  that are a little more common--  one is h-bar and the other is called the wave number k. ", "So these are these two constants and this one  is called the wave number.  ", "The 2 pi's are all over the place.  If you have a wave with some frequency nu,  there's also a frequency omega, which is 2 pi nu. ", " So we're going to look at this wave,  and it has some momentum and some wave number, ", "therefore it has some wavelength,  and let's see-- if we compare things  between two different frames, what do we find?  So we'll put the frame S and a frame S ", "prime moving with some velocity plus v in the x direction. ", " So the setup is relatively common.  We'll have one frame here that's the S frame, ", "and it's the x-axis of the S frame.  And the S prime frame coincided with the S frame at time  equals 0-- now it's moving, so it's now over here, ", "it's S prime.  It has moved a distance of vt--  it's moving with velocity v and there's t. ", "And S prime has--  and x is x prime.  On this, we're going to write a few things. ", "We're going to say we have a particle of mass m.   It has velocity v underbar, otherwise ", "I'm going to get all my velocities confused.  So this velocity v is the velocity of the frame,  v underbar is the velocity of the particle, ", "and v underbar prime, because the velocity depends  on the frame of reference.  Similarly, it will have a momentum-- ", "and all the things we're doing are nonrelativistic,  so momentum p or p prime.  ", "Here is the particle.   And that's the position x prime with the particle. ", "And that's a position x of the particle.  So that's our system.  This particle is moving with some velocity over here, ", "and we're going to compare these observations.  So it's simple to write equations  to relate the coordinates. ", "So x prime, for example, is the value  of the corner at x of the particle minus the separation. ", "So x minus vt.   And I should say it here, we're assuming  that t prime is equal to t, which ", "is good nonrelativistically.  It's fairly accurate.  But that's the exact Galilean answer--  when you talk about Galilean transformations ", "and Galilean physics, it's very useful.  Even in condensed matter physics,  people write these days lots of papers about Galilean physics,  so when you have particles moving with low velocities, ", "it's accurate enough, so might as well consider it.  And these are the two ways you transform coordinates, ", "coordinates and time.  So from this, we can take a time derivative talking about  the particle-- so we have dx prime and dt prime or t, ", "it's your choice--  I guess I should put dt prime here,  dx/dt minus v, which means that the velocity v prime underbar ", "is equal to v underbar minus little v.  And that's what you expect. ", "The difference of velocities is given  by the subtraction of the velocity  that the frame is moving. ", "So if this particular has some high velocity with respect  to the lab frame with respect to this frame,  it will have a smaller velocity.  So this sine seems right. ", "And therefore, multiplying by m, you  get that p prime is equal to p minus mv. ", " So if you have that, we would have  that lambda prime, the de Broglie wavelength measured ", "by either running person, is equal to h over  p prime is equal to h over p minus mv, ", "and it's quite different, quite substantially different from h  over p, which is equal to the de Broglie wavelength seen ", "in the lab.  So these two de Broglie wavelengths  will differ very substantially.  ", "If this would be a familiar type of wave--  like a sound wave that propagates  in the medium, any kind of wave that propagates in a medium, ", "like a water wave or any wave of that type--  this would simply not happen.  In the case of those waves, you get a Doppler shift-- ", "omega is changed-- but the wavelength really  doesn't change.  The wavelength is almost like something  you look at when you take a picture ", "and whether you take a picture of the wave  as you run or you take a picture of the wave  as you are sitting still, you'll measure the same wavelength.  Let me convince you of that. ", "It's an opportunity to just do a little more  formal transformations, because these  are going to be Galilean transformations,  simple transformations.  So our first observation is that the de Broglie wavelength ", "don't agree, which pretty much, I think, ", "intuitively is saying that if you could just sort of see  those waves and measure the distance between peaks,  they should agree, but they don't, so there's something ", "BARTON ZWIEBACH: Do normal wave analysis  to demonstrate that indeed these things should not quite happen.  So for that, so ordinary waves and Galilean transformations. ", "", "So when you have a wave, as you've probably have  seen many times before, the key object in the wave  is something called the phaze of the wave. ", "Phaze, the phaze.  And it's controlled by this quantity kx minus omega t. ", "k being the wave number, omega being the angular frequency  and we spoke about.  And the wave may be sine of that phaze or cosine of that phaze ", "or a linear combination of sines and cosines, or E to this wave,  any of those things could be your wave. ", "And whenever you have such a wave, what we say  is that the phaze of this wave is a Galilean invariant.  ", "Invariant.   What it means is that two people looking at this wave, ", "and they look at the point on this wave,  both people will agree on the value of the phaze, ", "because basically, the reality of the wave  is based on the phaze, and if you have, for example, cosine  of this phaze, the place where this cosine is 0 ", "is some of the phaze, and if the cosine is 0, the wave is 0,  and everybody should agree that the wave is 0 at that point.  So if you have a place where the wave has a maximum or a place ", "where the wave is 0, this is an ordinary wave,  everybody would agree that at that place you have a maximum  and in that place you have a 0.  So observers should agree on the value of this phaze. ", "It's going to be an invariant.  And we can rewrite this phaze in a perhaps more familiar way  by factoring the k, and then you have x minus omega over kt, ", "and this is 2 pi over lambda, x minus--  this quantity is called the velocity of the wave, ", "and we'll write it this way.   And I'll write in one last way-- ", "2 pi x over lambda minus 2 pi V over lambda t. ", "And this quantity is omega and this quantity is k.  ", "So this is our phaze.  And we've said that it's a Galilean invariant, so I  will say that S should see-- ", "the observer S prime should see the same phaze--  phaze-- as S. So phi prime, the phaze that S prime sees, ", "must be equal to phi when referring to the same point.  When referring to the same point at the same time. ", "", "Let's write this.  So phi prime should be equal to phi.  And phi, we've written there.  2 pi over lambda x minus Vt. ", " And this is so far so good, but we  want to write it in terms of quantities  that S prime measures. ", "So this x should be replaced by 2 pi  over lambda x prime plus Vt minus Vt like this. ", "And I could even do more if I wish.  I could put t prime here, because the t and t  primes are the same.  So phi prime, by the condition that these phazes agree, ", "it's given by this, which is by the relation  between the coordinates and times of the two frames, just  this quantity. ", "So we can rewrite this as 2 pi over lambda x prime minus 2  pi over lambda V 1 minus little v over capital V t prime. ", "I think I got the algebra right.  2 pi over lambda, the sine--  yes, I grouped those two terms and rewrote in that way. ", "So that is the phaze.  And therefore, we look at this phaze  and see, oh, whenever we have a wave,  we can read the wave number by looking ", "at the factor multiplying x, and we  can read the frequency by looking  at the factor multiplying t.  So you can do the same thing in this case ", "and read, therefore, that omega prime,  this whole quantity is this, omega prime. ", "And this is k prime, because they can  respond to the frame as prime.  So omega prime is equal to this 2 pi ", "V over lambda, which is omega, times 1  minus V over V. And k prime is equal to k ", "or, what I wanted to show, that lambda prime for a normal wave  is equal to lambda for ordinary wave moving in the medium. ", " So at this moment, one wonders, so what happened? ", "What have we learned?  Is that this wave function is not like a sound wave.  It's not like a water wave.  We're doing everything non-relativistic. ", "But still, we're seeing that you're not  expected to have agreement.  That is, if somebody looks at one wave function ", "and you look at the same wave function,  these two people will not agree on the value of the wave  function necessarily. ", "So the things that we conclude-- so the conclusions are  that waves are surprising. ", "So size are not directly measurable--   measurable-- because if you had a quantity for which you could ", "measure, like a sound wave or a water wave,  and you could measure aspects to it,  they should agree between different observables.  So this is going to be something that ", "is not directly measurable-- not all of psi can be measured.  Some of psi can be measured, and you're already  heard the hints of that. ", "Because we said any number that you multiply,  you cannot measure, and in the phase that you multiply,  you cannot measure.  So complex numbers can't be measured,  you measure real numbers. ", "So at the end of the day, these are not directly measurable,  per se.  The second thing is that they're not Galilean invariant, ", "and that sets the stage to that problem 6.  You see, the fact that this phaze that  controls these waves is Galilean invariant  led you to the quality of the wavelengths, ", "but these wavelengths don't do that.  The de Broglie wavelengths don't transform  as they would do for a Galilean invariant wave. ", "Therefore, this thing is not Galilean invariant,  and what does that mean?  That if you have two people and you  ask, what is the value of the wave function here at 103, ", "the two observers might give you a different complex number  for the wave function.  They will just not agree.  Not all is lost, because you will  find how their measurements can be compared. ", "That will be the task of the problem.  How-- if you have a wave function, how does your friend,  that is moving with some velocity,  measure the wave function?  What does this other person measure? ", "So the end result, if you have a point here at some time t,  the wave function psi of x and t is not  going to be the same as the wave function measured ", "by the prime observer at x prime t  prime, so this point is the point x and t or x prime and t  prime. ", "These are two different labels for the same point.  You're talking about the wave function  at the same point at the same time.  You still don't agree.  These two people will not agree. ", "If they agreed, this wave function  would have a simpler transformation law  with a wavelength that this can serve.  So by simply discussing the Galilean properties ", "of this wave, we're led to know that the de Broglie waves are  not like normal matter waves that propagate ", "PROFESSOR: We've talked a lot about de Broglie saying  that the wavelength is given by h over p.  But we have not said much yet about the frequency ", "of the waves.  So what is the frequency of those matter waves?  So what is the frequency--  ", "frequency--   of the matter waves.  ", "So de Broglie did answer that same question.  And the answer was obtained by analogy.  We have p equal h bar k. ", " And he said, well, just like the wavelength  is determined by the momentum, we'll have e equal h bar omega. ", "So the frequency-- so this equation  is the one that now completes the story.  Omega is equal to e over h bar.  ", "Fixes omega in terms of the energy.  And we're going to say a few things.  In fact, this will be an interesting digression ", "into an important subject about waves  that illustrates why this answer makes a lot of sense.  ", "And that's, really, all you can do at this moment.  This is a postulate of quantum mechanics.  That you do this thing, and with this, you  get quantum mechanics. ", "So the best thing we can do is to explain  why it makes sense in a number of ways,  and then hope that the theory that you built  makes full sense. ", "So I want to remind you about velocities of waves.  So if you have a wave now that it has k and omega-- ", "you have this thing. k minus omega, wave with a phase.   kx minus omega t. ", "Then there is something called the phase velocity.  ", "And it's given by omega over k.   It's the velocity in which the nodes and maxima of this plane ", "wave move.  So let's see if this makes some sense.  Omega over k is the same thing as e over p. ", " We're nonrelativistic, so let's continue.   1/2 mv squared over mv. ", "And this seems a little strange.  1/2--   v. So if I have a particle, you see,  this is matter waves of energy e and momentum p. ", "And e is 1/2 mv squared, the velocity of the particle.  p is equal to mv.  And now, somehow this wave seems to be ", "moving with half the speed of the particle.  That looks pretty bad.  What's going on?  ", "Well, this is the usual story with waves.  If the wave itself doesn't--  a wave, a plane wave carries no real information. ", "It's not the signal.  So many times when you try to represent the particle--  a little bit of information traveling-- representing it  with a plane wave is actually quite wrong. ", "You have to represent it with a wave packet.  And therefore, this phase wave velocity  being one half of the velocity of the particles ", "seems to just confirm the idea that, first, these waves are  a little strange.  And second, phase velocity is not very meaningful physically. ", "The velocity that this more meaningful is v group velocity.   And it's d omega dk evaluated at the value k that you're using. ", "k is a proxy for momentum.  So d omega dk may depend on k and omega.  So if it's d omega, dk is a function. ", "Which value should you use?  Well, the value at the k that you're propagating.   And this would be the same as d omega dk. ", " Is because of the constant separating-- the same as de vp.  ", "But what is the kinetic energy in terms of the momentum?  We wrote it last time.  p squared over 2m.  That's the kinetic energy expressed in terms of momentum. ", "So this is d dp of p squared over 2m.  ", "Write p equal mv and you'll recover the kinetic energy.  And this is just--  because of the 2--  p over m, which is the velocity of the particle. ", "And this is the reason people believe de Broglie.   De Broglie made sense because the group velocity ", "of this [? package ?] would be correct.  And that's a very beautiful result.  Actually, it's true relativistically, as well.  If you put the energy and the momentum in relativity, ", "this answer comes out exactly the same, perfectly well.  So to a large degree, since it also  works for energy and momentum in relativity, ", "there was a motivation from relativity  that I want to quote, although not elaborate on it too much.  So-- ", " the motivation--   is that in special relativity-- ", " relativity--   the components of the energy divided by c and the momentum ", "form a 4-vector.   Just like position and time forms a 4-vector and transform ", "nicely about--  with Lorenz transformation-- e and p form a 4-vector.  Nevertheless, when you consider phases--  ", "like this, and you have x and t that form a 4-vector,  the good behavior of phases also imply  that k and omega form a 4-vector. ", "In fact, omega-- in relativity, omega over c and the k vector--   form a 4-vector. ", "You see, in all the equations we've written--  and de Broglie-- de Broglie in three dimensions or more,  really, is p vector equal h bar k vector. ", "And k is usually used for the magnitude of this k vector.  So this is also 4-vector in special relativity. ", "And therefore, vectors are things that transform nicely.  So it makes sense to say that one 4-vector is ", "equal to another 4-vector.  Because if it's true in one reference frame,  it will be true in every reference frame.  So it's almost irresistible to make them equal. ", "And de Broglie, in some sense, said this is equal to h bar.  That's de Broglie.  ", "The interesting thing is that this is true relativistically.  But actually, nonrelativistically, you  can make sense of this and set it equal to be the same things. ", "And the phase velocities, group velocities all makes sense.   Certainly, we've now said for [? minor ?] particles  that e is equal to j bar omega. ", "But another statement would be that, yes, indeed, Einstein  said that.  That for photons, e was equal to h bar omega or h nu. ", "And therefore, yes, whatever happens for photons  happens for this matter waves.  And so also, so this is another argument. ", "Group velocities is one.  Special relativity is another reason.  And of, course photons.   Einstein-- ", "  PROFESSOR: Velocity.  ", "So we assume that we have an omega of k.  That's the assumption.  There are waves in which, if you give me k, the wavelength, ", "I can tell you what is omega.  And it may be as simple as omega equal to kc,  but it may be more complicated.   In fact, the different waves have different relations. ", "In mechanics, omega would be proportional to k squared.  As you've seen, the energy is proportional to p squared.  So omega will be proportional to k squared. ", "So in general, you have an omega of k.  And the group velocity is the velocity of a wave packet-- ", "packet--   constructed--   by superposition of waves.  ", "Of waves.   All right.  So let's do this here.  Let's write a wave packet.  Psi of x and t is going to be done by superposing waves. ", "And superposition means integrals, summing over  waves of different values of k.  Each wave, I will construct it in a simple way ", "with exponentials.  ikx minus army of kt.   And this whole thing, I will call the phase of the wave. ", "Phi of k.   So that's one wave.  It could be sines or cosines, but exponentials are nicer. ", "And we'll do with exponentials, in this case.  But you superimpose them.  And each one may be superimposed with a different amplitude. ", "So what does it mean?  It means that there is a function, phi of k, here.  And for different k's, this function  may have different values. ", "Indeed, the whole assumption of this construction  is based on the statement that phi of k peaks.  So phi of k--  ", "as a function of k is 0 almost everywhere,  except a little bump around some frequency that we'll call k0. ", " Narrow peak.  ", "That is our wave.  And depending on how this phi of k looks,  then we'll get a different wave. ", "We're going to try to identify how this packet moves in time.  Now--   There is a quick way to see how it moves. ", "And there is a way to prove how it moves.  So let me do, first, the quick way to see how it moves.  It's based on something called the principle ", "of stationary phase.  I doubt it was said to you in [? A03 ?] in that way.   But it's the most powerful wave to see this. ", "And in many ways, the quickest and nicest way to see.  Takes a little bit of mathematical intuition,  but it's simple.  And intuition is something that. ", "I think, you have.   If you're integrating--   a function--  ", "multiplied-- a function, f of x, multiplied by maybe sine of x. ", "Well, you have f of x, then sine of x.  Sine is 1/2 the times positive, 1/2 the times negative. ", "If you multiply these two functions,  you're going to get the function that is 1/2 time positive  and 1/2 the time negative.  And in fact, the integral will contribute almost nothing ", "if this function is slowly varying.  Because if it's slowly varying, the up peak and the down peak  hasn't changed much the function.  And they will cancel each other. ", "So the principle of stationary phase  says that if you're integrating a function times a wave,  you get almost no contribution, except in those places where ", "the wave suddenly becomes of long wavelength  and the phase is stationary.  Only when the wave doesn't change much for a while, ", "and then it changes again.  In those regions, the function will give you some integral.  So that's the principle of stationary phase. ", "And I'll say it here, I'll write it here.  Principal--   of stationary phase. ", "We're going to use that throughout the course.  Phase.  And I'll say the following.  Since-- ", " phi anyway only peaks around k0--   This is the principle of stationary phase applied ", "to this integral.  Since-- since only for k roughly equal to k0. ", " The integral--   has a chance--  ", "To be non-zero.   So here is what I'm saying.  Look.  The only place where this integral contributes-- it ", "might as well integrate from k0 minus a little delta  to k0 plus a little delta.  Because this whole thing vanishes outside.  And if we're going to integrate here, over this thing, ", "it better be that this wave is not oscillating like crazy.  Because it's going to cancel it out.  So it better stop oscillating there ", "in order to get that contribution,  or send in another way.  Only when the phase stops, you get a large contribution. ", "So on the phase stops varying fast with respect to k.  So you need-- need-- ", "that the phase becomes stationary--  ", "with respect to k, which is the variable of integration--   at k0. ", " So around k0, better be that the phase doesn't change quickly.  And the slower it changes, the better for your integral. ", "You may get something.  So if you want to figure out where  you get the most contribution, you  get it for k around k0, of course. ", "But only if this thing it's roughly stationary.  So being roughly stationary will give the following result. ", "", "The result is that the main contribution  comes when the phase, phi of k, which is kx minus omega of kt, ", "satisfies the condition that it just doesn't vary.  You have 0 derivative at k0.   So the relative with respect to k ", "is x minus d omega of k dk at k0 t must be 0. ", "Stationary phase.  Function phase has a stationary point.  Look what you get.  It says there that you only get a contribution ", "if this is the case.  So the value of x, where you get a big bump in the integral,  and the time, t, are related by this relation. ", "The hump in this packet will behave obeying this relation.  So x is equal to d omega dk at k0 t. ", "And it identifies the packet as moving with this velocity.  x equal velocity times times.  This is the group velocity.  ", "End of the answer by stationary phase.  PROFESSOR: Let me demonstrate now  with plain doing the integral that, really, ", "the shape of this wave is moving with that velocity.  So in order to do that, I basically  have to do the integral.  ", "And of course, if it's a general integral, I cannot do it.  So I have to figure out enough about the integral.  So here it is.  We have psi of x and t. ", "It's integral dk phi of k e to the ikx minus omega of kt.  ", "OK.  It's useful for us to look at this wave at time equals 0  so that we later compare it with the result of the integral. ", "So phi psi at time equals 0 is just dk phi of k e to the ikx.  ", "Only thing you know is that phi has peaked around k0.  You don't know more than that.  But that's psi of x and time equals 0. ", "Let's look at it later.  So we have this thing here.  And I cannot do the integral unless I do some  approximations. ", "And I will approximate omega.  Omega of k, since we're anyway going to integrate around k0,  let's do a Taylor series. ", "It's omega of k0 plus k minus k0, the derivative  of omega with respect to k at k0 plus order k minus k0 squared. ", " So let's--   do this here.  So if I've expanded omega as a function of k, ", "which is the only reasonable thing to do.  k's near k0 are the only ones that contribute.  So omega of k may be an arbitrary function, ", "but it has a Taylor expansion.  And certainly, you've noted that you get back  derivative that somehow is part of the answer,  so that's certainly a bonus. ", "So now we have to plug this into the integral.  And this requires a little bit of vision  because it suddenly seems it's going to get very messy.  But if you look at it for a few seconds, ", "you can see what's going on.  So psi of x and t, so far, dk phi of k e to the ikx. ", " So far so good.  I'll split the exponential so as to have this thing separate. ", "Let's do this. e to the minus i.  I should put omega of k times t.  So I'll begin.  Omega of k0 times t.  That's the first factor. ", "e to the minus i, the second factor.  k--   k d omega dk. ", " k0 times t.  And the third factor is this one with the k0. ", "e to the minus-- it should be e to the plus.  i k not d omega dk.  k0 t. ", "Plus order--   higher up.  So e to the negligible--  ", "negligible until you need to figure out  distortion of wave patterns.  We're going to see the wave pattern move.  If you want to see the distortion,  you have to keep that [INAUDIBLE]. ", "We'll do that in a week from now.   This is the integral.  And then, you probably need to think a second.  And you say, look. ", "There's lots of things making it look like a difficult integral,  but it's not as difficult as it looks.  First, I would say, this factor-- ", " doesn't depend on k.  It's omega evaluated at k0.  So this factor is just confusing. ", "It's not-- doesn't belong in the integral.  This factor, too.   k0 is not a function of k. ", "d omega dk evaluated at k0 is not a function of k.  So this is not really in the integral.  This is negligible.  This is in the integral because it has a k. ", "And this is in the integral.  So let me put here, e to the minus i omega of k0 t  e to the minus-- ", "to the plus i k0 d omega dk--   at k0 t. ", "Looks messy.  Not bad.  dk.  And now I can put phi of k.  ", "e to the i k x minus these two exponentials,  d omega dk at k0 times t. ", "And I ignore this.  So far so good.   For this kind of wave, we already get a very nice result ", "because look at this thing.   This quantity can be written in terms of the wave function ", "at time equals 0.  It's of the same form at 5k integrated  with ik and some number that you call x,  which has been changed to this. ", " So to bring in this and to make it a little clearer--  and many times it's useful.  If you have a complex number, it's ", "a little hard to see the bump.  Because maybe the bump is in the real part  and not in the imaginary part, or in the imaginary part  and not in the real part.  So take the absolute value, psi of x and t, absolute value. ", "And now you say, ah, that's why.  This is a pure phase.  The absolute value of a pure phase is that.  So it's just the absolute value of this one quantity, which ", "is the absolute value of psi at x minus d omega dk k0 t comma ", "0.   So look what you've proven.   The wave function-- the norm of the wave function-- ", "or the wave.  The new norm of the wave at any time t  looks like the wave looked at time ", "equals 0 but just displaced a distance.  If there was a peak at x equals 0, at time equals 0. ", "If at time equals 0, psi had a peak when x is equal to zero,  it will have a peak--  This function, which is the wave function at time equals 0, ", "will have a peak when this thing is 0, the argument.  And that corresponds to x equals to d omega dk times t,  showing again that the wave has moved to the right by d omega ", "dk times t.  So I've given two presentations, basically,  of this very important result about wave packets  ", "PROFESSOR: So what are we trying to do?  We're going to try to write a matter wave.   We have a particle with energy e and momentum p. ", "e is equal to h bar omega.  So you can get the omega of the wave.  And p is equal to h bar k.  You can get the k of the wave. ", "So de Broglie has told you that's the way to do it.  That's the p and the k.  But what is the wave? ", "Really need the phase to-- how does the wave look like?  So the thing is that I'm going to do an argument based  on superposition and very basic ideas of probability to get-- ", "to find the shape of the wave.  And look at this possibility.  Suppose we have plane waves-- ", "plane waves in the x plus direction.  A particle that is moving in the plus x direction. ", "No need to be more general yet.  So what could the wave be?  Well, the wave could be sine of kx minus omega t. ", "Maybe that's the de Broglie wave.   Or maybe the de Broglie wave is cosine of kx minus omega t. ", " But maybe it's neither one of them.  Maybe it is an e to ikx minus i omega t. ", "These things move to the right.  The minus sign is there.  So with an always an e to the minus i omega t. ", "Or maybe it's the other way around.  It's e to the minus ikx plus i omega t. ", "So always an e to the i omega t.  And then you have to change the sine of the first term  in order to get a wave that is moving that way. ", " And now you say, how am I ever going to know which one is it?  Maybe it's all of them, a couple of them, none of them. ", " That's we're going to try to understand.   So the argument is going to be based on superposition and just ", "the rough idea that somehow this has  to do with the existence of particles having a wave.   And it's very strange. ", "In some sense, it's very surprising.  To me, it was very surprising, this argument,  when I first saw it.  Because it almost seems that there's no way  you're going to be able to decide. ", "These are all waves, so what difference can it make?  But you can decide.  ", "So my first argument is going to be,  it's all going to be based on superposition.  Use superposition-- --position. ", "Plus a vague notion of probability--   --bility. ", " So I'm going to try to produce with these waves  a state of a particle that has equal probability to be moving ", "to the right or to the left.   I'm going to try to build a wave that  has equal probability of doing this thing. ", "So in case 1, I would have to put a sine of kx minus omega t.  That's your wave that is moving to the right. ", " I have to change one sine here.  Plus sine of kx. ", " Say, plus omega t.   And that would be a wave that moves to the right. ", "Just clearly, this is the wave that moves to the left.  And roughly speaking, by having equal coefficients here,  I get the sense that this would be  the only way I could produce a wave that has equal probability ", "to move to the left and a particle that  moves to the right.   On the other hand, if I expand this ", "you get twice sine of kx cosine omega t.  ", "The fact is that this is not acceptable.  Why it's not acceptable?  Because this wave function vanishes for all x at t ", "omega t equal to pi over 2, 3pi over 2, 5pi over 2.  At all those times, the wave is identically 0. ", "The particle has disappeared.  No probability of a particle.  That's pretty bad.  That can't be right. ", "And suddenly, you've proven something very surprising.  This sort of wave just can't be a matter particle.  Again, in the way we're trying to think of probabilities. ", " Same argument for 2 for same reason.  2-- So this is no good. ", "No good.   The wave function cannot vanish everywhere at any time.  If it vanished everywhere, you have no particle. ", "You have nothing.  With 2, you can do the same thing.  You have a cosine plus another cosine.  ", "Cosine omega t minus--  kx minus omega t plus cosine of kx plus omega t. ", "That would be 2 cosine kx cosine omega t.  It has the same problems.  ", "Let's do case number 3.  Case number 3 is based on the philosophy  that the wave that we have-- e to the ikx minus i omega t ", "always has an e to the minus i omega t as a phase.  So to get a wave that moves in the opposite direction,  we have to do minus ikx minus i omega t. ", "Because I cannot change that phase.  Always this [INAUDIBLE].  Now, in this case, we can factor the time dependence. ", "You have e to the ikx e to the minus ikx  e to the minus i omega t.  ", "And be left with 2 cosine kx e to the minus i omega t.  ", "But that's not bad.  This way function never vanishes all over space.  Because this is now a phase, and this phase is always non-zero. ", " The e to the minus i omega t is never 0.  The exponential of something is never 0,  unless that something is real and negative. ", "And a phase is never 0.  So this function never vanishes for all x--  vanishes for all x. ", "So it can vanish at some point for all time.  But those would be points where you don't find the particle. ", "The function is nonzero everywhere else.  So this is good.  Suddenly, this wave, for some reason,  is much better behaved than these things for superposition. ", "Let's do the other wave, the wave number 4.  ", "And wave number 4 is also not problematic.   So case 4, you would do an e to the minus ikx e ", "to the i omega t plus an e to the ikx e to the i omega t.  Always the same exponential. ", "This is simply 2 cosine of kx e to the i omega t.  And it's also good.  At least didn't get in trouble. ", "We cannot prove it is good at this point.  We can only prove that you are not getting in trouble.  We are not capable of producing a contradiction, so far. ", "So actually, 3 and 4 are good.  And the obvious question that would come now  is whether you can use both of them ", "or either one at the same time.  So the next claim is that both cannot be true at the same ", "time.  You cannot use both of them at the same time.  So suppose 3 and 4 are good. ", "Both 3 and 4--  and 4 are both good--  both right, even. ", "Then remember that superimposing a state to itself  doesn't change the state.  So you can superimpose 3 and 4-- ", "e to the ikx minus i omega t.  That's 3.  You can add to it 4, which is e to the minus ikx-- ", " minus omega t.  I factor a sine.  And that's 4.   And that should still represent this same particle ", "moving to the right.  But this thing is twice cosine of kx minus omega t.  So it would mean that this represents ", "a particle moving to the right.  And we already know that if this represents  a particle moving to the right, you get in trouble.  So now, we have to make a decision. ", "We have to choose one of them.  And it's a matter of convention to choose one of them,  but happily, everybody has chosen the same one.  ", "So we are led, finally, to our matter wave.  We're going to make a choice.  ", "And here is the choice.  Psi of x and t equal to the ikx minus i omega t. ", "The energy part will always have a minus sign.   Is the mother wave or wave function ", "for a particle with p equal hk and e equal h bar ", "omega according to de Broglie.  You want to do 3 dimensions, no problem.  You put e to the i k vector, x vector, minus i omega t. ", "On p, in this case, is h bar k vector.  So it's a plane wave in 3 dimensions.  So that's the beginning of quantum mechanics. ", "You have finally found the wave corresponding  to a matter particle.  And it will be a deductive process  to figure out what equation it satisfies, "], "vid_duration": [12.95, 11.06, 28.725, 13.125, 14.57, 11.67, 10.4, 17.14, 10.68, 12.84, 10.53, 12.95, 12.38, 10.68, 12.0, 13.56, 10.2, 13.67, 15.94, 11.57, 11.47, 13.29, 10.53, 12.1, 10.94, 11.62, 11.82, 11.64, 13.41, 17.21, 12.16, 13.7, 15.9, 10.14, 11.98, 17.19, 17.936, 13.554, 12.65, 10.8, 10.59, 17.21, 10.63, 11.91, 10.85, 10.39, 12.27, 10.22, 11.28, 13.07, 10.59, 12.36, 10.23, 13.5, 15.91, 10.47, 10.62, 11.98, 11.77, 11.44, 11.96, 14.44, 13.61, 12.76, 12.42, 10.08, 11.13, 13.64, 14.43, 12.093, 23.61, 10.31, 11.89, 10.95, 12.63, 11.19, 13.33, 10.71, 10.77, 13.41, 13.23, 16.36, 18.92, 13.57, 10.46, 13.1, 13.71, 11.39, 19.15, 17.805, 11.685, 13.95, 11.62, 20.58, 16.63, 10.1, 22.8, 12.47, 13.47, 12.78, 14.36, 10.89, 17.26, 16.325, 10.895, 10.89, 13.51, 10.03, 11.27, 16.77, 11.16, 10.65, 11.23, 17.13, 13.44, 12.41, 15.04, 13.54, 12.37, 11.9, 10.409, 11.161, 16.99, 11.49, 13.32, 12.49, 15.68, 12.385, 15.945, 14.19, 10.12, 10.63, 10.62, 12.3, 12.86, 14.35, 10.61, 15.58, 12.22, 13.35, 14.04, 11.01, 10.27, 11.57, 12.91, 11.22, 13.29, 19.92, 11.51, 10.81, 15.49, 12.27, 11.28, 14.32, 10.79, 12.6, 11.5, 11.331, 11.009, 12.06, 12.02, 11.86, 10.74, 11.43, 12.408, 11.132, 10.53, 10.29, 11.48, 11.41, 12.65, 12.78, 10.08, 10.412, 12.248, 13.35, 14.05, 12.96, 11.72, 12.843, 14.027, 11.61, 13.4, 12.65, 12.43, 11.58, 13.07, 10.71, 16.4, 11.0, 13.73, 11.82, 10.6, 11.17, 12.17, 10.95, 10.17, 14.78, 12.88, 12.19, 11.64, 11.78, 11.24, 10.062, 11.878, 10.26, 12.22, 11.85, 14.65, 12.72, 12.03, 10.32, 11.8, 11.92, 11.99, 10.32, 12.952, 10.588, 16.29, 12.23, 12.53, 11.98, 13.32, 16.05, 13.44, 11.0, 13.5, 11.089, 13.171, 12.66, 12.45, 11.01, 10.41, 10.59, 16.775, 14.685, 11.07, 12.97, 12.81, 11.48, 10.47, 12.62, 10.47, 10.41, 12.11, 10.42, 11.31, 11.26, 10.605, 10.725, 12.61, 12.09, 10.23, 10.47, 11.24, 15.78, 15.9, 13.66, 10.96, 10.53, 15.79, 13.67, 14.875, 11.295, 10.62, 12.71, 14.37, 16.29, 10.95, 16.079, 10.661, 10.58, 15.21, 10.0, 11.94, 13.86, 11.78, 17.02, 15.16, 10.23, 12.72, 12.54, 16.09, 12.75, 11.28, 10.59, 11.31, 10.39, 15.8, 11.67, 11.055, 10.005, 15.25, 14.25, 11.41, 14.46, 19.94, 14.07, 10.08, 10.734, 11.276, 10.675, 13.835, 11.51, 10.43, 17.31, 14.22, 13.87, 11.089, 11.111, 13.47, 14.63, 13.72, 10.05, 13.97, 10.09, 12.8, 11.31, 11.22, 11.94, 12.36, 12.31, 10.55, 11.89, 10.66, 11.83, 13.979, 12.811, 13.45, 11.1, 11.88, 11.04, 23.4, 14.45, 17.319, 13.081, 11.267], "stet": [[0, 12.95], [12.95, 24.009999999999998], [24.009999999999998, 52.735], [52.735, 65.86], [65.86, 80.43], [80.43, 92.10000000000001], [92.10000000000001, 102.50000000000001], [102.50000000000001, 119.64000000000001], [119.64000000000001, 130.32000000000002], [130.32000000000002, 143.16000000000003], [143.16000000000003, 153.69000000000003], [153.69000000000003, 166.64000000000001], [166.64000000000001, 179.02], [179.02, 189.70000000000002], [189.70000000000002, 201.70000000000002], [201.70000000000002, 215.26000000000002], [215.26000000000002, 225.46], [225.46, 239.13], [239.13, 255.07], [255.07, 266.64], [266.64, 278.11], [278.11, 291.40000000000003], [291.40000000000003, 301.93], [301.93, 314.03000000000003], [314.03000000000003, 324.97], [324.97, 336.59000000000003], [336.59000000000003, 348.41], [348.41, 360.05], [360.05, 373.46000000000004], [373.46000000000004, 390.67], [390.67, 402.83000000000004], [402.83000000000004, 416.53000000000003], [416.53000000000003, 432.43], [432.43, 442.57], [442.57, 454.55], [454.55, 471.74], [471.74, 489.676], [489.676, 503.22999999999996], [503.22999999999996, 515.88], [515.88, 526.68], [526.68, 537.27], [537.27, 554.48], [554.48, 565.11], [565.11, 577.02], [577.02, 587.87], [587.87, 598.26], [598.26, 610.53], [610.53, 620.75], [620.75, 632.03], [632.03, 645.1], [645.1, 655.69], [655.69, 668.0500000000001], [668.0500000000001, 678.2800000000001], [678.2800000000001, 691.7800000000001], [691.7800000000001, 707.69], [707.69, 718.1600000000001], [718.1600000000001, 728.7800000000001], [728.7800000000001, 740.7600000000001], [740.7600000000001, 752.5300000000001], [752.5300000000001, 763.9700000000001], [763.9700000000001, 775.9300000000002], [775.9300000000002, 790.3700000000002], [790.3700000000002, 803.9800000000002], [803.9800000000002, 816.7400000000002], [816.7400000000002, 829.1600000000002], [829.1600000000002, 839.2400000000002], [839.2400000000002, 850.3700000000002], [850.3700000000002, 864.0100000000002], [864.0100000000002, 878.4400000000002], [878.4400000000002, 890.5330000000001], [890.5330000000001, 914.1430000000001], [914.1430000000001, 924.4530000000001], [924.4530000000001, 936.3430000000001], [936.3430000000001, 947.2930000000001], [947.2930000000001, 959.9230000000001], [959.9230000000001, 971.1130000000002], [971.1130000000002, 984.4430000000002], [984.4430000000002, 995.1530000000002], [995.1530000000002, 1005.9230000000002], [1005.9230000000002, 1019.3330000000002], [1019.3330000000002, 1032.563], [1032.563, 1048.923], [1048.923, 1067.843], [1067.843, 1081.413], [1081.413, 1091.873], [1091.873, 1104.973], [1104.973, 1118.683], [1118.683, 1130.073], [1130.073, 1149.2230000000002], [1149.2230000000002, 1167.0280000000002], [1167.0280000000002, 1178.7130000000002], [1178.7130000000002, 1192.6630000000002], [1192.6630000000002, 1204.2830000000001], [1204.2830000000001, 1224.863], [1224.863, 1241.4930000000002], [1241.4930000000002, 1251.593], [1251.593, 1274.393], [1274.393, 1286.863], [1286.863, 1300.333], [1300.333, 1313.113], [1313.113, 1327.473], [1327.473, 1338.363], [1338.363, 1355.623], [1355.623, 1371.948], [1371.948, 1382.843], [1382.843, 1393.7330000000002], [1393.7330000000002, 1407.2430000000002], [1407.2430000000002, 1417.2730000000001], [1417.2730000000001, 1428.5430000000001], [1428.5430000000001, 1445.313], [1445.313, 1456.4730000000002], [1456.4730000000002, 1467.1230000000003], [1467.1230000000003, 1478.3530000000003], [1478.3530000000003, 1495.4830000000004], [1495.4830000000004, 1508.9230000000005], [1508.9230000000005, 1521.3330000000005], [1521.3330000000005, 1536.3730000000005], [1536.3730000000005, 1549.9130000000005], [1549.9130000000005, 1562.2830000000004], [1562.2830000000004, 1574.1830000000004], [1574.1830000000004, 1584.5920000000006], [1584.5920000000006, 1595.7530000000006], [1595.7530000000006, 1612.7430000000006], [1612.7430000000006, 1624.2330000000006], [1624.2330000000006, 1637.5530000000006], [1637.5530000000006, 1650.0430000000006], [1650.0430000000006, 1665.7230000000006], [1665.7230000000006, 1678.1080000000006], [1678.1080000000006, 1694.0530000000006], [1694.0530000000006, 1708.2430000000006], [1708.2430000000006, 1718.3630000000005], [1718.3630000000005, 1728.9930000000006], [1728.9930000000006, 1739.6130000000005], [1739.6130000000005, 1751.9130000000005], [1751.9130000000005, 1764.7730000000004], [1764.7730000000004, 1779.1230000000003], [1779.1230000000003, 1789.7330000000002], [1789.7330000000002, 1805.313], [1805.313, 1817.5330000000001], [1817.5330000000001, 1830.883], [1830.883, 1844.923], [1844.923, 1855.933], [1855.933, 1866.203], [1866.203, 1877.773], [1877.773, 1890.683], [1890.683, 1901.903], [1901.903, 1915.193], [1915.193, 1935.113], [1935.113, 1946.623], [1946.623, 1957.433], [1957.433, 1972.923], [1972.923, 1985.193], [1985.193, 1996.473], [1996.473, 2010.793], [2010.793, 2021.5829999999999], [2021.5829999999999, 2034.1829999999998], [2034.1829999999998, 2045.6829999999998], [2045.6829999999998, 2057.0139999999997], [2057.0139999999997, 2068.0229999999997], [2068.0229999999997, 2080.0829999999996], [2080.0829999999996, 2092.1029999999996], [2092.1029999999996, 2103.9629999999997], [2103.9629999999997, 2114.7029999999995], [2114.7029999999995, 2126.1329999999994], [2126.1329999999994, 2138.5409999999993], [2138.5409999999993, 2149.6729999999993], [2149.6729999999993, 2160.2029999999995], [2160.2029999999995, 2170.4929999999995], [2170.4929999999995, 2181.9729999999995], [2181.9729999999995, 2193.3829999999994], [2193.3829999999994, 2206.0329999999994], [2206.0329999999994, 2218.8129999999996], [2218.8129999999996, 2228.8929999999996], [2228.8929999999996, 2239.3049999999994], [2239.3049999999994, 2251.5529999999994], [2251.5529999999994, 2264.9029999999993], [2264.9029999999993, 2278.9529999999995], [2278.9529999999995, 2291.9129999999996], [2291.9129999999996, 2303.6329999999994], [2303.6329999999994, 2316.475999999999], [2316.475999999999, 2330.5029999999992], [2330.5029999999992, 2342.1129999999994], [2342.1129999999994, 2355.5129999999995], [2355.5129999999995, 2368.1629999999996], [2368.1629999999996, 2380.5929999999994], [2380.5929999999994, 2392.1729999999993], [2392.1729999999993, 2405.2429999999995], [2405.2429999999995, 2415.9529999999995], [2415.9529999999995, 2432.3529999999996], [2432.3529999999996, 2443.3529999999996], [2443.3529999999996, 2457.0829999999996], [2457.0829999999996, 2468.903], [2468.903, 2479.5029999999997], [2479.5029999999997, 2490.673], [2490.673, 2502.843], [2502.843, 2513.7929999999997], [2513.7929999999997, 2523.9629999999997], [2523.9629999999997, 2538.743], [2538.743, 2551.623], [2551.623, 2563.813], [2563.813, 2575.453], [2575.453, 2587.233], [2587.233, 2598.473], [2598.473, 2608.535], [2608.535, 2620.413], [2620.413, 2630.6730000000002], [2630.6730000000002, 2642.893], [2642.893, 2654.743], [2654.743, 2669.393], [2669.393, 2682.113], [2682.113, 2694.143], [2694.143, 2704.463], [2704.463, 2716.2630000000004], [2716.2630000000004, 2728.1830000000004], [2728.1830000000004, 2740.1730000000002], [2740.1730000000002, 2750.4930000000004], [2750.4930000000004, 2763.4450000000006], [2763.4450000000006, 2774.033000000001], [2774.033000000001, 2790.323000000001], [2790.323000000001, 2802.553000000001], [2802.553000000001, 2815.083000000001], [2815.083000000001, 2827.063000000001], [2827.063000000001, 2840.383000000001], [2840.383000000001, 2856.4330000000014], [2856.4330000000014, 2869.8730000000014], [2869.8730000000014, 2880.8730000000014], [2880.8730000000014, 2894.3730000000014], [2894.3730000000014, 2905.4620000000014], [2905.4620000000014, 2918.633000000001], [2918.633000000001, 2931.293000000001], [2931.293000000001, 2943.743000000001], [2943.743000000001, 2954.753000000001], [2954.753000000001, 2965.163000000001], [2965.163000000001, 2975.753000000001], [2975.753000000001, 2992.528000000001], [2992.528000000001, 3007.213000000001], [3007.213000000001, 3018.2830000000013], [3018.2830000000013, 3031.253000000001], [3031.253000000001, 3044.063000000001], [3044.063000000001, 3055.543000000001], [3055.543000000001, 3066.013000000001], [3066.013000000001, 3078.6330000000007], [3078.6330000000007, 3089.1030000000005], [3089.1030000000005, 3099.5130000000004], [3099.5130000000004, 3111.6230000000005], [3111.6230000000005, 3122.0430000000006], [3122.0430000000006, 3133.3530000000005], [3133.3530000000005, 3144.6130000000007], [3144.6130000000007, 3155.2180000000008], [3155.2180000000008, 3165.9430000000007], [3165.9430000000007, 3178.553000000001], [3178.553000000001, 3190.643000000001], [3190.643000000001, 3200.873000000001], [3200.873000000001, 3211.3430000000008], [3211.3430000000008, 3222.5830000000005], [3222.5830000000005, 3238.3630000000007], [3238.3630000000007, 3254.263000000001], [3254.263000000001, 3267.9230000000007], [3267.9230000000007, 3278.8830000000007], [3278.8830000000007, 3289.413000000001], [3289.413000000001, 3305.203000000001], [3305.203000000001, 3318.873000000001], [3318.873000000001, 3333.748000000001], [3333.748000000001, 3345.043000000001], [3345.043000000001, 3355.663000000001], [3355.663000000001, 3368.373000000001], [3368.373000000001, 3382.743000000001], [3382.743000000001, 3399.033000000001], [3399.033000000001, 3409.9830000000006], [3409.9830000000006, 3426.062000000001], [3426.062000000001, 3436.723000000001], [3436.723000000001, 3447.303000000001], [3447.303000000001, 3462.513000000001], [3462.513000000001, 3472.513000000001], [3472.513000000001, 3484.453000000001], [3484.453000000001, 3498.313000000001], [3498.313000000001, 3510.093000000001], [3510.093000000001, 3527.113000000001], [3527.113000000001, 3542.273000000001], [3542.273000000001, 3552.503000000001], [3552.503000000001, 3565.223000000001], [3565.223000000001, 3577.763000000001], [3577.763000000001, 3593.853000000001], [3593.853000000001, 3606.603000000001], [3606.603000000001, 3617.883000000001], [3617.883000000001, 3628.4730000000013], [3628.4730000000013, 3639.7830000000013], [3639.7830000000013, 3650.173000000001], [3650.173000000001, 3665.9730000000013], [3665.9730000000013, 3677.6430000000014], [3677.6430000000014, 3688.6980000000012], [3688.6980000000012, 3698.7030000000013], [3698.7030000000013, 3713.9530000000013], [3713.9530000000013, 3728.2030000000013], [3728.2030000000013, 3739.613000000001], [3739.613000000001, 3754.0730000000012], [3754.0730000000012, 3774.0130000000013], [3774.0130000000013, 3788.0830000000014], [3788.0830000000014, 3798.1630000000014], [3798.1630000000014, 3808.8970000000013], [3808.8970000000013, 3820.173000000001], [3820.173000000001, 3830.8480000000013], [3830.8480000000013, 3844.6830000000014], [3844.6830000000014, 3856.1930000000016], [3856.1930000000016, 3866.6230000000014], [3866.6230000000014, 3883.9330000000014], [3883.9330000000014, 3898.153000000001], [3898.153000000001, 3912.023000000001], [3912.023000000001, 3923.112000000001], [3923.112000000001, 3934.223000000001], [3934.223000000001, 3947.6930000000007], [3947.6930000000007, 3962.323000000001], [3962.323000000001, 3976.0430000000006], [3976.0430000000006, 3986.0930000000008], [3986.0930000000008, 4000.0630000000006], [4000.0630000000006, 4010.1530000000007], [4010.1530000000007, 4022.953000000001], [4022.953000000001, 4034.263000000001], [4034.263000000001, 4045.4830000000006], [4045.4830000000006, 4057.4230000000007], [4057.4230000000007, 4069.783000000001], [4069.783000000001, 4082.0930000000008], [4082.0930000000008, 4092.643000000001], [4092.643000000001, 4104.533000000001], [4104.533000000001, 4115.193000000001], [4115.193000000001, 4127.023000000001], [4127.023000000001, 4141.002000000001], [4141.002000000001, 4153.813000000001], [4153.813000000001, 4167.263000000001], [4167.263000000001, 4178.363000000001], [4178.363000000001, 4190.243000000001], [4190.243000000001, 4201.283000000001], [4201.283000000001, 4224.683000000001], [4224.683000000001, 4239.133000000001], [4239.133000000001, 4256.452000000001], [4256.452000000001, 4269.533000000001], [4269.533000000001, 4280.800000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [891, 1625, 2245, 2874, 3410, 4281]}
{"example_id": "mit035@@MIT8_04S16_lec12_300k", "text": ["PROFESSOR: You first are facing the calculation of the energy  eigenstate with some arbitrary potential.  You probably want to know some of the key features of the wave ", "functions you're going to calculate.  So in fact, all of today's lecture  is going to be devoted to this intuitive, qualitative insights ", "into the nature of the wave function.  So we will discuss a few properties  that help us think clearly.  And these are two of those properties. ", "I want to begin with them.  Then we'll do a third one that we have already used,  and we will prove it completely.  And then turn to the classical and semi-classical intuition ", "that lets us figure out how the wave function will look.  And that's a great help for you.  Even if you're solving for your wave function numerically, ", "you always need to know what the answer should look like.  And it's ideal if before you calculate, you think about it.  And you realize, well, it should have this t properties. ", "And if you find out that those are not true,  well, you will learn something about your intuition  and see what was wrong with it. ", "So we're talking about one dimensional potentials, time  independent potentials.  And a first statement that is very important, ", "and you will prove in an exercise after spring break,  and that is the fact that one dimensional potentials, when ", "you look at what are called bound states,  you never find degeneracies, energy degeneracies.  And this is when x extends from minus infinity to infinity. ", "You've seen already, in the case of a particle in a circle,  there are degenerate energy eigenstates.  But if the potential extends to infinity, ", "there is no such things.   Now what is a bound state?  A bound state sounds like a complicated concept. ", "But it is not.  It really means an energy eigenstate  that can be normalized.  Now if an energy eigenstate can be normalized ", "and you live in the full real line,  that the wave function must go to 0 at infinity.  Otherwise you would never be able to normalize it. ", "And if the wave function goes 0 at infinity,  the bound state is some sort of bump in the middle region  or something like that.  And it eventually decays. ", "So this is bound by the potential in some way.  And that's basically what we use to define a bound state. ", "We'll take it to be that generally.  So this is something, this property,  which is very important, is something you will prove. ", "But now we go to another property.  We've emphasized forever that the Schrodinger equation  is an equation with complex numbers.  And the solutions have complex numbers. ", "And suddenly, I wrote a few lectures ago  a wave function was real.  And I was asked, well, how can it be real?  Well, we've discussed stationary states in which the full wave ", "function, capital PSI, is equal to a little psi of x  times the exponential of e to the minus i et over h bar. ", "And there in that exponential, there  is complex numbers on this little psi  of x in front of that exponential, which  is what we called basically those energy eigenstates. ", "The e to the minus i et over h bar,  it's understood that little psi of x  is the thing we've been looking for.  And this psi of x solves the time independent Schrodinger ", "equation h psi equal e psi.  And that equation has no complex number in it.  So little psi of x can be real. ", "And there's no contradiction.  Because the full solution to the time  dependent Schrodinger equation is complex.  But here is a statement. ", "With v of x real, the energy eigenstates  can be chosen to be real.  And the words can be chosen are very important here. ", "It means that you may find a solution that is complex,  but you need not stick to that solution. ", "There is always a possibility to work with real solutions.  And what is the way you prove this?  This I will put this in the notes. ", "You don't have to worry about the proof.  You consider the Schrodinger equation for psi.  And you show that psi star, the complex conjugate of psi, ", "solves the same equation that psi solves.  And therefore, if psi is a solution,  psi star is a solution with the same energy. ", "That part is very important.  Therefore, if you have two energy eigenstates  with the same energy, you can form the sum.  That's still an energy eigenstate ", "with the same energy.  Even formed in difference, that's  still an energy eigenstate with the same energy.  And the sum of psi plus psi star is real. ", "And the difference psi minus psi star, if you divide by 2i,  is real as well.  Therefore you can construct two solutions, the real part of psi ", "and the imaginary part of psi.  And both are solutions to the Schrodinger equation.  So I've said in words what is the proof of the first line. ", "It's that if you have a psi, psi star is also a solution.  Therefore, psi plus psi star and psi minus psi star  are solutions. ", "So given a complex psi, then psi psi of x. ", "Then psi real of x that we define to be psi  of x plus psi star of x over 2. ", "And the imaginary part of the wave  function 1 over 2i psi of x minus psi ", "star of x are both solutions with the same energy  as this one has. ", "So these are the two solutions.  So far so good.  You don't like to work with complex psi?  No need to work with complex psi. ", "Work with real psi.  But here comes the second part of the argument,  the second sentence.  I want you to be alert that the second sentence is ", "very powerful.  It says that if you have a bound state of a one  dimensional potential, more is true. ", "There are no genuinely complex solutions in this case.  Any solution that you will find, it's not that it's complex ", "and then you can find the real and imaginary part.  No, any solution that you will find will be basically real.  And how can it fail to be real? ", "It just has a complex number in front of it  that you can ignore.  So it is a very strong statement.  That the wave function, it's not that you can choose to work it. ", "You're forced to do it up to a phase.  So how is that possible?  How is that true?  And here is the argument for the second line. ", "If we're talking bound states, then these two  are real solutions with the same energy. ", " So now suppose these are bound states. ", "There is a problem if there are two real solutions  with the same energy.  They would be degenerate.  And property number 1 says there's  no such thing as degenerate energy bound states. ", "So they cannot be degenerate.  So if you start with a complex psi, and you build these two,  they must be the same solution.  Because since there are no degenerate bound states, ", "then psi, I will write it as psi imaginary,  of x must be proportional to psi real of x. ", "And both are real, so the only possibility  is that they are equal up to a constant,  where the constant is a real constant.  ", "You see there cannot be degenerate bound states.  So the two tentative solutions must be the same.  But that means that the original solution, psi, ", "which is by definition the real part plus i  times the imaginary part, is now equal to psi  r plus i times c times psi r again, ", "which is 1 plus ic times psi r.  And that is basically the content of the theorem.  Any solution is up to a number, just the real solution. ", "So you're not going to find the real solution has  non-trivial different real imaginary parts here.  No, just the real solution and a complex number.  Now if you want, you can just write ", "this as e to the i argument of 1 plus ic times square root of 1  plus c squared psi r. ", "And then it's literally the way it's said here.  The wave function is proportional to a real wave ", "function up to a phase.   So that's a very neat situation. ", "And therefore, you should not be worried  that we are going to have to assume many times  in our analysis that the bound states were  trying to look for are real.  And we plot real bound states. ", "And we don't have to worry about, what are you plotting?  The real part?  The imaginary part?  PROFESSOR: Now we prove the other thing  that we used in order to solve the square well. ", "So this is property number 3.  It's so important that I think I should do it here.  If a potential is even-- ", "here comes again the careful statement--  the energy eigenstates can be chosen to be even or odd ", "under x goes to minus x.  So that's analog of the first sentence in property number 2. ", "But then comes the second sentence,  that you can imagine what it is.  For 1D potentials the bound states are either even or odd. ", " So look again at this freedom.  You have a general problem-- you're not  talking bound states. ", "You have a wave function that solves  a problem of a potential of the symmetric around a mid-point.  Then you find an arbitrary solution, no need ", "to work with that solution.  You can work with a solution that is even,  and a solution that is odd.  You can always choose to be even or odd. ", "But if you have one-dimensional potential,  there is no such solution that is neither even nor odd. ", "You cannot find it.  It will be, automatically, even or odd--  which is kind of remarkable.  It's sufficiently subtle that in the general exam at MIT ", "for graduate quantum mechanics, the professor that invented  the problem forgot this property and the problem had to be  cancelled. ", " It's a very interesting.  So let's just try to prove it. ", "So complete proof in this case.  So what is the equation?  Proof.  What is the equation we have to solve?  Sine double prime of x, plus 2M over h squared. ", "E minus v of x.   Equals 0. ", "Now, the proof, actually, is very simple.  I just do it and I elaborate on it,  because it's possible to get a little confused about it. ", "I think it's kind of interesting.  So here's equation one.  And sine double prime of x notation ", "means the second derivative of psi evaluated at x. ", " You see, what you want to do is to show that psi of minus x ", "solves the same equation.  Right?  It's kind of clear.  Well, you sort of put psi of minus x here, minus x here. ", "Well, you would do minus x here.  But if the potential is even it will solve the same equation.  Now, the only complication here is  that there are a few X's in the derivatives here. ", "But whether there's a complication or not there's  two derivatives, so the [? signs ?] should not matter.  But I want to make this a little clearer,  and in order to do that I will just define phi of x ", "to be equal to psi at minus x.   So if you have that, the derivative of phi-- ", "with respect to x--  you must differentiate this with respect to the argument. ", "You evaluate at the argument, and then  differentiate the argument with respect to x.  So that leaves you a minus 1.  ", "On the second derivative of phi with respect to x squared--  at x-- will be yet another derivative. ", "So you now get a second derivative  evaluated at the thing.  And then differentiate the thing inside again.  So minus 1 plus another minus 1. ", "So this is just psi double prime of x--   of minus x. ", "", "Now, evaluate equation one at minus x. ", "Well, it would be the second derivative of psi evaluated  at minus x, plus 2m h squared, E minus V of minus x-- ", "but that's the same as v of x--  psi at minus x equals 0.  ", "And then you'll realize that this thing is just  the second phi of x.  ", "[? h squared ?] of x, plus 2m over h squared,  e minus v of x, phi of x equals 0. ", "So actually you've proven that phi  defined this way solved the same Schrodinger  equation with the same energy. ", "So if one is true--  this thing-- I guess we could call it [? three ?]  or [? two. ?]  So you've proven that both psi of x and phi of x-- ", "which is equal to psi of minus x are  solutions of the Schrodinger equation with the same energy. ", " And, therefore, if you have two solutions--  and now I emphasize this psi of minus x, and the psi of x. ", "If you have two solutions then you  can form the symmetric part of the wave function, which is 1/2  psi of x, plus psi of minus x. ", " And the anti-symmetric part of the wave function, ", "which would be 1/2 of psi of x minus psi of minus x.  And notice that by definition psi s of minus ", "x is indeed psi s of x.  It's symmetric.  If you change x for minus x on the left hand side,  this goes into this, this goes into that. ", "So it's unchanged.  Here it's changed by a psi.  So psi a of minus x is equal to psi minus psi a of x. ", "And these two are solutions with the same energy--  psi s and psi a.  You see, if you have-- ", "remember that key fact-- if you have  two solutions of the Schrodinger equation with the same energy,  any linear combination of them is a solution  with the same energy. ", "So we form two linear combinations  and they have the same energy.  And, therefore, the theorem has been proven. ", "The first part of the theorem--  the wave functions that you work with--  can be chosen to be even or odd. ", "And that's pretty nice.  But now we go to the second part of the statement. ", "So for one-dimensional bound states--   1-D bound states.  ", "Again, there cannot be two solutions.   So it cannot be that there are two degenerate solutions. ", "So after all, psi of x and psi of minus x,  we have two solutions. ", " This and psi of minus x.  But if you're in a one-dimensional bound state you  cannot have two solutions. ", "So they must be proportional to each other.  Now, if you started with a solution--  I want to say this. ", "You start with a solution from there,  from the beginning you can assume now--  because of property two--  that the solution is real. ", "[? You can work those ?] with real solutions.  So in here, I can assume that psi is real.  ", "Just simpler.  So these two solutions-- that would be two real solutions--  would be degenerating energy--  there's no degeneracy for bound states. ", "Therefore, these two must be the same  up to a constant, that again--  because psi is real c--  is real.  ", "There cannot be two solutions.  Let x goes to minus x in this equation.  So you would get psi of x equals c of psi of minus x. ", "But psi of minus x uses this equation again.  You get c times c psi of x.  ", "But from comparing these two sides,  you get that c squared must be equal to 1.  But c is real.  ", "Therefore, there's only two solutions.  Two options.  C is equal to plus 1-- in which case-- ", "psi is even-- automatically.  Or c is equal to minus 1 and psi is odd. ", " You have no option. ", "You may think that the general solution of a bound state--  of a symmetric potential--  could be arbitrary.  But no.  The solutions come out automatically symmetrical ", "or anti-symmetrical.  And that's why-- when we decided to search  for all the solutions of the finite square-- well,  we could divide it into two cases. ", "Let's find the symmetric solutions  and the anti-symmetric solutions.  There is no other solution of the Schrodinger equation.  But what if you add a symmetric to an anti-symmetric solution? ", "Don't you get the general solution?  Well you cannot add them, because for bound states they  are different energies.  And adding two solutions with different energies  is pointless. ", "It's not a energy eigenstate anymore.  So a very powerful theorem.  We'll be using it a lot, and I thought ", "PROFESSOR: This will be qualitative insights  on the wave function.   It's qualitative, and it's partially ", "quantitative of course, insights into, let's say, ", "real energy eigenstates.   So whenever you have a problem and a potential, ", "we have what is called the total energy, the kinetic energy,  and the potential energy.  So you have the energy, which is total, equal kinetic energy ", "plus the potential energy.  Now, the potential energy, as you've seen,  sometimes depends on position.  We did piecewise continuous end potentials, ", "but they could be more complicated  and do funny things.  So this is a function of x.  And classically speaking, we speak of the energy. ", "You see in quantum mechanics, the energy is an observable  and is the result of a measurement with a permission  operator.  Sometimes there could be uncertainty, sometimes not. ", "But in classical physics, which this intuition will come from,  you have a total energy.  It is conserved.  It's equal to potential energy and kinetic energy. ", "That will also depend on where the particle is  in the potential.  Let's do a very simple case.   Coordinate x, a potential. ", "v of x, this based the potential. v of x, it's  a constant, nothing that complicated.  And suppose you have a total energy. ", "Now, the total energy in classical mechanics  is conserved.  So when I draw a line, I'm not implying  that is a function of x, that sometimes the energy is ", "like that.  No, it's just a number there that I fixed.  Here is the energy.   And then wherever you move, if the particle, ", "the classical particle, is here, then it  has some potential energy, v of x, and some kinetic energy,  k of x, building up the total energy. ", " Classically, the kinetic energy determines the momentum.  The kinetic energy is p squared over 2m. ", "Now, the kinetic energy is p squared over 2m.  In this case, the kinetic energy is a constant.  The momentum will be a constant.  And then what we really want to just say something about ", "is the wave function.  Well, but if we note the momentum classically  it's a momentum p, we can infer the Broglie wavelength ", "of the particle.  And that the Broglie wavelength would be h over p.  And that's for the wave function. ", "So we should expect a wave function  that has a wave length equal to lambda.  After all, that is what the Broglie did. ", "And from the Broglie, you got the Schrodinger equation.  The Schrodinger equation, in fact,  says this, if you look at it again.  So if you look at the wave function. ", "Well, it must have wavelength lambda.  And therefore, I'm talking about real wave function.  So it could be a cosine or a sine that ", "has that wavelength lambda.  Of course in quantum mechanics, a cosine or a side  doesn't have exactly--  it's not an eigenstate of momentum. ", "But it's an eigenstate state of energy.  And we want to plug eigenstates of energy.  So you will have something like that, with that lambda.  ", "And that's intuition.  You go from the diagram to a kinetic energy,  from a kinetic energy to a momentum,  from a momentum to a wavelength, and that's the wavelength ", "of your energy eigenstate.  And maybe it's a good idea that you try to convince yourself  this is true by looking again at the Schrodinger equation. ", "For this simple case of a constant potential  and an energy that is big, you will find this result  very quickly.  But let's do now a more interesting case, in which here ", "is x.  And the potential is a growing function of x.   And there's a total energy here still.  ", "So if you are at some point here,  here is the potential of x.  And now, this is k of x.  ", "And now comes the interesting thing.  You see, as your particle, or whatever particle,  is moving here, the kinetic energy ", "is decreasing as you move to the right.  So the kinetic energy [INAUDIBLE]  velocity and slows down, slows down, slows down.  The kinetic energy is becoming smaller and smaller. ", "Therefore the momentum is becoming smaller and smaller.  And therefore the wavelength, the Broglie wavelength,  must be becoming bigger and bigger. ", "Now that is not exact because you really  have to solve the Schrodinger equation to do this.  But intuitively, you know that if a potential is constant, ", "this is absolutely true.  The kinetic energy, and the momentum,  and the Broglie waveform have related in this way.  It will be sort of true, or approximately true, ", "if the potential is not changing that fast.  Because then it's approximately constant.  So there's a notion the slowly changing potential, ", "in which we can talk about the k of x that is decreasing as we  move to the right, a p of x that is also decreasing, ", "and a lambda of x that would be increasing,  a wave with the Broglie wavelength that is increasing. ", "Now I should have written in here, maybe,  k of x, p of x, lambda of x.  This is decreasing, decreasing, increasing. ", "So I can plot it here.   And I would say, well, I don't know exactly how this goes.  But maybe it's the wavelength is small. ", "And then the wavelength is becoming  bigger, something like that.   Well, the wavelength's becoming bigger in the energy eigenstate ", "that you will find is true.   But there's also the question whether the amplitude  of the wave will change or not. ", "So we'll answer that in a couple of minutes.  But the Broglie wavelength now is becoming  a function of position. ", "Now, you know that solving the Schrodinger equation now  with an arbitrary potential is a difficult thing.  With a linear potentially it's a difficult problem,  in which the exact solution exists in terms of Airy ", "functions and things like that.  So this can only be an approximate statement  that the Broglie wavelength is becoming bigger and bigger, ", "because the momentum is becoming smaller and smaller.  But it's a very useful statement.  And whenever you look at wave functions of potentials,  you see that thing happening. ", "Questions?  ", "Let me draw another diagram that illustrates these issues.  ", "[SIDE CONVERSATION]  So let's draw a general picture of a potential ", "now, so we can make a few features here.  So here it is.  ", "We'll have a potential that is like this, v of x, maybe  some energy, e, and that's it. ", "Now what happens classically, well,  if your particle has some energy,  you know already this part is v of x. ", "This is k of x.  There is a potential energy and kinetic energy.  The kinetic energy cannot become negative classically.  So the particle cannot go to the left of this point called xl, ", "x to the left.  So this region, x left, is the classically forbidden. ", " Similarly on the right, you cannot go beyond here.  Because then you would have negative kinetic energy. ", "So this is an x right.  And everything to the right [INAUDIBLE],  x right, is also classical forbidden.  ", "These points, x left and x right,  are called turning points.  ", "Because those are the points where  a particle, a classical particle,  if it lives in this potential, has to bounce back and turn. ", "As we mentioned, at any general point,  you have v of x and k of x. ", "And this point, for example, is the point  with maximum k of x or maximum velocity. ", " This is the point where the particle is moving the fastest.  And it always slows down as it reaches the turning point. ", "Because the kinetic energy is becoming smaller and smaller.  So as we said, if you had a constant potential, ", "this would be the solution.  It's constant p, constant lambda,  nice, simple wave function.  If it's not constant, well, nothing is guaranteed. ", "But if it's sufficiently constant or slowly varied,  then you're in good shape.  Now what is the meaning of slowly varying? ", "The meaning of slowly varying has  to be said in a precise way.  And this is what leads eventually ", "to the so-called WKB approximation of quantum  mechanics.  Because we're giving you the first results of this  approximation that you can understand classically ", "how they go.  To mean that you have a slowly varying potential,  is a potential whose percentage change ", "is small in the relevant distances.  So it's the change in the potential  over the relevant distance must be small ", "compared to the potential.  But what is a relevant distance?  If we use intuition from quantum mechanics,  it's at the Broglie wavelength at any point. ", "That is what the quantum particle sees.  So what we need is that the change  in the potential over at the Broglie wavelength-- ", "take the derivative multiply it by that.  The Broglie wavelength must be much smaller  than the potential itself.   And notice, of course, the potential is a function of x. ", "And even lambda is a function of x there  at the Broglie wavelength.  Now, an exact solution will not be a sine or a cosine. ", "So to say has a precise defined wavelength is an approximation.  It is the approximation of slowly varying.  But it's a nice approximation. ", "And this lambda is the lambda that  would come as h over p of x. ", "And h over p of x is the square root of 2m  times the kinetic energy over h squared-- ", "no, it's just that, the square root of 2mk.  ", "Square root of 2mk of x.  ", "So the idea is that you can roughly  say that the Broglie wavelength here is of some value here.  The momentum is small if the Broglie wavelength is large. ", "And so when you draw things, you adjust that.  You say, OK, here, the momentum is large.  Therefore the Broglie wavelength is small.  So you write a short wavelength thing. ", "And then it becomes longer wavelength and then shorter.  And you just tried to get some insight  PROFESSOR: There's one more property of this thing that  is important, and it's something called the correspondence ", "principle, which is another classical intuition.  And it says that the wave function,  and it addresses the question of what ", "happens to the amplitude of the wave function.  It says that the wave function should be larger in the regions  where the particle spends more time. ", "So in this problem, you have the particle going here.  It's bouncing and it's going slowly here,  it's going very fast here. ", "So it spends more time here, spends a lot of time  here, spends a lot of time here.  So it should be better in these regions  and smaller in the regions that spends little time. ", "So this was called the correspondence principle,  which is a big name for a somewhat vague idea. ", "But nevertheless, it's an interesting thing  and it's true as well.  So let me explain this a little more  and get the key point about this. ", "So we say, if you have a potential, you have x and x  plus dx, so this is dx, the probability ", "to be found in the x is equal to psi squared dx, ", "and it's proportional to the time spent there.  So we'll say that it's-- ", "we'll write it in the following way.  It's proportional to the fraction of time spent in dx. ", "And that, we'll call little t over the period of the motion  in this oscillation. ", "The classical particle is doing, the period there.  ", "That's the fraction of time it spends there.  Up two factors of 2, maybe, because it  spends going there and there for the whole period,  it doesn't matter, it's anyway approximate. ", "It's a classical intuition expressed as the correspondence  principle.  So this is equal to dx over v, over the velocity that ", "positioned the [INAUDIBLE] velocity T.  And this is there for dx.  And the velocity is p over m, so the mass ", "over period and the momentum.   So here we go.  Here's the interesting thing. ", "We found that the magnitude of the wave function  should be proportional to 1 over p of x, ", "or lambda over h bar of x.   So then the key result is that the magnitude of the wave ", "function goes like the square root  of the position the [INAUDIBLE] de Broglie wavelength.  So if here the de Broglie wavelength is becoming bigger ", "because the momentum is becoming smaller,  the logic here says that yes indeed, in here,  the particle is spending more time here, ", "so actually, I should be drawing it a little bigger.  ", "So when I try to sketch a wave function in a potential,  this is my best guess of how it would be.  And you will be doing a lot of numerical experimentation ", "with Mathematica and get that kind of insight.  They position the [INAUDIBLE] de Broglie wavelength as you have,  it is a function of the local kinetic energy. ", "And that's what it gives for you.  OK so that is one key insight into the plot of the wave  function. ", "Without solving anything, you can  estimate how the wave length goes,  and probably to what degree the amplitude goes. ", "What else do you know?  There's the node theorem that we mentioned, again,  in the case of the square well.  The ground state, the bounce state, the ground state bounce ", "state is a state without the node.  The first excited state has one node,  the next excited state has two nodes, the next, three nodes, ", "and the number of nodes increase.  With that information, it already  becomes kind of plausible that you can sketch a general wave  PROFESSOR: OK, so, local picture. ", " It's all about getting insight into how ", "the way function looks.  That's what we'll need to get.  These comments now will be pretty useful.  For this equation you have one over psi, ", "d second psi, d x squared is minus 2 m  over h squared, E minus v of x. ", "Look how I wrote it, I put the psi back here,  and that's useful.  ", "Now, there's a whole lot of discussion--  many textbooks-- about how the way function  looks, and they say concave or convex, but it depends. ", "Let's try to make it very clear how the wave function looks.  For this we need two regions.  So, the first case, A, is when the energy minus v of x ", "is less than 0.  The energy is less than v of x, that's a forbidden region--  as you can see there-- ", "so it's a classically forbidden.  Not quantum mechanically forbidden,  but classically forbidden.  ", "What is the main thing about this classically forbidden  region is that the right hand side of this equation  is positive.  ", "Now, this gives you two possibilities.  It may be that psi at some point is positive, in which case ", "the second psi must also be positive,  because psi and the second psi appear here.  If both are positive, this is positive. ", "Or, it may be case two, that psi is negative,  and the second psi--  the x squared-- it's also negative. ", " Well, how do we plot this?  Well, you're at some point x, and here it ", "is, a positive wave function seems  to be one type of convexity, another type of convexity  for a negative, that's why people get a little confused  about this. ", "There's a way to see in a way that there's is no confusion.  Look at this, it's positive, second derivative positive.  When you think of a second derivative positive, ", "I think personally of a parabola going up.  So, that's how it could look.  The wave function is positive, up, it's all real. ", "We're using the thing we proved at the beginning  of this lecture: you can work with real things, all real.  So, the wave from here is x, and here negative. ", "And the negative opening parabola,  that's something they got.  So nice.  So, the wave function at any point ", "could look like this if it's positive,  or, it could look like this if it's negative.  So, it doesn't look like both, it's not double value. ", "So, either one or the other.  But, this is easy to say in words,  it is a shape that is convex towards the axis. ", "From the axis it's convex here and convex there.  So, convex towards the axis. ", " Now, there's another possibility I want to just  make sure you visualize this.  Sometimes this looks funny-- doesn't mean actually the way ", "function can look like that--  but, it's funny because of the following reason.  It's funny because if you imagine it going forever, ", "it doesn't make sense because you're  in a classically the forbidden region.  And the way function's becoming bigger and bigger  is going to blow up.  So, eventually something has to happen. ", "But, it can look like this.  So, actually what happens is that when you're  going to minus infinity--  here is x and we use minus infinity-- ", "it can look like this.  This is an example of this piece that is asymptotic,  and it's positive, and the second derivative is positive. ", "Or, negative and the second derivative is negative.  So that's a left asymptote.  Or, you could have a right asymptote,  and it looks like this. ", "Again, second derivative positive, positive wave  function.  Second derivative negative, negative wave function.  So, you may find this at the middle of the potential, ", "but then eventually something has to take over.  Or, you may find this behavior, or this behavior, at plus minus  infinity.  But, in any case you are in a classically forbidden, ", "you're convex towards the axis.  That's the thing you should remember.   On the other hand, we can be on the classically allowed region. ", " So, let's think of that.  ", "Any questions about the classically forbidden?  ", "Classically allowed, B. E minus v of x greater than 0,  classically allowed. ", " On the right hand side of the equation is negative.  So, you can have, one, a psi that is positive, ", "and a second derivative that is negative.  Or, two, a psi that is negative, and a second derivative ", "that this positive.  So, how does that look?  Well, positive and second derivative negative, ", "I think of some wave function as positive, and negative  is parabolic like that.  ", "And then, negative and second derivative positive,  it's possible to have this.  The wave function there it's negative, ", "but the second derivative is positive.  These things are not very good--  they're not very usable asymptotically,  because eventually if you are like this, ", "you will cross these points.  And then, if you're still in the allowed region  you have to shift.  But, this is done nicely in a sense if you put it together  you can have this. ", " Suppose all of this is classically allowed.  Then you can have the wave function being positive,  the second derivative being negative,  matching nicely with the other half. ", "The second derivative positive, the wave function negative,  and that's what the psi function is.   It just goes one after another. ", "So, that's what typically things look  in the classically allowed region.  So, in this case, we say that it's concave towards the axis. ", "", "That's probably worth remembering.  So, one more case.  The case C, when E is equal to E minus v of x not is equal to 0. ", "So, we have the negative, the positive, 0.  How about when you have the situation where  the potential at some point is equal to the energy? ", "Well, that's the turning points there--  those were our turning points.  So, this is how x 0 is a turning point. ", " And, something else happens, see, the right hand side is 0. ", " We have that one over psi, the second psi,  the x squared is equal to 0. ", "And, if psi is different from 0, then you  have the second derivative must be 0 at x not. ", " And, the second derivative being 0 is an inflection point.  ", "So, if you have a wave function that has an inflection point, ", "you have a sign that you've reached a turning point.  An inflection point in a wave function  could be anything like that. ", "Second derivative is positive here--  I'm sorry-- is negative here, second derivative is positive,  this is an inflection point.  ", "It's a point where the second derivative vanishes.  So, that's an inflection point.  And, it should be remarked that from that differential ", "equation, you also get that the second psi, the x squared,  is equal to E minus v times psi, which is constant. ", "And, therefore, when psi vanishes,  you also get inflection points automatically  because the second derivative vanishes. ", "So, inflection points also at the nodes.  ", "Turning point is an inflection point  where you have this situation.  Look here, you have negative second derivative, positive ", "second derivative, the point where the wave  function vanishes and joins them is an inflection point as well.  Is not the turning point--  turning point are more interesting-- ", "PROFESSOR: Here is your potential.  It's going to be a smooth, nice potential like that.  V of x. ", " x, x.  And now, suppose you don't know anything ", "about the energy eigenstates.  Now, this potential will be assumed to be symmetric.  So here is one thing you can do. ", "You can exploit some things that you know about this potential.  And here's the wave function that we're  going to try to plot.  And we could say the following. ", "Let's see.  Whatever energy are here, for bound states,  I'm going to eventually be in the forbidden region. ", "So far on the right here, I will be in the forbidden region.  And I must meet the wave function  that looks like the forbidden region wave function. ", "And the only possibility is something like that.   You could say it's the [INAUDIBLE] of 1,  but actually, if it's a [INAUDIBLE] then ", "I could multiply by minus 1 and use this one conventionally.  That wave function is always going  to be like that over there. ", "On the other hand, very important-- the  on the very left, how will the wave function look? ", "Well it also has to decay, so it can decay like that,  or it might be decaying like this. ", "And in fact, you don't know until you figure out  what's happening in the middle.  It may be decaying like this or like that.  I fix the sign here, so whatever this ", "does it should either end up like that or end up like that.  So these are the guidelines that you have to solve this.  Should begin like that, and we'll see. ", "And it should be either symmetric or anti-symmetric.  This would be the case anti-symmetric,  this would be the case symmetric.  OK.  So let's draw one, two, three, four lines there. ", "One, two, three, and four.  ", "And I don't know where the energies lie.  I don't know what is the ground state energy.  And I want to give you an insight into how ", "you can figure out why you get this energy one decision  when this happens.  So let's plot the wave function for the first case. ", "I don't know if I have a label, but let's assume  this is E0, E1, E2, E3. ", "Three energies [INAUDIBLE], and here's the one for e0.  OK.  So I begin here, that's how it goes. ", "And then I go through my Schrodinger equation,  integrate it.  You see?  Numerical, you can always integrate the Schrodinger  equation.  And this should be always in this region, let me-- ", "like this.  And it's growing.  And, oops, there should be turning points here.  There should be turning points--  ", "suppose this is--  I'm not going to get this so well, but it goes like this.  And now this should be a turning point. ", "So I should change to the other type of curvature,  curvature down.  But what probably will happen with E0 is that it will switch ", "and it will go like and start to curve, maybe.  Well, if it looks like that, it must ", "match to the development of the odd piece or the even piece.  Now, it's never going to match with the odd one,  so it might be with the even.  And yes, it would match turning point here, ", "but look what has happened here.  You got the corner there.  You know, this was turning slowly,  and this is starting to turn slowly, ", "but here there is a discontinuity  in the derivative.  So this is not the solution.  You try, but you fail.  But that's-- right. ", "Not every energy gives a solution.  So they should have matched continuously  and derivative continuously at that point, ", "but it didn't have enough time to do that.  On the other hand, if we try the next one, maybe. ", "The turning points will be here.   Let's see what happens.  Well, now the forbidden energies are over here, ", "and now you have a turning point here that--  in here, the curvature is negative,  the second derivative's curvature. ", "And it's larger than it was here.  Here it was small, here it's larger.  So it's going to curve faster.  Maybe if you get the E1 right, it ", "will curve enough so this flat here, in which case  the other side will match nicely and you've got the solution. ", "So you probably have to go little by little  until this becomes flattened and, boom,  you've got the solution.  Energy eigenstate. ", "Let's go a little further.   This graph continues there. ", "Now I want to go to E2.  How am I going to do that?  I'm going to do it this way.   So this was here, this was there. ", "There is the vertical line here.  And for E2, the turning points are even further out.  ", "And here is the wave function.  And let's look at this thing that I have.  Now, the turning point in this one corresponds  to the E2 turning point. ", "This is E1.  And now this will go in here, we'll turn,  and we will go curve and maybe do something like that. ", "Because it's curving more and more, and faster.  So by the time you reach here, this  is no good, because this one will be symmetric. ", "You know, you would have an anti-symmetric one  that is no use.  But now you don't have a solution, again.  So as you increase the energy, this is starting to do this, ", "and that is not quite so good.  And then when you go to E3, you have a turning point over here.  ", "So maybe in this case it will go up here  and it will start turning, and it will turn enough to just-- ", "this dip go to the origin.  OK.  You're saying no good either, because this is terrible, this  continuous.  But, ah, you were supposed to draw the other one as well. ", "The old one is actually perfect for it.  So this is dash, it doesn't exist,  and this one matches here. ", "So by the time the dip--  this is not a solution, but the dip goes down and down,  and eventually goes to zero, it matches with this one. ", "That's why I said sometimes you don't know whether this matches  with the one that comes from here  or the one that comes from the bottom.  So there you go.  This is an energy eigenstate again. ", "It's odd and it has one node.  And that gives you the intuition how,  as you sort of come from the end and you reach the middle, ", "you sometimes match things or sometimes don't match.  And explains why you get energy quantization.   The other way in which you're going to gain intuition ", "is with the so-called shooting method,  which is the last thing I want to discuss for a minute.   So the shooting method in differential equations ", "is quite nice.  Shooting method.   Suppose you have a potential that this symmetric may ", "be something like this--  it doesn't look very symmetric.   It looks a little better now. ", "And you want to find energy eigenstates.   You do the following.  You say, well, the normalization of the energy eigenstates ", "is not so important.  Let's look for even states.   Now, you can look for even or odd states ", "if the potential is symmetric.  Sometimes the potential will have a wall, in which case  you have to require a symmetric potential. ", "It's easy to solve, as well.  But let's consider the case when the potential is symmetric  and you look for even states.  So what you do is just, say, you pick an energy. ", "Pick some energy E0.  And then you put some boundary condition.  You say that the wave function at x equals 0 is 1. ", "And then you say that the derivative of the wave function  at x equals zero is how much?  Any suggestion?  How much should it be? ", "You see, you have a second order differential equation.  The second psi is equal to E minus V. That's the Schrodinger ", "equation.  You need-- the boundary conditions are the value of psi  and the derivative at one point, and then the computer  will integrate for you. ", "Mathematica will do it.  But you have to give me the derivative, so  what should I put?  A number there, 1, 2, 3?  Is that an unknown? ", "What should I pick?  We must put in the 0, because if you had a wave function whose  derivative is not 0, and it's an even wave function, ", "it would look like this.  And there would be a discontinuity in psi prime--  discontinuous.  And that's not possible unless you have a hard wall ", "or you have a delta function.  So you must put this.  And then you integrate numerically.  Numerically. ", " And what will happen?  Well, if you integrate numerically,  the computer is just going to integrate and see no problem. ", "Basically, it's just going to do the interview.  Ask the computer to calculate the wave function out  to x equal 5, it will calculate it.  So the problem is that-- ", "you can see visually, if you pick some energy,  the wave function will do like something,  and then will start blowing up. ", " And then you say, oh, that energy  is no good because the wave function won't be normalizable. ", "And then you go back to the computer  and change the energy a little bit,  and then you will find, well, maybe this.  Now it blows up in the other direction. ", "No good either.  But in some energy in between, as you change,  there must be one in which it does  the right thing, which is BK. ", "Somewhere in between.  And numerically, you change the value of the energy,  you go-- in the shooting method, when you shoot  it either goes up or down.  And you start working within those two numbers ", "to restrict it until you get here.  If you have a solution with five-digit accuracy,  it will do this, this, this, and then blow up. ", "If you have a solution with 10 digits after it,  it will do this and go up to here and blow up again.  You need 500-digits accuracy to get that wall. ", "But it's a fun thing that you can do numerically and play  with it.  You can calculate five digits accuracy, ten digits accuracy  within a matter of minutes. ", "It's very practical, and it's very nice,  but one thing you have to do is clean up your equation  before you start.  You cannot have an equation in Mathematica with h-bar and m ", "and all that.  So you have to clean up the units, is the first step,  and write it as an equation question without units.  Your And this plots very nicely in Mathematica, ", "and you will have lots of practice. "], "vid_duration": [12.11, 14.79, 14.31, 14.28, 10.89, 13.26, 11.01, 14.69, 12.67, 12.06, 10.49, 11.03, 11.31, 10.1, 11.49, 11.19, 10.41, 10.71, 13.745, 10.511, 14.324, 13.18, 13.32, 10.46, 14.02, 12.27, 11.62, 13.6, 11.47, 10.98, 11.59, 16.83, 11.52, 10.61, 14.25, 12.23, 11.17, 10.33, 12.22, 10.21, 11.79, 11.84, 10.95, 12.83, 14.82, 15.166, 16.724, 15.0, 23.39, 12.74, 12.47, 11.53, 13.83, 16.23, 11.7, 14.27, 11.08, 10.38, 12.84, 10.313, 12.18, 21.22, 12.09, 27.34, 12.2, 13.92, 11.909, 10.74, 14.28, 10.429, 11.712, 19.26, 11.23, 12.119, 12.271, 16.91, 12.319, 10.73, 11.561, 19.289, 13.701, 10.08, 11.699, 10.591, 10.23, 10.65, 11.49, 19.1, 13.08, 11.708, 11.28, 14.152, 12.699, 21.901, 14.925, 14.865, 13.01, 10.02, 12.9, 11.8, 15.34, 11.22, 11.01, 10.98, 10.549, 10.011, 11.14, 10.93, 10.59, 10.69, 11.51, 10.899, 10.591, 13.09, 15.118, 16.152, 11.966, 13.083, 11.141, 10.17, 10.89, 13.11, 11.855, 13.215, 10.606, 10.334, 10.97, 10.869, 12.75, 13.355, 11.385, 14.911, 10.039, 11.471, 12.349, 12.42, 10.421, 11.199, 14.63, 14.81, 13.94, 12.58, 10.261, 10.679, 10.81, 11.21, 10.681, 14.299, 13.49, 12.3, 13.845, 13.836, 11.016, 11.394, 12.98, 12.05, 14.71, 13.51, 10.849, 14.75, 15.75, 12.45, 10.871, 14.77, 11.46, 11.04, 13.948, 10.25, 12.451, 13.21, 15.04, 10.29, 12.86, 18.171, 10.71, 16.73, 14.534, 12.455, 12.42, 10.011, 10.859, 10.101, 11.859, 11.701, 12.49, 11.66, 12.438, 11.562, 12.45, 11.67, 12.42, 10.83, 16.02, 13.37, 10.97, 10.3, 10.46, 11.409, 10.081, 14.79, 12.68, 11.92, 13.85, 11.52, 14.34, 12.06, 14.08, 10.659, 14.92, 11.071, 10.17, 10.77, 16.37, 10.54, 10.74, 13.57, 13.01, 10.88, 10.8, 13.41, 14.01, 19.81, 12.44, 10.75, 11.63, 14.86, 10.1, 10.68, 11.12, 10.059, 11.064, 10.697, 11.54, 12.83, 10.469, 12.11, 20.43, 10.32, 16.731, 16.179, 11.811, 11.549, 11.334, 10.717, 10.48, 10.41, 12.99, 13.77, 10.14, 10.4, 13.95, 10.962, 15.547, 11.42, 10.971, 10.409, 10.741, 13.049, 10.631, 13.88, 18.17, 11.49, 12.07, 12.614, 18.756, 14.92, 10.86, 10.24, 12.29, 12.949, 11.686, 12.694, 10.91, 14.741, 12.139, 21.301, 11.849, 12.47, 10.911, 14.11, 14.85, 19.19, 11.23, 12.37, 12.83, 11.219, 12.431, 10.12, 14.28, 11.989, 11.68, 10.89, 10.88, 13.66, 11.47, 11.3, 10.77, 10.92, 11.32, 11.51, 11.05, 11.469, 13.791, 16.43, 13.69, 10.32, 14.485, 10.935, 12.41, 15.705, 11.845, 10.05, 10.99, 10.69, 17.4, 11.34, 12.27, 11.14, 10.009, 16.54, 10.521, 10.56, 13.5, 12.21, 10.0, 13.6, 11.45, 12.29, 14.32, 12.06, 12.779, 14.431, 10.45, 14.01, 14.47, 10.96, 11.94, 13.04, 12.53, 13.89, 12.55, 12.179, 13.601, 12.02, 13.35, 12.42, 16.32, 12.81, 10.84, 10.34, 10.7, 11.93, 11.06, 10.58, 15.06, 11.56, 11.525, 12.685, 13.39, 13.809, 12.961, 10.2, 10.92, 12.18, 12.84, 10.72, 1.091], "stet": [[0, 12.11], [12.11, 26.9], [26.9, 41.21], [41.21, 55.49], [55.49, 66.38], [66.38, 79.64], [79.64, 90.65], [90.65, 105.34], [105.34, 118.01], [118.01, 130.07], [130.07, 140.56], [140.56, 151.59], [151.59, 162.9], [162.9, 173.0], [173.0, 184.49], [184.49, 195.68], [195.68, 206.09], [206.09, 216.8], [216.8, 230.54500000000002], [230.54500000000002, 241.056], [241.056, 255.38000000000002], [255.38000000000002, 268.56], [268.56, 281.88], [281.88, 292.34], [292.34, 306.35999999999996], [306.35999999999996, 318.62999999999994], [318.62999999999994, 330.24999999999994], [330.24999999999994, 343.84999999999997], [343.84999999999997, 355.32], [355.32, 366.3], [366.3, 377.89], [377.89, 394.71999999999997], [394.71999999999997, 406.23999999999995], [406.23999999999995, 416.84999999999997], [416.84999999999997, 431.09999999999997], [431.09999999999997, 443.33], [443.33, 454.5], [454.5, 464.83], [464.83, 477.05], [477.05, 487.26], [487.26, 499.05], [499.05, 510.89], [510.89, 521.84], [521.84, 534.6700000000001], [534.6700000000001, 549.4900000000001], [549.4900000000001, 564.6560000000002], [564.6560000000002, 581.3800000000002], [581.3800000000002, 596.3800000000002], [596.3800000000002, 619.7700000000002], [619.7700000000002, 632.5100000000002], [632.5100000000002, 644.9800000000002], [644.9800000000002, 656.5100000000002], [656.5100000000002, 670.3400000000003], [670.3400000000003, 686.5700000000003], [686.5700000000003, 698.2700000000003], [698.2700000000003, 712.5400000000003], [712.5400000000003, 723.6200000000003], [723.6200000000003, 734.0000000000003], [734.0000000000003, 746.8400000000004], [746.8400000000004, 757.1530000000004], [757.1530000000004, 769.3330000000003], [769.3330000000003, 790.5530000000003], [790.5530000000003, 802.6430000000004], [802.6430000000004, 829.9830000000004], [829.9830000000004, 842.1830000000004], [842.1830000000004, 856.1030000000004], [856.1030000000004, 868.0120000000004], [868.0120000000004, 878.7520000000004], [878.7520000000004, 893.0320000000004], [893.0320000000004, 903.4610000000004], [903.4610000000004, 915.1730000000003], [915.1730000000003, 934.4330000000003], [934.4330000000003, 945.6630000000004], [945.6630000000004, 957.7820000000004], [957.7820000000004, 970.0530000000003], [970.0530000000003, 986.9630000000003], [986.9630000000003, 999.2820000000003], [999.2820000000003, 1010.0120000000003], [1010.0120000000003, 1021.5730000000003], [1021.5730000000003, 1040.8620000000003], [1040.8620000000003, 1054.5630000000003], [1054.5630000000003, 1064.6430000000003], [1064.6430000000003, 1076.3420000000003], [1076.3420000000003, 1086.9330000000002], [1086.9330000000002, 1097.1630000000002], [1097.1630000000002, 1107.8130000000003], [1107.8130000000003, 1119.3030000000003], [1119.3030000000003, 1138.4030000000002], [1138.4030000000002, 1151.4830000000002], [1151.4830000000002, 1163.1910000000003], [1163.1910000000003, 1174.4710000000002], [1174.4710000000002, 1188.6230000000003], [1188.6230000000003, 1201.3220000000003], [1201.3220000000003, 1223.2230000000004], [1223.2230000000004, 1238.1480000000004], [1238.1480000000004, 1253.0130000000004], [1253.0130000000004, 1266.0230000000004], [1266.0230000000004, 1276.0430000000003], [1276.0430000000003, 1288.9430000000004], [1288.9430000000004, 1300.7430000000004], [1300.7430000000004, 1316.0830000000003], [1316.0830000000003, 1327.3030000000003], [1327.3030000000003, 1338.3130000000003], [1338.3130000000003, 1349.2930000000003], [1349.2930000000003, 1359.8420000000003], [1359.8420000000003, 1369.8530000000003], [1369.8530000000003, 1380.9930000000004], [1380.9930000000004, 1391.9230000000005], [1391.9230000000005, 1402.5130000000004], [1402.5130000000004, 1413.2030000000004], [1413.2030000000004, 1424.7130000000004], [1424.7130000000004, 1435.6120000000003], [1435.6120000000003, 1446.2030000000002], [1446.2030000000002, 1459.2930000000001], [1459.2930000000001, 1474.411], [1474.411, 1490.563], [1490.563, 1502.529], [1502.529, 1515.612], [1515.612, 1526.7530000000002], [1526.7530000000002, 1536.9230000000002], [1536.9230000000002, 1547.8130000000003], [1547.8130000000003, 1560.9230000000002], [1560.9230000000002, 1572.7780000000002], [1572.7780000000002, 1585.9930000000002], [1585.9930000000002, 1596.5990000000002], [1596.5990000000002, 1606.9330000000002], [1606.9330000000002, 1617.9030000000002], [1617.9030000000002, 1628.7720000000002], [1628.7720000000002, 1641.5220000000002], [1641.5220000000002, 1654.8770000000002], [1654.8770000000002, 1666.2620000000002], [1666.2620000000002, 1681.1730000000002], [1681.1730000000002, 1691.2120000000002], [1691.2120000000002, 1702.6830000000002], [1702.6830000000002, 1715.0320000000002], [1715.0320000000002, 1727.4520000000002], [1727.4520000000002, 1737.8730000000003], [1737.8730000000003, 1749.0720000000003], [1749.0720000000003, 1763.7020000000005], [1763.7020000000005, 1778.5120000000004], [1778.5120000000004, 1792.4520000000005], [1792.4520000000005, 1805.0320000000004], [1805.0320000000004, 1815.2930000000003], [1815.2930000000003, 1825.9720000000004], [1825.9720000000004, 1836.7820000000004], [1836.7820000000004, 1847.9920000000004], [1847.9920000000004, 1858.6730000000005], [1858.6730000000005, 1872.9720000000004], [1872.9720000000004, 1886.4620000000004], [1886.4620000000004, 1898.7620000000004], [1898.7620000000004, 1912.6070000000004], [1912.6070000000004, 1926.4430000000004], [1926.4430000000004, 1937.4590000000005], [1937.4590000000005, 1948.8530000000005], [1948.8530000000005, 1961.8330000000005], [1961.8330000000005, 1973.8830000000005], [1973.8830000000005, 1988.5930000000005], [1988.5930000000005, 2002.1030000000005], [2002.1030000000005, 2012.9520000000005], [2012.9520000000005, 2027.7020000000005], [2027.7020000000005, 2043.4520000000005], [2043.4520000000005, 2055.9020000000005], [2055.9020000000005, 2066.7730000000006], [2066.7730000000006, 2081.5430000000006], [2081.5430000000006, 2093.0030000000006], [2093.0030000000006, 2104.0430000000006], [2104.0430000000006, 2117.9910000000004], [2117.9910000000004, 2128.2410000000004], [2128.2410000000004, 2140.6920000000005], [2140.6920000000005, 2153.9020000000005], [2153.9020000000005, 2168.9420000000005], [2168.9420000000005, 2179.2320000000004], [2179.2320000000004, 2192.0920000000006], [2192.0920000000006, 2210.2630000000004], [2210.2630000000004, 2220.9730000000004], [2220.9730000000004, 2237.7030000000004], [2237.7030000000004, 2252.2370000000005], [2252.2370000000005, 2264.6920000000005], [2264.6920000000005, 2277.1120000000005], [2277.1120000000005, 2287.1230000000005], [2287.1230000000005, 2297.9820000000004], [2297.9820000000004, 2308.0830000000005], [2308.0830000000005, 2319.9420000000005], [2319.9420000000005, 2331.6430000000005], [2331.6430000000005, 2344.1330000000003], [2344.1330000000003, 2355.793], [2355.793, 2368.231], [2368.231, 2379.793], [2379.793, 2392.243], [2392.243, 2403.913], [2403.913, 2416.333], [2416.333, 2427.163], [2427.163, 2443.183], [2443.183, 2456.553], [2456.553, 2467.5229999999997], [2467.5229999999997, 2477.823], [2477.823, 2488.283], [2488.283, 2499.692], [2499.692, 2509.773], [2509.773, 2524.563], [2524.563, 2537.243], [2537.243, 2549.163], [2549.163, 2563.013], [2563.013, 2574.533], [2574.533, 2588.873], [2588.873, 2600.933], [2600.933, 2615.013], [2615.013, 2625.672], [2625.672, 2640.592], [2640.592, 2651.663], [2651.663, 2661.833], [2661.833, 2672.603], [2672.603, 2688.973], [2688.973, 2699.513], [2699.513, 2710.2529999999997], [2710.2529999999997, 2723.823], [2723.823, 2736.833], [2736.833, 2747.713], [2747.713, 2758.5130000000004], [2758.5130000000004, 2771.9230000000002], [2771.9230000000002, 2785.9330000000004], [2785.9330000000004, 2805.7430000000004], [2805.7430000000004, 2818.1830000000004], [2818.1830000000004, 2828.9330000000004], [2828.9330000000004, 2840.5630000000006], [2840.5630000000006, 2855.4230000000007], [2855.4230000000007, 2865.5230000000006], [2865.5230000000006, 2876.2030000000004], [2876.2030000000004, 2887.3230000000003], [2887.3230000000003, 2897.3820000000005], [2897.3820000000005, 2908.4460000000004], [2908.4460000000004, 2919.1430000000005], [2919.1430000000005, 2930.6830000000004], [2930.6830000000004, 2943.5130000000004], [2943.5130000000004, 2953.9820000000004], [2953.9820000000004, 2966.0920000000006], [2966.0920000000006, 2986.5220000000004], [2986.5220000000004, 2996.8420000000006], [2996.8420000000006, 3013.573000000001], [3013.573000000001, 3029.752000000001], [3029.752000000001, 3041.563000000001], [3041.563000000001, 3053.112000000001], [3053.112000000001, 3064.446000000001], [3064.446000000001, 3075.163000000001], [3075.163000000001, 3085.643000000001], [3085.643000000001, 3096.053000000001], [3096.053000000001, 3109.0430000000006], [3109.0430000000006, 3122.8130000000006], [3122.8130000000006, 3132.9530000000004], [3132.9530000000004, 3143.3530000000005], [3143.3530000000005, 3157.3030000000003], [3157.3030000000003, 3168.2650000000003], [3168.2650000000003, 3183.8120000000004], [3183.8120000000004, 3195.2320000000004], [3195.2320000000004, 3206.2030000000004], [3206.2030000000004, 3216.6120000000005], [3216.6120000000005, 3227.3530000000005], [3227.3530000000005, 3240.4020000000005], [3240.4020000000005, 3251.0330000000004], [3251.0330000000004, 3264.9130000000005], [3264.9130000000005, 3283.0830000000005], [3283.0830000000005, 3294.5730000000003], [3294.5730000000003, 3306.6430000000005], [3306.6430000000005, 3319.2570000000005], [3319.2570000000005, 3338.0130000000004], [3338.0130000000004, 3352.9330000000004], [3352.9330000000004, 3363.7930000000006], [3363.7930000000006, 3374.0330000000004], [3374.0330000000004, 3386.3230000000003], [3386.3230000000003, 3399.2720000000004], [3399.2720000000004, 3410.9580000000005], [3410.9580000000005, 3423.6520000000005], [3423.6520000000005, 3434.5620000000004], [3434.5620000000004, 3449.3030000000003], [3449.3030000000003, 3461.4420000000005], [3461.4420000000005, 3482.7430000000004], [3482.7430000000004, 3494.5920000000006], [3494.5920000000006, 3507.0620000000004], [3507.0620000000004, 3517.9730000000004], [3517.9730000000004, 3532.0830000000005], [3532.0830000000005, 3546.9330000000004], [3546.9330000000004, 3566.1230000000005], [3566.1230000000005, 3577.3530000000005], [3577.3530000000005, 3589.7230000000004], [3589.7230000000004, 3602.5530000000003], [3602.5530000000003, 3613.7720000000004], [3613.7720000000004, 3626.2030000000004], [3626.2030000000004, 3636.3230000000003], [3636.3230000000003, 3650.6030000000005], [3650.6030000000005, 3662.5920000000006], [3662.5920000000006, 3674.2720000000004], [3674.2720000000004, 3685.1620000000003], [3685.1620000000003, 3696.0420000000004], [3696.0420000000004, 3709.702], [3709.702, 3721.172], [3721.172, 3732.472], [3732.472, 3743.242], [3743.242, 3754.1620000000003], [3754.1620000000003, 3765.4820000000004], [3765.4820000000004, 3776.9920000000006], [3776.9920000000006, 3788.042000000001], [3788.042000000001, 3799.511000000001], [3799.511000000001, 3813.302000000001], [3813.302000000001, 3829.732000000001], [3829.732000000001, 3843.422000000001], [3843.422000000001, 3853.742000000001], [3853.742000000001, 3868.227000000001], [3868.227000000001, 3879.162000000001], [3879.162000000001, 3891.572000000001], [3891.572000000001, 3907.277000000001], [3907.277000000001, 3919.1220000000008], [3919.1220000000008, 3929.172000000001], [3929.172000000001, 3940.1620000000007], [3940.1620000000007, 3950.8520000000008], [3950.8520000000008, 3968.252000000001], [3968.252000000001, 3979.592000000001], [3979.592000000001, 3991.862000000001], [3991.862000000001, 4003.002000000001], [4003.002000000001, 4013.011000000001], [4013.011000000001, 4029.551000000001], [4029.551000000001, 4040.072000000001], [4040.072000000001, 4050.632000000001], [4050.632000000001, 4064.132000000001], [4064.132000000001, 4076.342000000001], [4076.342000000001, 4086.342000000001], [4086.342000000001, 4099.942000000001], [4099.942000000001, 4111.392000000001], [4111.392000000001, 4123.682000000001], [4123.682000000001, 4138.002], [4138.002, 4150.062000000001], [4150.062000000001, 4162.841000000001], [4162.841000000001, 4177.272000000001], [4177.272000000001, 4187.722000000001], [4187.722000000001, 4201.732000000001], [4201.732000000001, 4216.202000000001], [4216.202000000001, 4227.162000000001], [4227.162000000001, 4239.102000000001], [4239.102000000001, 4252.142000000001], [4252.142000000001, 4264.6720000000005], [4264.6720000000005, 4278.562000000001], [4278.562000000001, 4291.112000000001], [4291.112000000001, 4303.291000000001], [4303.291000000001, 4316.892000000001], [4316.892000000001, 4328.912000000001], [4328.912000000001, 4342.2620000000015], [4342.2620000000015, 4354.682000000002], [4354.682000000002, 4371.002000000001], [4371.002000000001, 4383.812000000002], [4383.812000000002, 4394.652000000002], [4394.652000000002, 4404.992000000002], [4404.992000000002, 4415.692000000002], [4415.692000000002, 4427.622000000002], [4427.622000000002, 4438.6820000000025], [4438.6820000000025, 4449.262000000002], [4449.262000000002, 4464.322000000003], [4464.322000000003, 4475.882000000003], [4475.882000000003, 4487.407000000003], [4487.407000000003, 4500.092000000003], [4500.092000000003, 4513.482000000004], [4513.482000000004, 4527.291000000004], [4527.291000000004, 4540.252000000004], [4540.252000000004, 4550.452000000004], [4550.452000000004, 4561.372000000004], [4561.372000000004, 4573.552000000004], [4573.552000000004, 4586.392000000004], [4586.392000000004, 4597.112000000005], [4597.112000000005, 4598.203000000005]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [752, 1607, 2555, 2906, 3676, 4600]}
{"example_id": "mit035@@MIT8_04S16_lec18_300k", "text": ["PROFESSOR: I'll begin by reviewing quickly  what we did last time.  We considered what are called finite range potentials, ", "in which over a distance R, in the x-axis,  there's a non-zero potential.  So the potential is some v of x for x between capital R and 0, ", "is equal to 0 for x larger than capital R,  and it's infinity for x negative. ", "So there's a wall at x equals 0.  And there can be some potential, but this  is called a finite range potential, because nothing ", "happens after distance R.  As usual, we considered scattering solutions, solutions  that are unnormalizable with energies, ", "h squared k squared over 2m, for a particle with mass m.  And if we had no potential, we wrote the solution phi ", "of x, the wave function, which was sine of kx.   And we also wrote it as a superposition  of an incoming wave. ", "Now, an incoming wave in this set up  is a wave that propagates from plus infinity towards 0.  And a reflected wave is a wave that bounces back ", "and propagates towards more positive x.  So here we'll write this as minus  e to the minus ikx over 2i, plus e to the ikx over 2i. ", " This is the sine function rewritten ", "in terms of exponential in such a way that  here is the incoming wave.  Remember the time dependence is minus iet over h bar. ", "So this wave combined with a time  is a wave that is moving towards the origin.  This wave is moving outwards.  Then we said that there would be, in general, with potential. ", "With a potential, you would have a solution psi effects,  which we wrote after some tinkering in the farm  i delta sine of kx plus delta. ", " And if you look at the part of the phase that  has the minus ikx would have a minus delta and a delta here. ", "So they would cancel.  So this solution has the same incoming wave  as the no potential solution. ", "On the other hand here, you would have e to the 2i delta,  e to the ikx over 2i, and this solution ", "is only valid for x greater than R. You see,  this is just a plane wave after all.  There's nothing more than a plane wave and a phase shift. ", "The phase shift, of course, doesn't  make the solution any more complicated or subtle,  but what it does is, by depending on the energy, ", "this phase shift delta depends on the energy, and we're on k.  Then, it produces interesting phenomena  when you send in wave packets. ", "So if we write psi, we usually write  psi is equal to the phi plus psi s, ", "where psi s is called the scattered wave.  You see, the full wave that you get, for x greater than R,  we would have to solve and work very carefully to figure out ", "what is the wave function in the region 0 to R.  But for x greater than R is simple,  and for x greater than R the wave function psi ", "is the free wave function, in the case of no potential,  plus the scattered wave.  Quick calculation with this, things [? give to ?] you ", "the scatter wave is e to the i delta sine delta e to the ikx ", "is an outgoing wave.  And this coefficient is called the scattering amplitude.  It's the amplitude of the scattered wave. ", "This is a wave that is going out, and this is its amplitude.  So it has something to do with the strength of the scattering,  because if there was no scattering, ", "the wave function would just behave like the no  potential wave function.  But due to the potential, there is an extra piece,  and that represents an outgoing wave ", "beyond what you get outgoing with a free no potential wave  function.  So it's the scattering amplitude, ", "and therefore sometimes we are interested in as squared,  which is just sine squared delta.  ", "Anyway, those are the things we did last time.  And we can connect to some ideas that we were talking about ", "in the past, having to do with time delays,  by constructing a wave packet.  That's what's usually done.  Consider the process of time delay, which ", "is a phenomenon that we've observed  happens in several circumstances. ", "If you have an incident wave, how do you  construct an incident wave?  Well, it has to be a superposition of e  to the minus ikx, for sure. ", "So we'll put the function in front, we'll integrate over k,  and we'll go from 0 to infinity.  ", "I will actually add the time dependence as well.  So let's do phi of x and t.  Then, we would have e to the minus i, e of k, t over h bar, ", "and this would be valid for x greater than R.  Again, as a solution of the Schrodinger equation. ", " You see, it's a free wave.  There's nothing extra from what you know from the de Broglie ", "waves we started a long time ago.  So if this is your incident wave,  you have to now realize that you have this equation over here ", "telling you about the general solution of the Schrodinger  equation.  The general solution of the Schrodinger equation,  in this simple region, the outside region, ", "is of this form, and it depends on this delta  that must be calculated.  This is the incoming wave, this is the reflected wave, ", "and this is a solution.  So by superposition, I construct the reflected wave of x and t.  So for each e to the minus ikx wave, ", "I must put down one e to the ikx,  but I must also put an e to the 2i delta of the energy, ", "or delta of k.  And I must put an extra minus sign,  because these two have opposite signs,  so I should put a minus 0 to infinity dk f of k. ", "And we'll have the e to the minus i, e of k, e over h bar.  And just for reference, f of k is some real function that ", "picks at some value k naught.   So you see, just like what we did ", "in the case of the step potential, in which we  had an incident wave, a reflected wave  packet, a transmitted wave packet, the wave packets go  along with the basic solution. ", "The basic solution had coefficients A, B, and C,  and you knew what B was in terms of A and C.  Therefore, you constructed the incoming wave with A e to ikx, ", "and then the reflected wave with B e to the minus ikx.  The same thing we're doing here inspired by this solution, ", "the psi affects we superpose many of those,  and that's what we've done here.   Now of course, we can do the stationary phase calculations ", "that we've done several times to figure out  how the peak of the wave packet moves.  So a stationary phase at k equal k naught. ", "As you remember, the only contribution  can really come when k is near k naught, and at that point,  you want the phase to be stationary as a function of k. ", "I will not do here the computation again  for psi incident.  You've done this computation a few times already. ", "For psi incident, you find the relation between x and t,  and I will just write it.  It's simple. ", "You find that x is equal to minus h  bar k naught over mt, or minus some v velocity, group ", "velocity, times t.   That is the condition for a peak to exist.  The peak satisfies that equation, ", "and this makes sense when t is negative.  This solution for psi incident only makes sense for x positive  if in fact x greater than R. So this solution needs x positive. ", "So it needs t negative [? indeed. ?]  This is a wave that is coming from plus infinity,  x equal plus infinity, at time minus infinity, ", "and it's going in with this velocity.  For psi reflected, the derivative  now has to take the derivative of delta, with respect to e, ", "and then the derivative of e with respect to the energy.  And the answer, in this case--  ", "you've done this before--  it's v group times t minus 2 h bar delta prime of E. ", "So yes, in the reflected wave, x grows as t grows  and it's positive. ", "t must now be positive, but in fact,  if you would have a just x equal v group t,  this would correspond to a particle that  seems to start at the origin at time equals 0 and goes out. ", "But this actually there is an extra term subtracted.  So only for t greater than this number  the particle begins to appear. ", "So this is a delay, t minus some t naught,  the packet gets delayed by this potential. ", "Now, this delay can really get delayed.  Sometimes it might even accelerated,  but in general, the delay is given by this quantity ", "So I'll write it here.  The delay, delta t, is 2 h bar delta prime of E. ", "And let's write it in a way that you  can see maybe the units better and get a little intuition  about what this computation gives.  For that, let's differentiate this with respect to k, ", "and then k with respect to energy.  So v delta with respect to k, and dk with respect to energy. ", " This is 2 over 1 over h bar dE with respect to k. ", "I do a little rearrangement of this derivative  is one function of one variable k  and neither is a single relation.  So you can just invert it. ", "This is more dangerous when you have partial derivatives.  This is not necessarily true but for this ordinary derivatives  is true, and then you have this 2 to the left here. ", "The h bar went all the way down, and I have d delta dk.   And here, we recognize that this is 2, ", "and this is nothing else than the group velocity  we were talking before.  The E, the energy, is h squared k squared over 2m. ", "You differentiate, divide by h bar,  and it gives you the group velocity hk naught over m.  Because these derivatives all have ", "to be evaluated at k naught.  So this derivative is really evaluated at k naught.  This is also evaluated at k naught. ", " So this is the group velocity, d delta, dk, and finally, ", "let me rewrite it in a slightly different way.  I multiply by 1 over R. Why? ", "Because d delta dk, k has units of 1 over length.  So if I multiply by 1 over R, this will have no units.  So I claim that one over R d delta dk is equal to delta t, ", "and you'll have 2 over vg and R. So I did a few steps. ", "I moved the 2 over vg down to the left,  and I multiplied by 1 over R, and now we  have a nice expression. ", "This is the delay.  Delta t is the delay, but you now  have divided it by 2R divided by the velocity, which ", "is the time it takes the particle with the group  velocity to travel back and forth in the finite range ", "potential.  So that gives you an idea.  So if you compute the time delay,  again, it will have units of microseconds,  and you may not know if that's little or much. ", "But here, by computing this quantity,  not exactly delta prime of v but this quantity.  You get an [? insight, ?] because this is  the delay divided by the free transit time. ", "", "It's kind of a nice quantity.  You're dividing your delay and comparing it with the time  that it takes a particle, with a velocity that ", "is coming in, to do the bouncing across the finite range  PROFESSOR: So let's do an example where ", "we can calculate from the beginning  to the end everything.  Now, you have to get accustomed to the idea of even  though you can calculate everything, ", "your formulas that you get sometimes are a little big.  And you look at them and they may not  tell you too much unless you plot them with a computer. ", "So we push the calculations to some degree,  and then at some point, we decide  to plot things using a computer and get some insight ", "on what's happening.  So here's the example.   We have a potential up to distance, a, to 0. ", "The wall is always there, and this number is minus v naught.  So it's a well, a potential well. ", "And we are producing energy.  Eigenstates are coming here.   And the question now is to really calculate the solution ", "so that we can really calculate the phase shift.  We know how the solutions should read,  but unless you do a real calculation,  you cannot get the phase shift. ", "So that's what we want to do.  So for that, we have to solve the Schrodinger equation.  Psi of x is equal to what? ", " Well, there's a discontinuity.  So we probably have to write an answer in which we'll  have a solution in one piece and a solution in the other piece. ", "But then we say, oh, we wrote the solution  in the outside piece already.  It is known.  It's always the same. ", "It's universal.  I don't have to think.  I just write this.  E to the i delta.  I don't know what delta is, but that's ", "the answer, E to the i delta sine kx plus delta should  be the solution for x greater than a.  ", "You know if you were not using that answer,  it has all the relevant information  for the problem, time delays, everything,  you would simply write some superposition of E ", "to the i kx and E to the minus i kx with two coefficients.  On the other hand, here, we will have, again, a wave. ", "Now, it could be maybe an E to the i kx or E  to the minus i kx.  Neither one is very good because the wave function ", "must vanish at x equals 0.  And in fact, the k that represents the kinetic energy  here, k is always related to E by the standard quantity, ", "k squared equal to mE over h squared or E equal  the famous formula.  On the other hand, there is a different k here ", "because you have different kinetic energy.  There must be a k prime here, which is 2m E plus v naught. ", "That's a total kinetic energy over h squared.  And yes, the solutions could be E to the ik prime  x equal to minus ik prime x minus ik prime x, ", "but since they must vanish at 0, should be a sine function.  So the only thing we can have here  is a sine of k prime x for x less than a and a coefficient. ", "We didn't put the additional normalization here.  We don't want to put that, but then we  must put the number here, so I'll put it here.  ", "That's the answer, and that's k and k prime.   Now we have boundary conditions that x equals a. ", "So psi continues at x equals a.  What does it give you? ", "It gives you a sine of ka is equal to E to the i delta  sine of ka plus delta. ", "And psi prime continues at x equals a will give me  ka cosine ka equal-- ", "I have primes missing; I'm sorry, primes--  equals k E to the i delta cosine ka plus delta. ", " What do we care for?  Basically we care for delta. ", "That's what we want to find out because delta tells us  all about the physics of the scattering.  It tells us about the scattering amplitude, sine squared delta. ", "It tells us about the time delay, and let's calculate it.  Well, one way to calculate it is to take  a ratio of these two equations so that you get rid ", "of the a constant.  So from that side of the equation,  you get k cotangent of ka plus delta ", "is equal to k prime cotangent of k prime a.  ", "Or cotangent of ka plus delta is k prime over k.  We'll erase this. ", "And now you can do two things.  You can display some trigonometric wizardry,  or you say, OK, delta is arc cotangent of this minus ka. ", " That is OK, but it's not ideal.  It's better to do a little bit of trigonometric identities. ", "And the identity that is relevant  is the identity for cotangent of a plus b is cot a cot b minus 1 ", "over cot a plus cot b.  So from here, you have that this expression ", "is cot ka cot delta minus 1 over cot ka plus cot delta. ", "And now, equating left-hand side to this right-hand side,  you can solve for cotangent of delta. ", "So cotangent of delta can be solved for--  and here is the answer.  Cot delta is equal to tan ka plus k prime over k cot k ", "prime a over 1 minus k prime over k cot k prime a tan ka. ", " Now, who would box such a complicated equation?  Well, it can't be simplified any more. ", "Sorry.  That's a solution.  It's an accomplishment to have such a solution.  If somebody gives you a value of the energy,  you can calculate what is the phase shift, ", "but we probably want to do more with it.  So you decide to plot this on a computer. ", "Again, there's lots of variables going on here,  so you would want to figure out what are the right variables  to plot this.  And the right variables suggest themselves. ", "From k squared equal 2 me over h squared, unit less constant  are things like ka, k prime a, and that's it. ", "Well, so ka is a proxy for the energies.  OK, a squared is really 2me, a squared over h bar squared. ", " And so this we could call anything.  Well, let's call it u. ", "On the other hand, k prime squared then--  if you have k prime a squared that it's also unit free ", "would be 2me a squared over h squared plus 2mv0 ", "a squared over h squared.  You probably recognize them.  The first one is just u squared.  I should call this u squared, sorry. ", "U squared, and this is our friend z0 squared.   It's that number that tells you the main thing you always want ", "to know about a square well.  That ratio between the energy v0 to the demand to the energy  that you can build with h bar m and a. ", " So here we go.  We have k prime a given by this quantity,  and therefore let me manipulate this equation. ", "Might as well do it.  It probably easier to consider just tan delta, which  is the inverse of this.  You would have 1 minus the inverse ", "of this would be k prime a over ka, put the a's always,  so cot k prime a tan ka over tan ka plus k prime aka cot k ", "prime a.  So in terms of our variables, see  k prime a is the square root of this, ", "so k prime a square root of u squared plus z0 squared,  and k prime a over ka, you divide now by u. ", "So it's square root of 1 plus z0 squared over u squared.  That's this quantity.  So how big, how much space do I need to write it? ", "Probably, I should write it here.  1 minus square root of 1 plus z0 squared over u  squared cot k prime a is the square root of z0 squared ", "plus u squared and tan of k a, which is u over tan u ", "plus square root of 1 plus z0 over u  squared cotangent of square root of z0 squared plus u squared. ", "OK, it's not terrible.  That's tan delta.  So if somebody gives you a potential, ", "you calculate what z0 is for this potential,  you put z0 there, and you plot as a function of u  with Mathematica.  And plotting as a function of u is ", "plotting as a function of ka.  And that's perfectly nice thing to do.  And it can be done with this expression.  ", "In this expression, you can also see  what goes on when u goes to 0. ", "Not immediately, it takes a little bit of thinking,  but look at it.  As u goes to 0, well, these numbers  are 1, that's perfectly OK.  That seems to diverge, goes like 1 over u, but u going to 0. ", "This goes to 0.  So the product goes to a number.  So the whole-- the numerator goes to a number,  some finite number. ", "On the other hand, when u goes to 0,  the denominator will go to infinity,  because while this term goes to 0 the tan u, ", "this number is finite.  And here you have a 1/u.  So the denominator goes to infinity.  And the numerator remains finite.  So as u goes to 0, tangent of delta goes to zero. ", "So you can choose delta to be 0 for 0 energy.  So as u goes to 0, you get finite divided by infinity, ", "and goes to zero.  So tan delta goes to 0.  And we can take delta of ka equals 0, which is u to be 0. ", "The phase shift is 0 for 0 energy.   Let me go here. ", "So here is an example.  z0 squared equal 3.4.  That actually correspond to 0.59pi for z0. ", "z0 equal 0.59pi.  You may wonder why we do that, but let  me tell you in a second.  So here are a couple of plots that occur. ", "So here is u equals ka.  And here's the phase shift, delta of u.  You have the tangent of delta, but the phase shift ", "can be calculated.  And what you find is that, yes, it  starts at 0, as we mentioned.  And then it starts going down, but it ", "stabilizes at minus pi, which is a neat number.  ", "That's what the phase shift does.   The so-called scattering amplitude, well you  could say, when is this scattering strongest? ", "When you get an extra wave of this propagating more strongly?  So you must plot sine squared delta and sine squared is ", "highest for minus pi over 2.  So this goes like this, up, and decays as a function of u. ", " Third thing, the delay, is 1/a. ", " The delay is 1/a d delta dk, as a function of u. ", "So that, you can imagine, that takes a bit of time,  because you would have to find the derivative of delta  with respect to u, and do all kinds of operations. ", "Don't worry, you will have a bit of exercises on this  to do it yourselves.  But here the delay turns out to be negative.  And this is unit-free. ", "And here, comes to be equal minus 4 for equals 0,  and goes down to 0.  ", "So in this case, the delay is negative.  So the reflected packet comes earlier  than you would expected, which is possible, ", "because the reflected packet is going slowly here.  Finally, at this point, reaches more kinetic energy, just-- ", "and then back.  So that's the delay.  ", "And you can plot another thing.  Actually it's kind of interesting, is the quantity  a, this coefficient here. ", "That gives you an idea of how big the wave  function is in the well.  How much does it stick near the well?  So it peaks to 1. ", "And it actually goes like this, and that's  the behavior of this form.   Basically, it does those things.  So, so far so good. ", "We got some information.  And then you do a little experiment,  and try, for example, z0 equals 5. ", " And you have delta as a function of u,  and here is minus pi, minus 2pi. ", "And actually, you find that it just goes down, and approaches  now minus 2pi.  ", "So actually, if you increase this z0 a bit,  it still goes to pi, a pi excursion of the phase. ", "But suddenly, at some value, it jumps.  And it now goes to 2pi.  And if you do with a larger value, at some point ", "it goes to 3pi and 4pi.  And it goes on like that.   Well if z0 would have been smaller, like half of this, ", "the phase would go down and would go back up,  wouldn't go to minus pi.  It does funny things. ", "So what's really happening is that there  is a relation between how much the phase moves, ", "and how many bound states this potential has.  And you say, why in the world?  This calculation had nothing to do with bound states. ", "Why would the phase shift know about the bound states?  Well actually, it does.  And here is the thing.  If you remember, you've actually solved this problem ", "in homework, the half square well, in which you  put an infinite wall here.  And if you had the full square well, from minus a to a, ", "this problem has all the old solutions  of the full square well.  All the old solutions exist. ", "And if you remember the plots that you  would do in order to find solutions,  you have pi/2, pi, 3pi/2, 2pi. ", "And here is the even solution.  Here is the odd solution.  I'll do it like that.  Here is an even solution. ", "Here is an odd solution.  And I marked the odd solutions, because we  care about the odd ones, because that's what this potential has. ", "So z0 equals 0.59pi is a little more than pi/2.  So it corresponds to one solution. ", "So there is one bound state for this z0.  z0 equals 5 is about here. ", "it's in between 3pi/2 and this.  And there's two nodes, two intersections.  Therefore, two solutions in the square well. ", "And here we have that the phase has an excursion of, not just  pi for one, but 2pi.  ", "And if you did this experiment for awhile,  you would convince yourself there's  a magic relation between how much the phase shift moves, ", "and how many bound states you have in this potential.  This relation is called Levinson's theorem.  And that's what we're going to prove in the last half ", "PROFESSOR: Levinson's theorem, in terms of derivations,  that we do in this course, this is probably ", "the most subtle derivation of the semester.  It's not difficult, but it's kind of interesting  and a little subtle. ", "And it's curious, because it relates to things that  seem to be fairly unrelated.  But the key thing that one has to do ", "is you have to use something.  How all of the sudden are you going  to relate phase shifts to bound states?  The one thing you have to imagine  is that if you have a potential and you ", "have states of a potential, if the potential changes,  the states change. ", "But here comes something very nice.  They never appear or disappear.  And this is something probably you haven't thought about this ", "all that much.  Because you had, for example, a square, finite square well.  If you made this more deep, you've got more bound states. ", "If you made it less deep, the bound states disappear.  What does it mean the bound states disappear?  Nothing, really can disappear.  What really is happening, if you have the bounds, ", "the square well.  You have a couple of bound states, say.  But then you have an infinity of scatterings states. ", " And as you make this potential less shallow,  the last bound state is approaching here. ", "And at one state, it changes identity  and becomes a scatterings state, but it never gets lost.  And how, when you make this deeper and deeper ", "you get more state, is the scattering state  suddenly borrowing, lending you a state that goes down?  The states never get lost or disappear. ", "And you will, say, how could you demonstrate that?  That sounds like science fiction,  because, well, there's infinitely many states here.  How do you know it borrowed one? ", "Well, you can do it by putting it in a very large box.  And then the states here are going  to be finitely countable and discrete. ", "And then you can track and see indeed  how the states become bound.  So you'd never lose or gain states.  And that's a very, very powerful statement about quantum states ", "in a system.  So this is what we're going to need  to prove Levinson's theorem.   So Levinson theorem theorem-- ", " so it relates a number of bound states of the potential  to the excursion of the phase shift. ", "So let's state it completely.   It relates the number N of bound states of the potential ", "to the excursion, excursion of the phase from E equals 0 to E ", "equals infinity.  So in other words, it says that N is 1 over pi delta of 0  minus delta of infinity, a number ", "of bound states of your potential  is predicted by the behavior of the phase shift of scattering. ", "So how do we do this?  This is what we want to prove.  So consider, again, our potential of range R and 0 ", "here and here is x.   And I want you to be able to count states, ", "but discovering states are a continuous set of states.  So in order to count states, we're  going to put a wall here, as well, ", "at some big distance L much bigger than A than R.  And we're going, therefore-- ", "now the states are going to be quantized.  They're never going be quite scatterings states.  They're going to look like scatterings states.  But they're precisely in the way that they ", "vanished at this point.  Now you would say, OK, that's already a little dangerous  to be.  Oh, you've changed the problem a little, yes. ", "But we're going to do the analysis  and see if the result depends on L. If it doesn't depend on L  and L is very large, we'll take the limit this L goes ", "to infinity.  And we claim, we have answer.  So we argue that L is a regulator, regulator ", "to avoid a continuum, continuum of states ", "to avoid that continuum of states.   All right, so let's begin to count. ", "To count this thing, we start with the case  where there is no potential again.  ", "And why is that?  Because we're going to try to compare  the situation with no potential to the situation  with potential.  So imagine let V identical is 0, no potential ", "and consider positive energy states.  These are the only states that exist. ", "There are no bound states, because the potential is 0.   Well, the solutions were found before, we  mentioned that these are what we call phi effects or sine of kx. ", "But now we require that phi of L is equal to 0,  because we do have the wall there.  And therefore, si of kl must be 0 and kl must be n pi and n ", "is 1, 2 to infinity.  You know we manage with the wall to discretize this state, ", "because the whole world is now an infinite, a very big box,  not infinite, but very big.  So you've discrete the state.  The separations are microelectron volts, ", "but they are discrete.  You can count them.  And then with this state over here,  we think of counting them. ", "And you say, well, I can count them with n.  So if I imagine the k line from 0 to 50, ", "the other states are over, all the values of k.  And they could say, well, I even want  to see how many states there are in a little element dk. ", " And for the that you would have that dk taken  a differential here is dn times pi. ", "So of the number of states that there are in dk, dn--  let me right here--  dn equals l over pi dk is the number of positive energy ", "states in dk.   In the range dk, in the range of momentum, ", "dk that little interval, there are that many positive energy  eigenstates.  ", "So far, so good.  ", "So now let's consider the real case.  Repeat for the case there is some potential.  ", "Well, you would say, well, I don't know how to count.  I have to solve the problem of when the potential makes  a difference.  But no, you do know how to count. ", "So repeat for V different from 0.  This time we have a solution for x greater ", "than R. We know the solution.  This is our universal solution with the phase.  So there you have the si effect is e to i delta sine ", "kx plus delta of k.  That's a solution.   Yes, you have the solution always. ", "You just don't know what delta is.  But you don't know what delta--  you don't need to know what delta is to prove the theorem,  You just need to know it's there. ", "So here it goes.  And this time the wall will also do the same thing.  We'll demand the si of x vanishes for x equal L. ", "So this time we get that kx--  no kL plus delta of k is equal to some other number n ", "prime times pi multiple of pi.  This phase-- this total phase has to be a multiple of pi. ", "And what is n prime?  I don't know what is n prime?  It is some integers.  I don't know whether it starts from 1, 2, 3 or from 100  or whatever. ", "The only thing we care is that, again,  taking a little differential, you  have dk times L plus d delta, dk, ", "times dk is equal to the dn prime times pi.   We take an infinitesimal version of this equation, which again ", "tells me how many positive-- all these states are  positive energy states.  They have k.  So all these are positive energy states. ", " So from this equation, we get that dn prime is equal to L ", "over pi dk plus 1 over pi d delta dk times dk, which ", "gives me if I know the dk, again, the number of states  that you have in that range of k, ", "You see it's like momentum is now quantized.  So for any little range of momentum,  you can tell how many states there are.  And here it is how many states there are, positive energy ", "states, positive.  This is the number of positive energy states in dk with V ", "different from 0, here is with V equal 0.  ", "PROFESSOR: We have two equations now relating  this number of states.  And now you can say, oh, OK, so I look at the k line. ", "And I look at the little piece of the k  and say, oh, how many states were there  with 0 potential, some number, first blackboard.  How many states are there now with some potential, ", "some other number?  It has changed.  For every-- because these two equations, the n for equal dk,  the n is not equal to the dn prime. ", "In one case, the energy levels or the momentum levels  are more compressed or more separated,  but whatever it is, whatever the sign is, ", "there is a little discrepancy.  So both of them are giving me the total number  of positive energy states in the little dk. ", "Case So if I take the difference,  I will get some information.  So I would say the following, if I  want to calculate the number of positive energy solutions ", "and now I think the following, I take the potential V equals 0  and slowly but surely deepen it, push it, and do things  and create the potential V of x slowly, slow the formation. ", "In this process, I can look at a little interval dk  and tell how many states are positive energy states I lost. ", "So if, for example, dn is bigger than dn prime, dn equal 5  and dn prime is equal to 3, I started with 5 positive energy ", "states in this little interval and by the time  I change the potential I ended up with 3.  So I lost 2.  So let me write here the number of positive energy ", "solutions lost in the interval dk ", "as the potential is turned on is dn the original number ", "minus the dn prime.   If that's positive, I've lost state.  If it's negative, I gained state, positive energy states. ", "In this number, we can calculate the difference.  This is minus 1 over pi d delta dk dk. ", "I'll put it here.  ", "We'll we're not far.  We'll this is what you lost.  The number of positive energy eigenstates  that you lost in little dk. ", "To see how many positive energy states you lost over all,  you must integrate over all the dk's and see how much  you lost in every little piece. ", "So the number of positive energy solutions lost, not in the dk, ", "but lost as the potential is turned on ", "is equal to the integral over k from 0 to infinity of minus 1  over pi d delta dk is in the way of that expression ", "of that right coincide.  But this is a total derivative.  So this is minus 1 over pi delta of k evaluated ", "between infinity and 0.  And therefore, the number of states lost is 1 over pi,  because of the sign down to 0 minus delta of infinity. ", " So we're almost there. ", "This is the number of positive energy solutions lost.  Now I want to emphasize that the situation is quite interesting. ", "Let me make a little drawing here.  ", "So suppose here is the case where  you have the potential equal to 0  and here is energy equal to 0.  Then you have all these states. ", " Now even though we've put the wall, ", "the wall allows us to count the states,  but there are still going to be an infinite number of states.  The infinite square wall has an infinite number of states. ", "So that thing really continues, but what happens by the time v  is deferred from 0? ", "Here is that the E equals 0 line and here is  the E equals 0 line.  As we've discussed, as you change ", "the potential slowly, this are going to shift a little  and some are going to go down here, ", "are going to become bound states.  They're going to be a number of bound states, N bound states, ", "number of bound states equal N. And then  there's going to be still sub states here  that's also go to infinity. ", " So you cannot quite say so easily, well, ", "the number of states here minus the number of states here is  the number lost.  That's not true, because that's infinite, that's infinite,  and subtracting infinity is bad. ", "But you know that you've lost a number of finite number  of positive energy solutions. ", "So as you track here, the number of states must--  the states must go into each other. ", "And therefore, if these four states are now here,  before they were here, and those were the positive energy  solutions that were lost, in going from here to here, ", "you lost positive energy solutions.  You lost a finite number of positive energy solutions. ", "Even though there's infinite here and infinite here,  you lost some.  And you did that by keeping track at any place  how much you lost.  And therefore the states lost are never really lost. ", "They are the ones that became the band states here.  So the positive energy states that got lost  are the bound states.  So the number bound states is equal to the number ", "of positive energy solutions, because there  are no lost states.  So this is equal to a number of bound states,  because there are overall no lost states. ", ""], "vid_duration": [11.35, 17.08, 10.84, 12.47, 13.579, 13.711, 11.22, 12.15, 17.58, 10.46, 12.04, 16.46, 13.965, 14.245, 13.81, 12.79, 12.57, 14.26, 11.67, 14.18, 12.48, 10.8, 11.43, 11.82, 10.96, 12.53, 12.3, 18.42, 10.12, 12.34, 13.11, 10.81, 13.12, 12.85, 15.63, 11.255, 12.125, 17.34, 12.62, 11.11, 13.41, 11.46, 18.93, 14.1, 13.38, 13.52, 11.52, 11.35, 14.58, 19.752, 12.278, 10.74, 10.24, 14.66, 12.42, 16.56, 10.95, 14.44, 10.27, 16.78, 10.94, 14.73, 10.98, 10.41, 14.24, 11.34, 15.33, 11.935, 16.615, 12.65, 13.09, 12.48, 10.83, 10.17, 10.81, 11.89, 10.94, 23.548, 11.382, 13.18, 12.26, 13.5, 13.05, 16.27, 10.17, 10.73, 14.358, 12.03, 12.1, 12.47, 15.01, 12.4, 14.79, 13.07, 10.6, 12.71, 10.17, 10.39, 18.45, 12.57, 13.68, 12.96, 13.4, 12.3, 12.86, 12.54, 18.91, 10.48, 12.19, 10.74, 12.44, 16.03, 14.495, 10.305, 12.36, 15.67, 11.73, 11.52, 12.52, 17.285, 11.445, 16.11, 13.02, 17.0, 12.88, 16.31, 12.08, 10.101, 11.929, 13.44, 13.41, 13.32, 15.485, 10.225, 11.46, 10.2, 10.96, 12.0, 12.79, 15.38, 11.56, 24.06, 11.53, 14.42, 14.846, 15.584, 15.639, 16.091, 13.19, 11.52, 13.26, 10.15, 15.48, 10.42, 10.01, 17.19, 19.62, 15.1, 11.48, 18.47, 14.32, 12.31, 10.23, 11.63, 11.43, 13.29, 10.35, 12.0, 16.05, 11.35, 11.33, 10.26, 10.02, 10.07, 11.12, 11.59, 14.36, 15.17, 11.306, 12.234, 14.38, 13.98, 10.04, 16.87, 10.8, 10.78, 11.88, 12.51, 11.1, 10.56, 17.1, 12.57, 12.1, 11.33, 10.38, 10.02, 10.79, 14.06, 13.17, 10.13, 12.42, 12.54, 13.799, 10.111, 11.23, 12.69, 15.12, 11.619, 13.341, 11.329, 12.841, 10.679, 10.941, 14.389, 15.395, 14.235, 27.861, 16.719, 14.071, 12.02, 16.299, 11.021, 11.939, 10.871, 11.009, 11.151, 10.44, 14.15, 14.489, 11.701, 12.189, 16.061, 11.62, 16.6, 22.139, 10.897, 12.563, 12.511, 12.14, 13.909, 14.17, 20.091, 12.73, 11.759, 15.621, 16.17, 10.05, 12.909, 12.931, 12.589, 11.5, 15.681, 13.52, 14.67, 11.66, 12.73, 14.09, 15.259, 12.0, 18.011, 12.18, 12.75, 21.96, 11.505, 12.301, 11.71, 11.699, 11.211, 12.0, 14.009, 17.82, 13.031, 11.239, 18.721, 14.68, 17.269, 14.651, 14.949, 19.43, 10.86, 11.43, 16.46, 11.74, 19.49, 16.581, 14.89, 10.98, 11.059, 14.26, 10.331, 11.98, 11.14, 12.279, 12.71, 11.25, 12.752, 10.949, 11.349, 11.79, 10.83, 10.31, 13.23, 12.9, 14.431, 13.559, 22.731, 0.646], "stet": [[0, 11.35], [11.35, 28.43], [28.43, 39.269999999999996], [39.269999999999996, 51.739999999999995], [51.739999999999995, 65.31899999999999], [65.31899999999999, 79.02999999999999], [79.02999999999999, 90.24999999999999], [90.24999999999999, 102.39999999999999], [102.39999999999999, 119.97999999999999], [119.97999999999999, 130.44], [130.44, 142.48], [142.48, 158.94], [158.94, 172.905], [172.905, 187.15], [187.15, 200.96], [200.96, 213.75], [213.75, 226.32], [226.32, 240.57999999999998], [240.57999999999998, 252.24999999999997], [252.24999999999997, 266.42999999999995], [266.42999999999995, 278.90999999999997], [278.90999999999997, 289.71], [289.71, 301.14], [301.14, 312.96], [312.96, 323.91999999999996], [323.91999999999996, 336.44999999999993], [336.44999999999993, 348.74999999999994], [348.74999999999994, 367.16999999999996], [367.16999999999996, 377.28999999999996], [377.28999999999996, 389.62999999999994], [389.62999999999994, 402.73999999999995], [402.73999999999995, 413.54999999999995], [413.54999999999995, 426.66999999999996], [426.66999999999996, 439.52], [439.52, 455.15], [455.15, 466.405], [466.405, 478.53], [478.53, 495.86999999999995], [495.86999999999995, 508.48999999999995], [508.48999999999995, 519.5999999999999], [519.5999999999999, 533.0099999999999], [533.0099999999999, 544.4699999999999], [544.4699999999999, 563.3999999999999], [563.3999999999999, 577.4999999999999], [577.4999999999999, 590.8799999999999], [590.8799999999999, 604.3999999999999], [604.3999999999999, 615.9199999999998], [615.9199999999998, 627.2699999999999], [627.2699999999999, 641.8499999999999], [641.8499999999999, 661.6019999999999], [661.6019999999999, 673.8799999999999], [673.8799999999999, 684.6199999999999], [684.6199999999999, 694.8599999999999], [694.8599999999999, 709.5199999999999], [709.5199999999999, 721.9399999999998], [721.9399999999998, 738.4999999999998], [738.4999999999998, 749.4499999999998], [749.4499999999998, 763.8899999999999], [763.8899999999999, 774.1599999999999], [774.1599999999999, 790.9399999999998], [790.9399999999998, 801.8799999999999], [801.8799999999999, 816.6099999999999], [816.6099999999999, 827.5899999999999], [827.5899999999999, 837.9999999999999], [837.9999999999999, 852.2399999999999], [852.2399999999999, 863.5799999999999], [863.5799999999999, 878.91], [878.91, 890.8449999999999], [890.8449999999999, 907.4599999999999], [907.4599999999999, 920.1099999999999], [920.1099999999999, 933.1999999999999], [933.1999999999999, 945.68], [945.68, 956.51], [956.51, 966.68], [966.68, 977.4899999999999], [977.4899999999999, 989.3799999999999], [989.3799999999999, 1000.3199999999999], [1000.3199999999999, 1023.8679999999999], [1023.8679999999999, 1035.25], [1035.25, 1048.43], [1048.43, 1060.69], [1060.69, 1074.19], [1074.19, 1087.24], [1087.24, 1103.51], [1103.51, 1113.68], [1113.68, 1124.41], [1124.41, 1138.768], [1138.768, 1150.798], [1150.798, 1162.898], [1162.898, 1175.368], [1175.368, 1190.378], [1190.378, 1202.778], [1202.778, 1217.568], [1217.568, 1230.638], [1230.638, 1241.2379999999998], [1241.2379999999998, 1253.9479999999999], [1253.9479999999999, 1264.118], [1264.118, 1274.508], [1274.508, 1292.958], [1292.958, 1305.528], [1305.528, 1319.208], [1319.208, 1332.1680000000001], [1332.1680000000001, 1345.5680000000002], [1345.5680000000002, 1357.8680000000002], [1357.8680000000002, 1370.728], [1370.728, 1383.268], [1383.268, 1402.178], [1402.178, 1412.6580000000001], [1412.6580000000001, 1424.8480000000002], [1424.8480000000002, 1435.5880000000002], [1435.5880000000002, 1448.0280000000002], [1448.0280000000002, 1464.0580000000002], [1464.0580000000002, 1478.553], [1478.553, 1488.8580000000002], [1488.8580000000002, 1501.218], [1501.218, 1516.8880000000001], [1516.8880000000001, 1528.6180000000002], [1528.6180000000002, 1540.1380000000001], [1540.1380000000001, 1552.6580000000001], [1552.6580000000001, 1569.9430000000002], [1569.9430000000002, 1581.3880000000001], [1581.3880000000001, 1597.498], [1597.498, 1610.518], [1610.518, 1627.518], [1627.518, 1640.3980000000001], [1640.3980000000001, 1656.708], [1656.708, 1668.788], [1668.788, 1678.8890000000001], [1678.8890000000001, 1690.8180000000002], [1690.8180000000002, 1704.2580000000003], [1704.2580000000003, 1717.6680000000003], [1717.6680000000003, 1730.9880000000003], [1730.9880000000003, 1746.4730000000002], [1746.4730000000002, 1756.698], [1756.698, 1768.1580000000001], [1768.1580000000001, 1778.3580000000002], [1778.3580000000002, 1789.3180000000002], [1789.3180000000002, 1801.3180000000002], [1801.3180000000002, 1814.1080000000002], [1814.1080000000002, 1829.4880000000003], [1829.4880000000003, 1841.0480000000002], [1841.0480000000002, 1865.1080000000002], [1865.1080000000002, 1876.6380000000001], [1876.6380000000001, 1891.0580000000002], [1891.0580000000002, 1905.9040000000002], [1905.9040000000002, 1921.4880000000003], [1921.4880000000003, 1937.1270000000002], [1937.1270000000002, 1953.218], [1953.218, 1966.4080000000001], [1966.4080000000001, 1977.928], [1977.928, 1991.188], [1991.188, 2001.3380000000002], [2001.3380000000002, 2016.8180000000002], [2016.8180000000002, 2027.2380000000003], [2027.2380000000003, 2037.2480000000003], [2037.2480000000003, 2054.438], [2054.438, 2074.058], [2074.058, 2089.158], [2089.158, 2100.638], [2100.638, 2119.1079999999997], [2119.1079999999997, 2133.428], [2133.428, 2145.738], [2145.738, 2155.968], [2155.968, 2167.598], [2167.598, 2179.028], [2179.028, 2192.3179999999998], [2192.3179999999998, 2202.6679999999997], [2202.6679999999997, 2214.6679999999997], [2214.6679999999997, 2230.718], [2230.718, 2242.0679999999998], [2242.0679999999998, 2253.3979999999997], [2253.3979999999997, 2263.658], [2263.658, 2273.678], [2273.678, 2283.748], [2283.748, 2294.868], [2294.868, 2306.458], [2306.458, 2320.818], [2320.818, 2335.9880000000003], [2335.9880000000003, 2347.2940000000003], [2347.2940000000003, 2359.5280000000002], [2359.5280000000002, 2373.9080000000004], [2373.9080000000004, 2387.8880000000004], [2387.8880000000004, 2397.9280000000003], [2397.9280000000003, 2414.7980000000002], [2414.7980000000002, 2425.5980000000004], [2425.5980000000004, 2436.3780000000006], [2436.3780000000006, 2448.2580000000007], [2448.2580000000007, 2460.768000000001], [2460.768000000001, 2471.868000000001], [2471.868000000001, 2482.428000000001], [2482.428000000001, 2499.5280000000007], [2499.5280000000007, 2512.098000000001], [2512.098000000001, 2524.198000000001], [2524.198000000001, 2535.5280000000007], [2535.5280000000007, 2545.908000000001], [2545.908000000001, 2555.928000000001], [2555.928000000001, 2566.7180000000008], [2566.7180000000008, 2580.7780000000007], [2580.7780000000007, 2593.948000000001], [2593.948000000001, 2604.078000000001], [2604.078000000001, 2616.498000000001], [2616.498000000001, 2629.038000000001], [2629.038000000001, 2642.837000000001], [2642.837000000001, 2652.948000000001], [2652.948000000001, 2664.178000000001], [2664.178000000001, 2676.868000000001], [2676.868000000001, 2691.9880000000007], [2691.9880000000007, 2703.607000000001], [2703.607000000001, 2716.948000000001], [2716.948000000001, 2728.277000000001], [2728.277000000001, 2741.118000000001], [2741.118000000001, 2751.797000000001], [2751.797000000001, 2762.7380000000007], [2762.7380000000007, 2777.127000000001], [2777.127000000001, 2792.522000000001], [2792.522000000001, 2806.757000000001], [2806.757000000001, 2834.618000000001], [2834.618000000001, 2851.337000000001], [2851.337000000001, 2865.408000000001], [2865.408000000001, 2877.428000000001], [2877.428000000001, 2893.7270000000008], [2893.7270000000008, 2904.748000000001], [2904.748000000001, 2916.687000000001], [2916.687000000001, 2927.558000000001], [2927.558000000001, 2938.567000000001], [2938.567000000001, 2949.7180000000008], [2949.7180000000008, 2960.158000000001], [2960.158000000001, 2974.308000000001], [2974.308000000001, 2988.797000000001], [2988.797000000001, 3000.498000000001], [3000.498000000001, 3012.687000000001], [3012.687000000001, 3028.748000000001], [3028.748000000001, 3040.368000000001], [3040.368000000001, 3056.9680000000008], [3056.9680000000008, 3079.107000000001], [3079.107000000001, 3090.004000000001], [3090.004000000001, 3102.567000000001], [3102.567000000001, 3115.078000000001], [3115.078000000001, 3127.2180000000008], [3127.2180000000008, 3141.127000000001], [3141.127000000001, 3155.297000000001], [3155.297000000001, 3175.388000000001], [3175.388000000001, 3188.118000000001], [3188.118000000001, 3199.877000000001], [3199.877000000001, 3215.498000000001], [3215.498000000001, 3231.668000000001], [3231.668000000001, 3241.718000000001], [3241.718000000001, 3254.6270000000013], [3254.6270000000013, 3267.5580000000014], [3267.5580000000014, 3280.1470000000013], [3280.1470000000013, 3291.6470000000013], [3291.6470000000013, 3307.3280000000013], [3307.3280000000013, 3320.8480000000013], [3320.8480000000013, 3335.5180000000014], [3335.5180000000014, 3347.1780000000012], [3347.1780000000012, 3359.9080000000013], [3359.9080000000013, 3373.9980000000014], [3373.9980000000014, 3389.2570000000014], [3389.2570000000014, 3401.2570000000014], [3401.2570000000014, 3419.2680000000014], [3419.2680000000014, 3431.4480000000012], [3431.4480000000012, 3444.1980000000012], [3444.1980000000012, 3466.1580000000013], [3466.1580000000013, 3477.6630000000014], [3477.6630000000014, 3489.9640000000013], [3489.9640000000013, 3501.6740000000013], [3501.6740000000013, 3513.3730000000014], [3513.3730000000014, 3524.584000000001], [3524.584000000001, 3536.584000000001], [3536.584000000001, 3550.593000000001], [3550.593000000001, 3568.4130000000014], [3568.4130000000014, 3581.4440000000013], [3581.4440000000013, 3592.6830000000014], [3592.6830000000014, 3611.4040000000014], [3611.4040000000014, 3626.084000000001], [3626.084000000001, 3643.353000000001], [3643.353000000001, 3658.004000000001], [3658.004000000001, 3672.953000000001], [3672.953000000001, 3692.3830000000007], [3692.3830000000007, 3703.243000000001], [3703.243000000001, 3714.6730000000007], [3714.6730000000007, 3731.1330000000007], [3731.1330000000007, 3742.8730000000005], [3742.8730000000005, 3762.3630000000003], [3762.3630000000003, 3778.9440000000004], [3778.9440000000004, 3793.8340000000003], [3793.8340000000003, 3804.8140000000003], [3804.8140000000003, 3815.8730000000005], [3815.8730000000005, 3830.1330000000007], [3830.1330000000007, 3840.464000000001], [3840.464000000001, 3852.444000000001], [3852.444000000001, 3863.5840000000007], [3863.5840000000007, 3875.8630000000007], [3875.8630000000007, 3888.573000000001], [3888.573000000001, 3899.823000000001], [3899.823000000001, 3912.5750000000007], [3912.5750000000007, 3923.524000000001], [3923.524000000001, 3934.873000000001], [3934.873000000001, 3946.663000000001], [3946.663000000001, 3957.493000000001], [3957.493000000001, 3967.803000000001], [3967.803000000001, 3981.033000000001], [3981.033000000001, 3993.933000000001], [3993.933000000001, 4008.364000000001], [4008.364000000001, 4021.923000000001], [4021.923000000001, 4044.6540000000014], [4044.6540000000014, 4045.3000000000015]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1129, 1680, 2594, 3478, 4046]}
{"example_id": "mit035@@MIT8_04S16_lec07_300k", "text": ["PROFESSOR: We'll begin by discussing the wave packets and uncertainty. ", "So it's our first look into this Heisenberg uncertainty relationships.  And to begin with, let's focus it as fixed time, t equals zero. ", "So we'll work with packets at t equals zero.  And I will write a particular wave function that you may have at t equals 0, and it's ", "a superposition of plane waves.  So it would be e to the ikx. ", "You sum over many of them, so you're going to sum over k, but you're going to do it with  a weight, and that's 5k. ", "And there's a lot to learn about this, but the physics that is encoded here is that any  wave at time equals 0, this psi of x at time equals 0, can be written as a superposition ", "of states with momentum h bar k.  You remember e to the ikx represents a particle or a wave that carries momentum h bar k. ", "So this whole idea here of a general wave function being written in this way carries  physical meaning for us. ", "It's a quantum mechanical meaning, the fact that this kind of wave has momentum.  But this phi of k, however, suppose you know this wave function at time equals 0. ", "Phi of k is then calculable.  Phi of k can be determined, and that's the foundation of what's called Fourier's theorem, ", "that gives you a formula for phi of k.  And it's a very similar formula.  1 over 2 pi, this time an integral over x. ", "So you take this of psi of x0 that you know and then multiply by e to the minus ikx. ", "Integrate over x, and out comes this function of k.  So if you know phi of x0, you know phi of k. ", "You can calculate this interval and you can rewrite phi of x0 as a superposition of plane  waves.  So that's how you would do a Fourier representation. ", "So somebody can give you an initial wave function, and maybe it's a sine function or a Gaussian  or something, then what you would do if you wanted to rewrite it in this way, is calculate ", "phi of k, because you know this psi, you can calculate this integral, at least with a computer.  And once you know phi of k, you have a way of writing psi as a superposition of plane ", "waves.  So we've talked about this before, because we were doing wave packets before and we got  some intuition about how you form a wave packet and how it moves. ", "Now we didn't put the time dependence here, but that can wait.  What I wish to explain now is how by looking at these expressions, you can understand the ", "uncertainties that you find on the wave function, position, and momentum uncertainties, how  they are related. ", "So that is our real goal, understanding the role of uncertainties here.  If phi of k has some uncertainty, how is the uncertainty in psi determined? ", "So that's what we're looking for.  So relationship of uncertainties.  Now as before, we will take a phi of k, that we've usually be in writing, that depends ", "on k and it's centered around some value k0.  It's some sort of nice, centered function.  And it has then, we say, some uncertainty in the value of the momentum. ", "That is this signal, this phi of k that we're using to produce this packet.  It has some uncertainty, it's not totally sharp, it's peaked around k0 but not fully ", "sharp.  So the uncertainty is called delta k and it's some typical width over here.  Delta k is then uncertainty. ", "Now it's not the purpose of today's lecture to make a precise definition of what the uncertainty  is.  This will come later.  At this moment, you just want to get the picture and the intuition of what's going on. ", "And there is some uncertainty here, perhaps you would say, look at those points where  the wave goes from peak value to half value and see what is the width. ", "That's a typical uncertainty.  So all what we're going to do in these arguments is get for you the intuition.  Therefore, the factors of 2 are not trustable. ", "If you're trying to make a precise statement, you must do precise definitions.  And that will come later, probably in about one or two lectures. ", "So at this moment, that's the uncertainty, delta k.  And let's assume that this phi of k is real. ", "And its peaked around k0 uncertainty delta k.  Now what happens with psi of x? ", "Well, we had our statements about the stationary phase that you already are practicing with  them for this homework. ", "If you want to know where this function peaks, you must look where the phase, this phi--  we say it's real, so it doesn't contribute to the phase-- where the phase, which is here, ", "is stationary, given the condition that it should happen at k0.  The only contribution to the integral is basically around k0. ", "So in order to get something, you must have a stationary phase, and the phase must be  stationary as a function of k, because you're integrating over k. ", "And the phase is kx, the derivative with respect to k of the face is just x, and that must ", "vanish, therefore, so you expect this to be peaked around x equals zero.  So the x situation, so psi of x0 peaks at x equals 0. ", "And so you have a picture here.  And if I have a picture, I would say, well it peaks around the x equals 0. ", "So OK, it's like that.  And here we're going to have some uncertainty.  Here is psi of x and 0, and here is x. ", "And let me mention, I've already become fairly imprecise here.  If you were doing this, you probably would run into trouble. ", "I've sort of glossed over a small complication here.  The complication is that this, when I talk about the peaking of psi, and you probably ", "have seen it already, you have to worry whether psi is real or psi is complex.  So what is this psi here? ", "Should it be real?  Well actually, it's not real.  You've done, perhaps, in the homework already these integrals, and you see that psi is not ", "real.  So when we say it peaks at x equals 0, how am I supposed to plot psi?  Am I plotting the real part, the imaginary part, the absolute value? ", "So it's reasonable to plot the absolute value and to say that psi absolute value peaks at ", "x equals 0.  And there will be some width again here, delta x, width. ", "And that's the uncertainty in psi of x.  So the whole point of our discussion for the next 10 minutes is to just try to determine ", "the relation between delta k and delta x and understand it intuitively.  PROFESSOR: We ask, is psi of x, 0 real? ", "And I told you the answer is no.  And how would I know that this is not real?  Well, we can take the complex conjugate. ", "And at the end of the day, this will boil down  to some property of phi of k.  You see, you have an expression phi of x in terms of phi of k. ", "So it would not be surprising that the requirement  that psi is real means something about phi of k.  So let's just say, suppose psi is given by that, ", "then psi x, 0 star, the complex conjugate  would be 1 over square root of 2 pi integral phi of k star ", "e to the minus ikx dk.  ", "I conjugated everything in that equation for psi of x and 0.  Now, you want to compare this with psi of x and 0 ", "to see if it's real.  Or let's consider what is the condition that this be real.  So I want to simplify here a little more.  So what I'm going to do is going to change variables, ", "by changing k to minus k.   If you prefer to go a little more slowly, ", "you could say you're going to change k prime--  you're going to be a new k, called k prime,  equals to minus k.  But it's possible to do it this way. ", "Now, there's going to be a couple of changes.   Wherever you see k, you're now going to see minus k--  so 1 over 2 pi integral phi of minus k. ", "And I'll just put this star here, not so many parentheses--  e to the minus ikx becomes ikx.  And the dk will go to minus dk, but the order of integration, ", "that was from minus infinity to plus infinity, would switch.  So those two signs cancel.  So there's a sign from doing dk to minus dk, ", "and 1 from the limit of integration--  so at the end of the day, you have dk,  and you still have this--  minus infinity to infinity. ", " And you can say, well, is this equal to--  or what is the condition of for psi to be real? ", "Well, is this equal to 1 over 2 pi minus phi of k, e  to the ikx dk-- ", "is that-- question mark-- is that equal to it?  That would mean that the psi of x, 0 ", "is real, because this thing is just psi of x and 0.  So this is a question mark-- this is a condition. ", "So here you could say, exploring the reality condition-- ", "condition-- when is a psi of x real?  So what must be true is that these two terms  must equal each other. ", "So, in fact, this requires--  reality requires that 1 over square root of 2 pi integral ", "from minus infinity to infinity phi of k  minus phi star of minus k, e to the ikx dx is equal to 0. ", "I brought the two terms to one side.  Both are of the same type--  they're integrated against an e to the ikx. ", "And therefore, we can combine them,  and that's what must be true in order for the function ", "to be real.  And now you can say, so what is it?  What's the answer?  Well, this integral should vanish.  ", "Now, this integral should vanish--  it should vanish for all values of k.  So actually, what you want to conclude  is that this thing is identically 0. ", "AUDIENCE: Excuse me, shouldn't that be dk and not dx?  PROFESSOR: Yes, thank you.  ", "Thanks very much.   So this property that this whole integral be equal to 0, you ", "were tempted to conclude that it means  that this thing is equal to 0.  And that is correct--  that is a perfectly legal argument. ", "And it basically-- if you want to express it more precisely,  you could base it on the Fourier theorem, again. ", "These two sets of equalities here are Fourier's theorem.  And look what this is saying--  this is saying that this quantity has a 0 Fourier ", "transform.  Because how do you do the Fourier transform  of a function of k?  You multiply by e to the ikx and integrate. ", "And therefore, this function has a 0 Fourier transform.  So, but if a function has a 0 Fourier transform, ", "the function must be 0.  Because already this is 0, and the integral is 0--  0.  So this is absolutely rigorous. ", "And therefore, you get the conclusion  that phi of minus k star must be equal to phi of k, ", "and that's the condition for reality.   So if a phi of k satisfies this property, that psi of x ", "will be real, and our phi of k doesn't satisfy this property,  what do you see in this property?  Basically, if you have phi that exists for some value of k, ", "it should also exist for the value of minus k.  And in fact, should be the complex conjugate  of the other value.  But here, you have some phis of k, and no phis at minus k. ", "So the phi that we wrote above doesn't satisfy this condition.  And therefore psi is not real, and it all makes sense. ", " OK, so basically, if you were plotting ", "not the absolute value, but the real part  and the imaginary parts of psi, you  would see some sort of funny waves. ", "I think if you were plotting the real part, for example,  you would see a wave like that.  And if you were plotting the imaginary part, ", "you'd presumably see some other wave like that.  And the absolute value, it's much nicer and simpler. ", " PROFESSOR: So we go back to the integral.  We think of k.   We'll write it as k naught plus k tilde. ", "And then we have psi of x0 equal 1  over square root of 2pi e to the ik naught x-- ", "that part goes out--  integral dk tilde phi of k naught plus k tilde ", "e to the ik tilde x dk.  OK.  ", "So we're doing this integral.  And now we're focusing on the integration ", "near k naught, where the contribution is large.  So we write k as k naught plus a little fluctuation. ", "dk will be dk tilde.  Wherever you see a k, you must put k naught plus k tilde.  And that's it. ", "And why do we have to worry?  Well, we basically have now this peak over here, k naught. ", "And we're going to be integrating  k tilde, which is the fluctuation, all  over the width of this profile. ", "So the relevant region of integration for k tilde  is the range from delta k over 2 to minus delta k over 2. ", "So maybe I'll make this picture a little bigger.  ", "Here is k naught.  And here we're going to be going and integrate in this region.  And since this is delta k, the relevant region ", "of integration--  integration-- for k tilde is from minus delta k over 2 ", "to delta k over 2.   That's where it's going to range.  So all the integral has to be localized in the hump. ", "Otherwise, you don't get any contribution.  So the relevant region of integration  for the only variable that is there is just that one. ", " Now as you vary this k tilde, you're going to vary the phase. ", "And as the phase changes, well, there's some effect [? on ?]  [? it. ?] But if x is equal to 0, the phase is stationary, ", "because k tilde is going to very, but x is equal to 0.  No phase is stationary.  And therefore, you will get a substantial answer.  And that's what we know already. ", "For x is going to 0 or x equal to 0,  we're going to get a substantial answer.  But now think of the phase in general. ", "So for any x that you choose, the phase  will range over some value.  So for any x different from 0, the face in the integral ", "will range over minus delta k over 2x and to delta k over 2x. ", "You see, x is here.  The phase is k tilde x.  Whatever x is, since k tilde is going run in this range, ", "the phase is going to run in that range multiplied by x.   So as you do the integral-- ", "now think you're doing this integral.  You have a nice, real, smooth function here.  And now you have a running phase that you don't  manage to make it stationary. ", "Because when x is different from 0,  this is not going to be stationary.  It's going to vary.  But it's going to vary from this value to that value. ", "So the total, as you integrate over that peak,  your phase excursion is going to be delta k times x-- ", "total phase excursion is delta k times x. ", " But then that tells you what can happen. ", "As long as this total phase excursion is very small--  so if x is such that delta k times ", "x is significantly less than 1--  or, in fact, I could say less than 1-- ", " there will be a good contribution ", "if x is such that--  then you will get a contribution. ", "And the reason is because the phase is not changing much.  You are doing your integral, and the phase is not killing it.  On the other hand, if delta k times x-- ", " delta k times x is much bigger than 1,  then as you range over the peak, the phase ", "has done many, many cycles and is going to kill the integral.  So if k of x is greater than 1, the contribution goes to 0. ", " So let's then just extract the final conclusion ", "from this thing.  So psi of x 0 will be sizable in an interval x belonging ", "from minus x0 to x0.  ", "So it's some value here minus x0 to x0.  ", "If, even for values as long as x0,  this product is still about 1-- ", " if for delta k times x0, roughly say of value 1, we have this. ", "And therefore the uncertainty in x would be given by 2x0. ", " So x0 or 2x0, this x0 is basically the uncertainty in x. ", "And you would get that delta k times  delta x is roughly equal to 1--  so delta k delta x roughly equal to 1. ", "So I'm dropping factors of 2.  In principle here, I should push a 2.  But the 2s, or 1s, or pi's at this moment ", "are completely unreliable.  But we got to the end of this argument.  We have a relation of uncertainties is equal to 1. ", "And the thing that comes to mind immediately  is, why didn't Fourier invent the uncertainty principle? ", "Where did we use quantum mechanics here?   The answer is nowhere. ", "We didn't use quantum mechanics.  We found the relation between wave packets, known to Fourier,  known to electrical engineers. ", "The place where quantum mechanics comes about  is when you realize that these waves in quantum mechanics, e ", "to the ikx represent states with some values of momentum.  So while this is fine and it's a very important intuition, ", "the step that you can follow with is--  it's interesting.  And you say that, well, since p, the momentum, ", "is equal to h bar k and that's quantum mechanical--  it involves h bar.  It's the whole discussion about these waves of matter particles ", "carrying momentum.   You can say-- you can multiply or take a delta here.  And you would say, delta p is equal to h bar delta k. ", " So multiplying this equation by an h bar,  you would find that delta p, delta x is roughly h bar. ", " And that's quantum mechanical.  ", "Now we will make the definitions of delta p and delta  x precise and rigorous with precise definitions. ", " Then there is a precise result, which is very neat,  which is that delta x times delta p ", "is always greater than or equal than h bar over 2.   So this is really exact. ", "But for that, we need to define precisely what we  mean by uncertainties, which we will do soon, but not today. ", "So I think it's probably a good idea  to do an example, a simple example,  to illustrate these relations. ", "And here is one example.  You have a phi of k of the form of a step that ", "goes from delta k over 2 to minus delta k over 2,  and height 1 over square root of delta k. ", "That's phi of k.  It's 0 otherwise--  0 here, 0 there.  Here is 0. ", "Here is a function of k.   What do you think?  Is this psi of x, the psi x corresponding ", "to this phi of k-- is it going to be a real function or not?  ", "Anybody?  AUDIENCE: This equation [? is ?] [? true, ?] [? but-- ?]  PROFESSOR: Is it true or not?  AUDIENCE: I think it is.  PROFESSOR: OK. ", "Yes, you're right.  It is true.  This phi of k is real.  And whenever you have a value at some k, ", "there is the same value at minus k.  And therefore the star doesn't matter, because it's real.  So phi is completely real. ", "So phi of k is equal to phi of minus k.  And that should give you a real psi of x--  correct.  So some psi of x-- have to do the integral-- psi of x0 ", "is 1 over square root of 2 pi minus delta k over 2  to delta k over 2.  The function, which is 1 over delta k in here-- ", " that's the whole function.  And the integral was supposed to be from minus infinity  to infinity.  But since the function only extends from minus delta ", "k over 2 to plus delta k over 2, you restrict the integral  to those values.  So we've already got the phi of k and then e to the ikx dx. ", " Well, the constants go out--  2 pi delta k. ", "And we have the integral is an integral over x--  ", "no, I'm sorry.  It's an integral over k.  What I'm writing here--  dk, of course.  And that gives you e to the ikx over ix, ", "evaluated between delta k over 2 and minus delta k over 2.   OK, a little simplification gives the final answer. ", "It's delta k over 2pi sine of delta kx over 2 ", "over delta kx over 2.   So it's a sine of x over x type function. ", "It's a familiar looking curve.  It goes like this.  It has some value-- it goes down, up, down, up like that-- ", " symmetric.  And here is psi of x and 0. ", "Here is 2 pi over delta k, and minus 2 pi over delta k here. ", " Sine of x over x looks like that.  So this function already was defined with the delta k. ", "And what is the delta x here?  Well, the delta x is roughly 2 pi over delta k. ", " No, it's-- you could say it's this much or half of that.  I took [? it half ?] of that. ", "It doesn't matter.  It's approximate that at any rate now.  So delta x is this.  And therefore the product delta x, delta k, ", "delta x is about 2 pi.  PROFESSOR: Next is this phenomenon that when  you have a wave packet and it moves ", "it can change shape and get distorted.  And that is a very nice phenomenon  that takes place in general and causes ", "technological complications.  And it's conceptually interesting.  So let's discuss it. ", "So it's still wave packets.  But now we have to go back and add some time to it. ", "So shape changes.   So we had a psi of x and t is equal to 1 ", "over square root of 2 pi phi of k e to the ikx  e to the minus i omega of kt. ", " And what did we do with this to analyze how it propagates?  We expanded omega of k as omega of k0, ", "which, again, this quantity is centered and peaks around k0,  plus k minus k0 times d omega dk at k0 ", "plus 1/2 k minus k0 squared, the second omega, dk squared at k0. ", "And it might seem that this goes on forever.   And what did we do before?  We looked at this thing and we did the integral with this term ", "and ignored the next.  And with this term, we discovered  that the profile moves with this velocity, the group velocity. ", "Now we want to go back and at least get  an idea of how this term could change the result.  And it would change the result by deforming ", "the shape of the packet.  So it is of interest to know, for example, how long you have  to wait before your packet gets totally deformed, ", "or how do you evolve a packet.  So we need to recall these derivatives.  So the omega vk is the same as de dp by multiplying by h bar. ", "And this you'll remember, was p over m.   The edp is p over m and is equal to h bar k over m. ", " So the second omega, dk squared. ", "I must differentiate the first derivative with respect to k.  So I differentiate the first derivative with respect k.  And now I get just h bar over m, which is quite nice. ", "And the third derivative, the 3 omega, dk cubed, is 0.  And therefore, I didn't have to worry about these terms. ", "The series terminates.  The Taylor series terminates for this stuff.  Yes?  AUDIENCE: The reason this happens  is because we're [INAUDIBLE]. ", "PROFESSOR: That's right.   So of what is it that we get?  Well, this term is roughly then 1/2 k minus k0 squared ", "times h bar over m.   And we can go back to the integral ", "that we're trying to do.  We don't do it again or not by any means.  But just observe what's going on there.  ", "And we have an e to the minus i omega of kt  that we did take into account.  But the term that we're dropping now ", "is a term that is minus i omega of k,  well, whatever we have here, 1/2 k minus k0 ", "squared h bar over mt.   That's the phase that we ignored before. ", " But now we'll just say, that we expect, therefore, ", "that the shape doesn't change as long as we  can ignore this phase.  And this phase would start changing shape of the object. ", " So our statement is going to be that we have no shapes. ", "So let's imagine you started with a packet  that sometime t equals 0.  And then you let time go by.  Well, there's some numbers here and time is increasing. ", "At some point, this phase is going to become unignorable.  And it's going to start affecting everything.  But we have no shape change, or no appreciable shape change, ", "as long as this quantity is much less than 1.  So as long as say, k minus k0 squared ", "h bar over m absolute value of t is much less than 1,  no shape change.  ", "Now it's convenient to write it in terms of things  that are more familiar.  So we should estimate this thing. ", "Now we're doing estimates in a very direct and rough way here.  But look, your integrals are around k0. ", "And as you remember, they just extend a little bit  because it has some width.  So k minus k0, as you do the integral over k, ", "you're basically saying this thing  is about the size of the uncertainty in k.  So I'll put here delta k squared. ", " Then you'll have h bar t over m much less than 1. ", "Now h bar times delta k is delta p.  So this equation is also of the form delta p squared t ", "over h bar m much less than 1.  There's several forms of this equation that is nice. ", "So this is a particularly nice form.   So if you know the uncertainty and momentum of your packet, ", "or wave packet, up to what time, you can wait  and there's no big deformation of this wave packet. ", "Another thing you can do is involve the uncertainty in x.   Because, well, delta p delta x is equal to h bar. ", "So we can do that.  ", "And so with delta p times delta x equal to about h bar, ", "you can write t less than h bar over m ", "over a delta p squared, which would  be h squared delta x squared.  I think I'm getting it right. ", "Yep, so t much less than m over h bar delta x squared. ", "That's another way you could write this inequality.   There is one way to write the inequality ", "that you can intuitively feel you  understand what's happening.  And take this form a from a. ", " Write it as delta p t over m is less than h bar over delta p. ", " And h bar over delta p is delta x. ", "So you go delta p over mt much less than delta x. ", " I think this is understandable.  ", "Why does the packet change shape?  The reason it changes shape is because the group velocity  is not the same for all the frequencies. ", "The packet mostly moves with k0.  And we haven't rated the group velocity in k0.  But if it would have a definite velocity, ", "we would have a definite momentum.  But that's not possible.  These things have uncertainty in momentum.  And they have uncertainty in k that we use it to write it. ", "So different parts of the wave can  move with different velocities, different group velocities.  The group velocity you evaluated at k0. ", "But some part of the packet is propagating  with group velocities that are near k0 but not exactly there.  So you have a dispersion in the velocity, which ", "is an uncertainty in the velocity  or an uncertainty in the momentum.  Think, the momentum divided by mass is velocity.  So here it is, an uncertainty in the velocity. ", "And if you multiply the uncertainty  in the velocity times this time that you can wait,  then the change in shape is not much ", "if this product, which is the difference of how  one part moves with respect to the other, the difference  of relative term, is still smaller ", "than the uncertainty that controls  the shape of the packet.  So the packet has a delta x.  ", "And as long as this part, the left part of the packet, then  the top of the packet, the difference of velocities  times the time, it just still compared to delta x is small, ", "then the thing doesn't change much.  So I think this is one neat way of seeing  what an equation that you sometimes ", "use in this form, sometimes use in in this form--  it's just things that you can use in different ways.  So for example, I can do this a little exercise. ", " If you have delta x equals 10 to the minus 10 meters, that's  atomic size for an electron. ", " How long does it remain localized? ", " So you have an electron. ", "And you produce a packet.  You localize it to the size of an atom.  How long can you wait before this electron is just  all over the room? ", "Well, when we say this t, and we say this time,  we're basically saying that it's roughly still there.  Maybe it grew 20%, 30%. ", "But what's the rough time that you  can expect that it stays there?  So in this case, we can use just this formula.  And we say the time could be approximately ", "m over h bar delta x squared.  It's fun to see the numbers.  ", "You would calculate it with mc squared over h bar  c times delta x over c, this squared. ", " The answer is about 10 to the minus 16 seconds, not much. ", " This is a practical issue in accelerators as well. ", "Particle physics accelerators, they  concern bunches, a little bunch of protons in the LHC.  It's a little cylinder in which the wave functions ", "of the protons are all collimated very thin, short,  a couple of centimeters short.  And after going around many times around the accelerator, ", "they always have to be compressed and kept back,  sent back to shape.  Because just of diffusion, these things just propagate. ", "PROFESSOR: Time evolution of a free particle wave packet. ", " So, suppose you know psi of x and 0. ", "Suppose you know psi of x and 0.  So what do you do next, if you want ", "to calculate psi of x and t?   Well, the first step, step one, is calculate phi of k. ", "So you have phi of k is equal 1 over square root of 2 pi  integral dx psi of x, 0 e to the minus ikx. ", " So you must do this integral.  ", "Step two-- step two--  with this, now rewrite and say that psi of x, 0 ", "is 1 over square root of 2 pi dk e to the--  no, I'm sorry-- phi of k, e to the ikx. ", " So that has achieved our rewriting of psi of x and 0, ", "which was an arbitrary function as a superposition of plane  waves.   Step three is the most fun step of all. ", "Step three-- you look at this, and then you say,  well, I know now what psi of x and t is.  Evolving this is as easy as doing nothing. ", "What I must do here is 1 over square root of 2 pi--  just copy this-- dk, phi of k, e to the ikx. ", "And I put here minus omega of k, t.   And I remind you that h bar omega of k is the energy, ", "and it's equal to h squared k squared over 2m.  This is our free particle. ", "And I claim that, just by writing this,  I've solved the Schrodinger equation  and I've time-evolved everything. ", "The answer is there--  I didn't have to solve the differential equation, or--  that's it.  That's the answer.  Claim this is the answer. ", " And the reason is important.  ", "If you come equipped with a Schrodinger equation, what  should you check, that ih bar d psi dt is equal to h psi-- ", "which is minus h-- squared over 2m, d second, dx squared psi.  Well, you can add with ih d dt on this thing. ", "And you remember all that happens  is that they all concentrate on this thing.  And it solves this, because it's a plane wave. ", "So this thing, this psi of x and t,  solves the Schrodinger equation.  It's a superposition of plane waves, each of which ", "solves the free Schrodinger equation.  So, we also mention that since the Schrodinger equation is  first ordered in time, if you know the wave function at one ", "time, and you solve it, you get the wave function at any time.  So here is a solution that is a solution of the Schrodinger  equation. ", "But at time equals 0--  this is 0-- and we reduce this to psi of x and 0. ", "So it has the right condition.  Not only solve the Schrodinger equation,  but it reduces to the right thing.  So it is the answer. ", "And we could say--   we could say that there is a step four, which is-- ", " step four would be do the k integral. ", " And sometimes it's possible.  You see, in here, once you have this phi of k, ", "maybe you can just look at it and say, oh,  yeah, I can do this k integral and get psi of x and 0,  recover what I know. ", "I know how to do-- this integral is a little harder,  because k appears a little more complicated.  But it has the whole answer to the problem. ", "I think one should definitely focus on this  and appreciate that, with zero effort and Fourier's theorem, ", "you're managing to solve the propagation of any initial wave  function for all times.  So there will be an exercise in the homework, which is called ", "evolving the free Gaussian--  Gaussian.  So you take a psi a of x and time ", "equals 0 to be e to the minus x squared over 4a  squared over 2 pi to the 1/4-- ", "that's for normalization-- square root of a.  And so what is this?  This is a psi--  this is a Gaussian-- and the uncertainty's roughly a-- ", "is that right?  Delta x is about a, because that controls  the width of the Gaussian.  ", "And now, you have a Gaussian that you have to evolve.  And what's going to happen with it?  This Gaussian, as written, doesn't ", "represent a moving Gaussian.  To be a moving Gaussian, you would  like to see maybe things of [? the ?] from e  to the ipx that represent waves with momentum. ", "So I don't see anything like that in this wave function.  So this must be a Gaussian that is just sitting here.  And what is it going to do in time? ", "Well, it's presumably going to spread out.  So the width is going to change in time.  There's going to be a time in which the shape changes. ", "Will it be similar to what you have here?  Yes.  The time will be related.  So time for changes. ", "So there will be some relevant time  in this problem for which the width starts to change.  And it will be related to ma squared over h bar. ", "In fact, you will find that with a 2,  the formulas look very, very neat.  And that's the relevant time for the formation of the Gaussian. ", "So you will do those four steps.  They're all doable for Gaussians.  And you'll find the Fourier transform,  which is another Gaussian. ", "Then you will put the right things  and then try to do the integral back.  The answer is a bit messy for psi, ", "but not messy for psi squared, which is what we typically "], "vid_duration": [13.88, 16.72, 12.131, 10.449, 13.81, 20.659, 15.53, 12.68, 18.751, 10.3, 13.93, 10.27, 15.95, 12.73, 15.61, 14.42, 15.73, 17.779, 10.321, 15.59, 18.53, 19.64, 15.91, 18.65, 14.68, 13.5, 14.52, 10.98, 16.769, 13.591, 13.04, 13.78, 12.35, 10.14, 13.32, 24.53, 11.81, 15.68, 13.659, 14.71, 11.891, 15.62, 12.18, 10.51, 14.19, 14.289, 11.414, 10.249, 12.921, 13.05, 16.12, 10.07, 11.67, 13.35, 11.39, 11.35, 16.12, 16.35, 12.57, 11.14, 15.0, 13.9, 11.15, 10.33, 10.26, 12.75, 13.12, 19.69, 10.98, 10.02, 12.55, 12.35, 10.86, 12.46, 13.119, 13.541, 15.35, 10.05, 11.97, 11.31, 17.57, 13.67, 14.04, 16.53, 12.645, 13.765, 11.969, 12.421, 10.223, 14.2, 11.13, 16.172, 12.378, 10.53, 11.075, 11.465, 10.28, 12.45, 16.74, 10.93, 16.73, 15.25, 12.34, 10.17, 11.94, 12.11, 11.91, 11.44, 17.8, 19.78, 10.77, 11.48, 12.32, 12.43, 11.25, 12.51, 10.18, 14.61, 10.16, 12.6, 17.96, 12.26, 14.31, 17.01, 11.17, 23.15, 11.35, 10.11, 10.608, 23.762, 12.66, 11.4, 18.75, 11.94, 13.027, 11.183, 11.56, 12.36, 12.01, 13.76, 13.48, 14.34, 14.358, 15.632, 11.82, 11.569, 12.921, 11.98, 12.34, 14.72, 15.66, 12.459, 10.011, 12.23, 15.13, 11.1, 12.18, 11.73, 18.045, 16.865, 13.08, 14.73, 11.52, 11.102, 19.428, 17.8, 10.59, 13.23, 13.084, 14.649, 12.847, 16.76, 11.05, 10.7, 11.11, 11.773, 13.92, 10.049, 11.951, 13.809, 10.741, 14.73, 15.84, 11.939, 11.611, 14.43, 12.24, 10.95, 19.91, 13.15, 11.3, 12.09, 11.58, 10.04, 21.1, 17.36, 12.51, 12.3, 11.07, 10.67, 17.09, 10.875, 14.355, 12.0, 16.18, 13.95, 14.09, 15.399, 14.231, 11.55, 10.055, 12.055, 14.69, 11.15, 12.209, 10.461, 12.25, 12.61, 14.02, 12.15, 10.41, 11.61, 10.02, 14.0, 17.86, 10.64, 17.85, 12.64, 12.51, 13.86, 13.36, 14.29, 13.72, 14.32, 11.769, 10.261, 13.52, 14.01, 12.39, 16.64, 12.34, 15.5, 10.31, 10.21, 12.35, 17.01, 10.68, 11.09, 10.895, 12.835, 12.209, 13.891, 10.77, 12.36, 11.57, 12.59, 20.14, 13.579, 10.631, 18.04, 11.3, 11.63, 14.426, 14.434, 14.87, 13.27, 10.5, 11.33, 10.73, 11.54, 14.64, 11.52, 11.239, 12.921, 13.85, 10.53, 10.76, 11.18, 12.75, 15.06, 13.32, 10.44, 14.08, 11.09, 14.01, 14.07, 11.61, 13.86, 14.18, 13.89, 15.03, 12.94, 11.85, 10.6, 16.62, 11.009, 11.341, 10.17, 3.931], "stet": [[0, 13.88], [13.88, 30.6], [30.6, 42.731], [42.731, 53.18], [53.18, 66.99], [66.99, 87.649], [87.649, 103.179], [103.179, 115.85900000000001], [115.85900000000001, 134.61], [134.61, 144.91000000000003], [144.91000000000003, 158.84000000000003], [158.84000000000003, 169.11000000000004], [169.11000000000004, 185.06000000000003], [185.06000000000003, 197.79000000000002], [197.79000000000002, 213.40000000000003], [213.40000000000003, 227.82000000000002], [227.82000000000002, 243.55], [243.55, 261.329], [261.329, 271.65000000000003], [271.65000000000003, 287.24], [287.24, 305.77], [305.77, 325.40999999999997], [325.40999999999997, 341.32], [341.32, 359.96999999999997], [359.96999999999997, 374.65], [374.65, 388.15], [388.15, 402.66999999999996], [402.66999999999996, 413.65], [413.65, 430.419], [430.419, 444.01], [444.01, 457.05], [457.05, 470.83], [470.83, 483.18], [483.18, 493.32], [493.32, 506.64], [506.64, 531.17], [531.17, 542.9799999999999], [542.9799999999999, 558.6599999999999], [558.6599999999999, 572.3189999999998], [572.3189999999998, 587.0289999999999], [587.0289999999999, 598.9199999999998], [598.9199999999998, 614.5399999999998], [614.5399999999998, 626.7199999999998], [626.7199999999998, 637.2299999999998], [637.2299999999998, 651.4199999999998], [651.4199999999998, 665.7089999999998], [665.7089999999998, 677.1229999999998], [677.1229999999998, 687.3719999999998], [687.3719999999998, 700.2929999999999], [700.2929999999999, 713.3429999999998], [713.3429999999998, 729.4629999999999], [729.4629999999999, 739.5329999999999], [739.5329999999999, 751.2029999999999], [751.2029999999999, 764.5529999999999], [764.5529999999999, 775.9429999999999], [775.9429999999999, 787.2929999999999], [787.2929999999999, 803.4129999999999], [803.4129999999999, 819.7629999999999], [819.7629999999999, 832.333], [832.333, 843.473], [843.473, 858.473], [858.473, 872.3729999999999], [872.3729999999999, 883.5229999999999], [883.5229999999999, 893.853], [893.853, 904.1129999999999], [904.1129999999999, 916.8629999999999], [916.8629999999999, 929.983], [929.983, 949.673], [949.673, 960.653], [960.653, 970.673], [970.673, 983.223], [983.223, 995.573], [995.573, 1006.433], [1006.433, 1018.893], [1018.893, 1032.012], [1032.012, 1045.5529999999999], [1045.5529999999999, 1060.9029999999998], [1060.9029999999998, 1070.9529999999997], [1070.9529999999997, 1082.9229999999998], [1082.9229999999998, 1094.2329999999997], [1094.2329999999997, 1111.8029999999997], [1111.8029999999997, 1125.4729999999997], [1125.4729999999997, 1139.5129999999997], [1139.5129999999997, 1156.0429999999997], [1156.0429999999997, 1168.6879999999996], [1168.6879999999996, 1182.4529999999997], [1182.4529999999997, 1194.4219999999998], [1194.4219999999998, 1206.8429999999998], [1206.8429999999998, 1217.0659999999998], [1217.0659999999998, 1231.2659999999998], [1231.2659999999998, 1242.396], [1242.396, 1258.568], [1258.568, 1270.946], [1270.946, 1281.4759999999999], [1281.4759999999999, 1292.551], [1292.551, 1304.0159999999998], [1304.0159999999998, 1314.2959999999998], [1314.2959999999998, 1326.7459999999999], [1326.7459999999999, 1343.4859999999999], [1343.4859999999999, 1354.416], [1354.416, 1371.146], [1371.146, 1386.396], [1386.396, 1398.7359999999999], [1398.7359999999999, 1408.906], [1408.906, 1420.846], [1420.846, 1432.956], [1432.956, 1444.866], [1444.866, 1456.306], [1456.306, 1474.106], [1474.106, 1493.886], [1493.886, 1504.656], [1504.656, 1516.136], [1516.136, 1528.456], [1528.456, 1540.886], [1540.886, 1552.136], [1552.136, 1564.646], [1564.646, 1574.826], [1574.826, 1589.436], [1589.436, 1599.596], [1599.596, 1612.196], [1612.196, 1630.156], [1630.156, 1642.416], [1642.416, 1656.7259999999999], [1656.7259999999999, 1673.7359999999999], [1673.7359999999999, 1684.906], [1684.906, 1708.056], [1708.056, 1719.406], [1719.406, 1729.5159999999998], [1729.5159999999998, 1740.1239999999998], [1740.1239999999998, 1763.8859999999997], [1763.8859999999997, 1776.5459999999998], [1776.5459999999998, 1787.946], [1787.946, 1806.696], [1806.696, 1818.636], [1818.636, 1831.663], [1831.663, 1842.846], [1842.846, 1854.406], [1854.406, 1866.7659999999998], [1866.7659999999998, 1878.7759999999998], [1878.7759999999998, 1892.5359999999998], [1892.5359999999998, 1906.0159999999998], [1906.0159999999998, 1920.3559999999998], [1920.3559999999998, 1934.7139999999997], [1934.7139999999997, 1950.3459999999998], [1950.3459999999998, 1962.1659999999997], [1962.1659999999997, 1973.7349999999997], [1973.7349999999997, 1986.6559999999997], [1986.6559999999997, 1998.6359999999997], [1998.6359999999997, 2010.9759999999997], [2010.9759999999997, 2025.6959999999997], [2025.6959999999997, 2041.3559999999998], [2041.3559999999998, 2053.8149999999996], [2053.8149999999996, 2063.8259999999996], [2063.8259999999996, 2076.0559999999996], [2076.0559999999996, 2091.1859999999997], [2091.1859999999997, 2102.2859999999996], [2102.2859999999996, 2114.4659999999994], [2114.4659999999994, 2126.1959999999995], [2126.1959999999995, 2144.2409999999995], [2144.2409999999995, 2161.1059999999993], [2161.1059999999993, 2174.1859999999992], [2174.1859999999992, 2188.9159999999993], [2188.9159999999993, 2200.4359999999992], [2200.4359999999992, 2211.537999999999], [2211.537999999999, 2230.965999999999], [2230.965999999999, 2248.765999999999], [2248.765999999999, 2259.3559999999993], [2259.3559999999993, 2272.5859999999993], [2272.5859999999993, 2285.669999999999], [2285.669999999999, 2300.318999999999], [2300.318999999999, 2313.1659999999993], [2313.1659999999993, 2329.9259999999995], [2329.9259999999995, 2340.9759999999997], [2340.9759999999997, 2351.6759999999995], [2351.6759999999995, 2362.7859999999996], [2362.7859999999996, 2374.5589999999997], [2374.5589999999997, 2388.479], [2388.479, 2398.528], [2398.528, 2410.479], [2410.479, 2424.288], [2424.288, 2435.029], [2435.029, 2449.759], [2449.759, 2465.599], [2465.599, 2477.538], [2477.538, 2489.149], [2489.149, 2503.5789999999997], [2503.5789999999997, 2515.8189999999995], [2515.8189999999995, 2526.7689999999993], [2526.7689999999993, 2546.678999999999], [2546.678999999999, 2559.8289999999993], [2559.8289999999993, 2571.1289999999995], [2571.1289999999995, 2583.2189999999996], [2583.2189999999996, 2594.7989999999995], [2594.7989999999995, 2604.8389999999995], [2604.8389999999995, 2625.9389999999994], [2625.9389999999994, 2643.2989999999995], [2643.2989999999995, 2655.8089999999997], [2655.8089999999997, 2668.109], [2668.109, 2679.179], [2679.179, 2689.849], [2689.849, 2706.9390000000003], [2706.9390000000003, 2717.8140000000003], [2717.8140000000003, 2732.1690000000003], [2732.1690000000003, 2744.1690000000003], [2744.1690000000003, 2760.349], [2760.349, 2774.299], [2774.299, 2788.389], [2788.389, 2803.788], [2803.788, 2818.0190000000002], [2818.0190000000002, 2829.5690000000004], [2829.5690000000004, 2839.6240000000003], [2839.6240000000003, 2851.679], [2851.679, 2866.369], [2866.369, 2877.5190000000002], [2877.5190000000002, 2889.728], [2889.728, 2900.189], [2900.189, 2912.439], [2912.439, 2925.049], [2925.049, 2939.069], [2939.069, 2951.219], [2951.219, 2961.629], [2961.629, 2973.239], [2973.239, 2983.259], [2983.259, 2997.259], [2997.259, 3015.119], [3015.119, 3025.759], [3025.759, 3043.609], [3043.609, 3056.249], [3056.249, 3068.759], [3068.759, 3082.619], [3082.619, 3095.9790000000003], [3095.9790000000003, 3110.2690000000002], [3110.2690000000002, 3123.989], [3123.989, 3138.309], [3138.309, 3150.078], [3150.078, 3160.339], [3160.339, 3173.859], [3173.859, 3187.869], [3187.869, 3200.259], [3200.259, 3216.899], [3216.899, 3229.239], [3229.239, 3244.739], [3244.739, 3255.049], [3255.049, 3265.259], [3265.259, 3277.609], [3277.609, 3294.619], [3294.619, 3305.299], [3305.299, 3316.389], [3316.389, 3327.284], [3327.284, 3340.119], [3340.119, 3352.328], [3352.328, 3366.219], [3366.219, 3376.989], [3376.989, 3389.349], [3389.349, 3400.9190000000003], [3400.9190000000003, 3413.5090000000005], [3413.5090000000005, 3433.6490000000003], [3433.6490000000003, 3447.2280000000005], [3447.2280000000005, 3457.8590000000004], [3457.8590000000004, 3475.8990000000003], [3475.8990000000003, 3487.1990000000005], [3487.1990000000005, 3498.8290000000006], [3498.8290000000006, 3513.2550000000006], [3513.2550000000006, 3527.6890000000008], [3527.6890000000008, 3542.5590000000007], [3542.5590000000007, 3555.8290000000006], [3555.8290000000006, 3566.3290000000006], [3566.3290000000006, 3577.6590000000006], [3577.6590000000006, 3588.3890000000006], [3588.3890000000006, 3599.9290000000005], [3599.9290000000005, 3614.5690000000004], [3614.5690000000004, 3626.0890000000004], [3626.0890000000004, 3637.3280000000004], [3637.3280000000004, 3650.2490000000003], [3650.2490000000003, 3664.099], [3664.099, 3674.6290000000004], [3674.6290000000004, 3685.3890000000006], [3685.3890000000006, 3696.5690000000004], [3696.5690000000004, 3709.3190000000004], [3709.3190000000004, 3724.3790000000004], [3724.3790000000004, 3737.6990000000005], [3737.6990000000005, 3748.1390000000006], [3748.1390000000006, 3762.2190000000005], [3762.2190000000005, 3773.3090000000007], [3773.3090000000007, 3787.319000000001], [3787.319000000001, 3801.389000000001], [3801.389000000001, 3812.999000000001], [3812.999000000001, 3826.8590000000013], [3826.8590000000013, 3841.039000000001], [3841.039000000001, 3854.929000000001], [3854.929000000001, 3869.959000000001], [3869.959000000001, 3882.8990000000013], [3882.8990000000013, 3894.749000000001], [3894.749000000001, 3905.349000000001], [3905.349000000001, 3921.969000000001], [3921.969000000001, 3932.978000000001], [3932.978000000001, 3944.319000000001], [3944.319000000001, 3954.489000000001], [3954.489000000001, 3958.420000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [671, 1217, 2367, 3380, 3961]}
{"example_id": "mit035@@MIT8_04S16_lec09_300k", "text": ["PROFESSOR: Today we'll talk about observables  and Hermitian operators.  ", "So we've said that an operator, Q, is Hermitian in the language ", "that we've been working so far, if you find  that the integral, dx psi 1 Q psi 2, ", "is actually equal to the integral dx of Q, ", "acting this time of Psi 1 all star psi 2.  So as you've learned already, this requires some properties ", "about the way functions far away,  at infinity, some integration by parts, some things to manage,  but this is the general statement  for a large class of functions, this should be true. ", "Now we want to, sometimes, use a briefer notation  for all of this.  And I will sometimes use it, sometimes not,  and you do whatever you feel. ", "If you like to use this notation, us it.  So here's the definition.  If you put up Psi 1, Psi 2 and a parentheses, ", "this denotes a number, and in fact denotes  the integral of psi 1 star of x, psi 2 of x dx. ", " So whatever you put in the first input  ends up complex motivated.  When you put in the second input, ", "it's like that, it's all integrated.  This has a couple of obvious properties.  If you put a number times psi 1 times psi 2 like this, ", "the number will appear, together with psi 1,  and will complex conjugated.  So it can go out as a star psi 1 psi 2. ", " And if you put the number on the second input, ", "it comes out as is.   Because the second input is not complex  conjugated in the definition. ", "With this definition, a Hermitian operator,  Q is Hermitian, has a nice look to it. ", "It becomes kind of natural and simple.  It's the statement that if you have psi 1, Q psi 2, ", "you can put the Q in the first input.  Q psi 1 psi 2.  ", "This second term in the right hand side  is exactly this integral here.  And the first tern in the left hand side ", "is the left hand side of that condition.  So it's just maybe a briefer way to write it.  So when you get tired of writing integral dx of the first,  the second, you can use this. ", "Now with distance last time, the expectation  values of operators.  So what's the expectation value of Q in some state psi of x? ", "And that is denoted as these braces here and of psi  is equal to the integral of psi. ", "The expectation value depends on the state you live in  and it's psi Q psi.  Or if you wish, dx in written notation psi ", "Q. I should put the hats everywhere.  This is the expectation value of Q. I'm sorry, ", "I missed here a star.   So so far, so good. ", "We've reviewed what a Hermitian operator is,  what an expectation value is, so let's begin with some claims.  Claim number one. ", " The expectation value of Q, with Q Hermitian. ", "So everywhere here, Q will be Hermitian.  The expectation value of Q is real.  A real number, it belongs to the real numbers. ", "So that's an important thing.  You want to figure out the expectation value of Q,  you have a psi star, you have a psi.  Well, it'd better be real if we're going to think, ", "and that's the goal of this discussion,  that Hermitian operators are the things you  can measure in quantum mechanics,  so this better be real. ", "So let's see what this is.  Well, Q psi, that's the expectation value.  If I complex conjugate it, I must complex ", "conjugate this whole thing.  Now if you want to complex conjugate an integral,  you can complex conjugate the integrand. ", "", "Here it is.  I took this right hand side here, the integrand.  I copied it, and now I complex conjugated it.  That's what you mean by complex conjugating an integral. ", "But this is equal, integral dx.  Now I have a product of two functions here.  Psi star and Q that has acted on psi. ", "So that's how I think.  I never think of conjugating Q. Q is  a set of operations that have acted on psi ", "and I'm just going to conjugate it.  And the nice thing is that you never  have to think of what is Q star, there's no meaning for it.  So what happens here? ", "Priority of two functions, the complex conjugate  of the first--  now if you [INAUDIBLE] normally something twice,  you get the function back.  And here you've got Q psi star. ", "But that, these are functions.  You can move around.  So this Q hat psi star Q psi. ", "And so far so good.  You know, I've done everything I could have done.  They told to come to complex conjugate this,  so I complex conjugated it and I'm still not there. ", "But I haven't used that this operator is Hermitian.  So because the operator is Hermitian,  now you can move the Q from this first input to the second one. ", "So it's equal to integral dx psi star Q psi.  And oh, that was the expectation value of Q on psi, ", "so the star of this number is equal to the number itself,  and that proves the claim, Q is real. ", " So this is our first claim. ", "The second claim that is equally important, claim two.  ", "The eigenvalues of the operator Q are real.  ", "So what are the eigenvalues of Q?  Well you've learned, with the momentum operator,  eigenvalues or eigenfunctions of an operator  are those special functions that the operator acts on them ", "and gives you a number called the eigenvalue times  that function.  So Q, say, times, psi 1, if psi 1  is a particularly nice choice, then it ", "will be equal to some number.  Let me quote Q1 times psi1.  And there, I will say that Q1 is the eigenvalue. ", " That's the definition.  And psi1 is the eigenvector, or the eigenfunction. ", " And the claim is that that number is going to real. ", " So why would that be the case?  Well, we can prove it in many ways,  but we can prove it kind of easily with claim number one. ", "And actually gain a little insight,  cold calculate the expectation value of Q  on that precise state, psi 1. ", "Let's see how much is it.  You see, psi 1 is a particular state.  We've called it an eigenstate of the operator. ", "Now you can ask, suppose you live in psi 1?  That's who you are, that's your state.  What is the expectation value of this operator? ", "So we'll learn more about this question later,  but we can just do it, it's the integral of dx psi 1 Q psi 1. ", " And I keep forgetting these stars,  but I remember them after a little while. ", "So at this moment, we can use the eigenvalue condition,  this condition here, that this is  equal to dx psi 1 star Q1 psi 1. ", " And the Q1 can go out, hence Q 1 integral dx of psi ", "1 star psi 1.   But now, we've proven, in claim number one, ", "that the expectation value of Q is always real,  whatever state you take.  So it must be real if you take it on the state psi 1. ", "And if the expectation value of psi 1 is real,  then this quantity, which is equal to that expectation  value, must be real.  This quantity is the product of two factors. ", "A real factor here--  that integral is not only real, it's even positive--  times Q1.  So if this is real, then because this part is real, ", "the other number must be real.  Therefore, Q1 is real.  ", "Now it's an interesting observation  that if your eigenstate, eigenfunction ", "is a normalized eigenfunction, look at the eigenfunction  equation.  It doesn't depend on what precise psi 1 you have, ", "because if you put psi 1 or you put twice psi 1,  this equation still holds.  So if it hold for psi 1, if psi 1 is called an ideal function, ", "3 psi 1, 5 psi 1, minus psi 1 are all eigenfunctions.  Properly speaking in mathematics,  one says that the eigenfunction is ", "the subspace generated by this thing, by multiplication.  Because everything is accepted.  But when we talk about the particle ", "maybe being in the state of psi 1,  we would want to normalize it, to make psi 1 integral squared  equal to 1.  In that case, you would obtain that the expectation ", "value of the operator on that state  is precisely the eigenvalue.  ", "When you keep measuring this operator, this state,  you keep getting the eigenvalue.  So I'll think about the common for a normalized psi ", "1 as a true state that you use for expectation values.  In fact, whenever we compute expectation values,  here is probably a very important thing. ", "Whenever you compute an expectation value,  you'd better normalize the state, because otherwise,  think of the expectation value. ", "If you don't normalize the state, you the calculation  and you get some answer, but your friend  uses a wave function three times yours and your friend  gets now nine times your answer. ", "So for this to be a well-defined calculation,  the state must be normalized.  So here, we should really say that the state is normalized. ", "Say one is the ideal function normalized.  And this integral would be equal to Q1 belonging to the reals. ", " And Q1 is real.  So for a normalized psi 1 or how it should be,  the expectation value of Q on that eigenstate ", " PROFESSOR: So here comes the point that this quite fabulous  about Hermitian operators.  Here is the thing that it really should impress you. ", "It's the fact that any, all Hermitian operators  have as many eigenfunctions and eigenvalues as you can possibly ", "need, whatever that means.  But they're rich.  It's a lot of those states. ", "What it really means is that the set of eigenfunctions for any  Hermitian operator-- whatever Hermitian operator, ", "it's not just for some especially nice ones--  for all of them you get eigenfunctions.  And these eigenfunctions, because it has vectors, ", "they are enough to span the space of states.  That is any state can be written as a superposition  of those eigenvectors. ", "There's enough.  If you're thinking finite dimensional vector spaces,  if you're looking at the Hermitian matrix, ", "the eigenvectors will provide you  a basis for the vector space.  You can understand anything in terms of eigenvectors. ", "It is such an important theorem.  It's called the spectral theorem in mathematics.  And it's discussed in lots of detail in 805. ", "Because there's a minor subtlety.  We can get the whole idea about it here.  But there are a couple of complications  that mathematicians have to iron out. ", "So basically let's state we really  need, which is the following.  Consider the collection of eigenfunctions and eigenvalues ", "of the Hermitian operator q.  And then I go and say, well, q psi 1 equal q 1 psi 1 q psi ", "2 equal q2 psi 2.   And I actually don't specify if it's ", "a finite set or an infinite set.  The infinite set, of course, is a tiny bit more complicated.  But the result is true as well. ", "And we can work with it.  So that is the set up.  And here comes the claim.  ", "Claim 3, the eigenfunctions can be ", "organized to satisfy the following relation, integral dx ", "psi i of x psi j of x is equal to delta ij.  ", "And this is called orthonormality.   Let's see what this all means. ", " We have a collection of eigenfunctions.  And here it says something quite nice.  ", "These functions are like orthonormal functions,  which is to say each function has unit norm. ", "You see, if you take i equal to j,  suppose you take psi 1 psi 1, you get delta 1 1, which is 1. ", "Remember the [INAUDIBLE] for delta is 1 from the [INAUDIBLE]  are the same.  And it's 0 otherwise. psi 1 the norm of psi 1 ", "is 1 and [INAUDIBLE] squared [INAUDIBLE]  psi 1, psi 2, psi3, all of them are well normalized.  So they satisfied this thing we wanted them to satisfy. ", "Those are good states.  psi 1, psi 2, psi 3, those are good states.  They are all normalized.  But even more, any two different ones are orthonormal. ", "This is like the 3 basis vectors of r3.  The x basic unit vector, the y unit vector, the z unit vector, ", "each one has length 1, and they're all orthonormal.  And when are two functions orthonormal?  You say, well, when vectors are orthonormal I know what I mean. ", "But orthonormality for functions means doing this integral.  This measures how different one function is from another one.  Because if you have the same function, ", "this integral and this positive, and this all adds up.  But for different functions, this  is a measure of the inner product between two functions. ", "You see, you have the dot product between two vectors.  The dot product of two functions is an integral like that.  It's the only thing that makes sense ", "So I want to prove one part of this,  which is a part that is doable with elementary methods.  And the other part is a little more complicated. ", "So let's do this.  And consider the case if qi is different from qj, ", "I claim i can prove this property.  We can prove this orthonormality.  So start with the integral dx of psi i star q psi j. ", " Well, q out here at psi j is qj. ", "So this is integral dx psi i star qj psi j. ", "And therefore, it's equal to qj times integral psi i star psi  j.  I simplified this by just enervating it. ", "Because psi i and psi j are eigenstates of q.  Now, the other thing I can do is use the property  that q is Hermitant and move the q to act on this function. ", "So this is equal to integral dx q i psi i star psi j. ", "And now I can keep simplifying as well.  And I have dx.  And then I have the complex conjugate of qi psi i psi i, ", "like this, psi j.  And now, remember q is an eigenvalue for Hermitian  operator. ", "We already know it's real.  So q goes out of the integral as a number.  Because it's real, and it's not changed.  Integral dx psi i star psi j. ", "The end result is that we've shown that this quantity is  equal to this second quantity.  And therefore moving this-- ", "since the integral is the same in both quantities, this shows  that q i minus qj, subtracting these two equations, ", "or just moving one to one side, integral psi i star psi j dx  is equal to 0. ", "So look what you've proven by using Hermiticity,  that the difference between the eigenvalues  times the overlap between psi i and psi j must be 0. ", "But we started with the assumption  that the eigenvalues are different.  And if the eigenvalues are different, this is non-zero.  And the only possibility is that this integral is 0. ", "So this implies since we've assumed  that qi is different than qj.  We've proven that psi i star psi j dx is equal to 0. ", "And that's part of this little theorem.  That the eigenfunctions can be organized  to have orthonormality and orthonormality ", "between the different points.  My proof is good.  But it's not perfect.  Because it ignores one possible complication, ", "which is that here we wrote the list of all the eigenfunctions.  But sometimes something very interesting  happens in quantum mechanics. ", "It's called degeneracy.  And degeneracy means that there may  be several eigenfunctions that are different but have ", "the same eigenvalue.   We're going to find that soon--  we're going to find, for example, states  of a particle that move in a circle that are different ", "and have the same energy.  For example, a particle moving in a circle with this velocity  and a particle moving in a circle with the same magnitude  of the velocity in the other direction ", "are two states that are different but have  the same energy eigenvalue.  So it's possible that this list not all are different. ", "So suppose you have like three or four degenerate states,  say three degenerate states.  They all have the same eigenvalue.  But they are different. ", "Are they orthonormal or not?  The answer is-- actually the clue is there. ", "The eigenfunctions can be organized to satisfy.  It would be wrong if you say the eigenfunctions satisfy. ", "They can be organized to satisfy.  It means that, yes, those ones that have different eigenvalues  are automatically orthonormal. ", "But those that have the same eigenvalues,  you may have three of them maybe,  they may not necessarily be orthonormal.  But you can do linear transformations of them ", "and form linear combinations such that they are orthonormal.  So the interesting part of this theorem,  which is the more difficult part mathematically, ", "is to show that when you have degeneracies  this still can be done.  PROFESSOR: That brings us to claim number four, which is ", "perhaps the most important one.  I may have said it already.b The eigenfunctions of Q ", "form a set of basis functions, and then any reasonable psi ", "can be written as a superposition ", "of Q eigenfunctions.   OK, so let's just make sense of this. ", "Because not only, I think we understand  what this means, but let's write it out mathematically.  So the statement is any psi of x, or this physical state, ", "can be written as a superposition of all  these eigenfunctions So there are numbers, alpha 1 psi  1 of x plus alpha 2 psi 2 of x. ", "Those are the expansion coefficients with alphas.  And in summary, we say from sum over i, alpha i psi i of x. ", "So the idea is that those alpha i's exist  and you can write them.  So any wave function that you have, ", "you can write it in a superposition  of those eigenfunctions of the Hermitian operator.  And there are two things to say here. ", "One is that, how would you calculate those alpha i's?   Well, actually, if you assume this equation,  the calculation of alpha i's is simple, ", "because of this property.  You're supposed to know the eigenfunctions.  You must have done the work to calculate the eigenfunctions. ", "So here is what you can do.  You can do the following integral.  You can do this one, psi i psi. ", "Let's calculate this thing.  Remember what this is.  This is an integral, dx, of psi i star. ", "That's psi.  And psi is the sum over j of alpha j psi j. ", "You can use any letter.  I used i for the sum, but since I put that psi i,  I would make a great confusion if I used another i. ", "So I should use j there.  And what is this?  Well, you're integrating the part of this.  That's a sum.  So the sum can go out. ", "It's the sum over j alpha j integral of psi i star psi j d. ", "And what is this delta ij?  That is our nice orthonormality.  So this is sum over j alpha j, delta i j. ", "Now, this is kind of a simple sum.  You can always be done.  You should just think a second.  You're summing over j, and i is fixed. ", "The only case when this gives something is when j,  and you're summing over, is equal to i,  which is a fixed number.  Therefore, the only thing that survives ", "is j equals to i, so this is 1.  And therefore, this is alpha i.  So we did succeed in calculating this,  and in fact, alpha i is equal to this integral of psi i ", "with psi.  So how do you compute it now for i?  You must do an integral.  Of what?  Of psi i star times your wave function. ", "So in this common interval.  So the alpha i's are given by these numbers.  This would prove. ", "The other thing that you can check  is if the wave function squared dx is equal to 1. ", " What does it imply for the alpha i's? ", "You see, the wave function is normalized,  but it's not a function of alpha 1, alpha 2, alpha 3, alpha 4,  all these things.  So I must calculate this.  And now let's do it, quickly, but do it. ", "Sum over i, alpha i, psi i star, sum over j, alpha j, psi j. ", "See, that's the integral of these things squared dx.   I'm sorry.  I went wrong here. ", "The star is there.  The first psi, starred, the second psi.  Now I got it right.  Now, I take out the sums i, sum over j, alpha i star alpha j, ", "integral dx psi i star psi j.  This is delta i j, therefore j becomes equal to i, ", "and you get sum over i of alpha i star alpha  i, which is the sum over i of, then alpha i squared. ", "OK.  So that's what it says.  Look.  This is something that should be internalized as well.  The sum over i of the alpha i squared is equal to 1. ", "Whenever you have a superposition of wave  functions, and the whole thing is normalized,  and your wave functions are orthonormal, ", "then it's very simple.  The normalization is computed by doing the sums of squares  of each coefficient.  The mixings don't exist because there's no mixes here. ", "So everything is separate.  Everything is unmixed.  Everything is nice.   So there you go.  This is how you expand any state in the collection ", "of eigenfunctions of any Hermitian operator  that you are looking at.  OK.  So finally, we get it.  We've done all the work necessary to state ", "the measurement possibility.  How do we find what we measure?  So here it is.  ", "Measurement Postulate.  ", "So here's the issue.  We want to measure.  I'm going to say these things in words.  You want to measure the operator, q, of your state. ", "The operator might be the momentum, might be the energy,  might be the angular momentum, could be kinetic energy,  could be potential energy.  Any Hermitian operator. ", "You want to measure it in your state.  The first thing that the postulate will say  is that you will, in general, obtain just one number ", "each time you do a measurement, but that number  is one of the eigenvalues of this operator.  So the set of possible measurements, ", "possible outcomes, better say, is the set  of eigenvalues of the operator.  Those are the only numbers you can get.  But you can get them with different probabilities. ", "And for that, you must use this plane.  And you must, in a sense, rewrite your state  as a superposition of the eigenfunctions, those alphas. ", "And the probability to measure q1  is the probability that you end up  of this part of the superposition,  and it will be given by alpha 1 squared, [INAUDIBLE]. ", "The probability to measure q will  be given by alpha 2 squared and all of these numbers.  So, and finally, that after the measurement, ", "another funny thing happens.  The state that was this whole sum collapses to that state  that you obtained.  So if you obtained q1, well, the whole thing collapses to psi 1. ", "After you've done the measurement,  the state of the system becomes psi 1.  So this is the spirit of what happens.  Let me write it out. ", "If we measure Q in the state psi, ", "the possible values obtained are q1, q2. ", " The probability, p i, to measure q i ", "is p i equals alpha i squared.  And remember what this alpha i we calculated it. ", "This overlap of psi i with psi squared.  ", "And finally, after finding--   after, let's write it, the outcome, q i, ", "the state of the system becomes psi ", "of x is equal to psi i of x.  And this is a collapse of the wave function. ", " And it also means that after you've done the measurement ", "and you did obtain the value of q i, you stay with psi i,  if you measure it again, you would keep obtaining q i.  ", "Why did it all become possible?  It all became possible because Hermitian operators  are rich enough to allow you to write ", "any state as a superposition.  And therefore, if you want to measure momentum,  you must find all the eigenfunctions of momentum  and rewrite your state as a superposition of momentum. ", "You want to do energy?  Well, you must rewrite your state  as a superposition of energy eigenstates,  and then you can measure.  Want to measure angular momentum? ", "Find the eigenstates of angular momentum,  use the theorem to rewrite your whole state in different ways.  And this is something we said in the first lecture ", "of this course, that any vector in a vector space  can be written in infinitely many ways  as different superpositions of vectors. ", "We wrote the arrow and said, this vector  is the sum of this and this, and this plus this plus this,  and this plus this plus this. ", "And yes, you need all that flexibility.  For any measurement, you rewrite the vector  as the sum of the eigenvectors, and then you ", "can tell what are your predictions.  You need that flexibility that any vector in a vector space  can be written in infinitely many ways ", "as different linear superpositions.  So there's a couple of things we can  do to add intuition to this. ", "I'll do, first, a consistency check,  and maybe I'll do an example as well.   And then we have to define uncertainties, ", "those of that phase.  So any question about this measurement postulate?  Is there something unclear about it?  ", "It's a very strange postulate.  You see, it divides quantum mechanics into two realms.  There's the realm of the Schrodinger equation, ", "your wave function evolves in time.  And then there's a realm of measurement.  The Schroedinger equation doesn't tell you  what you're supposed to do with measurement. ", "But consistency with a Schroedinger equations  doesn't allow you many things.  And this is apparently the only thing we can do.  And then we do a measurement, but somehow, this psi of x ", "collapses and becomes one of the results of your measurement.   People have wondered, if the Schroedinger equation is  all there is in the world, why doesn't the result ", "of the measurement come out of the Schroedinger equation?  Well, people think very hard about it,  and they come up with all kinds of interesting things. ", "Nevertheless, nothing that comes out  is sufficiently clear and sufficiently useful  to merit a discussion at this moment.  It's very interesting, and it's subject of research, ", "but nobody has found a flaw with this way of stating things.  And it's the simplest way of stating things.  And therefore, the measurement is an extra assumption, ", "an extra postulate.  That's how a measurement works.  And after you measure, you leave the system,  the Schroedinger equation takes over and keeps evolving. ", "You measure again, something happens,  there's some answer that gets realized.  PROFESSOR: Let me do a little exercise using still ", "this manipulation.   And I'll confirm the way we think ", "about expectations values.  So, suppose exercise.  Suppose you have indeed that psi is equal to alpha i psi i. ", " Compute the expectation value of Q in the state of psi.  Precisely, the expectation value of this operator ", "we've been talking about on the state.  So this is equal to the integral dx psi star Q psi. ", "And now I have to put two sums before.  And go a little fast here.  dx sum over i alpha i psi i star Q sum over j alpha j psi j. ", "No star.   This is equal to sum over i sum over j alpha i star alpha j ", "integral dx psi i star Q psi j.  But Q psi j is equal to qj psi j. ", " Therefore, this whole thing is equal to qj ", "times the integral dx of psi i star psi j,  which is qj delta ij. ", "So here we go.  It's equal to sum over i, sum over j,  alpha i star alpha j, qj delta ij, which ", "is equal to the sum over i.  The j's disappear.  And this is alpha i squared qi. ", "That's it.  OK.  Now you're supposed to look at this and say, yay.  Now why is that? ", "Look.  How did we define expectation values?  We defined it as the sum of the value times the probability ", "that this value have.  It's for a random variable.  So here our random variable is the result of the measurement.  And what are the possible values?  qi's. ", "And what are the probabilities that they have Pi?  OK.  So the expectation value of q should be that, ", "should be the sum of the possible values  times their probabilities, and that's what the system gives.  This is how we defined expectation value of x. ", "Even though it's expectation value of P.  And it all comes from the measurement postulate  and the definition.  Now, this definition and the measurement postulate ", "just shows that this is what we expect.  This is the result of the expectation value.  OK. ", "I think I have a nice example.  I don't know if I want to go into all  the detail of these things, but they illustrate  things in a nice way. ", "So let's try to do it.   So here it is.  It's a physical example. ", "This is a nice concrete example because things work out.  So I think we'll actually illustrate ", "some physical points.  Example.  Particle on a circle.  ", "x 0 to L. Maybe you haven't seen a circle described by that,  but you take the x-axis, and you say yes, the circle ", "is 0 to L. L and 0.  And the way you think of it is that this point  is identified with this point. ", "If you have a line and you identify the two endpoints,  that's called a circle.  It's in the sense of topology.  A circle as the set of points equidistant to a center ", "is a geometric description of a round circle.  But this, topologically speaking, anything  that is closed is topologically a circle. ", "We think of a circle as this, physically,  or it could be a curved line that makes it into a circle.  But it's not important. ", "Let's consider a free particle on a circle,  and suppose the circle has an end L. So x belongs here.  And here is the wave function, psi equals 2 over L, ", "1 over square root of 3 sine of 2 pi  x over L, plus 2 over square root of 3 cosine 6 pi x over L. ", "This is the wave function of your particle on a circle.   At some time, time equals 0, it's a free particle. ", "No potential.  And it lives in the circle, and these functions  are kind of interesting.  You see, if you live on the circle  you would want to emphasize the fact that this point 0 is ", "the same as the point L, so you should have that psi  and L must be equal to psi at 0.  It's a circle, after all, it's the same point. ", "And therefore for 0 or for L, the difference here  is 0 or 2 pi, and the sine is the same thing. ", "And 0, when x equals 0, and 6 pi, so that's also periodic,  and it's fine.  It's a good wave function result. ", "The question is, for this problem,  what are, if you measure momentum, measure momentum, ", "what are the possible values and their probabilities? ", "Probabilities.   So you decide to measure momentum of this particle. ", "What can you get?   OK.  It looks a little nontrivial, and it is a little nontrivial. ", "Momentum.  So I must sort of find the momentum eigenstates.  Momentum eigenstates, they are those infinite plane waves, ", "e to the ikx, that we could never normalize.  Because you square it, it's 1, and the integral over all space ", "is infinite.  So are we heading for disaster here?  No.  Because it lives in a finite space.  Yes, you have a question? ", "STUDENT: Should it be a wave function [INAUDIBLE] complex?  Because right now, it just looks like it's a real value.  And we can't [INAUDIBLE] real wave functions, can we? ", " PROFESSOR: Well, it is the wave function at time equals 0.  So the time derivative would have ", "to bring in complex things.  So you can have a wave function that  is 0, that is real at some particular time. ", "Like, any wave function psi of x e to the minus iEt over h bar  is a typical wave function.  And then at time equal 0 it may be real. ", "It cannot be real forever.  So you cannot assume it's real.  But at some particular times it could be real.  Very good question.  ", "The other thing you might say, look, this  is too real to have momentum.  Momentum has to do with waves.  That's probably not a reliable argument.  OK, so, where do we go from here? ", "Well, let's try to find the momentum eigenstates.  They should be things like that, exponentials.  So how could they look?  Well, e to the 2 pi i, maybe. ", " What else?  x, there should be an x for a momentum thing. ", "Now there should be no units here,  so there better be an L here.   And now I could put, maybe, well the 2 maybe was-- ", "why did I think of the 2 or the pi?  Well, for convenience.  But let's see what.  Suppose you have a number m here. ", " Then the good thing about this is that when x is equal to 0, ", "there is some number here, but when x is equal to L,  it's a multiple of e to the 2 pi i, so that's periodic.  So this does satisfy, I claim, it's the only way ", "if m is any integer.  So it goes from minus infinity to infinity.  Those things are periodic. ", "They satisfy psi.  Actually they satisfy psi of x plus L is equal to psi of x.  ", "OK.  That seems to be something that could be a momentum eigenstate.  And then I have to normalize it.  Well, if I square it and integrate it. ", "If I square it then the phase cancels, so you get 1.  If you integrate it you get L. If you put 1  over the square root of L, when you square it and integrate, ", "you will get 1.  So here it is.  Psi m's of x are going to be defined to be this thing. ", "And I claim these things are momentum eigenstates.  In fact, what is the value of the momentum?  Well, you calculate h bar over i d dx on psi m. ", "And you get what?  You get 2 pi m over L times h bar times psi. ", "The h bar is there, the i cancels, and everything then  multiplies, the x falls down.  So this is the state with momentum  P equals to h bar 2 pi m over L. ", "OK.  Actually, doing that, we've done the most difficult part  of the problem.  You've found the momentum eigenfunctions. ", "So now the rest of the thing is to rewrite this in terms  of this kind of objects.  ", "I'll do it in a second.   Maybe I'll leave a little space there  and you can check the algebra, and you ", "can see it in the notes.  But you know what you're supposed to do.  A sine of x is e to the ix minus is e to the minus ix over 2i. ", "So you'd get these things converted to exponentials.  The cosine of x is equal to e to the ix  plus e to the minus ix over 2. ", "So if you do that with those things, look.  What the sine of 2 pi x going to give you?  It's going to give you some exponentials of 2 pi ix over L. ", "So suppose that m equals 1.  And m Equals minus 1.  And this will give you m equals 3, 3 times 2 is 6. ", "And m equal minus 3.  So I claim, after some work, and you could try to do it.  I think it would be a nice exercise.  Psi is equal square root of 2 over 3, ", "1 over 2 i psi 1 minus square root of 2 over 3, 1 over 2i psi  minus 1 plus 1 over square root of 3 psi 3, ", "plus 1 over square root of 3 psi minus 3.  And it should give you some satisfaction  to see something like that.  You're now seeing the wave function ", "written as a superposition of momentum eigenstates.  This theorem came through.  In this case, as a particle in the circle, ", "the statement is that the eigenfunctions  are the exponentials, and it's Fourier's theorem.  Again, for a series.  So finally, here is the answer. ", "So psi 1, we can measure psi 1.  What is the momentum of psi 1?  So here are p values. ", "And probabilities.   The first value, psi 1, the momentum is 2 pi h bar over L. ", "So 2 pi h bar over L. And what is its probability?  It's this whole number squared.  So square root of 2/3, 1 over 2i squared. ", "So how much is that?  It's 2/3 times 1/4.  2/3 times 1/4, which is 1/6. ", "And the other value that you can get is minus this one,  so minus 2 pi h bar over L. This minus doesn't matter, ", "probability also 1/6.  The next one is with 3.  So you can get 2, 6 pi, 6 pi h bar over L, ", "with probability square of this, 1/3.   And minus 6 pi h bar over L with probability 1/3. ", "Happily our probabilities add up.   So there you go.  That's the theorem expressed in a very clear example. ", "We had a wave function.  You wrote it as a sum of four momentum eigenstates.  And now you know, if you do a measurement,  what are the possible values of the momentum. ", "This should have been probably 1/6.  PROFESSOR: Uncertainty.   When you talk about random variables, random variable Q, ", "we've said that it has values Q1 up to, say, Qn,  and probabilities P1 up to Pn, we ", "speak of a standard deviation, delta Q,  as the uncertainty, the standard deviation. ", " And how is that standard deviation defined?  Well you begin by making sure you  know what is the expectation value of the-- ", "or the average value of this random variable,  which was defined, last time, I think I put braces,  but bar is kind of nice sometimes ", "too, at least for random variables,  and it's the sum of the Pi times the Qi.   The uncertainty is also some expectation value. ", "And expectation value of deviation.  So the uncertainty squared is the expectation value,  sum over i, of deviations of the random variable from the mean. ", "So you calculate the expected value  of the difference of your random variable and the mean squared,  and that is the square of the standard deviation. ", "Now this is the definition.  And it's a very nice definition because it  makes a few things clear.  For example, the left hand side is delta Q squared, which ", "means it's a positive number.  And the right hand side is also a positive number,  because you have probabilities times differences of quantities ", "squared.  So this is all greater and equal to zero.  And moreover, you can actually say the following. ", "If the uncertainty, or the standard deviation, is zero,  the random variable is not that random. ", "Because if this whole thing is 0, this delta squared,  delta Q squared must be 0 and this must be 0.  But each term here is positive. ", "So each term must be 0, because of any one of them  was not equal to zero, you would get a non-zero contribution.  So any possible Qi that must have a Pi different from 0 ", "must be equal to Qbar.  So if delta cubed is equal to 0, Qi  is equal to Q as not random anymore. ", " OK, now we can simplify this expression. ", "", "Do the following.  By simplifying, I mean expand the right-hand side.  So sum over i, Pi Qi squared, minus 2 sum over i, ", "Pi Qi Q bar plus sum over i, Pi Q bar squared. ", " This kind of thing shows up all the time,  shows up in quantum mechanic as well, as we'll see in a second. ", "And you need to be able to see what's happenening.  Here, you're having the expectation value  of Qi squared. ", " That's the definition of a bar of some variable,  you'd multiply with variable by the exponent of [INAUDIBLE]. ", "What is this?  This a little more funny.  First, you should know that Q bar is a number,  so it can go out.  So it's minus 2 Q bar. ", "And then all that is left is this, but that's another Q bar.  So it's another Q bar.   And here, you take this one out because it's a number, ", "and the sum of the probabilities is 1,  so it's Q bar squared as well.  And it always comes out that way, this minus 2 ", "Q bar squared plus Q bar squared.  So at the end, Delta Q, it's another famous property,  is the mean of the square minus the square of the mean. ", " And from this, since this is greater or equal than 0, ", "you always conclude that the mean of the square  is always bigger than the--  ", "maybe I shouldn't have the i here,  I think it's a random variable Q squared.  So the mean, the square of this is greater or equal ", "than Q bar squared.   OK.   Well, what happens in quantum mechanics, ", "let give you the definition and a couple of ways of writing it.  So here comes the definition. ", "It's inspired by this thing.  So in quantum mechanics, permission operator Q ", "will define the uncertainty of Q in the state,  Psi O squared as the expectation value ", "of Q squared minus the expectation value of Q squared. ", "Those are things that you know in quantum mechanics,  how you're supposed to compute.   Because you know what an expectation value ", "is in any state Psi.  You so Psi star, the operator, Psi.  And here you do this thing, so it's all clear. ", "So it's a perfectly good definition.  Maybe it doesn't give you too much insight yet,  but let me say two things, and we'll leave ", "them to complete for next time.  Which is claim one, one, that Delta Q squared ", "Psi can be written as the expectation  value of Q minus absolute expectation value of Q squared. ", "Like that.  Look.  It looks funny, and we'll elaborate this,  but the first claim is that this is a possible re-writing. ", "You can write this uncertainty as a single expectation value.  This is the analog of this equation in quantum mechanics. ", "Claim two is another re-writing.  Delta Q squared on Psi can be re-written as this. ", "That's an integral.   Q minus Q and Psi. ", "Look at that.  You act on Psi with the operator, Q, and multiplication  by the expectation value of Q. This is an operator, ", "this is a number multiplied by Psi.  You can add to this on the [? wave ?] function,  you can square it, and then integrate.  And that is also the uncertainty. ", " We'll show these two things next time  and show one more thing that the uncertainty vanishes ", "if and only if the state is an ideal state of Q.  So If the state that you are looking for  is an ideal state of Q, you have no uncertainty. ", "And if you have no uncertainty, the state  must be an ideal state of Q. So those all things  will come from this planes, that we'll elaborate on next time. "], "vid_duration": [18.8, 12.959, 12.201, 10.96, 12.78, 13.56, 12.56, 12.92, 12.602, 11.288, 14.5, 13.38, 11.46, 12.09, 14.13, 10.15, 14.466, 10.764, 13.72, 23.51, 13.73, 14.06, 14.34, 10.89, 10.019, 10.141, 13.92, 12.975, 10.695, 14.61, 10.742, 10.332, 13.276, 11.8, 10.365, 10.385, 14.92, 14.14, 14.96, 14.47, 11.27, 11.771, 12.959, 10.67, 19.97, 12.27, 13.425, 13.635, 14.15, 14.23, 14.38, 13.67, 10.34, 11.6, 13.95, 11.97, 15.26, 14.522, 11.613, 10.775, 13.23, 15.94, 11.72, 10.34, 10.875, 12.115, 11.44, 10.66, 13.346, 10.134, 20.088, 11.642, 11.44, 11.49, 12.16, 13.115, 13.545, 14.7, 13.635, 11.685, 11.25, 14.219, 10.451, 11.12, 10.28, 11.53, 11.07, 25.641, 16.799, 11.24, 10.662, 12.768, 14.42, 13.82, 12.22, 10.315, 20.265, 11.81, 10.57, 10.13, 12.62, 15.19, 10.47, 11.02, 11.99, 12.4, 13.84, 15.32, 14.95, 17.92, 10.14, 10.77, 15.65, 13.01, 11.38, 14.811, 10.489, 15.53, 10.93, 11.87, 12.65, 12.97, 12.29, 17.93, 10.84, 12.17, 12.02, 12.45, 13.66, 11.56, 12.0, 10.89, 12.716, 10.294, 11.723, 15.427, 10.58, 12.315, 15.575, 22.91, 11.14, 12.512, 20.728, 13.91, 12.45, 10.17, 13.68, 12.53, 10.19, 13.8, 11.275, 10.165, 10.81, 11.47, 10.24, 13.27, 11.97, 12.36, 18.22, 10.06, 11.887, 14.183, 11.2, 12.88, 10.2, 13.032, 17.868, 11.57, 12.46, 13.59, 13.95, 15.93, 16.52, 14.7, 15.47, 14.25, 11.08, 11.03, 12.69, 11.49, 12.63, 14.464, 14.752, 14.844, 15.79, 11.31, 14.8, 12.38, 16.3, 11.24, 15.57, 17.09, 13.05, 11.521, 11.829, 16.05, 11.64, 13.77, 10.14, 10.85, 10.84, 10.17, 11.58, 11.25, 13.31, 11.964, 12.656, 10.25, 10.92, 13.62, 13.02, 12.06, 13.14, 11.815, 10.325, 11.57, 11.969, 15.078, 13.283, 11.37, 20.0, 13.57, 13.915, 13.965, 11.02, 13.92, 12.41, 11.906, 14.594, 10.37, 12.4, 11.29, 13.52, 10.92, 10.21, 11.53, 14.11, 11.06, 14.14, 11.22, 13.17, 12.32, 10.84, 14.81, 14.97, 12.76, 11.89, 12.77, 11.13, 12.57, 14.88, 11.97, 13.01, 11.27, 13.57, 10.4, 11.0, 10.174, 11.596, 10.61, 10.93, 12.732, 13.118, 19.38, 11.93, 12.46, 10.08, 11.88, 14.25, 12.3, 10.56, 14.67, 10.41, 10.59, 16.165, 14.975, 25.14, 10.44, 11.912, 10.098, 16.04, 14.89, 13.24, 11.945, 12.835, 13.535, 12.007, 10.098, 14.22, 10.89, 19.86, 13.89, 14.46, 10.31, 13.58, 13.39, 11.43, 12.34, 13.75, 10.512, 10.377, 12.591, 10.4, 16.319, 19.311, 16.33, 13.67, 12.149, 10.201, 10.33, 11.27, 15.23, 11.453, 13.907, 15.68, 20.609, 13.351, 10.159, 11.056, 13.984, 10.37, 14.481, 13.479, 14.95, 13.441, 11.754, 12.666, 14.67, 12.009, 12.481, 13.899, 14.781, 10.87, 10.139, 11.721, 13.359, 16.022, 10.157, 14.792, 17.199, 15.321, 12.435, 12.685, 12.04, 13.691, 8.716], "stet": [[0, 18.8], [18.8, 31.759], [31.759, 43.96], [43.96, 54.92], [54.92, 67.7], [67.7, 81.26], [81.26, 93.82000000000001], [93.82000000000001, 106.74000000000001], [106.74000000000001, 119.34200000000001], [119.34200000000001, 130.63000000000002], [130.63000000000002, 145.13000000000002], [145.13000000000002, 158.51000000000002], [158.51000000000002, 169.97000000000003], [169.97000000000003, 182.06000000000003], [182.06000000000003, 196.19000000000003], [196.19000000000003, 206.34000000000003], [206.34000000000003, 220.80600000000004], [220.80600000000004, 231.57000000000005], [231.57000000000005, 245.29000000000005], [245.29000000000005, 268.80000000000007], [268.80000000000007, 282.5300000000001], [282.5300000000001, 296.5900000000001], [296.5900000000001, 310.93000000000006], [310.93000000000006, 321.82000000000005], [321.82000000000005, 331.83900000000006], [331.83900000000006, 341.9800000000001], [341.9800000000001, 355.9000000000001], [355.9000000000001, 368.8750000000001], [368.8750000000001, 379.5700000000001], [379.5700000000001, 394.1800000000001], [394.1800000000001, 404.92200000000014], [404.92200000000014, 415.25400000000013], [415.25400000000013, 428.53000000000014], [428.53000000000014, 440.33000000000015], [440.33000000000015, 450.69500000000016], [450.69500000000016, 461.08000000000015], [461.08000000000015, 476.00000000000017], [476.00000000000017, 490.14000000000016], [490.14000000000016, 505.10000000000014], [505.10000000000014, 519.5700000000002], [519.5700000000002, 530.8400000000001], [530.8400000000001, 542.6110000000001], [542.6110000000001, 555.57], [555.57, 566.24], [566.24, 586.21], [586.21, 598.48], [598.48, 611.905], [611.905, 625.54], [625.54, 639.6899999999999], [639.6899999999999, 653.92], [653.92, 668.3], [668.3, 681.9699999999999], [681.9699999999999, 692.31], [692.31, 703.91], [703.91, 717.86], [717.86, 729.83], [729.83, 745.09], [745.09, 759.6120000000001], [759.6120000000001, 771.2250000000001], [771.2250000000001, 782.0000000000001], [782.0000000000001, 795.2300000000001], [795.2300000000001, 811.1700000000002], [811.1700000000002, 822.8900000000002], [822.8900000000002, 833.2300000000002], [833.2300000000002, 844.1050000000002], [844.1050000000002, 856.2200000000003], [856.2200000000003, 867.6600000000003], [867.6600000000003, 878.3200000000003], [878.3200000000003, 891.6660000000003], [891.6660000000003, 901.8000000000003], [901.8000000000003, 921.8880000000003], [921.8880000000003, 933.5300000000003], [933.5300000000003, 944.9700000000004], [944.9700000000004, 956.4600000000004], [956.4600000000004, 968.6200000000003], [968.6200000000003, 981.7350000000004], [981.7350000000004, 995.2800000000003], [995.2800000000003, 1009.9800000000004], [1009.9800000000004, 1023.6150000000004], [1023.6150000000004, 1035.3000000000004], [1035.3000000000004, 1046.5500000000004], [1046.5500000000004, 1060.7690000000005], [1060.7690000000005, 1071.2200000000005], [1071.2200000000005, 1082.3400000000004], [1082.3400000000004, 1092.6200000000003], [1092.6200000000003, 1104.1500000000003], [1104.1500000000003, 1115.2200000000003], [1115.2200000000003, 1140.8610000000003], [1140.8610000000003, 1157.6600000000003], [1157.6600000000003, 1168.9000000000003], [1168.9000000000003, 1179.5620000000004], [1179.5620000000004, 1192.3300000000004], [1192.3300000000004, 1206.7500000000005], [1206.7500000000005, 1220.5700000000004], [1220.5700000000004, 1232.7900000000004], [1232.7900000000004, 1243.1050000000005], [1243.1050000000005, 1263.3700000000006], [1263.3700000000006, 1275.1800000000005], [1275.1800000000005, 1285.7500000000005], [1285.7500000000005, 1295.8800000000006], [1295.8800000000006, 1308.5000000000005], [1308.5000000000005, 1323.6900000000005], [1323.6900000000005, 1334.1600000000005], [1334.1600000000005, 1345.1800000000005], [1345.1800000000005, 1357.1700000000005], [1357.1700000000005, 1369.5700000000006], [1369.5700000000006, 1383.4100000000005], [1383.4100000000005, 1398.7300000000005], [1398.7300000000005, 1413.6800000000005], [1413.6800000000005, 1431.6000000000006], [1431.6000000000006, 1441.7400000000007], [1441.7400000000007, 1452.5100000000007], [1452.5100000000007, 1468.1600000000008], [1468.1600000000008, 1481.1700000000008], [1481.1700000000008, 1492.5500000000009], [1492.5500000000009, 1507.3610000000008], [1507.3610000000008, 1517.8500000000008], [1517.8500000000008, 1533.3800000000008], [1533.3800000000008, 1544.3100000000009], [1544.3100000000009, 1556.1800000000007], [1556.1800000000007, 1568.8300000000008], [1568.8300000000008, 1581.8000000000009], [1581.8000000000009, 1594.0900000000008], [1594.0900000000008, 1612.020000000001], [1612.020000000001, 1622.8600000000008], [1622.8600000000008, 1635.0300000000009], [1635.0300000000009, 1647.0500000000009], [1647.0500000000009, 1659.500000000001], [1659.500000000001, 1673.160000000001], [1673.160000000001, 1684.720000000001], [1684.720000000001, 1696.720000000001], [1696.720000000001, 1707.610000000001], [1707.610000000001, 1720.326000000001], [1720.326000000001, 1730.620000000001], [1730.620000000001, 1742.343000000001], [1742.343000000001, 1757.770000000001], [1757.770000000001, 1768.3500000000008], [1768.3500000000008, 1780.6650000000009], [1780.6650000000009, 1796.240000000001], [1796.240000000001, 1819.150000000001], [1819.150000000001, 1830.290000000001], [1830.290000000001, 1842.802000000001], [1842.802000000001, 1863.530000000001], [1863.530000000001, 1877.4400000000012], [1877.4400000000012, 1889.8900000000012], [1889.8900000000012, 1900.0600000000013], [1900.0600000000013, 1913.7400000000014], [1913.7400000000014, 1926.2700000000013], [1926.2700000000013, 1936.4600000000014], [1936.4600000000014, 1950.2600000000014], [1950.2600000000014, 1961.5350000000014], [1961.5350000000014, 1971.7000000000014], [1971.7000000000014, 1982.5100000000014], [1982.5100000000014, 1993.9800000000014], [1993.9800000000014, 2004.2200000000014], [2004.2200000000014, 2017.4900000000014], [2017.4900000000014, 2029.4600000000014], [2029.4600000000014, 2041.8200000000013], [2041.8200000000013, 2060.0400000000013], [2060.0400000000013, 2070.1000000000013], [2070.1000000000013, 2081.9870000000014], [2081.9870000000014, 2096.1700000000014], [2096.1700000000014, 2107.3700000000013], [2107.3700000000013, 2120.2500000000014], [2120.2500000000014, 2130.450000000001], [2130.450000000001, 2143.4820000000013], [2143.4820000000013, 2161.3500000000013], [2161.3500000000013, 2172.9200000000014], [2172.9200000000014, 2185.3800000000015], [2185.3800000000015, 2198.9700000000016], [2198.9700000000016, 2212.9200000000014], [2212.9200000000014, 2228.8500000000013], [2228.8500000000013, 2245.3700000000013], [2245.3700000000013, 2260.070000000001], [2260.070000000001, 2275.540000000001], [2275.540000000001, 2289.790000000001], [2289.790000000001, 2300.870000000001], [2300.870000000001, 2311.900000000001], [2311.900000000001, 2324.590000000001], [2324.590000000001, 2336.080000000001], [2336.080000000001, 2348.710000000001], [2348.710000000001, 2363.174000000001], [2363.174000000001, 2377.926000000001], [2377.926000000001, 2392.770000000001], [2392.770000000001, 2408.560000000001], [2408.560000000001, 2419.870000000001], [2419.870000000001, 2434.670000000001], [2434.670000000001, 2447.050000000001], [2447.050000000001, 2463.3500000000013], [2463.3500000000013, 2474.590000000001], [2474.590000000001, 2490.160000000001], [2490.160000000001, 2507.2500000000014], [2507.2500000000014, 2520.3000000000015], [2520.3000000000015, 2531.8210000000017], [2531.8210000000017, 2543.650000000002], [2543.650000000002, 2559.700000000002], [2559.700000000002, 2571.340000000002], [2571.340000000002, 2585.110000000002], [2585.110000000002, 2595.250000000002], [2595.250000000002, 2606.1000000000017], [2606.1000000000017, 2616.940000000002], [2616.940000000002, 2627.110000000002], [2627.110000000002, 2638.690000000002], [2638.690000000002, 2649.940000000002], [2649.940000000002, 2663.250000000002], [2663.250000000002, 2675.2140000000018], [2675.2140000000018, 2687.8700000000017], [2687.8700000000017, 2698.1200000000017], [2698.1200000000017, 2709.040000000002], [2709.040000000002, 2722.6600000000017], [2722.6600000000017, 2735.6800000000017], [2735.6800000000017, 2747.7400000000016], [2747.7400000000016, 2760.8800000000015], [2760.8800000000015, 2772.6950000000015], [2772.6950000000015, 2783.0200000000013], [2783.0200000000013, 2794.5900000000015], [2794.5900000000015, 2806.5590000000016], [2806.5590000000016, 2821.6370000000015], [2821.6370000000015, 2834.9200000000014], [2834.9200000000014, 2846.2900000000013], [2846.2900000000013, 2866.2900000000013], [2866.2900000000013, 2879.8600000000015], [2879.8600000000015, 2893.7750000000015], [2893.7750000000015, 2907.7400000000016], [2907.7400000000016, 2918.7600000000016], [2918.7600000000016, 2932.6800000000017], [2932.6800000000017, 2945.0900000000015], [2945.0900000000015, 2956.9960000000015], [2956.9960000000015, 2971.5900000000015], [2971.5900000000015, 2981.9600000000014], [2981.9600000000014, 2994.3600000000015], [2994.3600000000015, 3005.6500000000015], [3005.6500000000015, 3019.1700000000014], [3019.1700000000014, 3030.0900000000015], [3030.0900000000015, 3040.3000000000015], [3040.3000000000015, 3051.8300000000017], [3051.8300000000017, 3065.940000000002], [3065.940000000002, 3077.000000000002], [3077.000000000002, 3091.1400000000017], [3091.1400000000017, 3102.3600000000015], [3102.3600000000015, 3115.5300000000016], [3115.5300000000016, 3127.8500000000017], [3127.8500000000017, 3138.690000000002], [3138.690000000002, 3153.500000000002], [3153.500000000002, 3168.4700000000016], [3168.4700000000016, 3181.230000000002], [3181.230000000002, 3193.1200000000017], [3193.1200000000017, 3205.8900000000017], [3205.8900000000017, 3217.020000000002], [3217.020000000002, 3229.590000000002], [3229.590000000002, 3244.470000000002], [3244.470000000002, 3256.440000000002], [3256.440000000002, 3269.450000000002], [3269.450000000002, 3280.720000000002], [3280.720000000002, 3294.2900000000022], [3294.2900000000022, 3304.6900000000023], [3304.6900000000023, 3315.6900000000023], [3315.6900000000023, 3325.8640000000023], [3325.8640000000023, 3337.4600000000023], [3337.4600000000023, 3348.0700000000024], [3348.0700000000024, 3359.0000000000023], [3359.0000000000023, 3371.7320000000022], [3371.7320000000022, 3384.850000000002], [3384.850000000002, 3404.2300000000023], [3404.2300000000023, 3416.160000000002], [3416.160000000002, 3428.620000000002], [3428.620000000002, 3438.700000000002], [3438.700000000002, 3450.580000000002], [3450.580000000002, 3464.830000000002], [3464.830000000002, 3477.1300000000024], [3477.1300000000024, 3487.6900000000023], [3487.6900000000023, 3502.3600000000024], [3502.3600000000024, 3512.7700000000023], [3512.7700000000023, 3523.3600000000024], [3523.3600000000024, 3539.5250000000024], [3539.5250000000024, 3554.5000000000023], [3554.5000000000023, 3579.640000000002], [3579.640000000002, 3590.080000000002], [3590.080000000002, 3601.992000000002], [3601.992000000002, 3612.090000000002], [3612.090000000002, 3628.130000000002], [3628.130000000002, 3643.020000000002], [3643.020000000002, 3656.2600000000016], [3656.2600000000016, 3668.2050000000017], [3668.2050000000017, 3681.040000000002], [3681.040000000002, 3694.5750000000016], [3694.5750000000016, 3706.5820000000017], [3706.5820000000017, 3716.6800000000017], [3716.6800000000017, 3730.9000000000015], [3730.9000000000015, 3741.7900000000013], [3741.7900000000013, 3761.6500000000015], [3761.6500000000015, 3775.5400000000013], [3775.5400000000013, 3790.0000000000014], [3790.0000000000014, 3800.3100000000013], [3800.3100000000013, 3813.8900000000012], [3813.8900000000012, 3827.280000000001], [3827.280000000001, 3838.710000000001], [3838.710000000001, 3851.050000000001], [3851.050000000001, 3864.800000000001], [3864.800000000001, 3875.3120000000013], [3875.3120000000013, 3885.689000000001], [3885.689000000001, 3898.280000000001], [3898.280000000001, 3908.680000000001], [3908.680000000001, 3924.999000000001], [3924.999000000001, 3944.3100000000013], [3944.3100000000013, 3960.6400000000012], [3960.6400000000012, 3974.3100000000013], [3974.3100000000013, 3986.459000000001], [3986.459000000001, 3996.660000000001], [3996.660000000001, 4006.990000000001], [4006.990000000001, 4018.260000000001], [4018.260000000001, 4033.490000000001], [4033.490000000001, 4044.943000000001], [4044.943000000001, 4058.8500000000013], [4058.8500000000013, 4074.530000000001], [4074.530000000001, 4095.139000000001], [4095.139000000001, 4108.490000000001], [4108.490000000001, 4118.649], [4118.649, 4129.705], [4129.705, 4143.689], [4143.689, 4154.059], [4154.059, 4168.54], [4168.54, 4182.019], [4182.019, 4196.969], [4196.969, 4210.41], [4210.41, 4222.164], [4222.164, 4234.83], [4234.83, 4249.5], [4249.5, 4261.509], [4261.509, 4273.99], [4273.99, 4287.889], [4287.889, 4302.67], [4302.67, 4313.54], [4313.54, 4323.679], [4323.679, 4335.4], [4335.4, 4348.759], [4348.759, 4364.781], [4364.781, 4374.938], [4374.938, 4389.7300000000005], [4389.7300000000005, 4406.929], [4406.929, 4422.25], [4422.25, 4434.685], [4434.685, 4447.370000000001], [4447.370000000001, 4459.410000000001], [4459.410000000001, 4473.101000000001], [4473.101000000001, 4481.817000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [998, 1781, 2794, 3856, 4484]}
{"example_id": "mit035@@MIT8_04S16_lec03_300k", "text": ["PROFESSOR: Last time, we spoke about photons  in the context of an interferometer.  The Mach-Zehnder interferometer.  And we saw the very unusual properties ", "of photons and interference, and how relatively simple  interference a effect can be used to produce  a very surprising measurement. ", "Today we're going to backtrack and go from the beginning,  and think about photons as physicists did 100 years ago,  and how, by thinking about photons, ", "they pretty much came up with quantum mechanics.  So we want to trace this back.  And the best place to start, probably,  is with a photoelectric effect. ", "The photoelectric effect is an experiment  done by Hertz in 1887, in which he irradiated plates. ", "That means shine light, high energy beams of light,  on metal plate, and he found that electrons were released.  Those were called photo electrons. ", "And therefore, you would get a photoelectric current  from those electrons.  So this is the effect we want to discuss now,  is the photoelectric effect. ", " And it's Hertz, 1887. ", "So first a description.  So polished metal plates irradiated may emit electrons. ", "And these are called photo electrons sometimes.   Photo electrons is just an electron that ", "was released due to a photon.  And therefore, we get a photoelectric current.  ", "OK so so far, so good.  But what was special about this experiment?  The first step that was special was that there  was a critical frequency. ", "If you would take a sample and you would irradiate it  with light, and you would begin with light  with very low frequency, nothing would happen. ", "And all of a sudden after a certain frequency, boom.  You would get a current.  So there is a threshold frequency, nu0, ", "such that only for Nu greater than nu0 there is a current.  ", "So no current for lower frequencies.  Now as it turned out, nu0 depends on the metal  you're irradiating. ", "And even more, it's a complicated thing to calculate.  It depends on the surface of the metal,  so that's why Hertz apparently had to polish the metal. ", "And this frequency, if the metal is irregular,  may depend on where you shine.  So you'd better prepare the metal very nicely. ", "And it may even depend on the crystalline nature  of the metal, because it's a many body effect.  You see, anticipating the resolution, ", "there is this piece of metal and there are a few free electrons  running around.  And they run around among the crystalline structure  of the metal.  And removing them, it's going to take some energy, ", "and that energy depends on the metal and the arrangement  and all kinds of things.  So this nu0 depends on the metal and the configuration ", "of atoms at the surface.  ", "Third property was kind of interesting.  The magnitude of the current was proportional ", "to the intensity of the light.  Magnitude current is proportional ", "to the light intensity.  ", "And perhaps the last one and fourth, a rather important one,  a very crucial property, is that you ", "could observe the energy of the photo electrons,  and it seemed to be independent of the light intensity.  So energy of the photo electrons is ", "independent of the intensity of light ", "The number of photo electrons would  depend on the intensity of light,  but not the energy of the photo electrons.  Now there is more to that, but I think it was not ", "quite exactly noticed by Hertz.  So Hertz probably didn't notice all these things.  But the last one, that maybe we can put in brackets here, ", "is that the energy of the photo electrons E gamma--  oh, no-- E of the electrons increases linearly ", "with the frequency of the light.  ", "So this photoelectric effect was not  easy to understand if you thought of light as a wave. ", "And Einstein came up with an answer  that he almost said what was going on,  but didn't quite use the word.  He said that light comes in bundles of energy. ", "And in a beam, you have bundles of energy quanta.  Didn't quite say light is a particle.  He himself was a little non-committal, I think, ", "about this concept.  But Einstein, in 1905, gives the natural explanation ", "and says that light is composed of quanta.  ", "He would have to wait until 1920s  until the name photons came up, given by a chemist, Lewis.  ", "So he called them quanta.  These are later photons, and I will use the name photons  from the beginning.  With energy, E equal h nu, where nu is the frequency and h ", "was Planck's constant.  Planck had already introduced the constant  in trying to fit the black body spectrum. ", "The black body spectrum, the intensity of light  is a function of frequency in black body radiation,  had a particular curve.  Planck tried to fit it and he realized he needed one constant ", "and he called it h.  That's Planck's constant.  And the same constant that Planck introduced,  reappeared in Einstein's proposition. ", "This is Planck's constant.   So the picture that Einstein and others had ", "was that you would have kind of a potential  here and plot energy over here, and maybe this ", "is some distance.  And you have a metal and there is the electrons captured here.  And here is zero energy.  So they have negative energy, they're captured. ", "And you need some amount of energy, w,  which is called the work function, that depends  on the type of metal you have. ", "And if you could supply that energy, w,  to any one of these electrons that are bound in this metal, ", "they would come out and not be attracted any more  and would be able to fly free.   So it is like an escape velocity, ", "you're bound by the gravity of earth.  You need something velocity, some energy to shoot you out.  Same thing here.  So this w, or work function, is defined as the energy needed ", "to release an electron.   And that work function is that thing ", "that depends on the metal you have and the structure  and how well you've polished the surface.  So if this is true, then Einstein, ", "if he was right with this property,  there would be the following statement that you could make.  The energy of the electron, which is, roughly speaking, ", "one half mv squared, would be equal to the energy  that the photon [INAUDIBLE], minus the work function. ", "So you supply a photon.  Some of the energy goes into the work function,  but the rest of the energy goes into giving free energy ", "to these electrons.  So you have the energy of the photon  minus w, which is what you need to just take it out  with 0 velocity. ", "And then the rest of the energy of the photon  would be transmitted as kinetic energy of the electron. ", "So if this is true, this would be h nu minus omega.  And this was considered a prediction, ", "because that statement that the energy of the electron  increases linearly with the frequency,  was not quite obvious to people. ", "Experiments were not fine enough.  Measuring the energy of the emitted particles  was not all that easy either.  So this was Einstein's prediction. ", "", "And the experimental confirmation  took 10 years to come.  It was verified by Millikan in 1915. ", "So Millikan, in 1915, measures the energy of the photo ", "electrons, verifies Einstein's conjecture, ", "and actually produces, by measuring so carefully  the energy of the photo electrons, produces  a measurement of h, which is the best to that point. ", "And h is measured to better than 1%, ", "so a very accurate measurement of h.  And perhaps you would say, OK, so this is all wonderful,  now everybody believes in photons. ", "But that's quite far from the truth.  They didn't believe in photons too much,  because Maxwell had been too successful. ", "And Einstein himself knew that once you started believing  in particles like photons, you had  this subject with this case of loss of determinism and waves ", "that we have sometimes as particles and things  he didn't like much.  So people were quite reluctant to believe in these things. ", "It's quite amazing.  So it took a while still.  So let's do a simple exercise to introduce some numbers here, ", "and show you how to do some very simple computation.  So let me do an example.  ", "You shine UV light with lambda 290 nanometers on a metal ", "with work function 4.05 EV.  What is the energy, E of the photo electrons, ", "and what is their speed?   Now it is a goal of mine, and of the instructors in this course, ", "that a calculation like that, you should  be able to do without turning on your iPhone  and checking what the h bar is, and getting a few constants, ", "and what is an EV or all these things.  Well nowadays, you can just check Wolfram Alpha  and they will give you the answer  for this, in beautiful, beautiful calculations. ", "Just copy the question like that,  pretty much, I think it will answer it for you.  But you should be able to do back  of the envelope calculations, in which you estimate things ", "quickly.  And with one significant digit, you don't even  need a calculator to do this.  So let's see how one does this thing.  So the first thing to do is to figure out what ", "is the energy of this photon.  That's the first problem.  So the energy of a photon is h nu.  ", "But nu it's not lambda.  So nu time lambda is c, so this is hc over lambda,  where c is the speed of light. ", "OK, hc lambda, we could do it if we knew h.  I must say, I never remember what h is in normal units. ", "Joule seconds, six point something,  I don't quite remember it.  So what do I do?  I use h bar, which is h over 2 pi. ", "So h is 2 pi h bar c over lambda.  And here is where you--  here is the first thing that maybe you ", "want to remember by heart.  h bar c is a pretty nice number, it's  about 200mev times a fermi, If you want it more precise, ", "it's 197.33, if you want to get five digits,  but it's pretty close to 200 mev fermi.  And what is a fermi? ", "It's 10 to the minus 15 meters.  OK, so with this number, I claim you can do  pretty much all you want to do. ", "So here you have 2pi times 200 mev times  10 to the minus 15 meters divided-- ", "I'll put 197 here--   divided by lambda, which is 290 nanometers, which ", "is 10 to the minus 9 meters.   So 10 to the minus 9 and 10 to the minus 15  is 10 to the minus 6 up. ", "And this is a million ev, which is 10 to 6 ev.  So all these meters cancel and there's just an ev left. ", "So this is 2 pi times 197 over 290 ev.  And you certainly could estimate this like 2 over 3 times 2 pi, ", "which is 6.  And that's about four.  And if you want to do it more carefully,  it comes out to 4.28 ev. ", "And the nice thing is that the answer comes in ev's.  And the work functions, everybody  gives them in ev's, so it's a convenient thing. ", "So at this moment, you have this electron energy  of the photon being this.  So energy of the electron is energy ", "of the photon minus the work function, which is 428  minus 405 ev, and it's 0.23 ev. ", "That's a kinetic energy and that should  be a non-relativistic electron because the rest  mass of an electron is about half a million ev. ", "It is 511,000 ev.  So this is fairly non-relativistic, but how slow  is it?  Is it moving a centimeter per second? ", "No, it's moving pretty fast.  You can write this as one half mv squared.  And then what do you do? ", "You put one half m of the electron c  squared v squared over c squared.  And this is one half of 511,000 ev times v over c squared. ", "So do the arithmetic, it's 20.46 over that, square root  and multiply it by the speed of light.  You can do this roughly in your head. ", "And the velocity comes out to 284 kilometers per second,  BARTON ZWIEBACH: Now that we've introduce h, ", "h is a very important quantity in quantum mechanics.  So let's talk a little more about h, its units,  and we already put one number that I really ", "wish you will remember.  Now let's talk about the units of h  and some other things you can do with h.  So units of h. ", " So if you have a quantity that appears for the first time  and as it appears here, E equal h nu, ", "this is a good place to understand the units of h  because the units of h would be units of energy  divided by units of frequency. ", "And I put this square brackets to denote units.  Now what are the units of energy?  We're going to work with units that are characterized ", "by M, L and T--  mass, length, and time.  So energy, you think kinetic energy and you say, MV squared, ", "so that's a mass and velocity squared  is L squared over T squared.  So that's units of energy. ", "Frequency is cycles per unit time.  Cycles have a number of units, so it's 1 over time here.  So then you say that it's ML squared over T. ", "So that's the first answer and that's  a nice answer, although it's never  quite that useful in this way, so we try to rearrange it. ", "And I will rearrange it the following way to think--  you see, it's nice to think of what physical quantity that we  are familiar, hats units of h-bar. ", "We know these units of h-bar are energy over frequency,  but that's not a single physical quantity, so let's look at it  and separate this as L times MLT. That's the same thing. ", "And then I see an interesting thing--  this is the units of position, or length.  Length or radius. ", "Distance.  And this has the units of momentum p.  Momentum.  ", "So this product has the units of angular momentum.  ", "And perhaps that's the most important quantity  that has the units of h-bar.  It's something that you should remember.  Of h-bar has units of angular momentum, ", "that's why when people talk about a particle of spin 1/2,  they say the angular momentum is 1/2 of h-bar, ", "and that has the right units.  So spin 1/2 particle--  1/2 particle-- means that the magnitude ", "of the intrinsic angular momentum is 1/2 of h-bar.  h or h-bar have the same units, they just differ by a 2 pi ", "that--  unfortunately, we have to be careful about that 2 pi,  it affects numbers and some formulas  are nicer without the bar, some formulas are less nice. ", "So OK.  So another thing that you could say  is that this h allows you to construct ", "all kinds of new quantities.  And that's a nice thing to do.  Whenever you have a new constant of nature that comes up,  and we have the speed of light, Planck's constant, ", "Newton's constant-- seem to be the three fundamental units  of nature--  you can do some things.  And you can look at this quantity-- ", "h is proportional to rp and get an inspiration.  So you can think h has units of r times p. ", "And you can say, look--  if I have any particle with mass M,  I can now associate a length to it. ", "I can invent a length associated to that particle.  And how do I do it?  Well, this has units of length, so all I have to do ", "is take h and divide by p.   Well, that will be one way to get the length ", "where p is the momentum, and it will be called the de Broglie  wavelength.  But there is another way.  Suppose this particle is just not moving  and you have the momentum and you say, wow, ", "momentum is not moving, so what's going on here?  So think of it at rest and then you say,  well, you still can construct a length. ", "You can put h and divide by the mass times the velocity  of light, why not?  That's a velocity, it is a constant of nature. ", "So that way, you associate a length  to any particle of a given mass. ", "You don't have to tell me what is the momentum.  You can just know the mass and it  has a length associated to it. ", "So it's called the Compton--  Compton-- wavelength of a particle. ", " And I want to make sure you don't confuse,  it's not the same as de Broglie wavelength ", "that we will see later.  It's not the same as the de Broglie wavelength.  This is the Compton wavelength of the particle.  ", "And you can say, all right, good,  you give me a particle of some mass,  I can tell you what a length associated to it-- ", "why would it be important?  It will be important in two different ways--  through an experiment and through a thought experiment,  which I want to do right now. ", "You see, I could ask the following question--  I have this particle, has a mass M. I use the speed of light, ", "so with that mass M, I could associate out to this particle  a rest energy.   MC squared.  That's the rest energy. ", "And then I could ask, what is the wavelength  of a photon that has the same energy as the rest ", "energy of this particle?  So you translate the question into a question of a length.  Once you have some energy, there is a natural length, ", "which is the wavelength of a photon with that energy.  So let's ask this question independently of what we did.  So what is the wavelength-- ", "wavelength-- of a photon whose energy is the rest mass-- ", " rest mass-- of a particle?  ", "So the rest mass is MC squared, and that's  the energy of this photon.  And we know that energy of a photon h nu or hC over lambda, ", "and there, we can calculate the lambda.  Lambda is hC over MC squared, and no surprise,  it gives us h over MC and that thing ", "is the Compton wavelength.  So it's sometimes called l-Compton  of the particle of mass M. ", "So this is a way that you can think of this particle.  You think of a particle, you have a Compton wavelength, ", "and that Compton wavelength is the wavelength of light  that has that rest energy.  And that actually has experimental implications ", "in high energy particle physics.  Because if you have an electron and it has a Compton  wavelength, and you shine a photon that has that size, ", "that photon is carrying as much energy  as the rest energy of the electron.  And in particle theory and quantum field theory,  particles can be created and destroyed, so this photon maybe ", "can do some things and create more particles out  of this electron, particle equation could start.  happening.  So it will be difficult to isolate a particle to a size ", "smaller than its Compton wavelength,  because the photons could do such damage to the particle  by creating new particles or doing other things to it. ", "So for an electron, let's calculate the Compton  wavelength.  So l-Compton of an electron would be h over MeC, ", "and you would do h--  you would do 2 pi h-bar C over and MeC squared.  ", "And you've got 2 pi 197.33 MeV fermi, ", "and here you would have 0.511 MeV.  So this gives you 2,426 fermi, or about 2.426 picometers. ", "Picometers is kind of a natural length.  Picometer is 10 to the minus 12 meters.  The Bohr radius is about 50 picometers, ", "so that's how big this thing is.  Is it still much bigger than the size of the nucleus?  The nucleus is a few fermis. ", "A single proton is about a fermi big.  And nucleus grow slowly, so you can  have a big nucleus with 200 particles maybe  of a radius of 7 or 8 fermi. ", "So this is still a lot bigger and it's   PROFESSOR: So we're building this story. ", "We had the photoelectric effect.  But at this moment, Einstein, in the same year  that he was talking about general relativity, ", "he came back to the photon.  And there there's actually a quote of Einstein's saying,  his greatest discoveries, for sure, ", "were special relativity and general relativity.  The photo-- he got the Nobel Prize  for the photoelectric effect, and he certainly helped ", "invent the quantum theory and many important things  in this subject, but in retrospect, his greatest  successes were that. ", "But he may have not quite seen it exactly that way.  He wrote, that some stage of his whole life  had been a difficult struggle against the quantum, pulsed ", "by some small happy interludes of some other discoveries.  But the quantum theory certainly made him very-- ", " well, he was very suspicious about the truth, the deep truth  of the quantum theory.  So 1916, he is busy with general relativity, ", "but then he's more ready to admit that the photon is  a particle, because he adds that the photon now has momentum ", "as well.  So it's a-- these photons that were not called photons yet  are quanta for energy. ", " But now he adds it's also for momentum.  ", "So this already characterizes particles.  You see, there is the relativistic relation, well ", "known by then, that e squared minus p squared c squared  is equal to m squared c to the fourth. ", "You might say, well, this is a little surprising.  And If you don't remember too much special relativity,  this may not quite be your favorite formula. ", "Your favorite formulas might be that the energy is mc  squared divided by 1 minus v squared over c squared. ", "And that the momentum is the ordinary momentum  again multiplied by this denominator like this. ", "But these two equations, with a little bit of algebra,  yield this equation, which summarizes something ", "about a particle, that basically if you  know the energy and the momentum of a particle,  you know its mass.  And it comes out from this.  This is the relativistic version of similar equations ", "in which you have energy one half mv squared, momentum, mv, ", "and then energy equal p squared over 2m, a very important  relation that you can check.  For out of these two comes this one. ", "And this is nonrelativistic.  ", "So for photons, we will have particles of zero mass. ", " Photons have zero mass, m of the photon equals zero, ", "and therefore e is equal to pc for a photon.   So we can look at what the photon momentum is, ", "for example photon momentum.  We can treat it as some particle and the photon momentum ", "would be e of the photon divided by c, or h  Nu of the photon divided by c. ", "And it's h over lambda of the photon of gamma.  ", "So this is a very interesting relation  between the momentum of the photon  and the wavelength of photons.  ", "So the idea that the photon is really a particle  is starting to gather evidence, but people were not  convinced about it until Compton did his work. ", "So the same Compton that we used this length over there,  he works on this problem and does the following. ", " So is Compton scattering, the name of the work.  Compton Scattering. ", " So what is Compton scattering? ", "It is x-rays shining on atoms again,  but this time, these are very energetic photons, ", "energetic x-rays.  X-rays can have anything from a hundred EV  to 100kEV, 100,000 electron volts. ", "And what are the energies, of binding energies  of electrons in atoms?  10 EV, 13 EV for hydrogen. So you're ", "talking about 100,000 EV coming in,  so it's easily going to shake electrons and release them  very easily. ", "So you're going to have almost--  even though you're shining on electrons  that are bound to atoms, it's almost  like shining light on free electrons if it's x-rays. ", "So a few things happening.  So this is photons scattering on electrons.  Scattering on electrons that are virtually free. ", "And the first thing that happens is  that there is a violation of what  was called the classical Thomson scattering, that you ", "may have started in 802.  So the reason Compton scattering did ", "the job and physicists finally admitted  the photon was a particle is that it made  it look like particle collision of a photon with an electron, ", "it could calculate and measure and treat  the photon as a particle, just like another particle like  the electron, and out came the right result.  So the classical Thomson scattering ", "was a photon as a wave.  And what does that do?  Well, you have a free electron, and here comes  an electromagnetic wave, E and B. ", "And if it's low frequency wave, low energy electron,  this electric-- the magnetic field  does very little, because this election doesn't move too fast ", "and the velocity is being small, the Lorentz force  is very small.  But the electric field shakes the electron.  And as the electron is being shaken, it's accelerating, ", "and therefore it radiates itself.  And it radiates in a pattern, so you get photons out. ", "And the pattern is the following.  I'll write the formula with this cross-section.  ", "We'll maybe not explain too much about what  this cross-section means, it could  be a nice thing for recitation.  ", "This is the formula for the Thomson cross-section  as a function of the angle between the incident  direction of the photon and the photon that emerges. ", "So you detect photons out and this is the cross-section.  What does it mean, cross-section?  Well this has units. ", "I will say, very briefly, units of area.   Area per solid angle, but solid angle has no units. ", "So if you imagine a little solid angle here  and you multiply by this cross-section,  it gives you some area that represents ", "the solid angle you're looking at to see  how many photons you get.  And the solid angle that you have multiplied here ", "to give you an area, the area should  be thought of as the area that captures from the incoming beam  the energy that is being sent into this solid angle. ", "So it represents an area, and an area represents an energy,  because if you have a beam coming in from a magnetic wave  through a little area, some energy goes in. ", "So that area that you get is that area  that extracts from the incident beam  the energy that you need to go in this solid angle direction.  So basically, this is a plot of intensity of the radiation ", "as a function of angle.  But the most important thing, not only-- this  is not quite accurate when the photon is of high energy.  The thing that is pretty wrong about this ", "is that the outgoing photon or wave has the same frequency ", "as the original wave.   So that's a property of this scattering. ", "The electron is being moved at the frequency  of the electric field, and therefore  the frequency of the radiation is the same.  And this is all classical. ", "But out comes, when you have a high energy,  this thing is not accurate, and you have a different result. ", "So what did Compton find?   Well, the first thing is a couple of observations. ", ".   Treat the photon as a particle.  ", "OK, so it has some energy and some momentum.  The electron has some energy and momentum.  You should analyze the collision using energy and momentum ", "conservation.  So before the collision, you have an incoming photon  that has some energy and some momentum, ", "and you have an electron, maybe here.  And then after a while, the electron  flies away in some direction, E minus. ", "And the photon also, a photon prime of different frequency  flies away.  It's like a collision.  ", "You can do this calculation and maybe it could even  be done in recitation.  It's a relativistic calculation.  You were asked in first homework to show that the photon can not ", "be absorbed by the electron, and that  uses the relativistic relations if you  want to show you just can't absorb it.  It's not consistent with energy and momentum conservation. ", "So it's something you can try to figure out.  The other thing that should become obvious  is that the photon is going to lose some energy, ", "because as it hits the electron, it gives the electron a kick.  The electron now has kinetic energy.  Think of this in the lab.  The electron was static, the photon was coming. ", "After a while, the electron has moved,  it's moving now with some velocity.  The photon must have lost some energy.  So photon loses energy. ", " And therefore, the final lambda must be bigger  than the initial lambda. ", "Remember the shorter the wavelength, the more energetic  the photon is.  So what is the difference? ", "That's the result of a calculation.  It's a nice calculation, all of you should do it.  It's probably in some book, in many books.  And it's a nice exercise also for recitation. ", "Lambda final minus lambda initial.   Or I'll write it differently.  Lambda final is equal to lambda initial plus something ", "that depends on the angle theta, in fact, has a one  minus cosine theta dependence.  But here has to be something with units of length ", "And the only party you have here is the electron.   And this electron has some length, ", "which is the quantum wavelength, which  is very natural for a Compton scattering problem, of course.  And it's here, h over mec. ", "So the l Compton of the electron.  And that's the correct formula for the loss of energy, ", "or change in frequency.  So the most you can get is if you don't interact when theta ", "is equal to zero, the photon keeps going,  doesn't even kick the electron.  And then you get zero, the initial lambda  is equal to the final lambda. ", "But this can be as large as two, for totally backwords photon  emitted.  So theta equals pi, cosine pi is minus 1, you get 2. ", "At 90 degrees, you get the Compton shift.  So it's a very nice thing, you even  know already what's happening here. ", "So let's describe the experiment itself, of how it was done.  ", "So he used, Compton, the experiment ", "have a source of molybdenum x-rays ", "that have lambda equals 0.0709 nanometers.  So smaller than nanometers, it's 70 picometers. ", "And that corresponds to e photon--  that's pretty small, so it must be high energy--  and it's 17.49 kEV. ", "That's very big energy.  And there was a carbon foil here.  ", "And you send the photons in this direction.  And they were observed at several degrees,  but in particular, I'll show you a plot ", "of how it looked for theta equal 90 degrees, so detector.  ", "So source comes in, carbon is there, and what do you get?  You get the following plot.   Intensity-- so you plot the intensity of the photons ", "that you detect, as a function of the wavelength  of the photons that you get, because there's ", "supposed to be a wavelength, a shift of wavelength.  So it's actually quite revealing,  because you get something like this. ", "A bump and a bigger bump here.  Something like that.  Pretty surprising, I think, to first approximation. ", "And here is about--  the first bump happens to have about the same wavelength ", "as the incoming radiation, 0.0709.  I should write it a little more to the left.  0.0709 nanometers over here. ", "And then there is another peak at lambda f,  about 0.0731 nanometers. ", "And the question is, what is the interpretation?  Why are there two peaks and what's going on?  Anybody has any idea? ", "Let me ask a simpler question.  Which is the lambda that corresponds  to the prediction of the fact that the wavelength must ", "change, the smaller one or the bigger one?   The bigger one.  You certainly should loose energy, so the lambda ", "f, the thing we were expecting to see, presumably that thing,  because we were expecting to see that at 90 degrees,  the photons have this thing. ", "So we seem to observe this one.  And let's look at it in a little more detail.  You have this 0.0731 nanometers and you have the original light ", "was at 0.0709 nanometers.  So the difference is 0.0022 nanometers, ", "which is 10 to the minus 9, but it's exactly, or pretty close,  to this thing, because a picometer is ", "10 to the minus 3 nanometers.  So this is 0.0024 nanometers.  So this is pretty nice. ", "Look, at 90 degrees, cosine theta is zero.  So the difference between initial and final wavelengths  should be equal to the Compton wavelength ", "with about 0.0024 nanometers.  And that's about it pretty close.  So this peak is all right. ", "Should've been there.  The other peak, why is it there?  PROFESSOR: This is Louis-- ", "L-O-U-I-S d-e Broglie.  And this is not hyphenated nor together. ", "They are separate.  And the d is not capitalized apparently too.  And it's 1924, the photon as a particle is clear, ", "and the photon is also a wave.  And Louis de Broglie basically had a great insight  in which he said that if this is supposed ", "to be a universal or a real basic physical property  that photons are waves and particles, ", "we knew them as waves and now we know they're particles.  But if they are dualed with respect to each other,  both descriptions are in different regimes ", "and in a sense, a particle at the end of the day  has wave attributes and particle attributes.  Wave attributes because it interferes  and is described by waves. ", "And particle attributes is because it has a definite  amount of energy, it comes in packets,  they cannot be broken into other things--  this could be a more general property. ", "And in a sense, you could say that de Broglie did  a fundamental step almost as important as Schrodinger ", "when he claimed that all matter particles behave as waves as  well.  Not just the photon, that's one example, but everybody does. ", "So associated to every modern particle, there is a wave.  But that is quite interesting because in quantum mechanics, ", "you have the photon and it's a particle,  but it's associated to a wave and if you are a little quick,  you say, oh sure, the electromagnetic wave, ", "but no, in quantum mechanics, it's  the probability amplitude to be some work.  Those are the numbers we tracked in the mass  and the interferometer, the probability to be sampled. ", "We didn't track the waves or a single photon,  the wave was a wave of probability amplitude,  something they didn't know at all about yet at that time. ", "So de Broglie's says just like the photons have properties  of particles and properties of waves, ", "every particle has properties of waves as well  and every wave has a property of particles.  But what is left unsaid here is yes, you have a wave, ", "but a wave of what?  And we've already told you a little bit,  the answer has to do with probability waves.  So it's very strange that the fundamental equation ", "for a wave that represents a particle is not  an electric field or a sound wave or this,  it's for all of them is a probability wave. ", "Very, very surprising.  But that's what de Broglie's ideas led to.  So if you had a photon, you would say it's a particle, ", "and when you think of it as a particle,  you would say it's a bundle of some energy and some momentum.  And if you think of it as a wave, ", "you would say it has a frequency.   And that's a particle wave duality or in some sense, ", "a particle wave description of this  object-- you have a particle and a wave at the same time.  When we have this, we have a particle wave duality. ", "And de Broglie said that this is universal for all particles.  Universal.  And it appeared the name of matter waves. ", " These are the matter waves that we're going to try to discuss.  These are the waves of something that  are probability amplitudes we're going to try to discuss. ", "So you could say wave of what?   What.  And that comes later, but the answer ", "is probability amplitudes, those complex numbers whose squares  are probabilities. ", "So just like we had for a photon,  de Broglie's idea was that we would associate to a particle ", "a wave that depends on the momentum.  So remember, the Compton wavelength  was a universal-- for any particle,  the Compton wavelength is just one number, ", "but just for photons, the wavelength depends  on the momentum, so in general, it should  be dependent on the momentum.  So we say that for a particle of momentum p, ", "we associate a wave--  a plane wave, in fact--  a plane wave, so we're getting a little more technical, ", "with of lambda equals h over p, which  is the de Broglie wavelength--  de Broglie wavelength. ", " So it's a pretty daring statement. ", "It was his PhD thesis and there was no experimental evidence  for it.  It was a very natural conjecture-- ", "we'll discuss it a lot more next lecture--  but there are very little evidence for it.  So experiments can a few years later, ", "and people saw that you could interfere or diffract  electrons. ", "They would behave, colliding into lattices like waves,  and those are rather famous experiments  of Davisson and Germer. ", "So particles, just like you do as an interference effect--  a two slit interference effect in which  you have a screen, a slit and a screen, and you shine photons ", "and then you get an interference effect over here  because of the wave nature of photons,  or in quantum mechanics, you would ", "say, because there are probability amplitudes, that  are complex numbers that have to be interfered  between the possibilities of the two paths,  because every photon goes through both paths ", "at the same time, these experiments of interference,  or two slit interference, were done for electrons. ", "And then, eventually, they've been  done for bigger and bigger particles,  so that it's not just something that you do  with elementary particles now. ", "There's experiments done about three years ago--  I will put on the web site or on the notes some of these things ", "so that you can see them, but now  you can throw in molecules here, molecules  that have a weight of now 10,000 atomic mass units, like 10,000 ", "protons, like hundreds of--  430 atom molecules, and you can get an interference pattern,  so it's pretty ridiculous. ", "It's almost like, you one day so you throw a baseball  and you're going to see an interference pattern,  but, you know, we've got to things  with about 10,000 hydrogen atoms and de Broglie ", "wavelengths of 1 picometer, which are pretty unbelievable.  So the experiments are done with those particles and in fact ", "with electrons.  People do those experiments and they're  in very beautiful movies in which you  see those electrons hitting on the screen and then-- ", "I'll give you some links so you can find them as well--  and you see one electron falls here  and it gets detected and two electrons, three electrons,  four electrons, five electrons, six electrons-- by the time ", "you get 10,000 electrons, you see lots of electrons  here, very well here, lots of electrons  here, and the whole interference pattern is created ", "by sending one electron at that time in an experiment that  takes several hours and it's reduced  to a movie of about one minute.  So particles, big particles interfere, not just photons ", "interfere.  So those particles have some waves,  some matter waves discovered by de Broglie, and next lecture,  we're going to track the story from de ", "Broglie to the Schrodinger equation  where the nature of the wave suddenly becomes clear. "], "vid_duration": [12.38, 13.62, 12.65, 13.14, 12.44, 12.45, 10.83, 16.79, 28.14, 12.96, 13.54, 12.48, 11.31, 23.08, 14.24, 10.41, 12.39, 11.46, 12.49, 13.91, 26.55, 12.24, 12.16, 20.1, 12.15, 10.42, 18.43, 16.22, 14.16, 13.14, 20.1, 16.38, 10.87, 15.74, 12.1, 11.87, 10.11, 11.46, 25.84, 10.89, 13.17, 12.01, 14.81, 11.16, 12.87, 11.49, 10.2, 10.95, 23.87, 10.57, 12.83, 18.71, 12.82, 11.1, 10.56, 10.85, 10.9, 11.61, 12.57, 10.29, 11.34, 10.46, 14.68, 14.61, 14.29, 11.31, 11.18, 12.13, 10.14, 12.79, 11.11, 15.57, 19.31, 15.82, 13.859, 12.019, 12.162, 12.96, 11.22, 11.88, 11.7, 15.14, 12.14, 17.55, 12.87, 10.2, 13.53, 10.26, 13.0, 10.23, 14.5, 10.61, 11.32, 11.51, 22.26, 14.53, 11.17, 10.77, 23.07, 11.82, 12.274, 15.03, 12.2, 11.82, 13.651, 11.099, 10.131, 11.46, 16.53, 14.379, 13.041, 19.37, 12.559, 12.641, 10.42, 13.64, 12.98, 12.289, 10.951, 13.359, 13.631, 13.65, 12.36, 11.46, 12.079, 10.741, 11.12, 12.54, 12.55, 10.829, 11.151, 10.21, 10.98, 14.54, 13.629, 11.53, 13.631, 11.0, 10.619, 10.171, 11.4, 13.609, 11.615, 11.135, 15.371, 15.409, 10.741, 10.75, 11.4, 14.52, 14.52, 14.22, 12.31, 12.38, 12.239, 12.12, 24.181, 10.3, 12.019, 13.081, 10.144, 10.62, 13.44, 10.26, 10.38, 14.73, 10.14, 14.58, 11.01, 11.61, 10.94, 10.6, 10.13, 10.74, 10.35, 11.16, 10.32, 14.34, 10.65, 12.9, 11.09, 11.455, 10.195, 13.46, 13.1, 10.59, 10.32, 10.24, 14.35, 13.18, 12.34, 10.6, 12.53, 11.15, 10.44, 11.11, 11.81, 27.02, 18.72, 11.22, 10.59, 14.43, 12.72, 10.38, 13.35, 10.95, 10.44, 11.85, 14.05, 13.14, 12.54, 10.25, 11.04, 12.96, 10.67, 14.86, 10.86, 14.31, 13.3, 11.23, 10.53, 12.537, 15.913, 10.55, 12.0, 11.17, 12.54, 16.47, 12.82, 10.16, 11.08, 11.01, 11.0, 10.21, 14.06, 13.7, 14.6, 11.3, 12.17, 10.6, 13.14, 11.1, 12.93, 10.62, 20.97, 11.879, 12.971, 15.9, 11.25, 13.57, 11.25, 11.27, 14.43, 10.02, 10.47, 10.62, 11.56, 19.5, 19.26, 13.15, 12.69, 10.02, 11.16, 15.87, 21.46, 11.2, 10.11, 11.97, 11.76, 11.05, 12.05, 18.56, 13.56, 10.53, 12.08, 12.88, 13.77, 10.74, 12.6, 13.58, 10.2, 12.9, 15.23, 10.86, 14.33, 11.83, 12.14, 14.0, 10.75, 11.14, 12.73, 13.925, 12.715, 10.01, 10.29, 10.65, 12.45, 19.71, 11.17, 13.576, 13.334, 10.48, 14.1, 10.17, 11.01, 13.98, 11.16, 13.44, 12.76, 10.31, 12.45, 14.16, 10.6, 12.44, 10.92, 13.2, 12.81, 10.89, 15.36, 11.31, 5.521], "stet": [[0, 12.38], [12.38, 26.0], [26.0, 38.65], [38.65, 51.79], [51.79, 64.23], [64.23, 76.68], [76.68, 87.51], [87.51, 104.30000000000001], [104.30000000000001, 132.44], [132.44, 145.4], [145.4, 158.94], [158.94, 171.42], [171.42, 182.73], [182.73, 205.81], [205.81, 220.05], [220.05, 230.46], [230.46, 242.85000000000002], [242.85000000000002, 254.31000000000003], [254.31000000000003, 266.8], [266.8, 280.71000000000004], [280.71000000000004, 307.26000000000005], [307.26000000000005, 319.50000000000006], [319.50000000000006, 331.6600000000001], [331.6600000000001, 351.7600000000001], [351.7600000000001, 363.9100000000001], [363.9100000000001, 374.3300000000001], [374.3300000000001, 392.7600000000001], [392.7600000000001, 408.98000000000013], [408.98000000000013, 423.14000000000016], [423.14000000000016, 436.28000000000014], [436.28000000000014, 456.38000000000017], [456.38000000000017, 472.76000000000016], [472.76000000000016, 483.63000000000017], [483.63000000000017, 499.3700000000002], [499.3700000000002, 511.4700000000002], [511.4700000000002, 523.3400000000001], [523.3400000000001, 533.4500000000002], [533.4500000000002, 544.9100000000002], [544.9100000000002, 570.7500000000002], [570.7500000000002, 581.6400000000002], [581.6400000000002, 594.8100000000002], [594.8100000000002, 606.8200000000002], [606.8200000000002, 621.6300000000001], [621.6300000000001, 632.7900000000001], [632.7900000000001, 645.6600000000001], [645.6600000000001, 657.1500000000001], [657.1500000000001, 667.3500000000001], [667.3500000000001, 678.3000000000002], [678.3000000000002, 702.1700000000002], [702.1700000000002, 712.7400000000002], [712.7400000000002, 725.5700000000003], [725.5700000000003, 744.2800000000003], [744.2800000000003, 757.1000000000004], [757.1000000000004, 768.2000000000004], [768.2000000000004, 778.7600000000003], [778.7600000000003, 789.6100000000004], [789.6100000000004, 800.5100000000003], [800.5100000000003, 812.1200000000003], [812.1200000000003, 824.6900000000004], [824.6900000000004, 834.9800000000004], [834.9800000000004, 846.3200000000004], [846.3200000000004, 856.7800000000004], [856.7800000000004, 871.4600000000004], [871.4600000000004, 886.0700000000004], [886.0700000000004, 900.3600000000004], [900.3600000000004, 911.6700000000003], [911.6700000000003, 922.8500000000003], [922.8500000000003, 934.9800000000002], [934.9800000000002, 945.1200000000002], [945.1200000000002, 957.9100000000002], [957.9100000000002, 969.0200000000002], [969.0200000000002, 984.5900000000003], [984.5900000000003, 1003.9000000000002], [1003.9000000000002, 1019.7200000000003], [1019.7200000000003, 1033.5790000000002], [1033.5790000000002, 1045.5980000000002], [1045.5980000000002, 1057.7600000000002], [1057.7600000000002, 1070.7200000000003], [1070.7200000000003, 1081.9400000000003], [1081.9400000000003, 1093.8200000000004], [1093.8200000000004, 1105.5200000000004], [1105.5200000000004, 1120.6600000000005], [1120.6600000000005, 1132.8000000000006], [1132.8000000000006, 1150.3500000000006], [1150.3500000000006, 1163.2200000000005], [1163.2200000000005, 1173.4200000000005], [1173.4200000000005, 1186.9500000000005], [1186.9500000000005, 1197.2100000000005], [1197.2100000000005, 1210.2100000000005], [1210.2100000000005, 1220.4400000000005], [1220.4400000000005, 1234.9400000000005], [1234.9400000000005, 1245.5500000000004], [1245.5500000000004, 1256.8700000000003], [1256.8700000000003, 1268.3800000000003], [1268.3800000000003, 1290.6400000000003], [1290.6400000000003, 1305.1700000000003], [1305.1700000000003, 1316.3400000000004], [1316.3400000000004, 1327.1100000000004], [1327.1100000000004, 1350.1800000000003], [1350.1800000000003, 1362.0000000000002], [1362.0000000000002, 1374.2740000000001], [1374.2740000000001, 1389.304], [1389.304, 1401.5040000000001], [1401.5040000000001, 1413.324], [1413.324, 1426.9750000000001], [1426.9750000000001, 1438.074], [1438.074, 1448.2050000000002], [1448.2050000000002, 1459.6650000000002], [1459.6650000000002, 1476.1950000000002], [1476.1950000000002, 1490.574], [1490.574, 1503.615], [1503.615, 1522.985], [1522.985, 1535.5439999999999], [1535.5439999999999, 1548.185], [1548.185, 1558.605], [1558.605, 1572.2450000000001], [1572.2450000000001, 1585.2250000000001], [1585.2250000000001, 1597.5140000000001], [1597.5140000000001, 1608.4650000000001], [1608.4650000000001, 1621.824], [1621.824, 1635.4550000000002], [1635.4550000000002, 1649.1050000000002], [1649.1050000000002, 1661.4650000000001], [1661.4650000000001, 1672.9250000000002], [1672.9250000000002, 1685.0040000000001], [1685.0040000000001, 1695.7450000000001], [1695.7450000000001, 1706.865], [1706.865, 1719.405], [1719.405, 1731.955], [1731.955, 1742.7839999999999], [1742.7839999999999, 1753.935], [1753.935, 1764.145], [1764.145, 1775.125], [1775.125, 1789.665], [1789.665, 1803.2939999999999], [1803.2939999999999, 1814.8239999999998], [1814.8239999999998, 1828.455], [1828.455, 1839.455], [1839.455, 1850.0739999999998], [1850.0739999999998, 1860.245], [1860.245, 1871.645], [1871.645, 1885.254], [1885.254, 1896.869], [1896.869, 1908.004], [1908.004, 1923.375], [1923.375, 1938.784], [1938.784, 1949.525], [1949.525, 1960.275], [1960.275, 1971.6750000000002], [1971.6750000000002, 1986.1950000000002], [1986.1950000000002, 2000.7150000000001], [2000.7150000000001, 2014.9350000000002], [2014.9350000000002, 2027.2450000000001], [2027.2450000000001, 2039.6250000000002], [2039.6250000000002, 2051.864], [2051.864, 2063.984], [2063.984, 2088.165], [2088.165, 2098.465], [2098.465, 2110.484], [2110.484, 2123.565], [2123.565, 2133.709], [2133.709, 2144.3289999999997], [2144.3289999999997, 2157.769], [2157.769, 2168.029], [2168.029, 2178.409], [2178.409, 2193.139], [2193.139, 2203.279], [2203.279, 2217.859], [2217.859, 2228.869], [2228.869, 2240.4790000000003], [2240.4790000000003, 2251.4190000000003], [2251.4190000000003, 2262.0190000000002], [2262.0190000000002, 2272.1490000000003], [2272.1490000000003, 2282.889], [2282.889, 2293.239], [2293.239, 2304.399], [2304.399, 2314.719], [2314.719, 2329.059], [2329.059, 2339.7090000000003], [2339.7090000000003, 2352.6090000000004], [2352.6090000000004, 2363.6990000000005], [2363.6990000000005, 2375.1540000000005], [2375.1540000000005, 2385.3490000000006], [2385.3490000000006, 2398.8090000000007], [2398.8090000000007, 2411.9090000000006], [2411.9090000000006, 2422.4990000000007], [2422.4990000000007, 2432.819000000001], [2432.819000000001, 2443.0590000000007], [2443.0590000000007, 2457.4090000000006], [2457.4090000000006, 2470.5890000000004], [2470.5890000000004, 2482.9290000000005], [2482.9290000000005, 2493.5290000000005], [2493.5290000000005, 2506.0590000000007], [2506.0590000000007, 2517.2090000000007], [2517.2090000000007, 2527.649000000001], [2527.649000000001, 2538.759000000001], [2538.759000000001, 2550.569000000001], [2550.569000000001, 2577.589000000001], [2577.589000000001, 2596.3090000000007], [2596.3090000000007, 2607.5290000000005], [2607.5290000000005, 2618.1190000000006], [2618.1190000000006, 2632.5490000000004], [2632.5490000000004, 2645.2690000000002], [2645.2690000000002, 2655.6490000000003], [2655.6490000000003, 2668.9990000000003], [2668.9990000000003, 2679.949], [2679.949, 2690.389], [2690.389, 2702.239], [2702.239, 2716.289], [2716.289, 2729.429], [2729.429, 2741.969], [2741.969, 2752.219], [2752.219, 2763.259], [2763.259, 2776.219], [2776.219, 2786.889], [2786.889, 2801.7490000000003], [2801.7490000000003, 2812.6090000000004], [2812.6090000000004, 2826.9190000000003], [2826.9190000000003, 2840.2190000000005], [2840.2190000000005, 2851.4490000000005], [2851.4490000000005, 2861.9790000000007], [2861.9790000000007, 2874.5160000000005], [2874.5160000000005, 2890.4290000000005], [2890.4290000000005, 2900.9790000000007], [2900.9790000000007, 2912.9790000000007], [2912.9790000000007, 2924.149000000001], [2924.149000000001, 2936.6890000000008], [2936.6890000000008, 2953.1590000000006], [2953.1590000000006, 2965.9790000000007], [2965.9790000000007, 2976.1390000000006], [2976.1390000000006, 2987.2190000000005], [2987.2190000000005, 2998.2290000000007], [2998.2290000000007, 3009.2290000000007], [3009.2290000000007, 3019.4390000000008], [3019.4390000000008, 3033.4990000000007], [3033.4990000000007, 3047.1990000000005], [3047.1990000000005, 3061.7990000000004], [3061.7990000000004, 3073.0990000000006], [3073.0990000000006, 3085.2690000000007], [3085.2690000000007, 3095.8690000000006], [3095.8690000000006, 3109.0090000000005], [3109.0090000000005, 3120.1090000000004], [3120.1090000000004, 3133.039], [3133.039, 3143.659], [3143.659, 3164.629], [3164.629, 3176.508], [3176.508, 3189.479], [3189.479, 3205.379], [3205.379, 3216.629], [3216.629, 3230.199], [3230.199, 3241.449], [3241.449, 3252.719], [3252.719, 3267.149], [3267.149, 3277.169], [3277.169, 3287.6389999999997], [3287.6389999999997, 3298.2589999999996], [3298.2589999999996, 3309.8189999999995], [3309.8189999999995, 3329.3189999999995], [3329.3189999999995, 3348.5789999999997], [3348.5789999999997, 3361.729], [3361.729, 3374.419], [3374.419, 3384.439], [3384.439, 3395.5989999999997], [3395.5989999999997, 3411.4689999999996], [3411.4689999999996, 3432.9289999999996], [3432.9289999999996, 3444.1289999999995], [3444.1289999999995, 3454.2389999999996], [3454.2389999999996, 3466.2089999999994], [3466.2089999999994, 3477.9689999999996], [3477.9689999999996, 3489.019], [3489.019, 3501.069], [3501.069, 3519.629], [3519.629, 3533.189], [3533.189, 3543.719], [3543.719, 3555.799], [3555.799, 3568.679], [3568.679, 3582.449], [3582.449, 3593.189], [3593.189, 3605.7889999999998], [3605.7889999999998, 3619.3689999999997], [3619.3689999999997, 3629.5689999999995], [3629.5689999999995, 3642.4689999999996], [3642.4689999999996, 3657.6989999999996], [3657.6989999999996, 3668.5589999999997], [3668.5589999999997, 3682.8889999999997], [3682.8889999999997, 3694.7189999999996], [3694.7189999999996, 3706.8589999999995], [3706.8589999999995, 3720.8589999999995], [3720.8589999999995, 3731.6089999999995], [3731.6089999999995, 3742.7489999999993], [3742.7489999999993, 3755.4789999999994], [3755.4789999999994, 3769.4039999999995], [3769.4039999999995, 3782.1189999999997], [3782.1189999999997, 3792.129], [3792.129, 3802.419], [3802.419, 3813.069], [3813.069, 3825.519], [3825.519, 3845.229], [3845.229, 3856.399], [3856.399, 3869.975], [3869.975, 3883.3089999999997], [3883.3089999999997, 3893.7889999999998], [3893.7889999999998, 3907.8889999999997], [3907.8889999999997, 3918.0589999999997], [3918.0589999999997, 3929.069], [3929.069, 3943.049], [3943.049, 3954.209], [3954.209, 3967.649], [3967.649, 3980.409], [3980.409, 3990.719], [3990.719, 4003.169], [4003.169, 4017.3289999999997], [4017.3289999999997, 4027.9289999999996], [4027.9289999999996, 4040.3689999999997], [4040.3689999999997, 4051.2889999999998], [4051.2889999999998, 4064.4889999999996], [4064.4889999999996, 4077.2989999999995], [4077.2989999999995, 4088.1889999999994], [4088.1889999999994, 4103.548999999999], [4103.548999999999, 4114.8589999999995], [4114.8589999999995, 4120.379999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1373, 2131, 3485, 4120]}
{"example_id": "mit057@@MIT9_00SCF11_lec08_300k", "text": ["So a reminder, and I think you know this well by now that the  world out there is divided into a left and right visual  field as we look for it in the middle, that the information ", "from the left visual field goes through your brain and  ends up shown in the right primary visual cortex, from  the right visual field into your left  primary visual cortex.  But there's one other pathway we haven't talked about very ", "much which goes to a structure called the superior  colliculus.  It's part of your midbrain.  And it's the system we think gives rise to the possibility  of sensation without perception. ", "That phrase, sensation without perception, is a good one to  describe blindsight.  And we'll describe it in a moment.  So from your retina, where all vision has to go through, a  little bit of information-- ", "a small number of fibers-- go to part of your brain that  controls your pupillary reflexes, what makes your  pupils get wider or smaller to see.  90% of the fibers coming in, the fibers come from your eye ", "and go through the lateral geniculate or through the  major system that you've heard about from Melissa that  connect to your primary visual cortex.  And then, there's one other small visual pathway from your ", "retina to this superior colliculus sometimes called a  tectopulvinar system.  So it's a small pathway from your eyes in terms of the  number of nerve fibers. ", "And so people said, well, can we say what's not done by the  major visual pathway that goes from the eye to the cortex?  What's done by this other small pathway?  And one of the ways they looked at it originally all ", "the way back in 1881 was to create in dogs bilateral  occipital lesions.  So now, they're cortically blind.  They're not retinally blind.  They're cortically blind.  It's in the cortex.  And what could these animals do? ", "And they were very impressed.  Although these animals didn't recognize many things, they  could steer their way around their environment.  They wouldn't bump into things.  If you had a blindfold on or if you were retinally blind ", "and weren't given any opportunity to know your  environment, you would bump into things, right?  But these animals seemed to steer their way around things  pretty well.  And they can do some other very simple tasks even though ", "they ought to have been seeing nothing.  So this is a suggestion in animals that there's something  in the brains of primates that gives you some information  that doesn't go through your conscious cortex. ", "And then, a number of patient studies in patients with  naturally occurring injuries have really shown us, given us  a chance to experiment on them in a human and relate them to  human experience. ", "So here's a patient who had a large injury, a large bleed,  in the right visual cortex.  So because of this, this patient, this man was blind in  the left visual field. ", "This field was fine.  This field was blind.  Cortically blind.  And the way that people figure out in what way are you blind, ", "what parts of the world do you see and do you not see, is  they'll put you in front of a computer monitor.  And they'll turn on lights in various locations.  And they'll create a map like this, which shows you where ", "you respond when a light comes on and where you don't see it.  So your job, basically you just look in the middle.  And you say, push a button when a light comes on.  So you're waiting.  And a light comes on somewhere on the monitor. ", "So what this picture is showing you is that the person  could respond when the lights came on anywhere on the left  side, but never responded, never said a light came on on  the right side.  People call this perimetry. ", "It's a standard neurological test of visual difficulty.  Here's a person whose injury harms only a quadrant of their  visual field.  So they never respond when a light turns on in that quarter ", "of the world out there.  But the other three quarters, they respond to.  So that's a way of testing what do you do.  And you're not asking them anything sophisticated, just  did a light come on.  Is that OK?  So for this patient, here's the mapping. ", "This patient was fine in the right visual field.  This is one eye.  This is the other eye.  And terrible--  with a few spots a little bit better-- because lesions  occurring naturally in people are seldom perfect lesions. ", "But you can see that all this area that's dark are areas  that, when a light came on in the left visual field, this  man never responded that anything had turned on. ", "There's nothing simpler, right, than a light  turning on and off.  He did not experience anything turning on in that way in the  left half of the world.  So they noticed as they gave this test that even though he ", "was saying, I don't see anything, nothing's happening,  that when they flash something in that cortically blind  field, he would move his eyes in that direction as if  something in his mind and brain felt ", "something had happened.  Not only something happened, but roughly where it happened.  But that information was not available to  his conscious mind.  He's never pushing a button that he says he saw it.  He always says nothing. ", "I'm waiting for something to come on.  And if it comes on in his good field, he responds.  Does that make sense, OK?  But something seemed to do it.  And when they found that it was better than chance in the  left visual field, about things like if they put on a ", "bigger patch of light.  He could tell if they gave him a short line or a long line.  Now, he would never say, I see the line.  You would have to make him make a guess. ", "So when you read the papers, it's something like, I don't  see anything.  I don't see anything.  Well, you must guess.  Is it a short line or a long line?  I don't see it.  There's no basis for me to guess.  It'll be a completely random guess.  But you must guess, OK? ", "Short or long?  And then, if the lines are far enough apart in size, he's  almost 100%--  97% accurate.  If he's forced to guess but he never has the experience that ", "he sees the line, he's just forced to guess and told that  it's two lines.  Or he can judge things like, is it a circle or a cross?  Is it an x or an o?  But he can't do something like a square versus a rectangle. ", "It's very limited.  Subjectively, he always feels he sees nothing.  If he's given two choices, for some things he can make the  correct choice if he's forced to make a guess. ", "And there's other sophisticated ways, again, to  show that even though he's unconscious of anything in his  blind field, something in his mind and brain is processing  information there. ", "So here, they had a thing where he pushed a button when  a light came on.  This is his good field.  And it takes him, on average, 359 milliseconds.  Now, they do the same thing. ", "This is his good field.  But they put on at the same time a light  in his blind field.  And when they do that, his time goes up by about a tenth  of a second as if the distraction in the blind field ", "was slightly distracting him from making that button press.  So another objective way of demonstrating that some  information has been processed in the blind field even though  he never says he feels like something's happening there. ", " So here's one more patient, and the last one I'll show you  of this kind, who had the unfortunate occurrence of  having two strokes, one in the left occipital cortex and one ", "in the right occipital cortex, about 36 days apart.  So now, he was blind in both fields by the time he had had  both of his strokes.  So he was a very unlucky person. ", "Here in the dark is the missing cortex  that has died away.  ", "Now, always the problems with humans is the injuries are not  controlled and precise.  And so here's two examples, one in monkeys, an incredibly  clever experiment to get a monkey to tell you what he or ", "she is thinking about.  And then, one with infants as well, human infants.  And how do you get a monkey to talk to you about their  subjective experience?  The striking thing about blindside is the person's ", "saying, I see nothing.  I see nothing.  I see nothing, even as he walks past obstacles with  precision and carefulness.  So here, what it is, they took monkeys and made unilateral  lesions in them. ", "There's a control monkey and three where they surgically  removed, as precisely as they could, the left occipital  visual cortex and the corpus callosum that connects the  left and the right. ", "And the first task-- and I'll show you in a moment-- was to  touch a light when it comes on.  And the second half is the clever design to get the  monkey to tell you what he or she subjectively ", "feels is going on.  So here's the video they would make of the monkey.  And in one case, here's the light coming on.  So the monkeys had left removal. ", "So this is the blind side.  These bars show you how often they point correctly to a  light going on.  And under this circumstance, forced to point, forced to ", "point, here's the control animal.  And you can see that the animals who are blind in this  field do almost perfectly.  When they're forced to point, they pick almost perfectly ", "which stimulus comes on in the blind field.  Now, they add one more thing to the experiment.  They have a number of lights on the good side. ", "Here is a response that they can push to signal \"I saw  nothing.\" And if they truly saw nothing, they get the  juice reward for which they're working for. ", "But there's a light that can come on here in their bad  field on their right side.  Now, what happens?  Here's the control monkey doing perfectly well for the  lights on this side, lights on this side, and when nothing is ", "happening pushing this bar to signal  that nothing is happening.  Sometimes, no light comes on.  So now, the monkeys will have to say, \"I see nothing,\" by  pushing this big panel up here if nothing seems  to have turned on. ", "But look what happens to the monkeys with the cortical  lesions on the left.  When this light comes on, they almost never say they saw it.  They almost always push, \"I saw nothing.\" ", "When they're allowed to say \"I saw nothing\" by the response,  then even though this thing that you know they can see--  because you see here they're responding  perfectly well over here-- ", "but when allowed to consciously respond what they  see, then these black bars are all the way down.  They almost never indicate they saw something.  They almost always pick the response, \"I saw nothing.\" So ", "the monkey is telling you what his subjective experience is,  which is like the humans with the cortical lesions.  They're reporting they see nothing, even though some part  of their brain can pick it up. ", "How about in humans?  So sometimes humans, children, infants, for medical reasons  have to have hemispherectomies in the first year.  These are unfortunate infants who have severe brain ", "injuries, severe epilepsy.  And it's considered better to help them by removing an  entire hemisphere than to let them have the severity of the  epilepsy they were having.  These are rare cases in very unfortunate infants. ", "And in these infants who got this for purely medical  reasons to make their lives better, they also did an  experiment to show you something not only about, I  think, again, what happens in our conscious visual system, ", "but also how that system grows in infancy and the growth of a  conscious cortical visual system.  So here's what they did.  Infants this young-- because they're in their first year-- ", "can't even point and you can't tell them to point.  So again, you have to be clever experimentally.  And what they did is they watched where their eyes moved  and recorded that information. ", "And that was the behavior.  Sometimes, they would have a fixation.  They've always had a fixation.  You're looking in the middle.  And then, something would come on out of side or this side,  in the blind field or in the intact field. ", " And they would see how often would their eyes move to a  stimulus in their good field, which they  expected all the time.  But how often would it move to the stimulus in the blind  field, the eye movement? ", "Then, they had a competition condition where you have a dot  in the middle.  And that fixation dot would stay on while a box appeared  here or here. ", "So the only sense--  the only difference between these two is there's a dot in  the middle that can compete for what you look at.  OK?  It's not a big competition.  It's just a boring dot that stays on. ", "But there's a big consequence.  So here's how often they moved their eyes to the target in  the non-competition condition.  The dot goes on.  It goes off.  And the box comes on in your good field or your bad field. ", "And all these bars are up at the top.  And practically every trial, at eight weeks, 10 weeks, and  12 weeks of age, the infant moves his or her eyes to the  stimulus whether it's in the blind field or the good field. ", "So something in their mind and brain is letting them identify  something and moves their eyes to the good field, much like  we talked about before for the adults.  Now, in the competition condition, you can already see ", "it's not quite the same.  If there's a dot on and the box comes on their blind  field, they don't always make it to the box.  That dot is capturing their conscious cortical attention ", "and diminishing the likelihood they notice the box coming on  in the blind field.  And as the weeks pass from eight to 10 to 12, just a  month of development, look what happens.  This bar goes from a little lower, a lot lower, near zero. ", "That is, from eight to 12 weeks, what it looks like is  happening is that as the cortical system matures and  the infant's consciousness is growing in some sense, now ", "it's no longer tending to process the information in the  blind field if there's competition.  Because the growth of that consciousness in the cortex is ", "suppressing the ability of the infant to communicate with  unconscious systems or be guided by unconscious systems  in the brain.  So the cool thing is the implication of this, is all of ", "us have this collicular system in us.  It's a visual system that's been around  long through evolution.  All of us have this massive conscious geniculate, the one ", "that goes into your cortex system.  And that dominates this other system.  And so we only see it revealed in these  patients as guiding behavior.  But who knows what it really does in us? ", "Because it's quietly sitting there.  We don't have conscious access to it.  And who knows how much it's guiding our behavior?  And it's very hard to figure that out.  But it's definitely disappearing from our ", "conscious life within the first couple months of our  development.  So now, I'm going to switch to the second major disorder  we'll talk about, attention and neglect, and go through ", "anosagnosia, a spectacular version of that disorder,  something about how it's behaviorally measured, its  brain basis, and then a few more analyses.  But in the book, there's a very nice ", "chapter about these patients.  Now, patients with blindsight are extremely rare.  You have to have exactly the right kind of injury to damage  a lot of your occipital cortex. ", "And those kinds of injuries rarely occur on that scale.  Attention and neglect, what I'm about to describe to you,  if any of you become physicians or work in hospital  settings, you are guaranteed to see this a lot. ", "A lot-- it's very, very common for patients who've had things  like stroke or brain injuries of some kind or another.  And a pretty typical example is from Oliver Sacks. ", "Most of the Sacks cases are pretty rare, prosopagnosia,  pretty rare.  Neglect?  Incredibly common in the hospital ward,  in neurology service.  So here, he talks about a woman, an intelligent woman in  her 60s, massive stroke affecting deep or inner back ", "portions of her right cerebral hemisphere, good  intelligence and humor.  And what happens to her when they bring her her dessert or  coffee on her tray in the hospital?  PROFESSOR: Yeah, she complains that she's not getting enough ", "food because she's only eating food on the  right half of her plate.  The left half of the plate, it's as if it  weren't present for her. ", "When they say, \"But Mrs. S., it is right there on the  left,\" she seems not to understand what they say and  does not look to the left.  If her head is gently turned so the dessert comes into  sight in the preserved right half of her field, she says, ", "\"Oh, there it is!  It wasn't there before.\"  You understand?  It's as if the left half of the plate did not exist.  And if they swivel her head and now that left half of her  plate is in her right field, now she goes, oh my gosh! ", "Who snuck that on my plate?  Now I can finish my meal.  And it's not just that.  She also only puts on makeup on half her face looking in  the mirror, which can lead to comical impressions. ", "So she ignores the left half of her world.  And it's not just that it isn't there.  It's as if it couldn't be there.  It's as if, what are you talking about there's a left ", "half of something?  I see everything.  So we'll talk a little about this and understand more  of it coming up.  So neglect means a failure to respond or report to something  that's opposite to the lesion-- contralateral means ", "opposite to the lesion--  that can't be accounted for by simple things.  These patients don't have primary visual problems.  They understand language.  They're paying attention.  They're the ones who deny the left half of their body. ", "They dress on one side.  They eat from one side of the plate.  And they also have something that I'll show you in a  moment, the example because it comes back a couple times.  And it sounds fancy, but it's simple. ", "There's extinction to double simultaneous stimulation seen  in the late stages.  So here's what the neurologist does-- and you'll see at least  one neurologist doing this in a film clip coming up-- and ", "they do this all the time in the hospital.  They'll wiggle their fingers.  They'll try to get it in the middle of the patient.  This isn't carefully controlled, but it's done on  the bedside.  They'll wiggle one side and say, do you  see anything moving?  Or the other side, and sometimes they wiggle both. ", "And the typical response in neglect is already  fascinating.  So past the early stages of the disorder, they'll notice  the thing on the left side. ", "From their perspective, that's their neglected side.  They'll notice it on the right side.  That's their good side.  They're noticing this finger wiggling.  They're noticing that finger wiggling.  But when the physician wiggles both fingers at the same time, ", "then the patient will only notice the  one on the good side.  It's as if this is extinguished because this one  grabs your attention.  And you know they can see it by itself. ", "So it's only when it's both sides that it's extinguished.  And we'll come back to that.  It's interesting.  It's not that their mind can't see.  But when there's competition in the two fields-- which  reminds me a little bit of blindsight -- ", "then their mind can't see it.  So a strong, a fascinating and rarer piece of this, but again  not very rare, is something called anosagnosia where they ", "not only have the neglect that I just described, but they  deny any problem at all.  So typically, the patient has a big, right lesions, about 5% ", "of neglect cases.  And a very fascinating neuroscientist, you may have  read some of his stuff.  He's a very creative mind, Ramachandran at UCSD, did some ", "semi-experiments with some of these patients.  So these are patients with right sided lesions.  It says they have weakness or non-use of their left hand.  And so here's his dialogue with them. ", "Can you use your right hand?  And that patient's hand is fine.  Yes.  Can use your left hand?  Yes.  The patient can't use her left hand.  Are your hands equally strong? ", "Yes.  Can you point to my nose with your right hand?  And she does.  Her right hand is fine.  Can you point to my nose with your left hand?  The paralyzed left hand-- it's the left hand because it's a ", "right hemisphere stroke--  does not move at all.  Are you pointing to my nose?  Yes.  Can clearly see it pointing?  Yes, it's about two inches from your nose. ", "Can you clap?  Of course I can clap.  And here's what she does.  Are you clapping?  Yes, I'm clapping.  She can't move her left side.  But in every way in this patient's reports, she seems ", "to deny in a deep sense that there's any problem in her  performance or any weakness of any kind.  So he wanted to do a couple little experiments to show ", "that it's not just that they're saying, but they'll  follow all the way through.  So imagine that you had injured your left ", "arm, was in a cast.  And somebody asked you, I'm going to give you two choices.  I'm going to give you $5 to screw in a light bulb--  your left arm is in a cast now--  or $10 to tie your shoe laces. ", "Which would you take?  The light bulb, right?  Because it's going to be hard to tie your shoe laces with  one arm out of action.  This person is the same way.  She's had a stroke.  Her left arm's not functioning. ", "She should definitely take the light bulb.  She takes the shoe laces.  When the physician, Ramachandran, describes as she  sits there with one hand trying to flop the laces ", "together making no progress at all, he says finally he has to  end the exercise.  He can't take it anymore.  She'll just keep going until--  So she just doesn't process that her left side of her ", "body's not working.  And then, he does another experiment more impressive.  I can use one of these, I think.  So imagine this was a tray of cocktail glasses full of ", "water, let's say to the very brim.  Imagine there's three here and three-- six things.  You can see they're right at the top.  And you're just hoping that the person bringing it to you  doesn't spill it on you.  And the person brings it over to you, actually filled with ", "water and asks a patient to hold the tray.  OK, can I pick on you for one second?  Imagine you had only--   how would you hold the tray if one arm was ", "unavailable for you?  OK, I'm bringing this over.  You have to watch, very exciting.  There's water.  Yes, OK.  How would you had if two hands were available to you? ", "OK, thank you.  OK, right?  That's easy for you to imagine how you would hold it.  They walk over to the patient with all this stuff.  They hand it to her.  And what does the patient do?  She puts out her right hand on the right side.  And the whole thing falls over.  They're trying to demonstrate it goes all the way through. ", "This person really believes there's not a problem.  And they can be doused in water for a moment-- and I'm  sure dried appropriately--  and still deny there's any problem at all. ", "Now, one thing they can do-- and this is a weird line of  research, but there's a number of papers that show this.  And I'm not recommending you do this at home because  actually, it's worse than it sounds. ", "They take a syringe with cold water, and they put it into  the left ear, the image is here.  The patient's eye starts to move.  They get a nystagmus.  And they ask them how they feel.  And then she says, my ear is very cold. ", "But other than that, I'm fine.   But they've given her a little bit of a  shock in the left ear.  And now, he does the interesting experiment. ", "Do you feel OK?  She says her ear is cold.  Can you use your hands?  At this moment when they've done something in the left ear  that wakes up the opposite right hemisphere. ", "I can use my right arm, but not my left arm.  I want to move it, but it doesn't move.  This happens just in a moment from the cold  syringe in her ear.  Whose arm is this? holding up the paralyzed arm.  It's mine, of course. ", "Can you use it?  No, it's paralyzed-- like, what kind of doctor do I have?  It's paralyzed, of course.  Now, here's something really fun in a  Sherlock Holmesian sense.  How long has your arm been paralyzed? ", "Did it start just now?  Because what he's asking is, does she have a memory  somewhere in her mind of her entire experience, or does she  say it just started right now?  I don't know how this happened.  It's just not working.  And she says, it's been paralyzed for ", "several days now.  About 90 minutes later when they redo this, she's back to  just how she was.  So they can temporarily alleviate this by this  irrigation to the ear. ", "So this denial of the left half of your body, this denial  that you have any disorder whatsoever is a  very striking thing.  In most patients, it clears up. ", "You saw pictures of it from Melissa.  You saw movies of patients with object disorders.  Those don't clear up.  Balint's syndrome, spatial disorders--  those don't clear up.  Anosagnosia patients grow out of it. ", "Somehow, their brains recover over time.  But again, it shows you how much attention is  constructed, right?  Because they have the stuff to represent  their arm, their disease. ", "That's all in their mind and brain.  But the state they're in because of the brain injury  lets them not construct that reality.  So now, I'm going to show you measures of neglect.  This is in your list just for your notes, but sort of fun ", "just to look at the examples.  So here's a patient.  With these patients, they typically have right sided  lesions, so the neglect is to the left half of the world.  And here's a patient going to the bathroom as if all you can ", "do is make right turns instead of going this way, as if the  world weren't there, to proceed on the left.  Here's another test that happens  every day in a hospital. ", "The physician has drawn these lines and says,  cross out the lines.  It's not perfect.  The patient does that one.  But look, they cross out all these lines.  And the left half ones are mostly left uncrossed. ", "It's as if they weren't there.  Here's what's called a cancellation test.  There's lots of letters here.  And their job is to cross out all the A's.  Now, let me start with neglect.  You see over here, this whole area? ", "Nothing is circled or crossed out.  And you could say, well, what would happen if instead of  neglect, you were like one of those blindsight patients who  had a big lesion in the cortex and you were ", "blind on one side?  What would you do there?  Well, it's easy for those patients because what they do  is they don't see part of the world.  But what do they do?  They turn their head, just like you would do. ", "They turn their head.  They don't see it, but they know they don't see it.  And they turn their head.  And a patient who's blind on one side, loss in the visual  field, gets all the lines because all you have to do if ", "you're blind on one side is turn your head.  It's not that hard in a practical sense.  But if you don't imagine the left half of the world exists,  where would you turn your head to? ", "And that's what these neglect patients do, don't imagine the  left half of the world exists.  So here's an example of a patient reading a text.  They're handed this text.  The slash lines here are where this patient seems to think ", "the left side of the page stops.  OK So they're overcoming everything they know about how  a sentence should be and reading this passage.  The patient says, \"had to pass the windows whom good morning ", "message for the ground his with all his and he bottle.\"  Thank you very much.  It's right in front of them, but the left half of the page  is just not present for this person's mind. ", "Here is a person copying a flower.  A psychologist or a neurologist draws this flower  or has a flower ready to go, a drawing, and says copy  everything you see.  And it's not always totally perfect exactly how it works. ", "But you can see there's a lot of the left side of this  flower missing--  right in front of them.  Here's a very simple one, too.  Copy everything you see here.  And what they see is these three things up here. ", "Their job's to copy everything down here.  They have all the time they want.  Left side is neglected.  And all they copy is the triangle.  That's all they draw.  And the tester will always say, are you done?  Are you sure you're done? ", "The person says, I'm sure I'm done.  Thank you very much.  Sometimes, they do something remarkable.  They're shown a scene like this.  Here's four trees with a house in the middle.  And you can see this patient starts over here. ", "They say, oh, there's a tree over, draws this.  There's a house over here.  And they jump from location to location.  Every time their attention lands, they draw the right  half of it. ", "It's always as if the left were missing.  And again, this idea of how constructed this is.  Here's two more examples.  And the clock thing, we'll talk a fair bit about.  Here's a patient writing to dictation. ", "The first sentence, they sort of stay--  but now, it's as if they were running out  of room on the page.  It's like they're reading, but it's writing.  The left half of the page doesn't exist.  Clocks are used a lot in this land, because it's kind of  impressive. ", "And we'll come back in a couple different versions  about this.  But look at that.  They were asked to draw the time on a clock.  And it's as if they could draw the time on the right side,  their good side.  But it's as if the left half of the clock didn't exist. ", "Here's another patient asked to draw the time.  And you see almost what seems like a struggle in the  patient, right?  They start on the right side. ", "And then here, they're running out of space.  They've got to cram in that 10.  Their mind knows it goes to 12, right?  But there's no space to put it in.  And so you put them, in a sense, in a sense of conflict. ", "And that's the top version.  The bottom, they were given numbers one at a time.  They were given, it tells you here, 12 and 6.  So they put those in the right spots.  Here comes 11.  Already, 11 is like, uh-oh, right? ", "And then, they get 4, 9.  9 is not going to make it.  And 10, they know it has to come after-- you can see that  they put them actually in a struggle between what they ", "know, something about where the numbers ought to go, but  the impossibility of the left half existing.  Now, here's something-- and we'll come back to this in a  few minutes--  what happens if you just give them a piece of paper and say, ", "write down 1 o'clock.  And then, you take that piece of paper away.  Write down 2 o'clock.  Take that piece of paper away.  Then look--  6, 7, 8, 9, 10, those are not bad, right?  If they just do one of them, the very same patient who had ", "to crowd everything on the right is quite comfortable in  putting down a pretty good 9, 10, and 11 if  it's just one of them.  We'll come back in a little bit to experiments that help ", "understand what's going on this case because we don't  only want a scientist to say, wow, this is  unbelievable and amazing.  We like to say something more about how the mind is doing  this and what part of their brain is important. ", "And kind of impressively, here's a patient with eyes  open mostly crowding on the right.  Got the 10 on the left, but doing a better job when their  eyes are closed.  They missed the dial altogether. ", "Their eyes are closed.  But they actually do it-- the same patient  does a better job.  OK, so how does that work?  And one more thing to mention is that neglect occurs across  modalities. ", "That is, when these patients have neglect, I  focused on the visual.  But these patients also don't do very well if they're doing  things like reaching for things.  It's not just vision.  It's pretty much everything in the left half of the world. ", "And you can do these kinds of things which, again, show not  only their neglect but the constructed psychological  nature of the neglect.  It varies in ways that are interesting.  So they're given a line like this and say ", "mark the exact middle.  You would draw something here.  They draw here because they're going to neglect  that part of the line.  Then, they say read the A. So they draw the person's  attention to A. And now draw it, and they get better. ", "Then, they're asked to mark the middle.  Not too good.  Mark the middle-- but you see the difference here.  The A is present or the B is present.  And if the B is present, it pulls them over here.  If the A is present, it pulls their attention over here. ", "They put their hand at the middle and say.  Now, please mark the middle.  Their hand goes over here for the middle.  But if they start them all the way over here, their hand will  only go this far.  So as you see, all these different movements are ", "telling you that the mind is interpreting what the  world is out there.  If you pull a little bit the person to the left, they'll  notice a little bit more of the left. ", "Where is the injury?   So almost everywhere you read still in neurology books to  this day that it's in the parietal cortex. ", "But in the last few years, people have mostly come to  this idea that the damage tends to be in  the temporal lobe.  And what happens when the temporal lobe is injured, it  knocks of the balance of attention in the left and ", "right parietal cortex.  And there's something about the activity in the right  parietal cortex goes way down.  That's paying attention to the left half of the world.  And as patients recover from this, the balance comes back. ", "And that's actually been measured now by brain imaging.  Their attention comes back clinically, and it does in  most patients.  Then, the balance between the two parietal cortices get  reestablished.  So even though people thought the site of damage was here, ", "the interpretation's usually here in the temporal lobe.  But the consequence of that is reduced activity in this part  of the brain, even if it's not physically injured.  ", "The fantastic thing is--  think about this for a second-- in order to ignore  the left half of the flower, the left half of a design, the  left half of a page, the left half of a clock, what do you ", "have to know?  Where the left and right are.  It's not as if his eyes were closed.  If your eyes were closed, you wouldn't know where left and  right are on a page, right?  He has to represent in his mind what is left and right ", "reasonably accurately.  And then, he extinguishes awareness that anything in the  left could exist.  But part of his mind has to know what is left for that to  work, right?  Otherwise, the digits would be all over the piece of paper, ", "not even on the paper.  He centers on the paper.  He centers on the circle.  Centering means I know what's left.  I know what's the center.  And then boom, the left disappears as a place that ", "could exist.  So these are all tasks in front of you.  There's been some incredibly Sherlock Holmes like clever  experiments asking whether you also neglect your imagination. ", "Not what's in front of you, but your imagination.  So here's the way they did it.  Have any of you been in Milan?  There's a central cathedral in part of town.  It's a big deal. ", "So they took Milanese patients, people who lived in  Milan their whole lives who had strokes in the right  hemisphere who had neglect, and they asked them to imagine  the Piazza del Duomo, the major church there, looking at  it from one side of the square or from entering from the ", "opposite side of the square.  And I'll show you the other experiment.  Here's the idea.  They said imagine that you're entering the square this  direction so that the church is behind you, or this ", "direction so that the church is in front of you.  So you're entering the square from one side or from the  other side.  Now, the square that you've been too many times, that you  know very well, tell me everything that's in the  square as you imagine entering from one side. ", "And here's what the patient reports.  They're imagining coming out facing the church.  And they report these kinds of things from this side. ", "If that's only on the right side, they're  ignoring the thing.  So they say there's a cafe.  There's a bookstore or whatever else there is here.  That's everything that's in the square.  Everything that's in the square is shown in red? ", "Everything that's in the square.  They wait just moments.  And they say, now imagine instead you were coming out  from the church, opposite view of the square.  Tell me everything that's in the square. ", "And here's what they tell you.  The items that are in blue-- and they don't tell you the  items they just told you, the locations they've just told  you circled in red.  So they're sitting their imagining their square. ", "And then, they will ignore everything on the left,  whatever's their subject of left.  And you know they know it because all they have to do is  imagine they're on the opposite side of the square,  and then they report. ", "Does that make sense?  They're ignoring the left half of what they imagine the  square looks like when they've been to it many times.  And here's another patient doing exactly the same thing. ", "Imagine you're coming out of the church.  What's in the square?  Well, here's some specific places I know.  That's it?  That's it.  Wait a minute.  Imagine you come this way into the square facing the church. ", "What's everything in the square?  And they only report the things on this side.  So they're ignoring-- yeah?  AUDIENCE: Does the patient realize after a few seconds? ", "PROFESSOR: No, they never do.  It's an excellent question.  They just answered a moment ago one side, right?  Why don't they tell you, I just told you the stuff on the  other side?  Because it's as if it couldn't exist. ", "It's a little bit analogous to the patient  whose arm isn't moving.  And you go, do you have any problem?  And they go, no, I don't have any problem.  It's as if there couldn't be a problem.  What are you talking about, right? ", "So it overcomes all their knowledge and all their  intelligence.  It's as if I forced you to guess in detail what's in the  back of the room if something new was there.  And you go, there's no way. ", "I can't see.  I have no eyes in the back of my head.  It's sort of like that.  It's as if the left half couldn't exist.  The contradiction they could note--  just a moment ago I told you the other one-- they don't ", "notice it because something about this neglect swallows up  all of your judgment.  It's beautifully phrased by some neurologist as, it's as  if the left half could not exist. ", "Whenever you're thinking left, it doesn't exist.  And ironically, you have to think left for that to work.  That's the amazing thing.  You have to go, I'm in the middle.  There's a left. ", "There's a right.  Now, the left doesn't exist.  And it couldn't exist.  And every hint I get that it does exist, like there's food  on that side or the pages usually go all the way here ", "and makes the sentences make sense, it all disappears on  you because it couldn't possibly exist.  And the neat thing about that is it's striking  neurologically.  But that means in our own heads as we go around, we're ", "constructing the world this way, building up two separate  sides of our brain that are gluing together a picture of  the world around us.  And these patients lose that glue on one  side of their brain. ", "Is that OK?  Here's another version.  It's less flashy, but it's the same idea.  Now, neglect can't get small enough.  If you make something very tiny, then you ", "don't ignore the left.  Once it gets tiny enough, you can't do it.  So they took advantage of that.  And they show cloud like stimulus of these.  But they didn't show them like this.  They only had a slit.  So you only saw the cloud a bit at a time. ", "And you see one cloud, and then you see another cloud.  Perhaps you'd see this cloud go by, and you see  this cloud go by.  And your job was to say were they identical clouds or not?  And if they were not identical, on which side do ", "they differ?  So because of all your visual experiences through the slit--  which is too small for neglect to happen--  what you do is you create in your mind's eye what does that ", "whole cloud look like as it passed through the slit in  your mind's eye?  And then, you see another one.  And you put that up in your mind's eye.  And you compare these two things that are in your  imagination in your mind's eyes. ", "And what happens is if these two things differ on the left  side, the patients rarely can make that distinction.  It's not because they can't see it.  It's always in that narrow slit. ", "But once they put the pieces together, they put it up in  their mind, the left half disappears on them in their  mind's eyes.  So here's an experimental approach to think about what ", "might be going wrong in these patients.  So they used a very simple task, which is when a light  comes on, you push a button.  That's all the task is.  Any light comes on, you push a button. ", "And sometimes, they'll put an arrow.  And sometimes, you have no information.  The light comes on on the left or the right.  And sometimes, they'll put on an arrow in the middle that  will warn you whether the light is likely to come on in ", "the left or the right.  So sometimes, you have neutral things.  You get a cross in the middle.  Then, a light comes on.  You don't have to say left and right.  You just push a button when one of those goes on.  Sometimes, he gets an error that's called valid that, 80% ", "of the time if it's pointing this way, it will turn out on  that side, 80% it will turn on this side.  So 80% of the time, it's honest.  And 20% of the time, it's dishonest.  So here's what it looks like. ", "You're looking here at a computer display.  That thing disappears.  And then, either an x is here or here.  And you push a button.  That's all.  Or a light comes on, and you just push a button. ", "That's all.  If it came on on the left or the right, I push button.  When an arrow appears, 80% of the time it's warning you  where that light will appear.  20%, it's dishonest and it appears on the opposite side. ", "So you will know, how good an experimental psychologist you  are right now, if I ask you which condition do you think  you're the fastest to push the button, when you have an arrow  that's truly telling you where the light will come on, an ", "arrow that's misleading you, or an x  that tells you nothing?  Which do you think you'll be fastest?  PROFESSOR: Where the arrow's pointing, right?  Like, here's the answer, over here!  OK, thank you very much. ", "Which do you think you'll be slowest on?  The dishonest arrow, right?  The arrow says, look over here, look over here!  And you're looking over there.  And you go, oh no!  It came on the other side.  You lied to me! ", "And the x is the middle.  And here's the data.  And it's a very simple experiment, right?  How fast are you?  This is reaction time just to push a button  when it comes on.  Here's the neutral condition in the middle. ", "You're a little bit faster if it's an honest arrow.  You're a little bit slower if it's a  dishonest, misleading arrow.  So now, you do this exact experiment. ", "And I'll show you the data.  And then, I'll simplify it for you with patients who have  right sided damage, left sided neglect.  And you can see as you look at these lines that the arrow can ", "be honest or dishonest, and it can be on the  left or right side.  Now, if you were always bad on the neglected side, you go,  well, that's not a big surprise.  But here's a surprise.  Patients were only bad-- ", "the times were way up here only when they had a dishonest  arrow that sent them into their good side.  That's when they were really bad.  So let's take a look at this again. ", "So here's the bad side.  Here's the good side.  When that arrow comes on that's honest, good.  When an arrow comes on that's honest this way, they do fine. ", "That's their bad field, but they do fine.  Tiny bit slower, but just a tiny bit.  Arrow comes on that moves them into their bad field but  really the light is on here, they do fine.  But if an arrow sends them into their good field, then ", "they're really, really slow to get back here.  So Posner argued that when you move your attention in the  world, you have three steps you have to do.  You have to disengage your attention from where you're ", "paying attention, just logically.  I'm paying attention here right now.  I'm going to pay attention over here.  I have to pull myself up from here, move my attention over  here, and then focus here.  So you disengage, get out from where you are, move to where ", "you need to go, and land and then focus  what you want to do.  And the only condition where they're bad is where they have  to get their attention out of the good field as if once  they're in that good field, once their mind is landed in ", "that good field, they're in quicksand.  And it's going to be really hard to get their attention to  move into the bad field.  So think about this.  The clocks are perfect for this because when you draw a ", "clock mostly--  think about that as intuitively--  if I was to ask you to draw the numbers on a clock, you  start with a 12 typically.  Then, what's the next one you would draw? ", "One, because that's how we're taught to do clocks.  Disaster if you have neglect.  You're in the good field.  Now, the left half of the clock has disappeared on you ", "because the clock has made you land your attention on the  good field.  And now, you can't pull out of it.  But what happens if you only have to draw 8 o'clock? ", "Your attention never got moved into the good field.  It's just starting from middle, so to speak.  And this very same patient can draw the 8 o'clock or 10  o'clock pretty well.  Does that makes sense? ", "Because they never got stuck in the good field.  They only moved into the bad field.  They can move into the bad field.  And so if their eyes are closed, that's better. ", "They get less stuck.  And now, we understand this thing.  Why is it these patients, if both fingers are moving--  because once their attention is drawn into the good field,  it's as if the bad field disappeared on them.  But if they only get stimulated in the bad field, ", "so right side here, then they're OK because they never  paid that much attention to the good field.  So this is a nice experiment.  It shows you what is the problem.  The problem is once you're paying attention to the good ", "field, the normal, healthy field, it's so powerful  compared to the weakened representation here, that you  never leave it because it just seems like everything.   Now, here's a clever one. ", "Again, this shows you how much of attention is created by our  minds as opposed to just simply defined by the  environment.  So what if you show a display to somebody with neglect and ", "then rotate the display right in front of them?  So initially, the neglect is going to be on the left side.  But imagine the thing is turning over like this, right  in front of them. ", "Will the neglect travel with the initial assignment?  So this is from Marlene Behrmann, a very clever  experiment.  They have to pay attention if the light  comes on here or here.  But what they do is while the experiment's going on, right ", "in front of you, it slowly rotates over to here.  And sure enough, then the light comes on.  Sure enough, the neglect now moves into the good field ", "because once you've assigned left and right, you  know this is left.  So OK, you turn it over.  That's still really left.  But think how weird that is.  The mind is deciding that. ", "In an absolute sense, this thing is on the right.  But the mind said, this is the leftward one.  And you can flip it over, but you're not tricking me.  I know it's on the left, and I'm considering it the ", "leftward one.  The mind is deciding what counts as left and  right, not the world.  And what other kinds of information is being processed ", "that's not reaching attention levels?  So here's a cute experiment.  They would say to these patients, any difference  between these two things? ", "No.  But if you had to live in one of these houses, which one do  you think you'd live?  Well, I don't know.  They're pretty much the same.  Why would I pick one?  Well, pick one!  They go, ah, this looks like a little better place to live if  I have to pick one. ", "Which vase do you want?  I don't know.  They look the same.  You have to pick.  I pick this one.  Which glass to drink from?  You have to pick.  Pick this one.  So they consciously are not aware of what's going on here ", "when there's information to the opposite side to draw  their attention.  But something in their mind somewhere is picking up  information.  So the last question-- and I'll show you a final video--  is this.  What kind of information is picked up in the neglected ", "field as you decide, some part of your mind, to neglect it?  So imagine if I showed you two forks versus  a fork and a spoon. ", " In order for that to make a difference whether you report  both are present-- so again, if you have a right sided  lesion, you might tend not to report this fork or not to ", "report this key.  If you just don't report either one, OK, left is left  and you're bad at reporting that one.  There's something competing in the good field.  Your attention gets drawn here, hard to disengage. ", "But if it makes a difference what this thing is, that means  that your mind kind of knows what it is.  And your mind is saying, well, if it's a key, that's ", "different enough that I can still pay attention to it.  But if it's another fork, those are really similar.  And now, my mind is really sucked into this fork.  But in order for that to make a difference, do you see that ", "you have to know somewhere in your mind what's different on  the left for that to affect your performance?  So now, we'll see a video of a patient, the last one.  This is a neurologist, Bob Rafal, and a patient. ", "It's a hugely nice thing of the patients, most of all, but  also the physicians to make these tapes available for  teaching purposes.  ", "So you understand--  just review for one month and we're done--  that when the same object came up, did he pretty much notice  the one on the bad side and the right side for him?  No.  Same object, he almost always said it's one. ", "If they're different objects, he typically reported slightly  sluggishly the one on his bad side.  That means part of his mind has to know what the object is  so that he ignores it if it's identical and he reports it if ", "it's different.  Well, you have to know what it is to base  your answer on that.  Yet, the logic of neglect is that if they're identical,  then he's going to ignore the one that he spotted on the ", "left in part of his mind but squashed from his awareness on  the other side.  OK, thanks very much. "], "vid_duration": [11.81, 12.039, 11.241, 10.66, 12.97, 11.039, 10.38, 11.951, 10.579, 11.691, 12.61, 11.6, 10.43, 10.55, 11.219, 10.991, 11.769, 11.25, 10.631, 11.07, 12.64, 10.459, 15.933, 11.778, 10.09, 11.13, 11.16, 11.14, 10.26, 10.99, 11.74, 10.61, 10.67, 12.36, 11.38, 13.45, 10.87, 13.56, 13.41, 10.12, 10.829, 10.99, 10.76, 10.221, 11.029, 10.891, 11.43, 10.87, 12.16, 10.82, 11.84, 10.56, 12.32, 11.8, 10.3, 12.77, 11.11, 12.03, 10.64, 12.82, 10.86, 10.44, 10.44, 10.48, 13.34, 11.12, 11.44, 13.99, 12.89, 10.71, 11.24, 13.125, 11.475, 11.11, 13.93, 10.56, 11.59, 14.09, 10.64, 12.228, 11.512, 11.33, 10.18, 13.65, 12.39, 10.0, 11.36, 10.39, 11.429, 11.23, 13.101, 10.1, 12.01, 11.74, 10.44, 12.83, 10.39, 11.13, 10.34, 11.23, 10.58, 10.19, 11.04, 11.66, 10.17, 10.86, 10.76, 11.14, 13.515, 12.055, 13.45, 10.93, 10.44, 13.07, 11.27, 11.26, 12.5, 10.43, 10.03, 10.65, 10.805, 11.645, 10.78, 10.01, 12.14, 11.41, 10.41, 10.51, 10.41, 10.51, 11.45, 11.76, 11.44, 11.02, 11.34, 12.17, 12.7, 13.7, 11.68, 12.14, 10.87, 12.94, 10.32, 10.61, 10.34, 13.61, 11.39, 11.3, 13.05, 10.63, 11.78, 12.0, 10.27, 12.56, 11.01, 10.18, 12.9, 11.0, 12.106, 11.714, 10.85, 11.57, 10.05, 12.93, 11.08, 12.7, 17.95, 10.59, 11.75, 11.239, 10.391, 13.29, 11.66, 13.42, 11.75, 12.909, 10.011, 10.799, 10.5, 10.73, 10.691, 11.03, 11.15, 11.68, 12.87, 10.53, 10.68, 11.12, 11.41, 10.13, 11.025, 10.815, 10.56, 10.28, 13.44, 10.46, 11.83, 11.13, 11.6, 13.95, 10.97, 11.415, 10.805, 11.36, 10.3, 14.69, 12.33, 10.69, 11.34, 10.05, 10.91, 11.87, 10.76, 10.58, 10.86, 12.98, 11.3, 12.03, 12.16, 11.47, 10.14, 10.48, 10.8, 10.36, 11.33, 13.33, 12.73, 12.32, 11.93, 10.11, 11.72, 10.0, 10.61, 10.15, 10.43, 10.83, 11.08, 11.36, 11.81, 10.04, 10.99, 12.08, 11.42, 10.04, 12.25, 12.65, 11.92, 13.86, 10.01, 7.32], "stet": [[0, 11.81], [11.81, 23.849], [23.849, 35.09], [35.09, 45.75], [45.75, 58.72], [58.72, 69.759], [69.759, 80.139], [80.139, 92.09], [92.09, 102.66900000000001], [102.66900000000001, 114.36000000000001], [114.36000000000001, 126.97000000000001], [126.97000000000001, 138.57000000000002], [138.57000000000002, 149.00000000000003], [149.00000000000003, 159.55000000000004], [159.55000000000004, 170.76900000000003], [170.76900000000003, 181.76000000000005], [181.76000000000005, 193.52900000000005], [193.52900000000005, 204.77900000000005], [204.77900000000005, 215.41000000000005], [215.41000000000005, 226.48000000000005], [226.48000000000005, 239.12000000000006], [239.12000000000006, 249.57900000000006], [249.57900000000006, 265.51200000000006], [265.51200000000006, 277.2900000000001], [277.2900000000001, 287.38000000000005], [287.38000000000005, 298.51000000000005], [298.51000000000005, 309.6700000000001], [309.6700000000001, 320.81000000000006], [320.81000000000006, 331.07000000000005], [331.07000000000005, 342.06000000000006], [342.06000000000006, 353.80000000000007], [353.80000000000007, 364.4100000000001], [364.4100000000001, 375.0800000000001], [375.0800000000001, 387.4400000000001], [387.4400000000001, 398.8200000000001], [398.8200000000001, 412.2700000000001], [412.2700000000001, 423.1400000000001], [423.1400000000001, 436.7000000000001], [436.7000000000001, 450.1100000000001], [450.1100000000001, 460.23000000000013], [460.23000000000013, 471.05900000000014], [471.05900000000014, 482.04900000000015], [482.04900000000015, 492.80900000000014], [492.80900000000014, 503.03000000000014], [503.03000000000014, 514.0590000000002], [514.0590000000002, 524.9500000000002], [524.9500000000002, 536.3800000000001], [536.3800000000001, 547.2500000000001], [547.2500000000001, 559.4100000000001], [559.4100000000001, 570.2300000000001], [570.2300000000001, 582.0700000000002], [582.0700000000002, 592.6300000000001], [592.6300000000001, 604.9500000000002], [604.9500000000002, 616.7500000000001], [616.7500000000001, 627.0500000000001], [627.0500000000001, 639.82], [639.82, 650.9300000000001], [650.9300000000001, 662.96], [662.96, 673.6], [673.6, 686.4200000000001], [686.4200000000001, 697.2800000000001], [697.2800000000001, 707.7200000000001], [707.7200000000001, 718.1600000000002], [718.1600000000002, 728.6400000000002], [728.6400000000002, 741.9800000000002], [741.9800000000002, 753.1000000000003], [753.1000000000003, 764.5400000000003], [764.5400000000003, 778.5300000000003], [778.5300000000003, 791.4200000000003], [791.4200000000003, 802.1300000000003], [802.1300000000003, 813.3700000000003], [813.3700000000003, 826.4950000000003], [826.4950000000003, 837.9700000000004], [837.9700000000004, 849.0800000000004], [849.0800000000004, 863.0100000000003], [863.0100000000003, 873.5700000000003], [873.5700000000003, 885.1600000000003], [885.1600000000003, 899.2500000000003], [899.2500000000003, 909.8900000000003], [909.8900000000003, 922.1180000000003], [922.1180000000003, 933.6300000000003], [933.6300000000003, 944.9600000000004], [944.9600000000004, 955.1400000000003], [955.1400000000003, 968.7900000000003], [968.7900000000003, 981.1800000000003], [981.1800000000003, 991.1800000000003], [991.1800000000003, 1002.5400000000003], [1002.5400000000003, 1012.9300000000003], [1012.9300000000003, 1024.3590000000004], [1024.3590000000004, 1035.5890000000004], [1035.5890000000004, 1048.6900000000005], [1048.6900000000005, 1058.7900000000004], [1058.7900000000004, 1070.8000000000004], [1070.8000000000004, 1082.5400000000004], [1082.5400000000004, 1092.9800000000005], [1092.9800000000005, 1105.8100000000004], [1105.8100000000004, 1116.2000000000005], [1116.2000000000005, 1127.3300000000006], [1127.3300000000006, 1137.6700000000005], [1137.6700000000005, 1148.9000000000005], [1148.9000000000005, 1159.4800000000005], [1159.4800000000005, 1169.6700000000005], [1169.6700000000005, 1180.7100000000005], [1180.7100000000005, 1192.3700000000006], [1192.3700000000006, 1202.5400000000006], [1202.5400000000006, 1213.4000000000005], [1213.4000000000005, 1224.1600000000005], [1224.1600000000005, 1235.3000000000006], [1235.3000000000006, 1248.8150000000007], [1248.8150000000007, 1260.8700000000008], [1260.8700000000008, 1274.3200000000008], [1274.3200000000008, 1285.250000000001], [1285.250000000001, 1295.690000000001], [1295.690000000001, 1308.760000000001], [1308.760000000001, 1320.0300000000009], [1320.0300000000009, 1331.2900000000009], [1331.2900000000009, 1343.7900000000009], [1343.7900000000009, 1354.220000000001], [1354.220000000001, 1364.250000000001], [1364.250000000001, 1374.900000000001], [1374.900000000001, 1385.705000000001], [1385.705000000001, 1397.350000000001], [1397.350000000001, 1408.130000000001], [1408.130000000001, 1418.140000000001], [1418.140000000001, 1430.280000000001], [1430.280000000001, 1441.6900000000012], [1441.6900000000012, 1452.1000000000013], [1452.1000000000013, 1462.6100000000013], [1462.6100000000013, 1473.0200000000013], [1473.0200000000013, 1483.5300000000013], [1483.5300000000013, 1494.9800000000014], [1494.9800000000014, 1506.7400000000014], [1506.7400000000014, 1518.1800000000014], [1518.1800000000014, 1529.2000000000014], [1529.2000000000014, 1540.5400000000013], [1540.5400000000013, 1552.7100000000014], [1552.7100000000014, 1565.4100000000014], [1565.4100000000014, 1579.1100000000015], [1579.1100000000015, 1590.7900000000016], [1590.7900000000016, 1602.9300000000017], [1602.9300000000017, 1613.8000000000015], [1613.8000000000015, 1626.7400000000016], [1626.7400000000016, 1637.0600000000015], [1637.0600000000015, 1647.6700000000014], [1647.6700000000014, 1658.0100000000014], [1658.0100000000014, 1671.6200000000013], [1671.6200000000013, 1683.0100000000014], [1683.0100000000014, 1694.3100000000013], [1694.3100000000013, 1707.3600000000013], [1707.3600000000013, 1717.9900000000014], [1717.9900000000014, 1729.7700000000013], [1729.7700000000013, 1741.7700000000013], [1741.7700000000013, 1752.0400000000013], [1752.0400000000013, 1764.6000000000013], [1764.6000000000013, 1775.6100000000013], [1775.6100000000013, 1785.7900000000013], [1785.7900000000013, 1798.6900000000014], [1798.6900000000014, 1809.6900000000014], [1809.6900000000014, 1821.7960000000014], [1821.7960000000014, 1833.5100000000014], [1833.5100000000014, 1844.3600000000013], [1844.3600000000013, 1855.9300000000012], [1855.9300000000012, 1865.9800000000012], [1865.9800000000012, 1878.9100000000012], [1878.9100000000012, 1889.9900000000011], [1889.9900000000011, 1902.6900000000012], [1902.6900000000012, 1920.6400000000012], [1920.6400000000012, 1931.2300000000012], [1931.2300000000012, 1942.9800000000012], [1942.9800000000012, 1954.2190000000012], [1954.2190000000012, 1964.6100000000013], [1964.6100000000013, 1977.9000000000012], [1977.9000000000012, 1989.5600000000013], [1989.5600000000013, 2002.9800000000014], [2002.9800000000014, 2014.7300000000014], [2014.7300000000014, 2027.6390000000015], [2027.6390000000015, 2037.6500000000015], [2037.6500000000015, 2048.4490000000014], [2048.4490000000014, 2058.9490000000014], [2058.9490000000014, 2069.6790000000015], [2069.6790000000015, 2080.3700000000013], [2080.3700000000013, 2091.4000000000015], [2091.4000000000015, 2102.5500000000015], [2102.5500000000015, 2114.2300000000014], [2114.2300000000014, 2127.1000000000013], [2127.1000000000013, 2137.6300000000015], [2137.6300000000015, 2148.3100000000013], [2148.3100000000013, 2159.430000000001], [2159.430000000001, 2170.840000000001], [2170.840000000001, 2180.970000000001], [2180.970000000001, 2191.9950000000013], [2191.9950000000013, 2202.8100000000013], [2202.8100000000013, 2213.3700000000013], [2213.3700000000013, 2223.6500000000015], [2223.6500000000015, 2237.0900000000015], [2237.0900000000015, 2247.5500000000015], [2247.5500000000015, 2259.3800000000015], [2259.3800000000015, 2270.5100000000016], [2270.5100000000016, 2282.1100000000015], [2282.1100000000015, 2296.0600000000013], [2296.0600000000013, 2307.030000000001], [2307.030000000001, 2318.445000000001], [2318.445000000001, 2329.250000000001], [2329.250000000001, 2340.610000000001], [2340.610000000001, 2350.910000000001], [2350.910000000001, 2365.6000000000013], [2365.6000000000013, 2377.930000000001], [2377.930000000001, 2388.6200000000013], [2388.6200000000013, 2399.9600000000014], [2399.9600000000014, 2410.0100000000016], [2410.0100000000016, 2420.9200000000014], [2420.9200000000014, 2432.7900000000013], [2432.7900000000013, 2443.5500000000015], [2443.5500000000015, 2454.1300000000015], [2454.1300000000015, 2464.9900000000016], [2464.9900000000016, 2477.9700000000016], [2477.9700000000016, 2489.270000000002], [2489.270000000002, 2501.300000000002], [2501.300000000002, 2513.460000000002], [2513.460000000002, 2524.9300000000017], [2524.9300000000017, 2535.0700000000015], [2535.0700000000015, 2545.5500000000015], [2545.5500000000015, 2556.3500000000017], [2556.3500000000017, 2566.710000000002], [2566.710000000002, 2578.040000000002], [2578.040000000002, 2591.3700000000017], [2591.3700000000017, 2604.1000000000017], [2604.1000000000017, 2616.420000000002], [2616.420000000002, 2628.3500000000017], [2628.3500000000017, 2638.460000000002], [2638.460000000002, 2650.1800000000017], [2650.1800000000017, 2660.1800000000017], [2660.1800000000017, 2670.790000000002], [2670.790000000002, 2680.940000000002], [2680.940000000002, 2691.3700000000017], [2691.3700000000017, 2702.2000000000016], [2702.2000000000016, 2713.2800000000016], [2713.2800000000016, 2724.6400000000017], [2724.6400000000017, 2736.4500000000016], [2736.4500000000016, 2746.4900000000016], [2746.4900000000016, 2757.4800000000014], [2757.4800000000014, 2769.5600000000013], [2769.5600000000013, 2780.9800000000014], [2780.9800000000014, 2791.0200000000013], [2791.0200000000013, 2803.2700000000013], [2803.2700000000013, 2815.9200000000014], [2815.9200000000014, 2827.8400000000015], [2827.8400000000015, 2841.7000000000016], [2841.7000000000016, 2851.710000000002], [2851.710000000002, 2859.030000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [435, 1275, 1854, 2290, 2686, 2859]}
{"example_id": "mit057@@MIT9_00SCF11_lec07_300k", "text": ["PROFESSOR: So today we're going to talk about attention.  And sometimes we talk about patients who are very unusual.  In the next lecture, we will do that. ", "We'll talk about spectacular disorders of attention.  But today we're going to talk about attention as it  typically occurs in you sitting here right now.  I want to convince you that in addition to slips of attention ", "that can occur as you get older, also how you attend to  the world around you is weirder than you think.  In a broad sense, I hope to convince you that it's ", "happening all the time.  Right now, as you go back to your room, as you walk to the  next class, or your room.  How you attend to what's around you in the world is  weirder than you think.  So what is attention? ", "What do we mean by attending to things?  So William James was a psychologist at Harvard who,  in many ways, articulated concepts in psychology that,  till this day, turned out to be beautiful ways to talk ", "about them in an everyday sense.  \"Everybody knows what attention is.  It's the taking possession by the mind in clear and vivid  form of one out of what seems like several simultaneous ", "objects or trains of thought.  It applies withdrawal of some things in order to deal with  others.\"  So a big idea there is we can pay attention to some things  and there's a lot of things around us.  And so we have to pick where we focus our attention. ", "A little bit like if you have a budget.  If you have some money, what do you spend your money on,  and what do not spend your money on?  So we're going to talk about attention.  It's kind of similar to the idea of awareness.  What are you aware of? ", "Or what are you conscious of?  And two themes across the talk will be we often attend to  more than we realize.  And I'll show you very specific evidence for that. ", "But we often attend to things less than we  realize all the time.  And here's roughly the outline.  We're saying attention, what you pay attention to, is kind  of a gatekeeper to what you perceive and what you know. ", "Attention is very limited.  We can only process one thing at a time.  And because of that, we miss a lot around us all the time.  There are unconscious processes that pick up  information.  So sometimes things that we don't notice do influence us. ", "And attention can be viewed as kind of a  dialogue between two things.  Between things in the world that capture your attention.  If somebody throws a ball at you, something dramatic  happens-- you hear a scary sound that captures your ", "attention--  we talk about that as \"bottom-up\" processing.  It impinges on you.  It forces you to attend to it.  Because it's danger, it's moving, it's unusual.  And then, \"top-down\" things. ", "What's your goal?  What are you paying attention to?  What do you care about?  What are you up to?  People call that top-down processing.  So things that the environment drives into your attention  because they're so dramatic, bottom-up. ", "Things that you're looking for, thinking about, you know  are useful for your purposes, top-down.   There's tremendous evidence that we encode a very small ", "fraction of what's around us in a very specific way.  Estimate with me how often a day, on average, since you've  been about five or six or seven and you've been allowed  to have any money in your possession at all. ", "Do you think you've held or seen a penny?  OK, so we all know the horror when you're  handed $0.4 in change.  That's 4 pennies right there.  So we'll make an estimate. ", "Pretend from age 5 to 20 you've been handling change.  So maybe you've encountered 3 pennies a day.  OK, that's reasonable?  OK. ", "We don't have to be just in the right ballpark.  There's 365 days a year, skip 15 years.  Just do the multiplication.  You end up with about 16,380 penny experiences. ", "All right, so we all know that if you head towards midterms,  it's going to be hard to study a lot of stuff quickly.  But if somebody said to you, if you study something  approximately 17,000 times, you'd think, well, that one ", "I'm going to get.  So let's ask the question.  Does the Lincoln penny face to the left or the right?  Is there anything above his head or below his head?  Is there anything on the penny to the left or to the right? ", "And how about the other side?  And how many of you with approximately 17,000, or  certainly many thousands of visual experiences with a  penny would bet something that means a lot to you on the ", "correctness of your answer to these 5 fundamental questions?   This is good teamwork.  ", "Let's take it multiple choice.  That's better, right?   AUDIENCE: It faces the right.  PROFESSOR: You're making me feel better because ", "of the fouls up.  And I appreciate that.  This is actually what it looks like.  So what do you think it means that 17,000 exposures to a  penny don't leave in you a reasonably accurate memory of ", "the main things you see in a penny?  How could that happen?  And it happens to everybody.  In fact, when they do experiments,  here's people's drawings. ", "Don't feel bad if you didn't know it.  Half the people don't even think that the version that  you show them, if you ask them is plausibly correct, you show  the correct answer, they go no. ", "That can't be right, OK?  So here's one thing.  If we don't attend to something very specifically,  we can see it a tremendous number of times and it leaves ", "no impression on our mind and no memory of it.  Now, why is that in an everyday sense?  We don't know on a deep science sense.  But what do you think the point of it is? ", "Why don't you know what a penny looks like?  Because it's not important somebody said.  Yeah.  Because it's close enough to see that brown smallish thing, ", "and you don't need the rest of any information to hand the  money back and forth.  So what you attend to, what you decide is important, makes  incredible difference.  And nothing else makes up for it. ", "17,000 exposures don't make up for what a penny looks like.  ", "So, it was research at MIT that used this method of  simultaneously processing two messages in the two ears, the  shadowed message, the one you're copying, and the second ", "message, the one that you try to pick up, but  it's hard to do.  So they ask in the ear that you're not paying attention  to, what can you pick up?  Here is what you can pick up if a voice is present. ", "Now you just imagine silence versus somebody talking.  That you can notice.  If the voice changes from a man to a woman--  if it changes from a man to woman, you can pick that up in  the unattended ear, the one you're not ", "paying attention to.  Or if the voice goes-- a person's talking and, all of a  sudden, it goes er.  You notice that.  Here's what you don't notice.  Anything about the content.  I mean, that's what you experience. ", "You can switch the language of the message.  You can go from English to Spanish, or Italian.  A person won't notice that it's changed.  ", "You can also change whether it's typical speech or  backward nonsense speech, which sounds very weird.  You don't notice that either.  So you notice a few things.  But there's a lot of other things you ", "don't notice at all.  Now, you may have all had the experience of what's called  the cocktail party phenomenon.  Do you know what that is?  Have you ever been talking with ", "people, you're at a party.  You're at some events, or something like that.  And somebody mentions your name.  Especially your first name, but your name.  Maybe your last name works, too.  And then all of a sudden, you notice a ", "conversation around you.  It's almost hard to pay attention to the person you're  talking to because the person over there has just said your  name and you wonder what they're saying about you.  Now, here's a really interesting paradox.  How did you not notice that other ", "conversation, which you didn't?  That's like the shadowing task.  I'm talking to one person, there's some hubbub over here.  I don't know what they're talking about.  All a sudden, they say my name and I notice what they're ", "talking about.  Well, how did that happen?  I wasn't paying attention to it.  I don't know anything about it.  But my name pounced out in my mind and drew my  attention to it.  So it's kind of a paradox.  I'm not paying attention, but somehow I pick up my name. ", "And so we'll talk a little bit more about this.  But people have looked at this very experimentally.  So here's how they approached it.  They would, again, hear a sentence in one ear, \"The man  approached the bank.\" That's the one they're repeating. ", "And in the other ear, they would hear one of two  different words.  In the unattended ear, they're not getting much out of that.  They would hear the word \"money\" or \"river.\" So now the  bank could be interpreted as you went to the bank to ", "deposit your paycheck, or you want to the bank to have a  picnic by the river.  Two different meanings of the word \"bank\" are suggested by  the word you hear in the ear that you're not processing ", "information in.  And then the people tell you, well, tell me what the  sentence is you just heard, kind of.  And people are primed to give the interpretation of the  sentence that goes with the word that's suggested in the ", "ear they weren't listening to.  So something in their mind and brain heard enough of that to  influence what they're interpreting in  the attended ear.  Here's another example. ", "They're shadowing, they're paying attention and repeating  aloud an essay in one ear.  And in the other ear, they hear something that's like a  word \"taxi fare.\" And they pick words that are spelled ", "two different ways, homonyms.  So the word F-A-R-E or F-A-I-R.  Now, if you were typically--  if I ask you to write down the word \"fair\" and spell it  correctly, you might say, well, which one do you want or ", "something like that?  But if I didn't tell you anything, most people would  put down the word F-A-I-R most of the time.  It's a more common word.  But what they found is this.  They finished the experiment.  They shadowed one thing. ", "They had a word like \"taxi fare\" in the unattended ear.  And they said, well, did you notice you got that word?  Well, if you listen to it, you remembered you heard \"taxi  fare.\" But if you were shadowed, you pretty much-- ", "you very rarely remembered that you heard it.  So it's not consciously available to you that you  heard it because you were so busy in the other ear.  And in your mind, listening to that ear.  But if you're asked to spell the word, how often do you ", "come up with the rare spelling because of what you  heard in your ear?  It's exactly the same.  So part of your mind heard that word, thought about that ", "phrase \"taxi fare.\" And when somebody says to you write  down the word \"fair,\" your mind got moved to think about  the alternative spellings.  Your unconscious processing of that content has influenced ", "you in experimentally verifiable way.  So what this shows, if you go back to the cocktail party  effect, which is the everyday kind of version of this, is  that weirdly enough some kinds of things that we don't pay ", "attention to have such a property that in a  machine-like reflexive way our mind brain process it to some  extent anyway.  And then there's something curious that we don't  understand deeply, which is somehow if it's your name, ", "it's going like, I'm hearing my name.  I'm hearing my name.  Pay attention over here.  That's a deep psychological, computational theory.  And somehow you pull it out because it's triggered your  mind enough.  Because our names are so important to us. ", "Yeah?  AUDIENCE: Is this similar to [INAUDIBLE]?  ", "PROFESSOR: OK, tell me again.  So the phenomenon where if you notice a word-- go ahead.  So tell me again.  Sorry.  AUDIENCE: Like you're just looking around and suddenly a  specific word [INAUDIBLE].  PROFESSOR: Yeah.  It's very much aligned to the same thing. ", "The question was, something pops in your head-- a word--  and then you look back and you go, wait a minute.  I just read that, but I wasn't even  thinking about it or something.  Somebody said it or it's on a sign.  But yes. ", "Some experience you're not paying much attention to tips  your mind to think a certain way.  And all of a sudden you're thinking that way and you  don't know what tipped your mind that way.  That's very similar, yeah.  ", "So again, the message here is, as you're walking around in  the world, there's very few things that you're very  specifically really aware of.  And many things can change on you in these examples. ", "So one of the reasons-- this is just a thought that by  being selective in attention, you can focus on what you want  to focus on.  It's not only a weakness, it's a strength.  So you could pick out the message in red or you could ", "pick out the message in blue.  Where you attend helps you select  information that's relevant.  But here's two more works.  Almost all the examples I just showed you were from Dan  Simons, who's done really beautiful work in this way. ", "Made it very available to--  so here's two YouTube ones.  ", "Sometimes people have said, OK, these are cute laboratory  things where you're having people counting.  But the real world is different.  When I'm out of the classroom and I'm out of the laboratory, ", "the real world you kind of notice a lot more.  Because it's real people, real situations.  So this is one more example that's a  beautiful example of this.  ", "So do you think it would have worked if the replacement  person was very different?  If we was a man or a woman, of if a very taller person versus  a person not--  no.  But what does that mean? ", "Why does it work for this one?  And why would it-- it means that in the person's head,  they have a very rough picture of who they're talking to. ", "Does that make sense?  So there's a lot of room for replacement.  Not total room, but a very rough picture.  But it's right in front of them.  OK, now, you've seen this thing, so I won't do it as a  demonstration now, where people simply read the words, ", "the red, orange, brown.  And that's easy because you're a very automatic reader.  If you're a typical adult, you read about 250 words a minute.  Zoom, zoom, zoom. ", "But if you have to name the color of the print when the  print is contradicted by the word, so you're reading the  word red printed in green, but your job is to say green. ", "That naming of the print when the word is not matching the  color of the print slows people down.  They make mistakes.  They're slower.  And that's because there's a big lesson in this.  It's great to get automatic at things. ", "That's how we're skilled at things-- speaking, driving,  everything physical.  We don't even think about how we walk.  The price of automaticity being really skilled and  reflexive is you lose control. ", "You lose control.  So you don't want to think about what that word says, but  you can't help but.  Now, let me touch one more thing.  How many people think-- and just be honest in your seat-- ", "that hypnosis is kind of bologna?  OK.  All right, a lot of you.  This is MIT, right?  OK.  So I'm going to tell you that I think a lot of hypnosis, the  kinds of things where if I learn how to hypnotize people, ", "then they can all vote for me, or something like that, that  doesn't work.  And people who are serious about hypnosis will tell you  that hypnosis is in the person, it's not in the ", "hypnotizer.  It's in the person, it's not in the hypnotizer.  And it turns out that, in ways that are not well understood,  there are some people who are highly hypnotizeable and some  people who are not. ", "So this is why I think we're suspicious.  Because if we're not, we're going, well, they must be  faking it, or pretending, or whatever.  But let me tell you what they did and let me see if this  convinces you at all as an experiment.  So they told people sometimes to read those words where it's ", "confusing because you're reading the color of the print  and the word is contradictory, it slows you down.  They told them, imagine those characters are characters in a  foreign language that you do not know. ", "Would the content of the word mess you up for the  color of the print?  No.  Because if it's a language you don't know, it's just stuff  and you can just name--  OK?  And they asked them to imagine that. ", "Now, here's what happened.  For people who are low hypnotizability, you can give  people questionnaires and they're pretty good at these  kinds of measures.   They're slowed down by about a tenth of a second per word ", "when the information is contradictory.  And when they're asked to imagine it's a foreign  language, it's about the same.  The low hypnotizables, you can tell them, imagine it's a  print you don't know.  It doesn't matter. ", "Here's the high hypnotizable.  Also slowed down.  But when they imagine it's a print in a foreign language  they don't know, not slowed down at all.  ", "So that's behavior.  That's evidence.  And we don't think you can fake it because how  would you fake it?  But here, in case you were still worried about that,  here's the brain imaging evidence from just the people ", "with high hypnosis, the high hypnotizable people.  What you see here turned on is the part--  our brain areas are turned on when you have to do the  difficult task where it's contradictory ", "versus the easy task.  All this area you see turned on in the anterior cingulate,  and especially--  which is an area that we know is involved when things are  contradictory or paradoxical and people are sorting it out. ", "Look what happens to that when these individuals are  imagining it's a foreign text.  It's pretty much gone.  Is that OK?  I'm as skeptical as anybody about behavioral ", "claims, I really am.  I think hypnosis is real for some people and very powerful  for some people.  And for other people it doesn't work at all.  I happen to be in the low hypnotizable category. ", "I'm as skeptical as anybody, but I think there are people  who can do remarkable things by hypnotic suggestion.  But it's in them, it's not in the-- a person who hypnotizes  you, so to speak, can help you a little bit. ", "But it's in you whether you have that approach to control  of your thoughts or not.   So let's go back to a test.  So we're talking, again, about two ideas. ", "That there's things--  top- down and bottom-up processes, and different ways  that you can attend to the world.  So I'm going to ask you to consult your own intuitions  for the following thing. ", "I'm going to show you things displayed on the monitor.  And your job is simply to answer in your own mind as  quickly as you possibly can.  Maybe just, if you're willing to do it out loud, let's just  say yes or no aloud, if you're willing to do it. ", "As quickly as you, whether you see a red X. Sometimes there's  a red X, sometimes not.  So ready?  Sorry, that's my get ready.  AUDIENCE: No.  PROFESSOR: No, great. ", "See, MIT is easy.  Sorry.  OK, ready?  Red X or not?  AUDIENCE: Yes.  PROFESSOR: Great.  Ready?  OK.  Thank you. ", "Ready?  Red X or not?  AUDIENCE: Yes.  PROFESSOR: Whoa.  You guys are amazing.  Now, look how many places you had to look to find it.  But did it feel that way, or did it seem to, what they  call, pop out?  It's just obvious.  It's just there. ", "So imagine I gave you this task.  I said, go into this room and please get a particular book.  And you go into the room and there's one book there.  And you've picked it up.  Would that be easy? ", "Yeah.  You go into a room and you go, my gosh, there's hundreds of  books in this room.  Would that be easy?  Now, here are many, many more things to find the red X. But  your mind instantly, easily, trivially finds it, right? ", "So now, let's try another version of this.  AUDIENCE: Yes.  PROFESSOR: Yes?  OK, get ready.   AUDIENCE: Yes.  PROFESSOR: All right.  Slower? ", "Harder?  OK, some disagreement.  OK.  All right, so let me show you data under well controlled  conditions.  And here's the concept.  People think that in many ways when we look out in the world,  there's features, things like simple things-- ", "shape or color.  Those are the two we're looking at here.  But in order to combine those, to know the same thing out  there has this shape and this color, to glue together  features, we have to have attention. ", "And so when the display looked like this, a single feature--  redness--  helps you.  A single feature-- redness--  helps you.  You don't have to worry about the shape. ", "Now, you have to worry about the shape and the color to  decide the red X. Worse yet, now it's a  slower, harder process.  And when people do this, here's exactly what they find. ", "If it's just a feature by shape or by color and that  alone would tell you the answer, you can have one  thing, a few things, and many things.  And boom, your mind instantly discovers it. ", "Instantly.  This is how long it takes you to do it.  But if you have to combine two things together, the shape and  the color on the very same thing, combine those things,  you need the glue of attention. ", "And the more things that are out there, the more your mind  has to search, search, search, search, until it  finally finds it.  It has to look around, and look around, and look around  to find the answer. ", "So some kinds of things in the world we notice without  attention features.  We can look everywhere at once in the display.  That's how we're so fast.  Things just pop out. ", "And the flat slope is-- mathematically.  Doesn't matter how many things are out there-- boom, you get  it right away.  Other things where we have to glue together two features  require our attention to do the gluing ", "things that are together.  We have to search spot, spot, spot, serially.  We don't feel the intuition of pop-out.  And we have a steep slope in search. ", "Now I need somebody from their chair who's pretty confident  in their math.   It's a little bit harder than before, but I'll tell you  don't have to go into triple digits. ", " Someone help me.  I owe you one.  I'll come back to you if there's one more.  I can't remember, sorry.  OK, ready? ", "So you're going to see some numbers and I want you to add  them and tell me what they are.  And I'm going to be pretty fast.  Is that OK?  AUDIENCE: [INAUDIBLE].  PROFESSOR: [INAUDIBLE].  AUDIENCE: OK.   PROFESSOR: Yes. ", "OK?  Ready?  AUDIENCE: 14.  PROFESSOR: Yes.  Ready?  AUDIENCE: 5.  PROFESSOR: Yes.  Ready?  AUDIENCE: 10.  PROFESSOR: Yes.  Ready?  AUDIENCE: 13. ", "PROFESSOR: Yes.  Now what were the letters between them?  Sorry, it's a trick.  It would have been mean.  AUDIENCE: [INAUDIBLE].  PROFESSOR: Sorry?  AUDIENCE: [INAUDIBLE] the last one so far.  PROFESSOR: Interesting. ", "OK.  Now, you can go, oh, that was a trick.  How reasonable is that?  Well, let me make the argument that in order to add the 5 and  the 8, you had to look at the letters.  You had to look at the letters. ", "They're in the middle.  But because your mind is not attuned to that, it's as if  they weren't there almost.  You know some thing's there, right?  It's right in front of you. ", "It doesn't seem that hard.  But again, if your mind is tuned to something, the other  stuff gets fuzzy.  And you got the R somewhere.  Now, let me ask one more question.  Do you the colors the letters were in? ", "No.  And in fact, you don't.  So thanks very much for willing to do that.  So again, we just said to bind shape and color, we need the ", "glue of attention.  We're not attending to the middle letters.  They seem irrelevant even though they're  right in front of us.  Even though we have to walk through them in our mind's eye  to move from one number to the other.  They're like, I don't care. ", "Boom, you move to the other side.  So it's not just seeing something, it's attending to  something that really matters.  And on top of that, you need a lot of attention if you do  glue together the shape and the color, that  requires a lot of focus. ", "What does this mean in everyday life?  In everyday life, we're probably walking around  constantly having free floating features around us ", "and things we're not paying attention to.  Right now I'm probably seeing a yellow computer over there.  And I'm seeing some blue fire extinguisher sign over there. ", "Now, why am I not freaked out by that?  And why are you not freaked out by that?  And why is it almost certain?  Because if you're not attending to things, you're  constantly having free floating  features that are incorrect. ", "Colors and shapes are just floating around you.  Why are we not disturbed by that?  Because we're not attending it to start with.  Because it's like you didn't notice the letters were there. ", "Well, then you're not bothered.  They're just free floating information.  You're not paying attention to it to start with.  But that's what's happening in your mind all the time.  And these experiments demonstrate that empirically  and directly. ", "There's also interesting temporal constraints.  I'll describe this experiment because it's too  hard to pull off here.  So there's a phenomenon called the attentional blink.  What's weird about these things, right? ", "Why is our minds like this?  You can speculate on that, but it's really well documented.  We attend to a small percentage of  what's around us.  And we need a lot of resources to know something well or ", "learn something well.  So here's another example.  What participants see is letters presented very quickly  one after the other--  E-L-H. Their job is to report any numbers that they see. ", "So you go, boom, boom, boom, boom.  What were the numbers?  Pretty fast, but humanly possible.  The interesting question is, what's the time gap between  the two numbers that you see? ", "There's usually two numbers.  We'll call this one the first one, time 1.  The second one, time 2.  What's the gap between them, and how does that influence  whether you're likely to report them?  So here's what's called the attentional blink and a ", "slightly scary graph that I'll tell you.  And let me tell you what it's like, the metaphor, and then  let me show you the result.  The metaphor is this.  Your mind, moment to moment to moment, is kind of like if you ", "could imagine you're next to a stream, a big stream with a  lot of fish zooming by.  You have a fishnet.  You dip into the stream.  You catch something at that moment. ", "But if a fish comes by just as you pull your fishnet out,  will you catch that one?  No.  So here's what happens.  Here's the time between the presentation. ", " If there's approximately three numbers between them, a couple  hundred milliseconds, you're almost a chance for the ", "possibility of reporting the second digit.  It's sort of like the fish you can't catch because you just  took your net out.  Except it's your mind, it's not a physical limitation.  So here's what it's like. ", "So this is perfect performance.  This is chance performance.  If it immediately follows, one number immediately follows the  next number, you're going to get both.  And the way to think about that is, it's kind of like ", "fishnet again.  You just put in your fishnet.  You got one fish.  And if you're lucky, while you're kind of pulling it out,  the next fish just swims in there.  You got two.  Now your fishnet's out. ", "And if something else comes, and something else comes, and  something else comes, you're pretty bad at recognizing it  was there at all.  A little bit of time comes back and you put your fishnet  back in and you're catching everything again. ", "About 1/2 second.  But how weird is that that your mind works like that for  spotting the digits?  That it has to take a break?  There's a part of your mind that's getting the digits. ", "And once it's gotten a digit, for the next couple of hundred  milliseconds, it's not going to have room to pay attention  to the following digits.  How weird is that? ", "It's because our mind has all these kind of limitations on  what we perceive in the environment.  Here's another sort of fun example of that.  So here's a task.  One of these dots are going to-- ", "One dot is going to blink.  And your job is to keep your eye on that dot.  You know when they say, keep your eye on the ball.  Keep your eye on the dot.  And when it stops moving, notice which is the one you've ", "been keeping your eye on.  So the first one's going to be easy, but it  will give you a feeling.  And then you'll see the answer given to you.  Ready?  People call this object tracking.  OK, here we go.  See that one blinking? ", "", "Now, let's try it one thing moving, but even faster.  ", "So let's try tracking four things.  ", "Last example.  ", "So here's a graph with a high level of  performance how people do.  So two things matter, and you might have felt that.  How many are viewing the number of targets? ", "And under many circumstances, people seem to be able to do  about three to four.  But also, the speed matters, too.  You might have felt that, too.  Both things contribute.  There's a lot of interest in this three to four limit that ", "people seem to have for things that they track,  three to four items.  And there's a lot of work, at Harvard actually, in  developmental psychology and related.  Let me just say a word about that to you. ", "There's a thought that pretty young when you're a kid, you  get to about this three to four things.  That our minds naturally contract about, or notice, or  keep a count of about three to four things in the world.  And so people who study, for example, math and the way that ", "humans perform it, think that we have in us, in our brains,  approximately two systems that are physically different and  culturally different.  And there's lots of debates about this, I  should tell you this.  But one of them being something like accurate ", "counting up to about three or four.  And then, cultures that don't have a organized system of  math, the next answer is many.  You've heard this, right?  It's like one, two, three, maybe four, and then a lot. ", "Now, we don't stop counting at four, but we might if we were  in a true state of nature and we didn't have an organized  system of math.  And weren't taught that in how it relates to  our language abilities. ", "So there's a lot of debate about the exactness of this.  But there's something fascinating about this idea  that our minds can have about four units of information kept  in mind, kept active, that we can track.  And that lots of things in the world reflect that limitation. ", "Including, for example, exact counting.  And without the cultural invention of mathematics, we  would count one, two, three, four, lots.  But there's debates about this because exactly how you ", "measure it can influence how you think about it.  Now, can attention be trained?  Could you be trained to have much more attention?  So in many ways, we don't think you can. ", "But in some ways, you can.  And part of this has come out of this ironic line of  research about things that are supposed to be bad for us.  Some of them might be OK for us.  Video games, OK? ", "If you're in my generation, people are going, oh, boy,  those video games are messing up all these kids.  Isn't that what you guys think?  No. ", "OK.  So Daphne Bavelier at Rochester has done a series of  studies showing that if you play certain kinds of video  games, you actually do expand your attentional capacity to ", "practice on those games.  Because they make you practice a lot.  So here's what she did.  She took people who didn't have experience  playing video games.  And now we're specifically talking about first-person  shooter video games. ", "And had them do 30 hours of practice.  And she looked at their ability to do multiple object  tracking of the kind you just saw, those dots whizzing ", "around, before and after.  So the games, as you know, are very different.  But they involve keeping track of lots of things  happening at once.  And here's what she found.  That these people who played 30 hours, these were people ", "who were not gamers beforehand, got better at  performing these tasks of keeping  track of multiple objects.  Of all things, a group that's super interested in that is ", "the military.  And why do you think that is?  AUDIENCE: [INAUDIBLE].  PROFESSOR: OK.  There was just a paper published recently that if ", "they take a brain image of your brain, they can predict  how good a gamer you'll become if you haven't  been a gamer before.  These are adults.  If you have bigger basal ganglia, you'll become a  better gamer in the next week starting from scratch. ", "The military's interested because you may know this.  An increasing amount of warfare is video game-like.  Which is kind of the haunting thing.  Because this is real people really being killed. ", "But, do you know the whole thing with the drones?  Have you followed this, some of you?  OK.  So the US has had a lot of success, and there's a lot of  debates about the ethics of this, in sending in unmanned ", "small airplanes into the Middle East.  And using that to kill opponents.  The person sitting in Washington, DC, or somewhere  else, is watching kind of like a video game when they make ", "that decision about whether that's  somebody to be attacked.  So a lot of operations now are computer-based and they're  kind of like a video game at one level.  And they're real-life hard decisions at another level. ", "So video games, they're becoming more and more, as you  can sense, a part of real world decisions and controls.  If you play Tetris because it doesn't require that kind of ", "fast thought stuff, you don't get any benefit.  There could be other benefits, but not this one.  So it's not just video games, it's the mental processes that  are practiced in the video games that give you certain ", "talents or not, or abilities you didn't have before.  OK, the last experiment I want to tell you is this.  So everything we've talked about now, except a little bit  about the stuff in the second year when you're shadowing, ", "has been about this idea that we don't pay much attention to  what's around us.  We don't get much in our mind compared to what we think we  would, even if it's right in front of us, even if it's all ", "over the place.  Even if we've seen a penny 17,000 times.  But there are some studies that have shown something  pretty interesting also, which reveals something very  paradoxical about the human mind. ", "That we can sometimes know things without seeing.  And people call that subliminal perception.  So how this experiment works is this.  And let me show you one example behaviorally.  I'm going to show you one brain example. ", "So here's what happens.  Let's pretend you have to read words aloud.  And we measure, to the millisecond, how fast  you read the word.  If I show you this word and I show you this word, and I ", "measure how quickly you read the word \"doctor,\" you're  slower than if you read the word \"nurse\" and then you read  the word \"doctor.\" Because these two are related.  And something in your mind gets warmed up ", "when you see this.  It doesn't get warmed up in a relevant way when  you see this word.  Does that make sense?  You see one word and then you read the next one.  If they're related semantically or conceptually ", "by meaning, you're faster for the second one.  OK, that's easy.  And it's not too surprising.  The clever discovery was this.  What they do is they do something call-- they present  these words under what they call masked conditions. ", "On the computer monitor you get something busy, like a  roll of X's.  For 10 milliseconds only, ten-thousandths of a second,  the word appears, and then there's a bunch of X's again. ", "So it's like a flash of X's.  And people, they create situations--  and I'll show you this again in a moment.  They create situations where people say, I'm not sure  anything was there. ", "I certainly don't know what it is.  You have to be there and you have to convince yourself, as  a scientist, that you've done that.  And then they have you read the word  \"doctor\" in full view.  And in these circumstances where people cannot tell you ", "that they saw a word, and they certainly can't tell you what  the word was, you still get faster.  So they don't know that they saw \"church\" or \"nurse,\" but ", "something in their mind picks it up.  And what's picked up in the mind under the subliminal  presentation changes the behavior when you have an  overt act of behavior reading the next word aloud. ", "So this is hardcore empirical evidence that your mind is  able to pick up stuff at the level of meaning.  Think about the paradox.  You think when I read a word, I see it and then I understand ", "its meaning.  Here it's flashed in such a way that you don't feel like  you see it, but you extract its meaning anyway.  And we know that because it makes you read the next word  faster only if they're related in meaning. ", "So your mind is subliminally primed.  Now, some years ago people used to worry that advertisers  could do this really cleverly and make you go do stuff.  The famous example is historically, can they make ", "you buy popcorn?  Which is now, since it's $48, that's harder to do.  But can they make you buy popcorn at the movie theater?  Or can they make you buy a Ford, or a Chevrolet, or ", "something like that, with the right subliminal message and  that kind of stuff?  Every experiment that's been done to ask whether subliminal  messages of this kind would make you get up and go do  something, like buy a car, or change what country you live ", "in, or something, it never works.  It never works.  Nobody's ever been able to show that in any  experimental condition.  Which doesn't prevent some companies from selling these  products to store owners that are thinking they're getting ", "their sales up.  But there's been never any evidence that these kinds of  subliminal presentations make people do something big and  complicated, like get up and go buy popcorn, or choose one  product over another. ", "People have never been able to show that under controlled  experiment.  But they have been able to show these kinds of changes in  behavior that last a moment.  So what's happening in your brain? ", "So this is the last experiment.  Again, they're presenting these things that in the same  place in the computer monitor all these things  to fill your eyes.  And then they present a word for either 29 milliseconds- ", "they present it either very briefly or in full view.  OK, so here it's visible because they remove the  confusing visual information just before and after it. ", "Here, people don't report seeing it.  And scientifically, it's really important because you  just say, oh, people didn't see it.  But it's really important in our field to  say, we're so convinced.  And why are we so convinced? ", "Because we say, was there any word present?  Because sometimes there's a word present and sometimes  there isn't.  Just is there a word present?  If you could see the word, because these things were a  little bit away in time and you could see it, you almost ", "always got it if it was visible.  You almost never got it if it was here.  You almost never said there was a word present.  And could you name it?  Yes, if you saw it like this.  You couldn't name it if it was presented brief-- if it was ", "surrounded by this visual stuff that  makes it hard to see.  If they give you a memory test for it, if you saw it fully in  full view, you got it.  If it was hidden like this, you didn't.  And finally, they give you a fourth choice. ", "They say, did you see the word \"note\" or did you see the word  \"coat?\" Choose between the two.  People are still at chance 50-50.  They're really pushing people to say, ", "really, did you see anything?  Do you know what it was?  There are completely a chance they don't remember anything.  They can't even tell if a word was there.  But we know it influences their mind.  And now let me show you what we know of how it influences ", "your brain.  So what's shown here in green are parts of your brain that  respond when a word is shown that you can see.  And what's shown here in red are the parts of your brain  that respond for that subliminally presented word, ", "the word that's presented but you can't tell that any word  was there, never mind what word it was.  So at first you can see there's a lot more brain  response for the visible than the masked or subliminal word. ", "But that makes a lot of sense.  You see something, you think about, you know it happened.  But you can measure what's happening in the brain.  It's very small.  Take this spot.  Here's the response if it's in full view. ", "Here's a tiny, tiny, tiny, tiny response when it's  presented in that minimalist way.  But it's measurable and it's present.  And we know that it's enough for you to figure out  unconsciously what the meaning of that word was. ", "So then, we ended with this paradox, which is on the one  hand, we live in a world where we only notice a small  fraction of what's around us.  What we focus our attention to because we have limited ", "attentional capacity.  On the other hand, there are channels of information that  sneak into your mind.  That probably influence you only for a few moments in the  unattended ear, in the cocktail parity. ", "You're actually picking up that conversation because if  they say your name, you'll get it.  Here's an example where your brain is responding to a word  you cannot identify or know that it was presented, and  those things can slightly move your behavior around. ", "But not in a science fiction or marketing dream that they  could make you go do something really big.  OK, that's never been shown and people have  tried to show that.  So attention is really weirder than you think. ", "You don't notice a lot of stuff, but a few things you  don't think are influencing you are influencing you here  and there all the time.  Thanks very much. "], "vid_duration": [10.35, 12.089, 11.301, 11.02, 11.19, 10.81, 12.17, 10.2, 10.18, 12.88, 12.68, 11.67, 10.29, 10.61, 11.49, 12.23, 13.38, 10.15, 13.08, 12.819, 11.971, 13.26, 11.44, 10.6, 13.25, 11.43, 11.29, 10.87, 10.84, 10.33, 10.48, 18.05, 10.09, 13.08, 11.29, 11.33, 11.54, 10.65, 10.38, 10.77, 11.57, 11.3, 12.82, 12.37, 11.6, 10.71, 10.58, 10.1, 12.51, 10.53, 10.89, 12.33, 11.39, 10.91, 11.44, 10.46, 12.84, 12.32, 11.066, 11.614, 10.52, 19.19, 14.11, 10.92, 11.8, 17.78, 10.9, 18.08, 11.11, 12.04, 12.75, 10.73, 11.35, 10.82, 12.19, 10.1, 12.76, 11.68, 10.88, 14.59, 13.66, 10.44, 12.96, 11.47, 10.67, 12.728, 10.422, 11.22, 10.98, 12.19, 12.24, 12.36, 10.05, 11.8, 11.0, 10.62, 10.85, 10.756, 13.794, 10.48, 11.45, 12.36, 12.07, 11.84, 10.23, 11.36, 11.8, 11.25, 11.9, 10.05, 10.74, 10.98, 11.195, 10.935, 10.406, 10.214, 10.92, 12.601, 11.369, 10.73, 10.91, 10.045, 10.595, 11.5, 10.48, 10.38, 10.84, 10.255, 10.985, 10.37, 13.82, 13.48, 11.33, 12.06, 10.5, 10.34, 11.69, 10.87, 11.8, 10.51, 12.06, 11.94, 10.025, 10.171, 15.274, 42.31, 42.81, 18.54, 10.91, 11.49, 10.11, 14.46, 13.3, 14.15, 11.03, 14.14, 10.94, 10.04, 10.89, 11.07, 10.01, 12.24, 10.94, 12.95, 10.3, 10.67, 13.62, 10.94, 10.31, 13.35, 11.81, 10.52, 10.8, 11.52, 11.6, 11.38, 10.04, 10.13, 10.45, 10.07, 12.11, 10.32, 10.64, 11.84, 12.66, 10.92, 10.52, 12.06, 11.55, 10.81, 13.55, 11.99, 11.1, 10.86, 12.81, 10.98, 10.46, 10.83, 11.95, 10.43, 10.06, 11.1, 13.43, 12.43, 10.65, 12.56, 10.0, 11.22, 12.66, 10.93, 6.23], "stet": [[0, 10.35], [10.35, 22.439], [22.439, 33.74], [33.74, 44.760000000000005], [44.760000000000005, 55.95], [55.95, 66.76], [66.76, 78.93], [78.93, 89.13000000000001], [89.13000000000001, 99.31], [99.31, 112.19], [112.19, 124.87], [124.87, 136.54], [136.54, 146.82999999999998], [146.82999999999998, 157.44], [157.44, 168.93], [168.93, 181.16], [181.16, 194.54], [194.54, 204.69], [204.69, 217.77], [217.77, 230.589], [230.589, 242.56], [242.56, 255.82], [255.82, 267.26], [267.26, 277.86], [277.86, 291.11], [291.11, 302.54], [302.54, 313.83000000000004], [313.83000000000004, 324.70000000000005], [324.70000000000005, 335.54], [335.54, 345.87], [345.87, 356.35], [356.35, 374.40000000000003], [374.40000000000003, 384.49], [384.49, 397.57], [397.57, 408.86], [408.86, 420.19], [420.19, 431.73], [431.73, 442.38], [442.38, 452.76], [452.76, 463.53], [463.53, 475.09999999999997], [475.09999999999997, 486.4], [486.4, 499.21999999999997], [499.21999999999997, 511.59], [511.59, 523.1899999999999], [523.1899999999999, 533.9], [533.9, 544.48], [544.48, 554.58], [554.58, 567.09], [567.09, 577.62], [577.62, 588.51], [588.51, 600.84], [600.84, 612.23], [612.23, 623.14], [623.14, 634.58], [634.58, 645.0400000000001], [645.0400000000001, 657.8800000000001], [657.8800000000001, 670.2000000000002], [670.2000000000002, 681.2660000000002], [681.2660000000002, 692.8800000000002], [692.8800000000002, 703.4000000000002], [703.4000000000002, 722.5900000000003], [722.5900000000003, 736.7000000000003], [736.7000000000003, 747.6200000000002], [747.6200000000002, 759.4200000000002], [759.4200000000002, 777.2000000000002], [777.2000000000002, 788.1000000000001], [788.1000000000001, 806.1800000000002], [806.1800000000002, 817.2900000000002], [817.2900000000002, 829.3300000000002], [829.3300000000002, 842.0800000000002], [842.0800000000002, 852.8100000000002], [852.8100000000002, 864.1600000000002], [864.1600000000002, 874.9800000000002], [874.9800000000002, 887.1700000000003], [887.1700000000003, 897.2700000000003], [897.2700000000003, 910.0300000000003], [910.0300000000003, 921.7100000000003], [921.7100000000003, 932.5900000000003], [932.5900000000003, 947.1800000000003], [947.1800000000003, 960.8400000000003], [960.8400000000003, 971.2800000000003], [971.2800000000003, 984.2400000000004], [984.2400000000004, 995.7100000000004], [995.7100000000004, 1006.3800000000003], [1006.3800000000003, 1019.1080000000003], [1019.1080000000003, 1029.5300000000002], [1029.5300000000002, 1040.7500000000002], [1040.7500000000002, 1051.7300000000002], [1051.7300000000002, 1063.9200000000003], [1063.9200000000003, 1076.1600000000003], [1076.1600000000003, 1088.5200000000002], [1088.5200000000002, 1098.5700000000002], [1098.5700000000002, 1110.3700000000001], [1110.3700000000001, 1121.3700000000001], [1121.3700000000001, 1131.99], [1131.99, 1142.84], [1142.84, 1153.596], [1153.596, 1167.39], [1167.39, 1177.8700000000001], [1177.8700000000001, 1189.3200000000002], [1189.3200000000002, 1201.68], [1201.68, 1213.75], [1213.75, 1225.59], [1225.59, 1235.82], [1235.82, 1247.1799999999998], [1247.1799999999998, 1258.9799999999998], [1258.9799999999998, 1270.2299999999998], [1270.2299999999998, 1282.1299999999999], [1282.1299999999999, 1292.1799999999998], [1292.1799999999998, 1302.9199999999998], [1302.9199999999998, 1313.8999999999999], [1313.8999999999999, 1325.0949999999998], [1325.0949999999998, 1336.0299999999997], [1336.0299999999997, 1346.4359999999997], [1346.4359999999997, 1356.6499999999996], [1356.6499999999996, 1367.5699999999997], [1367.5699999999997, 1380.1709999999998], [1380.1709999999998, 1391.5399999999997], [1391.5399999999997, 1402.2699999999998], [1402.2699999999998, 1413.1799999999998], [1413.1799999999998, 1423.225], [1423.225, 1433.82], [1433.82, 1445.32], [1445.32, 1455.8], [1455.8, 1466.18], [1466.18, 1477.02], [1477.02, 1487.275], [1487.275, 1498.26], [1498.26, 1508.6299999999999], [1508.6299999999999, 1522.4499999999998], [1522.4499999999998, 1535.9299999999998], [1535.9299999999998, 1547.2599999999998], [1547.2599999999998, 1559.3199999999997], [1559.3199999999997, 1569.8199999999997], [1569.8199999999997, 1580.1599999999996], [1580.1599999999996, 1591.8499999999997], [1591.8499999999997, 1602.7199999999996], [1602.7199999999996, 1614.5199999999995], [1614.5199999999995, 1625.0299999999995], [1625.0299999999995, 1637.0899999999995], [1637.0899999999995, 1649.0299999999995], [1649.0299999999995, 1659.0549999999996], [1659.0549999999996, 1669.2259999999997], [1669.2259999999997, 1684.4999999999995], [1684.4999999999995, 1726.8099999999995], [1726.8099999999995, 1769.6199999999994], [1769.6199999999994, 1788.1599999999994], [1788.1599999999994, 1799.0699999999995], [1799.0699999999995, 1810.5599999999995], [1810.5599999999995, 1820.6699999999994], [1820.6699999999994, 1835.1299999999994], [1835.1299999999994, 1848.4299999999994], [1848.4299999999994, 1862.5799999999995], [1862.5799999999995, 1873.6099999999994], [1873.6099999999994, 1887.7499999999995], [1887.7499999999995, 1898.6899999999996], [1898.6899999999996, 1908.7299999999996], [1908.7299999999996, 1919.6199999999997], [1919.6199999999997, 1930.6899999999996], [1930.6899999999996, 1940.6999999999996], [1940.6999999999996, 1952.9399999999996], [1952.9399999999996, 1963.8799999999997], [1963.8799999999997, 1976.8299999999997], [1976.8299999999997, 1987.1299999999997], [1987.1299999999997, 1997.7999999999997], [1997.7999999999997, 2011.4199999999996], [2011.4199999999996, 2022.3599999999997], [2022.3599999999997, 2032.6699999999996], [2032.6699999999996, 2046.0199999999995], [2046.0199999999995, 2057.8299999999995], [2057.8299999999995, 2068.3499999999995], [2068.3499999999995, 2079.1499999999996], [2079.1499999999996, 2090.6699999999996], [2090.6699999999996, 2102.2699999999995], [2102.2699999999995, 2113.6499999999996], [2113.6499999999996, 2123.6899999999996], [2123.6899999999996, 2133.8199999999997], [2133.8199999999997, 2144.2699999999995], [2144.2699999999995, 2154.3399999999997], [2154.3399999999997, 2166.45], [2166.45, 2176.77], [2176.77, 2187.41], [2187.41, 2199.25], [2199.25, 2211.91], [2211.91, 2222.83], [2222.83, 2233.35], [2233.35, 2245.41], [2245.41, 2256.96], [2256.96, 2267.77], [2267.77, 2281.32], [2281.32, 2293.31], [2293.31, 2304.41], [2304.41, 2315.27], [2315.27, 2328.08], [2328.08, 2339.06], [2339.06, 2349.52], [2349.52, 2360.35], [2360.35, 2372.2999999999997], [2372.2999999999997, 2382.7299999999996], [2382.7299999999996, 2392.7899999999995], [2392.7899999999995, 2403.8899999999994], [2403.8899999999994, 2417.3199999999993], [2417.3199999999993, 2429.749999999999], [2429.749999999999, 2440.399999999999], [2440.399999999999, 2452.959999999999], [2452.959999999999, 2462.959999999999], [2462.959999999999, 2474.179999999999], [2474.179999999999, 2486.839999999999], [2486.839999999999, 2497.7699999999986], [2497.7699999999986, 2503.9999999999986]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [172, 835, 1084, 1641, 2082, 2504]}
{"example_id": "mit057@@MIT9_00SCF11_lec11_300k", "text": ["And Oliver Sacks, in The Lost Mariner, chapter 2, talks  about one of the two major kinds of amnesia, the loss of  memory due to a brain disorder or a brain injury. ", "But he has a very nice language from Luis Bunuel  talking about memory. \"You have begun to lose your  memory, if only in bits and pieces, to realize that memory  is what makes our life.  Life without memory is no life at all. ", "Our memories, our coherence, our reason, our feeling, even  our action.  Without it, we are nothing.  I can only wait for the final amnesia, the one that erases  an entire life as it did  my mother's.\" Right?  So our memories of our lives, what we've done, where we've ", "been, what mattered to us--  that's a huge piece of who we are.  And he runs into a patient who came into the hospital early  in 1975 with a note saying \"Helpless, demented, confused, ", "and disoriented.\" He had what we call  clinically Korsakoff's Syndrome.  So these are individuals who have severe alcoholism for ", "many years, and a subset of those people develop a severe  memory disorder, like this man.  He's 49 years old. ", "He tells Sacks about his life, details of his life, going  into World War II, that he worked on a  submarine, and so on.  And Sacks says, \"a full and interesting life remembered  visually in detail, but for some reason his memories stop ", "around World War II.\"  Then he asked him, what year is it?  Remember the year is 1975.  And he says, it's 1945.  What do you mean?  We've won the war, FDR--  Franklin Delano Roosevelt-- is dead, Truman's at the helm. ", "These are great times ahead.  And Jimmy, how old would you be?  He stopped and he said, well, I guess I'm 19.  That would have been his age, you know, 20 years ago, right?  30 years ago. ", "So he's stuck in time.  He thinks it's historically a while ago.  He has the completely wrong age.  And Sacks takes out a mirror and throws it at him and says,  what do you--  what happened?  And he says, Jesus Christ, what's going on? ", "What happened?  Is this a nightmare?  Am I crazy?  Is this a joke?  So it's as if he's lost the last 30 years of his life.  And he's living as if it were 30 years ago.  ", "And then when he walks back in, he's hardly recognized.  Sacks is hardly recognized by the person.  On intelligence, he shows excellent ability, but his  memory-- very quickly, he forgets things. ", "What is this, I asked him, showing him a photo in a  magazine I was holding.  It's the moon.  No it's not, if it's a picture of the Earth  taken from the moon.  I'm mean, don't forget, in 1945, nobody imagined that we ", "would be sending up people to the moon, right?  And taking pictures from the moon of the Earth.  You're used to it.  It's nothing to you.  No it's not.  It's a picture of the Earth taken from the moon.  Doc, you're kidding.  Somebody would have to get a camera up there. ", "Naturally.  Hell, you're joking.  How would you know that?  So he has lost the last 30 years of his life, for all  practical purposes, despite normal ", "intelligence and normal thought.  So we're going to talk more about how this occurs in  another patient, and more generally, how the brain  supports your ability to learn things. ", "So here's this remarkable brain.  And in one sense, you could say it's almost all there to  absorb things in life.  You have very small insects that can do a lot with the ", "genes they're given.  We have big brains to learn the life we lead.  And I'm going to come back at the end to this metaphor, but  the idea that in many ways, your brain as you sit there ", "right now, or any healthy brain, is kind of like a  symphony orchestra that has many specialized instruments  for learning different kinds of things. ", "And you feel like a unified whole, and you are, and these  instruments interact with each other.  But just like a symphony orchestra, you know, together  they make a sound.  So imagine you're a Martian who lands outside a symphony ", "hall, and you hear a symphony playing.  It's something beautiful.  It sounds really interesting.  If you're a Martian on the outside of the symphony hall,  how many instruments are you guessing, how many things ", "might you guess, are making that sound?  Would you have any idea?  One big one?  Two big ones?  50?  It'd be very hard to guess. ", "And it's only been in the last 20 years or so that we had  some real clarification on the instruments of  learning in our brains.  So I'm going to talk about three things today.  Anterograde amnesia, the loss of the ability to form new ", "memories; retrograde amnesia, the loss of memories you  already had; and that idea of memory systems, this idea that  each of us has a symphony of learning instruments in our ", "brain that empowers us to learn  different kinds of things.  So anterograde amnesia is, again, the inability to  remember new information.  And people mostly talk about two kinds, but as you see, ", "they're most of life, OK?  Not all of that-- we'll talk about that-- but a lot of it,  such as events you experience or facts you encounter.  So think about this.  All the events you've remembered from your entire ", "life, all the facts you ever learned in school, at home, on  the computer--  that's a huge amount of what you know.  And a patient like we just described or the patients I'll  describe in a moment lose the ability to remember any event ", "from the day they become amnesic or remember much in  the way of new information of any kind, in terms of  facts of the world.  So in what sense is memory in the brain  distributed or localized? ", "In what sense is it in one place or many places?  And this has been a central debate in all of neuroscience,  but in memory, too.  And Karl Lashley, a giant of neuroscience, who worked just  two T stops away at Harvard, said this: \"It is not possible ", "to demonstrate the isolated localization of a memory trace  anywhere in the nervous system.  The engram is represented throughout the brain.\" The  engram's kind of a magic word in memory and the brain. ", "The engram is the thing in you that changes in your brain  that is the stuff of a memory.  If you learn today that there's more terrible news in  Japan with the nuclear reactors, and you remember ", "that because it matters to you, because you care about  the people, there's a physical change in your brain that is  the memory.  If you remember what I'm saying now for more than a few  moments, that is a physical change in your brain. ", "So all of us in neuroscience are amazed by that.  How can we physically change the brain to be the biological  record of a memory, that we can keep  and use in the future?  And the engram, Karl Lashley said, is represented ", "throughout the brain.  It's spread throughout the brain.  Here's why he thought that.  So he was working with rats, and they ran a maze.  And you saw how quickly you learned the maze to go from  start to finish to get the food if you're a rat. ", "And here's what he found, and the results won't amaze you,  to start with.  So what he did is he made--  this is number of errors during learning, so  it's good to be low.  And this is how much neocortex they took out, ranging from ", "10% to 80%.  And he discovered that the more neocortex you took out,  the worse learner you were.  Now if it didn't happen in some broad sense, we'd say,  well, what part of us is learning it? ", "You take out more brain, you're less of a good reader.  10% out, 10% percent bad memory.  50% of brain out, 50% of bad memory.  80% of the brain out, 80% bad memory, right?  OK, that makes sense. ", "But what he was really impressed by is it didn't seem  to him to matter where he took the brain out of the rat.  It just didn't matter.  It's just the percent that he took out. ", "Whatever percent he took out is how bad  the learner you were.  And we'll come back to that, but that's why I said, it must  be spread everywhere, because wherever I take out brain,  part of the memory is weakened or disappears. ", "And sometimes people call that mass action for distributed  memory, that's spread throughout the brain  in this mass way.  It's just spread all over the place.  And a single clinical case-- ", "I'll spend a few moments on him for two reasons.  It is the historical case that turned this around, and I have  a particular perspective on this because when I was a  graduate student, I did a lot of work with this single  patient whose case turned around our understanding of ", "the mammalian brain and memory.  So as I start to talk about it--  I can't tell you what Phineas Gage was really like, beyond  what I read, OK?  Or Broca's patients from the 1900s.  I can tell you what HM, the man we're about to talk about, ", "was like because I spent many, many hours with him, two  blocks from here, when I was a graduate student in Suzanne  Corkin's lab.  So the structure we'll focus on is something called the  hippocampus.  It looks sort of big in the picture. ", "It's about the size of about 2/3 of your thumb, one on the  left and one on the right in the insides of the medial part  of the temporal lobes.  A pretty small percentage of the brain. ", "And you can see it's located here.  Here it is sort of drawn out.  And here's the story of this man.  He died a couple years ago.  There's lots of plays and movies and books in the works. ", "I can also tell you that when I was a graduate student here,  my fellow graduate students would say, tell us who HM,  what his initials really stand for, as if it really mattered,  particularly.  But I felt privileged to have the secret knowledge of what ", "his name was.  When he died, they published it.  Everybody knows now, so my secret is out.  Or our secret is out.  He was born in 1926.  At age 16 he had his first major epileptic seizure. ", "By age 27, he was having many, many seizures a day.  You can have petit mal seizures, where you tune out  from the world.  You can have grand mal seizures that lead to physical  convulsions. ", "By age 27, the medications were not helping him, in 1953,  very much, that were available.  And he was just sitting in his house just waiting for the  next seizure, basically.  That was his life. ", "He was a man of normal intelligence and fairly  typical, average background.  Nothing remarkable.  And in order to treat the epilepsy, William Scoville,  the surgeon, resected, or took out surgically, the tissue. ", "Here's this cartoon of what he took out--  the hippocampus, also the amygdala just in front of it,  also tissue that surrounds it.  And the reason he took it out is the single most likely ", "place where epileptic seizures start is the hippocampus.  It's kind of a signal, in many ways, that the hippocampus  does something very dangerous.  It's operating in some sort of fast speed lane of ", "neurobiology.  It's a very sensitive part of the brain, for lack of oxygen,  for diseases.  We'll talk about Alzheimer's today.  It's a very vulnerable part of the brain, but it does ", "something magical and essential for memory.  And so they couldn't locate where the seizures were  starting, very well, from him in ways they typically do, so  they said, OK.  He has all these seizures.  We don't know what to do. ", "Let's take out the left and the right hippocampus and the  surrounding tissue.  And in terms of seizure control, it was pretty  successful.  He had to stay on medications from that day 'til a few years ", "ago, when he passed away.  But he had very, very few seizures  compared to before that.  So it was medically very successful in  terms of seizure control.  It had a giant side effect. ", "From that day 'til a couple years ago, HM never formed a  new memory for any event, or for all practical purposes,  for any fact that he was exposed to ever again, despite ", "his normal intelligence and his  otherwise intact abilities.  So they took an MR of HM.  It took a long time to decide they could even take a MR ", "picture of HM, because they were very worried that if you  put him in a MR scanner, there's magnetic fields, and  often they put in clips after surgery.  Regularly they put in clips after surgery, to keep the ", "vessels from bleeding.  And they weren't sure what the clips were  made of for a while.  And so they said, well, we can't put him in, because we  could move the clips and kill him, which would be bad. ", "So they thought it was dangerous.  And they did a huge detective process of going to factory  that made them and talking to people who built it before  they decided-- it took, like, 10 years of research to decide  that the clips were not metal and they could take an MR. ", "And even here-- here's the top of the brain, normal person.  Here's the hippocampus, the small structure in you--  pretty small.  It's removed in him, but you can see he's got a lot of  brain left, except for these removed structures. ", "But what happened was he had such a fantastic impairment of  learning new information, it got the  label of a global amnesia.  Global amnesia.  It didn't matter whether tests were hard, like remembering ", "stuff or multiple choice.  He failed practically every standard test of memory you'd  ever give a person.  Or if it's words or nonsense syllables, faces, clicks,  mazes, public events, assassinations of presidents, ", "wars, going to the moon, whatever  you think of as famous--  he didn't know they happened at all.  Personal events.  The death of his own parents. ", "If you asked him how his parents were doing, he would  say something like, I haven't seen them for a while.  He would not know they had passed away.  So no matter how publicly famous something was, no  matter how personally important it was, that ", "knowledge--  he could remember it for a few seconds, and we'll talk about  that more, but it would drift away  completely within seconds.  No matter how often he heard it, no matter how personally  important it was. ", "And you could say, what does he say his experience is like?  So Brenda Milner, the neuropsychologist, who did a  lot of the critical original research with him, describing  his case said that he's said, \"Every day is alone in itself, ", "whatever joy I've had and whatever sorrow I've had.\" I  mean, it sounds very poetic, and it's true, except that for  HM, his memory lasts seconds.  So he doesn't remember any day since 1950 or something. ", "So I think his experience is more like this. \"Right now I'm  wondering, Have I done or said anything amiss?  You see, at this moment, everything looks clear to me.\"  His mind is clear.  He's smart. ", "\"But what happened just before?\" What happened a  minute ago, or two minutes ago, or five minutes ago?  \"That's what worries me.  It's like waking from a dream; I just don't  remember.\" All right? ", "So when we worked with him here, a few blocks from here,  he wouldn't know who I was.  He wouldn't know why he was here.  He was an extremely pleasant and wonderful research  participant. ", "A piece of that was-- he was very nice and very pleasant.  A piece of that was he didn't know time was passing.  So if any of you are involved in experiments as  participants, sometimes people enjoy the experiment for about ", "five minutes but not for the next 55, because they're  getting a lot of measurements to get a good measurement.  For HM, it was never an hour-long experiment.  It was always a minute and a half experiment. ", "So you had to be very careful not to abuse that situation as  a researcher.  So here's his name, Henry Molaison.  Here's his pictures from his youth and from this. ", "But you see how he had a complete reversal?  All of a sudden, the removal just two small regions-- the  left and the right hippocampus in the brain--  stopped the creation, of formation of new memories ", "altogether and in any practical way.  So that shows you that memory's not spread throughout  the brain in a sort of undifferentiated mass-action  way, but that particular parts of the brain play very ", "particular roles in how memories are formed.  And the hippocampus plays a huge role in that.  Can't see it.  So they had a big project where they brought him from  the nursing home in Connecticut where he was. ", "They drove him by ambulance to  Massachusetts General Hospital.  They overnight did a something like an eight hour MRI scan on  him, to have the world's most detailed MRI scan you ", "practically have on anybody.  And then they removed his brain and sent it to a  laboratory in San Diego, where they took his brain and they  sliced it into many, many, many incredibly thin slices ", "that they're going to post on the web.  And on the web for quite a while was the  slicing of his brain.  He consented to this, all this research effort, and finally ", "his brain is a gift to research and understanding the  brain and memory.  ", "So let me tell you a couple of experimental results from him,  and then you might think of questions you have about what  a man like this is like, OK?  So we talked about last time about that if you give a list ", "of words to people, and you try to do it yourself, that  people remember the first words best--  the primacy effect, a long-term memory effect that's  not affected by adding a few seconds of delay--  and a recency affect-- ", "superior memory for the last few words of the list that's  strongly affected by adding in just 10 seconds of delay from  the last word until you recall.  And this is done with other amnesic patients, and not HM, ", "but a similar disorder.  You can see that their memory is worse overall--  there, the dark line--  but they have some benefit from the  beginning of the list and--  but it's small.  It's not the same as the control-- ", "but they're completely normal, completely normal for the last  two or three words.  So this is what we mean by impaired long-term memory and  spared short-term memory.  But the short-term memory's just moments. ", "But it's not just an impression you have.  It's a scientific experiment you can do.  Here's another--  we did this last time.  We said, if you read digits to people and ask them to repeat ", "them back aloud, that we have a limited short-term memory of  seven plus or minus two.  People get to about seven or eight, typically.  So there's a mean test that's given to look at something. ", "So here's what they do.  Imagine that you do this test, and you were correct for two  digits, correct for three, repeating them back after you  heard them.  Four, five, six, seven, you did well. ", "And then you made mistakes at eight, which would be very  typical for a human.  So your span, therefore, is seven.  That's how much you can hold in short-term memory. ", "It varies a little bit from person to person.  And now they're going to do all the rest of the experiment  at one beyond your span.  One beyond what you can do.  One beyond what your short-term memory-- ", "here's the limit of your short-term memory.  Let's add one thing.  And one thing that we know helps memory is repetition.  It's not the best way to learn things, but it is a powerful ", "way to learn things.  So now they give the entire experiment with eight digits  at a time for this person, one beyond what you could report.  So they give you this, and they give you this. ", "But they give you one boost, which is every third one, it's  the same sequence over and over again.  So some you hear once and once only.  And one, you hear over and over again. ", "Is that OK?  Now what would happen if you think, if you hear eight  digits over and over again?  What would happen?  You know this in your own life.  Your Social Security number, telephone numbers, things-- ", "what happens?  Can you learn eight digits if you do it over and--?  Yeah.  It wouldn't be easy, but you get it with repetition.  So here's what happens in typical people. ", "Here's the repetition.  Here's how well they do for the  non-repeated super-span ones.  They never get that good because they  basically can't do that.  Occasionally they get lucky, but mostly not. ", "But the ones that repeat, they get better and better.  So repetition is another way to break the bounds of  short-term memory and register something in long-term memory.  But in HM, they did this for hundreds of trials, and he ", "never got better at the repeated series.  So you could do endless repetition with him, or it  could be personally important.  He wouldn't remember it.  So let me add one more piece to the story. ", "If I talk to you and say, here are the digits, tell that back  to me, that's an auditory-verbal experiment.  So they're words, and you're hearing them.  You can also test short-term memory and long-term memory  using a visuo-spatial test of blocks. ", "So you're seeing what the examiner sees, with numbers on  the back of each of these.  The person taking the test just sees these blocks as  black boxes without any number. ", "You need that because you have a piece of paper with numbers  on it that tell you what to tap.  OK?  So when you give this test, you might see five, seven,  eight, and you would tap with your hand, five, seven, eight, ", "and the person would tap that back.  And I can tell you what made me pretty nervous when I gave  this test to a person who had a long one?  Because I'd have to read the numbers, practice it, and I'd  be desperately trying to get eight my head, which I could ", "barely do, maybe.  Because I could tap eight back, so if a person was--  and then we'd do the same thing.  We'd say, if you can do eight, we'll test you at nine and  repeat them. ", "And here's two findings, and let's talk  about HM for a moment.  So one finding is now, in patients now-- we're going to  switch one thing a little bit.  HM had the left and the right hippocampus removed. ", "In these patients, they had either the left  or the right removed.  Either the left or the right.  So here's what happens for normal controls, for the  numbers that are beyond their span.  Not too good, low performance, but they benefit from ", "repetition.  Here's what happens for the patients with left hippocampal  removals for the auditory-verbal  things for the digits.  ", "So they're good for immediate memory for this stuff, but  they're terrible at developing a long-term memory over here,  if it's verbal.  But the patients with the right temporal  ones are just fine. ", "For spatial things, it's exactly the opposite.  The group that's really impaired are the patients with  a large right hippocampal removal, and the people with  the left hippocampal do just fine. ", "So we have two separations in the brain for learning things  in the medial temporal lobes.  Neither the left nor the right are involved in short-term  memory, short-term memory lasting only seconds. ", "The left is important for verbal long-term memories, and  the right is important for long-term spatial memories,  which is very consistent with what we know about left and  right hemispheres for verbal and spatial knowledge. ", "So let me say a word more about how we think about the  organization of memory, and we'll come back to this chart.  So we're talking here, so far, about what people call ", "declarative or explicit memory.  You study some material, you get tested on it.  What did you study?  And people sometimes make a difference between  two kinds of things.  So episodic memory might be if I ask you-- ", "OK, I need a volunteer in your seat.  It's really easy, this one.  ", "OK, thanks.  I saw some people getting ready to go.  Well, OK.  OK, what did you have for breakfast this morning?  And you don't have to answer honestly if its embarrassing. ", "You can just give us a standard--  (LAUGHING) I'm not looking to make--  yeah.  AUDIENCE: Cereal.  PROFESSOR: Cereal.  How about you?  AUDIENCE: What?  AUDIENCE: Yogurt.  PROFESSOR: Yogurt.  Cereal and yogurt.  Two excellent healthy answers.  OK.  So now I'm going to ask you-- ", "if I could ask you first.  How many feet in a yard?  AUDIENCE: Three.  PROFESSOR: Excellent.  OK.  And now I'm going to ask you, when and where  did you learn that? ", "OK?  And you might go, I don't know.  I just learned it.  Right?  Or if I ask you, capital of France.  AUDIENCE: Paris.  PROFESSOR: Paris.  Excellent answer. ", "When was the shocking moment when this was revealed to you?  When you said, I'll never trust the world again--  yes.  Who knows, right?  So what you're learning is, episodic memory is memory for ", "specific events, like what I did last night, what I had for  breakfast, specific time and place.  Semantic memory is what we could call generic memory.  We know lots of things about the world, but we might not ", "know when or where we learned.  So that's a distinction psychologists find useful to  think about.  So how about in HM?  We said he can't remember digits, or faces,  or things like that.  How about generic memory? ", "So here's an experiment that I was involved in, where we  said-- because there were some debates  about this at the time.  So we gave HM a multiple choice test where he saw words ", "or phrases that entered the language after the onset of  his amnesia.  So we thought he wouldn't learn them, but we didn't know  for sure, from just everyday experience.  And by the way, I should tell you, he watched tons of ", "television.  What his experience was like watching television is an  interesting question.  You should be thinking now about questions you want to  ask about HM.  In a moment, I'll come back to that.  But look at-- so, he has four choices for the word ", "amniocentesis, including the correct one, but he picks \"an  infectious inflammatory disease of the  intestines.\" apartheid?  In front of him is the correct answer, two other answers, and  he picks, \"the separation of young cows that have not yet ", "given birth to calves.\"  Boat people? \"People who cater bon voyage parties,\" which is  completely the wrong--  Brainwash, \"a fluid that surrounds and bathes the  brain.\" Granola, \"a portable keyboard wind instrument.\"  Software, \"expensive clothing made of a soft, twilled ", "fabric.\"  What's going on with him?  Are these, like, crazy weird answers?  Or how would you-- what do we think is going on with him? ", "Why is he picking these?  The other one is right in front of him.  What's he doing?  AUDIENCE: Looking at words he knows.  PROFESSOR: Yeah.  He's doing what teachers teach you in school.  Take apart the word into its parts, right? ", "And so he goes, software, soft clothes that you wear.  But what does that mean?  He's missed, in every sense, the advent of computers and  software in the world. ", "The idea, the concept, the words--  it's as if it didn't exist, because in 1953, although  software existed, it wasn't a very popular concept.  Most people didn't know about the concept of that.  In 1953-- ", "the way we looked at these, these were not words that were  in the dictionary in the 1950s.  So now, what would you like to know about a man like HM?  ", "Yeah.  AUDIENCE: So obviously he couldn't remember something  that happened two hours ago, but if you're having a  conversation with him, would he not remember what you guys  were talking about?  Or could he remember the context of the conversation? ", "PROFESSOR: Right.  So you're saying, he wouldn't remember something two days  ago, but you're talking with him.  What's that like?  Right?  So let me give you one experimental  thing and then an exper--  so one experiment they did is they left him with something  like six numbers, well within the span, and said, remember ", "these numbers.  And it could be, you know, 1, 2, 3, 4, 5, 6-- well, that  wouldn't work so well.  2, 4, 6, 8, 9.  2, 4, 6, 8, 9.  They leave the room for 15 minutes.  They come back in. ", "He's an excellent subject.  He's going, 2, 4, 6, 8, 9.  2, 4, 6, 8, 9.  What were the numbers?  2, 4, 6, 8, 9.  They go, that's excellent.  Was there any trick you did to do that?  Or did you just--  And he'd go, oh, oh, oh.  What were the numbers? ", "As soon as a thought is out of the forefront of  his mind, it's gone.  So, yeah.  He would not recognize us, and we spent many hours with him. ", "A striking thing, which was amazing at first and then  sometimes irksome if you worked with him-- and he was a  delightful guy--  was that he would tell you a story from his past.  And he didn't have a huge array of stories, because they  were all from a long time ago. ", "And he would tell you about a gun collection he had.  And he would tell he had three guns, and they had this  property and that property.  He'd finish the story, and if you just stayed quiet for a  moment, he would forget that he told you the story, but it ", "would be vaguely on his mind because he  just told it to you.  And he would say to you, hey, did I tell you about my gun  collection?  And he would tell you, almost verbatim, the same story.  You'd just wait a moment.  He forgot that he told you this story, but it's slightly ", "on his mind because you just told you it.  And he goes, hey, did I tell you my--  he could tell you this until you could bear it no longer.  So it was kind of amazing how short his  short-term memory was. ", "Without this part of the brain,  it's just a few seconds.  His conversations were OK, but I would  call them pretty shallow.  I don't know how to put it.  You know, when you talk with somebody and you're on the ", "phone, and they're doing something  else, and you can tell--  for him it was a little bit like that.  He was-- so, good social convention.  He would smile.  He would chat with you.  But if what you were talking about depended on remembering ", "something from three sentences ago in any detail, gone.  Just seconds, unless he's practicing and practicing and  practicing without doing anything else.  Yeah.  AUDIENCE: So he did have the capability to learn ", "procedurally.  PROFESSOR: Yes.  We're going to come to that.  So the question is, did he ever learn-- he had other  kinds of learning that were amazingly  completely normal in him.  Procedural memory, you're absolutely right.  And we'll come to that just in about 20 minutes, OK? ", "Exactly right.  And if I don't answer that well, make me do that again.  OK?  But yeah.  Yeah?  AUDIENCE: Was he able to remember that he couldn't  remember things?  PROFESSOR: Yeah.  Really good question.  Was he able to remember that he couldn't remember things? ", "Yes, he knew he had a bad memory.  So now the question is, in what sense did he know he had  a bad memory?  Like, I know I can't draw very well, amongst many other ", "things I can't do very well.  But if you talked to him, he'd say, yeah, I  don't have a good memory.  But he's looking at you, and he's going, like, I don't know  where I am, who you are, or what I'm doing. ", "Everything is vague, for many, many years.  I must have bad memory.  Like, you would too, like a science fiction movie.  You woke up, you didn't know who you were, where you were,  what you were doing, and you can't remember anything except ", "from the most distant past.  You'd go, something is not good with my memory.  But you're smart, so you would know that.  What I don't know is if you woke him up at 2 AM and you  said, HM, how's your memory?  I don't know if he'd go, well, I'm a famous amnesic, of ", "course it's terrible.  I don't know if he knew it as a fact, like we might know  about what we're good and not good at, or he just knew it by  constantly being aware that he didn't know anything he ought ", "to know via memory.  Does that make sense?  Anything else about--?  Yeah.  AUDIENCE: How does one explain scientific consent to--?  PROFESSOR: Oh, this is good.  It's a very interesting question. ", "Informed consent.  So technically he was conserved by the state once  his family had passed away.  But, you know, his intelligence was fine, so you ", "had to be a little bit careful to do it right.  But you could tell him, we're going to do an experiment.  We're going to test your memory for words.  Is that OK with you?  And he'd say yes.  Of course, if you had him read a 12-page document, by the  time he got to page 12-- but you could talk him through it.  His intelligence was fine. ", "You could worry about the edges, if there--  so I think the investigators felt an extra ethical thing,  also, not to ask him to do anything that a person ", "might say no to.  He was a wonderful participant, but it was an  extra responsibility for the reason you're saying.  AUDIENCE: Does that mean he was happy all the time?  PROFESSOR: Was he happy all the time? ", "Excellent question.  He was a very sort of mellow--  yeah.  Well, you could think for a moment whether having no  memory would make you happy or sad.  So he couldn't hold a job.  He couldn't sustain a human relation because he would ", "never know he'd met you before.   So, those are things we often think of as pretty big in our  happiness, the kind of the work we do, in some broad  sense, and the people we relate to, right? ", "And those were all gone for him.  On the other hand, he didn't exactly realize that.  He didn't realize he didn't work.  He didn't realize he didn't have relations he might be  expected to have, because he'd forget that about as fast as ", "he could think about it.  So I--  he was kind of a very, I would say, mild, happy person.  So there's three possibilities that crossed my head. ", "And scientifically, we can never figure them out.  One of them is, maybe just he was that way.  I mean some people are just mellow and happy, right?  They don't have-- without amnesia. ", "Second possibility is-- he had removed, also, the amygdala.  We'll talk about that later in the course.  That's a structure that's pretty important for some  aspects of emotion and feeling.  So that could have been relevant. ", "The third one is, but this is kind of getting to your  question, which was just--  intuitively, I feel like this.  Again, this is not science but is just a feeling.  That what makes us mostly sort of happy or sad? ", "For me, it's mostly relatively recent things that went well  or didn't go well, or things I'm sad about recently, and  things on my horizon.  Things I'm worried about, or things I'm looking forward to. ", "And you guys might be different, but I don't get  that worked up these days about second grade.  At the time I'm sure it was pretty emotional about it.  So if you think about him, he doesn't remember anything ", "recent that was good or bad.  He doesn't remember anything coming up that's interesting,  or threatening, or risky, or unpleasant.  So he lives in this constant now. ", "You know, people tell you, live in the moment.  Nobody could have lived more in the moment than he did.  It's impossible to live more in the moment when the  previous moment you can consult is from  30, 40 years ago. ", "So, yeah, he was pretty happy, and a pretty pleasant guy.  Essentially, I don't think most of us want that life,  although he's probably happier than many people who have all  their memories.  One thing he's the opposite of, just to remind you-- ", "we talked about it now, but just to make it clear-- it's  the opposite of television amnesia.  What happens in soap operas and murder movies or comedy  shows when they get bonked on the head?  ", "Television amnesia.  They forget who they are and where they came from, right?  And then they marry their worst enemy or something like  this, to make the story go forward.  That's television amnesia. ", "But after that, they're kind of fine, right?  They're kind of operating but they just  forgot where they come--  that we never see after brain injuries.  We never see a person who forgets who they are but gets ", "around fine in the world.  HM is the opposite.  He remembers stuff from before, but he  can't learn new things.  Opposite of TV amnesia.   Any other questions about HM? ", "Yeah.  AUDIENCE: As he got older, could he recognize  people from his past?  AUDIENCE: Yes, and let me talk a little bit about that.  If I don't answer that, let me know.  So let me talk about this. ", "This sort of touches on this, loss of already-known  information.  And if I don't answer you well, just put your  hand up again, OK?  So it's easy to test learning new things, because you can ", "give somebody something in the laboratory and you see  if they learn it.  Knowing things they should have known from  before is much harder.  Different people know different things, in the past.  So here's how they'd test it.  And here's a thing that people have discovered, which is ", "people are pretty unknowledgeable, mostly, about  faces of people who were famous at the  time they were famous.  But if you're, like, 20, you don't know people who were ", "famous before you were born.  Mostly.  There's some exceptions.  So they'd take faces from different decades, and they'd  show you them and they'd ask you, do you know who this is?  So do you know who this is? ", "This is Lindbergh.   Frank Sinatra.   Bob Hope.  Does that name even ring a bell?  I know. ", "This is totally--  however old you are is totally how you do on this test.  Lyndon Baines Johnson, president of the United States  after Kennedy. ", "Douglas MacArthur, the general.  This, you might.  Richard Nixon.   McCarthy, as in McCarthyism. ", "Golda Meir.  Elvis.  OK now.  If you--  pretend you became amnesic.  You became amnesic.  Pretend you're old enough to become amnesic in 1990. ", "This is if you're feeling--  would you know this face, in 1990?  Let's say 1980.  Let's make it simple.  1980?  No.  Would you know this face? ", "No.  OK.  But you know them now.  So that tells you that you can put faces to decades, roughly.  You know, 1980, only Barack Obama's family knew Barack ", "Obama's face, right?  And now we all do.   Temporally limited retrograde amnesia.  So this is how well you do-- higher is better--  in decades.  In 1960, here's HM. ", "So here's faces that were famous in the '20s, '30s, and  '40s, before he became amnesic,  and he's pretty normal.  These are public faces.  And then he's terrible for the '50s and ", "'60s, after his amnesia.  So his memory for faces from the past is pretty normal.  His memory for faces from the onset of his amnesia forward  is terrible.  Is that OK?  Does that answer your question reasonably? ", " But here's another really weird thing that people  observed in many cases, which is kind of hard to understand,  but it's been observed in many cases. ", "So here's another patient.  He was a bus driver in Washington, DC.  He moved to work in a drugstore in Boston, then a  mattress factory in Boston.  Then he was hospitalized at the Boston VA in November 1965 ", "with a huge hematoma on the right temporal parietal-- a  big bleeding.  And he was pretty aphasic and stuporous.  He couldn't answer questions.  In a month, digit span, his short-term memory returns. ", "He states the date as approximately something like  September 1965.  He has a severe anterograde amnesia.  For example, he fails to learned the names of the ", "nurses he sees every day.  But when asked-- this is the striking thing.  When asked, where do you live?  He says, I live in Washington, with certainty, as if he lost  all these memories from before. ", "By March, he starts to learn the nurses' names.  He's recovering his memory capacity.  He couldn't remember that he'd moved to Boston, but he  doesn't fight the idea that he lives in Boston. ", "Then he remembers that he worked at a drugstore.  Then he remembers that he worked in a mattress factory.  And by the time that he's discharged, it's only the last  24 hours before he went into the hospital that he's lost.  So two things.  There's a coupling between the anterograde amnesia and the ", "retrograde amnesia.  He can't learn new things, but he lost old things.  And as the anterograde amnesia resolves, the retrograde  amnesia resolves, in some sense, in temporal order.  It's really odd, but it's been observed many times. ", "So there is some link between what the hippocampus does and  memory for the past.  Now in some ways, it's really hard to study these things in ", "detail in a patient like HM.  But some other patients give us another perspective.  Although every one of these examples is not quite perfect.  Here's patients who undergo treatment for depression with  electroconvulsive therapy. ", "And appropriately--  in movies like One Flew Over the Cuckoo's Nest, wrongly  used electroconvulsive therapy is wrong.  For some patients with severe depression who fail to respond ", "to medications and who have suicidal ideation--  literally attempt to take their lives or talk a lot  about it in a believable way to family and physician--  electroconvulsive therapy can be very helpful. ", "It's a hard choice to make, and a complicated one.  Here's what happens.  Patients typically go-- and it varies-- but they go in for  the electroconvulsive therapy.  And nowadays, it's done, typically, only in the right ", "hemisphere.  In this study, done some years ago around  1972, it was bilateral.  They put electrodes on both sides of the brain.  They passed current and they induced a seizure. ", "And they do that something like every second day for  about 10 days.  It's a very aggressive form of treatment, certainly.  But for some patients, the depression just lifts, and  they're no longer talking about taking their lives. ", "So for some people it seems to work when other things don't.  During the course of the treatment, these patients  develop and anterograde amnesia.  They become HM-like.  While they're in the hospital, they become HM-like. ", "They can't learn new things.  They forget the nurses.  You can test them formally.  And so Larry Squire did the following experiment with  these kinds of patients.  So we don't know that it's the hippocampus that's the ", "critical thing in these patients, but they  look a lot like HM.  And we know that the hippocampus has  a low seizure threshold.  That's why it occurs so often as the locus of epilepsy. ", "So what they did is they took television shows.  And this is another world than you can possibly imagine.  I grew up in a world where there were basically three  television stations.  And you're feeling sad for me already, right? ", "And so everybody knew what was on those  three television stations.  But they took shows that weren't very successful, that  were on for one season only.  So they weren't super popular, but a lot of people saw them. ", "And there were only three television  networks and stations.  So now what they did is they tested them on these events or  other things like that before they had ECT-- so this is ", "their knowledge before they had ECT.  Of course they remember recent things, 1971, better than  stuff from years ago.  We all do.  But the striking thing is that when these patients got ECT, ", "during the course of their amnesia they only lost memory  for TV shows from the last two years.  They didn't lose those memories.  These are the very same patients.  The very same patients before they got ECT and while they're ", "getting ECT, they lose memory only for the last two years of  TV shows and not all the other ones.  Or the same thing you can do with famous public events.  So this is what people call a ", "temporally-limited retrograde amnesia.  It goes back for some years, the knowledge you already had.  And here's the amazing thing.  When these patients go home, their memory largely comes  back and so does their knowledge of the TV shows. ", "It's as if it's in their brain.  They don't have access to it, for the last two years of  information.  But it's still sitting there and they regain that access.  Two more examples on this. ", "So here's an example--  because with humans it's always tough.  So they do the same thing with monkeys.  With monkeys, they could create a surgical lesion like  HM and train them on material.  They knew exactly what they learned. ", "Here they had the surgery either 2, 4, 8 or  12, or 8, 16 weeks.  And you can see the monkeys with the hippocampal damage  were performing poorly if they learned the material 2 or 4 ", "weeks ago but not 8 or 16 weeks ago.  Again, a temporally-limited retrograde amnesia.  So we're getting the idea that the hippocampus is important, ", "not only for forming new memories--  and this is kind of wild.  It's still important for you to remember stuff from a week  ago, a month ago, and a couple years ago.  And it takes years for your memory to become independent, ", "or what people call consolidated, so that it no  longer depends upon the hippocampus.  So the hippocampus both is required to form a new memory,  and it seems like it's necessary to remember that ", "memory from months to years, before that memory becomes  independent of the hippocampus.  So right now in you, it's as if you had a neurochemistry  team finishing your memories from the end of eighth grade. ", "We're done.  We're moving on to ninth grade!  Because it takes years for your hippocampus to no longer  be required to get those memories that you  acquired years ago. ", "And the same thing-- they did these famous faces, like the  ones I showed you before?  So these had to be somewhat older people.  Here's activation in the 1990s, if they were looking at  famous faces and the experiment was done in the ", "late 1990s.  So recent faces, hippocampus turned on, but not for '80s,  '70s, or '60s, or '50s, or '40s.  Again, they said the hippocampus is required to  retrieve memories that's in the rest of your brain for ", "some time period, but then after much time passes, it's  no longer required.  So this just summarizes those things.  So now, Tyler, if we could do the film.  We're going to how you an amnesic patient.  Most amnesic patients are like this man. ", "Very intelligent, very verbal.  Not dramatic, but with terribly impaired memory.  ", "So last part of the talk is this idea of memory systems  and procedural memory, the idea that you're a symphony of  the neural systems that learn different things.  So your brain is like the university, right? ", "Department of Chemistry, department of Biology,  department of Brain and  Cognitive Science, or Economics.  In you are multiple very specialized learning circuits  that are good for learning different things.  So this idea of a memory system, a particular part of ", "the brain that has a particular learning process.  And a key concept in that is, so far we've been talking  about what people would normally call memory--  explicit or direct testing. ", "You know, what did you study?  What year is it?  You're asked directly to do something.  But another way to show memory and learning is through  changes in performance with practice. ", "So people will sometimes call the first kind declarative  memory, where you directly have conscious memory about  facts and episodes.  You know that you know something, or  that something occurred.  And then the other kind, we'll talk about now, procedural ", "memory, accessible only through performance and  knowing how.  Now with these kinds of skill learning or procedural memory,  we see how people get better when they practice.  Getting better is a change in your behavior that's learned ", "and a change in your brain that performs.  This is for your performance.  So here's the experiment that was the original one Brenda  Milner did with HM, where you have to  trace a star in a mirror.  You see your hand in a mirror, but you don't have direct view ", "of your hand.  Have any of you done something like this for some odds and  ends reason?  Anybody?  Sometimes--  do I see a hand?  No.  OK.  It's surprisingly hard. ", "The horizontals and verticals are pretty easy.  The diagonals, as you move your hand, you  go, oh, it's no problem.  I just reverse everything.  And you see your hand just drift the wrong way.  And you go, OK, no, no, no, no. ", "I just have to go 45 degrees difference.  I can do it.  And you're controlling your hand, but then you move again  and it still goes the wrong way.  And so at first, you make lots of mistakes.  We understand this because you have such automaticity between ", "what you see and how you move all the time, that the mirror  reverse, you have to overcome that automatic relationship.  So at first you make a lot of mistakes and move slowly.  You practice, and you get better.  Here's the remarkable thing with-- so here's HM. ", "Each of these dots is the next time he does it consecutively.  He gets better from doing it over and over again.  That's not a shock.  Here's the shock.  He comes the next day, he keeps the learning he had and ", "he gets better.  He comes in day three, he keeps learning.  Now for him, a day is like infinity, for memory.  When he comes in the room, he says, what do I do with this?  You'd go, well, we did it the last two days. ", "Don't you know?  He said, no, I have no idea.  Have you done this before?  No.  You can give him multiple choice of different things he  might have done.  He'll pick the wrong thing.  When you come in on day three and you're this good, you're  pretty proud. ", "In fact, vain.  You're going, like, I can do this.  I'm awesome.  Just let me at it.  Because you know that you did it.  You know how good you are through practice.  He has no idea, but his learning is entirely normal. ", "Not just better than you'd think?  Just as good as you.  So a memory system in his brain, different than the  hippocampus, has kept that memory, uses that memory. ", "And the amazing thing is that this means that that's also  true in you, as far as we understand these things.  When you learn a physical or mental skill, a lot of it is  learned in a way that has nothing to do with your memory ", "that you learned the skill.  It's all by doing.  And it doesn't depend on the hippocampus.  And some years later, I did this again a little bit.  Here's his performance first, second, third day, a week ", "later, two weeks later, and a year later.  Complete retention for a man who can forget within moments.  A year later, a skill.  He forgets that he did it ever within moments. ", "So another kind of task that people do-- same idea.  A motor skill you can lose, it's called rotary pursuit.  There's a disc like this that revolves around a platter that  turns pretty fast.  Your job is to maintain contact between-- ", "this was sort of sad before video games, right?  This is about as interesting as 1940s games got.  It was whizzed around, and it's fast enough that it's not  easy to do.  And at first your hand goes off it, but with practice you ", "get really good at revolving with a rotating disc.  And HM and patients like him learned that very well.  Another motor skill.  So who's bad at learning this? ", "Which part of the brain is your instrument for learning  skills through practice?  So our best evidence comes from patients with a very  difficult disease called Huntington's disease.  It's a genetic rare disease.  Its onset is in the 30s or 40s. ", "These patients get severe motor problems and movement  problems, and then, over time, cognitive ones  and psychiatric ones.  There's no treatment for it. ", "So this is the caudate withering away in a patient  with Huntington's disease compared to a healthy  person's, post mortem.  Or if you look at an MRI, here's your basal ganglia. ", "Here's the withered away basal ganglia in the patients with  Huntington's disease.  And there's a brief--  can we do, Tyler-- there's a brief video of a patient with  early-stage Huntington's disease. ", "", "So it's not the most severe problem they have, but when  they do one of these motor kinds of tasks--  here's normal typical people learning a motor task, getting  better on it.  It's good to be high on this graph. ", "Here's the patients with Huntington's disease showing  no learning at all.  And this is a test that an amnesic  patient would learn normally.  So very convincing-- and you could say, well, if they have  a motor problem, they're not going to get a motor skill.  So one thing they do is they make the platter turn very ", "slowly, so at the beginning they're doing just as well.  And they still show no learning at all.  So there's a lot of other evidence sparked by this that  just shows that the basal ganglia is an instrument ", "that's essential for us to learn physical or motor  skills, perceptual skills, and a variety of  cognitive skills as well.  Things where we practice, practice, practice to become  excellent-- ", "basal ganglia is doing a lot of that work for you.  The last kind of learning I'll talk to you about, and the  last disease, is a sort of odder form of learning called  repetition priming. ", "It's a change in performance because of  something you did recently.  And if I give you a concrete example, it'll feel better.  So here's one of many examples. ", "Imagine you study a list of words like stamp, landmark,  speak, clock.  You study a list of words like these.  I can give you an explicit or declarative memory test.  What words did you see?  You'd recall them.  Or which word did you see, that we'd do multiple choice. ", "That's regular memory that we know depends on the  hippocampus.  I can also give you weird test like this, which says, tell me  the first word you think of that starts with STA.  Now if you have good memory, you'll go, do you want me to ", "give you stamp?  Is that the point?  And you go, no, no, no.  And they go, oh, it's a Freudian thing.  You want to know some weird things I'm gonna think of.  And you go, no, no, no.  Just tell me the first word you think of, OK?  And you can give many answers that are all perfectly fine. ", "You can give stall, stand, staccato, star, many STA  words, and all of them are fine.  That's all you have to do.  But if you saw stamp, one particular completion of this,  about 10 minutes ago, you're biased or primed to come up ", "with that word.  Not all the time, but much more than by chance.  A recent experience biases you to behave in a certain way.  And here's the remarkable thing.  When you do this experiment with HM, if you just had the ", "list of words and you wait about 20  seconds, here's your recall.  Now you're not surprised that recall from a healthy person  is about seven words, right?  You tried that yourself.  HM, sadly, has no score because he always ", "goes, like, what list?  So no recall.  Multiple choice recognition, where there are three choices,  here's typical people, HM about chance.  The probability above chance-- ", "that you give stamp as the completion to  STA if you saw stamp--  if I showed you star, probably you'd give star.  The specific word you saw 10 minutes ago?  Perfectly the same in HM as normal control subjects. ", "He was just as influenced by that word he saw 10 minutes  ago as you are, to give you that answer.  So this got people very excited, because they said, ", "now we can experimentally and scientifically study something  that Freud talked about as a very vague idea, the cognitive  unconscious.  He's not conscious that he saw a list of words 10 minutes ", "ago, but it's making him choose to behave in  a certain way now.  Now you have both things in you, as far as  we understand it.  You can both remember you saw the word list, but if you ", "switch your thinking a little bit, your behavior a little  bit, the unconscious system gets into the driver's seat.  Because the people with good memory were giving stamp often  but no more or less than HM. ", "So unconscious.  So what part of the brain does this kind of memory?  And our insight to that comes from Alzheimer's disease.  So HM's kind of amnesia is extremely rare. ", "Huntington's is quite rare.  Alzheimer's is tragically common.  In fact, they went to East Boston, the area near Logan,  and knocked on doors of people's homes.  Not people in nursing homes. ", "At home.  And they estimated--  and there's debates about this back and forth.  But about half the people over 85 who answered the door  qualify for diagnosis of Alzheimer's disease. ", "About half over 85.  There's debates about this.  There's debates about whether all of us would get it if we  lived long enough.  But as American society gets older, as us baby boomers all ", "move into our '60s, '70s, and '80s, there's going to be a  heck of a lot of people around with Alzheimer's disease.  And some of you have probably experienced this, with  grandparents if nothing else. ", "It's a very devastating disorder for the patient, for  the spouse or family.  It's a very challenging disorder.  So what is Alzheimer's disease?  Well behaviorally, it's an insidious  and progressive dementia. ", "Dementia means, unlike HM, it's many losses of abilities.  Unlike HM.  HM had his surgery one day, boom.  That was it.  Alzheimer's starts very slowly and gets worse  and worse over time. ", "The biggest problem early on is memory, the most common  problem but over time, language, thinking,  concentration, spatial thinking, sometimes mood and  personality, all of these get altered over time. ", "In the brain when you look at the changes, you see that the  changes occur especially in the hippocampal region-- so  that's why the memory problem is like HM--  and also in some other parts of the cortex, but not so ", "much, for example, in basal ganglia, that we just spoke  about as important for procedural memory.  Here's a control brain and equal-aged Alzheimer's brain.  The reason why these gyri, this whole side widened is ", "because of widespread neuronal shrinkage or death.  And what's happening inside the brain, when you look at  post mortem, there's sort of neurofibrillary tangles and ", "plaques that are associated with the diseases.  The tangles are something about the  cells that have died.  The plaques are thought to be maybe part of the process that  leads to the disorder, but there's a debate about ", "that to this day.  And if you look, on post mortem, where the tangles are,  the tangles up here, you can see they're most dense in the  hippocampus or near the hippocampus, like HM. ", "And so that's why we think so many patients with Alzheimer's  have an HM-like memory problem and then more  problems after that.  So here's a healthy person top of the brain. ", "Here's the left and right hippocampus in an 81-year-old.  And here in an 80-year-old Alzheimer's patient, the  hippocampus has withered away, both sides of the brain,  bilaterally. ", "So one more brain perspective on this.  This is a SPECT scan, that just shows you where there's  blood flow and metabolism.  Top of the brain, bottom of the brain.  Here's the insides of the temporal lobes in a healthy ", "elderly adult.  Look how much worse--  this is HM.  He looks pretty good, right?  You have to look really hard to see that the hippocampus is  missing because it's such a small structure.  And here's an early-stage Alzheimer's patient. ", "Lots of the tissue is there, but a lot of-- you know, it's  not functioning because there's so much damage.  Here's the medial temporal lobes but also cortical areas  that are compromised. ", " OK, again.  Not their biggest problem, but in terms of thinking about  different parts of the brain and what parts  of memory they do--  So these are amnesic patients, including HM, Alzheimer's ", "patients, and green in controls.  So recall of the list, what words were on the list,  explicit memory bad in the two patient groups.  Recognition pretty poor.  Word stem completion, the kind of thing that we said is ", "completely normal in HM, that's impaired  in Alzheimer's disease.  So we think that kind of priming depends on the  neocortex, the part of the brain that's also injured in ", "Alzheimer's.  Because we know it doesn't depend on the hippocampus,  because the patients with  hippocampus-only damage are fine.  So we end up with a picture like this of something on ", "memory systems.  For explicit or declarative memory, from patients with  amnesia, we know it depends on the medial temporal lobe.  Left, verbal; right, spatial.  For skill learning, anything you practice many times to get ", "better at, we know from Huntington's disease, that  depends on the basal ganglia.  For kinds of priming, recent experience altering something  about brain organization, Alzheimer's disease, we know ", "from that that it's likely mediated by the neocortex.  These are from patient studies, but the imaging  studies are very well aligned with these things.  So we think it's true not only of patients, but of you, in ", "terms of the instruments of your brain.  So now we have not only episodic memory  and semantic memory.  We talked about procedural memory.  We talked about priming.  I didn't talk about conditioning today, but we've  talked about that before. ", "So I have two more slides to add on conceptually.  So in what sense was Karl Ashley right or wrong when he  said memory's all over the brain?  Here's how we think about it now.  We think he was right that all of your brain is learning. ", "Practically all of your brain is plastic.  It changes with experience.  But different parts of your brain are  learning different things.  The basal ganglia is learning how to  be skilled at something.  The neocortex, how to gain knowledge and shift your ", "representation of knowledge, like in priming.  The medial temporal lobe on the left is learning verbal  facts, and the right is nonverbal  facts or spatial facts.  So all of your brain is learning, but it's learning ", "different things.  And in that sense we end up with this metaphor that-- you  know, just like there's a string section and a  percussion section or something like that, in you,  there's all these different instruments that are highly ", "tuned in the way they're organized to learn all the  different things you learned.  They're all pretty useful instruments to have.  And without these patients and the imaging studies, we  wouldn't have known that. ", "You would be like the Martian.  One instrument?  A thousand instruments?  Well, we know there's multiple ones, and we know pretty much  which structures are essential for them.  Thanks. "], "vid_duration": [10.049, 11.52, 12.791, 13.92, 10.22, 10.13, 13.02, 11.41, 10.56, 11.6, 12.009, 11.481, 10.4, 11.4, 11.14, 12.17, 12.09, 10.83, 10.11, 11.489, 11.471, 10.19, 12.88, 10.77, 10.18, 10.55, 12.71, 10.74, 13.74, 10.13, 13.07, 12.3, 12.28, 13.89, 12.24, 11.67, 11.11, 10.19, 10.98, 10.33, 12.799, 11.301, 11.199, 11.401, 12.18, 11.63, 11.25, 10.72, 10.46, 13.28, 10.88, 12.67, 10.31, 11.2, 11.0, 10.45, 12.72, 10.32, 11.96, 12.16, 12.05, 12.54, 11.51, 12.05, 10.5, 11.56, 11.52, 10.84, 12.51, 10.34, 10.21, 10.39, 11.02, 10.15, 11.82, 11.74, 12.72, 10.58, 10.07, 12.125, 11.635, 14.69, 10.15, 10.95, 11.99, 11.73, 10.789, 12.201, 12.839, 11.061, 10.24, 11.09, 10.81, 10.08, 10.26, 10.18, 10.77, 10.15, 12.6, 11.39, 12.37, 11.31, 11.01, 12.04, 10.46, 11.21, 11.88, 13.19, 12.35, 10.04, 11.82, 13.59, 10.27, 13.18, 11.36, 10.59, 12.76, 11.94, 10.58, 10.59, 11.57, 12.49, 10.17, 11.26, 11.9, 11.58, 11.24, 10.58, 11.59, 10.72, 11.46, 12.455, 12.375, 12.22, 10.0, 11.02, 10.28, 12.23, 11.9, 12.71, 10.61, 11.01, 10.11, 10.12, 10.95, 11.4, 10.07, 10.52, 10.29, 12.07, 10.75, 10.62, 11.07, 11.515, 10.045, 10.69, 10.43, 11.19, 10.19, 10.91, 10.85, 11.75, 12.08, 13.0, 10.79, 10.98, 11.34, 11.97, 12.2, 10.49, 13.72, 10.76, 10.8, 10.7, 13.85, 10.299, 11.871, 10.839, 10.141, 12.81, 12.73, 10.636, 11.044, 11.11, 11.5, 11.115, 10.075, 11.66, 10.91, 11.4, 11.83, 10.24, 12.8, 14.2, 10.17, 10.46, 10.84, 10.43, 10.05, 11.01, 11.24, 11.95, 10.81, 11.36, 10.51, 10.65, 10.09, 11.59, 11.78, 10.66, 11.97, 11.99, 11.67, 11.02, 10.91, 13.06, 11.01, 14.89, 11.05, 10.87, 11.38, 13.2, 16.64, 10.52, 12.02, 10.07, 11.51, 11.46, 12.15, 12.4, 10.71, 11.8, 12.81, 12.25, 10.765, 10.235, 10.48, 10.9, 11.42, 12.09, 11.7, 11.38, 12.59, 11.19, 10.66, 11.98, 10.28, 10.77, 11.04, 10.46, 10.9, 14.06, 10.62, 10.35, 11.09, 10.47, 11.73, 11.04, 11.85, 13.39, 12.99, 10.12, 11.92, 13.39, 10.05, 11.05, 10.37, 12.64, 13.62, 10.46, 13.49, 11.45, 10.82, 10.57, 10.56, 13.0, 11.53, 12.55, 10.66, 11.11, 12.01, 10.08, 11.35, 11.47, 11.33, 10.5, 11.39, 11.52, 10.64, 10.24, 11.39, 11.37, 10.17, 12.19, 11.99, 12.18, 10.99, 10.89, 10.47, 9.26], "stet": [[0, 10.049], [10.049, 21.569], [21.569, 34.36], [34.36, 48.28], [48.28, 58.5], [58.5, 68.63], [68.63, 81.64999999999999], [81.64999999999999, 93.05999999999999], [93.05999999999999, 103.61999999999999], [103.61999999999999, 115.21999999999998], [115.21999999999998, 127.22899999999998], [127.22899999999998, 138.70999999999998], [138.70999999999998, 149.10999999999999], [149.10999999999999, 160.51], [160.51, 171.64999999999998], [171.64999999999998, 183.81999999999996], [183.81999999999996, 195.90999999999997], [195.90999999999997, 206.73999999999998], [206.73999999999998, 216.84999999999997], [216.84999999999997, 228.33899999999997], [228.33899999999997, 239.80999999999997], [239.80999999999997, 249.99999999999997], [249.99999999999997, 262.88], [262.88, 273.65], [273.65, 283.83], [283.83, 294.38], [294.38, 307.09], [307.09, 317.83], [317.83, 331.57], [331.57, 341.7], [341.7, 354.77], [354.77, 367.07], [367.07, 379.34999999999997], [379.34999999999997, 393.23999999999995], [393.23999999999995, 405.47999999999996], [405.47999999999996, 417.15], [417.15, 428.26], [428.26, 438.45], [438.45, 449.43], [449.43, 459.76], [459.76, 472.55899999999997], [472.55899999999997, 483.85999999999996], [483.85999999999996, 495.05899999999997], [495.05899999999997, 506.46], [506.46, 518.64], [518.64, 530.27], [530.27, 541.52], [541.52, 552.24], [552.24, 562.7], [562.7, 575.98], [575.98, 586.86], [586.86, 599.53], [599.53, 609.8399999999999], [609.8399999999999, 621.04], [621.04, 632.04], [632.04, 642.49], [642.49, 655.21], [655.21, 665.5300000000001], [665.5300000000001, 677.4900000000001], [677.4900000000001, 689.6500000000001], [689.6500000000001, 701.7], [701.7, 714.24], [714.24, 725.75], [725.75, 737.8], [737.8, 748.3], [748.3, 759.8599999999999], [759.8599999999999, 771.3799999999999], [771.3799999999999, 782.2199999999999], [782.2199999999999, 794.7299999999999], [794.7299999999999, 805.0699999999999], [805.0699999999999, 815.28], [815.28, 825.67], [825.67, 836.6899999999999], [836.6899999999999, 846.8399999999999], [846.8399999999999, 858.66], [858.66, 870.4], [870.4, 883.12], [883.12, 893.7], [893.7, 903.7700000000001], [903.7700000000001, 915.8950000000001], [915.8950000000001, 927.5300000000001], [927.5300000000001, 942.2200000000001], [942.2200000000001, 952.3700000000001], [952.3700000000001, 963.3200000000002], [963.3200000000002, 975.3100000000002], [975.3100000000002, 987.0400000000002], [987.0400000000002, 997.8290000000002], [997.8290000000002, 1010.0300000000002], [1010.0300000000002, 1022.8690000000003], [1022.8690000000003, 1033.9300000000003], [1033.9300000000003, 1044.1700000000003], [1044.1700000000003, 1055.2600000000002], [1055.2600000000002, 1066.0700000000002], [1066.0700000000002, 1076.15], [1076.15, 1086.41], [1086.41, 1096.5900000000001], [1096.5900000000001, 1107.3600000000001], [1107.3600000000001, 1117.5100000000002], [1117.5100000000002, 1130.1100000000001], [1130.1100000000001, 1141.5000000000002], [1141.5000000000002, 1153.8700000000001], [1153.8700000000001, 1165.18], [1165.18, 1176.19], [1176.19, 1188.23], [1188.23, 1198.69], [1198.69, 1209.9], [1209.9, 1221.7800000000002], [1221.7800000000002, 1234.9700000000003], [1234.9700000000003, 1247.3200000000002], [1247.3200000000002, 1257.3600000000001], [1257.3600000000001, 1269.18], [1269.18, 1282.77], [1282.77, 1293.04], [1293.04, 1306.22], [1306.22, 1317.58], [1317.58, 1328.1699999999998], [1328.1699999999998, 1340.9299999999998], [1340.9299999999998, 1352.87], [1352.87, 1363.4499999999998], [1363.4499999999998, 1374.0399999999997], [1374.0399999999997, 1385.6099999999997], [1385.6099999999997, 1398.0999999999997], [1398.0999999999997, 1408.2699999999998], [1408.2699999999998, 1419.5299999999997], [1419.5299999999997, 1431.4299999999998], [1431.4299999999998, 1443.0099999999998], [1443.0099999999998, 1454.2499999999998], [1454.2499999999998, 1464.8299999999997], [1464.8299999999997, 1476.4199999999996], [1476.4199999999996, 1487.1399999999996], [1487.1399999999996, 1498.5999999999997], [1498.5999999999997, 1511.0549999999996], [1511.0549999999996, 1523.4299999999996], [1523.4299999999996, 1535.6499999999996], [1535.6499999999996, 1545.6499999999996], [1545.6499999999996, 1556.6699999999996], [1556.6699999999996, 1566.9499999999996], [1566.9499999999996, 1579.1799999999996], [1579.1799999999996, 1591.0799999999997], [1591.0799999999997, 1603.7899999999997], [1603.7899999999997, 1614.3999999999996], [1614.3999999999996, 1625.4099999999996], [1625.4099999999996, 1635.5199999999995], [1635.5199999999995, 1645.6399999999994], [1645.6399999999994, 1656.5899999999995], [1656.5899999999995, 1667.9899999999996], [1667.9899999999996, 1678.0599999999995], [1678.0599999999995, 1688.5799999999995], [1688.5799999999995, 1698.8699999999994], [1698.8699999999994, 1710.9399999999994], [1710.9399999999994, 1721.6899999999994], [1721.6899999999994, 1732.3099999999993], [1732.3099999999993, 1743.3799999999992], [1743.3799999999992, 1754.8949999999993], [1754.8949999999993, 1764.9399999999994], [1764.9399999999994, 1775.6299999999994], [1775.6299999999994, 1786.0599999999995], [1786.0599999999995, 1797.2499999999995], [1797.2499999999995, 1807.4399999999996], [1807.4399999999996, 1818.3499999999997], [1818.3499999999997, 1829.1999999999996], [1829.1999999999996, 1840.9499999999996], [1840.9499999999996, 1853.0299999999995], [1853.0299999999995, 1866.0299999999995], [1866.0299999999995, 1876.8199999999995], [1876.8199999999995, 1887.7999999999995], [1887.7999999999995, 1899.1399999999994], [1899.1399999999994, 1911.1099999999994], [1911.1099999999994, 1923.3099999999995], [1923.3099999999995, 1933.7999999999995], [1933.7999999999995, 1947.5199999999995], [1947.5199999999995, 1958.2799999999995], [1958.2799999999995, 1969.0799999999995], [1969.0799999999995, 1979.7799999999995], [1979.7799999999995, 1993.6299999999994], [1993.6299999999994, 2003.9289999999994], [2003.9289999999994, 2015.7999999999995], [2015.7999999999995, 2026.6389999999994], [2026.6389999999994, 2036.7799999999995], [2036.7799999999995, 2049.5899999999997], [2049.5899999999997, 2062.3199999999997], [2062.3199999999997, 2072.9559999999997], [2072.9559999999997, 2083.9999999999995], [2083.9999999999995, 2095.1099999999997], [2095.1099999999997, 2106.6099999999997], [2106.6099999999997, 2117.7249999999995], [2117.7249999999995, 2127.7999999999993], [2127.7999999999993, 2139.459999999999], [2139.459999999999, 2150.369999999999], [2150.369999999999, 2161.769999999999], [2161.769999999999, 2173.599999999999], [2173.599999999999, 2183.839999999999], [2183.839999999999, 2196.639999999999], [2196.639999999999, 2210.839999999999], [2210.839999999999, 2221.009999999999], [2221.009999999999, 2231.469999999999], [2231.469999999999, 2242.309999999999], [2242.309999999999, 2252.739999999999], [2252.739999999999, 2262.789999999999], [2262.789999999999, 2273.7999999999993], [2273.7999999999993, 2285.039999999999], [2285.039999999999, 2296.989999999999], [2296.989999999999, 2307.799999999999], [2307.799999999999, 2319.159999999999], [2319.159999999999, 2329.669999999999], [2329.669999999999, 2340.3199999999993], [2340.3199999999993, 2350.4099999999994], [2350.4099999999994, 2361.9999999999995], [2361.9999999999995, 2373.7799999999997], [2373.7799999999997, 2384.4399999999996], [2384.4399999999996, 2396.4099999999994], [2396.4099999999994, 2408.399999999999], [2408.399999999999, 2420.0699999999993], [2420.0699999999993, 2431.0899999999992], [2431.0899999999992, 2441.999999999999], [2441.999999999999, 2455.059999999999], [2455.059999999999, 2466.0699999999993], [2466.0699999999993, 2480.959999999999], [2480.959999999999, 2492.0099999999993], [2492.0099999999993, 2502.879999999999], [2502.879999999999, 2514.2599999999993], [2514.2599999999993, 2527.459999999999], [2527.459999999999, 2544.099999999999], [2544.099999999999, 2554.619999999999], [2554.619999999999, 2566.639999999999], [2566.639999999999, 2576.709999999999], [2576.709999999999, 2588.2199999999993], [2588.2199999999993, 2599.6799999999994], [2599.6799999999994, 2611.8299999999995], [2611.8299999999995, 2624.2299999999996], [2624.2299999999996, 2634.9399999999996], [2634.9399999999996, 2646.74], [2646.74, 2659.5499999999997], [2659.5499999999997, 2671.7999999999997], [2671.7999999999997, 2682.5649999999996], [2682.5649999999996, 2692.7999999999997], [2692.7999999999997, 2703.2799999999997], [2703.2799999999997, 2714.18], [2714.18, 2725.6], [2725.6, 2737.69], [2737.69, 2749.39], [2749.39, 2760.77], [2760.77, 2773.36], [2773.36, 2784.55], [2784.55, 2795.21], [2795.21, 2807.19], [2807.19, 2817.4700000000003], [2817.4700000000003, 2828.2400000000002], [2828.2400000000002, 2839.28], [2839.28, 2849.7400000000002], [2849.7400000000002, 2860.6400000000003], [2860.6400000000003, 2874.7000000000003], [2874.7000000000003, 2885.32], [2885.32, 2895.67], [2895.67, 2906.76], [2906.76, 2917.23], [2917.23, 2928.96], [2928.96, 2940.0], [2940.0, 2951.85], [2951.85, 2965.24], [2965.24, 2978.2299999999996], [2978.2299999999996, 2988.3499999999995], [2988.3499999999995, 3000.2699999999995], [3000.2699999999995, 3013.6599999999994], [3013.6599999999994, 3023.7099999999996], [3023.7099999999996, 3034.7599999999998], [3034.7599999999998, 3045.1299999999997], [3045.1299999999997, 3057.7699999999995], [3057.7699999999995, 3071.3899999999994], [3071.3899999999994, 3081.8499999999995], [3081.8499999999995, 3095.3399999999992], [3095.3399999999992, 3106.789999999999], [3106.789999999999, 3117.609999999999], [3117.609999999999, 3128.1799999999994], [3128.1799999999994, 3138.7399999999993], [3138.7399999999993, 3151.7399999999993], [3151.7399999999993, 3163.2699999999995], [3163.2699999999995, 3175.8199999999997], [3175.8199999999997, 3186.4799999999996], [3186.4799999999996, 3197.5899999999997], [3197.5899999999997, 3209.6], [3209.6, 3219.68], [3219.68, 3231.0299999999997], [3231.0299999999997, 3242.4999999999995], [3242.4999999999995, 3253.8299999999995], [3253.8299999999995, 3264.3299999999995], [3264.3299999999995, 3275.7199999999993], [3275.7199999999993, 3287.2399999999993], [3287.2399999999993, 3297.879999999999], [3297.879999999999, 3308.119999999999], [3308.119999999999, 3319.509999999999], [3319.509999999999, 3330.8799999999987], [3330.8799999999987, 3341.049999999999], [3341.049999999999, 3353.239999999999], [3353.239999999999, 3365.2299999999987], [3365.2299999999987, 3377.4099999999985], [3377.4099999999985, 3388.3999999999983], [3388.3999999999983, 3399.289999999998], [3399.289999999998, 3409.759999999998], [3409.759999999998, 3419.019999999998]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [458, 1281, 1976, 2544, 3419]}
{"example_id": "mit057@@MIT9_00SCF11_lec03_300k", "text": ["PROFESSOR JOHN GABRIELI: Last time we discussed how people  can approach psychological issues in terms of  experiments, and at least correlations in some cases or ", "causal studies through experiments.  And we discovered that if you think  about money, what happens?  On average, you become more self-reliant or less willing ", "to help, right?  We discovered that if you just change the way that men and  women approach each other at a dating event, you change their  internal feelings and their external behaviors simply by ", "who's approaching whom.  So we learned all kinds of things that you might or might  not have known unless you did the experiments.  And for all these things that are our mental life-- our ", "thoughts, our feelings, they are all  supported by our brains.  And so for me personally as a neuroscientist, I've always  thought that the brain is one of the three amazing things  out there in the natural world.  With the origins of the universe, the origin of life. ", "And the brain that allow us to think and feel, to see, that  remember, really everything that we do comes from that.  OK. ", "So here's this device.  And I want to share with you just this phrase that people  sometimes use, which is that your mind is  what your brain does. ", "That your mind is what your brain does And so the readings  from Oliver Sacks for today kind of remind you of that.  So there are two women who have ", "seizures of various kinds.  And what happens in them?  So one is Mrs. OC, 88-year-old woman.  And what starts to happen to her?  She starts to hear songs. ", "And so powerfully, not just when you have a little song in  your head, that it's hard for her to hear conversations.  For her, a conversation like we're having now, it's as if  the music stayed on really loud. ", "Turns out she's having temporal lobe seizures.  The temporal lobes are the parts of the brain that are  terribly important for hearing.  So music is something that we hear.  And then she has a right temporal lobe infarction. ", "She's had an injury in the right temporal lobe.  Music, for most of us, is more dependent on right hemisphere  processes than the left.  So that makes it unusual. ", "And how does she feel about the whole process?  So what's generating the songs, though?  What's generating the songs that she hears? ", "Yeah, her memory.  Her brain, right?  Because in epilepsy, what's happening?  Neurons are firing.  When neurons fire in organized patterns, those are memories,  desires, physical actions, thoughts. ", "When they're firing for no good reason like an epilepsy  because of some brain difficulty,  they just start firing.  But the neurons that happen to be firing will drive certain ", "mental processes that they normally support.  In this case, the neurons that are firing away are ones that  are involved in memory or songs and  perception for songs.  And when they fire, it's as if you heard the song itself. ", "Because when you hear my voice or when you hear a song,  you're never hearing the song.  You're always hearing what your neurons are interpreting  the sound that comes to your ear. ", "Your mind is what your brain does in that sense, and in a  very central way.  If you had an injury in that part of the brain, you can be  cortically deaf and never hear a sound, even though all the  information came through your ear. ", "So without your brain interpreting the environment,  you wouldn't know what it is.  But if your brain starts to fire on its own, that's just  as good a signal as if you heard a song itself. ", "Because that is the stuff of hearing songs.  So she enjoyed it, actually.  She declined taking anti-convulsive medications.  Because she felt it was a portal to her past, right? ", "The songs that she heard were ones that reminded her of her  life and were kind of pleasant to hear.  It was like being on a nonstop highlight film of for life, or  a highlight MP3. ", "So now an opposite response to a similar phenomenon comes  from a Mrs. OM in her 80s.  She hears songs, but she also hears a lot  of ringing and hissing.  It's not limited to the song itself. ", "She doesn't mention any of this for how long?  Four years.  She's hearing ringing, hissing, songs.  She knows because her mind is fine that they're coming from ", "nowhere but inside her head.  But she doesn't tell anybody.  That's a huge burden, right?  And why doesn't she tell them?  Yeah, yeah.  And especially if you're in your 80s, and you're going ", "around saying, I'm hearing things, people go, OK.  Were putting you in the old age home, right?  You're out of it.  So she doesn't want to give up her freedom. ", "And she gets a short playlist, just three songs, and hears  them over and over and over again.  You may have had the experience that some songs you  hear for a while.  You like them more, and then you get tired of them. ", "If you had only three all the time, every day, and a bad  version that was hissing and ringing, you would get pretty  tired of the songs too.  That stops by anti-convulsive medications and medications ", "that stops the seizures, stop the songs.  And so it's sort of a beautiful story, when two  opposite emotional responses for how your mind is what your ", "brain does.  Now from this, the fact that songs are played back as if  you had pulled out songs from your computer or shelf  somewhere, you might think that the brain retains these ", "records perfectly throughout life and epilepsy  would just sort them.  But we'll come back to that later on, and say that in very  much, we don't think memory is that way.  But we do remember songs that are important for us. ", "And if our brain just starts firing in the same place where  we store those songs, we hear them just as real as your  cortex hears it when it hears the actual song itself. ", "Because that's the place where you hear it.  So this is the kind of evidence that at least in some  sense, your mind is what your brain does.  And so here's this amazing brain.  It's about two to three pounds. ", "But every thought and feeling you'll ever have, or every  physical movement, every desire, every thing that  you're proud of or ashamed of that crosses your mind will be  supported by this structure. ", "So I'm going to talk a little bit about the neurons, just a  little bit about the neurons that compose the brain, and a  little bit about a quick tour through the gross organization  of the brain.  We'll come back to many of these structures as they're ", "relevant to different things like memory or emotion or  personality later in the course.  Talk a little bit about the enterprise of trying to say  which parts of our brain support which  parts of our mind. ", "Missteps about that, famous cases about that, that have  turned out to have roughly the right message.  And we'll focus on hemispheric specialization, the thing in  humans where our left hemisphere and our right ", "hemisphere are organized to accomplish different things,  to support different mental functions.  And the surprise from split brain or commissurotomy  patients, that these different mental lives that support our ", "different parts of the brain, that  they can live in isolation.  They don't even know they're there one to the other.  So let me rephrase this.  As you sit there, the thought is you might have independent ", "parts of your mind supported by independent  part of your brain.  And at any one moment, your consciousness might be in one  part, and then it might move to another. ", "And just like there's all these people in this room,  your brain might be all these things having their own  independent thinking lives.  They have to interact a lot.  But how much might there be independent modules in your ", "brain that are doing their own thing.  And now you're thinking about music, and those turn on, and  that's where your consciousness is.  Now you're thinking about history.  Now you're thinking about dinner tonight. ", "And different parts of your brain turn on and that's when  your consciousness is moving from one part of your  brain to the other.  But the other parts keep going.  So we'll see how plausible is that. ", "So it took a long time for people to decide that the  brain actually is the stuff of the mind.  Smart philosophers like Plato said, well, it's part of the ", "body that's closest to the heavens.  That's where the gods might reside, so that's a good place  to have your mind and that's where your brain is.  A sort of GPS approach to locating where ", "the mind might be.  Aristotle said, wait a minute.  It's the warm and active heart-- the heart was very  impressive in post-mortem examination of people who have  passed away--  that houses the mind.  And that it cools, and there's an inner brain. ", "So the brain was kind of a radiator that would sort of  cool stuff off to keep the heart in optimal.  And even now, we talk about people having  a big heart, right?  A cold heart, a warm heart.  We still talk about human personality or character in ", "terms of heart.  Galen said that the brain was surrounded-- there's  ventricles in the middle of the brain that have fluid,  cerebral spinal fluid.  And he hypothesized that the brain was the packing material ", "that protects that fluid.  Hang on to that fluid, that's all your stuff.  We're going to cram a lot of stuff around it, right?  Like the bubble pack that comes in the boxes.  And of course now we know it's the opposite way around.  The mind is in the physical, the dense part of ", "the brain, not that.  And then ideas from Descartes, the pineal body is one of the  very few structures that's in the midline of the brain, that  doesn't have a thing on the left and a thing on the right.  And so he thought maybe that's where things get unified in ", "the whole brain.  It all comes together as the place that  runs the whole brain.  And that's a wrong idea.  But people were trying to figure out what was going on.  In modern neuroscience, there's many levels of ", "analysis of the brain.  So if you go to any neuroscience program, like  Department of Brain and Cognitive Science, you will  actually see scientists who study things like molecules  and synapses, molecular neurobiology, how neurons ", "work, how neurons form networks, little organizations  of things that solve problems at a higher level, maps,  systems in the brain as a whole.  In this course, we mostly have to operate at this level. ", "That's the place where it's easy for us to relate in some  ways parts of the mind as we understand it, of human nature  as we understand it, and physical parts of the brain.  It's very hard for us to get that to  molecules at the moment. ", "But lots of neuroscience is working to connect these  things at different levels.  And I can't resist talking for one second, too, about the  fact that we know our brains were not  designed from scratch. ", "You are not humans 3.0 or 98.0, right?  Everything in us in some way evolved from other species  that were similar to us, and far enough back,  dissimilar to us. ", "So there's lots of speculation about how it is that we  balance parts of the brain that are ancient in their  evolutionary roots, that are more recent in their  evolutionary basis, and what that means about us. ", "Another sense in which we're comprised of multiple society  of brain systems in between our ears.  So we know the cells in the brain are glia support cells ", "and neurons, that a neuron--  and I know you all know all this.  Oh, let me say a word about notes.  So we sent PDFs of the lecture notes from the first two  lectures and the third one just recently. ", "Starting tomorrow, we'll send you the PDF of each lecture,  the latest by the night before the lecture.  So you will be able to print it out or look  at it on the computer.  But neurons have a soma or cell body. ", "Those make up the grey matter when we look at the brain.  They have an axon that can be covered with myelin that makes  the white matter.  The dendrite is the extensions of the neurons that have the ", "input to the neuron.  We know that neurons communicate by  neurotransmitters across synapses, junctions between  different parts of neurons. ", "When you have a collection of cell bodies,  people call it a nucleus.  When you have a collection of axons, they call it a tract.  It's just vocabulary and stuff.  And you know this from other courses, just reminding you  about them. ", "And then you get these unbelievably startling kinds  of numbers, which are always huge estimates.  But they show you how amazing your brain is, and how hard it  is for us to deeply understand how the brain works. ", "I mean, we understand incredibly more than we did 10  years ago, 20 years ago, 30 years ago.  We're incredibly far from understanding how your brain  accomplishes the amazing things it accomplishes. ", "So it has about 100 billion neurons.  It has about 100 trillion synapses, connections among  neurons and dendrites.  If you were to lay out the very thin myelinated axons in ", "your brain, just the big axons that get myelin, it's  estimated that you'd have 62,000 miles of axons.  That's pretty good, right?  Now you really want to wear helmets when you go ", "skateboarding or anything, right?  And about 100,000 miles of dendrites in each of you.  So this is why the brain is amazing and hard.  It's fantastic in its complexity. ", "An average neuron may have up to 15,000 connections, 1,000  synapses, and up to 1,000 neurons.  There's different ways of thinking about the ", "computational power of a neuron.  But they estimate that these might have, each one the  computational power of something like a  medium-sized computer.  So it's not the best computer, but you've got ", "100 billion of them.  Now, that's the easy part.  Take 100 billion neurons and your computer's in your head.  The hard part is to get them all working together  efficiently.  And you're not sitting around going, \"Computer 33, get up to ", "speed here.  Something's wrong here.\" You don't even think about them.  You just go about your business.  The time for information to go from neuron to neuron is  pretty slow compared to fast computers, pretty fast for ", "biology, 10 milliseconds.  And everybody thinks the secret of the brain, whatever  it will turn out to be in many ways, is that you can run a  fantastic number of computations simultaneously ", "and collaboratively.  But we don't have a deep understanding of how  that all plays out.  So here's a cartoon of this amazing axon, the cell body,  and the dendrites to get inputs to it. ", "The axon is the output signal of a typical neuron.  Neurons can have these beautiful arborizations,  tree-like properties of dendrites.  Neurons have all kinds of different shapes in different ", "parts of the brain, presumably reflecting their different  missions, what they have to accomplish.  An incredibly complicated cellular factory inside all of  them is producing different things. ", "This is a big overview.  This is not for you to learn a specific fact.  And this, here's an actual neuron that's injected in the  fantastic tree of connections it makes within the neurons to  accomplish its mission. ", "Here's a cartoon of a synapse, places where neurotransmitters  signal from one axon to one dendrite, for example.  Here's an actual picture.  Here's the package of vesicles that house the ", "neurotransmitters in them, making a connection or a  synapse onto a dendrite.  And you just have a fantastic number of these.  And as you're sitting in you right now an unbelievable  amount of stuff is going on-- releasing them, cleaning them ", "away so they don't hang around too long, building new ones to  get ready to go.  It's just an unbelievable story per neuron, never mind  the whole of them.  So now we take a step back to the brain as a whole. ", "Here's the front of the brain, top of the  brain, back of the brain.  I'm going to say a word about the cerebellum, which we'll  talk very little about in this course.  The cellular organization of the cerebellum is so  consistent that people estimate that half of all the ", "cortical neurons in the brain are in the cerebellum.  And if you see this cerebellar size is small, not that large,  it's because it's packed so tightly.  And it's so consistent in its organization that people ", "thought, that's the first part of the brain we'll crack.  Because the organization is so clear that we'll be able to  figure out what it's computing and how it does it.  And it's turned out to be about as mysterious a ", "structure as any.  I can't tell you the number of debates about what people-- we  know it's involved in motor control, but in many other  things, as well.  The wiring diagram, knowing it, what's connected to who, ", "turns out to be only a tiny step in understanding how what  part of the brain does what it does.  So here's this mysterious cerebellum.  And then here's a basal ganglia that we know is ", "involved in movement.  Parkinson's Disease affects it.  Huntington's Disease affects it.  It's also involved in learning habits of all kinds.  It's also involved in the reward systems of the brain. ", "What have we found delightful and important?  What did we want to do because the reward  system is turned on?  We'll come back to that later on.  And then the limbic system, the part of the brain that's ", "involved in emotion and memory--  amygdala and hippocampus.  We'll come back to that.  If you don't have this structure intact, you can't  form new memories ever again.  We'll talk about patients like that. ", "And then we'll come to the smarts of the brain, the  cerebral cortex, four lobes--  frontal, parietal, occipital, and temporal.  You have four on the left and four on the right. ", "These lobes are comprised of gyri.  That's the part of the brain that sticks out.  And then there's this sort of indentation where it dives  deep into a sulcus.  Comes back up, it's the next gyrus, dives deep into the ", "next sulcus.  A huge sulcus is called a fissure.  Here's a Sylvian fissure that separates the temporal and  frontal cortices.  And one of the reasons that people have speculated about ", "why do we have a thing like that?  Why do we have these waves of a gyrus going up and then  plunging into the depths, then coming back up like this again ", "and plunging from sulcus to sulcus?  And nobody really knows.  But there's kind of a speculation  that's fun and plausible. ", "One thing we know is that bigger cortices are good, not  so much one person to another, but across species.  Your smarts are in your cortices--  language, higher-level thought, and so on. ", "So on the whole, a species that has bigger cortices has a  lot of opportunities for thought and social  development and so on.  So you could imagine having babies with heads this big. ", "They'd be really smart, maybe.  But what would be the problem?   What would be the big problem? ", "Think about it not from your perspective, perhaps, if most  of you are sort of teenagers or young 20s or something like  that, most of you.  So you don't remember your birth experience directly. ", "But who remembers your birth experience pretty well?  Your parents?  OK.  All right.  It's your mother, especially.  Giving birth is a pretty painful,  specific, challenging process. ", "So if a head this big came out, it would be  incommensurate with the birth canal that  the mother can afford.  It's already pretty challenging with your head as  big as it is when it comes out.  That's the challenge of birth.  It's not getting the arms and legs out. ", "Its the head that's too big.  So now we have a problem that the mother's birth canal is  only so big.  We want as much brain and smartness in our species and  in ourselves as possible. ", "So how are we going to get a lot of neocortex in there?   We're going to fold it.  A lot of neocortex in there, but a smaller volume to get ", "out through the birth canal.  And that's thought to be why the brain has this elaborate  plunging from sulcus to sulcus, and this sort of  convolved physical structure. ", "And if we think about the brain, we can think about  things that go into our brains, about the outer world.  So when you see, vision enters through this area, or when you ", "hear, it enters here.  When you touch or when you move your body, these are the  motor cortical neurons.  So it's either sort of major inputs or major output.  That's in blue.  That's the areas that are devoted to specific perception ", "or modalities or sensories.  And then we have areas in yellow here.  They are the areas that are sort of  closely tied to one modality.  But already, they're interpreting what's going on. ", "And then you have areas in pink here that are sort of not  tied to any modality and are devoted to what we might call  abstract thought.  And you can see the prefrontal cortex, the part of the cortex ", "that's in front of the motor cortex.  There's a huge swath like that.  We'll come back to that.  We think it's terribly important for thinking,  problem solving, and many aspects of the  highest human mentation. ", "Now we're a huge believer in the end that form follows  function in the brain.  And if we understood the correct relationship between  form and function, we'd be very far.  And a neuroanatomist named [? Broadbent ?] ", "made the following heroic effort.  What he did is he sectioned brains into  lots of thin slices.  And he followed them through a microscope.  And every time the brain tissue changed, the neurons ", "looked different, he would change the number of the area.  So he started in something like Area One.  And the neurons look pretty similar.  And he's moving, moving, moving.  And then all of a sudden they start to look ", "different, the neurons.  And then that becomes something like Area Three.  Moving, moving, Area Four.  Moving, moving, Area Six.  So every time the neurons looked different to his eye, ", "it gets a new number.  The idea being when the neurons look different, they  have a different job to do.  And that part of the brain does something different.  And there's lots of debates about the best way to do this,  or different interpretations. ", "But something like this holds true in a striking way.  The cellular organization of the brain reflects in some way  what that part of the brain is accomplishing, what part of  your mind it supports. ", "And then we have simplified color pictures of this.  And we'll come back to neuroimaging next time.  But it's turned out to have a second life in neuroimaging.  Because when scientists across the world want to compare ", "their neuroimaging results, they'll talk about, well, I  got activation in Area 46, or I got it in Area 21.  It's become a nomenclature for the organization of the human  brain that allows you to integrate all kinds of imaging ", "data about the human species.  And here's a view from the inside of the brain.  And here's a structure chord, the corpus callosum, that  we'll come back to in the next few minutes. ", "So how much are functions localized or distributed?  How much is--  you have a specific thing your mind does, and it's in one  place in the brain versus it's spread over a range. ", "And this idea of how much things are distributed or  localized for mental functions in the brain has been a source  of huge debate.  And I'll show you a misstep, and then I'll show you some  things where we think we have it more correctly. ", "The misstep is a phrenology.  And the most famous name in this is from Gall.  Spurzheim is another one.  And in the 19th century-- that's the 1800s-- ", "the phrenology took hold a lot.  And there's a sort of a Freudian story.  If you want to call it that, of Gall, which is that  apparently when he was a student, he viewed himself as ", "a very effortful and fastidious student who took  all the notes you're supposed to take, and worked very hard  for exams and did everything you were supposed to do.  But shock of shocks, some students did  better than he did. ", "And he looked around the classroom.  He said, who are these students doing  better than I am?  Because I'm trying as hard as I can.  And some students are doing better.  And he said, hey, one thing I notice about these students is  they all seem to have big foreheads.  OK? ", "[CHUCKLES]  Now, I don't know how accurate he was scientifically.  But apparently, this was a emotionally transformative  moment for Gall.  And you'll see in what way this ended  up guiding his science. ", "So Gall and Spurzheim were actually good neuroanatomists.  They describe lots of things about the brain that were  correct that were kind of unknown at the time.  For example, the pyramidal tracts, the tracts that move ", "from your motor cortex-- say on your left to control your  right hand, or on your right to control your left hand--  they describe those very well.  But here's where they got kind of funny.  They said, OK, we can describe the physical ", "organization of the brain.  But now let's say which part of the brain is  which part of the mind.  And in a way that we now consider a bit willy-nilly,  they began to assign different mental processes to different  parts of the brain. ", "And the way they did it was they said, I'm going to look  at somebody.  And let's pretend somebody you know is very combative.  What they began to figure was this.  Well, maybe the part of the brain that's involved in being ", "combative--  the more combative you are, the more you have of it.  So if I feel your skull above the part of the brain that I  think goes with being combative, if you have a big ", "rise there, if I feel your head-- and most of our heads  are a little bumpy--  the person who's really combative is going to have a  lot of bump there.  And the person who's very meek will have none. ", "OK, does that make sense?  They have these little categories as they just  thought about people.  And they developed this idea that they could find where ", "cautiousness was, or precociousness, or  secretiveness.  You'd give it a big bump there.  Let me show you this picture.  Here's a device you would step into that would have springs ", "go down, and then it would go up, and they would say, where  do you have the high bumps?  And where do you have the little bumps?  Now all of this is wrong.  Because it's a naive way and not a scientific way to do it. ", "Weirdly enough, look at what they put below the eye--  language.  Now that's a weird place to put it.  And what they saw was a soldier who had a wound that  went his eye and into his brain. ", "And they said, OK, he had trouble producing language.  And they said, well, that's where language is.  Language is not below your eye.  But they didn't realize that the wound went up into what's ", "something called Broca's area.  We'll talk about that in a couple minutes.  And so they weren't that wrong.  They just didn't think through where the end  of the injury was.  All the other ones, we completely dismiss these days. ", "But we have to worry about naive ways in which we link  the life of the mind to the stuff of the brain.  And they did a control experiment. \"The famous  physiologist, Magendie, preserved with veneration the ", "brain of Laplace,\" who's a big name in  the history of chemistry.  \"Spurzheim had the natural wish to see the brain.\"  Spurzheim was the phrenologist.  \"To test the science of phrenologist, Magendie showed  him instead the brain of an imbecile. ", "Spurzheim, who had already worked up his enthusiasm,  admired the brain of the imbecile as he would have  admired that of Laplace.\"  So this was a control assess.  I give you a brain of somebody who's not a genius in  chemistry, and you go, oh my gosh. ", "This chemistry part of the brain is unbelievable.  And this is the old idea we talked about, that if you have  an idea you believe in as a scientist, you will always  find positive evidence for it everywhere you look. ", "Back to the brain, and let's talk about this part, the  lower part of the orbital frontal cortex.  It sits right above your eyes.  Your eyes would be something like here.  And we know something about what that part of the brain ", "does from the famous case of Phineas Gage.  He was involved in railroad construction in Vermont.  And that involved exploding rocks to level the area so  they could put in train tracks. ", "They would drill a hole, put in some  fuse, put in the powder.  And they would use a tamping iron to push down the sand and  powder so there would be a big explosion to flatten the rock.  And at age 25 in 1848, he has a mind who was described as ", "well-balanced, energetic, and persistent.  He was the ideal employee, resourceful, hardworking.  He was made a foreman, a leader.  He was the most efficient and capable in the group.  And on September 13, 1848, something big happened. ", "There was a miscommunication.  An iron that was three feet, seven inches in length--  I'll show you a picture in a moment, because even if you've  heard this story, until you see a picture of it, you can't  grasp how big this was compared to a human being. ", "There was a miscommunication, the explosion went off early.  He was directly over it.  The rod flew up, went through his head, all the  way through his head.  And it had the power to land 30 yards away after exploding ", "up into the air.  And by March of the next year, he was back at work.  Not too long a vacation, a recovery period for that big a  thing going through your head.  But his personality had fundamentally changed. ", "So here's his cast of his actual head and his skull.  Here's where it shot up through here  and out this hole.  Here's the actual rod compared to that. ", "So if you haven't seen this, you can underestimate the  amazingness of this thing.  And at the time he was famous not for the reason we now  think of him. ", "He was just a Ripley's believe it or not story of that a  human survived at all.  So Antonio Damasio has attempted to reconstruct by  computer where this rod shot up through here and out into ", "30 yards away.  They're that big compared to him.  And the amazing thing, and described by a physician who  worked with him at the time, is \"the equilibrium to his  intellectual faculties and animal propensities seems to ", "have destroyed.  He is fitful, irreverent, indulging at times in the  grossest profanity.  Little deference for his fellows, impatient of  restraint, conflicting with his desires.  At times pertinaciously obstinate, capricious and ", "vacillating, devising many plans of future operations,  which are no sooner arranged than they are abandoned in  turn for others appearing more feasible.\"  Exactly the opposite of who he was before.  He was a responsible, efficient leader. ", "And now he's a totally irresponsible person doing all  kinds of things that make no sense.  \"A child in his intellectual capacity, he has the animal  passions of a strong man.\" So he completely ", "changed who he was.  In this regard, his mind was so radically changed that his  friends and acquaintances said that \"he was no longer Gage.\"  So here's a physical insult to the brain that changes the ", "character of a person, that changes what we would think of  as the moral judgments.  Of when is it right to tell the truth, having plans and  being a responsible, trustworthy person, completely ", "changed by this injury.   One interpretation is this part of the brain is essential  for making moral judgments and being of good character. ", "What would be another interpretation of why he might  have changed, just common sense besides that this part  of the brain does that?  We want to not be for phrenologists, OK? ", "So the first thought is, this part of the brain supports  what we think of as moral reasoning and character.  Well, what else could you imagine might have happened? ", " Yeah.  AUDIENCE: He had a giant spike driven though his skull and is  upset about it?  PROFESSOR JOHN GABRIELI: Yeah.  I'll make up something like that. ", "But a more psychological and different interpretation, let  me try this one.  He was getting ready for the future.  I'll be a foreman today, and then next week, I'll be  executive vice president, and then I'll be associate ", "executive president.  And a rod goes through his head, and he  goes, wait a minute.  Life is short.  It could end at any moment.  Why not just do what I want to do all the time?  Because the next rod could come who knows when. ", "And I had all these plans, and I was promising people things  next week that I delivered on.  But that's a sucker's life, because your life  can end like that.  So forget all the stuff about-- just enjoy the moment. ", "That's a possible thing, OK?  You see movies like that, where people are told, you  have so long to live, and they change.  What would you want to convince yourself that it  wasn't something like that, which is not an unreasonable ", "interpretation?   What you would want to see, at a minimum, is that if you have  brain injuries other places in the brain, you don't see that. ", "And if you have other people with brain injuries in the  same part of the brain, you see that consistently.  At a minimum, you want to say it's not  just a big brain injury.  But it's consistently a brain injury in this part of the  brain that leads to this kind of behavior. ", "And for at least this example, that's true.  Other patients with similar injuries behaved similarly.  People with very big injuries elsewhere in the brain don't  behave similarly.  So there's a lot of reason in the end for us to believe that ", "this part of the brain is essential for something that  we consider almost metaphysical.  Character has this incredibly physical dependence.  And relatively recently, just a few years ago, they ", "discovered a picture of Phineas Gage himself.  Here's the rod.  Here's the injury to his eye, his eye is damaged. ", "So one more example, and then we'll switch this refrain.  Paul Broca.  And Broca's area in the brain, here's Paul Broca.  Here's a brain of a patient named Mr. Tan.  And let me say a word about the story. ", "So in France, a number of people observing patients with  injuries had talked about that the left side of the brain is  important for speech.  Until then there had not been much ideas that the left and  right were fundamentally different. ", "So there's always sort of a  background before the discovery.  And there's a talk in 1861 which describes a man who lost  his speech but understood everything said to him.  He couldn't produce speech.  He could understand speech. ", "His intelligence is still unimpaired.  His speech is gone.  And then Broca heard that talk, and he went back, and  five days later a patient named LeBorgne, who had lost  his speech-- he could only say two things, \"tan,\" and he ", "could swear like crazy.  And our current thought about that is swearing that's  emotional and intuitive, not the one where you think, OK,  I'm going to swear now to scare somebody. ", "But the one-- you stub your toe in the middle of the  night, and you really let out a curse--  we think that's guided like an animal cry  by the basal ganglia.  Those heartfelt, really emotional cursing is not ", "really language.  It's actually the same cry an animal makes on injury.  And it uses some of the same neurocircuitry.  But for higher level cortical stuff, the only word he could  say was \"tan.\" He died in 1871. ", "They looked at his brain, and they found this change in the  left frontal cortex.  And we now call that Broca's aphasia, the inability to  speak despite the presence of--  your mouth can move, and you can understand ", "language pretty well.  We'll come back to that.  So we talk about Broca's area, and then Wernicke--  the Broca's area's important for production.  And here's the kind of damage.  And we'll come back to Broca's aphasia later in the course. ", "So this was a big hint that there's something different  between the right and the left hemispheres.  Now in what percentage of people is language, especially  speech production, predominantly in the left? ", "And our best answer for that comes from a thing  called the Wada Test.  So this is a test given to patients who are undergoing  neurosurgery for something like epilepsy,  sometimes for tumors. ", "And they want to know for you personally with great  certainty, which hemisphere is the eloquent or speaking  hemisphere?  Because they want to remove more tissue if they're away ", "from your language areas, and less tissue if they're near  your language areas.  Maybe they won't even do a certain surgery if they're too  much in the middle of your language areas.  Because in many cases, it's so frustrating for people to lose ", "their ability to speak their thoughts, that they'd rather  have the seizures, for epilepsy, than  be unable to speak.  So physicians and neurosurgeons are very worried  about that.  So what they give you is, they give you a test where they put ", "in a drug called sodium amytal.  And they inject it into your femoral or carotid artery.  It feeds up.  And the way that the vasculatures between the two  hemispheres-- it mostly shuts down the operation of one ", "atmosphere.  If you're injected in this femoral artery, it'll mostly  shut down your left.  In this one, it will mostly shut down your right.  And while the patient has one hemisphere turned off, and ", "they know this because for example, let's say they shut  down this hemisphere with the injection.  You're waving your arm.  It falls down because your motor system can no longer  control your arm.  You're blind in this field.  We'll talk about that. ", "Many of the mental processes done by this half of the brain  are shut down.  And then they'll test you like crazy to see if you can talk.  They'll say, what are the days of the week?  What's your name?  Name these pictures.  OK?  Until the drug wears off. ", "And then you come back two days later or a day later, and  they'll inject the other side.  And they'll know with near certainty in you which is the  side of your brain that does the speaking.  And best estimates are that something like 90% to 99% of ", "people speak from their left.  Even left-handers mostly speak from the left hemisphere.  Because these are patients with epilepsy, we're not quite  sure how they generalize to everybody.  We wouldn't do this with typical people. ", "Because these kinds of tests are invasive and a bit risky.  But our best estimates are that if you're right-handed,  it's almost certain you speak from your left hemisphere.  And if you're left-handed, about 80% of left-handed ", "people also speak from the left hemisphere.  So it doesn't go by handedness, which makes  handedness a bit more of a mystery.  So now switch from grey matter discussions to white matter. ", "In the middle of your brain is something  called the corpus callosum.  Here it's viewed from the middle, if we cut  the brain this way.  200 million myelinated fibers that connect the similar areas ", "from the left and the right.  This is what hooks up the left and right hemisphere  from spot to spot.  Here it is connecting--  and this is from the side view-- so it's a huge white ", "matter area.  Corpus callosum.  And people noticed it because it was so striking.  But they couldn't figure out what it does.  And it kind of started to figure a little bit in  philosophical debates. ", "Would a divided brain-- if you cut the  brain down the middle--  would it read to separate stores of mood,  predisposition, knowledge, and memory?  That is, if your two halves of your brain were divided from  one other, would you be sort of two people? ", "Now, we're not going to do that to you.  But the fascinating thing is, are you two people to start  with, who talk to one another sometimes  across your corpus callosum? ", "And William McDougall said, well, the unity of  consciousness does not depend on the unity  of the nervous system.  And he volunteered for commissurotomy to cut the  corpus callosum.  Erickson noted in 1940 that epileptic seizures would ", "become generalized convulsions often in animal models--  if the seizure began here, it would spread to the  corresponding part of the opposite side of the brain,  and become a much worse seizure. ", "So they got the idea that if they cut the corpus callosum  in patients with severe epilepsy who did not respond  to medications that maybe that would make the  seizures less severe.  Does that make sense?  Because you wouldn't transmit the seizure from the left to ", "the right or the right to left.  But people were sort of almost making jokes  about the corpus callosum.  Because they couldn't figure out what it does.  They said, \"The corpus callosum is hardly connected  with the psychological functions at all. ", "It is for transmitting seizure activity from one hemisphere  to the other.\" That's kind of a neurology joke.  Or Karl Lashley at Harvard, \"to keep hemispheres from  collapsing into one another.\" You do have to have structure ", "to keep things from collapsing.  So now I need to tell you a word for the next couple  minutes for this to make sense, about how your visual  system is organized.  So here's the world out there. ", "And if you're looking straight ahead, everything to the left  people call the left visual field, everything to the right  people call the right visual field.  And we'll look at this more next week a little bit.  But weirdly, your eyes are not set up in that way. ", "You could think this eye looks at this half, and this eye  looks at that half.  The way it's set up, each eye looks at both fields.  Each eye looks at both fields. ", "And then the neurons that leave the eye get organized  here in the optic chiasm.  So by the time they move out towards the brain, everything ", "in the opposite half of the world is reflected.  So everything that's in the right visual field starts in  your brain in the left hemisphere.  Everything that's in the left visual field starts in your  brain in the right hemisphere. ", "Does that make sense?  So the first part of your smart neocortex that knows  what's out there as you're looking at a face, a word, a  scene, anything--  the right occipital cortex notices what's on the left, ", "and the left occipital cortex notices on the right.  Things are so seamlessly integrated in the brain that  you don't ever have that feeling.  You almost never have like, we're getting bad signals on  the left here. ", "If you didn't have a course like this, you wouldn't know  that exists.  And you could wonder, why on Earth is it like that?  Is it just to torture students and confuse them about fields,  eyes, and brains?  And people debate about some evolutionary ", "history behind this.  But it's a great big mystery--  why we don't organize things much more simply and just go  all the way this way.  Quite the opposite.  We have in the left posterior areas, that's where we see the ", "right half of the world.  And then things get integrated.  Is that OK?  Keep in mind also that our left hemisphere moves our  right hand, and our right hemisphere  moves our left hand.  So at least that's the same story-- ", "opposite hemisphere seeing the opposite field, controlling  the opposite hand.  So imagine these kinds of patients who had the surgery  that divided the corpus callosum or ", "treatment of epilepsy.  Let me tell you a couple things.  Clinically, it was pretty rarely done.  There weren't that many of them.  It's pretty rarely done nowadays, first.  Second, the first thing that people noticed was, it didn't ", "have much an effect on the patients.  It's a fascinating story.  Nobody noticed anything for decades.  Because they didn't have the right questions to ask. ", "So these patients are not like astounding patients, I can't  believe when I see them.  They seem pretty much like the same as they were.  I'll show you a video in a couple minutes of two of them. ", "They're not looking unusual in most ways.  But when people figured out what to ask of them, they saw  remarkable things.  They saw two minds in one head. ", "And here's how they saw that.  If they showed them a picture, let's say of a spoon and a  picture of a cup simultaneously in the two  fields, they would be up briefly and go. ", "But it's easy for you to say, I saw a spoon and I saw a cup.  They would say, what did you see?  And the person would say, a cup.  And that would be it. ", "What did you see?  A cup.  Because the information in the right visual field goes into  the left hemisphere.  That's the speaking hemisphere.  So left hemisphere says, I saw a cup. ", "The right hemisphere saw this perfectly well.  It's typically not the speaking hemisphere.  So that information is locked in the right hemisphere, and  it doesn't have access to the speaking part of the brain in ", "the left hemisphere.  So each hemisphere had its own experience, and only the left  hemisphere could speak.  You would integrate this information instantly via the  corpus callosum. ", "But each hemisphere only knew what it saw.  And so here's another example, which is not only that each  hemisphere only knows what it knows.  But it's completely ignorant that the  other one knows anything. ", "It's as if the two of you were sitting next to each other and  don't know each other, are not passing notes  or tweeting or whatever.  It's as if like, do you know exactly what the person next ", "to you is thinking?  No, not necessarily.  So that's exactly what it is like, like you're in one  person in their brain, in their skull.  So they would show them a square in the left visual ", "field and a triangle in the right visual field.  You would say, I saw a square, I saw a triangle.  What do you want?  Here's what happens.  If they're asked to say, say what did you see?  And then behind a board, draw what you saw. ", "The board is there so it's not confusing them.  So here's what they say.  What did you see?  I saw a triangle.  Because it's in the right field, it goes into their  visual area in the left hemisphere.  That's the speaking hemisphere. ", "But if they're drawing with their left hand,  what do they draw?  The square.  Because the right hemisphere saw a square, so the left hand  is drawing, it draws the square.  So simultaneously they will say, a triangle, and the hand ", "behind the board will draw a square.  And the patient is not bothered in the least.  Because each hemisphere only knows what it knows.  The reason they have the board there is if they didn't have ", "the board there, then the left hemisphere would see you  drawing a square.  And you go like, why am I drawing a square?  I saw a triangle.  And the person would be weirded out.  Does that make sense?  ", "But here's the thing.  The amazing thing is both of them have a lot of smarts by  themselves.  And they're completely unaware of what the  other hemisphere knows.  Again, the idea is in you, the hemispheres are ", "talking all the time.  But at lots of moments, different parts of your brain  might be knowing different things.  And we have a lot of belief for that.  But this is the most striking demonstration.  So here's a patient who was asked to say what he saw and ", "pick it up.  He had one instruction.  Read what you see, and pick it up with your left hand.  So he sees the word ring.  In the speaking hemisphere, he says ring. ", "His left hemisphere sees the word key, has enough language  to read that.  And it picks up the key behind the board.  And it never says, I saw two things or anything like that  in most cases. ", "So let me stop here.  And can we do the first video?  So you're going to see an example of a patient named  Vicky who's going to be tested by Mike Gazzaniga. ", "You're going to see two videos with Mike Gazzaniga when he  was younger and when he was older.  He did a lot of the work with these split brain patients.  Plus, Alan Alda from MASH will visit Mike Gazzaniga in the  second one.  ", "So one of the really interesting things is these  split brain patients have given us a chance to ask, you  and I, what are some different ways in which the right  hemisphere and left hemisphere are your own minds? ", "And what are the things they seem to care about, and that  are useful?  So here's one example from Jerre Levy.  It's a very clever experiment.  She would show in the left or right visual field  something like this. ", "And then say, in free view, which of these two things is  more similar?  And on purpose it's ambiguous.  On purpose you could say, well, this is more similar ", "because it has a similar shape or appearance.  This is more similar because I use a spoon and a fork to eat  a piece of cake.  And if this was seen by the left hemisphere, people would ", "pick by function.  If this was seen by the right hemisphere, the patients would  pick by appearance.  So the ideas is that the left-- and this is the power ", "of having two hemispheres in parallel figuring out what's  going on-- one is figuring out what's the information I need  about shape and things like that in the world?  And what's the information I need about function? ", "And because you have two semi-independent brains in  you, you're constantly figuring out form and function  and then using whatever you need to use to solve the  problem in front of you. ", "Does that make sense?  So here's another nice one.  Here's scissors projected into left visual field.  The right hemisphere, that would pick the  spoon and the fork.  Because the crossing shape is resembling that. ", "In the right visual field, left hemisphere, people would  pick the needle and thread.  Because that functionally goes with scissors.  So your mind is seeing the same thing, but in one case  it's tuned, in the left hemisphere, to functions, and ", "the right hemisphere to appearance.  So these are just notes for you going over what I said.  So they talked about, would you have two different  consciousnesses in you?  It's hard really to tell. ", "They did one experiment with Vicky, where they would  present a nude picture in the left visual field  unexpectedly--  and this was a long time ago, it was a shocking thing.  And the patient would blush and giggle. ", "When asked to explain why you were blushing and giggling,  all she could say is, oh doctor, you have some machine.  She knows something funny happened and inappropriate.  She can't tell you just in the language in the hemisphere ", "that saw it.  And so she gives this other kind of description.  Another kind of a favorite one is the dresses one.  There was one patient who went back to work in his father's  grocery store.  And this could be frustrating, early on after his treatment. ", "He would stock things onto a shelf with one hand and remove  it with the other.  You could imagine that would be a slow work day.  These kinds of weird behaviors pretty much  clear up within weeks. ", "After that, you have to test to see the difference.  Another one, they presented the instructions -- walk  across the room to the left visual field, right  hemisphere.  Person gets up, walks across the room.  That person's asked, why did you walk across the room? ", "Person doesn't know why.  Because their speaking hemisphere didn't see it.  And they'll just say something like, I was thirsty.  So interestingly, they fill in motivations.  They don't say, I don't know why, or I have a split brain. ", "What do you expect?  I mean they're being tested for that, right?  But they seem like they want to fill in some other  explanation.  And I'll show you another example for that.  And social psychologists have said-- ", "because they like this--  they said, this is an example that people are desperate  rationalizers for ourselves.  We'll come back to this in social psychology.  You could think about whether it's true for yourself or not. ", "That when things are contradictory, we don't say,  oh, things are contradictory.  We say, well, here's why, as we explain our own behavior,  that we have to rationalize our own behavior. ", "So here's the example.  Here's the picture.  So here's a split brain patient.  And he's shown pairs of pictures in visual fields. ", "And he's supposed to pick two of them in free vision, then  relate to what he sees.  Here's the picture that he sees.  Boom, this goes up and goes away.  Now both hands go and pick something related to what the ", "person just saw.  OK So this is shown briefly.  It disappears.  This hand--  let me do this right--  the chicken went to this part of the brain that ", "controls this hand.  So the claw goes to the rooster.  This hemisphere saw a snowy scene, controls this hand and  it goes for the shovel. ", "So now they're going to make the patient confront the  weirdness of what he just did.  His hand went out.  Each hemisphere points to what it saw.  And again, his answer could be, I'm in an experiment. ", "You're constantly tricking me.  I know that.  Basically they know that, they're in an experiment.  But his answer is, I saw a claw--  that's the speaking hemisphere.  I picked the chicken. ", "OK, that's fine, left hemisphere is speaking.  And then you have to clean out the  chicken shed with a shovel.  OK You understand?  He's creating a story to make his behavior seem coherent. ", "Rather than just saying, I'm an experimental subject and  that's why you're testing me.  Here's the last thing I want to show you for two minutes.  And then I'm going to show you a film that touches on this.  Psychologists are interested in understanding also in what ", "way we see the forests and the trees.  You see the bumper stickers, think globally, act locally.  Let's talk about global and local, or parts and wholes.  So the whole here is H. And the locals are S. Does that ", "makes sense?  It's a way to operationalize an experiment looking at the  forest versus the trees of S's.  Here the whole is the C, and the local elements are O's. ", "And there's a painter who did beautiful pictures.  You'll see another example.  But he made whole faces out of vegetable parts.  OK, do you see that? ", "Every part here of this face, if you look at it piece by  piece, is a different vegetable or fruit.  So it's a sort of play on this thing, and you'll see the ", "movie that way.  He made the whole face of the parts of this.  But here's what split brain patients do.  And I'll show you something else in a moment.  They're asked shortly after surgery to copy this. ", "It's right in front of them all the time.  It's right in front of them all the time.  Just copy what's right in front of you.  If they do it with their left hand, right hemisphere, you  see that you get the forest but not the trees. ", "Here's the trees, and then they don't  look that good, honestly.  But still, there's some Y-ish thing there.  Copy this.  It's right in front of you.  If it's the left hand, you get the forest but not the parts. ", "If it's the right hand, you get the  parts but not the forest.  Does that make sense?  It's as if each hemisphere is one hemisphere-- the left  hemisphere is seeing the parts, and the right  hemisphere is seeing the whole. ", "So that's awesome.  Because you don't have to be global or local.  Your mind is simultaneously figuring out the local parts  and the global parts.  And then you can use whatever is the useful information. ", "Your mind, because you have multiple brains in you, is  sort of figuring out what it needs to do.  Last thing I'll show you, and then we'll do one more video.  Here are patients who have injuries after stroke. ", "It's the same idea, though.  So here's what they have to copy.  It's right in front of them.  Just copy it exactly.  That's all they have to do.  If the patient has damage on the right, he loses his sense ", "of wholeness.  You see there's lots of Z's, that's the parts perceived by  the intact left hemisphere.  But the right hemisphere is not giving very much  information about the whole. ", "Here's another patient with left hemisphere damage.  That person fails to appreciate the parts,  but gets the whole.  Here's the same thing down here.  A patient with right hemisphere damage appreciates  the parts in the intact left hemisphere, but doesn't ", "appreciate the whole in the injured right hemisphere.  Conversely, here's the injured left hemisphere.  That patient copies the whole.  The right hemisphere gets it, left hemisphere  is missing the parts. ", "The amazing thing?  It's right in front of them.  They're copying it.  But if your brain is injured, it no longer appreciates that  the whole exists or that a part exists. ", "It's as if it wasn't there.  So that's how much our mind is what our brain  does in this regard.  And so if we do the last video you'll see that again.  ", "Any questions on what you saw?  So I would say neurons are unbelievably--  we can't even begin to figure out your brain  at the neuron level.  We're so far from that.  The big message from this last part besides hemispheric ", "specialization is that your brain--  and we'll show you this over and over  again in this course--  is a society of semi-independent brains doing  their own thing, sharing information as needed. ", "And the more we study the brain, the more we understand  how many parts of you there are that are semi-independent  and autonomous.  Thanks. "], "vid_duration": [10.649, 12.814, 12.207, 11.831, 14.249, 10.11, 10.03, 15.02, 11.03, 12.15, 12.3, 10.41, 12.09, 11.67, 10.15, 13.1, 10.71, 10.74, 10.61, 10.589, 10.82, 11.05, 12.021, 11.5, 10.01, 11.81, 10.97, 10.45, 10.77, 10.53, 10.58, 11.35, 10.7, 11.0, 11.89, 11.93, 13.95, 12.71, 10.05, 11.94, 10.58, 11.56, 11.59, 10.089, 12.211, 13.43, 11.05, 12.37, 13.19, 11.11, 12.16, 11.23, 10.86, 10.84, 10.68, 10.39, 11.28, 11.26, 12.62, 10.55, 10.6, 10.05, 14.37, 10.39, 11.46, 11.86, 10.81, 10.6, 12.78, 12.57, 10.22, 10.08, 10.27, 11.25, 12.13, 11.95, 12.08, 12.08, 11.34, 12.76, 10.06, 10.2, 10.63, 12.47, 11.69, 10.97, 12.98, 12.36, 10.96, 10.39, 10.33, 10.28, 10.58, 12.29, 12.45, 13.07, 10.83, 10.16, 11.16, 11.67, 12.9, 10.6, 11.68, 10.79, 10.26, 12.62, 11.6, 11.0, 10.28, 10.96, 10.68, 10.06, 12.79, 12.54, 11.02, 11.1, 11.91, 11.44, 10.14, 11.38, 10.296, 11.224, 11.45, 11.64, 10.58, 11.53, 10.88, 11.89, 10.22, 10.26, 12.17, 11.64, 10.95, 11.56, 10.78, 10.86, 11.11, 12.91, 12.29, 10.55, 13.5, 14.21, 11.9, 12.47, 12.91, 11.38, 10.55, 14.36, 11.59, 11.0, 11.77, 10.13, 10.51, 10.44, 11.23, 12.41, 10.42, 12.18, 11.08, 11.72, 12.69, 10.14, 10.69, 10.92, 12.6, 10.22, 10.28, 11.72, 11.99, 10.685, 12.265, 11.42, 12.97, 11.55, 11.88, 13.23, 11.5, 10.389, 11.471, 11.819, 11.801, 13.09, 10.18, 10.33, 10.57, 14.2, 11.46, 11.8, 12.27, 11.09, 10.23, 10.39, 11.61, 10.42, 12.9, 11.25, 11.42, 10.22, 11.47, 11.17, 11.87, 11.22, 10.12, 11.76, 11.25, 11.02, 11.68, 10.89, 10.42, 13.17, 12.49, 10.58, 10.51, 10.68, 10.46, 11.17, 13.02, 12.08, 10.29, 11.17, 11.05, 10.05, 13.32, 11.22, 12.46, 12.37, 10.37, 10.95, 11.27, 10.39, 11.04, 12.1, 20.84, 10.795, 10.935, 10.52, 11.54, 11.07, 11.7, 10.56, 12.22, 12.63, 11.16, 10.19, 11.35, 12.16, 10.81, 11.95, 10.86, 10.39, 10.18, 11.75, 13.56, 12.25, 10.43, 10.68, 11.19, 10.5, 14.23, 11.53, 13.77, 11.99, 10.26, 10.01, 10.51, 13.55, 12.04, 10.96, 11.18, 13.36, 13.6, 11.04, 14.43, 12.38, 11.76, 18.708, 12.122, 13.09, 9.51], "stet": [[0, 10.649], [10.649, 23.463], [23.463, 35.67], [35.67, 47.501000000000005], [47.501000000000005, 61.75000000000001], [61.75000000000001, 71.86000000000001], [71.86000000000001, 81.89000000000001], [81.89000000000001, 96.91000000000001], [96.91000000000001, 107.94000000000001], [107.94000000000001, 120.09000000000002], [120.09000000000002, 132.39000000000001], [132.39000000000001, 142.8], [142.8, 154.89000000000001], [154.89000000000001, 166.56], [166.56, 176.71], [176.71, 189.81], [189.81, 200.52], [200.52, 211.26000000000002], [211.26000000000002, 221.87], [221.87, 232.459], [232.459, 243.279], [243.279, 254.329], [254.329, 266.35], [266.35, 277.85], [277.85, 287.86], [287.86, 299.67], [299.67, 310.64000000000004], [310.64000000000004, 321.09000000000003], [321.09000000000003, 331.86], [331.86, 342.39], [342.39, 352.96999999999997], [352.96999999999997, 364.32], [364.32, 375.02], [375.02, 386.02], [386.02, 397.90999999999997], [397.90999999999997, 409.84], [409.84, 423.78999999999996], [423.78999999999996, 436.49999999999994], [436.49999999999994, 446.54999999999995], [446.54999999999995, 458.48999999999995], [458.48999999999995, 469.06999999999994], [469.06999999999994, 480.62999999999994], [480.62999999999994, 492.2199999999999], [492.2199999999999, 502.3089999999999], [502.3089999999999, 514.5199999999999], [514.5199999999999, 527.9499999999998], [527.9499999999998, 538.9999999999998], [538.9999999999998, 551.3699999999998], [551.3699999999998, 564.5599999999998], [564.5599999999998, 575.6699999999998], [575.6699999999998, 587.8299999999998], [587.8299999999998, 599.0599999999998], [599.0599999999998, 609.9199999999998], [609.9199999999998, 620.7599999999999], [620.7599999999999, 631.4399999999998], [631.4399999999998, 641.8299999999998], [641.8299999999998, 653.1099999999998], [653.1099999999998, 664.3699999999998], [664.3699999999998, 676.9899999999998], [676.9899999999998, 687.5399999999997], [687.5399999999997, 698.1399999999998], [698.1399999999998, 708.1899999999997], [708.1899999999997, 722.5599999999997], [722.5599999999997, 732.9499999999997], [732.9499999999997, 744.4099999999997], [744.4099999999997, 756.2699999999998], [756.2699999999998, 767.0799999999997], [767.0799999999997, 777.6799999999997], [777.6799999999997, 790.4599999999997], [790.4599999999997, 803.0299999999997], [803.0299999999997, 813.2499999999998], [813.2499999999998, 823.3299999999998], [823.3299999999998, 833.5999999999998], [833.5999999999998, 844.8499999999998], [844.8499999999998, 856.9799999999998], [856.9799999999998, 868.9299999999998], [868.9299999999998, 881.0099999999999], [881.0099999999999, 893.0899999999999], [893.0899999999999, 904.43], [904.43, 917.1899999999999], [917.1899999999999, 927.2499999999999], [927.2499999999999, 937.4499999999999], [937.4499999999999, 948.0799999999999], [948.0799999999999, 960.55], [960.55, 972.24], [972.24, 983.21], [983.21, 996.19], [996.19, 1008.5500000000001], [1008.5500000000001, 1019.5100000000001], [1019.5100000000001, 1029.9], [1029.9, 1040.23], [1040.23, 1050.51], [1050.51, 1061.09], [1061.09, 1073.3799999999999], [1073.3799999999999, 1085.83], [1085.83, 1098.8999999999999], [1098.8999999999999, 1109.7299999999998], [1109.7299999999998, 1119.8899999999999], [1119.8899999999999, 1131.05], [1131.05, 1142.72], [1142.72, 1155.6200000000001], [1155.6200000000001, 1166.22], [1166.22, 1177.9], [1177.9, 1188.69], [1188.69, 1198.95], [1198.95, 1211.57], [1211.57, 1223.1699999999998], [1223.1699999999998, 1234.1699999999998], [1234.1699999999998, 1244.4499999999998], [1244.4499999999998, 1255.4099999999999], [1255.4099999999999, 1266.09], [1266.09, 1276.1499999999999], [1276.1499999999999, 1288.9399999999998], [1288.9399999999998, 1301.4799999999998], [1301.4799999999998, 1312.4999999999998], [1312.4999999999998, 1323.5999999999997], [1323.5999999999997, 1335.5099999999998], [1335.5099999999998, 1346.9499999999998], [1346.9499999999998, 1357.09], [1357.09, 1368.47], [1368.47, 1378.766], [1378.766, 1389.99], [1389.99, 1401.44], [1401.44, 1413.0800000000002], [1413.0800000000002, 1423.66], [1423.66, 1435.19], [1435.19, 1446.0700000000002], [1446.0700000000002, 1457.9600000000003], [1457.9600000000003, 1468.1800000000003], [1468.1800000000003, 1478.4400000000003], [1478.4400000000003, 1490.6100000000004], [1490.6100000000004, 1502.2500000000005], [1502.2500000000005, 1513.2000000000005], [1513.2000000000005, 1524.7600000000004], [1524.7600000000004, 1535.5400000000004], [1535.5400000000004, 1546.4000000000003], [1546.4000000000003, 1557.5100000000002], [1557.5100000000002, 1570.4200000000003], [1570.4200000000003, 1582.7100000000003], [1582.7100000000003, 1593.2600000000002], [1593.2600000000002, 1606.7600000000002], [1606.7600000000002, 1620.9700000000003], [1620.9700000000003, 1632.8700000000003], [1632.8700000000003, 1645.3400000000004], [1645.3400000000004, 1658.2500000000005], [1658.2500000000005, 1669.6300000000006], [1669.6300000000006, 1680.1800000000005], [1680.1800000000005, 1694.5400000000004], [1694.5400000000004, 1706.1300000000003], [1706.1300000000003, 1717.1300000000003], [1717.1300000000003, 1728.9000000000003], [1728.9000000000003, 1739.0300000000004], [1739.0300000000004, 1749.5400000000004], [1749.5400000000004, 1759.9800000000005], [1759.9800000000005, 1771.2100000000005], [1771.2100000000005, 1783.6200000000006], [1783.6200000000006, 1794.0400000000006], [1794.0400000000006, 1806.2200000000007], [1806.2200000000007, 1817.3000000000006], [1817.3000000000006, 1829.0200000000007], [1829.0200000000007, 1841.7100000000007], [1841.7100000000007, 1851.8500000000008], [1851.8500000000008, 1862.5400000000009], [1862.5400000000009, 1873.460000000001], [1873.460000000001, 1886.0600000000009], [1886.0600000000009, 1896.2800000000009], [1896.2800000000009, 1906.5600000000009], [1906.5600000000009, 1918.2800000000009], [1918.2800000000009, 1930.270000000001], [1930.270000000001, 1940.9550000000008], [1940.9550000000008, 1953.220000000001], [1953.220000000001, 1964.640000000001], [1964.640000000001, 1977.610000000001], [1977.610000000001, 1989.160000000001], [1989.160000000001, 2001.040000000001], [2001.040000000001, 2014.2700000000011], [2014.2700000000011, 2025.7700000000011], [2025.7700000000011, 2036.159000000001], [2036.159000000001, 2047.630000000001], [2047.630000000001, 2059.449000000001], [2059.449000000001, 2071.250000000001], [2071.250000000001, 2084.340000000001], [2084.340000000001, 2094.520000000001], [2094.520000000001, 2104.850000000001], [2104.850000000001, 2115.420000000001], [2115.420000000001, 2129.620000000001], [2129.620000000001, 2141.080000000001], [2141.080000000001, 2152.880000000001], [2152.880000000001, 2165.150000000001], [2165.150000000001, 2176.240000000001], [2176.240000000001, 2186.470000000001], [2186.470000000001, 2196.860000000001], [2196.860000000001, 2208.470000000001], [2208.470000000001, 2218.8900000000012], [2218.8900000000012, 2231.7900000000013], [2231.7900000000013, 2243.0400000000013], [2243.0400000000013, 2254.4600000000014], [2254.4600000000014, 2264.680000000001], [2264.680000000001, 2276.150000000001], [2276.150000000001, 2287.320000000001], [2287.320000000001, 2299.190000000001], [2299.190000000001, 2310.4100000000008], [2310.4100000000008, 2320.5300000000007], [2320.5300000000007, 2332.290000000001], [2332.290000000001, 2343.540000000001], [2343.540000000001, 2354.560000000001], [2354.560000000001, 2366.2400000000007], [2366.2400000000007, 2377.1300000000006], [2377.1300000000006, 2387.5500000000006], [2387.5500000000006, 2400.7200000000007], [2400.7200000000007, 2413.2100000000005], [2413.2100000000005, 2423.7900000000004], [2423.7900000000004, 2434.3000000000006], [2434.3000000000006, 2444.9800000000005], [2444.9800000000005, 2455.4400000000005], [2455.4400000000005, 2466.6100000000006], [2466.6100000000006, 2479.6300000000006], [2479.6300000000006, 2491.7100000000005], [2491.7100000000005, 2502.0000000000005], [2502.0000000000005, 2513.1700000000005], [2513.1700000000005, 2524.2200000000007], [2524.2200000000007, 2534.270000000001], [2534.270000000001, 2547.590000000001], [2547.590000000001, 2558.810000000001], [2558.810000000001, 2571.270000000001], [2571.270000000001, 2583.640000000001], [2583.640000000001, 2594.0100000000007], [2594.0100000000007, 2604.9600000000005], [2604.9600000000005, 2616.2300000000005], [2616.2300000000005, 2626.6200000000003], [2626.6200000000003, 2637.6600000000003], [2637.6600000000003, 2649.76], [2649.76, 2670.6000000000004], [2670.6000000000004, 2681.3950000000004], [2681.3950000000004, 2692.3300000000004], [2692.3300000000004, 2702.8500000000004], [2702.8500000000004, 2714.3900000000003], [2714.3900000000003, 2725.4600000000005], [2725.4600000000005, 2737.1600000000003], [2737.1600000000003, 2747.7200000000003], [2747.7200000000003, 2759.94], [2759.94, 2772.57], [2772.57, 2783.73], [2783.73, 2793.92], [2793.92, 2805.27], [2805.27, 2817.43], [2817.43, 2828.24], [2828.24, 2840.1899999999996], [2840.1899999999996, 2851.0499999999997], [2851.0499999999997, 2861.4399999999996], [2861.4399999999996, 2871.6199999999994], [2871.6199999999994, 2883.3699999999994], [2883.3699999999994, 2896.9299999999994], [2896.9299999999994, 2909.1799999999994], [2909.1799999999994, 2919.609999999999], [2919.609999999999, 2930.289999999999], [2930.289999999999, 2941.479999999999], [2941.479999999999, 2951.979999999999], [2951.979999999999, 2966.209999999999], [2966.209999999999, 2977.7399999999993], [2977.7399999999993, 2991.5099999999993], [2991.5099999999993, 3003.499999999999], [3003.499999999999, 3013.7599999999993], [3013.7599999999993, 3023.7699999999995], [3023.7699999999995, 3034.2799999999997], [3034.2799999999997, 3047.83], [3047.83, 3059.87], [3059.87, 3070.83], [3070.83, 3082.0099999999998], [3082.0099999999998, 3095.37], [3095.37, 3108.97], [3108.97, 3120.0099999999998], [3120.0099999999998, 3134.4399999999996], [3134.4399999999996, 3146.8199999999997], [3146.8199999999997, 3158.58], [3158.58, 3177.288], [3177.288, 3189.41], [3189.41, 3202.5], [3202.5, 3212.01]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [359, 1155, 2159, 3212]}
{"example_id": "mit057@@MIT9_00SCF11_lec15_300k", "text": ["And then things about the brain basis of emotions.  So we have a huge number of words, by one count about 550  words, that describe the feelings we have,  the emotions we have. ", "And there's a lot of overlap conceptually among them, but  we have so many words because we think that, we feel that  from our daily lives, the feelings and emotions that we  have are such a big part of our human existence, how we ", "relate to other people, how we feel when we're by ourselves.  Emotions are just a big, big part of how we  go about our lives.  And they're readily apparent to us everywhere we look on ", "the faces of others.  Positive emotions, negative emotions, fearful emotions,  you see them around you all the time.  In psychology, a lot of ideas about formulating the field go ", "back to William James, who worked at Harvard, who  articulated in many ways, in language that's still relevant  to this day, the basic ideas, the basic things about being a  human that one wants to understand out of a ", "psychology.  And he wrote about emotion this way, \"If you can conceive  of yourself suddenly stripped of all the emotion with which  our world now inspires you, no one portion of the universe ", "would have more important characteristics beyond  another; and the whole character of its things and  series of events would be without significance,  character, expression, or perspective.\" That what we ", "fear, what we desire, what we enjoy, what we find  disgusting--  we'll talk a little bit about disgust today-- that all those  things tell us what's important and whether it's to ", "be avoided or approached, enjoyed or loathed.  And so people have thought about emotions.  You could pick a million different cultural directions.  Here's a picture from Greek philosophy. ", "But you could pick practically every  culture around the world.  You can't be a human and not think about the  feelings you have.  But kind of strikingly in terms of research, for a very, ", "very long time compared to language or thinking or many  topics, people didn't study emotion because it seemed hard  to study scientifically. ", "And it's still harder to study scientifically in many ways, I  think, than cognition.  But there's been tremendous progress in bringing  scientific approaches to understanding something about  emotions in you and I. And like many things, it was ", "reinvigorated around the Renaissance and the mystery of  Mona Lisa's smile.  And now there's entire journals and conferences and  organizations of scientific psychology  devoted to study emotion. ", "It's a big part of our lives.  You would think in the study of the human mind and brain it  would be a big endeavor.  And it is now.  But that wouldn't have been true even 20 years ago. ", "How might we define emotion just to sort of have some  boundaries?  So we could say that emotions are biologically-based  responses to situations that are seen  as personally relevant. ", "They are shaped by learning and usually involves changes  in peripheral physiology.  Your hands are trembling or things like that.  Your heart is pounding.  Expressive behavior, the intonation with which you ", "speak, the facial expression that you  have or see in others.  And subjective experience.  The emotions you have go with what you feel is going on  inside you. ", "Research has tried to distinguish between moods and  emotions, and talk about moods as diffuse, long-lasting  emotional states.  When you're in a funk or a positive mood over days, ", "weeks, months, that's not what we're going  to talk about today.  That's interesting and important also.  We're going to talk about emotions, which are very  punctate, immediate responses to situations, to a specific ", "thing or a specific stress or a specific element of your  environment, an immediate, strong response.  And within that, one more distinction has turned out to ", "be useful for thinking about emotions between two  dimensions, arousal, or you could call it  intensity, and valence.  Arousal means things that are exciting, intense, if they're ", "high arousal, or calm or lethargic  if they're low arousal.  Valence refers to whether it's a positive thing that makes  you elated or contented, negative sad or gloomy. ", "And you can already see, for example,  take positive valence.  Elated is high arousal.  Contented, ah, that's low arousal.  They're both positive, but they're kind of different. ", "So is calm versus lethargic.  Being calm can be sometimes good.  Feeling really slow, really lethargic, also is low  arousal, but it's usually not a desirable low arousal. ", "And so people think that they can take basically these two  dimensions, valence and arousal, and use it as a  useful way to say something like calm is here.  It's a little bit positive and it's low ", "on the arousal dimension.  Excited is up here.  It's a positive valence.  Different things, gloomy is negative and it's fairly  intense feeling, as opposed to merely lethargic. ", "These two dimensions can cover a big sense of the life of  emotions that inhabit us.  And a huge question, and one that's brutally hard to ", "satisfy in some deep scientific way, of course, is  it restricted to humans?  So if you hang around pets and animals in various  circumstances, you can't help but feel they have emotions. ", "It's just very hard for us to ask them to fill out  questionnaires telling us their emotions.  Here's a chimp that has lost its mother recently.  ", "Here's a dog going out for a good old night.  Here's an armadillo going, whee!  It looks pretty aroused.  We don't know how much of this in some cases is us reading ", "human feelings into their expressions, how much of that  is them feeling the same as we do.  There's a lot of sense, obviously, that many species  have feelings as well as humans. ", "We'll focus just on humans today.  And the other thing that's important is  they're shaped by learning.  What that means is many different things, but for  example, they can vary from one culture to another in ", "certain ways.  And here's one example of a movie that's bringing tears to  everybody's eyes, except this person who  finds it utterly hilarious. ", "If you work in emotion research, I can  tell you you get that.  I worked a little bit on that.  You show some really horrible pictures to everybody.  They go, oh, horrible, horrible, horrible.  And somebody else starts laughing.  It's like horror movies. ", "Have you've been around horror movies where some people are  really scared out of their seats and very worried about  the characters and other people think  it's all pretty funny?  So that's your prospective.  It's not an automatic response to many situations. ", "So how have people thought about the emotion you feel  when a bear jumps out of your closet unexpectedly?   Here's the logical one.  Common sense. ", "Bear is scary.  You feel fearful.  That's your subjective experience.  And your body starts to do things like your  heart starts to pump.  Your sweat glands start to sweat, because ", "you go, this is dangerous.  This is scary.  Here comes my body.  That would be the intuitive one.  My heart is pounding because I feel afraid.  Interestingly, you can reverse the order and find some things ", "that are better explained that way.  It's sometimes nice, sometimes people will say, oh my gosh.  Everything in psychology is so obvious.  For some reason, they always say, my grandmother  would have known it.  I don't know why they pick that example. ", "Show us something that science only can tell you.  So here's a very clever reversal from William James  and also Lange.  They reversed it.  They said that first comes the bodily response to the ", "situation and second comes your mind interpreting your  body's primary response.  The exact opposite order of why we feel as we do. ", "\"We feel sorry because we cry, angry because we strike,  afraid because we tremble, and not that we strike, cry, or  tremble because we are sorry, angry, or fearful.\" He sees  the exact opposite.  Here it says first comes an emotion that's shaking your ", "body in some way, and then comes to your mind saying,  aha, I'm afraid--  pretty fast--  or I'm happy or whatever.  Here's some examples, because you could think, OK, yes, you ", "can cleverly reverse them.  But is there any science to suggest that in some cases  that relationship does reverse?  So here's what people did.  And I'll show you a picture for this.  They said, how can peripheral bodily events, things on sort ", "of the edge of our bodies, influence the  emotions we feel inside?  So they would have people do things like hold a pencil  tightly between their teeth and--  look at that pencil. ", "They're not told to smile.  They're just told to keep that pencil there.  And what does that look like?  A smile, right?  OK.  You've tricked the person's face into smiling.  And they don't even know that, necessarily. ", "They're thinking, this is a weird psychology experiment  about how long can you hold a pencil in your mouth, although  they're going to know something more in a moment.  Or between the lips, hold that pencil. ", "Now, does this person look happy?  No.  A little bit not happy, right?  OK.  And then you have them watch a funny movie that most people ", "find funny.  And they rate how much they like it.  And the person who had this one rates it as more enjoyable  than the person holding a pencil this way, as if already ", "having the muscles in your face moved into a position  that typically signals happiness or laughter makes  you feel happy inside and the funny movie is even funnier. ", "Being in a somewhat neutral to negative position makes that  same funny movie seem less funny.  You're interpreting where your muscles are that normally go ", "with one emotion or another, and that's driving your  internal final emotion about how you feel about the movie.  Was there a question?  AUDIENCE: Could it require more  concentration, or patience?  ", "PROFESSOR: Does one require more concentration?  That's an excellent question, because we always like to say,  oh, it's this thing.  What if this is a harder thing like that?  And so when one have to hope-- and I have to  admit I don't know-- ", "that they've controlled for things like that in some way.  If you read the research paper,  you'd want to be concerned.  That's an excellent question.  If this is just harder work than maybe you're paying less  attention to the movie and just hanging onto that pencil. ", "I don't know.  And I have to hope they did a good job on this.  That's an excellent question.  And here's other ones, again, where they're trying to get  the face to go smiley or go frowny. ", "And then they just ask them, how do you feel?  And this person will rate themselves as feeling happier  than this person as they answer on a piece of paper in  front of them.  Again, they're trying to say, if I can move your peripheral ", "facial expressions into--  your muscles into expressions, the feelings will follow from  the expressions.   You can also do something else, which is you can tell ", "people-- so Paul Ekman, his name will come up a lot today.  He's done a fantastic amount of the key research on this,  making emotions into a research topic in many ways.  What he developed is a way that he said, I'm going to ", "describe objectively which muscles are in which position  for each of six fundamental emotional expressions.  We'll come back to those.  So he would tell a person, raise your eyebrows and pull ", "them together.  Raise your upper eyelids.  Now stretch your lips horizontally back  towards your ears.  So what he's giving this person, step by step, is  directions that move the muscles into an expression of ", "fear, by the time you end up there.  The participant usually doesn't know that, because  it's so weird.  You're moving your mouth.  You're moving--  it's just so weird.  But then they can do these kinds of experiments. ", "And these people will report a fearful movie as being more  fearful than somebody who just gets to sit there or whose  muscles are moved into a happy position.  So all of a sudden you've got all these peripheral things ", "being interpreted by our mind as a signal for what emotion  you have, or enhancing it anyway.  And then because any strong theory usually turns out to be  not nearly complicated enough, you get the wishy-washy middle ", "that probably covers more of the truth, which is both  things are going on.  Both you're having a subjective cognitive  interpretation of your environment and a bodily  response, maybe more in parallel than ", "one driving the other.  So again, how can peripheral bodily  events influence emotions?  One idea that's floated around, and probably true, is ", "that the perception or thought, your mental  interpretation of your emotion tells you the type of emotion.  so if a bear jumps out, you can say, OK, I know  something's pretty intense. ", "And I can tell you right away it's bad.  But if something wonderful jumps out of your closet  unexpectedly, then you go, oh my gosh.  I can't believe Lindsay Lohan is visiting me and I didn't ", "even know it.  Then if that is considered a good visit, that would  influence again, the interpretation, but the  intensity might come from the bodily parts. ", "How intense it is might be signaled from that.  So here's a couple of ways that people explore this.  Here's a study from years ago from Schacter, where he  injected people with adrenaline-- ", "adrenaline is the neurohormone that goes with high arousal,  it raises your heart rate--  or a placebo.  So he's directly taking the chemical that we normally ", "produce under higher arousal conditions.  And the first question you might ask is, and you might be  curious about, if somebody gave you a shot of adrenaline,  what would happen? ", "Would you like jump out of your seat and run  laps around the room?  What would you do?  And surprisingly, all by itself, not very much.  People said they feel a bit jittery, like if you've had  maybe a little too much coffee or Red Bull-- ", "is that the current?--   that little jittery feeling.  But they're not like jumping up and do jumping jacks and  one-armed push-ups and stuff like that. ", "Now, having had the placebo or the adrenaline injected into  you, and you don't know that, they show you an  emotion-eliciting--  they'll show you a movie, like a horror movie.  And the people who had the adrenaline will report more ", "fear when they see the horror movie, more anger when they  get insulted.  That's a fun experiment when you insult them.  I'm sure the IRB, you have to be pretty careful.  More laughter for a comedy. ", "Adrenaline seemed to amplify the intensity of the emotion.  But the emotion was driven by the situation.  Does that make sense?  OK?  But here's something quite interesting about humans, ", "which is that if you told them, we've given you  adrenaline and it usually amplifies stuff, then it  disappeared.  Once the person knew that, they could discount that in  their mind. ", "So it's not like adrenaline is your master, and that I must  have twice as big a response.  Once you knew that was in the picture, then the ratings went  back to placebo. ", "It's not that biology is destiny.  But under normal circumstances, it seems like  the adrenaline accentuates the intensity.  So that would go with the possibility that peripheral  stuff drives the intensity, peripherally injected ", "adrenaline, and our mind's  interpretation drives the content.  Here's a sort of fun, slightly sexist experiment that in the ", "end, I think, explains the following phenomenon.  When you see famous movie stars go into a movie set, on  set, or whatever they call it, you incredibly often hear  about romances occurring between the leads, right? ", "And there's debates about what this is just the press agent  selling their movie or whatever.  But you hear that all the time, right?  OK.  So I'm going to tell you why that happens  when it really happens.  I can't really tell you that.  But I can tell you an experiment that ", "might touch on that.  So here's the experiment.  This was done by Dutton and Aron in  North Vancouver, Canada.  And they did the experiment in an area where there were two  bridges not right next to each other, pretty near each other. ", "One was a flimsy suspension bridge, five feet wide,  swaying and wobbling 320 feet over jagged  boulders and river rapids.  So you have to imagine Indiana Jones, OK? ", "And you come to this bridge and you're  going, I don't know.  OK.  The other one, upstream, same river, same Canadian district.  There's a steady, low, broad bridge.  No problem at all. ", "You could drive your car over that, no problem.  Two bridges over the same waters, one  seeming scary, one not.  Then what they did is in the middle of each bridge they ", "placed an attractive, in this case female, confederate.  Maybe somebody's done the reverse gender experiment.  I don't know.  Anyway, as men walk across the bridge, they ask them to fill  out a questionnaire, some boring questionnaire. ", "And they casually mentioned that if that person, as they  finish the questionnaire, has more questions, he can call  the woman providing the questionnaire at home.  And she provides him her home number. ", "And the measure that they have is how many phone calls go  from the male subjects to the female experimenter at home.  And they're betting that it's not really scientific ", "curiosity that's driving a lot of the phone calling.  But here's what they actually find.  More males will call that female at home if they were on  the dangerous bridge than on the safe bridge. ", "That's the actual finding.  And the interpretation is this, the dangerous bridge,  because of the true feeling of danger, produces high arousal,  increased adrenalin.  And that's misinterpreted, if you want to call it that, by ", "the male because he thinks now he's super-attracted to that  woman because of the swaying bridge.  Another reason to take somebody you want to win over, ", "whatever the gender situation is, a really scary roller  coaster ride is highly recommended together with that  warm beverage, as long as it doesn't spill on them. ", "I'm making you too powerful to control people.   Again, the arousal of the bridge has been misinterpreted  by that person as an intense attraction to that woman. ", "And you could imagine making movies are probably high  arousal exciting situations, and that would promote  romantic relations and high intense situations that might  not otherwise occur.  Yes?  AUDIENCE: [INAUDIBLE]? ", "They had to randomly assign them to one bridge or the  other, you would hope.  I can tell you there's been a bunch of other experiments  sort of like this.  This is the most what you could call ecological, silly,  or sexist, you could figure. ", "But they all go with this idea that if you're in a high  arousal situation, you sort of move over that arousal into  whatever it is you're encoding.  Does that make sense? ", "And in this case, because you're creating an interaction  between a man and woman, it's promoting this probability of  a sense of romance in the male.  Is that OK?  But it could be any situation.  The arousal will make it-- if it's something, it can make ", "you feel worse about it.  AUDIENCE: [INAUDIBLE]?   PROFESSOR: Ah.  Totally excellent question.  You're asking awesome questions.  ", "I have to assume-- and I should  know this, but I don't--  that they weren't.  Yes, because if you had males self-selecting, you had some  males running to the danger bridge, drawn to danger, and ", "others saying, oh, please give me a safe road, is that the  real difference.  So you have to presume they did something to  control that, yes.  Excellent question.  ", "The current view is something like that there's two factors,  that there's both.  A bodily response that happens pretty fast, pretty  automatically, pretty unconsciously.  There's a lot of interpretation. ", "And the combination of that bodily response and an  interpretation leads you finally to the subjective  experience you have, and probably works differently for  different emotions.  And things are complicated. ", "But we're pretty far from this first guess in terms of the  fact that peripheral things can have very powerful effects  on how you interpret situations, the intensity of ", "your interpretations.  And the intensity itself can change the behaviors that  follows the situation.  Three questions in the field are, are emotions universal?  Are they in you from when you're born? ", "Are they the same for people around the world?  Do they have unique physiological signatures?  Could we define--  if we knew your heart rate, if we knew your pulse and so on, ", "could we know what emotional state you're in.  And then speculations as to why we have emotions at all.  What's the use of having emotions?  Brilliant as he is in so many ways, in many ways this ", "dialogue began in modern times with Charles Darwin, who  noticed that animals had very striking facial expressions,  as we saw before.  And that made him think about the evolution of facial  expressions.  This is one of his drawings of a cat. ", "Here are infants having early displays of emotions, joy,  disgust, surprise, sadness, anger, fear.  So people have been very impressed that very early on ", "infants are having the full array of expressions.  Of course, they might see them.  From moments from their birth they have people around them.  But it's very early, that's almost for sure. ", "A really interesting line of research-- and I'll show you  an example-- has been looking at emotional expressions,  emotional facial expressions, in people who are born deaf or  born blind, so they never hear intonation. ", "They never see a facial expression.  They can't learn it from their environments.  So they're sort of a natural window into is this inborn in ", "us, or do we learn it from people around us?  Here's an experiment where they took spontaneous facial  expressions of emotion in athletes from both the  Olympics and the Paralympics. ", "And they looked especially at congenitally blind people,  born blind, never saw a face, and sighted athletes.  And they looked at the expressions after winning or  losing an Olympic-level match. ", "Before I show you this, you may know the story.  What happens after an Olympic event?  Somebody wins and where do they go? ", "You know this podium thing?  The gold medal winners up here, and the silvers here and  the bronzes here.  And they've also done studies--this  is just a side note--  saying, who looks the happiest in those pictures? ", "AUDIENCE: Bronze.  PROFESSOR: The bronze medal winner.  Who looks the saddest in those pictures?  AUDIENCE: Silver.  PROFESSOR: The silver, right?  Because the bronze medal winner's going, thank goodness  I came in third place.  I'm on the podium. ", "I have an Olympic medal.  If I'm in fourth place, fourth through infinity gets the same  Olympic medal, right?  The silver medalist, what's he or she thinking?  On average.  Man, if I had just one more fraction of a millisecond, I ", "could be the gold medalist.  It's kind of an interesting thing of when we consider  things satisfactory or not.  But now let's turn back to this question.  Here's two people who just lost Olympic medal matches. ", "And your question is which is a sighted person and which is  a blind person?  And to the extent it's hard to be certain, that would be a  big suggestion that these expressions are inborn in us, ", "because a person who's never seen a sad expression still  has a sad expression.  And the answer is, that's the blind athlete and that's the  sighted athlete. ", "So it's pretty convincing, I think, that we're born with  this set of expressions as a core entity of being human.  ", "Even though we're born with that, we live in different  cultures, very different cultures around the world, and  even within countries and across countries.  So how universal are these sorts of things?  And there's lots of evidence of a degree of influence of ", "cultures around this core universality.  So does a smile mean friendship to everyone?  And again, Ekman and Izard made a big study in which they ", "argued that as far as they can tell in looking around at  facial expressions, there's six basic emotional  expressions that signal feelings, happiness, sadness, ", "fear, anger, surprise, or disgust.  These are all people who are trained to try to make the  perfect expression of those things. ", "They look kind of weird by themselves, right?  They look kind of weird.  You don't see a neutral one here.  Maybe we'll see a neutral one later.  Neutral is kind of weird, because you  go, well, it's neutral.  But I can tell you, a totally neutral face looking at you ", "can be kind of creepy.  Because if you interact with somebody and they have no  expression at all, it's a little disturbing.  But these are ones are pretty universally recognized, but ", "not completely.  Let's take Westerners, people from the  United States or Europe.  We're not perfect in that.  Even with these posed pictures, this is how often  people came up with the correct labels. ", "Pretty often, not perfect.  There's a lot of mystery at the edges of this.  But here's how people came up from non-Western cultures for  the same Western faces.  Well above chance, but not the same as Westerners looking at ", "Western expressions.  And it would reverse if Westerners had to look at  non-Western expressions.  So there's definitely a degree of cultural influences on the  recognition of these expressions as well. ", "It's partly innate and universal, and there's a  cultural overlay as well.  This is a joke.  \"Shoot!  You've got not only the wrong planet, but you've got the ", "wrong solar system.  I mean, a wrong planet I can understand.  But a wrong solar system--\" And you can tell with just a  little information that this is a sheepish smile of  embarrassment.  And this is a little bit of the body expression of a ", "little bit of irksomeness.  Irked.  But here's an isolated pre-literate  tribe in New Guinea.  And that smile looks like the smile of any kid you ever saw. ", "That's sadness, the sadness of any kid you every saw.  That's a little bit of a disgust.  And some people have built up a model, something like  there's things in the environment that happen that ", "drive some sort of facial affect program.  Your muscles in your face move to express 6 or so different  kinds of feelings.  Cultural rules about what should you show, what should ", "you not show in different cultures.  Some face's expressions are more appreciated than others.  And finally, all of that moves into the facial  expression you make. ", "So now the second question we have, we think to a first  approximation emotions, at least as far as we can tell,  are pretty universal but there's cultural and learned ", "pieces as well.  Do emotions have unique physiological signatures?  Can we tell from your  physiology what you're feeling?  And there was a lot of hope that this would work, because  intuitively emotions differ from one another. ", "Our body feels different as we go from  one emotion to another.  And we use language words like \"she got hot and bothered.\"  \"You make my blood boil.\" \"He's just letting off steam.\" ", "Different physiologies go with different feelings.  And so people hoped they could make decision trees like this.  Let's measure your heart rate, high or low.  Well, if it's high, then we get your skin temperature.  And then we can tell if you're angry or fear or sad. ", "That you could make a decision tree by looking at peripheral  measures of physiology.  But it never worked.  It's never been strongly discriminating.  People have not been able to have a physiological ", "fingerprint for the emotion that you feel that's  reasonably accurate.  Yes?  AUDIENCE: So why are they [INAUDIBLE] as something that  could go in that tree, for instance? ", "Could they measure chemical concentrations in places?  PROFESSOR: It's possible, yes.  Here's a very good question.  Here they're measuring peripheral physiology or  autonomic systems, skin temperature, heart rate.  Could there be other things like chemicals, right? ", "So I'd say yes, but we just don't know them well enough.  Or could you have brain measures that ultimately would  be sophisticated enough?  I can tell you that brain measures are not that  good at that now.  But could they be someday? ", "Yes.  So yes, it's the specific measures that we have.  A really deep question will be at some level when you're  fearful and I'm fearful, how identical will those be, ", "depending on our cultural background, depending on  situations we've experienced?  We can both agree we're scared of something, but it could be  pretty different.  ", "So it's a really deep question.  In the end, how close are these things from one person  to another?  Now, at least at speculative is why we have emotions. ", "And sometimes people think it's intrapersonal  functions within us.  We're organizing ourselves-- what's our basic feeling?  Are we basically happy or sad about something or fearful of ", "something?--  so that we use that feeling as a source of information to  sort of pull ourselves to say, this is  basically where I'm at.  It's a source of information for me.  And it can tell me what behavior makes sense to do in ", "this context.  And then from one person to another, interpersonally.  What does that person feel?  What am I signalling to that person?  So here's an experiment.  And I'll show you just a brief YouTube video on this, because ", "I think it's really cute.  But it's almost a life and death experiment, although no  infant was harmed in the making of this experiment.  So what they do is, this is a visual cliff. ", "An infant is put on this, a very tiny baby.  Here it's hard Plexiglas.  There is no danger to the baby.  But there is a drop here and a drop here. ", "Now, as the baby approaches this, they're not used to the  idea of Plexiglas.  Even you and I would be pretty worried about that if it was  on a larger scale.  We'd want to be pretty sure about the strength of the ", "Plexiglas But to the infant's eyes, they're approaching what  they call a visual cliff.  On the other side--  I'll show the film in a moment--  is a mother.  And the mother can either be showing a positive expression ", "or a negative expression.  And look what happens to the infants in this perilous  situation where they see a drop that's a big, and how ", "much they trust their mother's expression to know what to do.  So if the mother is looking happy, like it's OK.  This is going to be great.  We're having a lot of fun.  3/4 of the time the infant goes for it. ", "If the mother looks scary, never.  They're making kind of a dangerous decision entirely on  the facial expression of the mother and their trust that ", "the mother knows the right thing to do and is giving them  the right advice.  ", "Sometimes everything in psychology can just seem like,  oh, it's just another thing.  But facial expressions are an unbelievable powerful way that  we communicate with one another.  ", "Here's an extremely clever experiment from Adam Anderson,  who happened to be a postdoctoral fellow in my lab,  but he did this completely independently. ", "Here's the question.  So we have some different expressions.  And you could say, well, are they completely random as to  what the actual expression is?  We haven't even asked this.  Why does a smile go one way and a frown go the other way? ", "Does it mean anything or are they just arbitrary signals of  different emotions that have evolved over time?  And he's almost the first person I know to  even ask this question.  And he looked at two emotions that we'll come back to in ", "just a little bit, fear, and disgust.  And he thought, well, look, it's kind of interesting what  fear and disgust do.  For example, fear, your eyes get bigger, disgust-- ", "think about something really stinky--  you close your eyes.  You sort of scrunch up your nose.  Look at this.  And he looked at and measured how airflow patterns and ", "different things happen when you go into those expressions,  non-arbitrary properties of an expression.  And then he did psychological expressions.  He got people to get into these expressions. ", "And he found that if they were in a fearful expression, that  they would feel like they had a wider field of view, and if  it's disgust, a smaller. ", "Now think about this for a moment.  When it's fearful, do you want to feel like you know what's  going on around you?  Or do you want to sit back and think about stuff? ", "Or do you want to say like, uh-oh.  Where do I run?  What's going on?  When you go into some disgusting situation, do you  want to really look around a lot?  Or are you kind of happy to find some way out of it? ", "Same thing with your nose.  Here's the air velocity that's passing through your nose when  you're fearful and when you're disgusted.  Now you don't even think about that. ", "Who's thinking, I'm controlling my air velocity?  But why do you think you might want to really sample your  environment when you feel danger, visually and in an ", "olfactory way?  Why do you think you might want to sample?  Well, you want to know what's going on.  You want the information as fast as possible.  Do I run?  Do I duck?  What do I do?  Do I fight, flee?  What do I do?  I have moments to decide, because I'm in danger. ", "If you're in a disgust situation, are you interested,  typically, in exploring the olfactory environment in as  much detail as you can?  Usually not. ", "So it's kind of interesting.  The very first time --  I know, it's very clever --  asked where do these expressions come from?  Well, maybe they tend, to a certain extent, to exaggerate  or diminish forms of sensory input that are relevant for ", "the emotion.  So for the last little bit I'm going to talk about for a  little while what we know about the brain  basis of some emotions.  We already talked about the idea that the amygdala plays a ", "special role in fear.  And I'll show you a couple different ways in  which that's true.  This is just sitting in front of the hippocampus, one on the  left, one on the right, the core elements  of your limbic system. ", "Here it is viewed from the side, the amygdala.   Here's the actual amygdala from a post-mortem brain.  And there's another whole level of analysis that animal ", "researchers do that we can't touch today, which is the  amygdala itself is made out of bundles of neurons called  nuclei, very distinct ones that have different roles,  different inputs, different outputs. ", "And in animal research, where you can selectively influence  one or the other, you can see they have quite different  specific roles.  In humans we don't have that precision of control, so we ", "sort of have some clump average  statements about the amygdala.  But really we're mixing together a few functions.  So you already saw this picture, that animals, mice or ", "rats, that have an amygdala removed lose the fear they  ought to have of a cat.   In primate studies, they found that if they have amygdala  lesions, the loss of threat appreciation impairs social ", "fitness, that animals that don't know what they ought to  be afraid of get into big trouble.  They lose their position in dominance hierarchies.  You may know primate groups tend to have dominance ", "hierarchies, a sort of alpha male and so on.  They slide down that.  If they lesion the dominant male, the alpha male, the male  who wins all the fights and controls the group, that ", "animal will fall down the hierarchy and become  subordinate.  And in the wild, they've shown that if they do lesions and  return the animal to the social situation, they get  rejected by the other animals, because the other animals feel ", "there's something weird about the animals.  And they're often isolated and they get to early death,  because the other animals are not helping them  or supporting them.  So very important for learning what's dangerous. ", "Here's an experiment with rhesus monkeys lesioned at two  weeks as infants, returned to their mothers, and tested at  eight weeks.  And here's an example of something, this is if you show  an animal a novel object. ", "And this is how often they respond to it.  Young animals will often not explore it, because they go,  well, I don't know.  That could be dangerous.  They're waiting for their mother's expression. ", "Here's the other animals with the amygdala lesions.  They'll explore it.  In a sense, they're fearless.  But that's probably not an ideal thing to do when you're  an infant exploring the world. ", "Or they'll put food only or food next to a play snake.  Snakes are dangerous for monkeys. ", "They usually don't want to figure out at this age is it a  play snake or a real snake?  They just say, I don't really need to eat that.  So everybody likes the food.  Put the snake next to it, and the control animals go, no, I ", "don't think so, basically.  The amygdala ones, what's for dinner?  And the answer is, if it's a real snake, you're for dinner.  So they lose the fear of things they ought to have fear ", "of, they lose fear of unknown things, fear of things they  ought to be afraid of.  So the amygdala plays this really important role.  Fear sometimes is maybe the best understood emotion in ", "terms of brain processes, and maybe the most studied, partly  because we've had some success in understanding what's going  on and partly because fear is maybe the emotion that most  people think is closer to survival.  You fear what kills you. ", "You fear what pains you.  That's a very powerful emotion for survival and safety.  And you can do fear conditioning.  We talked about conditioning before in all species, from ", "humans to primates, other mammals, fruit flies.  All of them have, to a first approximation, similar fear  conditioning.  It's as if you're alive, you have to fear things that are ", "scary and dangerous.  So people have done fear conditioning experiments.  And now you know this very well.  You might hear a tone that's not scary at first.  If you put it with something that you don't like, like a ", "foot shock, you get fearful to the tone.  And what people have discovered kind of remarkably  is that you can make lesions in many parts of the brain and  you don't affect that learned fearfulness to the tone. ", "But if you make a damage in the part of the amygdala, you  abolish that learning.  These animals fail to learn the signal of something that  is coming up to be painful and dangerous. ", "And you can even make large lesions in the cortex.  That doesn't affect anything.  And these animals with the amygdala lesions, they have an  intact unconditioned response.  When they get the shock, they jump like the other animals. ", "They don't like it.  It's not that they can't feel pain.  They can't learn that the tone predicts the painful stimulus.  They can't learn the warning signal of danger.  ", "There's very few patients with amygdala injuries only.  But there's a few.  So here's a patient, SM, who's been studied by Damasio and  his colleagues.  This is where the amygdala ought to be. ", "It's a developmental disorder where this is calcified very  early in development.  It's not an adult lesion.  But it seems to be fairly amygdala-specific.   And people have done a couple of ", "experiments with these patients.  And it's sort of guided our understanding of what the  amygdala does in you and I. Here's one example where they  did conditioning.  Again, in this case they didn't use shocks. ", "They used a super-loud boat horn that's  pretty noxious to people.  People don't like it.  And they preceded that with something gentle that warned  you it was coming. ", "Here's the initial response.  And here's the important thing.  With humans, of course you can--  well, let me just say they managed a skin response, a  galvanic skin response to the bad tones. ", "So here's the conditioned stimulus, the response to the  boat horns in the conditioning, what predicts  the boat horns. ", "Here's the response to the baseline.  And here's the performance of patients with amnesia who have  the amygdala--  controls, I'm sorry, who both can tell you they're ", "responding selectively to the scariest tones and also  remember perfectly well.  At the end of the testing session, you go, what went on?  And they say, oh yes.  Well, when I got one signal I got a horrible boat horn. ", "And when I heard the other signal, I got nothing.  It's easy.  You do that for half an hour.  You get one visual signal that means boat horn coming up, one  visual signal, nothing coming up.  If you have patients who have amygdala lesions, that ", "galvanic skin response doesn't happen, even though they tell  you perfectly well afterwards what happened.  So they know just like everybody else that they got a  certain signal that went with a noxious boat horn. ", "But their body is not learning that association.  If a patient has hippocampal damage, their body learns that  association, but they don't remember it afterwards ", "consciously.  So you can separate out two kinds of learning, a  hippocampal-dependent learning of the facts of the session,  and an amygdala-dependent learning, which is a bodily ", "response to learning that something is dangerous and  unpleasant.   Now, we often learn things like the visual cliff without  having to have a boat horn and practice, right? ", "If somebody tells you that something is dangerous, or you  figure out that something is dangerous, you don't have to  go through a terrible experience to pretty much  decide you're not going to do it. ", "So here's an experiment that was aimed at showing you that.  What people were shown-- there's a funny human subjects  wrinkle to this I'll just tell you.  This occurred at Yale, where they had a ", "blue square came on.  That means safe.  You can just relax.  Nothing bad's going to happen.  But when the yellow square comes on, get ready.  You might get a somewhat unpleasant shock. ", "But they never give them a shock.  So you're not learning that way.  You just factually learn that something is safe and  something is dangerous.  And here is the amygdala response to the scary one, to ", "a neutral situation, and to the one where you  know, ah, I'm safe.  So you never got the shock.  You never got the shock.  You were just told about the shock.  You didn't have to get it, but you're human. ", "You can figure this out.  And your amygdala is going, you know, I can just figure  out that's dangerous.  That's baseline.  And that's the absence of danger, positive safety.  ", "The Yale IRB, hilariously I think, said, oh, but you're  deceiving the people, because you tell them they might get a  shock and they never got a shock.  So you have to give them one shock at the end of the  experiment. ", "So dutifully, the experimenters gave them one  shock after the experiment was over so they were honest.  Because during the experiment, as they measured the brain  activation in the amygdala responding to the threat of ", "pain without any pain being associated--  we're smart.  We can learn something is dangerous just by thinking it  through, and it engages the same part of the brain that  learns by actual painful experience. ", "Now how about memory?  So here's the way this study was done.  People viewed a slide story with an  emotional middle section.  So an example would be this, parents are home having ", "breakfast with a kid.  Parents go to work.  Kid walks to school, kind of tragically, but these are all  slides, again, nobody was injured,  child is hit by a car. ", "Something high arousing happens in the  middle of the story.  Everybody runs to the hospital.  The kid is OK.  When people ask a week later or something like that, a week  later, tell me about the stories I told you last week. ", "There's a number of stories.  People have best memory for the part where something  highly arousing happened, like the child was hit by a car.  That makes sense, right?  Kid having breakfast, huh.  Kid OK, huh. ", "Car accident with a kid, you're aroused and you  remember that better.  Emotion is amplifying memory.  The patients with the amygdala lesions don't have that memory  bump based on emotion. ", "The emotion is not enhancing their memory.  And you can imagine that there's a pretty good reason  for emotions to enhance memory, right?  If something is fearful, delightful, horribly ", "disgusting, those are all good reasons to remember.  Let's do that again, if it's great.  Let's avoid that, if it's terrible.  It's a good idea for emotions to drive memory formation. ", "And in your brain and mine, it appears the amygdala has this  role of transforming emotions into memories.  ", "Now we also talked about six facial expressions.  And I showed you this before.  The same patients have trouble in recognizing fearful facial  expressions.  So the amygdala in so many different ways, learning, ", "memory, perception of faces, seems to play this  huge role in fear.   And kind of interesting way, because you might have the ", "intuition--  and a lot of this came from Freud--  that a lot of emotions are happening kind of under our  conscious awareness.  We almost discover them after, like why am I angry with this ", "person, or why am I so happy?  We have to think it through, almost.  If you show subliminal fearful faces versus happy faces,  subliminally presented so people can't tell you what the ", "facial expression was, still they turn on the amygdala.  So unconscious perception of a fearful  face engages the amygdala.  You don't have to go through consciousness. ", "Cortical blindness.  We talked about that earlier in the course, where you're  blind in one visual field.  And yet individual patients, a couple of them with cortical  blindness, if they were shown a fearful stimulus in the ", "cortically blind field, still turn on, in the cortically  blind field, the amygdala for a fearful face versus a happy  face, which indicates that a non-conscious, subcortical ", "pathway that doesn't intersect with conscious thought or  cortex, is sending information from your eyes to your  amygdala, a different pathway. ", "And people have speculated that maybe again because fear  is survival and danger, we might have a super-highway of  information that sends dangerous information ", "immediately to our amygdala.  It doesn't wait for you to think a lot, so to speak, in  your cortex.  Boom.  Danger, danger, danger, even before you process the rest of  the situation. ", "So we talked about fear and the threat in the amygdala.  I'll just say a word about disgust.  People think there's many reasons things we can be  disgusted at or about, but that maybe in terms of ", "evolution, it might have been a pretty good signal for  contaminated food, food that makes you sick, things to  avoid that make you sick.  And it turns out another part of the brain called the insula ", "is pretty important for that.  So here's the amygdala left and right.  Here's the insula that you have, left and  right, outlined in purple.  And again, just like with the amygdala, patients with ", "lesions of the insula don't recognize facial expressions.  And imaging wise, if you see a disgusted face, that turns on  that part of the brain as well.  So those are the best understood brain pieces of ", "emotion by far.  So now those are patient things, so let me turn for a  moment, lastly to a few imaging studies of typical  people and some topics on emotion. ", "So here's some terrible pictures from 9/11.  \"The horror of the moment\"-- and we always  imagine we'll remember--  and we've already talked a little bit about this in  flashbulb memories--  emotionally things correctly for a long time. ", "\"'The horrors of that moment,' the King went on, 'I shall  never forget.'\" This is Lewis Carroll,  Through the Looking Glass.  \"'You will though,' the Queen said, 'if you don't make a  memorandum of it.'\"  And now you know that Lewis Carroll was talking about the  amygdala, right?  You didn't know that before, but you know that now. ", "Because if the amygdala isn't there, the emotional intensity  doesn't make the memory more permanent or more powerful.  So Larry Cahill at UC Irvine did the first brain study on ", "this topic.  And what he did is he showed students while they were  getting PET scanning, Positron Emission Tomography, short  films that were either powerfully ", "emotional or neutral.  And then he brought them back three weeks later.  And here's what he found.  The more activation there was in the amygdala-- ", "each square here is a different person--  the more they remembered the emotional stuff.  But it didn't matter for neutral things.  So the amygdala seems unimportant for neutral  information, but the more it was engaged, the more they ", "remembered emotional information.  So this is sort of evidence in the typical human mind of a  relationship between the amygdala  and emotional memories.  So here's an experiment actually that we did at ", "Stanford, where we showed people stimuli that were  either neutral, somewhat negative-- and I'm going to  show you something that's very negative.  If you don't want to look, close your eyes for a moment.  Close your eyes.  Here we go. ", "Very negative.  OK.  Sorry.  It turns out if we don't show you something that negative,  it's hard to get your brain pumped up.  It doesn't have to be that sad, but it has ", "to be pretty intense.  So we show you things like this.  And we record your brain response for each of those.  And here's what we do.  We ask you to tell us how bad is this? ", "So the baby picture was bad for most people.  We wait three weeks, pretty long time, and then we test  your memory for the scenes from before. ", "We test your memory three weeks later, pretty long time.  And here's what we see.  Two things.  In the left amygdala in this study, here's what you rated  as terrible, pretty bad, somewhat bad, and neutral. ", "So the amygdala is responding to your subjective sense of  terribleness.  Now, we were really looking at arousal and negativity.  We didn't look at positive ones. ", "I can tell you in other studies--  and here's a trick in research.  I'm going to tell you now--  I only have a couple more slides, but I'm going to tell  you a little bit about insider things on imaging, just so you  understand imaging as as human and fallible a form of ", "research as anything, which you might suspect anyway.   So we show these things.  And we got these responses. ", "So that's going with your subjective sense of  how bad films are.  And then we tested people's memory, what we also found was  that memory was best when we got the  biggest amygdala response. ", "So that's just like you heard before.  So that all seemed find and lined up with a prior result.  But here was the slight surprise in the thing that  followed and that still gets cited fairly often. ", "It's the research that I've been affiliated with that  still gets cited most often in newspapers and magazines.  Anyway, so this was a study that you saw before.  And the thing I didn't emphasize to you was that this  was in the right amygdala, in the right hemisphere. ", "It doesn't really matter.  It just happened to be there.  Our study at Stanford was in the left hemisphere.  This is where we were getting the emotion memory responses.  And so we were very deep scientists. ", "And we said, what could be going on?  Why is Larry Cahill at UC Irvine getting  it in the left amygdala?  The more active it is, the more you would remember  emotional information. ", "And why is he getting it in the right amygdala and we're  getting it in the left?  So we took a piece of paper and we wrote down the  different things that people had found.  Oh.  The story I was going to tell you is about ", "Stephan Hamann's study.  So Stephan Hamann at Emory did a study where he said, OK.  All this amygdala response to negative things, does it also  respond to positive things?  That's a good question. ", "And the answer is yes.  But it turns out in many experiments it doesn't look  that way, because you saw, for those of you who looked at  that horrible-looking baby picture, what would be an  equal positive powerful picture? ", "Let's try this one.  Everybody agrees it's cute when there's little children  around a birthday cake.  Smile, she smiles.  Powerful, unless it's your kid, maybe. ", "Powerful image.  Powerful as the face of the infant?  No.  So it's a really interesting thing.  It's very hard to get positive stimuli that are as potent as ", "negative stimuli.  You can get a million negative stimuli from the internet and  it's very hard to get very positive ones.  Having said that, we said, let's just think about the  negative ones for the moment.  So our studies were fMRI, PET, PET. ", "Ours were all with women.  And these were all with men.  And you could go, well, why did that happen?  It's good that it's half women and half men, because these  were Positron Emission Tomography.  That involves injecting radioactive stuff into people ", "to do that kind of imaging.  And many IRBs say, well, let's not have women do it, because  they could be unknowingly pregnant.  They could be.  And we shouldn't be giving radioactive stuff just for an ", "experiment.  You could have debates about that, but that's the thought.  Why not let the men get their radioactive stuff?  We don't really need them.  Then so when we did this study, we said, well, these ", "were all with men.  It seems in fairness we should do it with women too.  We just thought that seemed fair, kind of.  We didn't have any big thought about that.  And again, we were getting left amygdala and they were  getting right amygdala. ", "Pictures or films, different.  And this caught our eye, that we had done  studies with women.  We were getting left amygdala.  They did it with men, with right amygdala.  So deep scientists that we were, Larry Cahill said, I'll ", "test men and women.  And we said, we'll test men and women.  And here's what we found.  And these are averages, but one critical thing that we  discovered-- we didn't know this-- is that to the extent-- ", "and these are averages, of course these are averages--  that you compare men and women, on average women have  better memory for emotional life events, faster production ", "of autobiographical memories to cues, more accurate in  dating memories.  So these dating studies are pretty useful, because you  never know how accurate a person is when they have a  memory for something.  What they do in the dating studies is they have people ", "who are dating keep diaries, for  example, in the fall semester.  And presumably those are reasonably accurate.  They're filling them in every day.  And then things happen over the holidays and some people ", "remain dating and some don't.  So you go back to them in March, and you go, in your  fall, when the two of you were going out, tell us about what  you did in November.  And they can say who's more accurate. ", "And they have almost a virtual record, because they have the  responses that the men and women put down that day.  And on average-- these are averages-- the  women were more accurate.  And wives scored higher than husbands on vividness of ", "memories for first date, last vacation, recent argument.  So these are all averages.  There's lots of overlap, but an average is that way.  And so Larry Cahill went and did this thing.  And sure enough, again, as he found before, for men, the ", "more they turned on the right amygdala, the more certain  they were to remember negative films.  And for women, the more they turned on the left amygdala,  the more certain they would remember  negative films on average.  ", "Now, the thing to know is, on average again, when you have  people rate the kinds of pictures we  use, how do you think-- ", "here it is.  This is one example where your stereotype guesses probably  play out for the averages.  Who rates this as more scary, or who says it's more scary,  men or women? ", "OK.  So positive or negative, I should say  for positive or negative.  Here's the women, not finding this a particularly--  on average, and there's a range of responses-- ", " positive picture.  Here's men going, pretty cool.  What DVD did that come from?  So people are always asking, what does this really mean? ", "Are men just knowing they have to do this or whatever?  Who knows?  There's no answer to this about whether it's social  things or biology.  Certainly social things are a big part of the story. ", "When we have people rate the pictures in the scanner,  here's the women rating here's the worst pictures.  And look at the men.  They're less willing to rate these pictures as bad.  Again, psychologists who see these data say, well, maybe ", "the men think they're never supposed to rate them as bad,  because we're tough guys and nothing's so bad.  I mean, I don't know.  Who knows?  But this is the ratings.  ", "Now, if we look at the activation of the men and  women on the left as they rate them, the worse they rate it,  the more intense they find it, the more they turned on their  left amygdala.  So at the moment they're rating them, men and women ", "look very similar.  But when we relate it to their memory, two things happen.  First, the women did have superior memory to the men.  These were Stanford undergraduates, probably not  that dissimilar on average to the people in this room. ", "And quite strikingly, as you saw it, activation in the  right hemisphere predicted memory in men, and the left  hemisphere for women. ", "So I know there's been a lot of right and left.  But here we think was the message.  And it's kind of stood the test of time a  little bit, on average.  What you see here is the part of the left amygdala turned on ", "for women as they're rating it.  The more intense, the more active.  In relation to whether they form a long term memory, the  more active, the more likely they'll remember it.  And kind of the physical overlap of the two. ", "In men, more active in that amygdala on the left during  the rating, but doesn't seem to be  involved in memory formation.  In the hippocampus, again, overlap, overlap, overlap. ", "No apparent overlap in the men.  So what happens literally in the brain, I mean, literally  as far as we can measure it, in women on average there was  more overlap between the parts of the brain engaged as you  evaluate something and the parts of the brain that make ", "the memory of that.  And in men, on average it was as if, here's my emotional  rating on the right, and here's what I'm going to  remember on the left.  Kind of a separation of those processes in ", "the most simple sense.  Now here's a huge question.  Does this brain imaging study tell us anything about whether  this is in the genes of boys and girls as they're born or a ", "consequence of socialization or both?   It's incredibly intuitive for people to think that if you  see it in the brain it's hardwired and genetic or ", "hormonal or something.  Brain imaging data never tells you that.  It never tells you that.  It just tells you by this age, this is what's going on.  And you don't have to know much psychology to know that ", "we're all hugely influenced to varying degrees, but we're all  hugely influenced by social influences on what it is to be  a male or a female in our families, in our cultures, in ", "our societies.  Whether something's in your genes or in your culture, it  shows up in your brain.  And we can't tell those two things apart.  Is this anything to do with how we're born? ", "Is this anything to do with how Hollywood pitches movies  that are about video game battles versus chick flicks, ", "how they're pitching that and trying to tell us we're  supposed to like something?  Who knows?  We can't tell if it's social or genetic at all. "], "vid_duration": [10.87, 13.08, 13.14, 12.18, 11.38, 10.16, 10.15, 10.989, 11.381, 11.36, 10.37, 14.8, 10.87, 10.7, 10.149, 10.591, 11.609, 10.37, 10.961, 10.34, 10.75, 11.3, 11.399, 10.671, 11.4, 12.31, 10.15, 11.23, 11.0, 11.82, 10.51, 11.22, 11.17, 10.54, 13.81, 10.58, 10.98, 12.09, 11.23, 13.25, 10.34, 12.57, 10.38, 10.009, 11.371, 10.41, 10.36, 11.63, 11.7, 12.23, 10.52, 11.05, 10.37, 10.95, 11.51, 12.6, 10.19, 11.43, 13.02, 12.25, 10.41, 12.08, 11.74, 10.7, 10.89, 10.58, 11.31, 11.26, 10.86, 11.71, 10.32, 12.12, 10.65, 14.09, 11.9, 11.31, 10.01, 10.61, 12.33, 10.13, 10.47, 10.83, 11.44, 12.25, 10.77, 10.87, 13.84, 11.83, 11.17, 11.7, 13.05, 11.79, 10.71, 10.55, 12.11, 11.69, 11.0, 11.39, 12.35, 10.14, 10.75, 10.57, 11.02, 10.68, 10.38, 10.34, 12.48, 14.43, 11.78, 10.78, 10.12, 10.453, 11.177, 10.21, 10.05, 12.672, 10.098, 12.89, 14.01, 10.75, 10.45, 11.98, 13.09, 10.68, 11.31, 10.44, 13.01, 12.01, 11.21, 13.14, 10.89, 10.83, 10.58, 12.25, 12.51, 12.48, 10.36, 10.02, 11.73, 11.23, 11.08, 12.69, 10.638, 11.622, 11.6, 12.78, 10.54, 11.12, 10.67, 12.47, 12.13, 11.38, 11.23, 10.76, 12.77, 11.91, 12.03, 10.78, 10.99, 11.31, 10.15, 11.41, 14.37, 13.36, 12.49, 11.79, 10.2, 10.39, 12.94, 10.83, 11.44, 12.52, 10.57, 12.899, 10.881, 10.599, 12.0, 10.25, 10.361, 10.699, 13.411, 10.22, 10.099, 12.051, 10.42, 11.91, 11.78, 11.79, 10.58, 12.61, 11.11, 12.0, 10.93, 11.4, 12.71, 11.56, 13.1, 11.17, 11.88, 12.25, 10.23, 10.64, 10.29, 10.85, 11.34, 10.23, 12.01, 11.21, 11.69, 11.17, 10.12, 10.74, 11.67, 10.18, 11.77, 10.85, 13.79, 11.69, 12.85, 12.28, 10.66, 11.86, 11.25, 11.09, 12.32, 11.23, 12.1, 11.78, 11.03, 10.85, 13.77, 11.99, 11.47, 11.01, 11.21, 11.06, 11.79, 10.77, 10.16, 11.39, 12.08, 10.65, 13.02, 11.68, 10.29, 11.82, 11.49, 11.44, 11.41, 10.38, 11.55, 12.82, 10.0, 10.13, 11.12, 10.86, 12.77, 11.96, 11.62, 12.34, 10.495, 12.715, 11.485, 12.715, 10.16, 10.83, 10.19, 14.6, 11.04, 11.08, 13.08, 12.67, 10.78, 11.14, 11.04, 10.8, 10.14, 10.24, 11.85, 11.08, 10.72, 10.09, 11.77, 12.32, 10.3, 11.38, 10.23, 11.35, 11.73, 10.775, 10.035, 12.62, 11.99, 10.08, 12.96, 10.77, 12.67, 12.54, 11.69, 12.0, 12.22, 12.31, 10.08, 11.02, 11.54, 8.7], "stet": [[0, 10.87], [10.87, 23.95], [23.95, 37.09], [37.09, 49.27], [49.27, 60.650000000000006], [60.650000000000006, 70.81], [70.81, 80.96000000000001], [80.96000000000001, 91.94900000000001], [91.94900000000001, 103.33000000000001], [103.33000000000001, 114.69000000000001], [114.69000000000001, 125.06000000000002], [125.06000000000002, 139.86], [139.86, 150.73000000000002], [150.73000000000002, 161.43], [161.43, 171.579], [171.579, 182.17000000000002], [182.17000000000002, 193.77900000000002], [193.77900000000002, 204.14900000000003], [204.14900000000003, 215.11000000000004], [215.11000000000004, 225.45000000000005], [225.45000000000005, 236.20000000000005], [236.20000000000005, 247.50000000000006], [247.50000000000006, 258.89900000000006], [258.89900000000006, 269.57000000000005], [269.57000000000005, 280.97], [280.97, 293.28000000000003], [293.28000000000003, 303.43], [303.43, 314.66], [314.66, 325.66], [325.66, 337.48], [337.48, 347.99], [347.99, 359.21000000000004], [359.21000000000004, 370.38000000000005], [370.38000000000005, 380.9200000000001], [380.9200000000001, 394.7300000000001], [394.7300000000001, 405.31000000000006], [405.31000000000006, 416.2900000000001], [416.2900000000001, 428.38000000000005], [428.38000000000005, 439.61000000000007], [439.61000000000007, 452.86000000000007], [452.86000000000007, 463.20000000000005], [463.20000000000005, 475.77000000000004], [475.77000000000004, 486.15000000000003], [486.15000000000003, 496.15900000000005], [496.15900000000005, 507.53000000000003], [507.53000000000003, 517.94], [517.94, 528.3000000000001], [528.3000000000001, 539.9300000000001], [539.9300000000001, 551.6300000000001], [551.6300000000001, 563.8600000000001], [563.8600000000001, 574.3800000000001], [574.3800000000001, 585.4300000000001], [585.4300000000001, 595.8000000000001], [595.8000000000001, 606.7500000000001], [606.7500000000001, 618.2600000000001], [618.2600000000001, 630.8600000000001], [630.8600000000001, 641.0500000000002], [641.0500000000002, 652.4800000000001], [652.4800000000001, 665.5000000000001], [665.5000000000001, 677.7500000000001], [677.7500000000001, 688.1600000000001], [688.1600000000001, 700.2400000000001], [700.2400000000001, 711.9800000000001], [711.9800000000001, 722.6800000000002], [722.6800000000002, 733.5700000000002], [733.5700000000002, 744.1500000000002], [744.1500000000002, 755.4600000000002], [755.4600000000002, 766.7200000000001], [766.7200000000001, 777.5800000000002], [777.5800000000002, 789.2900000000002], [789.2900000000002, 799.6100000000002], [799.6100000000002, 811.7300000000002], [811.7300000000002, 822.3800000000002], [822.3800000000002, 836.4700000000003], [836.4700000000003, 848.3700000000002], [848.3700000000002, 859.6800000000002], [859.6800000000002, 869.6900000000002], [869.6900000000002, 880.3000000000002], [880.3000000000002, 892.6300000000002], [892.6300000000002, 902.7600000000002], [902.7600000000002, 913.2300000000002], [913.2300000000002, 924.0600000000003], [924.0600000000003, 935.5000000000003], [935.5000000000003, 947.7500000000003], [947.7500000000003, 958.5200000000003], [958.5200000000003, 969.3900000000003], [969.3900000000003, 983.2300000000004], [983.2300000000004, 995.0600000000004], [995.0600000000004, 1006.2300000000004], [1006.2300000000004, 1017.9300000000004], [1017.9300000000004, 1030.9800000000005], [1030.9800000000005, 1042.7700000000004], [1042.7700000000004, 1053.4800000000005], [1053.4800000000005, 1064.0300000000004], [1064.0300000000004, 1076.1400000000003], [1076.1400000000003, 1087.8300000000004], [1087.8300000000004, 1098.8300000000004], [1098.8300000000004, 1110.2200000000005], [1110.2200000000005, 1122.5700000000004], [1122.5700000000004, 1132.7100000000005], [1132.7100000000005, 1143.4600000000005], [1143.4600000000005, 1154.0300000000004], [1154.0300000000004, 1165.0500000000004], [1165.0500000000004, 1175.7300000000005], [1175.7300000000005, 1186.1100000000006], [1186.1100000000006, 1196.4500000000005], [1196.4500000000005, 1208.9300000000005], [1208.9300000000005, 1223.3600000000006], [1223.3600000000006, 1235.1400000000006], [1235.1400000000006, 1245.9200000000005], [1245.9200000000005, 1256.0400000000004], [1256.0400000000004, 1266.4930000000004], [1266.4930000000004, 1277.6700000000003], [1277.6700000000003, 1287.8800000000003], [1287.8800000000003, 1297.9300000000003], [1297.9300000000003, 1310.6020000000003], [1310.6020000000003, 1320.7000000000003], [1320.7000000000003, 1333.5900000000004], [1333.5900000000004, 1347.6000000000004], [1347.6000000000004, 1358.3500000000004], [1358.3500000000004, 1368.8000000000004], [1368.8000000000004, 1380.7800000000004], [1380.7800000000004, 1393.8700000000003], [1393.8700000000003, 1404.5500000000004], [1404.5500000000004, 1415.8600000000004], [1415.8600000000004, 1426.3000000000004], [1426.3000000000004, 1439.3100000000004], [1439.3100000000004, 1451.3200000000004], [1451.3200000000004, 1462.5300000000004], [1462.5300000000004, 1475.6700000000005], [1475.6700000000005, 1486.5600000000006], [1486.5600000000006, 1497.3900000000006], [1497.3900000000006, 1507.9700000000005], [1507.9700000000005, 1520.2200000000005], [1520.2200000000005, 1532.7300000000005], [1532.7300000000005, 1545.2100000000005], [1545.2100000000005, 1555.5700000000004], [1555.5700000000004, 1565.5900000000004], [1565.5900000000004, 1577.3200000000004], [1577.3200000000004, 1588.5500000000004], [1588.5500000000004, 1599.6300000000003], [1599.6300000000003, 1612.3200000000004], [1612.3200000000004, 1622.9580000000003], [1622.9580000000003, 1634.5800000000004], [1634.5800000000004, 1646.1800000000003], [1646.1800000000003, 1658.9600000000003], [1658.9600000000003, 1669.5000000000002], [1669.5000000000002, 1680.6200000000001], [1680.6200000000001, 1691.2900000000002], [1691.2900000000002, 1703.7600000000002], [1703.7600000000002, 1715.8900000000003], [1715.8900000000003, 1727.2700000000004], [1727.2700000000004, 1738.5000000000005], [1738.5000000000005, 1749.2600000000004], [1749.2600000000004, 1762.0300000000004], [1762.0300000000004, 1773.9400000000005], [1773.9400000000005, 1785.9700000000005], [1785.9700000000005, 1796.7500000000005], [1796.7500000000005, 1807.7400000000005], [1807.7400000000005, 1819.0500000000004], [1819.0500000000004, 1829.2000000000005], [1829.2000000000005, 1840.6100000000006], [1840.6100000000006, 1854.9800000000005], [1854.9800000000005, 1868.3400000000004], [1868.3400000000004, 1880.8300000000004], [1880.8300000000004, 1892.6200000000003], [1892.6200000000003, 1902.8200000000004], [1902.8200000000004, 1913.2100000000005], [1913.2100000000005, 1926.1500000000005], [1926.1500000000005, 1936.9800000000005], [1936.9800000000005, 1948.4200000000005], [1948.4200000000005, 1960.9400000000005], [1960.9400000000005, 1971.5100000000004], [1971.5100000000004, 1984.4090000000003], [1984.4090000000003, 1995.2900000000004], [1995.2900000000004, 2005.8890000000004], [2005.8890000000004, 2017.8890000000004], [2017.8890000000004, 2028.1390000000004], [2028.1390000000004, 2038.5000000000005], [2038.5000000000005, 2049.1990000000005], [2049.1990000000005, 2062.6100000000006], [2062.6100000000006, 2072.8300000000004], [2072.8300000000004, 2082.9290000000005], [2082.9290000000005, 2094.9800000000005], [2094.9800000000005, 2105.4000000000005], [2105.4000000000005, 2117.3100000000004], [2117.3100000000004, 2129.0900000000006], [2129.0900000000006, 2140.8800000000006], [2140.8800000000006, 2151.4600000000005], [2151.4600000000005, 2164.0700000000006], [2164.0700000000006, 2175.1800000000007], [2175.1800000000007, 2187.1800000000007], [2187.1800000000007, 2198.1100000000006], [2198.1100000000006, 2209.5100000000007], [2209.5100000000007, 2222.2200000000007], [2222.2200000000007, 2233.7800000000007], [2233.7800000000007, 2246.8800000000006], [2246.8800000000006, 2258.0500000000006], [2258.0500000000006, 2269.9300000000007], [2269.9300000000007, 2282.1800000000007], [2282.1800000000007, 2292.4100000000008], [2292.4100000000008, 2303.0500000000006], [2303.0500000000006, 2313.3400000000006], [2313.3400000000006, 2324.1900000000005], [2324.1900000000005, 2335.5300000000007], [2335.5300000000007, 2345.7600000000007], [2345.7600000000007, 2357.770000000001], [2357.770000000001, 2368.980000000001], [2368.980000000001, 2380.670000000001], [2380.670000000001, 2391.840000000001], [2391.840000000001, 2401.960000000001], [2401.960000000001, 2412.7000000000007], [2412.7000000000007, 2424.370000000001], [2424.370000000001, 2434.5500000000006], [2434.5500000000006, 2446.3200000000006], [2446.3200000000006, 2457.1700000000005], [2457.1700000000005, 2470.9600000000005], [2470.9600000000005, 2482.6500000000005], [2482.6500000000005, 2495.5000000000005], [2495.5000000000005, 2507.7800000000007], [2507.7800000000007, 2518.4400000000005], [2518.4400000000005, 2530.3000000000006], [2530.3000000000006, 2541.5500000000006], [2541.5500000000006, 2552.640000000001], [2552.640000000001, 2564.960000000001], [2564.960000000001, 2576.190000000001], [2576.190000000001, 2588.290000000001], [2588.290000000001, 2600.070000000001], [2600.070000000001, 2611.1000000000013], [2611.1000000000013, 2621.950000000001], [2621.950000000001, 2635.720000000001], [2635.720000000001, 2647.710000000001], [2647.710000000001, 2659.1800000000007], [2659.1800000000007, 2670.190000000001], [2670.190000000001, 2681.400000000001], [2681.400000000001, 2692.460000000001], [2692.460000000001, 2704.250000000001], [2704.250000000001, 2715.020000000001], [2715.020000000001, 2725.1800000000007], [2725.1800000000007, 2736.5700000000006], [2736.5700000000006, 2748.6500000000005], [2748.6500000000005, 2759.3000000000006], [2759.3000000000006, 2772.3200000000006], [2772.3200000000006, 2784.0000000000005], [2784.0000000000005, 2794.2900000000004], [2794.2900000000004, 2806.1100000000006], [2806.1100000000006, 2817.6000000000004], [2817.6000000000004, 2829.0400000000004], [2829.0400000000004, 2840.4500000000003], [2840.4500000000003, 2850.8300000000004], [2850.8300000000004, 2862.3800000000006], [2862.3800000000006, 2875.2000000000007], [2875.2000000000007, 2885.2000000000007], [2885.2000000000007, 2895.330000000001], [2895.330000000001, 2906.4500000000007], [2906.4500000000007, 2917.310000000001], [2917.310000000001, 2930.080000000001], [2930.080000000001, 2942.040000000001], [2942.040000000001, 2953.6600000000008], [2953.6600000000008, 2966.000000000001], [2966.000000000001, 2976.495000000001], [2976.495000000001, 2989.210000000001], [2989.210000000001, 3000.695000000001], [3000.695000000001, 3013.410000000001], [3013.410000000001, 3023.570000000001], [3023.570000000001, 3034.400000000001], [3034.400000000001, 3044.590000000001], [3044.590000000001, 3059.190000000001], [3059.190000000001, 3070.230000000001], [3070.230000000001, 3081.310000000001], [3081.310000000001, 3094.390000000001], [3094.390000000001, 3107.060000000001], [3107.060000000001, 3117.840000000001], [3117.840000000001, 3128.980000000001], [3128.980000000001, 3140.020000000001], [3140.020000000001, 3150.820000000001], [3150.820000000001, 3160.960000000001], [3160.960000000001, 3171.2000000000007], [3171.2000000000007, 3183.0500000000006], [3183.0500000000006, 3194.1300000000006], [3194.1300000000006, 3204.8500000000004], [3204.8500000000004, 3214.9400000000005], [3214.9400000000005, 3226.7100000000005], [3226.7100000000005, 3239.0300000000007], [3239.0300000000007, 3249.330000000001], [3249.330000000001, 3260.710000000001], [3260.710000000001, 3270.940000000001], [3270.940000000001, 3282.290000000001], [3282.290000000001, 3294.020000000001], [3294.020000000001, 3304.795000000001], [3304.795000000001, 3314.830000000001], [3314.830000000001, 3327.4500000000007], [3327.4500000000007, 3339.4400000000005], [3339.4400000000005, 3349.5200000000004], [3349.5200000000004, 3362.4800000000005], [3362.4800000000005, 3373.2500000000005], [3373.2500000000005, 3385.9200000000005], [3385.9200000000005, 3398.4600000000005], [3398.4600000000005, 3410.1500000000005], [3410.1500000000005, 3422.1500000000005], [3422.1500000000005, 3434.3700000000003], [3434.3700000000003, 3446.6800000000003], [3446.6800000000003, 3456.76], [3456.76, 3467.78], [3467.78, 3479.32], [3479.32, 3488.02]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [443, 1181, 1987, 2786, 3488]}
{"example_id": "mit057@@MIT9_00SCF11_lec16_300k", "text": ["And then finally some brain correlates for personality.  So I love this quote, because I think it's about  individuality, which says, every person is in certain  respects like all other people--  and we think that's true.  There's something deeply similar among all humans, also ", "about psychology, also about our brains.  Like some other people, that is, there's dimensions of  individuality, or like some other people, like if we're a  male or female, if we're this age or that age, this culture ", "or that culture, like math or don't like math, like vanilla  ice cream or don't like ice cream.  And then finally, we come down to the unique set of things  that make you you. ", "And that's very hard to study, the unique things  that make you you.  But the second level, dimensions of individuality,  we can study in personality.  It's obviously a big one that we feel in our own ", "lives and around us.  So this is the old original \"Star Trek.\" Like many  programs, or in TV series, it plays out really in part-- ", "they go from galaxy to galaxy and struggle with various  opponents, civilizations.  But it almost always comes down to a  personality thing, right?  The Captain Kirk who wants to be aggressive and charge in ", "there and do something very emotional, Spock who's the  pure rational machine, and McCoy who represents a sort of  humane touch, as opposed to the rational thought. ", "And somewhere in between is the man who has to pick the  action to command the ship, right?  So every show plays out with him asking him  to be human, right?  And him asking him to be rational, and him killing ", "somebody who's trouble making.  OK.  So what do we mean by personality?  A set of behavioral, emotional, and cognitive  tendencies that people display over time.  When we talk about personality, we really mean ", "something that we think is consistent in ourselves or in  other people.  It's that somebody is shy, somebody's  helpful, somebody's rude.  And across situations, not just one place, one time, but ", "pretty regularly.  And that varies across people.  That distinguishes them from one to another.  Something that's kind of--  there's some similarities, but people vary in this. ", "And so when people think about this, they think in three  categories as they conceptualize it.  One is traits.  By trait we mean something that's in you that's constant  across situations and times. ", "But we also think of it as a continuum.  So for example, we talk about introversion/extroversion or  outgoingness and shyness.  It's not that everybody's one or the other. ", "Along that path from being extremely shy to extremely  outgoing, many of us are somewhere in between.  And then we can talk about states, how we are  temporarily. ", "How do we feel, excited, afraid, that kind of stuff.  And then situations we're in, because they're specific at  times and places, and that influences us.  We're fearful, we're happy, we're looking forward to ", "something, we're not looking forward to something.  So these are different pieces that might end up in how we  feel inside and how we act on the world.  So here's a very funny thing, because it's a very different ", "line of research than practically anything else  that's out there.  Very active, because we're so curious about personality.  Here's how people have basically approached it.  Not everybody, but the main line scientific perspective. ", "They looked in the dictionary, originally in the 1930s, for  this line of work, and they said, let's look at all the  adjectives in the dictionary that we think might describe  personality in some sense. ", "They found nearly 18,000 words in the dictionaries that  seemed to be adjectives for describing people, and  something that might be about personality.  Whether you're affable, or amiable, congenial, convivial, ", "cordial, friendly, genial, sociable, welcoming.  These are all synonyms, right?  They all mean roughly the same thing, we think.  But they found 18,000 terms there because we think a lot ", "about other people, and talk a lot about other people, and  other people are interesting to us.  And as I said, we're not going to study 18,000 dimensions of  personality, especially when lots of them  overlap like this. ", "So what we're going to do is see, are there some underlying  traits, a manageable set of personality traits or  dimensions, that many of these 18,000 adjectives sort ", "of boil down to.  So a manageable set of personality dimensions.  So how do people measure personality in some way?  And for those of us who like to measure things by ", "behavior-- you do a test, or you push a button, or we  measure your brain--  personality research is always funny, because the bulk of it  is people's self report about themselves.  And about the last thing most of us in psychology trust is ", "people's reports about themselves.  And what we think is--  for many reasons that we can talk about a little bit--  what we think is that people, when they fill out a piece of ", "paper describing themselves, they start to have all kinds  of thoughts like, OK, I'm outgoing, but compared to who?  ", "Do I want to fill this out like I really like to think  about myself, or how I think I really am, or am I sometimes  this way and sometimes that way, which  is the right answer.  OK?  So all these things bother us as researchers, but we don't ", "have a more direct path towards personality.  So we can interview people about their personality.  We can observe--  I'll talk about some studies that involve observation.  But by far the dominant mode of collecting somewhat ", "quantitative data about personality are questionnaires  of the kind you just got handed out to you.  Thank you, Tyler.  And the most famous one of all, which you have in your  hands, is the so-called big five personality dimensions. ", "There's many other aspects of personality-- we'll talk about  that-- but this is the most famous one.  And it was derived in some sense objectively and  empirically from factor analysis like this. ", "What they said is we have this huge number of terms, but many  of them are either very similar to one another, or  what we might call anti-correlative, they're sort  of opposites.  So for example, if a person is rude, are we also likely to ", "think of them as kind?  Now you could have--  there's many movies of the rude senior citizen who turns  out to have a heart of gold underneath, right?  But in general, if you say this person's rude, usually ", "they'll go, and they're so kind, right?  We think of them as sort of opposites in personality.  If somebody's dependable or carefree.  Now, maybe you know somebody who's both dependable and  carefree, but we tend to think carefree people are not so ", "dependable.  They can be delightful dependable people.  But now, rude-- you can be dependable and rude or  dependable and polite, right?  OK, so get a feeling of that. ", "So they have people fill out tons of pieces of paper saying  how do they feel these factors describe them.  And they start out with this huge universe of terms, and ", "then they try to boil it down, and boil it down, and boil it  down, by looking at--  Oh, this doesn't show up very well, does it?  Oh, well.  Correlations--  you have the notes.  So you can guess without being able to see, you can guess-- ", "let's pick two things.  If I pick the adjectives carefree and dependable, kind  of go together or not go together? ", "Doesn't tend to go together in people describing themselves.  How about hard working and dependable?  Kind of goes together.  So they said, we can take a lot of these adjectives and ", "say piles of them go in one area, well, we'll just pick a  few words to describe that dimension.  Piles of them go in another area.  And they boil it down basically by factor analysis, ", "and they end up with five big factors in this  most widely used one.  So here's two of them.  And here comes a big thing.  They have the factor which is basically just mathematically ", "a set of adjectives that travel together, that are  highly correlated when people describe themselves.  And they're somewhat anti-correlated or  uncorrelated with the other dimensions.  That's purely empirical. ", "Now, though, they have the set of adjectives, like carefree  or dependable, not hard-working or hard-working.  Now they have to say, what's the label I'm going to put on ", "that dimension of human personality?  There's no science for that.  That's judgment.  But five of them get fixed.  And once these got fixed, they've become the terminology ", "of the field.  So they said, we're going to call one conscientiousness.  Those are people who say they're not carefree, they are  dependable, and they are hard-working.  Does that make sense? ", "Or somebody's agreeable--  that's one of the other big five, separate five.  If somebody says, I'm pretty compliant, I'm pretty kind,  and I'm seldom rude.  So I'm going to give you a minute to try this. ", "You can fill it out fully.  So your piece of paper that you have is a  version of this test.  It's the real thing.  One side tells you how to score it.  Don't look at that, the other side at the bottom. ", "Just try a few items for fun if you feel like it.  And you can fill it out later and score yourself or print it  out from the notes and score your friends. ", "Use it responsibly, the knowledge.   And you can just have an intuition of what does it  mean, because almost all personality research, almost ", "all of it does exactly what you're doing now, which is  gives you a piece of paper, and have you describe yourself  to yourself.  ", "I'll give you a minute just to get a feeling for it.  I think it's kind of fun.  And the feeling you get, like--  so people worry about stuff, like who are you comparing  yourself to?  If you're outgoing, compared to who? ", "Compared to Robin Williams, OK?  Maybe not so much.  Compared to your roommate?  Maybe yes.  So all these questions, like where do you get these number  from, how do you come to these answers, and so on. ", "People worry about polishing your image.  Oh yes, I'm always polite.  I'm nearly perfect when I'm asked to describe myself, OK?  So to the extent that people did that, it  wouldn't work, right? ", "Because everybody would look perfect all the time.   So these big five are openness, conscientiousness, ", "extroversion, agreeableness, and neuroticism.  And for memorizing for tests, OCEAN is the acronym.   These were the ones that have come out as five separable ", "dimensions that seem to cover a tremendous amount of  individual descriptions of human personality, and are  widely used in research.   So here's your big five inventory. ", " Here's--  on the backside, how to score it, if you feel like figuring  out what this test would say about yourself, OK? ", "You could be honest with your scoring, because we're not  going to collect it, it's just you describing you to  yourself, if you're curious.   And now I'm going to go on.  And you're more than welcome to finish it ", "whenever you want.  It's yours to keep.  And here's how we would score it, or you would score it.  It tells you on the bottom what to do.  For conscientiousness--  and we'll come back to this, it's a  really interesting measure. ", "If you rate yourself as somebody who does a thorough  job, is a reliable worker, perseveres until the task is  finished, does things efficiently, and makes plans  and follows through with them.  The higher you rate yourself on those-- this makes sense-- ", "you're more conscientious, right?  The less you say, that you're somewhat careless, you tend to  be disorganized, you tend to be lazy, and you're easily ", "distracted, well, those are negative  things for that dimension.  Does that make sense?  So you have to watch when you score it which are the  positive and which are the negative as you score them,  would you get a plus or a minus.  And they try to make it either way, so that if you constantly ", "say yes, you ought not to score anything that makes  sense, even to yourself.  Anyway, so here's the big questions, right?  All this sort of research behind or this factor ", "analysis, you'd want to know two things.  Are they stable?  Do they really describe a person across  situations and time?  That's what we mean by personality.  And secondly, do they predict behaviors and life outcomes? ", "Is there something about them that goes with things that we  care about, variably across people?  So where people have looked at this over some number of ", "years, it correlates 0.5 to 0.7 across 30  or 40 years of life.  Height and sex, to think about it, correlates 0.4.  Again, height and sex is kind of an-- people will pick that ", "to think about.  On average, men tend to be taller than women, but lots of  women are taller than lots of individual men, OK?  So it's a stronger relationship across time.  It's more stable than what you'd predict ", "by height and sex.  And here's something really interesting.  They tested people across seven years-- within  childhood, within young adulthood, within the 30s, and  in the 50 to 70 age range. ", "And here's something kind of striking.  If you test people twice across seven years, starting  from infancy as best you can-- or questions about them  because they can't fill out forms-- ", "to adulthood, the striking thing is that the older you  get, the more consistent you become across  a seven year period.  The older you get, the more consistent you become. ", "So how might you interpret that?   There's a couple different ways you  could think about that.  The older you become, the more consistent you become in ", "describing your personality--  let's pretend your descriptions are accurate--  the more consistent your personality is.  Did you expect that?  Is that what you expect?  Something opposite? ", "Yeah?  AUDIENCE: They get older, they kind of develop habits and get  set in their ways.  PROFESSOR: Yeah.  So there's two ways to describe getting older.  Like me, I get set in my ways. ", "Right?  That's OK.  Or I'll say it the other way, we discover the ways that we  really like.  OK?  My friend Robert Sapolsky at Stanford, who writes fantastic ", "books and who's a fantastic lecturer, had an essay where  he said he noticed in his late 40s or 50s, that the people in  his working lab that they were playing irritating music. ", "It was just bothering him when they were playing the music.  And it was music that people of your generation listen to.  He said, why is it irritating?  Because when he played his--  when he played The Beatles or whatever, they were irritating ", "to his parents, OK.  So what's going on?  And he said, oh.  And so he did a little informal study, he talked to  people of different ages and people in restaurants, they  said, at what age do people seem to stop wanting to do new ", "things, and get stuck in their ways, or find what they like  and stick with it?  And there's no one answer.  But he found a tremendous number of people, by about 30  to 35, that's their music, they like sushi or they don't ", "like sushi.  They have their set of stuff that they have going for them  or they don't like.  And so you could say they get stuck in their ways.  You could say they discover what they like ", "and stick with it.  And here's an age more of exploration and variability.  Who knows?  But it's kind of interesting, the older you get, the more  consistent you get. ", "Is this flexibility?  Is this chaos?  You could look at it either way.  There's no real answer.  People have looked at these scores and asked whether  things like--  do they vary with age and gender? ", "So for example, these broken lines are neuroticism, which  is a funny label.  It really means--  neuroticism is the bad side of it, stability is the ", "good side of it.  You could also say too stable could be boring and inert.  You could relabel these things pretty much.  But on average, women's scores are a little bit less stable ", "than men, a little bit more outgoing, a little bit.  By age, you get a few trends.  This will not surprise you, actually.  So for neuroticism-- again, stability-- ", "that neuroticism decreases with age.  People get more stable and they get more conscientious as  they get older.  You kind of expect that.  People get more used to their habits and more stuck in their  ways, that we would call stability. ", "So, let's ask for people who score high or low on these  measures, what do they go with?  So for these five fundamental personality measures.  So people who score highly on the neuroticism scale-- again, ", "these labels are tricky--  but it means ranging from very stable and emotional sense to  very labile--  they pay more attention to threat in the environment,  more stressed when given a surprise math test, have a ", "higher divorce rate, more susceptible to  depression and anxiety.  At the very, very, very highest scores of neuroticism,  it's a big risk for depression and anxiety. ", "And one of the deep questions always is, to what extent are  what we call psychiatric labels extremes of personality  or something beyond personality?  This is a much deeper issue than you'd think. ", "We'll come back to it in psychiatry.  Because some people say there's no such thing, for  example, as social anxiety disorder.  It's a recent invention for what people  used to call shyness. ", "I don't think that's right, mostly.  But this debate goes on, because there's not a sharp  boundary between being a little shy and so shy that you ", "don't leave your house to meet people.  That's kind of an extreme.  But most people--  it's not one person is here and the next person's here,  there's people all along the continuum.  Where you draw the line is a challenging issue. ", "Highly extroverted people versus highly introverted,  that sort of shyness and outgoingness.  This will be a big surprise.  Highly extroverted people-- by these personality measures--  attend more parties, they're more popular, they're ", "identified as leaders in college, they live with and  work with more people, they're less disturbed by sudden loud  sounds or intense stimuli.  You can do experiments in a laboratory and get these  differences.  None of these are sort of surprising. ", "They're just telling you there's something correct  about these personality measures.  Highly agreeable people are more willing to lend money,  have higher high school grades, and have  fewer arrests as adults.  But the cool thing is not-- ", "I mean, you're not surprised.  But the fact that they fill out a questionnaire sitting at  a desk like you do, predicts to some decent extent over the  population whether they'll go to jail or not.  That's kind of interesting. ", "More openness to experience.  You're more likely to major in the humanities--   not us--  ", "change careers in midlife, perform better in job training  programs, and play a musical instrument.  But these are massive statistical things.  Because kind of conversely-- ", "well, you know there's very interesting relations between  musicality and sort of math and science backgrounds.  So that seems to go against this.  So these are big averages.  Maybe, I think, in some ways the most interesting one, for ", "practical reasons, has turned out to be conscientiousness,  and that's like doing what you're supposed to do.  More sexually faithful to spouses, higher job ratings,  smoke less, drink less, drive more safely, live longer, less ", "risk for Alzheimer's Disease-- spectacularly less risk.  OK?  And also play a musical instrument?   So the Alzheimer's Disease is kind of interesting, because ", "what we think is happening-- and we don't really know--  is this.  So you may know there's basically one gene, now, more  recently, a couple other genes, identified as  significant risk genes for Alzheimer's.  But the one powerful well-identified one is the ", "so-called APOE gene.  And that is a significant risk gene.  If you're homologous for that, you have a higher risk for  Alzheimer's.  But that best-known, best-characterized gene is a ", "far smaller risk factor, mathematically, than being low  conscientiousness.  And we don't know what that really means, right? ", "What's your guess?  And nobody knows.  This is just an empirical finding, and it's been  replicated a number of times.  What's your guess?  So conscientious people do what they're supposed to. ", "All the things that you're supposed to, in the morning,  get up and do, they do them pretty well.  Right?   Make your bed, do your laundry regularly, brush your teeth ", "regularly, have your medical appointments regularly, eat  well, exercise, all the things that everybody tells you is  good for you, conscientious people are more  likely to do it.  Yeah?  AUDIENCE: It's sort of an analogy. ", "The thing is that someone who continuously uses them more--  more of the pipeline, basically.  Keep water going through them, makes it less likely that it  will clog the pipes--  PROFESSOR: Yeah, it's something like that. ", "The pipeline analogy.  If you keep flushing it regularly, instead of clogging  it up with bad things that are bad for you or whatever.  In the end, there has to be a biological mechanism.  In the end, there has to be.  But maybe it's a lifetime of doing healthy things. ", "And they add up and up, day in, day out, month in, month  out, year in, year out.  That they somehow, in some way, either fend off  Alzheimer's disease or diminish its expression for  much longer. ", "Does that sound OK?  But it's a very compelling finding.  All right.  So then there's always a fun question up for our  personality, and there will be one big  surprise here, I think. ", "I'll tell you this is our surprise.  [INAUDIBLE] was reminding me that--  there's a parents visiting weekend, which  is not today, right?  But a few years ago, I gave this lecture on that, and I  came to a conclusion that parents will find impossible, ", "untrue, and very disturbing.  Get ready.  Here we go.  Again, we're always curious, our personalities--  whether we're outgoing or not, agreeable or ", "not, open or not--  how much of that is in our genes at birth, how much is  that in our environment in terms of parental influence,  and sibling influence, and school, and so on.  So the usual way to this, until we know the true biology ", "of this, are estimates from twin studies and children  reared apart and reared separately.  So let me start with the twin studies.  So these are identical twins in green versus dizygotic or ", "fraternal twins, shared  environment, some shared genes.  The difference about this is thought to be an estimate of  pure genetic heritability.  And say you get a pretty good one-- ", "extroversion and openness the most, maybe--  but definitely a genetic contribution to personality.  That's the evidence from twin studies. ", "And it's even impressive if you do not self report  questionnaires, but behaviors that people describe,  activities they do.  Time spent watching television, number of  childhood accidents, tendency for marriage and divorce, ", "religious attitudes, your balance between work and  leisure, do you want to be at work all the time or leisure,  or what the balance ought to be.  0.5, that's about half heritable, estimated. ", "Happiness--  we'll come back to happiness ratings.  The way people rate happiness, it turns out, is if you do a  one to seven scale, that's the field.  OK?  Seven means happy all the time, one means  miserable all the time. ", "That's the way happiness research is done.  In the last lecture, we'll talk about what people think  people need to do to be happy.  But one thing we know is that people tend to have happiness  set-points-- ", "you may know this amongst your friends or yourselves--  that is, on average, a person will be very happy, or  moderately happy, or pretty grumbly most of the time.  OK?  Something happens in their lives that's really good or ", "bad, they'll move a little bit, but they'll slide right  back to it.  There's nothing better or worse about one or the other,  but it's just people tend to be pretty set.  And the estimates from twin studies are about half of your ", "chronic sense of happiness, day in and day out, it comes  from genes, is the estimate.  So that's a big piece.  But here's the kind of stunning thing. ", "And in the next couple slides I tell you.  Let me tell you the bottom line, let me  tell you the evidence.  The empirical evidence could support a position that  parents and family environments have zero ", "influence on your personality.  Then the question is, what is the environmental influence?  Because we know it's not all genetic.  But wherever it's been looked at carefully, parents and home ", "environments appear to have, as far as they can see, nearly  zero influence on your personality.  Now this is the thing that drives parents crazy.  Because as a parent, I can tell you, from the moment ", "they're born, or even months before children are born, to  the moment you're no longer around to take care of your  children, you want them to develop the right kind of--  be a happy person, a good person.  Hopefully something about conscientiousness, do well in ", "life, right?  And you're doing every little thing to encourage that.  The comments you make, the schools you send them to, the  activities you encourage them to do, you want them to have a  personality that will be happy for them and good for them and ", "thriving, right?  So to be told that whatever you do doesn't matter is kind  of a big shock.  And we don't really know the depth of this.  And it sounds like it's ridiculous.  But I can tell you the empirical evidence kind of ", "supports it.  So for example, for the twin studies, it makes no  difference at all for personality dimensions whether  twins are raised together or raised apart. ", "So they're in different families or the same family--  doesn't make a difference.  All the heritable estimates remain exactly the same.  So where are the environmental factors coming from?  We believe there's environmental factors, but we ", "can't spot them.  And what's fascinating about these things is that we as  human beings-- and this is just an example now--  always want to understand who we are as some sort of willful ", "response to our environment.  So here are two identical twins reared apart.  And they're both super neat.  OK? ", "And neither one of them tells you, well, it's in my genes,  what else was I going to do?  None of us mostly think that.  Outside of some dire circumstances or diseases, we ", "mostly think, it's my choice this morning whether I'm going  to make my bed or not.  It's my choice if I do laundry this year or not.  Yeah.  AUDIENCE: Could that other 50% come from things part of the ", "environment like diet or health?  PROFESSOR: Could the other 50% come from things like diet or  other things in the environment?  It could.  But even that tends to go by families some. ", "Some families just say, here's a few years worth of potato  chips, good luck.  Another family's going, oh my gosh, you didn't eat carrots  all month long.  Even that tends to be, on average, someone ", "environmental, right?  Both by economic opportunity, part of the world you're in,  parental attitudes, right?  I agree with you.  It's got to be something.  And maybe we just don't have the whole story right.  But here's two twins telling you why each of ", "them is very neat.  OK?  The first one is, my mother.  When I was growing up-- this is one household, one twin--  she always kept the house perfectly ordered.  I learned from her. ", "What else could I do?  I had a model in my parent.  She was neat, I'm neat.  Here's the other twin, who is also very neat.  The reason is quite simple.  I'm reacting to my mother, who was a complete slob. ", "OK?  So they're complete opposite stories.  I'm modeling my parents.  I'm rebelling against my parents.  But you know that they're identical twins, and they end  up in the same place. ", "Yeah?  AUDIENCE: [INAUDIBLE]  ", "PROFESSOR: That's another interpretation.  This is a good question.  The question is, I'm pretending the explanations  have nothing to do with anything, and you're saying  maybe this a personality thing.  Somebody who chooses to model their parent or just somebody  who chooses to rebel against their parent. ", "Maybe that's the personally dimension, right?  It could be.   It's just neatness.  Twins who aren't neat tend to go the same way and twins who  are neat tend to go the same way. ", "About 50 percent of the effect is in the genes.  I don't know.  I'm not saying that things aren't there.  It's a bit of a mystery, it's a bit of a shock.  So here's a couple more things. ", "Biological, non-twin siblings--  OK, so these are siblings but they're not twins--  are far more similar to one another  then adoptive siblings.  OK.  That's OK.  That's the genetics, right? ", "Because the adopted child is into the family.  But here's a shocking one.  For personality, children are no more similar to an adoptive  sibling than are two randomly selected children.  So in a household, if you have an adopted child and a ", "biological child in that household, sharing the same  environment, they are no more similar, one to the other,  than two random children in the world.  OK, where is the effect of the environment? ", "Where is the parental effect on the two children in terms  of personality?  So people have mounted this argument.  So let me pick another one.  Put up your hand if you want to. ", "I'll put up my hand.  How many people grew up in a household where one or more  parents spoke in a noticeable accent?  I mean, I did.  Let's just try this here. ", "How many of you who have your hand up-- keep your hand up--  did you keep your parents' accent?  Where's the environment? ", "In your critical moments of language development, you were  hearing that accent.  Where is the environment?  And you could say, well, yeah, but there are other people  speaking other things.  Yeah, but then zero parental influence on the way in which ", "you produce your language.  So there's a lot of different things to think as we move  from language to personality, but it's turning out to be  surprisingly hard on some dimensions to show an  influence of parental environment on child ", "development, especially in personality.  Yeah.  AUDIENCE: So, first off, for the adopted sibling thing.  It seems like that way, not only would they get similar  parental environment, but they also probably have similar ", "school environment--  PROFESSOR: Oh, yes.  It's worse than that.  This is a very good question.  It's not only that they have adoptive parents, if they have  another kid in the house, there's another kid in the  house, they probably go to the same-- if they go to church or ", "synagogue or anything like that.  Same school, same state, same influence of whoever's the NBA  basketball champion. ", "The whole list.  And it seems to be--  you can't identify anything in that.  Yeah?  AUDIENCE: Something that is biological but not in DNA, ", "that is also 50-50?  PROFESSOR: Yeah.  So diet would influence that.  Who knows?  AUDIENCE: Stuff like you're born with, so that it's not  just as an environmental thing, but it's not, strictly ", "speaking, in your DNA.  Because that's what identical twins--  PROFESSOR: Well, let me stop you there for one moment.  I think at some level of analysis, all environmental ", "influences--  education, parenting, everything--  will have a biological counterpart in your body and  in your brain, right?  Because the environment has to affect you by how it changes ", "your body or brain.  After you're born.  It could be added in.  There's things--  methylation, there's a lot-- yeah, it could be all those  things, but who's driving that? ", "So it's not--  my bet is that we'll discover stuff about this that  we don't grasp yet.  The answer is not going to be parenting makes no difference,  or environments make no difference, or schools make no ", "difference, for personality.  But we just don't know how to think about that yet is the  best guess, because it's just hard to believe.  Yeah.  AUDIENCE: Is there a correlation between IQ and any ", "kind of personality?  PROFESSOR: IQ and personality?  There is a moderate--  of conscientiousness especially,  but that makes sense.  On average--  and we certainly know people who are very smart and very ", "sloppy, but on average, the more conscientious you are,  like if you go to school, you do your homework, that kinds  of stuff, there is a positive correlation.  ", "So there's all kinds of-- one question is how much  personality is fixing your environment.  So how much is the way you are, from the moment you're  born, driving actually the way the teacher responds to you in ", "school, the way the parent responds to you?  And so that's why your personality's already driving  your actual environment.  Because we could say, well, you're in a school, but  really, do you like the teacher, do you  not like the teacher? ", "Do you like your parents?  Do you follow them?  Do you oppose them?  Maybe those kinds of things are happening.  Sometimes people think that your personality is driving ", "the way your environment responds to you.  It might be done by sibling contrast.  So you may have this experience that--  ", "parents and other people and siblings yourself often think  a fair bit how they are similar or dissimilar from  their own sibling, and they might overdo it.  Because a parent has two kids, one kid's like 1% more ", "outgoing, and they go, that's the outgoing one.  One kid plays 5% more time on the piano, and they go, oh,  she's the real musician.  And because he plays two more baseball games a year, he's ", "the athlete.  And then it starts to snowball that way, OK?  Or parent identification.  Could kids who identify with one parent or the other,  again, by their predispositions, sort of be ", "driving the way their parents interact with them in a way  that's, again, driven by the personality?  The personality--  from the first moment, for one reason or another--  is molding the environment around it and carrying the ", "environmental effect as well.  So one of the giant fights in all of psychology is this.  And there's not going to be an answer, I'll just  tell you the debate.  And it's at the core of this question of why do we do the ", "things we do.  So personality adjusted psychologists will say, it's  these things we've just discussed.  It's our predispositions to like things and not like other  things in a general way are personality. ", "Social psychologists--  and we'll spend two lectures in just a few weeks on social  psychology--  say people are all kind of the same.  It's all about the social situation we're in. ", "Probably it's like one of these nature-nurture things.  Probably something about the situation is something about  who you are.  But let me tell you how some of this debate is played out. ", "So a famous study that went against the idea of a  personality being constant across situations and time  came from Walter Mischel. ", "And they looked at conscientiousness.  And they said, OK, some kids score high or low or medium on  conscientiousness.  Now, let's look at 19 specific behaviors in their life. ", "Not their report of how they are, or their parents' report  of how they are, but things they do that we can measure.  How often do they make their bed?  How often do they go to class like they should?  How often do they complete their homework assignments?  How often do they have good class notes ", "when they leave classes?  So things you can check, yes or no.  And they said gee, what we notice is somebody tends to be  pretty consistent about whether they make their bed or ", "not every morning-- not perfect, but pretty  consistent.  But that same person may or may not be so good at  completing homework assignments.   And that person that's very consistent on completing ", "homework assignments may or may not be so good on having  neat class notes.  So it's not that people aren't consistent, but it's far more  specific about what they're consistent about than a big ", "personality dimension that covers a range of things that  ought to go together.  So this is situationism.  You behave in a certain way in a certain situation.  It's not like you have a personality that moves from ", "situation to situation and predicts the same behavior.  And here's another example of how they follow kids in a  summer camp, and here's different behaviors from one  child to another child. ", "So this is a child who, when a peer approaches, how verbally  aggressive they are.  And so, aggression is high this way.  These are different situations.  And you can see for one child they're aggressive in this ", "situation when they deal with an adult, and in this  situation this other child is aggressive when he or she  deals with a peer.  So if you were to say there's an aggressive thing about  people-- they're aggressive or they're not-- well, this ", "person's aggressive with a peer, and this person is  aggressive specifically with an adult.  And so is aggressiveness a personality thing?  Or situation by situation by situation? ", "In the movies you see all the time--  if you watch The Sopranos or many movies, it's not uncommon  to have the crime figure be really kind of nice with his  family, and really brutal with a competing criminal gang. ", "Right?  Have you seen that?  They're kind of nice at home, and then they go shoot people  on two seconds notice if they're  fighting about something.  So you see that kind of an idea. ", " Another thing that people have looked at that's related to  personality is temperament.  ", "So it's an innate, biologically based propensity  to engage in a certain style of behavior.  It's broader than a trait.  I'll describe one that's been well studied, but people like  it because they think it's observable.  So with traits, it's hard to just look at you and say ", "you're extroverted or you're conscientious.  I could follow you around all day and  maybe have an estimate.  But here, temperaments are broader than traits, and you  can see it in terms of people's sociability, ", "emotionality and activity level.  You can just follow them and see them  behave in certain ways.  So let's think about the temperament of shyness.  So the way these studies were done at Harvard was that some ", "babies, even at six weeks, are more reactive  to make sudden noises.  They're more fussy.  About 20% of children could be that way.  They make a noise or something and they cry, they get  disturbed, they're unhappy. ", "And so he called those children high-reactive or  inhibited babies.  They use those two terms for the same  idea, versus low reactive.  Ones who were very disturbed by the environment, and ones ", "who were, like, no big deal.  And the ones who were inhibited babies cried more,  they were distressed more, they showed more activity,  faster heart rates, higher levels of cortisol. ", "And they even have-- they could measure this in some  cases-- faster heart rates in the womb, even  before they were born.  Their hearts were racing.  So all they'd need is that one last little thing.  And the idea is that maybe their sympathetic nervous  system is easily aroused, seeks less arousing ", "situations, and it's inhibited because they're already  internally so aroused, they want calm.  So there's going to be a surprise in this story.  But as you go, in terms of thinking about shyness, and ", "you can measure these at two months or four months with  these very simple little things you do with babies to  see how they respond to some noise.  And to a decent extent, it predicts shyness in later  childhood and adulthood. ", "About a quarter of the children who look pretty  inhibited aren't shy, but about 75% who look pretty  inhibited end up shy.  So that's a pretty good prediction from a ", "two-month-old to a young adult.  About 75% of these children who look  pretty shy at two months--  and of course, they're not shy in a group, they're just  responding to noises--  end up being kind of shy as adults. ", " And they studied these until age 21, and again, in several  outcomes, specifically things like-- let's pick one-- ", "crime, how often they get in crime.  Children who are well controlled don't get so much  into crime.  Children who at 21 had poor control at age three are more  likely to get into trouble. ", "So as if these temperament factors in early, early  childhood are already risk factors for doing better or  worse in the world.  Another one that people enjoy studying is sensation seeking. ", "You know, the bungee jumpers, the people who like to  parachute, people who enjoy the thrill of activities,  novel, high-stimulation situations.  Statistically they have more fun, probably, in some ways. ", "They're more likely to dive, they're more likely to drive  fast, they're more likely to have drug or alcohol use,  they're more likely to send flame emails, listen to punk  music, and have driving accidents.  So it's an interesting mix of enjoyment and trouble. ", "And there's some evidence they have lower levels of something  in the blood that may be a measure of something that lets  dopamine last longer in the synapse in your brain.  Dopamine is the reward neurotransmitter. ", "So you could imagine that if the reward hangs around  longer, maybe you're more drawn towards instantly  rewarding things.  Another sort of, I think, two-dimensional classification ", "of personality.  Again, one dimension that he focused on was this  introversion to extroversion or stable to unstable.  This is neuroticism or introversion/extroversion in  the big five. ", "But there's some interesting turns on this.  Here's the interesting turn.  I mentioned it, but let me tell you one more time,  because it's counter-intuitive.  It's the opposite of what you think in terms of what people  have found.  So we think of extroverts as people who go to parties, are ", "very talkative, very outgoing, run around and have a social  time, and introverts as more likely to be shy, quiet,  withdrawn, right?  That's the definitions of the words.  But what people have found in a variety of studies is that ", "extroverts-- the outgoing people--  are less easily aroused.  So it's as if they seek stimulation.  It's as if their internal arousal is low, and they want  things that are stimulating in their environment to push up ", "their internal arousal, right?  Introverts are the opposite around.  Introverts are aroused already, and it's as if they  seek environments that are quiet, so their arousal is not ", "pushed above some level of discomfort.  So intuitively you might think extroverts are more aroused  internally, but the thought is that extroverts are actually  seeking arousal because they're a little lower inside. ", "Introverts are already feeling pretty aroused, so they don't  need more bungee jumping.  They're already feeling like they're bungee jumping, OK?  So then they're all seeking this sort of ", "optimal level of arousal.  So, for example, extroverts do better in noisy settings, they  can take the extra stuff, they don't mind it.  Introverts are more sensitive to pain, and they salivate ", "more to lemon juice.  They're already kind of revved up, is the story, internally.  So here's one--  we couldn't do this early in the course, and this almost ", "has practical concept--  you could think about this for your own test taking.  A three-way interaction.  This is three factors that all interact with one another in  performance, and it involves situation and personality. ", "So here we go.  So the three factors are whether you're introverted or  extroverted, whether you're taking a test-- a GRE kind of  a test-- in the morning or the afternoon, and whether you  drank a cup of coffee before the test or not. ", "Three different things floating around.  And here's what people have found several times in  experiments when you're taking a test.  Here's the upshot of the studies.  If you're introverted and the test is in the late afternoon ", "or evening, drink coffee.  If you're outgoing, drink coffee in the morning.  And I'll tell you the logic of this.  All right? ", "So here's the idea.  Many studies have shown-- and you may know this, if you  think about people you know or yourself.  On average, introverts are most aroused in the morning.  They tend to be get up early in the morning and get their  day going people. ", "Maybe because they didn't party deep into  the previous night.  There's cause and effect that's really hard to pull out  in all of this.  But introverts are more aroused in the morning and  less in the evening. ", "On average, they're the kind of people who are get up early  in the morning, go do their stuff.  In the evening they want to mellow down and maybe not go  to sleep so late.  Extroverts are more aroused in the evening,  and less in the morning. ", "And this is on average, and this has been  found a number of times.  So again, you can imagine if you're taking a test, if  you're under-aroused, you could use the  coffee to perk you up.  If you're over-aroused, the coffee is going to make you ", "jittery and push you over.  So depending on the time of day, you're going to be in one  state or the other depending on the kind of  personality you have.  Does that make sense?  These three things come together like that in the  famous Yerkes-Dodson Law of performance, which is this. ", "And this is observed in many years.  Here's arousal, how aroused you are.  Super aroused, super nervous, shaky, so sleepy you're about  to crash out. ", "Somewhere in the middle usually goes with best  performance, because this is too much,  and this is too little.  You know that.  If you're too nervous, you don't tend to perform well.  If you're too kind of out of it, you don't perform well. ", "Somewhere in the middle is just right.  So here's extroverts, for example.  In the morning, they're pretty low on this, they could use  some coffee to move to optimal. ", "Here's introverts in the morning, they're already ready  to go, I'm ready to go, I'm ready to go.  The last thing they need is more coffee.  I hope it's not a bubble test because my hands are shaking.  OK? ", "So three things.  The kind of personality you are, the time of day, and  whether your drinking coffee helps you to move to this  middle position or not.  Does that makes sense? ", "So that's three different factors sort of adding up to  optimize performance or not.  OK, lastly I'd like to talk a little bit about some things  we know about brain correlates of personality. ", "And in some areas, these brain things are more informative at  a broad level.  Because sometimes people will say, well, personality is all  this check box stuff.  Is it even relevant to anything biological? ", "Now, if it's relevant to behavior,  it's relevant to biology.  Behavior is biology, or biology is behavior.  We're not going to get one relative to the other.  But still, until recently, people couldn't measure this. ", "So these are pictures of--  not of brain functions, of a task turning on-- we'll see  pictures of those in a moment.  This is measurement of brain structure.  Measurement of brain structure. ", "And specifically, thickness of cortex.  So what you're seeing is a statistic here, which is, the  more extroverted you are, the thicker your cortex is here.  The more conscientious, the thicker your cortex here. ", "The more neurotic, the thicker your cortex here, and so on.  So we don't understand these deeply, but we do see  physically measurable correlates of these ", "personality dimensions.  So that's physical brain structure.  Let's talk about some function things.  This is a slide you saw before that in the amygdala, the more ", "emotionally intense something is, the more the response.  The more neutral it is, the less the response.  Here's a positive happy picture, right?  I'm going to show you a neutral picture.  I'm going to show you now the bad picture. ", "Don't look if you don't want to see it again.  It's the one you saw before.  Close your eyes for a moment.  Bad picture.  OK.  Here we go.  Now you can all look.  So people are introverted or extroverted.  Extroverts are sociable, talkative. ", "Introverts are, on average, more reserved or quiet.  Extroverts report more positive experiences, more  susceptible to positive mood induction.  Lots of evidence for some differences among them. ", "So imagine a study where you show people positive and  negative slides.  Again, people will say, well, if I'm on a diet, this is  really negative, or something.  You have people rate them. ", "But on average these are negative, and on average these  are positive.  You measure their personality, and here's what you find in  the amygdala.  ", "The more extroverted they are, the more their amygdala  responds to positive things.  The more introverted they are, the more it responds to  negative things. ", "So here's exactly what we mean by personality sort of  instantiated in one example.  And it's not the only example.  What do we mean by personality?  We mean there's a constant situation--  let's pretend a party you go to. ", "A party deep in my memory.  I remember parties I went to, the music is playing, and  there's sticky beer on the floor, and there's people you  know and a lot of people you don't know, right?  So who walks in the door and thinks this is awesome? ", "The extrovert, right?  Who walks in the door and thinks why did my friend drag  me to this?  I could be doing something good like chess at home.  ", "So now, identical situation, different-- but that's true of  so many things and preferences in life.  That's almost what we mean by personality, right?  Who likes what?  Situations, people, activities. ", "So for extroversion, here's the amygdala going, positive  things, whoopee!  They notice, so to speak, in their amygdala the positivity  of the environment.  They're drawn to things because they see positive. ", "Here is the introverts going, danger, danger.  OK?  Everybody sees the same set of slides, but people are drawn  to the positive or the negative aspects of this.  And you could say, is one better, the other worse?  Well, no. ", "Avoiding dangerous things is a good idea.  Enjoying positive things is a good idea.  One is not better than the other.  They're just different.  You're tuned to different rewards in life.  And this is one example of that. ", "How about a smiling face?  Who thinks a smiling face is an invitation to go over and  meet somebody new?  The introvert or the extrovert?  Help me on this.  Who thinks the smiling face is pressure? ", "Do I go over?  Are they smiling at me?   Or I'm going to go over and then they're  not gonna like me.  They like me now, right?  I should tell you, I was quite-- ", "only in my teaching mode do I appear extroverted, OK?  But I definitely was an introvert in  high school and college.  So if I make fun of introverts, I'm  making fun of myself.  So here's a response to fearful faces. ", "And we talked about that before, response in the  amygdala regardless of personality.  But now when we talk about the response in the amygdala for  happy faces, big response if you're extroverted, little ", "response if you're introverted.  Because a happy face is like compelling, cool, wonderful  for the extrovert, and not as enticing for the introvert.  So again, the way we might imagine, how do individual ", "differences in personality play out?  They play out that some things are beguiling, wonderful, and  other things not so much.  And depending on your personality, that can vary.  ", "So these are the children who were studied from the ages of  two and four months who were shy in temperament,  inhibited, in orange. ", "And they compared them to the most uninhibited.  They take the extremes.  But it's a very rare thing when you have a behavioral  assessment of a child in their infancy, and then you brain ", "image them about 20 years later when they're grown up.  So now you're making this 20 years of your life story, and  again in the amygdala, what they find is this. ", "If you look at the people who are uninhibited, here's a  novel face they see for the first time in the scanner, or  a face they've seen many times, and there's not much  difference. ", "For the people who are inhibited, you see a much  bigger amygdala response to the novel face.  Well, this is exactly what you might intuitively think  shyness would be about.  If you're a shy person and you know somebody well, I think a ", "lot of shyness disappears.  But where shyness shows the most is a face that you don't  know, a new person you haven't met, and maybe you're not so  comfortable with them yet.  So this is exactly the pattern you might expect, that it ", "doesn't matter too much for an extrovert, a new face, a  familiar face--  made familiar in the experiment, not somebody you  really know--  it doesn't make much of a difference.  For the person who is inhibited, much more response ", "to the face they see for the first time only, as opposed to  a face they've grown familiar with.  A couple more examples along this line.  Here's another scale. ", "There's an infinite number of them.  The Spielberger State and Trait Anxiety, so, state and  trait, right?  So they ask you-- this is just a reminder of that--  how do you feel right now?  That would be your state.  Right now. ", "Do I feel at ease?  Do I feel upset?  And in general, how do you feel, at ease or upset?  So this is day in day out, this is right now.  We're going to focus on the trait, how you say you feel ", "day in, day out.  And now they're going to show you faces of people who are  shown in full view, or who are shown in a subliminal masked  version where a fear or neutral face is followed by ", "another face.  This is the critical face.  So you see a face that you see pretty well, or you see a face  that's presented under circumstances where you can't  tell what the face was.  OK? ", "At first they say, what happens if we show you the  regular face that you see perfectly well?  Nothing makes much of a difference.  Here's the amygdala response to fearful face.  You've seen this now multiple times. ", "But kind of interestingly, you get a smaller response in the  amygdala, and it's driven by how anxious you report  yourself to be on a regular basis.  So the interpretation is this. ", "If you see a fearful face, you go, well, it's a fearful face,  I know it's a fearful phase, we're all the same.  If you subliminally present it, you have an  unknown source of danger. ", "What we intuitively imagine anxiety is is feeling danger  or threat in your environment more than is helpful, more  than is comfortable.  OK? ", "And you don't even know exactly why.  It's not entirely rational when you're  anxious in that way.  And so what happens is, the more anxious you are, the more  these subliminal faces drive an amygdala response, and you ", "don't have control over that, because you don't know what  happened, because it was subliminally presented.  Does that make sense?  When it's clear, everybody knows what to do.  It's just a face and not that scary.  But when it's an unknown source of a bit of unease, the ", "more chronically anxious you are, the more the brain's  responding.  Or we might say, the bigger the brain response is the  basis, perhaps, of the chronic unease. ", "So we talked also before about the amygdala being important  for recognizing fearful expressions.  And then I want to share two last examples.  How about genetic influences? ", "So we know genes are a big part of the story, but how big  a part of the story?  So again, we talked about single nucleotide  polymorphisms, common genetic variance.  And here's one that involves a serotonin ", "transporter in the amygdala.  There's a short or long allele, so we'll have two of  these, all of us.  The short allele is weakly correlated ", "with anxiety traits.  All this genetic stuff is pretty weak at the moment, for  reasons that are not well understood.  I'm only presenting you ones that have been at least  replicated once.  But practically every genetic example I'm going to show you, ", "there's been non-confirmations as well.  We don't know why this is.  The genes are just so far away from complex human behaviors  is probably the answer.  But what has been replicated a number of times is this. ", "If they show you fearful faces, and you have the short  allele, the one that's slightly associated with  anxiety, this is the difference between people with  the long allele and the shorter allele, a much more ", "powerful response to fearful faces if you  have the shorter allele.  So a single gene can be correlated with a more potent  response to a sort of threat stimulus.  And again, that goes with our sense of anxiety, and what we ", "might call a less than desirable response to threat  in the environment.  So here's the last two slides.  But it's the dream we all have in understanding people, and ", "actually all animals on the face of this planet, but  people most of all if you're curious about people, which  is, what is the interaction between the genes we're born  with and the life we lead, and how does that end up ", "with us being us?  And it's incredibly hard to study that, because everybody  says in biology and neuroscience, we know it's a  gene by experience interaction. ", "The genes will make you strong in some circumstances and  vulnerable in others.  But it's very hard to specify that.  The genes have been hard to identify.  And we can't put people into experiments. ", "We can't say, we'll take two identical twins and we'll put  one into some horrible household full of stress and  horribleness, and then one into a delightful household,  and then see them at 20 and see what happened. ", "OK?  We're just not allowed to do that, right?  So we can't experiment on the environment, and the genes are  poorly understood, very poorly understood, in relation to ", "basic human behaviors.  But there's a study from Caspi that is a glimpse of where we  think the field might be going.  But I'm going to warn you that this has not always been  replicated.  It's been replicated sometimes, ", "but not other times.  So it's an asterisk, but it's still a finding that's really  quite striking, if it turns out to be roughly correct.  So again, this is polymorphism of the same gene that's ", "associated with anxiety.  And what they did in a very large sample in New Zealand  was catalog stressful life events ages 21 to 26, job, ", "whether you have a job or not, your salary, decent housing,  terrible housing, good health, bad health, happy  relationships, no relationships, terrible  relationships.  People are filling out forms telling you about the stresses  in their life. ", "And then they also have information about childhood  maltreatment.  Some of these children, very sadly, when they were younger  were treated very poorly, they were abused in some way or  another, were in very terrible circumstances, and some not. ", "So they're going to look at stressful events in childhood  and adulthood, and sort them out by the allele that the  individuals have, the gene version, and what they find ", "is-- and I'll show you the graph in a moment--  more depression and suicidality in response to  stressful events if you have a short version of the allele.  The short version, we just said, is the one that seems to  drive a bigger anxiety response to fearful faces in ", "the amygdala, OK?  So it seems, first pass, to be a gene that's associated with  responding in a more anxious way to environmental stress, ", "threat, and bad things.  So here's a couple of graphs.  I'll just do a couple with you.  Here's the probability of major depression if you've had ", "no maltreatment as a child, if you've probably had some, or  you've had documented horrible maltreatment as a child.  And what you can see if you have the long version-- this  is this line here-- ", "the long version of this allele, no difference.  It's as if if you happen to be born in the biological lottery  that we all participate in at birth with these version of ", "these genes-- and maybe many other genes that are part of  this story, but they just measured this one.  That it doesn't matter whether you live in a nice supportive  environment or a brutalizing, horrible one, your probability ", "of depression is about the same.  It's a protective gene for stresses of life that are  visited upon you.  If you have the opposite, the short version, look. ", "The worse the environment, you double your chances of  depression.  It's as if you're born with a gene that, if you're given a  terrible environment--  this is exactly the interaction, right-- ", "then you're very susceptible to that.  And you see the same rough pattern in all of them, that  individuals who have this version of the gene seem to be ", "relatively impervious to environmental stressors.  The ones born with this version of the gene are  terribly-- so if this person's born with this version of the  gene, but happens to be in a nice supportive ", "household, no problem.  Right?  But if they happen to be born into a household where they  experience, sadly, severe maltreatment, big problem. ", "And so this is exactly what we imagine if we understood in  any depth what people are about, the genetic  potentiations you're born with, what's easy for you or  hard for you by genes. ", "And the world your handed as an infant, not under your  control, but the environment you're given, supportive or  threatening, how those two things play out in a sort of  duet, making you safe or putting you at risk. ", "That's exactly what would-- then we would deeply  understand the biology and the psychology of human life.  So this is the kind of study that gets a lot of attention,  because if we had it exactly right, which we don't yet, we ", "would understand something really deep about people and  vulnerability in environments. "], "vid_duration": [13.189, 11.55, 10.39, 10.351, 13.18, 10.789, 10.481, 12.13, 11.01, 10.27, 12.79, 11.48, 10.17, 11.02, 10.94, 12.4, 12.61, 13.26, 12.72, 12.52, 10.66, 10.2, 10.27, 13.55, 11.08, 10.22, 11.23, 10.69, 12.16, 11.62, 12.75, 12.43, 11.15, 10.7, 11.0, 14.19, 10.5, 11.769, 12.671, 12.449, 11.411, 10.01, 10.26, 10.589, 11.031, 12.04, 10.98, 10.51, 15.79, 11.09, 11.49, 10.44, 12.46, 13.15, 11.845, 11.265, 11.13, 11.15, 11.47, 10.64, 11.73, 11.36, 10.63, 10.04, 11.83, 11.64, 10.7, 11.76, 10.45, 12.56, 10.127, 10.763, 11.74, 11.48, 11.49, 13.43, 11.99, 10.72, 10.232, 13.048, 10.82, 12.5, 13.88, 13.619, 11.181, 11.27, 11.01, 10.6, 11.65, 10.87, 11.68, 10.11, 10.88, 11.68, 10.57, 11.0, 11.3, 13.23, 11.12, 14.64, 11.46, 12.83, 11.01, 10.12, 10.65, 10.67, 11.55, 11.47, 10.19, 10.0, 13.3, 10.44, 12.49, 11.47, 10.76, 12.36, 10.48, 11.95, 11.41, 10.72, 11.58, 10.06, 10.17, 12.69, 11.87, 11.46, 12.45, 11.52, 11.34, 11.94, 10.81, 11.22, 11.21, 10.33, 12.8, 11.45, 11.11, 12.25, 10.74, 10.47, 10.13, 13.45, 11.4, 10.66, 10.02, 12.06, 12.98, 12.7, 10.25, 10.28, 10.11, 12.8, 12.35, 11.698, 11.282, 11.28, 11.356, 11.436, 10.108, 11.51, 12.4, 10.9, 10.87, 12.2, 10.98, 10.37, 10.81, 10.43, 10.5, 10.67, 10.51, 10.85, 10.35, 11.9, 10.86, 11.99, 10.65, 10.01, 10.32, 12.059, 10.401, 11.119, 11.641, 10.13, 11.08, 10.88, 11.55, 10.72, 14.02, 10.25, 10.86, 12.16, 12.33, 10.3, 10.3, 10.12, 11.34, 12.25, 12.47, 10.31, 10.09, 11.81, 14.49, 11.12, 13.67, 12.6, 11.54, 12.34, 13.945, 11.535, 11.58, 11.635, 10.785, 10.5, 13.39, 10.59, 11.06, 10.74, 12.23, 12.6, 13.79, 10.32, 10.93, 11.19, 10.19, 11.02, 11.83, 10.45, 11.65, 12.1, 10.19, 10.37, 11.98, 11.43, 11.66, 11.39, 11.86, 10.39, 10.24, 11.77, 11.42, 10.88, 10.65, 10.08, 11.66, 10.93, 11.05, 10.28, 10.93, 11.23, 10.46, 11.78, 11.33, 12.4, 12.75, 11.1, 12.6, 11.68, 11.35, 10.07, 10.61, 10.39, 10.72, 12.81, 10.525, 10.185, 10.2, 10.99, 11.8, 10.88, 10.1, 11.65, 10.45, 10.62, 11.42, 12.51, 10.64, 10.53, 10.65, 11.2, 11.42, 10.64, 10.02, 11.82, 13.88, 10.3, 12.05, 10.83, 10.12, 10.31, 11.11, 10.65, 13.24, 11.49, 13.08, 11.11, 13.305, 10.095, 10.05, 10.9, 12.85, 12.05, 11.1, 12.13, 11.11, 10.57, 10.32, 10.44, 14.0, 11.065, 4.295], "stet": [[0, 13.189], [13.189, 24.739], [24.739, 35.129000000000005], [35.129000000000005, 45.480000000000004], [45.480000000000004, 58.660000000000004], [58.660000000000004, 69.449], [69.449, 79.92999999999999], [79.92999999999999, 92.05999999999999], [92.05999999999999, 103.07], [103.07, 113.33999999999999], [113.33999999999999, 126.13], [126.13, 137.60999999999999], [137.60999999999999, 147.77999999999997], [147.77999999999997, 158.79999999999998], [158.79999999999998, 169.73999999999998], [169.73999999999998, 182.14], [182.14, 194.75], [194.75, 208.01], [208.01, 220.73], [220.73, 233.25], [233.25, 243.91], [243.91, 254.10999999999999], [254.10999999999999, 264.38], [264.38, 277.93], [277.93, 289.01], [289.01, 299.23], [299.23, 310.46000000000004], [310.46000000000004, 321.15000000000003], [321.15000000000003, 333.31000000000006], [333.31000000000006, 344.93000000000006], [344.93000000000006, 357.68000000000006], [357.68000000000006, 370.11000000000007], [370.11000000000007, 381.26000000000005], [381.26000000000005, 391.96000000000004], [391.96000000000004, 402.96000000000004], [402.96000000000004, 417.15000000000003], [417.15000000000003, 427.65000000000003], [427.65000000000003, 439.41900000000004], [439.41900000000004, 452.09000000000003], [452.09000000000003, 464.53900000000004], [464.53900000000004, 475.95000000000005], [475.95000000000005, 485.96000000000004], [485.96000000000004, 496.22], [496.22, 506.809], [506.809, 517.84], [517.84, 529.88], [529.88, 540.86], [540.86, 551.37], [551.37, 567.16], [567.16, 578.25], [578.25, 589.74], [589.74, 600.1800000000001], [600.1800000000001, 612.6400000000001], [612.6400000000001, 625.7900000000001], [625.7900000000001, 637.6350000000001], [637.6350000000001, 648.9000000000001], [648.9000000000001, 660.0300000000001], [660.0300000000001, 671.1800000000001], [671.1800000000001, 682.6500000000001], [682.6500000000001, 693.2900000000001], [693.2900000000001, 705.0200000000001], [705.0200000000001, 716.3800000000001], [716.3800000000001, 727.0100000000001], [727.0100000000001, 737.0500000000001], [737.0500000000001, 748.8800000000001], [748.8800000000001, 760.5200000000001], [760.5200000000001, 771.2200000000001], [771.2200000000001, 782.9800000000001], [782.9800000000001, 793.4300000000002], [793.4300000000002, 805.9900000000001], [805.9900000000001, 816.1170000000001], [816.1170000000001, 826.8800000000001], [826.8800000000001, 838.6200000000001], [838.6200000000001, 850.1000000000001], [850.1000000000001, 861.5900000000001], [861.5900000000001, 875.0200000000001], [875.0200000000001, 887.0100000000001], [887.0100000000001, 897.7300000000001], [897.7300000000001, 907.9620000000001], [907.9620000000001, 921.0100000000001], [921.0100000000001, 931.8300000000002], [931.8300000000002, 944.3300000000002], [944.3300000000002, 958.2100000000002], [958.2100000000002, 971.8290000000002], [971.8290000000002, 983.0100000000002], [983.0100000000002, 994.2800000000002], [994.2800000000002, 1005.2900000000002], [1005.2900000000002, 1015.8900000000002], [1015.8900000000002, 1027.5400000000002], [1027.5400000000002, 1038.41], [1038.41, 1050.0900000000001], [1050.0900000000001, 1060.2], [1060.2, 1071.0800000000002], [1071.0800000000002, 1082.7600000000002], [1082.7600000000002, 1093.3300000000002], [1093.3300000000002, 1104.3300000000002], [1104.3300000000002, 1115.63], [1115.63, 1128.8600000000001], [1128.8600000000001, 1139.98], [1139.98, 1154.6200000000001], [1154.6200000000001, 1166.0800000000002], [1166.0800000000002, 1178.91], [1178.91, 1189.92], [1189.92, 1200.04], [1200.04, 1210.69], [1210.69, 1221.3600000000001], [1221.3600000000001, 1232.91], [1232.91, 1244.38], [1244.38, 1254.5700000000002], [1254.5700000000002, 1264.5700000000002], [1264.5700000000002, 1277.8700000000001], [1277.8700000000001, 1288.3100000000002], [1288.3100000000002, 1300.8000000000002], [1300.8000000000002, 1312.2700000000002], [1312.2700000000002, 1323.0300000000002], [1323.0300000000002, 1335.39], [1335.39, 1345.8700000000001], [1345.8700000000001, 1357.8200000000002], [1357.8200000000002, 1369.2300000000002], [1369.2300000000002, 1379.9500000000003], [1379.9500000000003, 1391.5300000000002], [1391.5300000000002, 1401.5900000000001], [1401.5900000000001, 1411.7600000000002], [1411.7600000000002, 1424.4500000000003], [1424.4500000000003, 1436.3200000000002], [1436.3200000000002, 1447.7800000000002], [1447.7800000000002, 1460.2300000000002], [1460.2300000000002, 1471.7500000000002], [1471.7500000000002, 1483.0900000000001], [1483.0900000000001, 1495.0300000000002], [1495.0300000000002, 1505.8400000000001], [1505.8400000000001, 1517.0600000000002], [1517.0600000000002, 1528.2700000000002], [1528.2700000000002, 1538.6000000000001], [1538.6000000000001, 1551.4], [1551.4, 1562.8500000000001], [1562.8500000000001, 1573.96], [1573.96, 1586.21], [1586.21, 1596.95], [1596.95, 1607.42], [1607.42, 1617.5500000000002], [1617.5500000000002, 1631.0000000000002], [1631.0000000000002, 1642.4000000000003], [1642.4000000000003, 1653.0600000000004], [1653.0600000000004, 1663.0800000000004], [1663.0800000000004, 1675.1400000000003], [1675.1400000000003, 1688.1200000000003], [1688.1200000000003, 1700.8200000000004], [1700.8200000000004, 1711.0700000000004], [1711.0700000000004, 1721.3500000000004], [1721.3500000000004, 1731.4600000000003], [1731.4600000000003, 1744.2600000000002], [1744.2600000000002, 1756.6100000000001], [1756.6100000000001, 1768.3080000000002], [1768.3080000000002, 1779.5900000000001], [1779.5900000000001, 1790.8700000000001], [1790.8700000000001, 1802.226], [1802.226, 1813.662], [1813.662, 1823.77], [1823.77, 1835.28], [1835.28, 1847.68], [1847.68, 1858.5800000000002], [1858.5800000000002, 1869.45], [1869.45, 1881.65], [1881.65, 1892.63], [1892.63, 1903.0], [1903.0, 1913.81], [1913.81, 1924.24], [1924.24, 1934.74], [1934.74, 1945.41], [1945.41, 1955.92], [1955.92, 1966.77], [1966.77, 1977.12], [1977.12, 1989.02], [1989.02, 1999.8799999999999], [1999.8799999999999, 2011.87], [2011.87, 2022.52], [2022.52, 2032.53], [2032.53, 2042.85], [2042.85, 2054.909], [2054.909, 2065.31], [2065.31, 2076.429], [2076.429, 2088.07], [2088.07, 2098.2000000000003], [2098.2000000000003, 2109.28], [2109.28, 2120.1600000000003], [2120.1600000000003, 2131.7100000000005], [2131.7100000000005, 2142.4300000000003], [2142.4300000000003, 2156.4500000000003], [2156.4500000000003, 2166.7000000000003], [2166.7000000000003, 2177.5600000000004], [2177.5600000000004, 2189.7200000000003], [2189.7200000000003, 2202.05], [2202.05, 2212.3500000000004], [2212.3500000000004, 2222.6500000000005], [2222.6500000000005, 2232.7700000000004], [2232.7700000000004, 2244.1100000000006], [2244.1100000000006, 2256.3600000000006], [2256.3600000000006, 2268.8300000000004], [2268.8300000000004, 2279.1400000000003], [2279.1400000000003, 2289.2300000000005], [2289.2300000000005, 2301.0400000000004], [2301.0400000000004, 2315.53], [2315.53, 2326.65], [2326.65, 2340.32], [2340.32, 2352.92], [2352.92, 2364.46], [2364.46, 2376.8], [2376.8, 2390.7450000000003], [2390.7450000000003, 2402.28], [2402.28, 2413.86], [2413.86, 2425.4950000000003], [2425.4950000000003, 2436.28], [2436.28, 2446.78], [2446.78, 2460.17], [2460.17, 2470.76], [2470.76, 2481.82], [2481.82, 2492.56], [2492.56, 2504.79], [2504.79, 2517.39], [2517.39, 2531.18], [2531.18, 2541.5], [2541.5, 2552.43], [2552.43, 2563.62], [2563.62, 2573.81], [2573.81, 2584.83], [2584.83, 2596.66], [2596.66, 2607.1099999999997], [2607.1099999999997, 2618.7599999999998], [2618.7599999999998, 2630.8599999999997], [2630.8599999999997, 2641.0499999999997], [2641.0499999999997, 2651.4199999999996], [2651.4199999999996, 2663.3999999999996], [2663.3999999999996, 2674.8299999999995], [2674.8299999999995, 2686.4899999999993], [2686.4899999999993, 2697.879999999999], [2697.879999999999, 2709.7399999999993], [2709.7399999999993, 2720.129999999999], [2720.129999999999, 2730.369999999999], [2730.369999999999, 2742.139999999999], [2742.139999999999, 2753.559999999999], [2753.559999999999, 2764.439999999999], [2764.439999999999, 2775.0899999999992], [2775.0899999999992, 2785.169999999999], [2785.169999999999, 2796.829999999999], [2796.829999999999, 2807.759999999999], [2807.759999999999, 2818.809999999999], [2818.809999999999, 2829.0899999999992], [2829.0899999999992, 2840.019999999999], [2840.019999999999, 2851.249999999999], [2851.249999999999, 2861.709999999999], [2861.709999999999, 2873.4899999999993], [2873.4899999999993, 2884.8199999999993], [2884.8199999999993, 2897.2199999999993], [2897.2199999999993, 2909.9699999999993], [2909.9699999999993, 2921.0699999999993], [2921.0699999999993, 2933.669999999999], [2933.669999999999, 2945.349999999999], [2945.349999999999, 2956.699999999999], [2956.699999999999, 2966.769999999999], [2966.769999999999, 2977.379999999999], [2977.379999999999, 2987.769999999999], [2987.769999999999, 2998.489999999999], [2998.489999999999, 3011.299999999999], [3011.299999999999, 3021.824999999999], [3021.824999999999, 3032.009999999999], [3032.009999999999, 3042.2099999999987], [3042.2099999999987, 3053.1999999999985], [3053.1999999999985, 3064.9999999999986], [3064.9999999999986, 3075.8799999999987], [3075.8799999999987, 3085.9799999999987], [3085.9799999999987, 3097.6299999999987], [3097.6299999999987, 3108.0799999999986], [3108.0799999999986, 3118.6999999999985], [3118.6999999999985, 3130.1199999999985], [3130.1199999999985, 3142.6299999999987], [3142.6299999999987, 3153.2699999999986], [3153.2699999999986, 3163.799999999999], [3163.799999999999, 3174.449999999999], [3174.449999999999, 3185.6499999999987], [3185.6499999999987, 3197.069999999999], [3197.069999999999, 3207.7099999999987], [3207.7099999999987, 3217.7299999999987], [3217.7299999999987, 3229.549999999999], [3229.549999999999, 3243.429999999999], [3243.429999999999, 3253.729999999999], [3253.729999999999, 3265.7799999999993], [3265.7799999999993, 3276.609999999999], [3276.609999999999, 3286.729999999999], [3286.729999999999, 3297.039999999999], [3297.039999999999, 3308.149999999999], [3308.149999999999, 3318.7999999999993], [3318.7999999999993, 3332.039999999999], [3332.039999999999, 3343.529999999999], [3343.529999999999, 3356.6099999999988], [3356.6099999999988, 3367.719999999999], [3367.719999999999, 3381.0249999999987], [3381.0249999999987, 3391.1199999999985], [3391.1199999999985, 3401.1699999999987], [3401.1699999999987, 3412.069999999999], [3412.069999999999, 3424.9199999999987], [3424.9199999999987, 3436.969999999999], [3436.969999999999, 3448.069999999999], [3448.069999999999, 3460.199999999999], [3460.199999999999, 3471.309999999999], [3471.309999999999, 3481.879999999999], [3481.879999999999, 3492.1999999999994], [3492.1999999999994, 3502.6399999999994], [3502.6399999999994, 3516.6399999999994], [3516.6399999999994, 3527.7049999999995], [3527.7049999999995, 3531.9999999999995]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [711, 1259, 2655, 3532]}
{"example_id": "mit057@@MIT9_00SCF11_lec05_300k", "text": ["How We See.  And for today's lecture, I got help from Melissa Troyer, one  of your teaching assistants.  So, one of the things we can think about is what are the  purposes of vision?  What do we use sight for? ", "And we'll talk about that.  Problems that the visual system has to overcome.  What are the obstacles for vision to work accurately and  efficiently?  And how does the brain organization of vision serve ", "the human capacity to see?  So human perceptual abilities are amazing, as are perceptual  abilities of many species in different areas.  But humans can detect a candle 30 miles away on ", "a dark, clear night.  They can detect cochlear displacements  that's in your ear--  equal to the width of a hydrogen atom.  You can taste 1 teaspoon of sugar, even when it's mixed in ", "two gallons of water.  You can smell a drop of perfume diffused into the  space of a three-bedroom apartment.  So the human capacity to perceive the world in a highly ", "sensitive way is remarkable.  We're going to focus on vision specifically today.  And think, what do we use vision for?  Well, how does it serve us in dealing with the world? ", "And researchers have thought about two major reasons that  we see, two purposes of vision.  One of them is object recognition.  Recognizing things in the world.  People we know, words we can read, ", "chairs, tables, animals--  all kinds of things that we see out there.  And we need to know who they are or what they are in order  to operate in the world.  And the second one is a little bit different, navigation-- ", "getting around in the world.  When you're running, when you're jumping, when you're  reaching to grab something, you're not usually much  interested in what something is, as where you're moving,  where you need to move to avoid something ", "being thrown at you.  So two big purposes of vision--  what things are and where they are, so you can navigate  around quickly in the world.  And when we think about purposes of vision, for what ", "things are or where they are, psychologists and people  working in computer vision have recognized a series of  problems that our visual system has to solve.  We have to link unique images. ", "Because when we see something, it'll almost always look  different from one perceptual moment to the next.  We can see the same person, for example, but under  different conditions of illumination, darkness or ", "lightness or shadows, the angle we see them at, the  distance we see them at, the expression on their face-- a  smile or frown--  shadows that might be being cast, occlusion, a thing  blocking part of their face. ", "And yet, we can recognize a person very well under all  these circumstances.  So what arrives in our eye is different from  all of these views.  But what we interpret them is all the same. ", "That's a person I know.  The same thing with letters.  We can see letters in all kinds of fonts and all kinds  of handwriting, and yet we can interpret what they are in a  uniform way.  Or body.  We can see bodies of all kinds of different positions. ", "But our visual system lets us know right  away that it's a person.  And so psychologists have tried to formalize these kinds  of problems to ones of equivalents.  So something is the same thing at different views. ", "Generalization--  something has a very different shape.  Or impoverished input, where there's poor lighting or  something's complicated.  And you still figure out what it is.  For getting around in the world or where things are in ", "the world, you're moving through space  and tracking things.  And there's many sources of movement.  Your eyes are constantly moving.  Your head is moving.  Your body is moving.  And the world is moving.  And you have to sort all those out. ", "Run quickly.  Jump [INAUDIBLE]  world spatially.  And so here's some examples.  Here's a shape constancy problem.  Here's two different versions of a cat. ", "It's trivial for you to know that even though these things  have different shapes, they represent the same thing.  But that's an achievement of your visual system, to easily  make that equivalence across two very different shapes. ", "And we know, from computer vision, how hard these  problems are.  No computer vision system sees with anything like the  generalized ability of a very young child. ", "So our visual systems are so brilliant that psychologists  and vision scientists really interrogate our visual system  to figure out, how do we do it.  If people didn't do this, we'd think it would be impossible ", "to accomplish at all.  Here's another example that's easily solved by people-- not  so easily solved by machines.  If you see something like a car at different angles, we ", "know that's the same thing, pretty easily, even though,  again, the information that arrives to our eyes is  radically different.  And the same thing can be said of something like all these ", "different versions of the letter C.  Radically different shapes.  But we can readily interpret almost all them-- this one  won't be too tough--  as the letter C.  So our visual system does this brilliantly. ", "And also you get very impoverished views.  A key might be covered by something, clothes on a hook.  There might be a book over here.  There might be a fire hydrant over here or a person.  And yet, even though you get only partial information, it's ", "relatively trivial to discover, for you, what it is  you're looking at.  Or you can see things like you've never seen before.  The pink elephant, this odd picture, this striped ... ", "you've never seen them before but it's not really ...  So again, your visual system is just so brilliant at  matching what it sees with what you know to figure out ", "what's in front of you.  So today we're going to talk about how our minds and brains  allow us to see the world vision.  And we'll talk about it in three parts; how philosophers ", "and psychologists have thought about the idea of seeing; how  when information first enters your eye-- your retina--  which are set of layers in the back of the eye; how that ", "retina's already organized to help you see the world; and  how that information is then transported into the cortex,  where higher-level processing lets you know where you are  and what you're looking at. ", "So the ideas about how we learn to see the world have  their roots in philosophy.  For example, John Locke is associated with the idea of  the blank slate or tabula rosa. ", "He said, \"Let us suppose the mind to be a white paper void  of any characters, without any ideas.  How comes it to be furnished?  Whence comes it by that vast store, which the busy and  boundless fancy of man has painted on it with an almost ", "endless variety?\" Where do we get the information for how  the world works when we look at it?  And his answer to that was experience.  That we notice things around us, and experience drives our ", "understanding of the world.  And that position that there's a blank slate and we learn  objectively from the world around us has been called the  Objectivist view.  And maybe, that we see the world that we build up through ", "experience, knowledge about how to accurately represent  what's around us.  The alternative you has emphasized how much our mind  organizes what we see, instead of what's out there itself. ", "And so Gestalt psychologists or Gestalt views on perception  say, it's not what's out there in the world, but the way our  mind organizes and believes what's out there.  And these two things can come together. ", "So for example, when you think about how you listen to a  piano, music comes from piano the same way a  pianist strikes chords.  There's things out there in the world that you see. ", "The piano has certain limitations.  It can sound like somethings but not others.  It can't be a clarinet.  There's constraints in the world on what's possible to  see what's out there. ", "And our percepts are evoked by nature in this way.  But they are personal and not a copy of nature.  In the words, we each, individually, figure out  what's going on there by our own experiences and  interpretation. ", "And they're exactly that-- an interpretation, not a simple  mirroring or copy of nature.  So I'm going to try and convince you of something that  might not be obvious to people when they first think about ", "it, that vision is an interpretation of the  world around us.  It's not simply a video camera or mirror, it's an active  calculation of what's out there.  And we see, through inference, what we believe that we see. ", "And that visual illusions--  and you've seen some before, and I'll show you some again--  are not just illusions to trick people and confuse them.  But they're demonstrations of a gap between what's actually ", "out there in the world and how we interpret it.  Most of the time we don't have illusions.  We don't walk into walls.  We don't misidentify people we know commonly. ", "Because illusions are rare, because our minds and brains  have evolved to interpret the world that's out there, and  the system works so brilliantly coupled with the  environment that we actually live in, that we  don't think about it. ", "So the person on the street says, well, what  do I need to see?  I open my eyes.  But that's because our visual system works so brilliantly,  effortlessly, and automatically. ", "It's such a calculating machine that that's why it  feels so simple.  So here's one, small example.  And I'll show you a number of visual illusions that show us ", "how we're constantly interpreting even the most  simple thing.  So for example, here's two people.  And we're not worried that this is one of the shortest  men you've ever seen, because we know, through prospective, ", "this person's standing back there.  Even though, if they were standing right next to  somebody, you'd worry about the size of that person.  So we're constantly interpreting information by  the context in which we see it. ", "Here's another example of the choice of interpretations.  You can see a vase.  Or you can see two faces here. , Usually it's hard for people  to see them both simultaneously.  They tend to flip back and forth.  But you can choose the ", "interpretation of what you see.  So let me pick one example where people have studied a  lot, which is the issue of brightness constancy.  So here's the problem for the visual system. ", "The ambient brightness, the brightness around us, varies  in staggering ratios.  When we're outdoors in the sun-- and even that's not  constant, right?  Sometimes it's a bright day.  Sometimes it's a cloudy day. ", "Sometimes we're indoors under bright conditions or less  bright conditions.  So huge changes in the ambient illumination.  Or in shadows-- we'll make it even more complicated.  That means in a purely measurement sense, in a purely ", "physics sense, a piece of coal in sunlight reflects 10 times  as much light as snow in the shade.  So think about that for a moment.  You're not disturbed if you see a piece of  coal inside or outside. ", "They both look, to you, like black, dark pieces of coal.  And snow looks, pretty much, the same to you if it's inside  or outside.  But if you're visual system worked like a simple,  objective light meter, you would conclude that the piece ", "of coal in the sunlight is a much brighter thing-- in an  objective sense--  than snow in the shade.  And yet, you never make that conclusion, because you're  constantly, automatically, without effort, adjusting ", "mentally for the ambient light condition.  So we use brightness all the time to help us figure out is  that a piece of coal or sunlight?  But that brightness perception is constantly adjusted to ", "interpret brightness in the context we're sitting in.  And perceptual psychologists have worked on how people  calculate this.  So here's an example of a dark letter T. Again, the black T ", "would be 10 times brighter outdoors than  white paper is indoors.  And yet, you're never bothered by that.  You can read a newspaper or something else indoors or ", "outdoors with equal these, because people are calculating  the ratio of the ambient lighting--  lower inside, much brighter outside, from the sun--  and using that information to make inferences about the ", "relative brightness of a stimulus they're looking at.  And there's all kinds of examples or illusions that  show us this.  So for example, here, you detect a white tile in the ", "shade and a gray tile in brightness.  And that's how you interpret it.  But that's because you're taking already into account--  without even thinking about it for a moment--  the fact that this is in the shadow, and this is in the ", "bright light.  You're right in your interpretation.  But if we show a constant background, you could see that  those two are actually identical in brightness. ", "The same thing-- you could take a look at this cube and  this cube as part of these Rubik's cubes.  This looks orange.  This looks brown.  You're adjusting for light, as you make those ", "interpretations.  And if you make the background constant, you can see those  are identical in color and luminance.  So this shows you that we're constantly making these  interpretations.  Only these tricks of visual illusion make us realize that ", "our inferences are occasionally wrong.  But they're incredibly right almost all the time.  So here's another example of taking a local  luminance into account.  So typically, people see this as a lighter gray. ", "And this is a darker gray.  Again, they're using the contrast that surrounds it to  make that interpretation.  Because if we give it a constant background, you can  see that in an objective sense the two are identical. ", " People use edges as a very powerful source of information  to make these inferences.  And you can see that in one moment.  Because this boundary, here, is used to make judgments ", "about the relative brightness around an object.  So you just do this.  The boundary disappears, and the two things look equally  gray, one above the other. ", "Or no less spectacular, but measured example, here's two  different shades of gray.  And if you're in a light meter, objectively looking at  how much light is reflected from this, here that changes. ", "This looks almost the same as this.  But really, there's just a manipulation at the  boundaries.  Again, here's a light meter.  Here's a boundary.  So these two sides are really identical.  It's just been manipulated by the boundary. ", "And you can see that, because if you get rid of that  boundary, now you can see that these two  sides are equally bright.   Another example, again, of how we're constantly using local ", "information about brightness to make  judgments about objects.  Here, you see a picture of a woman.  Here's her forehead.  Here's her darker hair.  But in fact, that's a judgment in interpretation. ", "Because if we cover up the surrounding information, the  hair is identical to the face.   Here's some other illusions, not all about brightness.  But, again, they're just reminders that what we see is ", "constantly a calculation and an  interpretation of many factors.  So here's a fun spiral.  You can see it zooming around, going from inner tightness and  unwinding peripherally. ", "And so we can add a dot to that.  And now, we can let this travel around to the middle.   You can see it's not quite making the middle. ", "And we can try that again.  Because in fact, in this picture, every line, every  circle is a circle.  And none of them are connected, one to the other.  They just appear that way. ", "This illusion, that Richard Gregory describes, was  inspired because he saw a wall in a cafe that looked like it  had not been well assembled by the person building it.  As if they had been consuming something from the cafe as ", "they built the wall.  And bizarrely, having all kinds of lines that are not  lined up, as you'd expect in  well-constructed tiles on a wall.  But in fact, every line, here, is perfectly straight. ", "And you're interpreting the black and white edges to  confuse you about the lining up across the horizontal.  This is very striking.  Here's Rubik's cubes that, again, now they're adding one ", "more story into this, which is color.  But we use that often in every day sight, of course, to make  conclusions about things.  And here, you can see the difference between, for  example, this yellow cube and this brown cube. ", " What did I want to do?  You can see the difference between this brown cube--  sorry, let me get my illusion correct-- ", "and this darker cube, lighter brown and darker brown.  But if we cover those up, those are identical.  And they're gray.  Here's another one that shows you it's not just the color ", "itself but the spatial location.  So here's a pink circle, near the middle of this display.  And here's a more orange one.  So we're just simply going to expand those out and get it ", "bigger and bigger.  And as it's moving across your eye--  even though, objectively, it remains pink and orange, or  the things will lead you to you interpret that--  as it gets big enough, the color difference disappears to ", "your perception.  And sometimes you can get-- and this is a  very complicated one--  illusions--  I don't know if it's working for you--  that these things are actually turning, even though none of ", "them are moving at all.   OK.  And one last, simple example.  Here's yellow on gray.  Here's light gray on yellow. ", "But in fact, these X's are identical.  And you can see that when they meet here.  So again, we're constantly interpreting color, shape,  brightness, by things that are surrounding it. ", "And everything is being the product of an interpretation,  not what's out there in an objective sense of self.  And so, if we think about this Objectivist view that that  can't be right, that the limit of this objective view would ", "be that everybody sees everything differently all the  time, that would be a confusing world of  hallucinations.  We don't live there either, mostly.  So we think it's the because there's a relationship between  these, or a synthesis.  We perceive only within limits of our nervous system. ", "There's a way that we see the world.  But the way that our nervous system computes and makes  inferences about the world reflects many properties of  the world that are efficient and accurate. ", "So how do we get information into our brains to see?  So, if you were to design a system that was hopelessly  failed, the first thing you would do is think the visual  system is going to fail. ", "The first thing it does is it takes objects in the world and  it flips them upside down-- and how they're perceived in  the eye, the front of the eye, the back of the eye.  Here's the retina.  And the first place in your brain that sees something is ", "in the back of your eye.  You'd think you would put it in the front of your eye.  And information bounces back into the  deepest part of the eye.  And then it comes out and leads through the optic nerve. ", "You also know, from prior classes, that the world is  organized by left and right visual fields, instead of the  way we intuitively think about the world.  Let's take a closer look at the retina. ", "These layers of cells in your eye that begin vision.  So light comes in and bounces through the back.  And here are the rods and cones where vision begins. ", "The cones are primarily near the fovea.  The rods are primarily peripheral.   And I'm reminding you, again, as the optic nerve leaves, it ", "goes through the optic chiasm.  The fibers get sorted out by whether they're having  information from the left or right side of the world, and  then enter the cortex that way.  ", "Within the retina, within your eye, here is a graphic of the  different kinds of cells.  Here's what the cells actually look like.  ", "And here's a blow up of these remarkable cones, these larger  entities and the rods that you can see are very small, but ", "many of them.  And the big difference between rods and cones is that the  rods are receptive to information at only one  wavelength.  They're effectively color blind.  We'll come back to that. ", "But that's a good wavelength to pick up information, for  example, in low light.  The cones are selective for blue or red or green.  That's the stuff of seeing color. ", "But it doesn't operate too well, unless you have a pretty  well illuminated situation.  And the rods and cones have a striking physical ", "organization.  So here's the distribution of cones for color.  Pretty much, all of them in the fovea in the middle part  of the retina.  And then the rods are spread out peripherally. ", "So there's this big difference in where they're located.  And another big difference is that the cones, the ones that  respond to color, and that are in the middle of the fovea, ", "have an almost one-to-one relationship between the  receptors for color information and the neurons  that leave the eye with information that  will go into the brain.  The rods have a many-to-one relationship. ", "Many rods are contributing for a combined calculation of some  kind to a single neuron that leaves the brain.  So you can already see, at the very first moment of reception  from the rods and from the cons, very different kinds of ", "processes are being begun, as you begin to see.  Two ideas have been very helpful for understanding how  vision is organized in the brain--  our receptive fields and retinotopy. ", "Receptive fields are, simply, an area of external space.  It's a physical spot in space in which a  stimulus activates a neuron.  So neurons, early in vision, will respond to specific ", "locations in space when you're looking straightforward.  One neuron might cover this area.  Another neuron might cover that area and so forth.  Retinotopy refers to topographic or spatial maps of ", "visual space across a restricted  region of the brain.  And so, retinotopy keeps these receptive fields lined up.  So if the neuron is seeing this spot, this retinotopic  map, and so the next spot stays next to it. ", "And the next spot stays next to it.  So you can reconstruct what you see, based on a lot of  very local glances at the environment.  And then it travels from the eye, through the optic nerve, ", "into something called the lateral geniculate nucleus.  The nucleus is simply a collection of cells.  This is part of the thalamus.  And from there, the fibers will travel into the cortex to  begin conscious visual perception. ", "And you have one on the left and one in the right of the  lateral geniculate nucleon.  And if you look at this blown up--  this is a sample from a monkey, but the human one  looks very similar.  You can see 1, 2, 3, 4, 5, 6 layers of cells in each ", "lateral geniculate nucleus.  The first two look a little bit different.  If you look carefully, they're comprised of larger cells.  The other four are comprised of smaller cells. ", "So people describe the cell layer, made up of larger  cells, as magnocellular--  big cells.  And the other four layers as parvocellular, or small cells.  The mangocellular layers tend to have large cells. ", "A lot of their information comes from the rods, the black  and white elements, good for seeing in low vision.  They have large receptive fields.  They cover relatively large patches of the  world for each neuron. ", "Three times larger than the parvocellular ones, the  neurons fire rapidly, transiently, are color blind.  They're good in low contrast, low lighting. ", "The parvocellular ones are smaller.  They get a lot of their input from the cones.  They have smaller receptive fields.  They have slow, sustained responses.  They don't turn on and off very quickly. ", "They're wavelength sensitive.  So they can respond to color.  They operate best when things are very bright.  They're unique to primates, and there are 10  times more of them.  But again, even before you get to the cortex, there's this ", "huge organization between two modes or pathways of  perception, so you can construct the  world as you see it.  And then we've gone over before that as you  leave the nuclei -- ", "the lateral geniculate nuclei-- then the next fiber  pathway takes you into the primary visual cortex in the  back of your brain.   Now, vision is so important for primates and people, that ", "when people estimate how much of the neocortex is devoted to  different modalities, a common estimate is that about half of  the brain is primarily devoted to vision-- ", "11% to touch, 3% to audition.  These are ballpark estimates.  But it shows you how visual we are with our fellow primates.  There's many specialized areas within the ", "human visual cortex.  They estimated some years ago it was 32 distinct areas, each  performing a different tasks, lots of specialization.  And another fascinating aspect of vision is proliferation as ", "we go up into higher stations of visual processing.  So in one lateral geniculate nucleus in your brain-- and  you have two of them, one on the left and one on the  right-- you have about a million neurons. ", "They will send information that will be interpreted by  about 250 million neurons in your visual cortex.  Those will communicate about 400 million neurons in the ", "next level of processing.  And finally, there'll be something like 1.3 billion  visual cortical neurons in the brain,  overall, in a gross estimate.  It's as if to discover what you're seeing, you're having ", "larger and larger populations of neurons unpacking the  mystery of what initially came into the brain very  impoverished information, that's expanded to begin to  understand what you need to perceive a face or a word or a ", "physical movement.  So a single lateral geniculate neuron, it could be estimated,  will take 600 cortical neurons to interpret what this lateral ", "geniculate neuron has been exposed to.   Here's this area in the visual cortex, where the information  arrives first into your brain and primary visual cortex. ", " And when we think about cortex in perception, in several  modalities, one of the striking things is how it's  organized to achieve certain goals. ", "So here, we're going to switch for a moment to the parts of  your brain that move your body--  motor cortex or that have your sense of touch.  And when people stimulate these and look at what they're ", "related to.  For example, in patients undergoing treatment for  epilepsy or an animal study-- support this where you can do  much more expensive experimentation--  a very striking thing occurs, which is the number of neurons ", "devoted to different parts of your body are radically  different than your actual body size.  So this funny looking, so-called homunculus  represents how many neurons, for example, in your motor ", "cortex are devoted to different parts of your body.  So it turns out that we do incredible things with our  hands, so we devote, it seems like, a tremendous amount of ", "this area to the hand.  That's what that looks so large.   There's a reason we do handshaking and handwriting  and typing with our hands and not with our hips. ", "Because although our hips are physically larger than our  hand, we devote an incredibly small number of  neurons to do that.  So it's a trick of the brain, given a certain limited size,  to blow up its representation of what needs to be done ", "brilliantly.  And to reduce its representation of parts of the  body that it doesn't have to do too much with.  So what's blown up?  Your hand?  Things to do with your face, so that you can speak? ", "Your tongue, because that has to accomplish a lot, in terms  of speech, in terms of eating.  And things like your toes and ankle are gypped of  representation, because you don't do that much that's  brilliance. ", "There's a very clever strategy, by the brain, to  devote the amount of neural resources to make that part of  your body accomplish either very complicated things or  very simple things. ", "And if people on the outside looked like this--  this is what they would look like.  Giant hands, giant head, and a very shriveled up trunk. ", "So that's not what we look like, but that's the way our  brain represents us, our bodies, so that we could have  fantastically complicated control of our hands and ", "things having to do with speech around our mouth.  It's different for different modalities.  For hearing, things are organized  by frequency, tonotopy. ", "For vision, things are organized in two ways.  Spatial relations are maintained.  They have to be, so you know, as different neurons saw  different receptive fields, how's that all kept up? ", "Here's a kind of a rough experiment, where a monkey  saw-- before it was, as they politely say, sacrificed--  a display like this.  This is the brain of the monkey, flattened out. ", "And you can see it has this representation, like this.  Now you could say, well, that's how we see.  We line everything up.  But this is not the part of our brain that we associate  with conscious perception at all.  But if you didn't keep the spatial information aligned ", "correctly, you could never interpret things, in the end,  correctly that go together, like different parts of a hand  or different letters within a word.  In humans, it's also in the back of the brain. ", "It also keeps spatial information.  But what do humans do, and other primates?  They greatly expand the central part of vision.  So here's the central part of vision, the so-called fovea, ", "which is a small part of the visual display.  Here is everything else that's in peripheral vision.  So this is dark green, dark purple.  But when it comes to the representation in the visual  cortex, this small area of what we see ", "becomes pretty large.  It's way overrepresented.  So just as the motor cortex over represents the hand, the  visual cortex over represents the cone ", "foveal part of the brain.  So they can do much more examination, much more  computation on that small foveated area.  So that's why it matters, tremendously, where people put ", "their eyes.  Where they put their eyes is where neuromachinery is  dedicated to do its most brilliant analysis.  And peripheral regions, which are large, in vision, get  relatively small representation. ", "All we do, in the periphery, is notice if something is  whizzing at our head.  And for that, we don't need to be that sophisticated.  ", "Now, what do neurons communicate in  primary visual cortex?  Well, this is the, sort of, seminal Nobel Prize-winning  work from Hubel and Wiesel, at Harvard, who discovered that  what neurons respond to in primary visual cortex is the ", "orientation of a piece of something like this.  So here's a neuron that loves a little bit of a stimulus.  You notice that disorientation?  Here's each of these lines as of the neuron firing. ", "It generalizes if a bar is close in orientation, it will  still like it, somewhat.  And if the bar moves away from its preferred orientation, it  won't respond and all. ", "So these neurons are coding something about local  orientation of little lines.  Those little lines will be assembled later on in the  brain to represent a letter, a word, a book, a face, a ", "chair, and so on.  But these neurons simply know they're seeing a line of this  angle or that angle that will be assembled later on for an  entire conscious percept.  And then that information will go from primary visual cortex, ", "in two pathways, that have two quite different properties,  but turn out to be the super-information processing  pathways of your brain and my brain.  So where do we first learn about this fundamental ", "organization of how we see into two giant highways of  information processing?  Well, the first studies where we should study's in monkeys.  And I'll show you work in humans as well.  And the major discovery was this, that in our brains, ", "there's a so-called where pathway that goes up in the  brain into the parietal cortex and a what pathway that goes  into temporal lobe or lower cortex.  And if you make lesions in these different regions, one ", "form of vision is spared and one is impaired  in selective ways.  So how did they discover this?  So again, here's the big picture.  Early visual processing information a what pathway to ", "know what objects are a face, a word, a chair.  Or where things are, that you might run to,  grab, or jump over.  So here was the experiment. ", "It was pretty simple.  Here were two food wells.  And monkeys that were eager to get food would get rewarded,  if they would pick the correct food well.  They didn't see where the food was that was hidden, but they ", "would get to pick one or the other.  And in one task they would have to pick which food well  is closer to the stimulus.  That's a where task.  Where is this located? ", "That's the piece of information that will tell me  where to get my food.  And you can see, here's the performance of the animals,  their errors.  So it's good to be low.  They are eager to get their food.  But if the animal had a surgical lesion in the ", "parietal cortex, the where pathway, they were very poor  at performing this task.  As if they couldn't appreciate the spatial relation between  where the cylinder was located and the food well. ", "On the other hand, monkeys who had lesions made in the  temporal cortex were poor when they had to make this task.  They would see two different objects.  And they were taught that one always meant that's ", "where the food is.  Let's pretend it's the cylinder.  So in order to know the correct answer, they would  have to say, OK, is it next to this object or this object?  That's a what discrimination.  Is it a cylinder or a cube? ", "And now, the temporal lobe lesions were the ones that  affected performance.  So it's as if one part of the brain tells you where things  are, in vision--  parietal lobe.  And one tells you what they are-- ", "the temporal lobe.  So that's lesion studies in monkeys.  But there's very interesting things about when we look at  what cells communicate in these two pathways that makes ", "sense in what we understand to be the goals of these systems.  So for example, in the where pathway, in the parietal  cortex, many neurons pick up information from the fovea,  the central part of vision. ", "But the majority are sensitive to stimuli in the periphery.  So if you imagine, a good thing to know if you're  running, is in the periphery.  Are there things coming at your head, things to avoid? ", "You might grab something here, if you need to grab it there.  You would want to have a lot of peripheral information for  spatial things around you.  And in fact, if a monkey was looking at this spot, which is ", "away, entirely, from the stimulus, it would respond to  both a large and small stimulus in the periphery  quite strongly.  So these neurons are responding to a pretty broad  range of space where things could happen. ", "Neurons in the what pathway have almost their entire  responsiveness in the fovea.  Because you know what something is, if you're  reading a word and looking at it.  If you're looking at a face, they're figuring out ", "who the person is.  So it's only responding, these kinds of neurons, to  information in the center.  But it has some very interesting properties, even  at the level of singular neurons. ", "So here's a depiction of an  experiment, now, from a monkey.  You're looking at a single neuron or  small group of neurons.  And you present something like a hand.  And you can see that those neurons really like the hand. ", "Now, don't forget, for a primary visual cortex, it just  sees lines.  It doesn't think about the entire objects.  But by the time you get to the higher levels of vision, it's  encoding an entire object.  And then, you can do experiments that basically ", "interrogate, what does this neuron discover in the world?  What is it interested in?  So if you turn the hand over, it's still very interested.  You show it a less detailed hand. ", "It's still very interested.  Maybe a bit less, but it's still very interested.  A hand, this way, where all the spatial relations have  changed still recognizes a hand.  It still recognizes a hand with a bit less enthusiasm. ", "But now, a mitten, which kind of looks like a hand.  That barely counts as a hand at all.  That neuron has lost interest in coding that as a hand.  And you're showed other things that have some ", "similarity in shape.  Because these all have four elements in  them, like four fingers.  This neuron's not responding at all.  It's not that it has four things or lines.  It's a hand. ", "And then, you could even worry about things.  Well, maybe this, because it's from a person.  But if they see the face, this neuron doesn't care.  So it's nothing about the gross shape  or that it's a person.  This neuron is specialized, foveally, for spotting a hand. ", "And not only that, these kinds of neurons already have the  properties we described that are big problems for vision.  So here's a neuron that's responding to an upright face.  ", "And then it's responding if the face is turned on its side  pretty well.  The face is turned upside down, a little less well, but  it's still responding to a face.  If the face is distant, it's still responding. ", "If the face changes expression, it's still  responding.  And if we put a green filter on it, so you have a Martian  person, it's still responding.  So all kinds of ways that a face changes in the world, ", "this neuron is still firing.  And interestingly, this neuron was firing for one of the  experimenters.  But it wasn't too interested in the other experimenter.  So it's a neuron that's generalizing all the different ", "views that you might have of a person.  But it's responding to one neuron versus another.  And there's been a lot of fun in monkey  neurophysiology stuff.  There's a so-called Jennifer Aniston cell, where ", "researchers have discovered neurons, in monkeys, that seem  to respond to Jennifer Aniston, for whatever reason.  And other specific famous people.  Although, not particularly meaningful to the primates. ", "And of course, in human brain imaging, you can do tasks that  emphasize what an object is or where it is.  And corresponding to the monkey work, we see activation  in this where pathway towards the parietal cortex. ", "If you have to make a spatial judgment,  where things are located.  Or this lower temporal lobe, what pathway.  You have to make a judgment about what object you're  looking at.  So that lines up in intact humans very much, with what we ", "see in primates with invasive studies.  So we're going to end today by discussing two kinds of  lesions in humans and some spectacular impairments in the ", "what or where pathways.  So let me get you ready for these films for a moment.  So one film you're going to see is the patient who has a  great injury to the parts of the brain in the parietal ", "cortex that serve our where system.  So this is so-called Balint's syndrome, in the Neurology.  These are bilateral injuries.  That means on both sides of the brain, in  the parietal region. ", "They're pretty good at knowing what something is, because the  temporal lobe pathway, the what pathway, is intact.  But they have problems in knowing where things are,  reaching for things, where to put their gaze, estimating  distances, and navigation, in general. ", "So I'll show you an example of a patient like this.  And then the converse, a patient who has big problems  in the what system.  And we'll start with that. ", "And I'll tell you just one last bit of information to  think about.  That the what and where distinction, sometimes, is not  as complete in every way as you might imagine.  And so, sometimes people have said, really, the where system ", "is better described as not where things are, but the  information you need for physical action in the world,  which is very close to where.  But it's a little bit different.  And let me give you the kind of what type of information ", "that the where system still seems to have in it.  So here's a patient with extensive damage in the what  system, in the lower parts of the brain and  posteriorly for vision. ", "Terrible perception of shapes and orientation of shapes.  Very bad what ability.  And she was asked, then, to reach with an envelope to a  slot at different orientations. ", "And what's striking is even though if her hand was a  distance away-- so if she would have to think, what is  the angle I would need to approach it with--  she was terrible.  When she actually moved her hand towards the slot, she was ", "surprisingly good.  So let me show you the feeling.  So if this patient would have to put her hand so that this  letter would fit into this slot-- ", "she was very poor at spatial relations and knowing what  things were--  she couldn't line them up at all.  But now, they said, well, please put your hand out and ", "just stick it in.  And as her hand approaches it, she changes orientations and  is correct.  Because in order to do things, like to grab something--  think about it.  When you grab something, like a pencil or a cup, you need a ", "little bit of knowledge to know what it is.  You wouldn't grab things similarly, whether they could  spill easily or be pointy or painful.  A little bit what information helps you guide even something ", "like a simple reaching, which is a special task.  So it's not so much, maybe, that the where  system is only where.  But it has just enough information to guide actions ", "in the world, which has a tiny bit of information about what  things are that you're jumping over.  If you're going to run into something, is it likely to be "], "vid_duration": [12.079, 10.05, 13.321, 10.789, 10.021, 11.77, 12.169, 11.851, 10.26, 11.26, 11.42, 10.19, 11.2, 10.22, 12.21, 10.74, 11.88, 11.46, 11.129, 10.671, 11.42, 11.3, 10.669, 10.091, 12.09, 12.9, 12.74, 11.21, 11.81, 11.27, 12.29, 10.63, 12.81, 10.2, 11.23, 11.29, 11.03, 10.93, 10.14, 10.71, 10.74, 12.57, 10.09, 10.18, 10.81, 10.16, 10.96, 10.26, 12.44, 10.73, 11.75, 10.72, 11.93, 10.61, 13.7, 12.11, 11.2, 12.63, 10.46, 10.28, 12.185, 10.595, 11.78, 11.06, 13.07, 12.71, 10.35, 11.77, 10.62, 12.07, 12.14, 11.97, 11.88, 12.77, 11.11, 13.05, 11.07, 12.89, 13.39, 13.0, 13.15, 10.76, 11.54, 14.07, 12.66, 12.76, 11.48, 11.04, 12.67, 11.939, 11.571, 11.19, 11.77, 10.07, 10.91, 10.51, 12.4, 10.27, 11.82, 11.78, 10.32, 11.41, 10.53, 12.57, 12.41, 11.56, 11.91, 12.31, 10.65, 10.795, 12.245, 12.34, 12.25, 15.04, 11.91, 13.08, 10.51, 11.0, 11.55, 10.41, 10.89, 12.64, 10.05, 13.08, 12.53, 12.17, 10.68, 11.15, 13.15, 10.14, 10.285, 11.485, 11.07, 11.58, 10.61, 10.12, 10.09, 12.83, 12.16, 10.51, 11.21, 10.64, 10.05, 11.68, 10.28, 10.02, 13.36, 10.59, 11.47, 12.32, 11.49, 12.23, 10.59, 10.01, 13.55, 11.07, 10.13, 10.09, 12.52, 11.45, 12.04, 12.76, 10.77, 10.32, 12.51, 11.18, 11.4, 10.99, 10.4, 10.69, 10.16, 10.5, 11.47, 11.44, 10.659, 12.801, 11.88, 10.0, 10.81, 11.7, 11.03, 12.02, 10.25, 10.12, 13.21, 11.36, 11.43, 10.69, 11.19, 12.67, 11.85, 11.35, 12.84, 12.6, 11.47, 11.83, 11.31, 10.88, 11.17, 13.14, 10.3, 13.21, 11.76, 10.77, 11.05, 12.39, 10.79, 10.05, 6.42], "stet": [[0, 12.079], [12.079, 22.129], [22.129, 35.45], [35.45, 46.239000000000004], [46.239000000000004, 56.260000000000005], [56.260000000000005, 68.03], [68.03, 80.199], [80.199, 92.05], [92.05, 102.31], [102.31, 113.57000000000001], [113.57000000000001, 124.99000000000001], [124.99000000000001, 135.18], [135.18, 146.38], [146.38, 156.6], [156.6, 168.81], [168.81, 179.55], [179.55, 191.43], [191.43, 202.89000000000001], [202.89000000000001, 214.019], [214.019, 224.69], [224.69, 236.10999999999999], [236.10999999999999, 247.41], [247.41, 258.079], [258.079, 268.17], [268.17, 280.26], [280.26, 293.15999999999997], [293.15999999999997, 305.9], [305.9, 317.10999999999996], [317.10999999999996, 328.91999999999996], [328.91999999999996, 340.18999999999994], [340.18999999999994, 352.47999999999996], [352.47999999999996, 363.10999999999996], [363.10999999999996, 375.91999999999996], [375.91999999999996, 386.11999999999995], [386.11999999999995, 397.34999999999997], [397.34999999999997, 408.64], [408.64, 419.66999999999996], [419.66999999999996, 430.59999999999997], [430.59999999999997, 440.73999999999995], [440.73999999999995, 451.44999999999993], [451.44999999999993, 462.18999999999994], [462.18999999999994, 474.75999999999993], [474.75999999999993, 484.8499999999999], [484.8499999999999, 495.0299999999999], [495.0299999999999, 505.8399999999999], [505.8399999999999, 515.9999999999999], [515.9999999999999, 526.9599999999999], [526.9599999999999, 537.2199999999999], [537.2199999999999, 549.66], [549.66, 560.39], [560.39, 572.14], [572.14, 582.86], [582.86, 594.79], [594.79, 605.4], [605.4, 619.1], [619.1, 631.21], [631.21, 642.4100000000001], [642.4100000000001, 655.0400000000001], [655.0400000000001, 665.5000000000001], [665.5000000000001, 675.7800000000001], [675.7800000000001, 687.965], [687.965, 698.5600000000001], [698.5600000000001, 710.34], [710.34, 721.4], [721.4, 734.47], [734.47, 747.1800000000001], [747.1800000000001, 757.5300000000001], [757.5300000000001, 769.3000000000001], [769.3000000000001, 779.9200000000001], [779.9200000000001, 791.9900000000001], [791.9900000000001, 804.1300000000001], [804.1300000000001, 816.1000000000001], [816.1000000000001, 827.9800000000001], [827.9800000000001, 840.7500000000001], [840.7500000000001, 851.8600000000001], [851.8600000000001, 864.9100000000001], [864.9100000000001, 875.9800000000001], [875.9800000000001, 888.8700000000001], [888.8700000000001, 902.2600000000001], [902.2600000000001, 915.2600000000001], [915.2600000000001, 928.4100000000001], [928.4100000000001, 939.1700000000001], [939.1700000000001, 950.71], [950.71, 964.7800000000001], [964.7800000000001, 977.44], [977.44, 990.2], [990.2, 1001.6800000000001], [1001.6800000000001, 1012.72], [1012.72, 1025.39], [1025.39, 1037.3290000000002], [1037.3290000000002, 1048.9], [1048.9, 1060.0900000000001], [1060.0900000000001, 1071.8600000000001], [1071.8600000000001, 1081.93], [1081.93, 1092.8400000000001], [1092.8400000000001, 1103.3500000000001], [1103.3500000000001, 1115.7500000000002], [1115.7500000000002, 1126.0200000000002], [1126.0200000000002, 1137.8400000000001], [1137.8400000000001, 1149.6200000000001], [1149.6200000000001, 1159.94], [1159.94, 1171.3500000000001], [1171.3500000000001, 1181.88], [1181.88, 1194.45], [1194.45, 1206.8600000000001], [1206.8600000000001, 1218.42], [1218.42, 1230.3300000000002], [1230.3300000000002, 1242.64], [1242.64, 1253.2900000000002], [1253.2900000000002, 1264.0850000000003], [1264.0850000000003, 1276.3300000000002], [1276.3300000000002, 1288.67], [1288.67, 1300.92], [1300.92, 1315.96], [1315.96, 1327.8700000000001], [1327.8700000000001, 1340.95], [1340.95, 1351.46], [1351.46, 1362.46], [1362.46, 1374.01], [1374.01, 1384.42], [1384.42, 1395.3100000000002], [1395.3100000000002, 1407.9500000000003], [1407.9500000000003, 1418.0000000000002], [1418.0000000000002, 1431.0800000000002], [1431.0800000000002, 1443.6100000000001], [1443.6100000000001, 1455.7800000000002], [1455.7800000000002, 1466.4600000000003], [1466.4600000000003, 1477.6100000000004], [1477.6100000000004, 1490.7600000000004], [1490.7600000000004, 1500.9000000000005], [1500.9000000000005, 1511.1850000000006], [1511.1850000000006, 1522.6700000000005], [1522.6700000000005, 1533.7400000000005], [1533.7400000000005, 1545.3200000000004], [1545.3200000000004, 1555.9300000000003], [1555.9300000000003, 1566.0500000000002], [1566.0500000000002, 1576.14], [1576.14, 1588.97], [1588.97, 1601.13], [1601.13, 1611.64], [1611.64, 1622.8500000000001], [1622.8500000000001, 1633.4900000000002], [1633.4900000000002, 1643.5400000000002], [1643.5400000000002, 1655.2200000000003], [1655.2200000000003, 1665.5000000000002], [1665.5000000000002, 1675.5200000000002], [1675.5200000000002, 1688.88], [1688.88, 1699.47], [1699.47, 1710.94], [1710.94, 1723.26], [1723.26, 1734.75], [1734.75, 1746.98], [1746.98, 1757.57], [1757.57, 1767.58], [1767.58, 1781.1299999999999], [1781.1299999999999, 1792.1999999999998], [1792.1999999999998, 1802.33], [1802.33, 1812.4199999999998], [1812.4199999999998, 1824.9399999999998], [1824.9399999999998, 1836.3899999999999], [1836.3899999999999, 1848.4299999999998], [1848.4299999999998, 1861.1899999999998], [1861.1899999999998, 1871.9599999999998], [1871.9599999999998, 1882.2799999999997], [1882.2799999999997, 1894.7899999999997], [1894.7899999999997, 1905.9699999999998], [1905.9699999999998, 1917.37], [1917.37, 1928.36], [1928.36, 1938.76], [1938.76, 1949.45], [1949.45, 1959.6100000000001], [1959.6100000000001, 1970.1100000000001], [1970.1100000000001, 1981.5800000000002], [1981.5800000000002, 1993.0200000000002], [1993.0200000000002, 2003.6790000000003], [2003.6790000000003, 2016.4800000000002], [2016.4800000000002, 2028.3600000000004], [2028.3600000000004, 2038.3600000000004], [2038.3600000000004, 2049.1700000000005], [2049.1700000000005, 2060.8700000000003], [2060.8700000000003, 2071.9000000000005], [2071.9000000000005, 2083.9200000000005], [2083.9200000000005, 2094.1700000000005], [2094.1700000000005, 2104.2900000000004], [2104.2900000000004, 2117.5000000000005], [2117.5000000000005, 2128.8600000000006], [2128.8600000000006, 2140.2900000000004], [2140.2900000000004, 2150.9800000000005], [2150.9800000000005, 2162.1700000000005], [2162.1700000000005, 2174.8400000000006], [2174.8400000000006, 2186.6900000000005], [2186.6900000000005, 2198.0400000000004], [2198.0400000000004, 2210.8800000000006], [2210.8800000000006, 2223.4800000000005], [2223.4800000000005, 2234.9500000000003], [2234.9500000000003, 2246.78], [2246.78, 2258.09], [2258.09, 2268.9700000000003], [2268.9700000000003, 2280.1400000000003], [2280.1400000000003, 2293.28], [2293.28, 2303.5800000000004], [2303.5800000000004, 2316.7900000000004], [2316.7900000000004, 2328.5500000000006], [2328.5500000000006, 2339.3200000000006], [2339.3200000000006, 2350.370000000001], [2350.370000000001, 2362.7600000000007], [2362.7600000000007, 2373.5500000000006], [2373.5500000000006, 2383.600000000001], [2383.600000000001, 2390.020000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [209, 564, 1050, 1393, 1834, 2216, 2390]}
