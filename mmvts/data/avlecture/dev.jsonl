{"example_id": "mit159@@MITRES18-009F15_3_300k", "text": ["PROFESSOR: OK.  So we've moved on into Chapter 3.  Chapter 1 and 2 were about equations we could solve,  first order equations, chapter one; ", "second order equations in chapter 2, often  linear, constant coefficient sometimes.  Now we take any equation.  And I'll start with first order. ", "First derivative is some function and not  a linear function, so I don't expect a formula. ", "A solution will exist.  But I won't have a formula for the solution.  But I can make a picture of the solution.  You see what's happening as time goes on. ", "And so that's today's lecture, is a picture.  So this function, whatever it is, gives the slope of y. ", "That's the slope.  And it will be the slope of the arrows  that I will draw in this picture.  So here's a picture that started, y, t. ", "And the slope of the arrows is f.  And here is my example.  Well, you will see.  I chose a constant coefficient linear equation. ", "Because I could find a solution.  So 2 minus y, I know from that minus sign  that I'm going to have exponential decay ", "in the null solution.  And then y equal to 2 is a very special particular solution,  a constant.  And in my picture, y equal to 2, it jumps out. ", "Because when y is 2, when y is 2 the slope is 0.  So all my arrows on the y equal to 2 line, have slope 0. ", "So that's a very special line.  And since the solution follows the arrows  that's the whole point.  The solution follows the arrows.  Because the arrows tell the slope. ", "So if I'm on that line, the solution  just follows those arrows, and stays on the line.  y equal to 2 is a fixed point, fixed point ", "of the solution, a fixed point for the equation.  And the question is, if I don't start at y equal to 2, ", "do I move toward 2 or away from it?  OK.  So I can see from the formula what the answer is going to be. ", "If I start with some other value, some other value of c  not 0, then there will be a null solution part.  But as t gets large that goes to 0. ", "So I move toward 2.  Now let's see that in the picture.  So let me-- I'm drawing the arrows first.  So this is all time starting at if y is 0, then if y is 0 ", "then dy dt is 2.  So I draw arrows with slope 2, along the y equals 0 line.  This is the y equals 0 line.  All my arrows have slope 2. ", " Now what else?  So that's a few arrows that show what will-- so the solution  if it starts there, will start in the direction of that arrow. ", "But then I have to see what the other arrows are  for other values of y.  Because right away the solution y will change. ", "And the slope will change.  And that's it needs more arrows.  Well, actually it needs way more arrows  than I can possibly draw.  Let me draw another line of arrows ", "when y is 1, along that line, along the line y equal 1.  When y is 1, 2 minus 1 is 1.  The slope is 1. ", "f is 1.  And my arrows have slope 1.  So all along here, the arrows go up.  Those went up steeply with slope 2. ", "Now the arrows will go up.  So I'll have arrows that are going a 45-degree angle, slope  1.  ", "Do you see?  I hope you begin to see the picture here.  The solution might start there.  It would start with that slope.  But it will curve down. ", "Because the arrows are not so steep.  As I go upward, the arrows are getting flat.  And so the curve that follows the arrows ", "has to flatten out, flatten out, flatten out.  The arrows are still, at that point  the arrows are still slope 1.  But it's flattening out.  And it's never going to cross this line. ", "And it will run closer and closer to that line.  And wherever it starts, if it starts  at time t equals to 1 there, it'll do the same thing. ", "And it will stay just below the other one.  Do you see what the pictures are looking like?  If it starts at different times, so these are different times. ", "These are different starts.  Yeah, really we're used to, at t equals 0,  we're used to giving y of 0. ", "So this is starting at 0.  This is starting at 2.  Starting at 1 would be a higher start.  What about starting at 4?  Suppose y of 0 is 4. ", "That point is t equals 0, y equal 4.  So that point is y of 0 equal 4.  What's the graph of the solution with that start? ", "Actually, I could figure out what  the solution would be if y of 0 was 4, I'd have 2 plus 2  e to the minus t. ", "At t equals 0, that's 4.  And it fits.  It solves the equation.  And it's going to be its graph. ", "I should be able learn that from the arrows.  So along this line of y equal 4, all the arrows when y is 4, ", "the slope is minus 2.  So these arrows from these points,  go down with slope minus 2. ", "But the solution starts down.  So it starts like that.  But then it has to follow the new arrows.  And the new arrows are not so steep. ", "So the new arrows are I have slope minus 1.  I hope my picture is showing the steeper slope 2 ", "along this line, and the flatter slope 1,  or rather minus 1 downwards, along this line.  So it just follows along here. ", "Well of course it's just a mirror image of that one.  It's a mirror image of that one.  I'm trying to show the graph of all solutions ", "from all starts, the whole plane.  Actually I could go, t could go to minus infinity.  And y could go all the way from minus infinity up,  all the way up. ", "I could fill the whole board here with arrows, and then  with solutions.  And the solutions would follow the arrows, the arrows changing  slope and actually in this case, all solutions wherever ", "you started, would approach 2.  And that's what the formula says.  But we get that information from the arrows with no formula. ", "Let me show you a next example.  And here's our next example.  The logistic equation, it's not linear.  So it's going to be more interesting.  And do you remember the solution? ", "You remember maybe the trick with the logistic equation  was 1 over the solution, gave a linear equation and expression ", "like that.  OK.  Time to draw arrows.  OK.  When y is 0-- so here's y-- when y is 0, the slope is 0. ", "So I have a whole line of flat.  I have a flat horizontal line.  That's the solution, y equals 0 fixed point. ", "Also we have another fixed point.  When y is 1, 1 minus 1 is 0.  Slope is 0.  Slope stays 0.  The arrows all have zero slope along the line y equal 1. ", "So there is another solution, which  doesn't do anything exciting.  It just stays at 1.  y equal 1 is another fixed point, steady state, ", "whatever words we want to use.  But again, the real picture is what about other starts.  What about a start at 1/2? ", "Well if it starts at-- if y is 1/2 half at the starting time,  what is the slope?  1/2 minus 1/4 is 1/4. ", "So the slope is upwards, but not very steep.  The slope along the-- and it doesn't  depend on t in these examples. ", "So that slope is the same as long as y is 1/2,  doesn't matter what the time is.  y equals 1/2 gives me a 1/2 minus 1/4, which is a 1/4. ", "It gives me that slope.  What about the slope 1/4?  So 1/4, I have 1/4 minus 1/16.  I think that's 3/16. ", "So it's beginning to climb upward.  So it's upwards again.  But 3/16 is a little-- I don't know ", "if I'm going to get the picture too brilliantly.  The slope, as soon it-- if it just starts a little above 0, ", "what happens to the solution that  starts a little bit above 0?  It climbs.  Because if y is above 0, say if it starts between 0 and 1, ", "if y is between 0 and 1, then y is bigger than y squared.  And the slope is positive.  And it goes up.  So do you see what it's doing? ", "The slope will just, if it starts a little bit above,  it'll have a small slope.  But that slope will gradually increase.  But then actually at this point, the slope ", "is 3/4 minus whatever it is.  It slows down, still going upwards.  y is still bigger than y squared.  ", "You recognize what the curve is going to look like.  So there is an S curve.  It's an S curve.  ", "Which we saw for the logistic equation, and here  we have a formula for it.  Well, the whole point of today's video  was we don't need a formula. ", "So you don't need that.  The arrows will tell you that it starts up slowly.  It gets only-- that's the biggest slope it gets. ", "And then it starts down.  The slope goes down again.  But it's still a positive slope.  Still climbing, climbing, climbing, and approaching 1. ", "Now that's sort of a sandwich in the picture.  But it could start with a negative.  So what happens if it starts at y equal minus 1? ", "The slope, if y is minus 1, we have minus 1,  minus 1, a slope of minus 2.  That's a steeper serious downward slope. ", "So the solution that starts here has-- that's tangent.  You see that it's tangent to the arrow,  because it has the same slope as the arrow. ", "And it comes down.  But as it goes down, the slopes are getting steeper.  Whoops, not flatter, but steeper.  ", "For example, if y is minus 2, I have minus 2, minus 4  is minus 6.  So as soon as it gets down to minus 2,  the slope has jumped way down to minus 6. ", "So here is the-- it falls right off.  It's a drop-off curve, a drop-off curve.  It falls right off actually to infinity.  It never makes it out to-- it falls down ", "to y equal minus infinity in a fixed time, in a definite time.  And so here's a whole region of curves going down ", "to minus infinity.  Here is a whole region.  What happens in this region?  Suppose y starts at plus 2? ", "Well, I have 2 minus 4.  So the slope is negative.  The slope is negative up here.  Yeah.  And this is the big picture.  The slope, the arrows are positive below this line. ", "They're upward.  They were downward here.  They're slowly upward in this sandwich.  And then up above, they're downward again. ", "So if slopes are coming down, and they drop into actually ", "it's a symmetric picture.  Really-- no reason not to go backwards in time.  Where are these coming from?  They're all coming from curves. ", "The whole plane is full of curves.  And these start at plus infinity.  They drop into 2.  These start below 0, and they drop off to minus infinity. ", "And then the real interest in studying population was these.  Can you do one more example?  Let me take a third example that has a t in the function. ", "So the arrows won't be the same along the whole line.  In fact, the arrows will be the same.  So if I have 1 plus t minus y, that's the f, equal a constant. ", " Then that's a curve-- well, it's actually a straight line.  It's actually a 45-degree line in this plane. ", "And along that line the f, this is the f, the f of t and y,  the arrow slope. ", "The arrows slopes are the same along that line.  That line is called an isocline.  This is called an I-S-O, meaning the same, cline, meaning slope. ", " So that's an isocline.  Here's an isocline.  It's a 45-degree line.  That's the 45-degree line, 1 plus t minus y equal 1. ", "Let me draw the 45-degree line 1 plus t minus y equals 0. ", "So it's a little bit higher.  OK.   Now arrows, and then put in the curves, the solution ", "curves that match the arrows.  So the arrows have this slope along that line.  Along this line, 1 plus t minus y, they have slope 0. ", "Oh, interesting.  At every point on the line the slope is 0.   Because this is the slope of the arrows.  At every point on this line, the slope ", "is 1, also very interesting.  Because that's right along the line.  So here we have a solution line.  That must be a solution line. ", "That's the line where y is t.  That's a very big 45-degree important line.  Because if y equals t, if y equals t ", "then dy dt should be 1.  And it is 1 for y equals t.  So that's a solution line with that solution.  Now what about a line with 1 plus t minus y ", "equal minus 1, a line?  If 1 plus t minus y is minus 1, if f is minus 1,  the slope is negative. ", "So what does that mean?  If 1 plus t minus y is minus 1, the slope is negative.  So at points on this line, the slope is going downwards. ", "Oh, interesting.  I wasn't quite expecting that.  Let me just see if I got a suitable picture.  Why is it not right? ", "If 1 plus t minus y is-- oh, I'm sorry.  This is the line, y equal 1 plus t. ", "I think what I'm expecting to see  is I'm expecting to see it from the formula  too that as time goes on, this part goes to 0, ", "and y goes to t.  I believe that all the solutions will  approach this y equal to t.  I think their slopes, their slopes ", "here-- darn, that's not right.  Their slopes should be coming upwards.  Yeah, let me-- I can figure that out. ", "If t is let's say 1, and y is 0.  OK.  If t is 1, and y is 0, I have a slope of 2.  Good.  OK.  There's a point t equal to 1. ", "Here is 0, 0.  Here's the point t equal to 1, y equals 0.  The slope came out to be 2.  It went up that way.  So along that line, the slopes are going up. ", " Along this line, the slopes are right on the line.  On this line the slopes are flat,  and the curve is moving toward the line. ", "I'll just draw the beautiful picture now of the solution.  So the solutions look like this.  They are-- this is the big line. ", "You've got to keep your eye on that line.  Because that's the steady state line that all solutions  are approaching.  So if you have the idea of arrows to show the slope, ", "fitting solution curves through tangent to the arrows,  and sometimes having a formula to confirm  that you did it right, you get a picture like this. ", "So that's the idea of first order equations, which  are graphed in the y-t plane.  And the arrows tell you the derivative. ", "GILBERT STRANG: OK.  This is the second video for Chapter 3.  And it's going to be pictures again.  But it's pictures for a second order equation. ", "And I'll make them-- these will be nice.  We'll know formulas here.  These will be constant coefficient,  linear second order equations.  And we know that the solution-- there ", "are two special solutions, e to the s1 t  and e to the s2t, two null solutions, ", "and any combination is a null solution.  So we're talking about null equations,  0 on the right-hand side.  And we just want to draw that picture that ", "goes with solutions like that.  So here is the magic word, phase plane, phase plane.  We're going to draw the pictures in a plane. ", "Because that's what a blackboard is.  And the axes we'll choose will be y and y prime, not t. ", "You'll see how t, time, comes into the picture.  But we have the two axes will be y and y prime.  So I had to figure out what y prime was.  It just brings down an s1 from that term, ", "and brings down an s2 from that term.  And now here's the example.  Here is the first example.  So I took this particular equation. ", "Notice that the damping term is negative.  I have negative damping.  This will be unstable.  Solutions will go out to infinity. ", "And I can find those solutions.  Because you know that I look for e to the st.  I always look for e to the st. I plug in e to the st.  I get an s squared from two derivatives, ", "minus 3s from one derivative, plus 2 equaling 0.  I factor that, and I find the 2s1 is 1, and s2 is 2. ", "And now I'm ready for the phase plane picture.  OK.  Phase plane picture, so here are my solutions.  s is 1 or 2. ", "Then the derivative has a 1 or a 2.  And here's my plane.  Here's my plane.  And I want to draw on that the solutions. ", "These solutions, I actually have formulas.  I just want to draw them.  So I'm plotting.  One example would be that c1 be 1, and let c2 be 0. ", "So that's gone.  c1 is 1.  I just have that picture.  What kind of a picture do I have in the phase  plane, in the y, y prime plane, when that's y ", "and that's y prime?  Well, those are equal.  So y equals y prime for that solution.  y equals y prime along the 45-degree line. ", "It's just like y equal x.  y prime is y.  And what's happening on this 45-degree line?  The solution is this solution, is going straight out the line. ", "As t increases, y and y prime both increase.  I go out.  This is t going to infinity.  ", "And what about t going to minus infinity?  Because we got the whole picture here.  When t goes to minus infinity that goes to 0, that goes to 0.  Here is the point where the universe began. ", "The Big Bang is right there at t equal minus infinity.  And as t increases, this point, y, y prime, ", "is traveling along that 45-degree line.  Because y equals y prime, and out there.  And what about the rest of the line? ", "Well, if c1 was negative, if c1 was negative  I'd have a minus there, and a minus there.  I would just have minuses.  And I'd be going out that line. ", "Well, that's one line in my whole plane, but not all.  Now let me take as a second line c1 equals 0. ", "So nothing from e to the t, and let me take y as e to the 2t,  and y prime then would be 2e to the 2t. ", "OK.  What's happening in the phase plane for this solution,  now looking at this one?  Well in this solution, in this case, y prime is 2 times y. ", "y prime is 2 times y.  So I'm staying on the line y prime,  where y prime is 2 times y.  It's a steeper line, steeper line. ", " So that was the case, this was the line where c2 was 0.  There was no e to the 2t on that first line that we drew. ", "In the second line that we drew, c1 is 0.  There's no e to the t.  Everything is in e to the 2t.  So now c1 is 0 on this line. ", "OK.  And we just go out it.  As t increases, y prime increases faster.  Because of the factor 2.  So it goes up steeply. ", "And it goes this way.   When c2 is negative, if I took a minus and a minus, ", "I would just go down the other way on the same line.  And this is still the Big Bang, t equal minus infinity,  where everything starts. ", "OK.  So that is two lines, the two special lines  in the phase plane.  But now I have to draw all the other curves. ", "And they will be curves.  And where will they come from?  They will come from a combination.  So now I'm ready for that one.  Let me take the case c1 equal 1, c2 equal 1. ", "Yeah, why not? c1 equal 1.  So I can erase c1.   c2 equal 1, I can erase c2. ", "And now I have another solution, y and y prime.  And I want to put it in the phase plane.  So at every value of t, at every value of t that's a point. ", "That's a value of y.  This is a value of y prime.  I plot the points y and y prime, and I look at the picture.  And again as t changes, as t changes ", "I'll travel along the solution curve in the phase plane.  I'll travel along.  As t changes, y will grow, y prime will grow.  I'll head out here. ", "But I won't be on that straight line or that straight line.  Because those were the cases when I had only one  of the two solutions.  These were the special solutions. ", "And now I have a combination.  So what happens as t goes to infinity?  As t goes to infinity, this wins. ", "As t goes to infinity, the e to the 2t  is bigger than e to the t.  So this is the larger term.  So it approaches. ", "This curve now will approach closer and closer  to the one when the line with slope 2. ", "The 2 will be the winner out here.  But at t equal minus infinity, near the Big Bang,  at t equal minus infinity, e to the 2t is even more small. ", "So at t equal minus infinity, or t equal minus 10,  let's say, this is e to the minus 10.  This would be e to the minus 20; very, very, very small. ", "These would win.  So what happens for this solution  is it starts out along the line given by the not-so-small t, ", "the not-so-small exponent.  It starts up that line.  But t is increasing.  When t passes some point, this 2t will be bigger than t. ", "And it will, I guess, at t equals 0, 2t  will be bigger than t.  And from that point on, from the t equal 0 point-- oh, ", "I could even plot the t equals 0.  So at t equals 0, y is 2 and y prime is 3.  So at 1, 2, 1, 2, 3; somewhere in there. ", "So you see, the curve starts up along the line where e to the t  is bigger. ", "They have the same size at t equals 0, both equal 1.  This is at t equals 0.  And then for large times, this one wins. ", "So I approach that line.  I don't know if you can see that curve.  And I don't swear to the slopes of that curve.  But in between in there is filled ", "with curves that start out with this slope,  and end with that slope.  And the same here, it'll start with this slope. ", "But then go-- probably this is a better picture.  Yeah.  That's a better picture.  Yeah.  It will just go up with slope. ", "At the end it will have slope 2 going upwards.  Yeah.  That looks good.  Well, you could say I only drew part of the phase plane.  And you're completely right. ", "If I start somewhere here, what would you think would happen?  What would you think would happen  if I start with that value of y that much, and that value of y ", "prime?  It would have some mixture of-- there would be a c1 and a c2.  So the other curves that I haven't drawn yet ", "come from the other c1 and c2.  I've done c1 equal 1, and c2 equal 1.  And c1 equal c2 equal 1. ", "But now I have many more possibilities.  And what they do is they will-- so suppose I start there. ", " It will approach-- this is the winner. ", "This is the winner.  Where c1 is 1, where this is happening,  there is the winner for large time.  So all curves swing up toward parallel to that line. ", " Or down here, they swing down parallel to that line.  So things here will swing down this way. ", " That's the phase plane.  May I do one more example to show that this was a source? ", "This is called a source.  Because the solution goes to infinity.  Wherever you start, the solution goes to infinity. ", "It's unstable, totally unstable.  Now if I change to a positive damping,  then I would have a plus sign there.  These would be plus signs. ", "I would have s equal minus 1, or s equal minus 2.  So with positive damping, I damp out naturally.  And this picture would be the same, ", "except all the lines are coming in to 0, 0.  The solutions are damping to 0, 0; to nothing happening.  So I just track the same lines, but in the opposite direction. ", "So instead of this being the Big Bang,  it's the end of the universe, t equal infinity.  OK.  I'm up for one more picture of this possibility. ", "And let me take the equation y double prime equal 4y.  So my equation will be s squared equal 4, s equals 2 or minus 2. ", "And when I draw the phase plane and the solutions,  the solutions will be c1 e to the 2t, and c2 e to the minus ", "2t, from a 2 and a minus 2.  That's the solution we all know.  And now I should compute its slope.  y prime will be 2c1 e to the 2t minus 2c2 e to the 2t. ", "And now you just want me to draw those pictures.  You just want me to draw those pictures,  and let me try to say what happens here. ", "This is a saddle point.  It's called a saddle, when we have in one direction things  are growing, but in the other, things are decreasing.  So most solutions, if c1 is not 0, ", "then the growth is going to win, and that will disappear.  But there is the possibility that c1 is 0.  So there will be one line coming from there. ", "There will be one line coming from there.  Maybe I can try to draw that.  Again, I'll draw that pure line, where c1 is 0. ", "So that pure line is coming.  These are minuses here.  So that line is coming in to the center.  So that's why we have a saddle. ", "We approach a saddle if along this where this is minus 2  of that, so I think it would be-- ", "so it's a slope of minus 2.  So I think a slope like that, so again this is y. ", "This is y prime.  This is the slope of minus 2.   And that's this curve.  ", "So it will be very exceptional that we're right on that line.  All other points, all other curves in this phase plane, ", "are going to have a little c1 in them.  And then this will take over.  And that gives us, as we saw before, this slope.  This is 2 times that. ", "So that line is where everybody wants to go.  And only if you start exactly on this line  do you get this picture, and you come into the saddle. ", "Instead of the Big Bang, or the end of the universe,  this is now the saddle point, where  we come in on this most special of all lines, ", "coming from this picture.  But almost always this is the dominant thing.  And we go out.  So if I take a typical starting point, ", "I'll go out this like that, or like this, oh no.  Yeah, no. ", "I'll go out.  It'll have to go out.  So if I start anywhere here, these are probably  they're hyperbolas going out in that direction. ", "I don't swear that they're hyperbolas.  Here again we might start in.  Because we have big numbers here.  But then e to the t takes over. ", "And we go out.  So those go out.  These go out.  And these go out. ", "So this is the big line.  That's the line coming from here.  And that's where everything wants to go,  and everything eventually goes that way, except the one ", "line where c1 is 0.  So this dominant term is not even here then.  And then we should become inwards.  So that saddle point is the special point ", "where you could go out, if you go the right way.  Or you could come in, if you go the other special, special way.  OK.  So that sources, sinks and saddles. ", "And I still have to draw the pictures, which  involves spirals that come from complex s,  where we have oscillation. ", "That'll be the next video.  GILBERT STRANG: OK.  So this is the second lecture about these pictures,  in the phase plane that's with axes y and y  prime, for a second order constant coefficient ", "linear, good problem.  Good problem.  And you remember that we study that equation  by looking for special solutions y equals e to the st. ", "When we plug that into the equation,  we get this simple quadratic equation.  And everything depends on that.  So today this video is about the case ", "when the roots are complex.  You remember, so the roots, complex roots, you  have a real part, plus or minus an imaginary part. ", "And this happens when b squared is smaller than 4ac.  Because you remember, there's a square root  in the formula for the solution of a quadratic equation. ", "There's a square root of b squared minus 4ac,  the usual formula from school.  And if b squared is smaller, we have a negative number ", "under the square root.  And we get complex roots.  So last time the roots were real.  The pictures in the phase plane set off to infinity, ", "or came in to 0, more or less almost on straight lines.  Now we're going to have curves and spirals, because ", "of the complex part.  So here are the three possibilities now.  We had three last time.  Here are the other three with complex roots. ", "So the complex, the real part, everything  depends on this real part that the stability  going in, going out, staying on a circle ", "depends on that real part.  If the real part is positive, then we go out.  We have an exponential e to the a plus i omega t. ", " And if a is positive that e to the at would blow up, unstable.  So that's unstable. ", "Here is a center.  When a is zero, then we just have e to the i omega t.  That's the nicest example.  I do that one first.  So in that case we're just going around in a circle ", "or around in an ellipse.  And finally, the physical problem  where we have damping, but not too much damping. ", "So the roots are still complex.  But they're going in.  Because if a is negative, e to the at is going to 0. ", "So that's a stable case.  That's a physical case.  We hope to have a little damping in our system, and be stable. ", "This one we could say neutrally stable.  This one is certainly unstable.  Let me start with that, the neutrally stable. ", "Because that's the most famous equation in second order  equation in mechanics.  It's pure oscillation, a spring going up and down, ", "an LC circuit going back and forth, pure oscillation.  And we see the solutions.  So I've written-- I've taken this particular equation. ", "You notice no damping.  There's no y prime term.  OK.  So here is the solution, famous, famous solution.  And y prime it will be c1, I guess ", "the derivative of the cosine is minus omega times  sine omega t, plus c2.  The derivative of that is omega cos omega t. ", "So that's the y and y prime.  So for every t, it's going to be an easy figure.  Here is y. ", "Here is y prime.  And that's the phase plane, phase plane.  So at each time t, I have a y and a y prime. ", "And it gives me a point.  So let me put it in there.  As time moves on that point moves.  And it's the picture in the phase plane, ", "the orbit sometimes you could say,  it's kind of like a planet or a moon.  So for that, what is the orbit for that one? ", "Well it goes around in an ellipse.  It would be a circle with-- let me draw it.   This is the case omega equal 1. ", "In that case, in that most famous case,  we simply go around a circle.  There's y.  There's y prime. ", "We have cosine and sine and cos squared plus sine squared  is 1 squared.  And we're going around a circle of radius 1, or another circle ", "depending on the initial condition.  Here there's a factor omega, giving an extra push  to y prime. ", "So if omega was 2, for example, then we'd have a 2  in y prime from the omega, which is not in the y.  And that would make y prime a little larger. ", "And it would be twice as-- it would go up to twice as--  that's meant to be, meant to be an ellipse with height 2 up ", "there, or in general omega, and 1 there.  So in the y direction there is no factor omega. ", "And we just have cosine and sine.  And that would be a typical picture in the phase plane.  But if we started with smaller initial conditions, ", "we would travel on another ellipse.  But the point is-- and these are called,  this picture is called a center.  ", "So that's one of the six possibilities, and in some way,  kind of the most beautiful.  You get ellipsis in the phase plane.  They close off. ", "Because the solution just repeats itself every period.  It's periodic.  y is periodic.  y prime is periodic.  They come around again and again and again. ", "No energy is lost, conservation of energy, perfection.  And I would say neutrally stable, neutral stability. ", " The solution doesn't go into 0.  Because there's no damping.  It doesn't go out to infinity. ", "Because there's constant energy.  And that's the picture in the phase plane.  OK.  So that's the center.  And now I'll draw one with a source, or a sink. ", "I just have to change the sign on damping  to get source or sink.  So let me do that.  So now I'm going to do a spiral source or sink. ", " This is the unstable one, going out to infinity.  This is the stable one coming in to 0.  And let me do y double prime, plus or maybe minus 4y prime, ", "plus 4y equals 0.  Suppose I take that equation.  Then I have s squared plus 4s, oh maybe-- ", "maybe 2 is a nicer number.  2 is nicer than 4.  Let me change this to a 2, and a 2.  And so I have s squared plus 2s plus 2 ", "or minus 2s plus 2 equals 0.  So those are my-- positive damping would be with a plus. ", "So with a plus sign, the roots are s squared plus 2s plus 2.  The roots are 1, or rather a minus 1 plus or minus i. ", " Plus sign, and then the minus sign, with a minus 2. ", "Then all the roots have a plus, plus or minus i.  Everything is depending on these roots, these exponents, ", "which are the solutions of the special characteristic  equation, the simple quadratic equation.  And you see that depending on positive damping ", "or a negative damping, I get stability or instability.  And let me draw a picture.  I don't if I can try two pictures in the same thing, ", "probably not.  That wouldn't be smart.  So what's happening then?  Let's take this one.  So this solution y is e to the minus t. ", "That's what's making it stable coming into 0, times--  and from here we have c1 cos t and c2 sine t. ", "That's what we get from the usual,  as in the case of a center that carries us around the circle.  So what's happening in this picture, in this phase plane? ", "Here's a phase plane again, y and y prime.  Without the minus 1, we have a center.  We just go around in a circle. ", "But now because of the minus 1, which  is the factor e to the minus t in the solution,  as we go around we come in. ", "And the word for that curve is a spiral.  So this would be the center, going around in a circle. ", "But now suppose we start here.  Suppose we start at y equal 1, and y prime equal 0,  start there at time 0. ", "Let time go.  Plot where we go.  Where does this y and the y prime,  where is the point, y, y prime?  OK. ", "I'm starting it at-- so I'm probably taking c1 as 1,  and c2 as 0.  So I'm starting it right there.  And then I'll travel along, depending on sines. ", "I would go, I think, probably this way.  So it will travel on a-- it comes in  pretty fast, of course. ", "Because that exponential is a powerful guy  that e to the minus t.  So this is the solution, damping out to 0. ", "That's with the plus sign, plus damping,  which gives the minus sign in the s, in the exponent. ", "And then so that is a spiral sink.   Sink meaning just as water in a bathtub  flows in, that's what happens. ", "Now what happens in a spiral source that's  what we have with a minus sign.  Now we have a 1.  Now we have an e to the plus t. ", "Everything is growing.  So instead of decaying, we're going around but growing-- OK.  I'm off the board, way off the board with that spiral. ", "Which is going to keep going around,  but explode out to infinity.  So those are the three possibilities  for complex roots, centers, spiral source, and spiral sink. ", "For real roots we had ordinary source,  and ordinary sink, no spiral.  And then the other possibility was a saddle point, ", "where almost surely we go out.  But there was one direction that came into the saddle point.  OK.  Those six pictures are going to control ", "the whole problem of stability, which is our next subject.  GILBERT STRANG: OK.  A third video about stability for second order, ", "constant coefficient equations.  But we'll move on to matrices here.  So this is a rather special video.  So this is our familiar equation. ", "And I took a to b1, I just divided out a.  No problem.  So that's one second order equation. ", "But we know how to convert it to two first order equations.  And here they are.  So this is two equations.  That's a 2 by 2 matrix there. ", "And so let me read the top equation.  It says that dy dt is 0y plus 1dy dt. ", "So that equation is a triviality.  dy dt equals dy dt.  The second equation is the real one.  The derivative of y prime is y double prime. ", "So this is second derivative here, equals minus cy and minus  b y prime.  And that's my equation y double prime, ", "when I bring the minus cy over as plus cy,  and I bring the minus b y prime over as plus b y prime. ", "I have my equation.  So that equation is the same as that one.  It's just written with a vector unknown.  It's a system, system of two equations. ", "And it's got a 2 by 2 matrix.  And it's called, this particular matrix with a 0  and a 1 is called the companion matrix. ", "Companion, so this is the companion equation to that one.  OK.  So whatever we know about this equation, ", "from the exponents s1 and s2, we're  going to have the same information out  of this equation.  But the language changes. ", "And that's really the point of this video,  just to tell you the change in language.  So here it is.  The old exponents, s1 and s2, for that problem, and everybody ", "watching this video is remembering  that the s's solve s squared plus Bs plus C equals 0. ", "So that's always what are s's are.  So that has two roots, s1 and s2 that control  everything, control stability. ", "Now if I do it in this language, I no longer  call them s1 and s2.  But they're the same two numbers. ", "What I call them is eigenvalues, a cool word,  half German half English maybe, kind of a crazy word.  But it's well established. ", "Those same numbers would be called  the eigenvalues of the matrix.  You see, the matrix in this problem is the same. ", "We've got the same information as the equation here.  So those are the eigenvalues.  And may I just tell you what you may know already?  That everybody writes lambda, a Greek lambda, for eigenvalue. ", "So where I had two exponents, here I have two eigenvalues.  And those numbers are the same as those numbers.  And they satisfy the same equation. ", "And when we meet matrices and eigenvalues properly and soon,  we'll see about eigenvalues of other matrices. ", "And we'll see that for these particular companion matrices,  the eigenvalues solve the same equation  that the exponents solve, this quadratic s squared ", "and Bs and C equals 0.  OK.  And stability, remember that stability  has been real part of those roots of those exponents ", "less than zero, because then the exponential  has that negative real part, and goes to zero.  Now we're just using, so that was our old language. ", "And our new language would be real part of lambda,  less than zero.  Stable matrix is real part of the eigenvalues, ", "lambda less than zero.  So we're just really exchanging the letters s  and the single high order equation for the letter lambda, ", "and two first order equations.  OK.  I'm doing this without-- just connecting the lambda to the s,  but without telling you what the lambda is on its own. ", "OK.  So let me remember.  So, here I've taken a further step.  Because basically I've said everything ", "about a second order equation.  We know the condition for stability.  The condition is that the damping should be positive, ", "B should be positive.  And the frequency squared better come out positive.  So C should be positive.  So B positive and C positive were the case ", "when this was our matrix.  Now I just have a few minutes more.  So why don't I allow any 2 by 2 matrix. ", "I'm not going to give you the theory of eigenvalues here.  But just make the connection.  OK.  So I want to make the connection.  And you remember that the companion matrix ", "had a special form 0.  a was zero, b was 1, c was the minus the big C,  and d was minus the B. That was the companion. ", " So what am I going to say at this early, almost too ", "early moment about eigenvalues?  Because I'll have to do those properly.  Eigenvalues and eigenvectors are the key  to a system of equations. ", "And you understand what I mean by system?  It means that the unknown-- that I have more than one equation.  My matrix is 2 by 2, or 3 by 3, or n by n. ", "My unknown z has 2 or 3 or n different components.  It's a vector.  So z is a vector.  A matrix multiplies a vector.  That's what matrices do. ", "They multiply vectors.  So that's the general picture.  And this was an especially important case.  So we can decide on the stability. ", "So I'll just summarize the stability for that system.  The stability will be-- well I have  to tell you something about the solutions to that system. ", "Remember z is a vector.  So here are solutions.  z is-- it turns out this is the key. ", "That there is an e-- you expect exponentials.  And you expect now eigenvalues instead of s there.  And now we need a vector. ", "And let me just call that vector x1.  And this will be the eigenvector.   And this is the eigenvalue. ", " And if I look for a solution of that form,  put it into my equation, out pops the key equation ", "for eigenvectors.  So again, I put this, hope for solution, into the equation.  And I'll discover that a times this vector x1 ", "should be lambda 1 times x1.  Oh well, I have a lot to say about that.   But if it holds, if a times x1 is lambda 1 times x1, ", "then when I put this in, the equation works.  I've got a solution.  Well I've got one solution.  And of course for second order things,  I'm looking for two solutions. ", "So the complete solution would also  be-- so I could have it's linear.  So I can always multiply by a constant.  And then I would expect a second one, of the same form, ", "e to some other eigenvalue, like some other exponent  times some other eigenvector.  Here's my look-ahead message that solutions look like that. ", "So we're looking for an eigenvalue,  and looking for an eigenvector.  And there is the key equation they have to satisfy.  And that equation comes when we put this ", "into the differential equation and make the two sides agree.  So that's what's coming.  Eigenvalues and eigenvectors control the stability  for systems of equations. ", "And that's what the world is mostly  looking at, single equation, once in awhile but very,  very often a system.  And it'll be the eigenvalues that tell us. ", "So are the eigenvalues positive?  In that case we blow up, unstable.  Are the eigenvalues negative, or at least the real part  is negative? ", "That's the stable case that we live with.   GILBERT STRANG: OK.  I'm concentrating now on the key question of stability.  Do the solutions approach 0 in the case of linear equations? ", "Do they approach some constant, some steady state in the case  of non-linear equations?  So today is the beginning of non-linear. ", "I'll start with one equation.  dy dt is some function of y, not a linear function probably.  And first question, what is a steady state or critical point? ", "Easy question.  I'm looking at special points capital  Y, where the right-hand side is 0, special points where ", "the function is 0.  And I'll call those critical points or steady states.  What's the point? ", "At a critical point, here is the solution.  It's a constant.  It's steady.  ", "I'm just checking here that the equation is satisfied.  The derivative is 0 because it's constant,  and f is 0 because it's a critical point. ", "So I have 0 equals 0.  The differential equation is perfectly good.  So if I start at a critical point, I stay there. ", "That's not our central question.  Our key question is, if I start at other points,  do I approach a critical point, or do I go away from it? ", "Is the critical point stable and attractive,  or is it unstable and repulsive?  So the way to answer that question ", "is to look at the equation when you're  very near the critical point.  Very near the critical point, we could make the equation linear. ", "We can linearize the equation, and that's the whole trick.  And I've spoken before, and I'll do it again now  for one equation.  But the real message, the real content ", "comes with two or three equations.  That's what we see in nature very often,  and we want to know, is the problem stable? ", "OK.  So what does linearize mean?  Every function is linear if you look at it  through a microscope.  ", "Maybe I should say if you blow it up near y equal Y,  every function is linear.  Here is f of y.  ", "Here it's coming through-- it's a graph  of f of y, whatever it is.  If this we recognize as the point capital Y,  right, that's where the function is 0. ", "And near that point, my function is almost a straight line.  And the slope of that tangent is the coefficient, ", "and everything depends on that.  Everything depends on whether the slope is going up like  that-- probably that's going to be unstable-- or coming down. ", "If it were coming down, then the slope  would be negative at the critical point,  and probably that will be stable.  OK.  So I just have to do a little calculus. ", "The whole idea of linearizing is the central idea of calculus.  That we have curves, but near a point,  we can pretend-- they are essentially straight if we ", "focus in, if we zoom in.  So this is a zooming-in problem, linearization.  OK.  So if I zoom in the function at some y. ", "I'm zooming in around the point capital Y.  But you remember the tangent line  stuff is the function at Y. So little y is ", "some point close by.  Capital Y is the crossing point.  And this is the y minus Y times the slope-- that's the slope-- ", "the slope at the critical point there is all that's-- you see  that the right-hand side is linear. ", "And actually, f of Y is 0.  That's the point.  So that I have just a linear approximation  with that slope and a simple function. ", "OK.  So I'll use this approximation.  I'll put that into the equation, and then I'll  have a linear equation, which I can easily solve. ", "Can I do that?  So my plan is, take my differential equation,  look, focus near the steady state,  near the critical point capital Y. Near that point, ", "this is my good approximation to f, and I'll just use it.  So I plan to use that right away. ", "So now here's the linearized.   So d by dt of y equals f of y. ", "But I'm going to do approximately equals this y  minus capital Y times the slope. ", "So the slope is my coefficient little a  in my first-order linear equation.  So I'm going back to chapter 1 for this linearization ", "for one equation.  But then the next video is the real thing  by allowing two equations or even three equations. ", "So we'll make a small start on that,  but it's really the next video.  OK.  So that's the equation.  Now, notice that I could put dy dt  as-- the derivative of that constant ", "is 0, so I could safely put it there.  So what does this tell me?  Let me call that number a.   So I can solve that equation, and the solution ", "will be y minus capital Y. It's just linear.  The derivative is the thing itself times a.  It's the pure model of steady growth or steady decay. ", "y minus Y is, let's say, some e to the at.  Right? ", "When I have a coefficient in the linear equation ay,  I see it in the exponential.  So a less than 0 is stable. ", " Because a less than 0, that's negative, ", "and the exponential drops to 0.  And that tells me that y approaches capital  Y. It goes to the critical point, to the steady state, ", "and not away.  Example, example.  Let me just take an example that you've  seen before, the logistic equation, where the right side ", "is, say, 3y minus y squared.  OK.  Not linear.  So I plan to linearize after I find the critical points. ", "Critical points, this is 0.  That equals 0 at-- I guess there will  be two critical points because I have a second-degree equation. ", "When that is 0, it could be 0 at y equals 0 or at y equals 3.  So two critical points, and each critical point ", "has its own linearization, its slope at that critical point.  So you see, if I graph f of y here, ", "this 3y minus y squared has-- there is 3y minus y squared.  There is one critical point, 0. ", "There is the other critical point at 3.  Here the slope is positive-- unstable.  Here the slope is negative-- stable.  So this is stable, unstable. ", "And let me just push through the numbers here.   So the df dy, that's the slope. ", "So I have to take the derivative of that.  Notice this is not my differential equation.  There is my differential equation.  Here is my linearization step, my computation ", "of the derivative, the slope.  So the derivative of that is 3 minus 2y,  and I've got two critical points. ", "At capital Y equal 0, that's 3.  And at capital Y equals 3, it's 3 minus 6, it's minus 3.  Those are the slopes we saw on the picture. ", "Slope up, the parabola is going up.  Slope down.  So this will correspond to unstable.  ", "So what does it mean for this to be unstable?  It means that the solution Y equals 0, constant 0,  solves the equation, no problem. ", "If Y stays at 0, it's a perfectly OK solution.  The derivative is 0.  Everything's 0.  But if I move a little away from 0,  if I move a little way from 0, then the 3y minus y ", "squared, what does it look like?  If I'm moving just a little away from Y  equals 0, away from this unstable point,  y squared will be extremely small. ", "So it's really 3y.   The y squared will be small near Y equals 0.  Forget that.  We have exponential growth, e to the 3t. ", " We leave the 0 steady state, and we move on. ", "Now, eventually we'll move somewhere  near the other steady state.  At capital Y equals 3, the slope of this thing is minus 3, ", "and the negative one will be the stable point.  So where y minus 3, the distance to the steady state, ", "the critical point will grow like e to the mi-- well,  will decay, sorry, I said grow, I meant decay-- will decay  like e to the minus 3t because the minus 3 in the slope ", "is the minus 3 in the exponent.   OK.  That's not rocket science, although it's  pretty important for rockets. ", "Let me just say what's coming next  and then do it in the follow-up video.  So what's coming next will be two equations, dy dt and dz dt. ", " I have two things.  y and z, they depend on each other.  So the growth or decay of y is given by some function f, ", "and this is given by some different function g, so  f and g.  Now, when do I have steady state? ", "When this is 0.  When they're both 0.  They both have to be 0.  And then dy dt is 0, so y is steady.  dz dt is 0, so z is steady. ", "So I'm looking for-- I've got two numbers to look for.  And I've got two equations, f of y-- oh,  let me call that capital Y, capital Z-- so those ", "are numbers now-- equals 0.  So I want to solve-- equals 0, and g of capital Y, capital Z ", "equals 0.  Yeah, yeah.  So both right-hand sides should be 0, ", "and then I'm in a steady state.  But this is going to be like more interesting to linearize.  That's really the next video, is how do you linearize? ", "What does the linearized thing look  like when you have two functions depending on two variables  Y and Z?  You're going to have, we'll see, [? for ?] slopes-- well, ", "you'll see it.  So this is what's coming.  And we end up with a two-by-two matrix  because we have two equations, two unknowns, and a little more ", "excitement than the classical single equation,  like a logistic equation.  OK.  GILBERT STRANG: OK.  Two equations, the question of stability for two equations, ", "stability around a critical point.  OK.  So the idea will be to linearize,  to look very near that critical point, that point. ", "But now we're in two dimensions.  So that's a little more to do.  So here's the general picture, and then here is an example. ", "So here's the general setup.  We have an equation for the changes in y.  But z is involved. ", "And we have an equation for the rate of change of z.  But y is involved.  So they're coupled together.  It's that coupling that's going to be new. ", "So what's a critical point?  Critical point is when those right-hand sides are 0.  Because then y and z are both constant. ", "So they stay at that point.  Wherever they are at this critical point is steady state.  They stay steady.  They stay steady.  They stay at that constant value. ", "So we want that to be 0.  And we want this to be 0.  We have two equations, f equals 0,  and g equals 0, two equations. ", "But we have two unknowns, y and z.  So we expect some solutions.  And each solution has to be looked at separately. ", "Each solution is a critical point.  It's like well, you could think of a golf course,  with a surface going up. ", "So critical points will be points where the maximum point  maybe, or the minimum point, or we'll  see something called a saddle point. ", "Actually, let's do the example.  The example is a famous one.  Predator-prey it's known as.  Predator like foxes, prey like rabbits. ", "So the foxes eat the rabbits.  And the question is, what are the steady states where  foxes' and rabbits' constant values could stay? ", "So here this is the equation for what happens to the prey.  So if the rabbits are left alone, the prey is the rabbits. ", "If they're left alone they multiply, plenty of grass.  Go for it.  But if there are foxes, and z counts the number of foxes, ", "then foxes eat, shall I say, those rabbits.  And we lose rabbits. ", "So we see that with a minus sign.  And the amount of preying that goes on  is proportional to the number of foxes  times the number of rabbits. ", "Because that gives the number of possible meetings.  And what about the foxes, the predator?  The predator increases. ", "So this is from encountering the rabbits.  That tends to make the number of predators increase. ", "But if there were no rabbits, the foxes don't eat grass.  They're out of luck, and they decay.  So I see a minus z there. ", "So you see the pattern?  So starting from 0 and 0, at that point,  so I've defined critical points. ", "So there's my f.  And that should be 0.  And there is my g, and that should be 0.  And it turns out there are just two possibilities.  This is one. ", "If y and z are both 0, then certainly I would get 0's.  So that's like starting with a very small number of foxes ", "and rabbits.  Or if y is 1 and z equal 1, do you see that that would be,  they would be in perfect balance?  If y is 1, and z is 1, then that's 0 and that's 0. ", "So the equation is satisfied.  We can stay at-- y can stay at 1, and z can stay at 1.  It's a steady state.  And the question is, is that steady state where rabbits ", "are staying-- their population is  staying at 1, because they're eating grass, good.  But they're getting eaten by the foxes, bad. ", "And those two balance, and give a rate of change of zero.  And the foxes similarly, the foxes get a positive push ", "from eating rabbits.  But natural causes cut them back. ", "And they balance at z equal to 1.  OK.  So what I have to do is linearize.  And that's the real point of the lecture. ", "That's the real point for linear-- how  do linearize for two functions?  And how do you linearize for these two functions?  So let me-- I have to write the general formula first, ", "so you'll see it.  And then I'll apply it to those two functions.  OK.  So here is the idea of linearize.  ", "So I'm linearizing.  So my first function is whatever its value is at this point, ", "it's like a tangent line.  But now I've got two derivatives.  Because the function depends on two variables.  So I have a y minus capital Y, times now I ", "have to do partial derivative.  So that's the slope in the y direction, multiplied  by the movement.  And then similar term, z minus capital Z times the movement ", "in the z direction.  And I have to, because I stopped,  this is the linear part of the function. ", "I have to put an approximate symbol.  Because I've ignored higher derivatives.  And of course this is 0. ", "So that's why we have linear in y and linear in z,  times some numbers, the slopes.  But we have two more slopes.  Because we have another function g of y and z. ", "And that again will just be approximately  g at the critical point, which is 0 plus y minus capital Y, ", "times dg dy plus z minus capital Z times dg dz. ", "So altogether, the linear stuff and four numbers,  the derivatives of f in the y and z directions, ", "the derivatives of g in the y and the z directions.  OK.  Now we had an example going.  Let me bring that example down again. ", "There was my f.  There was my g.  Can easily find those partial derivatives.  So let me do it.  So the partial derivative with respect to y will be 1 minus z, ", "z held constant for that partial derivative.  And the partial derivative with respect to z will be minus y.  Let me write all those things down.  So here is in the example. ", " So can I create a little matrix, df dy?  It's the nice way, if I've got four things, 2 by 2 matrix ", "is great.  df, dz; that number, dg, dy; and dg dz. ", "You could say this is the first derivative matrix.  It's the matrix of first derivatives  and it's always named after Jacobi who studied these first. ", "So it's called the Jacobian matrix.  Maybe I'll put his name to give him credit, Jacobi.   And the matrix is the Jacobian matrix. ", " And its determinant is important.  It's a very important matrix, important in economics.  We're doing things-- I'm speaking here ", "about predator-prey, little animals running around.  But serious stuff is the economy.  Is the economy stable?  If it's a running along at some steady state ", "and we move it a little bit, does it  return to that steady state, or does it  get totally out of hand? ", "So there is the Jacobian matrix.  And what are those derivatives?  ", "Remember again, what functions.  There's my functions.  So the y derivative is 1 minus z.  And the z derivative is minus y. ", "The y derivative is z, and the z derivative is y minus 1.  Is that all right? ", "This is what we need to know from the functions.  I've forgotten the functions in the board that went up.  Here are their derivatives.  Now that's my Jacobian matrix. ", "That's my matrix of the-- that matrix  has these four coefficients, those four numbers. ", " And really, so the linearization,  let me call that matrix.  I should call it J for Jacobian. ", "I will call it J for Jacobian.  OK.  That's the Jacobian matrix.  So then my approximate-- what's my linearized equation? ", "My linearized equation is the time derivative of y and z. ", "So this left-hand side is just dy dt, and dz dt.  So I'm using vector notations, putting y  and z together, instead of separately, no big deal. ", "So then I have this matrix J, this 2 by 2 matrix,  times you notice here is a y minus capital Y ", "and a z minus capital Z. There is the linearized problem. ", "Linearized because this is constant,  and this is linear, single y, single z, and we have a matrix  J.  So I have to find-- so now my little job is ", "find the critical points.  I've got everything ready.  I have to find the critical points.  Now remember, the critical points are where f and g are 0. ", "And let me remember what those are.  So there is the f.  There's the g.  One critical point was that one. ", "Everything is 0.  Another critical point is that one.  Again, everything is 0.  So I have two critical points, two Jacobian matrices,  one at the first point, one at the second point. ", "So what are those matrices?  At y and z equals 0, I have the matrix-- I'll put it here,  and then I'll copy it.  If y and z are 0, I have a 1 and a 0 and a 0 and a minus 1. ", " I just took y and z to be 0.  That was the first critical point.  The second critical point gives me the Jacobian ", "at that second point.  The second point was when z was 1.  So that's 0 now.  And y was 1, so that's minus 1.  z is a 1, y minus 1, y is a 1. ", "So that's a 0.  That's the second Jacobian.  So we're seeing something interesting here.  We're seeing how 2 by 2 matrices will  work by really nice examples, 1, 0, minus 1. ", "What's that telling me?  That's telling me that the rabbits grow.  Because the rabbits are the first, the y.  And the foxes decay. ", "And that's what's happening when the two populations are  really small.  When the two populations are really small, ", "multiplying them together is extremely small.  So when the two populations are really small,  forget the eating.  There aren't enough people around, enough  foxes and rabbits around to make a decent meal. ", "So I just have dy dt equal y.  Rabbits are growing from eating grass.  dz dt is minus z, foxes are decaying from natural causes. ", "So that's what kind of a stationary point will 0, 0 be?  Rabbits are growing.  It's an unstable point. ", "We're leaving at 0, 0.  Rabbits are increasing.  Now how about the second point?  The second point was when they were both 1. ", "when they're both 1, then we got this as the Jacobian matrix. ", "Oh, this is the interesting one.  Can I just stay with this one to finish?  So I'm interested in the-- and I'll  put these facts on a new board. ", "So again, y prime dy dt is y minus yz.  z prime is yz, rabbits are getting eaten, minus z. ", "And I'm interested in the point y equal 1, z equal 1.  And my matrix of this is the Jacobian matrix. ", "The Jacobian matrix had the derivatives,  which were 1 minus z, minus y.  The y derivative of that is z. ", "The z derivative is y minus 1.  And at this point y and z are 1.  So that became 0, minus 1, 1 and 0. ", "And what kind of a problem do I have here?  So my linearized equation, so linearized,  linearized around the point 1,1. ", "My equation is y minus 1 prime, sorry.  It's the distance to the critical points. ", " the derivative of y minus 1 is, I see here a minus 1.  I see a minus z minus 1. ", "And here a plus y minus 1.   You've got to understand this pair of linearized equations. ", "If I use some other variable, the derivative of the first guy  is minus the second.  The derivative of the second guy is plus the first. ", " What will happen?  Initially if I'm a little bit-- if I have extra foxes, ", "the rabbit population will drop.  The rabbit population-- this will be negative.  If z, the number of foxes, is a little higher than 1, ", "then the rabbit population drops.  And when the rabbit population drops, z starts dropping.  As z starts dropping below 1, the rabbit population ", "starts increasing.  I get, what shall we say, sort of exchange  of rabbits and foxes, oscillation  between rabbits and foxes?  ", "So this is the-- right in the center  there, that would be the point where y is 1 and z equal 1,  the critical point.  And if I start out with some extra rabbits, ", "then the number of rabbits will drop.  Because foxes are eating them.  The number of foxes will increase.  I'll go up. ", "So there I have a little bit later, I have foxes now,  but no rabbits to eat.  So the foxes start dropping, and what happens? ", "I think, yeah.  The number of rabbit starts increasing.  And this is what happens.  I'll go around and around in a circle. ", "If you remember the pictures of the paths for 2 by 2 equations,  there were saddle points. ", "That's what this is.  y equals 0, z equals 0 was a saddle point.  So no, it's a saddle. ", " And what I'm discovering now for y equal 1  is an oscillation between foxes and rabbits. ", "So again, I could say it'll be our center that  was the very special picture where it didn't spiral out. ", "It didn't spiral in.  The special numbers, the eigenvalues  of that matrix are-- well, better ", "leave eigenvalues for the future.  Because they happen to be i and minus i here.  It's motion in a circle.  It comes from this, the equation here. ", "Motion in a circle as in y double prime plus y equals 0.  That's motion in a circle. ", "And that's what we've got.  So this is a center.  Now what about-- do I call a center stable?  Not quite, because the rabbits and foxes don't approach 1. ", "They stay on a circle around 1.  Either I've got extra rabbits or extra foxes.  But the total energy or the total ", "stays a constant on that circle.  And I would call that neutrally neutral. ", "Neutral stability, because it doesn't blow up.  I don't leave the area around.  I stay close to the critical point.  But I don't approach it either. ", "OK.  So that's a case where we could see the stability, based  on the linearization. ", "OK.  One more example to come in another lecture.   GILBERT STRANG: This is a good time  to do two by two matrices, their eigenvalues, ", "and their stability.   Two by two eigenvalues are the easiest  to do, easiest to understand. ", "Good to separate out the two by two case from the later n  by n eigenvalue problem.   And of course, let me remember the basic dogma of eigenvalues ", "and eigenvectors.  We're looking for a vector, x, and a number, lambda,  the eigenvalue, so that Ax is lambda x. ", "In other words, when I multiply by A,  that special vector x does not change direction.  It just changes length by a factor lambda, ", "which could be positive.  It could be zero.  Could be negative.  Could be complex number.  It's a number, though.  So that's the key equation. ", "Let me go toward its solution.  So I want to move that onto the left hand side.  So I just write the same equation this way. ", "And now I see that this matrix times the vector gives me 0.  Now, when is that possible? ", "That matrix can't be invertible.  If it was invertible, the only solution would be x equals 0.  No good.  So this matrix must be singular. ", "It's determined it must be 0.  And now we have an equation for the eigenvalue lambda.  So lambda is how much we shift the matrix ", "to make the determinant 0.  We shift by lambda times the identity  to subtract that from the diagonal.  So can I begin with very easy two by two matrix, ", "the kind that we met first, called a companion matrix.  So we met this matrix when we had a second order equation. ", "So I started with the equation y double prime plus By prime plus  Cy equals, say, 0. ", "So I started with one second order equation.  And then I introduced y prime as a second unknown.  So now I have a vector unknown, y and y prime. ", "And then, when I wrote the equation down--  I won't repeat that-- it led us to a two by two matrix.  Two equations for two unknowns, y and y prime. ", "So there is a two by two matrix that we're interested in.  But we really are going to be interested in all two by twos.  So let me take that to be my matrix A, my companion matrix. ", "So I just want to go through the steps  of finding its eigenvalues.  What are the eigenvalues of that matrix?  We just take the matrix, subtract lambda ", "from the diagonal, and take the determinant.  And when I take the determinant of a two by two matrix,  it's just that times that, which is ", "minus lambda times minus lambda is lambda squared.  This gives me a B lambda.  And the other part of the determinant  is this product, minus C. But it comes with a minus sign, ", "so it's plus C. So there's my equation for the eigenvalues  of a companion matrix. ", "And of course you see that's exactly the same equation  that we had for the exponent s.  So lambda for the matrix case is the same as s, s1 and s2 ", "for the single second order equation.  So this equation has solutions e to the st ", "when the matrix has the eigenvalues lambda equal s.  Those same s1 and s2. ", "But now I move on to a general two by two matrix.  What are its eigenvalues?  What does that equation looks like for its two eigenvalues? ", "So this will be a special case of this.  Here, I have a general matrix, a, b, c, d.  I've subtracted lambda from the diagonal. ", "I'm taking the determinant.  That'll give me the two eigenvalues.  Let's do it.  Minus lambda times minus lambda is lambda squared. ", "Then I have a minus lambda d and a minus lambda a.  So I have an a plus a d lambda.  And then I have the part that doesn't involve lambda. ", "The part that doesn't involve lambda  is just the determinant of a, b, c, d.  It's just the ad and the minus bc.  So there's an ad and a minus bc, and all that is 0. ", " It's a quadratic equation, second degree.  A two by two matrix has two eigenvalues,  the two roots of that equation. ", "I just want to understand more and more and more  about the connection of the roots, lambda 1 lambda  2, to the matrix a, b, c, d. ", "If I know the two by two matrix, this tells me the eigenvalues.  So this will, being a quadratic equation, have two roots. ", " So if I factor this, this will factor into lambda minus lambda  1 times lambda minus lambda 2. ", "And of course, if the numbers are nice,  then I can see what lambda 1 and lambda 2 are.  In that case, I find the eigenvalues. ", "If the numbers are not nice, then lambda 1 and lambda 2  come from the quadratic formula, the minus b plus or minus  square root of b squared minus 4ac. ", "The quadratic formula will solve this equation, will tell me  these two numbers.  And if I multiply it out this way, I see lambda squared. ", "I see minus lambda times lambda 1 and lambda 2.   And then I see plus lambda 1 times lambda 2 equals 0. ", " Here, I've written the equation for the two lambdas.  Here, I've written the equation when I know the two lambdas. ", "Why did I do this?  I want to match this with this and see  that this number, whatever it is, is the same as that number. ", "They show up there, the coefficient of minus lambda.  So that's the first step, that lambda 1 plus lambda 2 ", "is the same as a plus d.   Just matching those two equations.  This is just like a general fact about a quadratic equation. ", "The sum of the roots is the minus coefficient of lambda.  And then the constant term is the constant term. ", "So lambda 1 times lambda 2 is ad minus bc.  ", "These are facts about a two by two matrix, a, b, c, d.  The sum of the eigenvalues.  So this is the sum of the eigenvalues-- ", "so I'll put s-u-m to indicate that I'm looking  at the sum-- is that a plus d.  A plus d are the numbers on the diagonal. ", "So that's a little special.  When I add the diagonal numbers, I  get something called the trace of the matrix. ", " I'm introducing a word, trace.  Trace is the add up down the diagonal.  And that matches a plus d. ", " And this one is the product of the eigenvalues lambda  1 times lambda 2.  So that's the product. ", "And that's equal to the determinant of a.   I'm just making all the neat connections that ", "are special for a two by two.  So that if I write down some matrices,  we could look at them immediately.  Let me write down a matrix. ", "Suppose I write down that matrix.   Oh, let me make them 0, 1-- well, 0, 4-- ah, ", "let me improve this a little.  2, 4, 4, 9.  2, 4, 4, 2 would be even easier.  Sorry.  ", "I look at that matrix.  I see immediately the two eigenvalues of that matrix  add to 4.  2 plus 2 is 4.  I took the trace. ", "The two eigenvalues of that matrix multiply  to the determinant, which is 2 times 2 is 4 minus 16 minus 12.  So the sum here for that matrix would be 4. ", "The determinant of that matrix would be 4 minus 16  is minus 12.  And maybe I can come up with the two numbers that have add to 4 ", "and multiply to minus 12.  I think, actually, that they are six and minus 2.  I think that the eigenvalues here are 6 and minus 2 ", "because those add up to 4, the trace,  and they multiply 6 times minus 2 is minus 12.  That's the determinant. ", "Two by two matrices, you have a good chance  at seeing exactly what happens.  Now, my interest today for this video is to use all this, ", "use the eigenvalues, to decide stability.  Stability means that the differential equation  has solutions that go to 0. ", "And we remember the solutions are  e to the st, which is the same as e to the lambda t. ", "The s and the lambda both come from that same equation  in the case of a second order equation reduced to a companion ", "matrix.  So I'm interested in when are the eigenvalues negative.  When are the eigenvalues negative? ", "Or if they're complex numbers, when  are their real parts negative.  So can we remember trace, the sum, product, the determinant. ", "And answer the stability questions.  So I'm ready for stability.   So stability means either lambda 1 negative ", "and lambda 2 negative.  This is in the real case.   Or in the complex case, lambda equals some real part ", "plus and minus some imaginary part.  Then we want the real part to be negative.  Real part of a lambda, which is a, should be 0. ", "So that's our requirement.  If the eigenvalues are complex, we  get a pair of them and the real part  should be 0 so that e to the-- the point about this negative a ", "is that e to the at will go to 0.  The point about these negative lambdas  is that e to the lambda t will go to 0. ", "This is stability.  So my question is, what's the test on the matrix that decides ", "this about the eigenvalues?   Can we look at the matrix-- maybe  we don't have to find those eigenvalues. ", "Maybe we can use the fact.  Again, the fact is that lambda 1 plus lambda 2  is the trace and lambda 1 times lambda 2 is the determinant. ", "And we can read those numbers off from the matrix.  Then there's a quadratic equation.  But if we only want to know information like ", "are the eigenvalues negative?  Are their real parts negative?  We can get that information from these numbers  without going to finding the eigenvalues ", "from that quadratic equation.  Wouldn't be that hard to do, but we don't have to do it.  So suppose we have two negative eigenvalues. ", "Then certainly, this would mean the trace would be negative.  Because the trace is the sum of the eigenvalues. ", "If those are both negative, trace is negative.  So we can check about the trace just right away.  What about the determinant? ", "If that's negative and that's negative,  then multiplying those will give a positive number.  So the determinant should be positive.  So trace less than 0. ", "Determinant greater than 0.  That is the stability test.  That's the stability test.  ", "Stable.   The two by two matrix A, B, C, D, if its trace is negative  and its determinant is positive, is stable. ", "That's the test.  And actually, it works also if lambda comes out complex  because lambda 1 plus lambda 2-- lambda 1 is a plus i omega. ", "Lambda 2 is a minus omega.  The sum is just 2a.  And we want that to be negative.  So again, trace negative. ", "Trace negative even if the roots are real or if they're complex.  That still tells us that the sum of the roots is negative  and the determinant also works. ", "If a plus i omega times a minus i omega-- in this case,  lambda 1 times lambda 2-- if I multiply those numbers, ", "I get a squared plus omega squared.  With a plus.  So that would be positive.  And we're good. ", "So my conclusion is this is the test for stability.  And I can apply it to a few matrices.  I wrote down a few matrices. ", "Can I just look at that test-- can you look at that test--  and just apply it to see.   So here's an example. ", "Say minus 2, minus 1, 3, and 4.  Is that any good?  The trace is minus 3. ", "That's good.  The determinant is 2 minus 12 minus 10.  That's bad.  That's bad.  So that would be unstable. ", " That has a negative determinant.  Unstable.  So I'll put an x through that.  Unstable.  Let me take a stable one. ", "Stable one, I'm going to want like minus 5, and 1, let's say.  That's OK.  The trace is negative.  Minus 4. ", "And now I want to make the determinant positive.  So maybe I better put like 6 and minus 7.  Just picking numbers. ", "So now the determinant is minus 5 plus 42.  A big positive number.  And the determinant test is passed. ", "So that is OK.  That one would be stable.   If this was my matrix A, then the solutions ", "to dy dt equal Ay, y prime equal Ay is my differential equation.  The two solutions which would track the eigenvectors ", "would have negative lambdas.  Negative lambdas because the trace is negative  and the determinant is positive.  Passes the stability test and the solutions ", "would go to minus infinity.  That's two by twos.  PROFESSOR: OK.  Here's an example that's more or less for fun.  Because you'll see me try to do it. ", "You can do it better.  I call the problem the tumbling blocks.  Only in this example, in my demonstration,  it's going to be a tumbling book. ", "I'm going to take a book, the sacred book,  and throw it in the air.  And I'll throw it three different ways.  And the question is, is the spinning book stable or not? ", "And let me tell you the three ways  and then give you the three equations that came from Euler.  So those are the three equations.  You see that they're not linear. ", "And those are for the angular momentum.  So there's a little physics behind the equations.  But for us, those are the three equations.  So the first throw will spin around ", "the very short axis, just the thickness of the book,  maybe an inch.  So when I toss that, as I'll do now,  you will see if I can toss it not too nervously I hope. ", "It came-- it was stable.  The book came back to me without wobbling. ", "Of course, my nerves would give it a little wobble,  and that wobble would continue.  It will be only neutrally stable.  The wobble doesn't disappear. ", "But it doesn't grow into a tumble.  OK.  So that's one axis, the short axis.  Then I'll throw it also around the long axis, flipped ", "like this.  I think that will be stable too.  And then, finally, on the intermediate axis,  is middle length axis.  Notice the rubber band that's holding the book together. ", "Holding so the pages don't open.  And this, we'll see, I think, will be unstable.  And similarly, throwing a football, ", "throwing other Frisbees, whatever your throw.  Any 3D object has got these three axes: a short one, ", "a medium one, and a long axis.  And the equations will tell us short  and long axes should give a stable turning. ", "And the in between axis is unstable.  Well, how do we decide for our differential equation  whether the fixed point, a fixed point, ", "that's a critical point, a steady state--  we have to find this steady state,  and then for each steady state we linearize.  We find the derivatives at that steady state. ", "And that gives us a constant matrix at that steady state.  And then the eigenvalue is decided.  So first, find the critical points. ", "Second, find the derivatives at the critical points.  Third, for that matrix of derivatives,  find the eigenvalues and decide stability. ", "That's the sequence of steps.  OK.  The first time we've ever done a three by three matrix.  Maybe the last time.  OK. ", "Let me, before I start-- before I  find the critical points-- notice some nice properties.  If I multiply this equation by x, this one ", "by y, this one by z, and add, those will add to 0.  When there's an x there, a y there, and a z there,  I get a 1 minus 2 and a 1 they add to 0. ", "So x times dx dt.  y times dy dt. z time dz dt adds to 0.  That's an important fact.  That's telling me that the derivative of something is 0. ", "That something will be a constant.  So I'm seeing here the derivative  of that whole business would be the derivative ", "of a half probably.  x squared, because the derivative of x squared  will be with a half. ", "The derivative will be x dx dt.  And y squared and z squared is the derivative is 0. ", "The derivative of that line is just this line.  It's 0.  So this is a constant.  ", "No doubt, that's probably telling me  that the total energy, the kinetic energy, is constant.  After I've tossed that book up in the air, ", "I'm not touching it.  It's doing its thing.  And it's not going to change energy because nothing  is happening to it.  It's just out there. ", "Now there are other-- so that's a rather nice thing.  This is a constant.   Now there's another way. ", "If I multiply this one by 2x, and I multiply this one by y,  and add just those two, that cancels. ", "So 2x dx dt-- 2x times the first one-- and y  times the second one gives 0.  Again, I'm seeing something is constant. ", "The derivative of something, and that something  is x squared plus 1/2 y squared is a constant. ", " Another nice fact.  Another quantity that's conserved. ", "And as I'm flying around in space,  this quantity x squared plus 1/2 y squared does not change.  This sort of-- that involved all of xyz. ", "And of course that's the equation of a sphere.  So in energy space, or in an xyz space, ", "our solution is wandering around a sphere.  And this is the equation for, I guess, it's an ellipse.  So there's an ellipse on that's sphere ", "that it's actually staying on that ellipse.  And in fact there's another ellipse  because I could've multiplied this one by 2z and this one ", "by y and added.  And then those would have canceled.  Minus 2 xyz plus 2xyz.  So that also tells me that it would ", "be probably z squared plus 1/2 y squared equals a constant. ", "That's another ellipse.  z squared plus 1/2 y squared.  You see this?  If I take the derivative of that,  I have 2z times dz dt plus y times dy dt. ", "Adding give 0.  The derivative is 0.  The thing is a constant.  But!  But, but, but!  If I subtract this one from this one, ", "take the difference of these two.  Suppose I take this one minus this one.  The 1/2 y squared will go.  So that will tell me that x squared minus z ", "squared is a constant.  Oh, boy!  I haven't solved my three equations. ", "But I found out a whole lot about the solution.  The solution stays on the sphere, wanders around somehow.  It also at the same time stays on that ellipse. ", "And it stays on that ellipse.  But this is not an ellipse, not an ellipse.  That's the equation of a hyperbola.  And that's why-- which, of course, goes off to infinity. ", "And that's why the-- well, it goes off to infinity,  but it has to stay on the sphere.  It wanders.  This will be responsible for the unstable motion. ", "Professor [INAUDIBLE], who would do this far better than me,  his great lecture in 1803, Differential Equations, ", "was exactly this.  The full hour to tell you everything about the tumbling  box.  So I'm going to do the demonstration ", "and write down the main facts and understand the stability,  the discussion of stability.  I'm ready to move on to the discussion of stability. ", "Again, here are my three equations.  We're up to three equation, so we're  going have a three by three matrix.  And first I have to find out the critical points, ", "the steady states of this motion.  How could I toss it so that if I toss it perfectly  it stays exactly as tossed?  And the answer is, around the axis. ", "If I toss this perfectly, with no nerves,  it'll just spin exactly as I'm throwing it.  The x, y, and z will all be constant. ", "Now, when I toss it on that axis.   I'm looking for-- here are my right hand side. ", "YZ, minus 2XZ, and XY.  And I wrote those in capital letters ", "because those are going to be my steady states.  Now I'm looking for are points where nothing's happened. ", "If those three right hand sides of the equation are 0,  I'm not going to move.  xyz will stay where they are.  So can you see solutions of those three equations? ", "Well, they're pretty special equations.  I get a solution when, for example, solutions could be 1, ", "0, 0/  If two of the three-- if y and z are 0.  y is 0, z is 0, y and z are 0, I get 0. ", "So that is a certainly steady state.  x equal 1, y and z equal 0 and 0.  And that steady state is spinning around one axis. ", "And, actually, I could have also a minus 1 would also be.  So I've found, actually, two steady states with y and z 0.  Then there'll be two more with x and z 0. ", "And this could be-- that'll be spinning  around the middle axis.  And then 0, 0, 1 or minus 1, that ", "would be spinning around the third axis, the long axis.  So those are my steady states.  And I guess, come to think of it, 0,  0, 0 would also be a steady state. ", "I think I found them all.  These are the xy's.  These are the x, y, z steady states. ", "OK.  So now once you know the steady states, that's usually fun,  as it was here.  Now the slightly less fun step is find all the derivatives, ", "find that Jacobian matrix of derivative.  So I've got three equations.  Three unknowns, xyz. ", "Three right hand sides.  And I have to find-- I'm going to have a three by three  matrix of derivatives. ", "This Jacobian matrix.  So J for the Jacobian, the matrix of first derivatives.  So what goes into the matrix of first derivative? ", "Let me write Jacobian.  It is named after Jacoby.  It's the matrix of first derivatives.  On the top row are the derivatives ", "of the first function with respect to x.  Well, the derivative with respect to x is 0.  The derivative with respect to y is z.  The derivative with respect to z is y. ", "Those were partial derivatives.   They tell me how much the first unknown x moves. ", "They tell me what's happening with the first unknown  x around the critical point whichever it is.  OK.  What about the partial derivatives ", "from the second equation?  it's partial derivatives will go into this row.  So x has a minus 2z.  y derivative is 0. ", "z derivative is minus 2x.  And the third one, the z derivative is 0 here.  The y derivative in x.  And the x derivative is y. ", " I've found the 3 by 3 matrix with the nine  partial first derivatives. ", "OK.  It's the eigenvalues of that matrix at these points  that decide stability.  So I write that down.  Eigenvalues of J at the critical points x, ", "y, z that's what I need.  That's what decides stability.  Let me just take the first critical point. ", "What is my matrix?  I have to figure out what is the matrix at that point?  And I'll just take 1, 0, 0.  1, 0, 0.  If x is 1-- so I'm getting, this is at the point x equal 1. ", "y and z are 0.  So if x is 1, then that that's a minus 2 and a 1.  And I think everything else is 0. ", " So it'll be the eigenvalues of that matrix that  decide the stability 1, 0, 0 of that fixed point. ", "And remember, that's the toss around the narrow axis.  That's the toss around the short axis. ", "OK.  What about the eigenvalues of that matrix?  Well, I can see here that really it's three by three.  But really, with all those 0s, that ", "gives me an eigenvalues of 0.  So I'm going to have an eigenvalue of 0 here.  And then I'm going to have eigenvalues  from the part of that matrix, which is two by two. ", "So I'll have a lambda equals 0 here.  And two eigenvalues from here.  And I look at that, and what do I see? ", "Now this is a two by two problem.  I see the trace is 0.  0 plus 0.  My eigenvalues are a plus and minus pair ", "because they add to 0.  They multiply to give the determinant.  The determinant of that matrix is 2.  The determinant of that matrix is 2. ", "OK.  So it has a positive determinant.  That's good for stability.  But the trace is only 0.  It's not quite negative.  It's not positive.  It's just at 0. ", "So this is going to be a case of neutral stability.  The eigenvalues will be-- I'll have a 0 eigenvalue from there.  The eigenvalues from this two by two will be-- there'll ", "be a square root of 2 times i and a minus  the square root of 2 times i.  I think those are the eigenvalues. ", "And what I see there is they're all imaginary.  This is a pure oscillation.  The wobbling keeps wobbling.  Doesn't get worse. ", "Doesn't go away.  It's neutral stability at this point.  So neutral stability is what we hopefully will see again. ", "Yes.  And I think, also, if I flip on the long axis.  Good.  Did you see that brilliant throw? ", "It's neutral stability.  It came back without doing anything too bad.  And I finally have to do the axis that we're all intensely ", "waiting for, the middle axis.  And the middle axis is when the book starts tumbling,  and it's going to be a question of whether I can catch it ", "or not.  May I try?  And then may I find-- what am I expecting on the neutral axis?  I'm expecting instability.  I think actually it will be a saddle point. ", "But there'll be a positive eigenvalues.  There will be a positive eigenvalue.  And it is responsible for the tumbling, the wild tumbling ", "that you will see.  And it's connected with the point staying  on this hyperbola that wonders away from-- so it's  this one now that I'm doing. ", "This guy is the-- I'll put a box around-- a double box  around it.  That's the unstable one, which I'm about to demonstrate. ", "Ready?  OK.  Whoops.  OK.  It took two hands to catch it.  Let me try it again. ", "The point is it starts tumbling, and it goes in all directions.  It's like a football, a really badly thrown football. ", "It's like a football being thrown that goes end to end.  The whole flight breaks up, and the ball is a mess. ", "Catching it is ridiculous.  And I'm doing it with a book.  Yes.  You saw that by watching really closely. ", "OK.  Better if you do it.  I'll end with the eigenvalues at this point.  So the eigenvalues at that point--  can I just erase my matrix? ", "So this was a neutrally stable one, a center  in the language of stability.  That's a center which you just go around and round and round. ", "But now I'm going to just take x and z to be 0 and y to be 1.  So can I erase that matrix and take--  If x and z are 0, and y is 1-- so I get a 1 down here. ", "And I get a 1 up there.  And nothing else.  Everything else is 0.   OK. ", "That's my three by three matrix.  What are its eigenvalues?  What are the eigenvalues of that three by three very  special matrix?  This is now the-- this was the first derivative matrix, ", "the Jacobian matrix, at this point, corresponding  to the middle axis.  OK.  Again, I'm seeing some 0s. ", "I'll reduce this to that two by two matrix and this matrix.  Really, I have this two by two matrix in the xz, ", "and this one in the y.  How about that guy?  You recognize what we're looking at with this matrix.  So with that matrix, I can tell you the eigenvalues. ", "We can see the trace is 0.  The eigenvalues add to 0.  They multiply to the determinant.  And the determinant is minus 1. ", "So the eigenvalues here are 1 and minus 1.  And then this guy gives 0.  And it's that eigenvalue of 1 that's unstable. ", "That eigenvalue of 1 is unstable.  OK.  So mathematics shows what the experiment  shows: an unstable rotation tumbling ", "around that middle axis. "], "vid_duration": [11.4, 12.16, 10.04, 10.68, 11.6, 10.64, 10.85, 10.21, 16.51, 12.13, 12.46, 14.55, 10.17, 11.02, 13.13, 20.44, 11.62, 14.97, 11.94, 11.71, 11.419, 10.211, 13.86, 12.18, 11.5, 12.45, 14.54, 13.96, 10.18, 11.765, 12.395, 10.17, 10.49, 10.26, 10.83, 11.85, 10.23, 11.25, 13.73, 10.56, 14.51, 10.65, 11.64, 12.84, 10.97, 12.87, 14.17, 16.65, 11.47, 11.42, 10.83, 12.39, 12.49, 10.61, 13.73, 14.09, 10.99, 10.48, 11.71, 15.61, 11.0, 10.84, 10.42, 11.41, 11.46, 10.23, 10.58, 13.38, 12.82, 10.82, 10.71, 12.72, 10.93, 11.42, 11.08, 15.38, 14.38, 14.7, 11.42, 11.21, 12.875, 15.205, 10.74, 10.77, 11.7, 13.27, 10.7, 13.57, 13.42, 12.08, 12.88, 10.4, 11.84, 12.16, 10.65, 10.11, 12.91, 13.25, 12.51, 13.312, 14.188, 14.24, 11.482, 11.68, 12.05, 10.19, 11.63, 12.2, 10.03, 12.41, 10.42, 10.1, 12.42, 11.74, 11.88, 12.38, 11.23, 13.51, 11.31, 15.85, 11.93, 14.51, 11.26, 10.18, 13.39, 10.04, 13.5, 13.03, 11.58, 15.5, 12.7, 10.47, 11.81, 10.9, 11.17, 13.84, 10.43, 15.12, 12.98, 11.74, 12.56, 10.66, 10.87, 10.38, 14.9, 11.34, 17.15, 12.48, 13.05, 12.69, 11.82, 13.52, 13.72, 10.38, 12.68, 10.57, 10.48, 12.14, 10.49, 10.475, 12.565, 12.71, 10.78, 10.03, 11.87, 11.41, 12.05, 13.04, 13.39, 14.88, 13.75, 19.09, 10.87, 16.76, 11.99, 10.49, 11.35, 10.46, 11.1, 13.7, 12.71, 11.72, 14.58, 10.87, 10.54, 10.0, 14.204, 11.306, 10.74, 13.94, 12.92, 12.089, 10.271, 14.021, 17.03, 12.9, 11.82, 12.2, 13.14, 11.0, 10.55, 10.59, 13.29, 14.41, 10.91, 11.905, 10.285, 10.57, 11.41, 11.02, 10.81, 14.99, 12.75, 14.69, 11.929, 10.281, 12.27, 10.66, 11.06, 10.32, 10.659, 10.271, 11.81, 10.99, 10.33, 10.55, 12.48, 10.16, 12.909, 11.456, 11.765, 11.45, 14.285, 18.725, 10.61, 15.64, 12.19, 14.8, 11.69, 11.0, 11.3, 11.86, 11.96, 14.8, 11.73, 11.29, 10.53, 13.77, 11.96, 10.32, 15.27, 11.28, 16.02, 10.26, 12.09, 10.17, 13.61, 15.68, 10.27, 10.5, 10.911, 11.779, 10.161, 12.73, 11.6, 13.13, 10.27, 10.54, 13.04, 11.23, 11.19, 11.66, 12.92, 10.27, 10.81, 10.13, 11.43, 10.4, 14.66, 12.29, 10.26, 11.089, 14.94, 13.02, 12.611, 12.76, 13.16, 15.15, 11.43, 12.8, 11.67, 12.35, 11.154, 10.216, 11.3, 11.46, 11.39, 16.279, 10.721, 10.58, 11.969, 12.616, 12.625, 13.03, 12.66, 12.029, 13.011, 16.96, 10.25, 12.88, 10.74, 10.61, 16.497, 11.23, 15.75, 13.08, 10.55, 10.59, 12.41, 12.04, 12.715, 11.595, 10.07, 12.89, 13.75, 13.58, 11.47, 11.37, 13.09, 13.15, 11.76, 15.28, 15.16, 15.06, 15.96, 12.99, 12.32, 12.44, 13.44, 10.07, 15.66, 12.74, 14.08, 12.03, 13.07, 14.59, 14.55, 10.35, 12.64, 11.0, 11.36, 13.44, 10.83, 12.46, 12.41, 11.33, 11.42, 12.97, 12.73, 11.74, 11.16, 11.65, 10.825, 11.855, 15.06, 12.34, 11.215, 10.005, 13.87, 16.49, 15.04, 12.4, 18.52, 16.48, 12.74, 10.36, 12.83, 10.83, 10.8, 11.21, 13.87, 13.91, 13.583, 12.98, 11.02, 11.8, 12.67, 10.34, 12.559, 12.131, 10.47, 12.6, 11.44, 13.39, 12.759, 12.96, 10.481, 11.769, 11.21, 11.04, 11.401, 12.02, 13.36, 10.105, 11.305, 13.76, 15.75, 12.73, 12.62, 10.819, 11.641, 12.58, 12.88, 11.31, 12.45, 16.78, 10.819, 11.721, 15.8, 11.12, 12.17, 10.729, 10.88, 14.701, 10.56, 13.489, 12.411, 13.57, 12.443, 12.407, 11.85, 11.0, 10.109, 10.881, 11.199, 12.011, 11.4, 10.79, 10.75, 11.07, 11.46, 11.24, 10.57, 14.11, 10.5, 10.849, 14.481, 14.55, 10.639, 13.371, 14.6, 12.73, 10.049, 13.221, 12.8, 10.6, 10.339, 10.231, 10.58, 16.389, 10.871, 10.66, 14.66, 13.68, 18.5, 14.84, 13.44, 10.233, 15.107, 10.44, 12.14, 13.38, 14.24, 10.8, 16.349, 12.551, 10.49, 11.334, 11.196, 12.25, 14.07, 12.42, 10.149, 13.281, 13.79, 11.799, 11.802, 10.769, 10.795, 10.72, 17.68, 10.77, 13.7, 13.61, 11.08, 10.35, 13.79, 10.46, 15.12, 12.03, 10.77, 13.5, 13.66, 14.42, 13.61, 12.26, 13.18, 10.11, 19.19, 11.08, 10.11, 13.6, 11.41, 11.26, 11.74, 15.28, 12.83, 11.65, 11.07, 12.27, 12.1, 12.27, 12.07, 17.29, 11.03, 11.98, 11.66, 14.51, 11.789, 11.201, 10.79, 11.75, 10.17, 10.65, 11.41, 12.24, 12.03, 19.4, 11.1, 11.98, 14.95, 12.63, 12.39, 10.18, 15.08, 12.07, 10.63, 11.439, 11.971, 11.66, 12.69, 17.179, 13.221, 12.5, 11.66, 12.38, 10.55, 15.21, 10.9, 15.42, 10.32, 11.68, 10.42, 11.79, 10.29, 12.17, 14.5, 11.25, 11.92, 10.69, 10.949, 12.901, 12.18, 11.3, 10.18, 11.56, 10.5, 11.23, 12.37, 11.19, 14.11, 11.9, 12.383, 12.072, 18.29, 12.4, 16.79, 15.21, 10.859, 10.67, 15.111, 12.53, 11.97, 12.009, 11.88, 14.521, 13.15, 11.069, 11.521, 10.29, 12.79, 12.739, 13.821, 10.795, 10.075, 11.87, 13.149, 10.641, 10.33, 12.81, 12.24, 11.96, 10.985, 12.555, 12.519, 10.2, 10.771, 11.76, 10.719, 10.461, 15.81, 13.109, 10.651, 10.38, 11.358, 12.772, 12.27, 11.72, 12.57, 13.0, 15.51, 14.16, 12.489, 12.511, 10.279, 10.29, 12.731, 10.109, 10.95, 14.911, 13.67, 10.11, 13.149, 11.641, 12.92, 10.55, 10.66, 12.29, 11.349, 14.261, 10.25, 13.699, 12.42, 11.511, 11.01, 16.982, 13.247, 18.021, 10.78, 15.97, 11.01, 12.12, 13.38, 10.98, 12.359, 11.67, 11.26, 13.551, 10.09, 10.35, 11.67, 10.359, 15.641, 10.349, 11.391, 10.789, 12.151, 11.669, 10.231, 12.039, 12.4, 10.26, 12.811, 10.1, 15.46, 10.58, 17.39, 14.95, 11.38, 16.64, 10.04, 11.379, 14.181, 2.636], "stet": [[0, 11.4], [11.4, 23.560000000000002], [23.560000000000002, 33.6], [33.6, 44.28], [44.28, 55.88], [55.88, 66.52000000000001], [66.52000000000001, 77.37], [77.37, 87.58000000000001], [87.58000000000001, 104.09000000000002], [104.09000000000002, 116.22000000000001], [116.22000000000001, 128.68], [128.68, 143.23000000000002], [143.23000000000002, 153.4], [153.4, 164.42000000000002], [164.42000000000002, 177.55], [177.55, 197.99], [197.99, 209.61], [209.61, 224.58], [224.58, 236.52], [236.52, 248.23000000000002], [248.23000000000002, 259.649], [259.649, 269.86], [269.86, 283.72], [283.72, 295.90000000000003], [295.90000000000003, 307.40000000000003], [307.40000000000003, 319.85], [319.85, 334.39000000000004], [334.39000000000004, 348.35], [348.35, 358.53000000000003], [358.53000000000003, 370.295], [370.295, 382.69], [382.69, 392.86], [392.86, 403.35], [403.35, 413.61], [413.61, 424.44], [424.44, 436.29], [436.29, 446.52000000000004], [446.52000000000004, 457.77000000000004], [457.77000000000004, 471.50000000000006], [471.50000000000006, 482.06000000000006], [482.06000000000006, 496.57000000000005], [496.57000000000005, 507.22], [507.22, 518.86], [518.86, 531.7], [531.7, 542.6700000000001], [542.6700000000001, 555.5400000000001], [555.5400000000001, 569.71], [569.71, 586.36], [586.36, 597.83], [597.83, 609.25], [609.25, 620.08], [620.08, 632.47], [632.47, 644.96], [644.96, 655.57], [655.57, 669.3000000000001], [669.3000000000001, 683.3900000000001], [683.3900000000001, 694.3800000000001], [694.3800000000001, 704.8600000000001], [704.8600000000001, 716.5700000000002], [716.5700000000002, 732.1800000000002], [732.1800000000002, 743.1800000000002], [743.1800000000002, 754.0200000000002], [754.0200000000002, 764.4400000000002], [764.4400000000002, 775.8500000000001], [775.8500000000001, 787.3100000000002], [787.3100000000002, 797.5400000000002], [797.5400000000002, 808.1200000000002], [808.1200000000002, 821.5000000000002], [821.5000000000002, 834.3200000000003], [834.3200000000003, 845.1400000000003], [845.1400000000003, 855.8500000000004], [855.8500000000004, 868.5700000000004], [868.5700000000004, 879.5000000000003], [879.5000000000003, 890.9200000000003], [890.9200000000003, 902.0000000000003], [902.0000000000003, 917.3800000000003], [917.3800000000003, 931.7600000000003], [931.7600000000003, 946.4600000000004], [946.4600000000004, 957.8800000000003], [957.8800000000003, 969.0900000000004], [969.0900000000004, 981.9650000000004], [981.9650000000004, 997.1700000000004], [997.1700000000004, 1007.9100000000004], [1007.9100000000004, 1018.6800000000004], [1018.6800000000004, 1030.3800000000003], [1030.3800000000003, 1043.6500000000003], [1043.6500000000003, 1054.3500000000004], [1054.3500000000004, 1067.9200000000003], [1067.9200000000003, 1081.3400000000004], [1081.3400000000004, 1093.4200000000003], [1093.4200000000003, 1106.3000000000004], [1106.3000000000004, 1116.7000000000005], [1116.7000000000005, 1128.5400000000004], [1128.5400000000004, 1140.7000000000005], [1140.7000000000005, 1151.3500000000006], [1151.3500000000006, 1161.4600000000005], [1161.4600000000005, 1174.3700000000006], [1174.3700000000006, 1187.6200000000006], [1187.6200000000006, 1200.1300000000006], [1200.1300000000006, 1213.4420000000005], [1213.4420000000005, 1227.6300000000006], [1227.6300000000006, 1241.8700000000006], [1241.8700000000006, 1253.3520000000005], [1253.3520000000005, 1265.0320000000006], [1265.0320000000006, 1277.0820000000006], [1277.0820000000006, 1287.2720000000006], [1287.2720000000006, 1298.9020000000007], [1298.9020000000007, 1311.1020000000008], [1311.1020000000008, 1321.1320000000007], [1321.1320000000007, 1333.5420000000008], [1333.5420000000008, 1343.962000000001], [1343.962000000001, 1354.0620000000008], [1354.0620000000008, 1366.4820000000009], [1366.4820000000009, 1378.222000000001], [1378.222000000001, 1390.102000000001], [1390.102000000001, 1402.482000000001], [1402.482000000001, 1413.7120000000011], [1413.7120000000011, 1427.2220000000011], [1427.2220000000011, 1438.532000000001], [1438.532000000001, 1454.382000000001], [1454.382000000001, 1466.312000000001], [1466.312000000001, 1480.822000000001], [1480.822000000001, 1492.082000000001], [1492.082000000001, 1502.262000000001], [1502.262000000001, 1515.6520000000012], [1515.6520000000012, 1525.6920000000011], [1525.6920000000011, 1539.1920000000011], [1539.1920000000011, 1552.2220000000011], [1552.2220000000011, 1563.802000000001], [1563.802000000001, 1579.302000000001], [1579.302000000001, 1592.002000000001], [1592.002000000001, 1602.4720000000011], [1602.4720000000011, 1614.282000000001], [1614.282000000001, 1625.1820000000012], [1625.1820000000012, 1636.3520000000012], [1636.3520000000012, 1650.1920000000011], [1650.1920000000011, 1660.6220000000012], [1660.6220000000012, 1675.742000000001], [1675.742000000001, 1688.7220000000011], [1688.7220000000011, 1700.4620000000011], [1700.4620000000011, 1713.022000000001], [1713.022000000001, 1723.6820000000012], [1723.6820000000012, 1734.552000000001], [1734.552000000001, 1744.9320000000012], [1744.9320000000012, 1759.8320000000012], [1759.8320000000012, 1771.1720000000012], [1771.1720000000012, 1788.3220000000013], [1788.3220000000013, 1800.8020000000013], [1800.8020000000013, 1813.8520000000012], [1813.8520000000012, 1826.5420000000013], [1826.5420000000013, 1838.3620000000012], [1838.3620000000012, 1851.8820000000012], [1851.8820000000012, 1865.6020000000012], [1865.6020000000012, 1875.9820000000013], [1875.9820000000013, 1888.6620000000014], [1888.6620000000014, 1899.2320000000013], [1899.2320000000013, 1909.7120000000014], [1909.7120000000014, 1921.8520000000015], [1921.8520000000015, 1932.3420000000015], [1932.3420000000015, 1942.8170000000014], [1942.8170000000014, 1955.3820000000014], [1955.3820000000014, 1968.0920000000015], [1968.0920000000015, 1978.8720000000014], [1978.8720000000014, 1988.9020000000014], [1988.9020000000014, 2000.7720000000013], [2000.7720000000013, 2012.1820000000014], [2012.1820000000014, 2024.2320000000013], [2024.2320000000013, 2037.2720000000013], [2037.2720000000013, 2050.662000000001], [2050.662000000001, 2065.5420000000013], [2065.5420000000013, 2079.2920000000013], [2079.2920000000013, 2098.3820000000014], [2098.3820000000014, 2109.2520000000013], [2109.2520000000013, 2126.0120000000015], [2126.0120000000015, 2138.0020000000013], [2138.0020000000013, 2148.492000000001], [2148.492000000001, 2159.842000000001], [2159.842000000001, 2170.302000000001], [2170.302000000001, 2181.402000000001], [2181.402000000001, 2195.1020000000008], [2195.1020000000008, 2207.812000000001], [2207.812000000001, 2219.5320000000006], [2219.5320000000006, 2234.1120000000005], [2234.1120000000005, 2244.9820000000004], [2244.9820000000004, 2255.5220000000004], [2255.5220000000004, 2265.5220000000004], [2265.5220000000004, 2279.7260000000006], [2279.7260000000006, 2291.0320000000006], [2291.0320000000006, 2301.7720000000004], [2301.7720000000004, 2315.7120000000004], [2315.7120000000004, 2328.6320000000005], [2328.6320000000005, 2340.7210000000005], [2340.7210000000005, 2350.9920000000006], [2350.9920000000006, 2365.013000000001], [2365.013000000001, 2382.043000000001], [2382.043000000001, 2394.943000000001], [2394.943000000001, 2406.7630000000013], [2406.7630000000013, 2418.963000000001], [2418.963000000001, 2432.103000000001], [2432.103000000001, 2443.103000000001], [2443.103000000001, 2453.653000000001], [2453.653000000001, 2464.2430000000013], [2464.2430000000013, 2477.5330000000013], [2477.5330000000013, 2491.943000000001], [2491.943000000001, 2502.853000000001], [2502.853000000001, 2514.758000000001], [2514.758000000001, 2525.043000000001], [2525.043000000001, 2535.613000000001], [2535.613000000001, 2547.023000000001], [2547.023000000001, 2558.043000000001], [2558.043000000001, 2568.853000000001], [2568.853000000001, 2583.8430000000008], [2583.8430000000008, 2596.5930000000008], [2596.5930000000008, 2611.283000000001], [2611.283000000001, 2623.212000000001], [2623.212000000001, 2633.493000000001], [2633.493000000001, 2645.763000000001], [2645.763000000001, 2656.4230000000007], [2656.4230000000007, 2667.4830000000006], [2667.4830000000006, 2677.803000000001], [2677.803000000001, 2688.462000000001], [2688.462000000001, 2698.733000000001], [2698.733000000001, 2710.543000000001], [2710.543000000001, 2721.533000000001], [2721.533000000001, 2731.8630000000007], [2731.8630000000007, 2742.413000000001], [2742.413000000001, 2754.893000000001], [2754.893000000001, 2765.053000000001], [2765.053000000001, 2777.962000000001], [2777.962000000001, 2789.418000000001], [2789.418000000001, 2801.183000000001], [2801.183000000001, 2812.6330000000007], [2812.6330000000007, 2826.9180000000006], [2826.9180000000006, 2845.6430000000005], [2845.6430000000005, 2856.2530000000006], [2856.2530000000006, 2871.8930000000005], [2871.8930000000005, 2884.0830000000005], [2884.0830000000005, 2898.8830000000007], [2898.8830000000007, 2910.573000000001], [2910.573000000001, 2921.573000000001], [2921.573000000001, 2932.873000000001], [2932.873000000001, 2944.733000000001], [2944.733000000001, 2956.693000000001], [2956.693000000001, 2971.4930000000013], [2971.4930000000013, 2983.2230000000013], [2983.2230000000013, 2994.5130000000013], [2994.5130000000013, 3005.0430000000015], [3005.0430000000015, 3018.8130000000015], [3018.8130000000015, 3030.7730000000015], [3030.7730000000015, 3041.0930000000017], [3041.0930000000017, 3056.3630000000016], [3056.3630000000016, 3067.643000000002], [3067.643000000002, 3083.663000000002], [3083.663000000002, 3093.923000000002], [3093.923000000002, 3106.013000000002], [3106.013000000002, 3116.1830000000023], [3116.1830000000023, 3129.7930000000024], [3129.7930000000024, 3145.4730000000022], [3145.4730000000022, 3155.743000000002], [3155.743000000002, 3166.243000000002], [3166.243000000002, 3177.1540000000023], [3177.1540000000023, 3188.9330000000023], [3188.9330000000023, 3199.0940000000023], [3199.0940000000023, 3211.8240000000023], [3211.8240000000023, 3223.4240000000023], [3223.4240000000023, 3236.5540000000024], [3236.5540000000024, 3246.8240000000023], [3246.8240000000023, 3257.3640000000023], [3257.3640000000023, 3270.4040000000023], [3270.4040000000023, 3281.6340000000023], [3281.6340000000023, 3292.8240000000023], [3292.8240000000023, 3304.484000000002], [3304.484000000002, 3317.4040000000023], [3317.4040000000023, 3327.6740000000023], [3327.6740000000023, 3338.484000000002], [3338.484000000002, 3348.6140000000023], [3348.6140000000023, 3360.044000000002], [3360.044000000002, 3370.4440000000022], [3370.4440000000022, 3385.104000000002], [3385.104000000002, 3397.394000000002], [3397.394000000002, 3407.6540000000023], [3407.6540000000023, 3418.743000000002], [3418.743000000002, 3433.6830000000023], [3433.6830000000023, 3446.7030000000022], [3446.7030000000022, 3459.314000000002], [3459.314000000002, 3472.0740000000023], [3472.0740000000023, 3485.234000000002], [3485.234000000002, 3500.3840000000023], [3500.3840000000023, 3511.814000000002], [3511.814000000002, 3524.6140000000023], [3524.6140000000023, 3536.2840000000024], [3536.2840000000024, 3548.6340000000023], [3548.6340000000023, 3559.7880000000023], [3559.7880000000023, 3570.004000000002], [3570.004000000002, 3581.3040000000024], [3581.3040000000024, 3592.7640000000024], [3592.7640000000024, 3604.1540000000023], [3604.1540000000023, 3620.4330000000023], [3620.4330000000023, 3631.1540000000023], [3631.1540000000023, 3641.734000000002], [3641.734000000002, 3653.7030000000022], [3653.7030000000022, 3666.3190000000022], [3666.3190000000022, 3678.9440000000022], [3678.9440000000022, 3691.9740000000024], [3691.9740000000024, 3704.6340000000023], [3704.6340000000023, 3716.6630000000023], [3716.6630000000023, 3729.6740000000023], [3729.6740000000023, 3746.6340000000023], [3746.6340000000023, 3756.8840000000023], [3756.8840000000023, 3769.7640000000024], [3769.7640000000024, 3780.504000000002], [3780.504000000002, 3791.1140000000023], [3791.1140000000023, 3807.611000000002], [3807.611000000002, 3818.841000000002], [3818.841000000002, 3834.591000000002], [3834.591000000002, 3847.671000000002], [3847.671000000002, 3858.2210000000023], [3858.2210000000023, 3868.8110000000024], [3868.8110000000024, 3881.2210000000023], [3881.2210000000023, 3893.2610000000022], [3893.2610000000022, 3905.9760000000024], [3905.9760000000024, 3917.571000000002], [3917.571000000002, 3927.6410000000024], [3927.6410000000024, 3940.531000000002], [3940.531000000002, 3954.281000000002], [3954.281000000002, 3967.861000000002], [3967.861000000002, 3979.331000000002], [3979.331000000002, 3990.701000000002], [3990.701000000002, 4003.791000000002], [4003.791000000002, 4016.941000000002], [4016.941000000002, 4028.7010000000023], [4028.7010000000023, 4043.9810000000025], [4043.9810000000025, 4059.1410000000024], [4059.1410000000024, 4074.2010000000023], [4074.2010000000023, 4090.1610000000023], [4090.1610000000023, 4103.151000000003], [4103.151000000003, 4115.471000000002], [4115.471000000002, 4127.911000000002], [4127.911000000002, 4141.3510000000015], [4141.3510000000015, 4151.421000000001], [4151.421000000001, 4167.081000000001], [4167.081000000001, 4179.821000000001], [4179.821000000001, 4193.901000000001], [4193.901000000001, 4205.9310000000005], [4205.9310000000005, 4219.001], [4219.001, 4233.591], [4233.591, 4248.1410000000005], [4248.1410000000005, 4258.491000000001], [4258.491000000001, 4271.131000000001], [4271.131000000001, 4282.131000000001], [4282.131000000001, 4293.491000000001], [4293.491000000001, 4306.9310000000005], [4306.9310000000005, 4317.761], [4317.761, 4330.2210000000005], [4330.2210000000005, 4342.631], [4342.631, 4353.961], [4353.961, 4365.381], [4365.381, 4378.351000000001], [4378.351000000001, 4391.081], [4391.081, 4402.821], [4402.821, 4413.981], [4413.981, 4425.630999999999], [4425.630999999999, 4436.455999999999], [4436.455999999999, 4448.310999999999], [4448.310999999999, 4463.370999999999], [4463.370999999999, 4475.710999999999], [4475.710999999999, 4486.9259999999995], [4486.9259999999995, 4496.931], [4496.931, 4510.8009999999995], [4510.8009999999995, 4527.290999999999], [4527.290999999999, 4542.330999999999], [4542.330999999999, 4554.730999999999], [4554.730999999999, 4573.250999999999], [4573.250999999999, 4589.730999999999], [4589.730999999999, 4602.470999999999], [4602.470999999999, 4612.830999999998], [4612.830999999998, 4625.660999999998], [4625.660999999998, 4636.490999999998], [4636.490999999998, 4647.290999999998], [4647.290999999998, 4658.500999999998], [4658.500999999998, 4672.370999999998], [4672.370999999998, 4686.280999999998], [4686.280999999998, 4699.863999999998], [4699.863999999998, 4712.843999999997], [4712.843999999997, 4723.863999999998], [4723.863999999998, 4735.663999999998], [4735.663999999998, 4748.333999999998], [4748.333999999998, 4758.673999999998], [4758.673999999998, 4771.232999999998], [4771.232999999998, 4783.363999999999], [4783.363999999999, 4793.833999999999], [4793.833999999999, 4806.433999999999], [4806.433999999999, 4817.873999999999], [4817.873999999999, 4831.263999999999], [4831.263999999999, 4844.022999999999], [4844.022999999999, 4856.982999999999], [4856.982999999999, 4867.463999999999], [4867.463999999999, 4879.232999999999], [4879.232999999999, 4890.442999999999], [4890.442999999999, 4901.482999999999], [4901.482999999999, 4912.883999999999], [4912.883999999999, 4924.9039999999995], [4924.9039999999995, 4938.263999999999], [4938.263999999999, 4948.368999999999], [4948.368999999999, 4959.673999999999], [4959.673999999999, 4973.433999999999], [4973.433999999999, 4989.183999999999], [4989.183999999999, 5001.913999999999], [5001.913999999999, 5014.533999999999], [5014.533999999999, 5025.352999999999], [5025.352999999999, 5036.993999999999], [5036.993999999999, 5049.573999999999], [5049.573999999999, 5062.453999999999], [5062.453999999999, 5073.763999999999], [5073.763999999999, 5086.213999999999], [5086.213999999999, 5102.993999999999], [5102.993999999999, 5113.812999999999], [5113.812999999999, 5125.533999999999], [5125.533999999999, 5141.333999999999], [5141.333999999999, 5152.453999999999], [5152.453999999999, 5164.623999999999], [5164.623999999999, 5175.352999999999], [5175.352999999999, 5186.232999999999], [5186.232999999999, 5200.933999999999], [5200.933999999999, 5211.494], [5211.494, 5224.982999999999], [5224.982999999999, 5237.393999999999], [5237.393999999999, 5250.963999999999], [5250.963999999999, 5263.406999999999], [5263.406999999999, 5275.813999999999], [5275.813999999999, 5287.664], [5287.664, 5298.664], [5298.664, 5308.773], [5308.773, 5319.654], [5319.654, 5330.853], [5330.853, 5342.8640000000005], [5342.8640000000005, 5354.264], [5354.264, 5365.054], [5365.054, 5375.804], [5375.804, 5386.874], [5386.874, 5398.334], [5398.334, 5409.574], [5409.574, 5420.143999999999], [5420.143999999999, 5434.253999999999], [5434.253999999999, 5444.753999999999], [5444.753999999999, 5455.602999999999], [5455.602999999999, 5470.083999999999], [5470.083999999999, 5484.633999999999], [5484.633999999999, 5495.272999999999], [5495.272999999999, 5508.643999999999], [5508.643999999999, 5523.244], [5523.244, 5535.973999999999], [5535.973999999999, 5546.022999999999], [5546.022999999999, 5559.243999999999], [5559.243999999999, 5572.043999999999], [5572.043999999999, 5582.643999999999], [5582.643999999999, 5592.982999999999], [5592.982999999999, 5603.213999999999], [5603.213999999999, 5613.793999999999], [5613.793999999999, 5630.182999999999], [5630.182999999999, 5641.053999999999], [5641.053999999999, 5651.713999999999], [5651.713999999999, 5666.373999999999], [5666.373999999999, 5680.053999999999], [5680.053999999999, 5698.553999999999], [5698.553999999999, 5713.393999999999], [5713.393999999999, 5726.833999999999], [5726.833999999999, 5737.066999999999], [5737.066999999999, 5752.173999999999], [5752.173999999999, 5762.613999999999], [5762.613999999999, 5774.753999999999], [5774.753999999999, 5788.133999999999], [5788.133999999999, 5802.373999999999], [5802.373999999999, 5813.173999999999], [5813.173999999999, 5829.522999999999], [5829.522999999999, 5842.074], [5842.074, 5852.563999999999], [5852.563999999999, 5863.897999999999], [5863.897999999999, 5875.093999999999], [5875.093999999999, 5887.343999999999], [5887.343999999999, 5901.413999999999], [5901.413999999999, 5913.833999999999], [5913.833999999999, 5923.982999999999], [5923.982999999999, 5937.263999999999], [5937.263999999999, 5951.053999999999], [5951.053999999999, 5962.852999999999], [5962.852999999999, 5974.654999999999], [5974.654999999999, 5985.423999999999], [5985.423999999999, 5996.218999999999], [5996.218999999999, 6006.938999999999], [6006.938999999999, 6024.619], [6024.619, 6035.389], [6035.389, 6049.089], [6049.089, 6062.699], [6062.699, 6073.7789999999995], [6073.7789999999995, 6084.129], [6084.129, 6097.919], [6097.919, 6108.379], [6108.379, 6123.499], [6123.499, 6135.5289999999995], [6135.5289999999995, 6146.299], [6146.299, 6159.799], [6159.799, 6173.459], [6173.459, 6187.879], [6187.879, 6201.489], [6201.489, 6213.749], [6213.749, 6226.929], [6226.929, 6237.039], [6237.039, 6256.228999999999], [6256.228999999999, 6267.308999999999], [6267.308999999999, 6277.418999999999], [6277.418999999999, 6291.018999999999], [6291.018999999999, 6302.428999999999], [6302.428999999999, 6313.688999999999], [6313.688999999999, 6325.428999999999], [6325.428999999999, 6340.708999999999], [6340.708999999999, 6353.538999999999], [6353.538999999999, 6365.1889999999985], [6365.1889999999985, 6376.258999999998], [6376.258999999998, 6388.528999999999], [6388.528999999999, 6400.628999999999], [6400.628999999999, 6412.898999999999], [6412.898999999999, 6424.968999999999], [6424.968999999999, 6442.258999999999], [6442.258999999999, 6453.288999999999], [6453.288999999999, 6465.268999999998], [6465.268999999998, 6476.928999999998], [6476.928999999998, 6491.4389999999985], [6491.4389999999985, 6503.227999999998], [6503.227999999998, 6514.428999999998], [6514.428999999998, 6525.218999999998], [6525.218999999998, 6536.968999999998], [6536.968999999998, 6547.138999999998], [6547.138999999998, 6557.788999999998], [6557.788999999998, 6569.198999999998], [6569.198999999998, 6581.438999999998], [6581.438999999998, 6593.468999999997], [6593.468999999997, 6612.868999999997], [6612.868999999997, 6623.968999999997], [6623.968999999997, 6635.948999999997], [6635.948999999997, 6650.898999999997], [6650.898999999997, 6663.528999999997], [6663.528999999997, 6675.918999999997], [6675.918999999997, 6686.098999999997], [6686.098999999997, 6701.178999999997], [6701.178999999997, 6713.248999999997], [6713.248999999997, 6723.878999999997], [6723.878999999997, 6735.3179999999975], [6735.3179999999975, 6747.288999999997], [6747.288999999997, 6758.948999999997], [6758.948999999997, 6771.6389999999965], [6771.6389999999965, 6788.817999999997], [6788.817999999997, 6802.038999999996], [6802.038999999996, 6814.538999999996], [6814.538999999996, 6826.198999999996], [6826.198999999996, 6838.578999999996], [6838.578999999996, 6849.128999999996], [6849.128999999996, 6864.338999999996], [6864.338999999996, 6875.238999999996], [6875.238999999996, 6890.658999999996], [6890.658999999996, 6900.978999999996], [6900.978999999996, 6912.658999999996], [6912.658999999996, 6923.078999999996], [6923.078999999996, 6934.868999999996], [6934.868999999996, 6945.158999999996], [6945.158999999996, 6957.328999999996], [6957.328999999996, 6971.828999999996], [6971.828999999996, 6983.078999999996], [6983.078999999996, 6994.998999999996], [6994.998999999996, 7005.688999999996], [7005.688999999996, 7016.637999999995], [7016.637999999995, 7029.538999999995], [7029.538999999995, 7041.7189999999955], [7041.7189999999955, 7053.018999999996], [7053.018999999996, 7063.198999999996], [7063.198999999996, 7074.758999999996], [7074.758999999996, 7085.258999999996], [7085.258999999996, 7096.488999999996], [7096.488999999996, 7108.858999999996], [7108.858999999996, 7120.048999999995], [7120.048999999995, 7134.158999999995], [7134.158999999995, 7146.058999999995], [7146.058999999995, 7158.441999999995], [7158.441999999995, 7170.513999999995], [7170.513999999995, 7188.803999999995], [7188.803999999995, 7201.203999999994], [7201.203999999994, 7217.993999999994], [7217.993999999994, 7233.203999999994], [7233.203999999994, 7244.062999999995], [7244.062999999995, 7254.732999999995], [7254.732999999995, 7269.843999999995], [7269.843999999995, 7282.373999999994], [7282.373999999994, 7294.343999999995], [7294.343999999995, 7306.352999999995], [7306.352999999995, 7318.232999999995], [7318.232999999995, 7332.753999999994], [7332.753999999994, 7345.903999999994], [7345.903999999994, 7356.9729999999945], [7356.9729999999945, 7368.493999999994], [7368.493999999994, 7378.783999999994], [7378.783999999994, 7391.573999999994], [7391.573999999994, 7404.312999999994], [7404.312999999994, 7418.133999999994], [7418.133999999994, 7428.928999999994], [7428.928999999994, 7439.0039999999935], [7439.0039999999935, 7450.873999999993], [7450.873999999993, 7464.022999999994], [7464.022999999994, 7474.663999999993], [7474.663999999993, 7484.993999999993], [7484.993999999993, 7497.803999999994], [7497.803999999994, 7510.0439999999935], [7510.0439999999935, 7522.0039999999935], [7522.0039999999935, 7532.988999999993], [7532.988999999993, 7545.5439999999935], [7545.5439999999935, 7558.062999999994], [7558.062999999994, 7568.262999999994], [7568.262999999994, 7579.033999999993], [7579.033999999993, 7590.7939999999935], [7590.7939999999935, 7601.512999999994], [7601.512999999994, 7611.973999999994], [7611.973999999994, 7627.783999999994], [7627.783999999994, 7640.892999999995], [7640.892999999995, 7651.543999999994], [7651.543999999994, 7661.9239999999945], [7661.9239999999945, 7673.281999999995], [7673.281999999995, 7686.053999999995], [7686.053999999995, 7698.323999999995], [7698.323999999995, 7710.043999999995], [7710.043999999995, 7722.613999999995], [7722.613999999995, 7735.613999999995], [7735.613999999995, 7751.123999999995], [7751.123999999995, 7765.283999999995], [7765.283999999995, 7777.772999999995], [7777.772999999995, 7790.283999999995], [7790.283999999995, 7800.562999999996], [7800.562999999996, 7810.8529999999955], [7810.8529999999955, 7823.583999999995], [7823.583999999995, 7833.692999999996], [7833.692999999996, 7844.6429999999955], [7844.6429999999955, 7859.5539999999955], [7859.5539999999955, 7873.223999999996], [7873.223999999996, 7883.333999999995], [7883.333999999995, 7896.482999999996], [7896.482999999996, 7908.123999999995], [7908.123999999995, 7921.043999999995], [7921.043999999995, 7931.5939999999955], [7931.5939999999955, 7942.253999999995], [7942.253999999995, 7954.543999999995], [7954.543999999995, 7965.8929999999955], [7965.8929999999955, 7980.153999999996], [7980.153999999996, 7990.403999999996], [7990.403999999996, 8004.1029999999955], [8004.1029999999955, 8016.522999999996], [8016.522999999996, 8028.033999999996], [8028.033999999996, 8039.043999999996], [8039.043999999996, 8056.025999999996], [8056.025999999996, 8069.2729999999965], [8069.2729999999965, 8087.293999999996], [8087.293999999996, 8098.073999999996], [8098.073999999996, 8114.043999999996], [8114.043999999996, 8125.053999999996], [8125.053999999996, 8137.173999999996], [8137.173999999996, 8150.553999999996], [8150.553999999996, 8161.533999999996], [8161.533999999996, 8173.892999999996], [8173.892999999996, 8185.5629999999965], [8185.5629999999965, 8196.822999999997], [8196.822999999997, 8210.373999999996], [8210.373999999996, 8220.463999999996], [8220.463999999996, 8230.813999999997], [8230.813999999997, 8242.483999999997], [8242.483999999997, 8252.842999999997], [8252.842999999997, 8268.483999999997], [8268.483999999997, 8278.832999999997], [8278.832999999997, 8290.223999999997], [8290.223999999997, 8301.012999999997], [8301.012999999997, 8313.163999999997], [8313.163999999997, 8324.832999999997], [8324.832999999997, 8335.063999999997], [8335.063999999997, 8347.102999999997], [8347.102999999997, 8359.502999999997], [8359.502999999997, 8369.762999999997], [8369.762999999997, 8382.573999999997], [8382.573999999997, 8392.673999999997], [8392.673999999997, 8408.133999999996], [8408.133999999996, 8418.713999999996], [8418.713999999996, 8436.103999999996], [8436.103999999996, 8451.053999999996], [8451.053999999996, 8462.433999999996], [8462.433999999996, 8479.073999999995], [8479.073999999995, 8489.113999999996], [8489.113999999996, 8500.492999999997], [8500.492999999997, 8514.673999999997], [8514.673999999997, 8517.309999999998]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1253, 2351, 3170, 3794, 4695, 5988, 7151, 8517]}
{"example_id": "mit126@@MIT2_003SCF11_lec13_300k", "text": ["J. KIM VANDIVER: If I wanted you to remember three equations,  really commit them to memory, that'd allow you to essentially  do everything that we've done, they'd be the following three. ", "The first would essentially be Newton's second law.  ", "We use that all the time, and in vector form,  summation of the external forces on a rigid body  must be equal to the time rate of change ", "of the linear momentum of the rigid body.  And that we know is equal to its mass times the acceleration ", "of its center of mass with respect to an inertial frame,  and this slash o means with respect to an inertial frame.  That's Newton's second law, and of course we ", "use it all the time.  Now Euler added to what Newton worked out for us. ", "And let me actually just point out over here.  So P with respect to o then is M velocity  of G with respect to the inertial frame-- vector, ", "vector, vector.  OK, what Euler taught us was that the summation  of the torques about a point A is the time rate of change ", "of the angular momentum with respect to that point  plus the velocity of the point cross P with respect to o. ", "So that's our general equation for angular momentum  and [? R ?] for torques.  And remember, H with respect to A is the cross product of R-- ", "how do I want to write this guy?  ", "I don't want to save that.  ", "So we define angular momentum.  It's just a cross product of the distance from the point  that we're at to the-- I didn't write this right. ", "This is A with respect to G cross P o, ", "so that's our general definition of angular momentum.  And finally, the third equation is the one  that I showed you last time, which does appear in the book  but not until you get into chapter 21, ", "and that is that you can write H with respect  to A as H with respect to G plus [? RG/A ?] cross P with respect ", "to o.   There's something wrong here.  Matt, what have I done wrong?  MATT: Do you want a sum that will give you ", "the angle [INAUDIBLE].  J. KIM VANDIVER: Yeah, it just slipped my brain  because I don't do it.  I don't think about this.  This is the-- yeah, it's a summation.  There we go. ", "In general, this is a summation, and it  is the location of all the little particles i with respect ", "to A cross the linear momentum of each particle [? mi ?] Vi ", "with respect to o.  And we add all that up, that's the definition  of angular momentum.  And we generally for rigid bodies then  reduce that to saying that it's a mass moment of inertia ", "matrix computed with respect to A times omega x, omega y,  omega z.  That's how we generally express this. ", "But the third equation I want to come to is this one.  Yeah?  AUDIENCE: That's not [INAUDIBLE], ", "but it's not really with respect to A in general.   [INAUDIBLE]  ", "J. KIM VANDIVER: This is i with respect to A. Let's just  do this because I've just slipped a bit this morning.  OK, I'm thinking too much about where I'm going here. ", "This equation I introduced last time.  The book doesn't make a big deal about this at all,  but it's really a fundamental equation  that we proved from scratch very simply last time. ", "And this equation allows you to solve lots of problems  without even, for example, knowing the parallel axis  theorem.  It'll just get you through it even without knowing things ", "like that.  So with these three equations, you can do all the problems  that we've done, and I'm going to do two or three examples  this morning, and including coming back  to a discussion of the parallel axis theorem. ", "OK, so these three are the ones I recommend that you remember  because everything else will flow from-- we know,  like, we have special cases. ", "So when A is at G, then this just ", "reduces to H with respect to G. When  there's no vel-- when A doesn't move, this term goes away.  Those are all special cases, which you can just  substitute in the numbers and discover for yourself if you ", "don't remember those.  But these are the three equations  you want to have in your kit to use.  ", "So last time, I kind of classified problems  in four different classes depending  on the simplifications.  And the class 4 problem was the more general case,  and that's when the point A is allowed to move in general, ", "and that last equation we had can  be very handy in those cases.  And I mentioned a problem last time, but I didn't work it out. ", "And that's simply this problem, where  you've got a block, maybe a box on a cart,  and you're accelerating the cart. ", "At what point will the block tip over?  So this one I've put a nail right here,  so the block can't slide, but it will tip about this point. ", "So if I accelerate it slowly, nothing happens.  If I accelerate it fast enough, it tips around that point.  So that's the key.  Identifying the point's have the work, so that's the key bit. ", "What's the greatest acceleration that I can have  so that this block will just not quite tip?  That's the problem. ", "If you didn't have the nail there,  there's also the possibility that it'll  slip without tipping over.  OK, so that's another problem that we'll  address at another moment.  OK, so let's do this problem quickly. ", " So this is our problem, and I've got a handle here, ", "and I'm pushing on it with a force.  I've got a couple of wheels.  This is M1.  This is M2, and I'll have an inertial frame here X, Y. ", "So the question is what's the maximum force  that I can apply such that the block won't tip over?  And I've got a little nub there, so this thing can't slide. ", "OK, and this is my point A because that's the point  I expect it to rotate around.  The X, Y, and Z is coming out of the board. ", "OK, so Newton's second, so we apply it first.  From Newton's second law, we say the sum  of the forces, in this case, on the system. ", "By the system I mean M1 and M2.  We want to remember that you can collect things together  at times.  So the sum of forces on the system, in this case, ", "is then M1 plus M2, and it's the acceleration of that point, ", "and in this case we are just going to do in the X-direction  because we know that's the only one where there's any action. ", "So the sum of the forces in the X-direction  is the total mass of the system times the acceleration  in the X-direction.  So the X double dot we're looking  for is F over M1 plus M2. ", "So this we're trying to find out what the maximum value for this  is.  ", "Now next we can apply the torque equation  because that's the key one.  And that's the sum of the torques-- now it's  just on the box-- at with respect to point A. ", "And we can say, well, looking at that,  we need a free body diagram now of our box.   You've got an M1g down. ", " And you might have a normal force upwards, generally, ", "but now we want to think about where  are the forces going to be acting on the box  when it's just at this point that it's just barely about-- ", "just barely starts to tip.   So we're hypothesizing that here at A, there'll  be some upward force, right? ", "And it's going to take care of the static equilibrium,  but it also could enter into our moment calculation  if we weren't clever with respect to where ", "we calculate this point.   So the sum of the torques about this point,  we don't have to bring this one into it. ", "We do have to consider this one.  So the [? R ?] here cross that force, so we get a moment, Mg, ", "and I need some dimensions on my box.  We'll call it b and a height h. ", "So the moment arm, this axon is b/2,  and it's in the minus [? z ?] direction,  so I get a minus M1g b/2 k hat. ", "Those are my external torques on the box  because the normal force supporting it on the floor  is acting at A now.  ", "And this must be from our second formula, ", "dH with respect to A/dt plus the velocity of A  with respect to o, cross P with respect to o.  And P with respect to o was [? M1VG ?] with respect ", "to o, all right?  So we need to know what is the velocity of A  with respect to o. ", " But we're only allowing motions in this direction.  This has to be evaluated in the inertial frame, ", "so we have a coordinate X here.  So it's going to be some X dot, and I'll  give you a capital I hat just remind you  that's in the inertial frame. ", "What is the velocity of G with respect to o?  ", "AUDIENCE: Would it be the same?  J. KIM VANDIVER: Yeah.  You know, in this condition we're  saying we want the block not to quite tip over,  and that means it's moving with the cart at exactly  the same velocity, so it's the same. ", "It's also equal to A with respect to o,  but if that's the case, what's the cross product  between velocity of A with respect to o  and G with respect to o?  Ah, so that one goes to zero. ", " That's because of this.  ", "OK, so that leaves us with-- we don't  have to deal with these terms, but we  do need to compute H with respect to A. ", "And now I'm going to use this formulation because it makes  this problem easy to do and not have  to deal with parallel axes or any of that.  So I'm going to use my third equation, ", "and it says that this is H with respect  to G plus RG with respect to A cross P with respect to o. ", " So you notice I chose this problem kind of on purpose  today because I started saying, here's three ", "really important equations.  We use all three to do this problem.  OK, so now we're exercising the third.  ", "So my block here, since we're dealing  with angular momentum of rigid bodies,  I now have to think in terms of a coordinate system attached ", "to the block, and I'll formulate it  so it's lined up the same way. ", "So this is a x1 I'll call it, y1, and z1.  But x1 and big X, these are in the same direction, ", "and so is z and z1 and capital [? E. ?]  And that means that my I hats are the same as the unit  vectors associated with my coordinate system attached ", "to the body.  Remember, this is this body-fixed coordinate system  that allows us to compute moments of inertia,  and I'm going to have this located at G, OK?  ", "So the only rotation that we're allowing in this problem.  This is basically a 2D planar motion problem.  It could conceivably have x and y translations ", "and a z rotation constrained in the y,  so it has possible rotation and translation.  So the only omega we're considering is this omega z, ", "and so we'll proceed to use it to compute H.  So we use this formula.  ", "So H with respect to G is-- just I'm  doing a couple of these things sort of carefully just  to remind you of where these things all come from.  This is I with respect to G, and in this case, 0 0 omega z. ", "And we come out of this then the only--  are these principal axes?  So if they are, this is diagonal, right, ", "so I've located these through G.  Taken into consideration the symmetries,  I know because the symmetry of these are principal axes.  Therefore, this is a diagonal mass moment of inertia matrix, ", "so when I calculate to do out the multiplication,  I get Izz with respect to G omega z k-hat. ", "There's only one vector component of H  that comes out of that, and that's Hz  is that Izz G omega z k-hat. ", "And there are two other possible components of H,  but they're both 0.  There's no other rotate-- there is no angular momentum ", "in the x- or y-directions.   OK.  ", "[? RG/A ?] in this problem is from here-- this  is point A-- two there, so RG respect to A is b/2 i plus ", "h/2 k.  It's the location of just the position of G with respect  to A. [? b/2 ?] over [? h/2 up. ?] So in order ", "to complete my calculation of H of A,  I need to get the second piece of the [? RG/A ?] cross P/o.  ", "So [? RG/A ?] is my b/2 i plus h/2 k cross. ", "And then my linear momentum is M1 x1 dot ", "in the i hat direction.  And it'll either be a capitalize I or a lowercase i.  They're the same, all right?  So this is my second term the RG cross  P. i cross i, these two-- this pair gives you nothing, ", "so it's k cross i is j, and so you get Izz with respect  to G omega z.  And then a k term from here M1 h/2 ", "x dot, and it's also in the k.   And that's my total angular momentum now with respect to A. ", "AUDIENCE: [INAUDIBLE]?  J. KIM VANDIVER: And I think-- just a sec-- k-- you're right.  Wait a second. ", "k cross i should give me a j, right?  AUDIENCE: [INAUDIBLE].  ", "Professor?  J. KIM VANDIVER: Yeah, k cross i gives me a positive j, right?  [INTERPOSING VOICES]  [? AUDIENCE: RGA ?] should be a positive j based off ", "of your [INAUDIBLE] system.  J. KIM VANDIVER: Ah, yeah, yeah.  This is a good catch.  All right, so what happens now? ", "Now we get j cross i, gives you a minus k.  ", "Now that should be OK, and let's see if that  agrees with what I wrote here.  Yes, they did it right in the paper.  Just couldn't put it right on the board.  ", "So now the sum of the torques with respect to A,  we've already figured out that it's minus M1 g b/2 k ", "hat must be equal to the time rate of change  from our second equation dH dt. ", "And we've already figured out that the second term goes away.  So it's just then the time rate of change of that expression.  ", "Oh, I think we could probably do it straight away,  so the time rate of change, the derivative of this,  you get omega z dot.  You get an x double dot.  The k doesn't rotate, so there's nothing that comes from that. ", "If you take that time derivative,  you get Izz with respect to G omega z dot minus M1 h/2 ", "x double dot, and these are still all in the k direction.  And that's an equation that only has  k hat terms on the left hand side, k on the right, ", "so this is just one potential component of the torque.  And so we can drop the k's at this point.  And we now have an expression for the external torques ", "in terms of the accelerations of the system.  This is essentially theta double dot [? if it ?] tips,  and that's the linear acceleration.  But now then the key to the problem ", "is we're trying to find out when just at the point  it might tip but doesn't, so what's omega dot-- omega z dot?  OK, so what we're looking for we let omega z ", "dot or require that to be 0.  I mean this makes this even simpler,  and you find out then that M1 g [? b/2 ?] ", "equals M1 h/2 x double dot.  And I have to add minus signs on both sides,  so I got rid of them.  And the M1s go away, and I can solve for h for x double dot, ", "and that's going to be g b/h.   OK, and we started off saying what's the maximum force? ", "So this is now x max, the acceleration maximum  and the force maximum is just equal to M1 plus M2 ", "x dot max for-- and let's see if that makes sense. ", "If b and h were equal-- that's sort of a common sense  argument here-- b and h were equal, ", "that tells you that you could accelerate 1g at 1g-- just 1g  and that makes sense.  The Mg here is [? putting a ?] restoring moment down of the MG ", "[? b/2. ?] And the acceleration of this is putting  an overturning moment on it in the other direction that would  be Mg [? h/2, ?] and if h and b are the same, ", "then it would be exactly 1g.  Now so that's the answer the problem.  If you want to do live dangerously from the beginning, ", "you could have done this with a fictitious force.  I just mention in passing I'm not recommending  that you generally go there.  This was a very straightforward way of doing it.  We just started with these three laws, ", "and we just worked our way through the problem and all  the way to the end, and it fell out.  If you didn't want to live dangerously though,  you could say that when you accelerate this, ", "you can think of there being a fictitious force that  is equal to minus the mass of this object  times the acceleration on the center of gravity of force ", "that is pulling it in the other direction.  So you could think of there being a force M1X double dot ", "opposite to the direction of the acceleration.  This is minus the mass times the acceleration.  It's the fictitious force.  Here's your point A. Here's gravity M1 g. ", "This is the distance b/2.   This is the height h/2, and you could say just  at that moment of balance, the sum of those two moment ", "should be 0-- the sub of the external torques.   And you would end up with a M1 x double dot ", "h/2 minus M1 g [? b/2, ?] and you come up  with the same answer.  But for most of this that takes a real leap of faith ", "to do that to convince yourself that you're right, right?  You got to know a lot of dynamics  and remember all the parts and pieces  to be able to just go there. ", "But if you do it just carefully, those three equations,  it'll all worked out.  Yeah?  AUDIENCE: Why is omega z [INAUDIBLE]?  J. KIM VANDIVER: Because as long as  the condition satisfied that it doesn't tip over, ", "what's the rotation rate of this block?  AUDIENCE: 0.  J. KIM VANDIVER: 0.  So we're not solving for dynamics in this problem  of the thing tipping. ", "It isn't rolling on us.  We're coming just up to the point  that it tips, and say we're not going any farther.  And so we just require the two moments-- the one essentially ", "caused by the acceleration, this fictitious force, that's  got to be just in equilibrium with the restoring moment  provided by Mg.  That's essentially the problem we've worked, ", "but we've done it really carefully just using  these three laws.  And the real problem though if you didn't have the nail here  is if now if you need to test your solution, ", "could you ever actually reach that rate of acceleration  before the thing starts sliding on you?  And, you know, maybe not.  This thing slides before it tips, OK? ", "AUDIENCE: Would the fictitious force take into account M2?  J. KIM VANDIVER: Take into account M2?  AUDIENCE: Yes.  J. KIM VANDIVER: So the angular momentum ", "was all calculated with respect to the rigid body M1, right?  The only reason M2 entered into it  this is the way things happen in real life.  It's just a real problem. ", "It's a box on a cart, and is it going to tip over,  and you're pushing on it.  How hard can I push?  To do that problem you just have to consider  these to begin with so that you realize that, ", "oh, the acceleration involves both of these masses,  but the angular momentum part of the problem  involves only the boxes tipping. ", "So problems even as simple as this one looks has  their little complications, and you've  got to work through them.  So just so we had to treat the body as a two-body system ", "to start with, and then look at angular momentum for just  the box.  AUDIENCE: Does the pin or screw exert  a force on the [INAUDIBLE]?  ", "J. KIM VANDIVER: Yes, absolutely, mm-hmm.  Does it create a moment?  No, and that's why we don't have to consider it.  I could have put it in there and probably should have. ", "If I had done a free body diagram here,  you could still say that there's a reaction force upwards here. ", "And I'll call it Ry and another one this direction  I'll call Rx.  And when computing moments about this point, neither of them ", "enter into the problem.  And that's why we like to do our calculations for angular  momentum with respect to points around which the body rotates ", "because that allows us to not have  to solve for those unknown forces that pop up there,  so yeah, indeed there are forces there.  OK, got it figured out. ", "So we've talked a little tiny bit about parallel axis  theorem, and so I'm going to consider this a slender rod.  ", "I can spin it about one of its printable axes and calculate  its angular momentum of whatever I need,  and if I move it over to an axis that's-- I just move it over ", "by a little bit.  Let's say this is the x-axis here in my body,  and this is the z, so it's at omega z. ", "And I move my point and around which I am rotating over  by a small amount A, and that's this distance between these two  holes.  And by parallel axis theorem, we could say, well, ", "now there's a mass moment of inertia with respect to A,  which is the mass moment of inertia with respect to g,  which is [? Ml ?] squared over 12, if this is the length, ", "plus the mass times this distance squared.  We know how to do that.  But now what happens if I take this stick, my slender rod, ", "and here's my original x, y, z.  And I want to move it, my point A, my stick now ", "I'm going to move it over by an amount a and up by an amount c  so that it's now up here with respect to this point. ", "So this stick has been like this,  and now I'm going to then rotate it about that.  That's the simple case.  Now I want to rotate it about this axis  when it's moved over to like that. ", " So not only have I moved it-- so here's the original problem--  like this, but now I move it up and over-- maybe ", "I'll do it there-- and now I spin it.  And I'm interested in angular momentum about this point,  so now it's dynamically unbalanced for sure.  This thing is trying to wobble, and it's ", "been pushed up and over, so is there  a way to get-- how do we solve that problem?  How do we compute the torques for this problem? ", "Well, we could try to go at it with parallel access  to start with, but you don't know how to do that in general  for this problem.  So what do we go to? ", "We go back to those three equations,  and just start there, and it'll all fall out.  I'm going to do this kind of briefly for this problem,  so I want to compute H with respect to A H with respect ", "to G plus RG with respect to A cross P.  And now this is [? RG/A ?] is this vector here, ", "that position vector, OK?   And the only rotation is omega z.  This is our z-axis. ", "So I can write this as Izz with respect to G, 0, 0,  omega z plus my [? RG/A ?] cross P/o, and that in this problem-- ", "let's get the vector right this time-- it's  a in the i direction plus c in the k direction cross. ", "Now we need to know what's P with respect to o,  but that's just the velocity of this so the center of mass, ", "which is now here.  The velocity is omega cross r, so when  you do that-- you've done that problem lots of times--  it's this distance, so perpendicular distance ", "[? across ?] k.  It's got to be going into the board  if it's spinning like this.  We know the answer's got to come out plus j,  and it's r-- it's A omega z in the j-direction cross Ma omega ", "z, but it is in the j hat direction.  That's your linear momentum, and this is [? RG/A ?]  cross with a linear momentum.  ", "This here is M velocity of G here with respect to o.  That's this term, so we carry out this calculation ", "and we get-- and I need a j, OK.  So i cross j gives me a k, so I'll get 2, ", "and this is a diagonal matrix because we  began with a set of principal axes for our stick,  so this term is Izz with respect to G. ", "I shouldn't have written zz here, just i with respect to z.  We multiply this out.  We pick up just this term omega z k hat plus i cross j is k, ", "so that's Ma squared omega [? zk, ?] and k cross j  is minus i minus M ac omega z in the i hat direction. ", " So this is my angular momentum, and reminding, it is a vector.  This has got components in the k and the i directions. ", "", "I've rewritten it here.  This also could be written-- this H with respect to A  is I with respect to A times the rotation vector. ", "If we had just set out with this problem,  and said we're going-- if we know the mass moment of inertia  matrix computed with respect to this point  and multiplied it by our rotation rate vector, ", "we should have gotten the same answer.  So we didn't do that.  We just worked it out using just this formula,  but we've essentially discovered the answer. ", "This is the rotation around k.   This is the Izz term with respect to A,  and it really looks like the familiar parallel axis piece. ", "It's the amount that you moved this axis over,  and the axis you're spinning around, you moved it over A.  And you know the parallel axis theorem just  says add Ma squared, and you've got the answer. ", "But we also moved it up, and it gave us another term.  What do you suppose in that term is?  So this is Izz with respect to A, this term. ", "By parallel axis theorem, you're familiar with it.  This one is I, and this is xz with respect ", "in the A coordinate system.  OK, we've created-- we've made this thing unbalanced.  The angular momentum vector no longer ", "points in the same direction as the rotation.  It has a k component and an I component,  and sure enough, when I spend that thing like that,  I feel that additional torque out around my hand ", "down here where I'm holding it.  This thing is going-- trying to pull it back and forth.  So we have essentially just shown--  we have just arrived at a more complicated parallel axis ", "theorem by just using this basic formula.  So Williams in the dynamics-- that second handout  from Williams has actually given us a general formulation ", "for parallel axis theorem.   So this is just handy to know.  I'll just give it to you, and if you have a problem some day, ", "where you just like to go directly to this statement,  so now I'm just going to say, in general, we  could have moved over by A, up by c and actually  into the board by b, so x, I'm moving A. y, I'm moving b. ", "z, I'm moving c.  OK, so you could have all those possible moves of the new point  about which you're rotating.  Yes?  AUDIENCE: For the [INAUDIBLE] matrix i with respect to A, ", "does that mean that you're rotating about point A?  Or what is it--  J. KIM VANDIVER: You are rotating about point A.  AUDIENCE: OK.  But isn't point A just the [? immersion? ?]  ", "J. KIM VANDIVER: Let me think.  I'm trying to think of a good way  to-- when you started this problem,  we're spending about the middle-- about G, OK? ", "And we can calculate angular momentum  of this object with respect to G and learn some things, right?  But now we've built a different device.  This is an object now that is, in fact, spinning. ", " Let's imagine it's a fan blade, and you've  broken one blade off.  The motor is here. ", "A proper fan blade would have blades on both sides,  so it's nice and balanced.  The shaft has some length and it sticks out,  and now you break off one of the blades.  And so you have a system that's doing this, ", "but this is going to put a lot of unusual loads on this point  down here.  So it is rotating at the same rotation rate about this point,  but it is now a system whose center of mass is over here, ", "and it's up.  It's above this point, and it's out  from this point, the center of mass.  And now you compute the angular momentum with this point,  and take its time derivative, you ", "will find all the torques required to make this happen.  AUDIENCE: [INAUDIBLE]?   J. KIM VANDIVER: A little louder.  AUDIENCE: The movement A, [? i-hat ?] Mc [? k-hat ?] ", "[INAUDIBLE]  J. KIM VANDIVER: Movement that you've moved the center of mass  away from this axis of rotation.  And you've moved it up and over. ", "So actually, let's think about that for a minute.  This is our beginning point, right?  We're at G. If I just move it up, does it cause any problems? ", "It's still balanced, and you'll find out  that nothing's happened in this problem.  H with respect to A is the same as it was before.  ", "But now you move it up and over, it  starts causing complications.  Yeah?  AUDIENCE: [INAUDIBLE] H of A equals [? A ?] times omega z.  So i doesn't have like direction, ", "but you have an [? ixz ?] terms and [? xc ?] term,  and you're multiplying it by a vector with an omega z term,  so how are you getting an i hat from that?  J. KIM VANDIVER: OK, so I haven't gone into this, ", "and I'm not going to.  The [? i ?] matrix is a thing called a tensor.  And so this is a convention that you ", "can make it a very mathematical and assigned unit vectors  to each of these terms inside, but I haven't done that.  But the convention here is that this, the H, angular momentum ", "is a vector.  It consists of three components.  ", "It has three potential vector components, Hx in the I,  Hy in the j, and Hz in the k directions. ", "And we, in a compact form, say we can express that  by multiplying its mass moment of inertia matrix  with respect to A times the vector that is its rotation. ", "And I only have one component of this omega,  but it is in the k direction.  And when you take this vector multiplied by the top row, that ", "gives you everything that's [? I. ?] You multiply  this vector times the second row,  it gives you everything is in the j direction,  and the result is part of Hy in the j direction. ", "You take this vector, and you multiply it by the third row,  it gives you the z-directed components, OK?  So this one, because when we multiply this out ", "what's in this matrix-- is this matrix diagonal?   No way.  And we move it, and we've gone and done something strange ", "here.  It's not diagonal, and when you multiply  this times this top row, there's a term here,  which is not 0-- shouldn't write 0.  Make an x here.  This times this gives you an omega z times that in the i hat ", "direction.   OK this term comes from there being something there.  OK, and I'm just going to give you a generalization that you ", "can go back and read the Williams handout, which  he says, if you want to rotate about some fixed point A. ", "Then you can say that this matrix  is equal to the one with respect to G, which in our case  is diagonal. ", "The original one that we had doesn't have to be,  but if you pick principal axes, this will be diagonal.  Plus M b squared plus c squared minus ab minus ac. ", "It's symmetric.  This is a squared plus c squared.  ", "So if we're rotating a system if you  know its mass moment of inertia matrix  with respect to G [INAUDIBLE] perhaps principal axes,  and you want to rotate it about any other point ", "where you've moved it by an a, by a b, by a c,  this is essentially the general parallel axis theorem.  And you can just plug it in and use that.  And you can see what would happen in this case ", "if you multiplied-- if you add these two together,  they add term by term.  This goes into this point on.  This one adds to this, so in this problem, ", "in our particular problem, this becomes  you have an Ixx, Iyy, Izz with respect to G terms. ", "It's diagonal to start with, and then in our problem  that we did there, we didn't have a b.  No b terms, so the b terms are all 0, ", "but you do end up with a minus ac term over here.   And if you multiply this by 0, 0, omega z, see what happens. ", "You get minus ac in the I direction,  and you need an M here.  ", "And you come down here, you get the Izz G omega  z in the k direction, and that's those two terms.  Here they are.  ", "Yeah, oops, I need the plus [? A ?] squared.   Yeah?  AUDIENCE: When you move it over to the end of the stick, ", "normally like you're just shifting it parallely,  but now there's gravity.  Is that why you have those little things?  J. KIM VANDIVER: Say again?  AUDIENCE: So normally, if you just take a stick ", "and you have a principal axis and you  can't move that parallel to the end,  you wouldn't get all of this but--  J. KIM VANDIVER: Yeah, and if you just move it-- so yeah,  I'm glad you asked that question. ", "So normally the types of problems in which we usually  use the parallel axis theorem is you've  been spinning it around one axis. ", "It's a principal axis, everything's fine,  and you want to just move it over,  so we do that when we do pendulum problems.  Here's the thing around the center, ", "and we just want to know, how does this thing behave?  When we move it up here, it becomes a pendulum,  and we would like to compute the angular  momentum around this point.  We say, oh, we've moved it a distance d. ", "The new mass moment of inertia in the z direction  is the original plus Md squared, right? ", "So when you only make one move, you only  have an a, a b, or a c.  You never get any of the off-diagonal terms  because their products, see? ", "But if you start doing more than one,  you've introduced complications, and that's  part of the reason I put this up is  there's limits to the simple parallel axis theorem, ", "but there is a general way of doing it.  Yes?  AUDIENCE: I believe her actual question involved  what causes the torques?  Is it gravity?  For example--  AUDIENCE: Yeah, I was asking why-- ", "AUDIENCE: [INAUDIBLE].  J. KIM VANDIVER: Ah, so what causes these torques when  you have two?  AUDIENCE: Yes.  J. KIM VANDIVER: OK, we've talked about this a little bit  before.  ", "When we calculate the angular momentum,  it never involves gravity.   Never gets in there, not in the angular momentum expression. ", "So when you go to compute d, the time derivative of the angular  momentum, you will not find torques  that are caused by gravity.  You just can't do them.  It's not part-- but are the torques in the System I mean, ", "why just hold this here.  There's [? Mg ?] down, and there's  a static moment caused by this thing trying  to twist this down.  When you sum the torques-- when you  do the sum of the torques in the equation, ", "you do your free body diagram, that term will appear.  But it is balanced by some physical torque over here  that balances it.  You just won't find it from doing [? dh ?] dt. ", "It's just part of the static equilibrium of the system.  AUDIENCE: But the reason when you move the pen over,  the reason you even have the shift is because of  [? gravity? ?] ", "J. KIM VANDIVER: No, no.  So she's asking if is gravity the reason you--  I'm not even quite sure. ", "AUDIENCE: How did you shift the z component of your [? plan? ?]  J. KIM VANDIVER: OK, so let's just make  this a real physical problem. ", "I'm making an airplane engine, and I'm making an airplane  with a propeller on it.  And the bearing that supports the propeller shaft, ", "if I put it really close to the propeller,  OK, then it's doing this, and everything's fine.  What if I extended the propeller shaft? ", "OK, so now the bearing is back here,  and now the propeller spins.  Does that cause any torques, any loads back here on the bearing ", "because I've extended it?  No, and you could prove that just by going through this.  You do [? dh ?] dt, and you find out the only torques  when it's nice and balanced are those required ", "to drive this propeller in the direction  of the axis of rotation.  But as soon as you do something to that propeller, like you ", "mount it off-center, which rarely happens,  but if you dinged-- if you broke off  the tip of one of the blades of this propeller,  you'd now have a propeller that looks like that, right? ", "And now, even in the original system  if your bearing is right close, this is spinning around,  but is it putting a load?  Sure there's a centrifugal force that ", "is going around and around.  It has nothing to do with gravity,  nothing at all to do with gravity.  OK, just because you now have the mass centers out here, ", "it has momentum, the time rate of change  of that linear momentum is a force making  this thing going in a circle.  OK, now if I extend the propeller shaft ", "so it's like that, and I foolishly designed my airplane  so it had a long propeller shaft sticking out there,  if there's a little bit of unbalanced in this blade ", "so that you're not spinning about the mass center.  You're spinning about some other point.  Now that centrifugal force going around is pulling  is trying to bend this back and forth around this bearing. ", "And because of the way in which we formulate angular momentum,  if you formulate it about that point  and take its time derivative, it will reveal those moments. ", "It's really amazing that it can do that for you,  but it has [? zero, ?] nothing to do with gravity, OK?   So handy, hard to remember this from just a blackboard ", "presentation, but it's in that second reading by Williams.  He does it in a very-- he proves it  in a very simple way using the summations of the MI [? RI's ?] ", "and so forth.  Proves it in a very simple way, but a very general  handy formula that you can use.  OK, so let's have another topic, which I'm not going to do. ", "We've got a few minutes.  You have [? money ?] cards.  We've been thinking about that.  And let's ask questions, yeah?  AUDIENCE: [INAUDIBLE]   J. KIM VANDIVER: Where did I the-- ", "AUDIENCE: The plus [? MA ?] squared and the plus A squared.  J. KIM VANDIVER: Ah, I was doing that kind of fast,  and I probably even messed it up,  so let me check the-- so I was doing for the example ", "that [? RG/A ?] equals-- we moved it over by ai and up ", "by ck, so and plus 0j.  We didn't move it in the j direction, OK?  So this is my amount that I've moved it. ", "I've moved it an amount a, and an amount c.  So the Williams formula would say, ah,  that new mass moment of inertia matrix with respect to a  becomes the original plus-- and now every place there's ", "a b here, it goes to 0.  ", "And the remaining bits I add with those,  so I should get a M-- whoops, this is a c squared, ", "no second term.  The third term is minus Mac.  Over here, that one is 0.  This one becomes a squared plus c squared-- ", "AUDIENCE: --minus [INAUDIBLE]?  J. KIM VANDIVER: Minus, yep, M.  And this one is minus Mac 0 Izz and a squared plus b squared, ", "so it's just a squared.  So this is now correct.  AUDIENCE: [INAUDIBLE]?  J. KIM VANDIVER: Pardon?  AUDIENCE: Times M in the bottom of it?  J. KIM VANDIVER: Yeah, all of these  needs M. Ma squared's M, M, M, M, ", "so that's our problem when we did two shifts.  But a second we shifted it in two directions,  we get these off-diagonal terms, which ", "means that if you are actually making this device rotate  about point A, you will get these unbalanced moments--  this dynamically unbalanced.  ", "Yeah?  AUDIENCE: Will we be trying to find our [? mass ?] moments  of inertia directly, or should we just do [INAUDIBLE] equation  and have them fall out like the integral with x times y ", "[? vM? ?] [INAUDIBLE]  J. KIM VANDIVER: He's kind of asking advice in whether or not  we ought to be trying to find the inertia ", "matrix about other points, right,  like [? the I ?] with respect to A.  Where I started today, I said you can basically  do all the problems with these three equations, ", "and this doesn't mention parallel axis theorem.  We use this to find, in fact, to solve this problem.  We didn't talk parallel axis theorem at all, ", "it just-- the answer dropped out.  And if we looked into that careful,  we could generalize that.  We could work now with that a bit and say, ah,  there's a pattern to this. ", "I'll bet this can be recast like this, and it can.  So if you know this exists, and you ", "don't want to have to grind through finding  these terms that come from here, you  can do the problems by finding the mass moment of inertia ", "matrix with respect to A.  You can use this form only when you have fixed axis rotation. ", "The thing is the point A is [? about ?] which  this rotation is occurring, then you can write down the formula  this directly like that. ", "So you that got to be careful when you apply  the parallel axis theorem.   The nice thing about these three forms ", "is they're generally true.  Point A can move.  Point A can be accelerating.  The problem that we did here, point A is accelerating. ", "Not only moving, it's not even an inertial frame.  We solved this problem-- this is a non-inertial frame problem.  We went right at it and solved it directly, OK? ", "So I would say, if you have any doubt to answer your question,  when you're in doubt just use the formula.  And then you will need to find moments of inertia  with respect to the center of mass, ", "and it's in your interest to use principal axes because they're  easier.  Yeah?  AUDIENCE: If you were to say [INAUDIBLE]?  ", "J. KIM VANDIVER: Ah, so if you took  the derivative of this, [? dh ?] dt,  this one just gives you omega z dot.  That's you're spin in the direction of rotation. ", "This term, that unit vector rotates.  This gives you two terms-- gives you an i term, omega dot i, ", "and it gives you an omega j term, OK?  And what those are, those are two torques.  This problem, there's a torque caused ", "by the centrifugal force trying to bend  this in the j direction.  And if this is accelerating, you know, a theta double dot term, ", "there is a torque trying to bend this thing backwards.  OK, get them both.  All right [? money ?] cards and see you on Thursday. ", "Thursday we're going to do a nasty problem,  and it is it a lead in to a problem.  You can do the same problem extraordinarily easily ", "using energy.  And that's kind of the purpose of doing it,  so you see both ways of doing it. "], "vid_duration": [14.012, 14.628, 13.07, 10.389, 11.97, 10.643, 14.243, 17.575, 17.37, 21.43, 11.265, 17.535, 14.68, 10.78, 11.6, 19.175, 11.474, 11.391, 10.81, 10.18, 14.92, 13.33, 10.659, 10.921, 11.18, 12.64, 11.98, 12.2, 10.74, 14.59, 10.98, 26.77, 15.5, 10.45, 13.22, 12.26, 12.3, 10.274, 11.486, 11.87, 15.28, 13.14, 10.65, 13.022, 10.348, 10.26, 11.53, 15.65, 11.83, 13.73, 10.86, 11.56, 12.42, 13.53, 10.19, 11.88, 10.39, 13.5, 15.42, 10.38, 10.89, 20.04, 10.63, 10.33, 12.28, 11.023, 11.547, 10.53, 12.84, 16.04, 10.81, 11.36, 11.87, 20.69, 12.19, 10.71, 20.71, 12.34, 33.77, 10.85, 16.17, 12.83, 17.07, 13.83, 13.73, 13.28, 14.26, 11.04, 16.25, 20.99, 14.04, 23.73, 12.44, 10.39, 15.78, 25.45, 13.458, 10.572, 10.686, 10.99, 10.624, 11.55, 30.39, 10.97, 10.78, 16.347, 12.433, 15.67, 12.76, 11.45, 12.68, 13.49, 10.62, 13.155, 12.875, 15.19, 12.87, 13.92, 10.912, 14.568, 10.88, 12.43, 21.87, 12.53, 12.124, 14.276, 14.28, 12.81, 13.84, 11.48, 12.77, 11.0, 11.78, 11.58, 13.81, 13.095, 10.295, 10.4, 10.27, 11.4, 10.94, 13.27, 11.425, 12.185, 10.11, 11.41, 13.51, 11.12, 11.55, 11.8, 11.21, 11.33, 13.55, 12.19, 14.21, 10.928, 21.267, 12.225, 10.24, 10.0, 16.28, 14.73, 11.56, 18.09, 10.98, 13.13, 15.23, 19.67, 11.63, 12.45, 13.39, 14.9, 14.01, 18.455, 10.07, 29.855, 18.622, 11.938, 10.3, 12.42, 12.13, 13.227, 11.203, 11.6, 13.6, 11.18, 13.87, 15.54, 14.78, 12.234, 16.306, 11.16, 13.84, 12.71, 12.57, 14.02, 10.64, 13.09, 12.11, 11.43, 11.1, 13.955, 13.745, 11.7, 14.22, 10.12, 13.02, 12.62, 11.48, 11.11, 15.95, 10.091, 14.514, 11.255, 12.65, 11.29, 18.67, 21.49, 11.58, 12.95, 13.22, 15.67, 12.78, 16.01, 13.83, 11.01, 11.24, 11.253, 11.101, 11.436, 11.07, 12.04, 10.56, 10.87, 13.88, 11.15, 12.62, 12.07, 11.42, 12.23, 14.42, 10.69, 10.5, 10.43, 10.22, 10.76, 11.18, 10.07, 13.69, 13.63, 10.59, 10.72, 12.81, 10.09, 12.5, 11.97, 15.07, 10.449, 12.751, 10.453, 19.497, 10.55, 11.35, 14.5, 10.86, 20.13, 11.58, 10.44, 15.79, 11.56, 10.66, 13.215, 10.405, 11.77, 11.41, 10.26, 10.17, 15.65, 11.61, 11.24, 13.83, 11.29, 12.7, 11.42, 11.722, 12.238, 10.82, 12.32, 10.61, 11.96, 10.52, 5.68], "stet": [[0, 14.012], [14.012, 28.64], [28.64, 41.71], [41.71, 52.099000000000004], [52.099000000000004, 64.069], [64.069, 74.712], [74.712, 88.955], [88.955, 106.53], [106.53, 123.9], [123.9, 145.33], [145.33, 156.59500000000003], [156.59500000000003, 174.13000000000002], [174.13000000000002, 188.81000000000003], [188.81000000000003, 199.59000000000003], [199.59000000000003, 211.19000000000003], [211.19000000000003, 230.36500000000004], [230.36500000000004, 241.83900000000003], [241.83900000000003, 253.23000000000002], [253.23000000000002, 264.04], [264.04, 274.22], [274.22, 289.14000000000004], [289.14000000000004, 302.47], [302.47, 313.129], [313.129, 324.05], [324.05, 335.23], [335.23, 347.87], [347.87, 359.85], [359.85, 372.05], [372.05, 382.79], [382.79, 397.38], [397.38, 408.36], [408.36, 435.13], [435.13, 450.63], [450.63, 461.08], [461.08, 474.3], [474.3, 486.56], [486.56, 498.86], [498.86, 509.134], [509.134, 520.62], [520.62, 532.49], [532.49, 547.77], [547.77, 560.91], [560.91, 571.56], [571.56, 584.582], [584.582, 594.93], [594.93, 605.1899999999999], [605.1899999999999, 616.7199999999999], [616.7199999999999, 632.3699999999999], [632.3699999999999, 644.1999999999999], [644.1999999999999, 657.93], [657.93, 668.79], [668.79, 680.3499999999999], [680.3499999999999, 692.7699999999999], [692.7699999999999, 706.2999999999998], [706.2999999999998, 716.4899999999999], [716.4899999999999, 728.3699999999999], [728.3699999999999, 738.7599999999999], [738.7599999999999, 752.2599999999999], [752.2599999999999, 767.6799999999998], [767.6799999999998, 778.0599999999998], [778.0599999999998, 788.9499999999998], [788.9499999999998, 808.9899999999998], [808.9899999999998, 819.6199999999998], [819.6199999999998, 829.9499999999998], [829.9499999999998, 842.2299999999998], [842.2299999999998, 853.2529999999998], [853.2529999999998, 864.7999999999998], [864.7999999999998, 875.3299999999998], [875.3299999999998, 888.1699999999998], [888.1699999999998, 904.2099999999998], [904.2099999999998, 915.0199999999998], [915.0199999999998, 926.3799999999998], [926.3799999999998, 938.2499999999998], [938.2499999999998, 958.9399999999998], [958.9399999999998, 971.1299999999999], [971.1299999999999, 981.8399999999999], [981.8399999999999, 1002.55], [1002.55, 1014.89], [1014.89, 1048.66], [1048.66, 1059.51], [1059.51, 1075.68], [1075.68, 1088.51], [1088.51, 1105.58], [1105.58, 1119.4099999999999], [1119.4099999999999, 1133.1399999999999], [1133.1399999999999, 1146.4199999999998], [1146.4199999999998, 1160.6799999999998], [1160.6799999999998, 1171.7199999999998], [1171.7199999999998, 1187.9699999999998], [1187.9699999999998, 1208.9599999999998], [1208.9599999999998, 1222.9999999999998], [1222.9999999999998, 1246.7299999999998], [1246.7299999999998, 1259.1699999999998], [1259.1699999999998, 1269.56], [1269.56, 1285.34], [1285.34, 1310.79], [1310.79, 1324.248], [1324.248, 1334.82], [1334.82, 1345.5059999999999], [1345.5059999999999, 1356.4959999999999], [1356.4959999999999, 1367.12], [1367.12, 1378.6699999999998], [1378.6699999999998, 1409.06], [1409.06, 1420.03], [1420.03, 1430.81], [1430.81, 1447.157], [1447.157, 1459.59], [1459.59, 1475.26], [1475.26, 1488.02], [1488.02, 1499.47], [1499.47, 1512.15], [1512.15, 1525.64], [1525.64, 1536.26], [1536.26, 1549.415], [1549.415, 1562.29], [1562.29, 1577.48], [1577.48, 1590.35], [1590.35, 1604.27], [1604.27, 1615.182], [1615.182, 1629.75], [1629.75, 1640.63], [1640.63, 1653.0600000000002], [1653.0600000000002, 1674.93], [1674.93, 1687.46], [1687.46, 1699.584], [1699.584, 1713.8600000000001], [1713.8600000000001, 1728.14], [1728.14, 1740.95], [1740.95, 1754.79], [1754.79, 1766.27], [1766.27, 1779.04], [1779.04, 1790.04], [1790.04, 1801.82], [1801.82, 1813.3999999999999], [1813.3999999999999, 1827.2099999999998], [1827.2099999999998, 1840.3049999999998], [1840.3049999999998, 1850.6], [1850.6, 1861.0], [1861.0, 1871.27], [1871.27, 1882.67], [1882.67, 1893.6100000000001], [1893.6100000000001, 1906.88], [1906.88, 1918.305], [1918.305, 1930.49], [1930.49, 1940.6], [1940.6, 1952.01], [1952.01, 1965.52], [1965.52, 1976.6399999999999], [1976.6399999999999, 1988.1899999999998], [1988.1899999999998, 1999.9899999999998], [1999.9899999999998, 2011.1999999999998], [2011.1999999999998, 2022.5299999999997], [2022.5299999999997, 2036.0799999999997], [2036.0799999999997, 2048.2699999999995], [2048.2699999999995, 2062.4799999999996], [2062.4799999999996, 2073.4079999999994], [2073.4079999999994, 2094.6749999999993], [2094.6749999999993, 2106.899999999999], [2106.899999999999, 2117.139999999999], [2117.139999999999, 2127.139999999999], [2127.139999999999, 2143.419999999999], [2143.419999999999, 2158.149999999999], [2158.149999999999, 2169.709999999999], [2169.709999999999, 2187.7999999999993], [2187.7999999999993, 2198.7799999999993], [2198.7799999999993, 2211.9099999999994], [2211.9099999999994, 2227.1399999999994], [2227.1399999999994, 2246.8099999999995], [2246.8099999999995, 2258.4399999999996], [2258.4399999999996, 2270.8899999999994], [2270.8899999999994, 2284.2799999999993], [2284.2799999999993, 2299.1799999999994], [2299.1799999999994, 2313.1899999999996], [2313.1899999999996, 2331.6449999999995], [2331.6449999999995, 2341.7149999999997], [2341.7149999999997, 2371.5699999999997], [2371.5699999999997, 2390.1919999999996], [2390.1919999999996, 2402.1299999999997], [2402.1299999999997, 2412.43], [2412.43, 2424.85], [2424.85, 2436.98], [2436.98, 2450.207], [2450.207, 2461.41], [2461.41, 2473.0099999999998], [2473.0099999999998, 2486.6099999999997], [2486.6099999999997, 2497.7899999999995], [2497.7899999999995, 2511.6599999999994], [2511.6599999999994, 2527.1999999999994], [2527.1999999999994, 2541.9799999999996], [2541.9799999999996, 2554.2139999999995], [2554.2139999999995, 2570.5199999999995], [2570.5199999999995, 2581.6799999999994], [2581.6799999999994, 2595.5199999999995], [2595.5199999999995, 2608.2299999999996], [2608.2299999999996, 2620.7999999999997], [2620.7999999999997, 2634.8199999999997], [2634.8199999999997, 2645.4599999999996], [2645.4599999999996, 2658.5499999999997], [2658.5499999999997, 2670.66], [2670.66, 2682.0899999999997], [2682.0899999999997, 2693.1899999999996], [2693.1899999999996, 2707.1449999999995], [2707.1449999999995, 2720.8899999999994], [2720.8899999999994, 2732.5899999999992], [2732.5899999999992, 2746.809999999999], [2746.809999999999, 2756.929999999999], [2756.929999999999, 2769.949999999999], [2769.949999999999, 2782.569999999999], [2782.569999999999, 2794.049999999999], [2794.049999999999, 2805.159999999999], [2805.159999999999, 2821.1099999999988], [2821.1099999999988, 2831.2009999999987], [2831.2009999999987, 2845.714999999999], [2845.714999999999, 2856.969999999999], [2856.969999999999, 2869.619999999999], [2869.619999999999, 2880.909999999999], [2880.909999999999, 2899.579999999999], [2899.579999999999, 2921.069999999999], [2921.069999999999, 2932.6499999999987], [2932.6499999999987, 2945.5999999999985], [2945.5999999999985, 2958.8199999999983], [2958.8199999999983, 2974.4899999999984], [2974.4899999999984, 2987.2699999999986], [2987.2699999999986, 3003.279999999999], [3003.279999999999, 3017.1099999999988], [3017.1099999999988, 3028.119999999999], [3028.119999999999, 3039.3599999999988], [3039.3599999999988, 3050.612999999999], [3050.612999999999, 3061.713999999999], [3061.713999999999, 3073.149999999999], [3073.149999999999, 3084.2199999999993], [3084.2199999999993, 3096.2599999999993], [3096.2599999999993, 3106.8199999999993], [3106.8199999999993, 3117.689999999999], [3117.689999999999, 3131.5699999999993], [3131.5699999999993, 3142.7199999999993], [3142.7199999999993, 3155.3399999999992], [3155.3399999999992, 3167.4099999999994], [3167.4099999999994, 3178.8299999999995], [3178.8299999999995, 3191.0599999999995], [3191.0599999999995, 3205.4799999999996], [3205.4799999999996, 3216.1699999999996], [3216.1699999999996, 3226.6699999999996], [3226.6699999999996, 3237.0999999999995], [3237.0999999999995, 3247.3199999999993], [3247.3199999999993, 3258.0799999999995], [3258.0799999999995, 3269.2599999999993], [3269.2599999999993, 3279.3299999999995], [3279.3299999999995, 3293.0199999999995], [3293.0199999999995, 3306.6499999999996], [3306.6499999999996, 3317.24], [3317.24, 3327.9599999999996], [3327.9599999999996, 3340.7699999999995], [3340.7699999999995, 3350.8599999999997], [3350.8599999999997, 3363.3599999999997], [3363.3599999999997, 3375.3299999999995], [3375.3299999999995, 3390.3999999999996], [3390.3999999999996, 3400.8489999999997], [3400.8489999999997, 3413.6], [3413.6, 3424.053], [3424.053, 3443.5499999999997], [3443.5499999999997, 3454.1], [3454.1, 3465.45], [3465.45, 3479.95], [3479.95, 3490.81], [3490.81, 3510.94], [3510.94, 3522.52], [3522.52, 3532.96], [3532.96, 3548.75], [3548.75, 3560.31], [3560.31, 3570.97], [3570.97, 3584.185], [3584.185, 3594.59], [3594.59, 3606.36], [3606.36, 3617.77], [3617.77, 3628.03], [3628.03, 3638.2000000000003], [3638.2000000000003, 3653.8500000000004], [3653.8500000000004, 3665.4600000000005], [3665.4600000000005, 3676.7000000000003], [3676.7000000000003, 3690.53], [3690.53, 3701.82], [3701.82, 3714.52], [3714.52, 3725.94], [3725.94, 3737.6620000000003], [3737.6620000000003, 3749.9], [3749.9, 3760.7200000000003], [3760.7200000000003, 3773.0400000000004], [3773.0400000000004, 3783.6500000000005], [3783.6500000000005, 3795.6100000000006], [3795.6100000000006, 3806.1300000000006], [3806.1300000000006, 3811.8100000000004]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [434, 1960, 3408, 3812]}
{"example_id": "mit126@@MIT2_003SCF11_lec19_300k", "text": ["J. KIM VANDIVER: Today's lecture is not mathematically hard,  but it's really important to establish vocabulary today.  We're going to talk about vibration ", "for the rest of the term.  And vibration is essentially applied dynamics.  So up until now, we've been finding equations of motion, ", "but not solving them.  Did you notice that?  I've almost never asked you to solve the equation of motion  that you've just discovered using Lagrange or whatever. ", "The rest of the term, we're actually  going to be talking mostly about the resulting motion.  The equations of motion are pretty easy to find.  You have all the techniques that you need to know for finding. ", "And now, we're going to talk about how things vibrate.  So why do we choose vibration?  Vibration, one, is an incredibly common phenomenon. ", "We wouldn't have speech without vibration.  You wouldn't have musical instruments without vibration.  It's a positive thing when it's making good music.  It's a negative thing when it's keeping you awake at night ", "because the air conditioner in the next room  is causing something to rattle in the room  and it's driving you nuts.  So you can want it, it can be desirable, ", "and you cannot want it.  And you need to know ways of getting rid of it.  And so we're going to talk about vibration, about making ", "vibration, about suppressing vibration,  about isolating sensitive instruments from the vibration  of the floor, things like that.  So that's the topic of the rest of the term. ", "And today, we're going to talk about single degree of freedom  systems.  And you might think that we're spending an awful lot of time ", "on single degree of freedom systems.  But actually, there's a reason for that.  Lots of things in real life, like-- this ", "is just an aluminum rod.  This will vibrate.  And continuous systems, which this is,  have a theoretically infinite number of degrees of freedom. ", "Yet when it comes to talking about its vibration,  it is conceptually easy to think about the vibration  of an object like this, one natural frequency, ", "one natural mode at a time.  And in fact, you can model that natural mode  with its single degree of freedom equivalent.  And that's the way I approach vibration. ", "So if you can isolate one particular mode,  you can literally model it as a Mass-Spring-Dashpot.  So you need to understand the Mass-Spring-Dashpot behavior  inside and out, because it's the vocabulary we use to do ", "much more complicated things.  So a single degree of freedom system,  like the simple pendulum, has a natural frequency. ", "In this case, it has mode shape.   Here's another one, kind of fun, single degree of freedom. ", "This obviously involves rotation.  ", "And you can figure that out using  Lagrange or whatever, single degree of freedom systems.  But now, I'm going to excite one mode of vibration of this.  ", "[CLANG]  [HIGH-PITCHED TONE]  Hear the real high pitch?   I'll get it down here by the mic so that people at home ", "can hear it-- about a kilohertz, way up there.  And that's one natural mode of this thing  in longitudinal vibration.  When I thump it sideways-- ", "[CLANG]  [LOWER TONE]  you hear a lower tone.  Hear that?  [HUMS LOW]  rather than--  [HUMS HIGH]  [CLANG]  That's bending vibration of this thing. ", "But each mode of vibration I can think  of in terms of its equivalent single degree of freedom  oscillate.  So we'll get to talking about these things  a little bit-- continuous systems-- in the last couple ", "lectures of the term.  But for today then, we're really going  to develop this vocabulary around the vibration  of single degree of freedom systems. ", "So let's start.  ", "All right.  So to keep it from being totally boring,  I'm going to start with a little Mass-Spring-Dashpot that ", "has two springs.  ", "And they're of such a length that unstretched,  they just meet in the middle.  And then, I'm going to take a mass ", "and I'm going to squeeze it in between these two springs--  I can't draw a spring very well today-- and this is k1  and this is k2 and here's m. ", "And we'll put it on a roller so it's obviously constrained  to motion in one direction.  And I'll pick this point here as the place ", "I'm going to put my inertial coordinate.  So my inertial coordinate's just measured from  or happens to be where the endpoints of these two springs  were.  Now, to squeeze the spring in here, ", "I have this clearly pre-compression  in these springs.  So we are no longer in a zero-force state, right? ", "So and I want to get the equations of motion in this.  And moreover, I want to predict--  I want to find out what's the natural frequency  of this spring.  So let's check your intuition. ", "So write down on your piece of paper  whether or not the natural frequency will be different  because there's pre-compression, or whether or not ", "that pre-compression in the springs  has nothing to do with the natural frequency.  So write down on your paper \"natural frequency  is different\" or \"natural frequency is the same.\" ", "Let's have a prediction here.   And then, we'll set about figuring this out  and in the course of doing it, we'll  develop a little vocabulary. ", "All through the course so far, when  we've done equations of motion, we've  usually picked the zero-spring-force position.  And we sort of led you down this rosy path that suggests ", "that's the way we do it.  But there are other ways that you're  going to find that are preferable to that, sometimes.  So that's one of the reasons I'm doing this example.  So let's do a free body diagram. ", " And if I held this mass, for example, ", "right at the center when I put the springs in,  it's obvious that this spring gets compressed  by half of the length of the mass  and this spring gets compressed by half  of the length of the mass, right? ", "So this is going to be L long.  So if I held it right in the middle,  it would compress L/2 and L/2.  But then, when I release it, if these springs ", "are a different spring constant, it's  going to move a little bit.  So the force on this side pushing back  is sum k1 times L/2 minus the distance ", "that I move in that direction, which would relieve it.  And the force on this side also pushes back.  It's k2 times L/2 over 2 plus x, because when ", "I go in that direction, I'm compressing it even further.  And those are the total forces in the x-direction  on this body.  There's an N and an mg, which we know ", "we don't have to deal with because we're only  interested in motion left and right.  All right?  So we can say sum of the forces in the x-direction, ", "mass times the acceleration.  And those forces are k1 L/2 minus x minus k2 L/2 plus x. ", "And that's the complete equation of motion for this problem.  And rearrange it so that I get the functions  of x together here. ", "So mx double dot plus k1 plus k2 times x ", "equals L/2 times k1 minus k2. ", "And that's your equation of motion.  It's non-homogeneous.  This is all constants on the right-hand side.  And on the left-hand side are the functions of x, right? ", "So what's the natural frequency of the system?   AUDIENCE: Square root of k1 plus k2 over m. ", "J. KIM VANDIVER: I hear a square root of the quantity k1  plus k2, the stiffness, divided by m, k over m,  a usual Mass-Spring-Dashpot system.  Did the pre-compression have anything ", "to do with the natural frequency?  I won't ask you to embarrass yourselves, but a few of you  probably got that wrong, all right?  So there's a lesson in this that I want you to go away with. ", " and I'll say it once.  And that is when an external force ", "has nothing to do with the motion coordinates  in the problem.  It doesn't affect the natural frequency.  ", "These come from external forces.  These are these pre-compressions, right?  And I can separate them out and they are not functions of x.  The stuff on the right-hand side of the equation, ", "that's not a function of the motion variable--  cannot affect the natural frequency.  So I'll give you another one.  ", "This is our common thing hanging from a stick.  ", "I've taken my system I built the other day  for a different purpose, but now, it's just a mass  hanging from a spring. ", "And it's right now at its equilibrium position  or there's non-zero force in the spring.  It clearly has a natural frequency.  ", "And is that natural frequency a function of gravity?   And so if you go to write the equation to motion  of this system, you would find mx double dot plus kx equals mg ", "g.  But the mg is not a function of x.  The natural frequency's again, the square root of k/m.  ", "Now, we want to talk about solving this differential  equation.  And because it's got this constant term  in the right-hand side, it's non-homogeneous,  which is kind of a nuisance term in terms of dealing ", "with a differential equation.  It'd be a lot nicer if the right-hand side were 0.  So I want to make the right-hand side of this one 0. ", "And draw a use of a conclusion from that.  ", "First thing I need to know is I'd  like to know what is the static equilibrium position of this.  ", "And when you go to compute static equilibrium,  you look at the equation of motion  and you say, make all motion variables things  that are functions of time 0.  So no acceleration-- you're left with this. ", "So you just solve this for whatever the value of x is  and I'll call it x of s for x-static.  And you'll find that, oh, well, it's  that term divided by k1 plus k2, k1 ", "minus k2 all over k1 plus k2.  And that's the static position.  ", "So now, let's say, ah, well, we started off  with this motion variable that wasn't arbitrarily defined  at the middle.  And let's say that, well, it's made up ", "of a static component, which is a constant, just  a value, plus a dynamic component I'll  call x of d, which moves. ", "This is the function of time.  This is a constant.  It's not a function of time.  And that means if I take its derivative,  I might need a value for x dot. ", "That goes away.  It's just xd dot.  And x double dot is xd double dot.  And let's substitute this into my equation of motion. ", "So it becomes m xd double dot plus k1 plus k2 times-- ", "and now, this term has got two pieces now-- times xd plus k1  plus k2 times xs equals L/2 k1 minus k2. ", " All right?  Now if I say, well, let's examine the static case, ", "then this goes away.  For the static equilibrium case, this term is 0.  This term is 0 because the dynamic motion  is 0 in the static case. ", "That xd is motion about the static equilibrium position.  So for static case, these two terms go away  and we know that this equals that.  But if that's true, we can get rid of these. ", "They cancel one another.  These terms cancel and I'm left with m xd double dot  plus k equivalent, I'll call it, xd equals 0. ", "So the k equivalent's just the total stiffnesses  in the system, whatever works out, right?  In this case, it's k1 plus k2 and the natural frequency,  omega n, is the square root of k equivalent divided by m. ", " So most often, if you're interested in vibration,  you're interested in natural frequencies,  you're interested in solving the differential equation, ", "you will find it advantageous to write your equations of motion  around the static equilibrium position.  ", "So I could have started this problem by saying,  whatever the static equilibrium position is  of this thing, that's what I'm measuring x from.  ", "And then, I would have come to this equation eventually.  You'd have to figure out what is the static equilibrium position  and know what you're doing, but once you know it,  then you have the answer. ", "Now, the same thing is true of that problem.  That's a non-homogeneous differential equation  for the hanging mass. ", "And we derive the equations of motion things  for this many different ways this term, all right?  But we usually said, zero-spring force. ", "But now, if you started from here and said,  this is the static equilibrium position,  what's the motion about this position,  then you'd get the equation with 0 on the right-hand side-- ", "lots of advantages there to using that.  ", "All single degree of freedom oscillators  will boil down to this equation.  This is one involving translation,  but for a simple pendulum. ", "This object, for example, is a pendulum, but it's rotational.  So it's a pendulum, but it's one degree of freedom.   All pendulum problems, if you do them ", "about equilibrium positions, boil  down to some I with respect to the point  that they're rocking about, theta double ", "dot plus some Kt, torsional spring constant theta,  equals 0.  They take the same form. ", "So all translational single degree  of freedom systems, all rotational single degree  of freedom systems, it's the same differential equation--  just this involves mass and linear acceleration. ", "This involves mass moment of inertia and rotational  acceleration.  So everything that I say about the solution  to single degree of freedom systems  applies to both types of problems. ", "So let's look into the solution of this equation briefly.  ", "Mostly, I'm doing this to establish some terminology.   So a solution I know or I can show that xd of t, ", "the solution to this problem-- notice,  are there any external forces, by the way, excitations,  f of t's or anything?  No.  So this thing has no external excitation  that's going to make it move. ", "So it's only source of vibration or motion is what?  Comes from-- I hear initial conditions, right? ", "You have to do something to perturb it  and then it will vibrate.  So here it is.  It's about its equilibrium position. ", "I give it an initial deflection and let go.  Or it's around its initial condition  and I give it an initial velocity. ", "It also responds to some combination of the two.  So initial conditions are the only things  that account for motion of something  without external excitation.  And that motion, I can write that solution ", "as A cosine omega t.  You'll find this is a possible solution. ", "B sine omega t is another possible solution.  Sum A cosine omega t minus phase angle's also a solution. ", "And sum A e to the i omega t you'll find is also a solution.  Any of those things you could throw in ", "and the precise values of these things, the A's, the B's, the  phi's, and so forth depend on--  AUDIENCE: the initial conditions.  J. KIM VANDIVER: The initial conditions.  So let's do this one quickly. ", " All right. ", "And I'll choose And I'm going to stop writing the x sub d here. ", "This is now my position from the equilibrium point.  So x of t-- I'm going to say, let ", "it be an A1 cosine omega t plus a B1 sine omega t ", "and plug it in.  When I plug it into the equation of motion, ", "x double dot requires you to take two derivatives of each  of these terms.  Two derivatives of cosine gives you minus omega cosine.  Two derivative sine minus omega squared cosine minus omega ", "squared sine.  So the answer comes out minus m omega  squared plus k equivalent here times A1 cosine ", "plus B1 sine-- omega t's obviously in them-- equals 0. ", "So I just plugged in that equation of motion.  I get this back.  This is what I started with.  That's x.  In general, it is not equal to 0, can take on all ", "sorts of values.  So that's not generally 0 and that means this must be.   And from this, then, when we solve this,  we find that omega what we call n squared is k over m. ", "And that's, of course, where our natural frequency comes from.  This is called the undamped natural frequency, ", "because there's no dampening in this problem yet.  We get the square root of k over m  is the natural frequency of the system.  Let's find out what are A1 and B1. ", "Well, let's let x0 be x at t equals 0 here.  ", "And if we just plug that in here, put t equals 0 here,  cosine goes to 1.  This term goes away.  So this implies that A1 equals x0. ", "So we find out right away that the A1 cosine omega  t takes care of the response to an initial deflection.  And we need a x dot here minus A1 omega sine omega t plus B1 ", "omega cosine omega t.  That's the derivative of x.  You know the solution's that, so its first derivative,  the velocity, must look like this. ", "And let's let v0 equals x dot at t equals 0.  When we plug that in, this term goes away ", "and we get B1 omega and cosine is 1.  So therefore, B1 is v0 over omega. ", "But in fact, the omega's omega n,  because we already found that, that the only frequency that  satisfies the equation of motion when ", "you have only initial conditions in the system,  the only frequency that is allowed in the answer  is the natural frequency.  So we now know B1 is v0 over omega n and A1 is x0. ", "So if I give you any combination of initial displacement  and initial velocity, you can write out for me the exact time  history of the motion. ", "X0 to cosine omega t plus v0 over omega n sine omega t  is the complete solution for a response to initial conditions.  ", "So any translational oscillator one degree ", "of freedom where you have a translational coordinate  measured from its equilibrium position ", "has the equation of motion-- actually,  you've done this enough.  But if we added a force here and we added some damping  and I wanted the equation of motion of this, ", "you know that it's m x double dot plus b x  dot plus kx equals F of t. ", "And so you're going to be confronted with problems--  find the equation of motion in a system.  It comes up looking like that and they say,  what's the natural frequency?  And I've been a little sloppy.  I really mean, what's the undamped natural frequency? ", "And so to find the undamped-- when  one says that, what's the undamped natural frequency,  you just temporarily let b and F be 0, just temporarily, ", "and solve then for omega n equals square root of k/n.  It's what you do.  And then, so we know this is a parameter that tells us ", "about the behavior of the system, which we always  want to know for the single degree of freedom systems.  What is the natural frequency of the system?  ", "And we know for b equals 0 and F of 0,  then the response can be only due to initial conditions.  So we have x of t. ", "We know it's going to be some x0 cosine omega n  t plus v0 over omega n sine omega n t. ", "And every simple vibration system in the world  behaves basically like this from initial conditions.  It'll be some part responding to the initial displacement,  some part to the initial velocity. ", "And damping is going to make it a little bit more complex,  but not actually by much.  The same basic terms appear even when you have damping in it.  ", "This can be expressed as sum A cosine omega, in this case, ", "n t minus the phase angle.  And it's useful to know this trigonometric identity  to be able to put things together ", "into an expression like that.  And you'll find out that A is just the square root of the two ", "pieces.  It's a sine and cosine term.  So you have an x0 squared plus a v0 over omega n squared  square root. ", "Remember, this is any A and B. It's just a square root  of A squared plus B squared.  That's what we're doing here.  And the phase angle, the tangent inverse ", "of this-- we've been calling this like an A and this  is the B quantity.  So tangent inverse of-- get my signs right-- ", "B over A, which in this case then  is tangent inverse of v0 over x0 omega n. ", "That's all there is to it.  And finally, another trig thing that you  need to know-- we're going to use it quite a bit-- ", "is that if you have an expression A cosine omega  t minus phi, that's equal to the real part of A e to the i omega ", "t.   And if A is real and-- I don't want to write it that way-- ", "when A is real, it's A times e to the i omega t minus phi, ", "because Euler's formula says e to the i theta  equals cosine theta plus i sine of theta. ", "So if you have an i omega t minus phi  here, you get back a cosine omega  t minus phi and another term, an i sine omega t minus phi. ", "So you can always express that as the real part of that.  So we're going to need that little trig identity  as we go through the term.  ", "Now, I've found in many years of teaching vibration ", "that something that many students  find a little confusing is this notion of phase angle.  What does \"phase angle\" really mean? ", "So I'll try to explain it to you in a couple different ways.  So let's look at what this vibration  that we're talking about here, x0 cosine omega ", "t plus v0 over omega n sine-- what's it look like?  So that's-- we've just got our-- and we see what it looks like. ", "But if you plot the motion of this thing just versus time,  what's it look like and where does phase angle come into it? ", "So this is now x of t and this is  t equals 0 and this undamped system ", "is essentially going to look like that.   And this is the value x0, the amplitude,  the initial condition on x that you began with. ", "And right here, the slope-- v0 is the slope, the initial slope  of this curve, right, because the time derivative is F x dot. ", "If we were plotting x dot, the initial velocity is omega x0.  And so it's just the slope is v0 here.  So this is your initial velocity. ", "This is the-- and I didn't-- yeah, that's right.  ", "This is the initial displacement.  The total written out mathematically,  it looks like that.  And I'm plotting this function, A cosine omega t minus phi. ", "Yeah?  Did I see a hand up?  AUDIENCE: Does x0 at t equals 0 or is it a little bit after?  J. KIM VANDIVER: Well, I was just ", "looking at it myself and said, this can't be right.   This has got to be the initial condition on x and this  has to be the initial condition on v. ", "Now, whatever this turns out to be is  whatever it turns out to be.  You have some initial velocity.  You have some initial displacement.  The system can actually peak out sometime later ", "at a maximum value, right?  And that maximum value is that.  So this over here is the square root ", "of x0 squared plus v0 over omega n squared square root. ", "That's what the peak value is.  And this system's undamped, so it just goes on forever.  So the question is, though, what is this gap here  between when it starts and when it meets its maximum? ", "Well, when we use an expression like-- we  said we can express this as some A cosine omega t minus phi. ", "It's just the point at which the cosine then  reaches its maximum.   So if this axis here is omega t, if we plot this actually ", "versus omega t, then one full cycle  here is 2 pi or 360 degrees. ", "So if you plot it versus omega t, then this gap in here  is just phi.  That's the delay in angle, if you will, ", "that the system goes through between getting  from the initial conditions to getting  to the peak of the cosine.  ", "And phi must also then be equal to some omega  n times a delta tau, I'll call it, some time delay. ", "So if this is plotted-- if this axis is time--  not omega t, but time-- then x the same plot, this delay here, ", "this is a time delay.  And when you plot it against time,  it's a delay in time to get to the peak.  And omega n delta tau, this delay, ", "must be equal to the phase angle.  So the delta tau, this time delay, is phi over omega n.  ", "So you can think about this as a delay in time  or as a shift in phase angle, depending on whether or not  you want to plot this thing as a function of omega t ", "or as a function of time.  But you're going to need this concept of phase angle  the rest of the term.  Want to ask any questions about phase? ", " Because we're doing vibration for the remainder of the term, ", "this is an introduction to a topic called linear systems.  And so this is basically the fundamental stuff in which you  then, when you go on to 2004, which ", "is controls and that sort of thing,  this is the basic intro to it.  And we'll talk more about linear system behavior as we go along. ", " Now, we're going to do something that you've-- much of this ", "stuff I know you've seen before.  Some of the new parts is just vocabulary and ways  of thinking about vibration that engineers  do that mathematicians tend not to. ", "So you have seen most of this stuff before where?  AUDIENCE: 1.803.  J. KIM VANDIVER: 1.803, right?  You've done all this.  And a year ago last May, in May, I taught the 1803 lecture ", "with Professor Haynes Miller.  Now, if you had 1.803 last spring,  I think you had somebody different.  But he invited me to come here.  It was in the same classroom and we  taught the second-order ordinary differential equation together. ", "It was really a lot of fun.  He said, well, here's what we do.  And then, I said, oh, well, engineers  look at it the following way.  So what I'm going to show you is what  he and I did in class that day. ", "You can go back and watch that on video.  It's kind of fun.  But I'll give you my take on it today.  So this is the engineer's view of what  you've already seen in 1.803.  So we have that system and we have that equation of motion. ", "And the engineers and mathematicians  would more or less agree to that m x double dot plus bx.  But I went and looked at the web page last night.  Last spring, the person used c instead of b. ", "Haynes Miller the year before used b.  So you can't depend on any absolute consistency.  So let's start off with our homogeneous equation here. ", "And I'm looking now for the response to initial conditions  with damping.  You've done this in 1.803.  You know that you can solve this by assuming a solution ", "of a form Ae to the st.  Plugging it in gives you a quadratic equation  that looks like s squared plus sb plus k equals 0. ", "This has roots.   I left out my m here, so it starts off looking like that.  You divide through by the m. s squared ", "plus b/m s plus k/m equals 0.  And that's where Haynes would leave it.  And he'd give you the entire answer in terms of b/m and k/m ", "and that kind of thing.  Engineers, we like to call that the natural frequency squared.  And this term, we'd modify to put it  in a terminology that is more convenient to engineering. ", "So I'll show you how that works out.  When you solve this quadratic just using  the quadratic equation, you get the following.  ", "You get that the roots, there's two of them.  I'll call them S1 and 2.  The roots to this equation look like  minus b over 2m plus or minus square root of b squared ", "over 4m squared minus k/m.   And that's what you'd get to do in 1.803. ", "And an engineer would say, well, let's change that a little bit.  So my roots that I would use for S1 and 2, ", "I just factor out-- that's omega n squared.  I can factor that out and it becomes omega n on the outside.  And I put an omega n in the numerator and denominator here,  as well. ", "So I get roots that look like-- so I've just ", "manipulated that a little bit.   I have a name for this term.  I use the Greek letter zeta is b over 2 omega n ", "m is the way I remember it in my brain.  It's called the damping ratio.  ", "And if I say that, then the roots, S1 and 2 for this,  look like minus zeta omega n plus or minus ", "omega n times the square root of zeta squared minus 1.  ", "And those are the roots that a vibration engineer  would use to describe this second-order linear  differential equation solution homogeneous solution. ", " Those are the roots of the equation.  And when you have no damping, then this term goes away  and you're left with-- and I left an i out of here, I think. ", " No, I'm fine.  The i comes out of here.  ", "So for one thing to absolutely take away from today  is to remember this.   That's our definition of damping called the damping ratio. ", "When that's 1, it's a number we call critical damping.  I'll show you what that means in a second.  And when it's greater than 1, the system won't vibrate. ", "It just has exponential decay.  If it's less than 1, you get vibration.  And that's why we like to use it this way as it's meaningful.  Its value, you instantly know if it's  greater than or less than 1, it's  going to change the behavior of the system ", "from vibrating to not vibrating.  So now, there's four possible solutions to this.  I'm not going to elaborate on all of them, but zeta equals 0, ", "we've already done.  We know the answer to that.  Response to initial conditions-- simple.  We know that one.  We have another solution when zeta's greater than 1. ", "When zeta's greater than 1, this quantity here  is the inside is greater than 1, so it's a real positive number.  And both the roots of this thing are completely real. ", " And you know that the-- remember the response,  we hypothesize in the beginning that response ", "looks like some Ae to the st. So now, we just plug back in.  This is our st value.  We can plug them back in and we will get  the motion of the system back.  So for zeta greater than 1, st comes out ", "looking like minus zeta omega n t plus or minus ", "square root of zeta squared minus 1 times t.  And you just plug this in, and x is just e to the st. ", "But these are just pure real values.  And you'll find out that the system from initial conditions  on velocity and displacement just-- ", "[WINDS DOWN]  and dies out.   Zeta equals to 1.  Then, st is just minus-- you get a double root-- minus omega nt, ", "twice.   And the solution for this, I can write out the whole thing.  x of t here is just some A1 plus t A2 e ", "to the minus zeta omega n t.  And again, it looks-- it's just some kind  of damp, not very interesting response, no oscillations. ", "And then finally, zeta less than 1.  And this is the only one-- this one produces oscillation.   And the solution for st is plus or minus-- minus zeta omega n ", "t, a real part, plus or minus i omega n t ", "times the square root of 1 minus zeta squared.  Now, I've turned around this zeta squared minus 1.  This is now a negative number. ", "A square root of a negative number gives me i.  And now, I turn this around, so this is just  a real positive number.  So when you get i into this answer,  what does it tell you that the solution looks like? ", "AUDIENCE: Sines and cosines.  J. KIM VANDIVER: Sines and cosines, right?  So now, this gives you sines and cosines with a decay.  This is an exponential to e to the minus zeta omega n  t multiplied by a sine and a cosine. ", "And so this is the interesting part.  So most of the work of the rest of this term,  we're only interested in this final solution.  ", "And what it looks like for this one-- so for zeta less than 1, ", "x of t is some Ae to the minus zeta omega n  t times a cosine omega d t-- make it d times ", "t minus a phase angle-- come out looking like that.  And if you draw it, depends on initial conditions, so again,  a positive velocity and a positive displacement. ", "It does this, but then it dies out.   It's very similar to the undamped case,  except that it has this damping that  causes it to die out with time. ", "But this right here, this is still the initial slope is v0  and the initial displacement here is x0.  ", "And I'm now going to give you the exact expressions for this  and we'll talk about it.  ", "Another way of writing this then in terms  of the initial conditions is this looks like x0 cosine omega ", "d t plus v0 over omega d.  ", "So expanding this out, this result clearly  has to depend on the initial displacement  and on the initial velocity.  Now, what's this?  I keep writing this omega d. ", "So notice in here in the solution,  it's omega n times the square root of 1 minus zeta squared.  So the frequency that's in here isn't exactly omega n.  It's omega n altered by a bit. ", "Omega sub d is called the damped natural frequency. ", " And it's equal to omega n times the square root  of 1 minus theta squared. ", " The system actually oscillates at a slightly different  frequency.  And for most systems that vibrate at all, ", "this damping term is quite small.  And when you square it, it gets even smaller.  So this is usually a number that's 0.99, oftentimes, ", "or even bigger than that.  This is very close to 1 for all small amounts of damping.  But being really careful about this ", "in including it everywhere, that's  what this result looks like.  And this little thing, psi, this little phase angle here,  is tangent inverse of theta over the square root of 1 ", "minus theta squared.  And this number-- when damping is small,  this is a very small number.  And most of the time of problems that we deal with, ", "the damping will be small.  So let's say, for small damping-- ", "and by that, I mean zeta, say, less than 10%,  what we call 10%, 0.1.  And if you have a little more-- you don't care too much ", "about the precision, it might even be 20%.  Actually, if it were 0.2, squared is 0.04, right?  1 minus 0.04-- 0.96 square root, 0.98. ", "So even with 20% damping, the difference  between the undamped natural frequency  and the damped natural frequency's 2%.   So for most cases with any kind of small damping at all, ", "we can write an approximation which is easier to remember.  And it's all I carry around in my head.  I can't remember this, quite frankly.  Don't try to and I would instead express ", "the answer to this as just x0 cosine omega  d t plus v0 over omega d sine omega damped times time ", "times e to the minus zeta omega n t.  So why do I bother to carry the omega d's along  if I just said that they're almost exactly the same. ", "For light damping, then omega n's approximately omega d.  Well, you need to keep this one in here  because even though it's only 2% difference at 20% damping, ", "if you say the solution is omega n when it's really omega d,  this thing will accumulate a phase error over time. ", "So it's gets bigger and bigger, this error here,  because you haven't taken care of that little 2%.  That 2% can bite you after you go through enough cycles. ", "So I keep omega d in the expression here.  But other than that, it's almost exactly the same expression  that we just came up to for the simple response ", "of an undamped system to initial conditions,  x0 cosine plus v0 over omega n sine.  And now, all we've added to it is put the transient decay ", "and the fact that it decays into the expression  and changed the frequency it oscillates at to omega  d instead of omega n.  ", "So I'm going to try to impress something on you.  If I took this pendulum and my stopwatch, ", "measured the natural frequency of this thing,  I could get a very accurate value if I do it carefully.  Then, I take the same object and I dunk it in water ", "and it goes back and forth.  And it conspicuously goes back and forth  but dies down now after a while, because it's  got that water damping it.  But I measure that frequency and it's ", "10% different, 20% different.  And I have seen people make this mistake dozens of times.  You say, that's the experiment. ", "Explain why.  What's the reason that that measured frequency has changed?  Got any ocean engineers in the audience? ", "All right.  So why does-- if you put the pendulum in water--  and it's still oscillating now.  So it isn't so damp that it's--  [BLOWS]  So it's got some damping. ", "It's dying out and the natural frequency's  changed by 15% or 20%.  What's the explanation?  And the answer you always get from people is, damping. ", "Why?  Because everybody's been taught this thing, right?  And they all then assume that the change in the frequency  is caused by damping.  But damping couldn't possibly be the reason, ", "because with 20% damping, this thing'll die out  in about two swings and it's done.  That's a lot of damping, actually,  but it only accounts for 2% change in natural frequency, ", "not 15%.  Hmmm.  So what causes the change in the frequency?   AUDIENCE: Buoyancy of the pendulum? ", "J. KIM VANDIVER: No, not buoyancy.   That could actually have an effect.  That's actually-- I should say, yes, you're partly right. ", "There's another reason.   When the thing is swinging back and forth there in the water,  it actually carries some water with it. ", "Effectively, the kinetic energy-- you  now know how to do vibration problems.  Find the equations of motion accounting  for the potential energy and the kinetic energy. ", "The kinetic energy changes, because some water  moves with the object and it's called added mass.  It literally-- there is water moving with the object that  has kinetic energy associated with the motion ", "and it acts like it's more massive.  It is dynamically more massive.  There's water moving with it.  So trying to impress on you that damping ", "doesn't cause much of a change in systems  that actually vibrate.  Really observe the vibration.  If you can observe the vibration,  damping cannot possibly account for a very large shift ", "in frequency.  What's the motion look like?  Let's move on a little bit here.  ", "So that's what this solution looks like.  We know it depends on initial conditions.  The distance from here to here will make this a time axis. ", "This is one period.  So this is tau d.  That's the damped period of vibration.  ", "And we know that x of t is some Ae to the minus theta omega n t ", "cosine omega d t minus a phase angle.  We can write that expression like this.  ", "And this term, this is just a cosine.  This term repeats every period, right? ", " If it's at maximum value here, exactly one period later,  it's again at its maximum.  So the cosine term goes to 1 every 2 pi ", "or every period of motion, right?  So I want to take-- I'm going to define this as the value ", "at x at some time t.  I'll call it t0.  And out here is x at t0 plus n tau d, n periods later. ", "So this is the period, defined as period.   Remember, omega d is the same thing ", "as 2 pi times the frequency in hertz.  And frequency is 1 over period, 2 pi over the period. ", "So remember, there's a relationship  that you need to remember now that relates radian  frequency to frequency in cycles per second in hertz ", "to frequency expressed in period.  All right?  This would be tau d here and this would be an f d.  For any frequency, you can say that. ", "At omega is 2 pi f is 2 pi over tau.  So you've got to be good with that.  But now, so here we are, two peaks separated by n periods. ", "And I want to take the ratio of x of t to x of t plus n tau d  here. ", "And that's just going to be then my--  when I take that ratio, x of t has cosine omega d t  minus phi in it. ", "And n periods later, exactly the same thing appears, right?  So the cosine term just cancels out.  This just is e-- and the A's cancel out.  That's the initial conditions. ", "It's e to the minus zeta omega n t--  and I guess I called it t0-- over e ", "to the minus zeta omega n t0 plus n damped periods. ", " And if I bring this into the numerator,  the exponent becomes positive.  The t0 terms, minus zeta omega and t0 plus, those cancel. ", "And this expression is just e to the plus zeta omega  n times n td. ", " And the last step that I want to do to this, what I'm coming up  with is a way of estimating-- purposely ", "doing this-- is this transient curve we know is controlled  by a damping, by zeta. ", "I want to have an experimental way to determine what is zeta.  And I do it by computing something called  the logarithmic decrement. ", "So if I take the natural log of x of t over x of t  plus n periods, it's the natural log of this expression. ", "So I just get the exponent back.  This then is n zeta omega-- I guess ", "I better to do it carefully-- omega n n tau d.  The tau d is 2 pi over omega and I get some nice things ", "to cancel out here.  ", "So this natural log over the ratio-- this is n zeta omega n  and this is 2 pi over omega d, which ", "is omega n times the square root of 1 minus zeta squared.  Omega n's go away.  And for zeta small, this term's approximately 1, in which case ", "this then becomes n 2 pi zeta.  And zeta equals 1 over 2 pi n natural log ", "of this ratio of x of t over x of t plus nt.  ", "So experimentally, if you just go in and measure your--  if you plot out the response, you measure a peak value, ", "you measure the peak value n periods later,  compute the log of that ratio, divide by 1 over 2  pi n, the number of periods, you have ", "an estimate of the natural frequency--  estimate of the damping ratio, excuse me.   And to give you one quick little rule of thumb here, ", "so this is an experimental way that very quickly, you  can estimate the damping of a pendulum or whatever  by just doing a quick measurement. ", "", "So if it happens that after n periods,  this value is half of the initial value,  then this ratio is 2, right? ", "So x of t-- some n periods later, this is only half  as big.  This value's 2.  The natural log of 2 is some number you can calculate.  So there's a little rule. ", "If you just work that out, you find  that zeta equals 1 over 2 pi n 50% times the natural log of 2. ", "And you end up here was 0-- let me do this  carefully-- 1 over 2 pi, n 50%, natural log of 2. ", "And that is 0.11 over n 50%.  That's a really handy little engineer tool ", "to carry around in your head.  So if I have an oscillator, this little end here,  I can do an experiment. ", "Give it initial deflection and it starts off  at six inches or three inches amplitude.  And you let it oscillate until you see it die down  to half of that value. ", "So let's say, one, two, about four cycles  this thing decays by about 50%.  Four cycles-- plug 4 into that formula. ", "You get about 0.025.  Agree?  2 and a 1/2% damping.  Really very convenient little thing ", "to carry around with you-- measure pendulum,  how much damping does it have?  And now, this is what I'm saying.  Most things that have any substantial amount  of vibration, the damping is going to be way less than 10%. ", " If it dies, if it takes one cycle for the amplitude  to decrease, one cycle for the amplitude to decrease by 50%, ", "how much damping does it have?  AUDIENCE: 11%.  J. KIM VANDIVER: 11%.  So 11% damping is a lot of damping.  The thing starts out here and the next cycle, it's half gone, ", "and the next cycle after that, it's half of that.  And so in about three cycles, it's gone.  So if you see anything that's vibrating any length of time  at all, its damping is way less than 10% ", "and this notion of small damping is a perfectly good one.  And I'll close by just saying one other thing.  If something vibrates a lot, the damping's small. ", " You need small damping for things  to actually vibrate very much.  This thing, this is vibrating-- ", "[HIGH TONE]  that high-pitched one, that's about a kilohertz.  How many cycles do you think it's gone through  to get down to 50% of that initial amplitude ", "that you could hear?  A few thousand?  How much damping do you think this rod has?  Really tiny, really tiny. ", "All right.  So even though all we talked about today was  single degree of freedom oscillators,  I hope you learned a few things that we'll carry now  through the rest of the term.  We'll use all these concepts that we did today ", "to talk about more complicated vibration.  Good luck on your 2.001 quiz.  See you on Tuesday. "], "vid_duration": [11.39, 12.35, 11.15, 11.129, 13.671, 12.5, 10.81, 10.34, 11.23, 11.889, 10.52, 12.411, 14.35, 11.56, 15.29, 11.372, 11.208, 14.186, 10.282, 10.441, 13.432, 10.739, 10.89, 10.48, 20.023, 10.637, 10.0, 14.77, 11.53, 13.25, 11.69, 12.53, 11.56, 10.48, 14.352, 10.238, 10.63, 11.355, 10.855, 11.64, 10.43, 12.74, 13.51, 11.2, 10.94, 20.15, 10.876, 10.154, 10.53, 14.982, 11.708, 11.06, 12.0, 16.65, 12.81, 11.315, 10.855, 10.82, 11.02, 12.16, 22.87, 12.53, 10.29, 14.25, 24.53, 17.2, 11.42, 15.61, 13.2, 12.41, 11.07, 10.385, 14.395, 15.07, 20.12, 10.92, 13.37, 11.4, 16.35, 12.979, 12.92, 10.671, 10.82, 11.2, 12.56, 10.64, 15.386, 26.814, 11.94, 11.82, 13.37, 10.72, 10.7, 13.39, 13.65, 12.28, 11.3, 11.42, 10.92, 10.58, 12.89, 10.64, 13.62, 10.46, 10.89, 12.33, 14.23, 11.06, 11.03, 11.98, 11.02, 16.61, 11.536, 15.154, 14.917, 16.442, 10.071, 12.43, 13.23, 24.62, 11.94, 10.54, 12.57, 13.17, 19.71, 11.88, 41.27, 10.14, 12.81, 10.95, 12.75, 12.88, 16.19, 15.39, 15.822, 11.924, 13.474, 11.72, 14.11, 11.7, 10.34, 11.12, 11.87, 15.39, 11.87, 26.48, 10.2, 23.368, 11.432, 11.84, 10.3, 10.39, 14.08, 10.605, 10.475, 12.67, 14.46, 10.368, 15.995, 13.007, 15.24, 11.31, 12.4, 13.19, 10.01, 10.2, 10.39, 12.16, 10.41, 14.19, 13.0, 16.47, 10.28, 11.22, 12.09, 13.62, 22.5, 14.17, 11.81, 10.57, 11.905, 12.135, 10.06, 10.12, 11.86, 10.67, 15.33, 13.0, 10.06, 12.83, 12.14, 13.78, 11.16, 15.99, 12.04, 11.7, 14.15, 19.107, 19.123, 17.521, 11.399, 11.1, 34.72, 15.21, 15.66, 12.16, 13.28, 12.795, 13.875, 21.72, 11.12, 10.25, 11.73, 13.86, 11.27, 10.62, 12.34, 16.5, 10.07, 11.1, 10.69, 17.66, 15.76, 12.04, 23.26, 12.95, 10.27, 14.054, 13.146, 10.92, 19.996, 18.974, 11.98, 11.4, 19.36, 12.76, 13.36, 64.94, 11.36, 13.0, 12.78, 10.745, 13.145, 11.17, 10.04, 22.51, 12.3, 11.07, 12.33, 18.53, 14.65, 11.55, 24.24, 14.06, 14.25, 12.2, 10.51, 10.73, 12.72, 43.77, 19.98, 13.26, 13.17, 11.97, 13.319, 10.601, 12.95, 12.48, 10.23, 10.62, 11.607, 12.153, 10.31, 11.25, 10.15, 11.47, 14.82, 12.91, 10.04, 13.76, 11.06, 12.9, 15.24, 11.42, 20.78, 12.68, 17.08, 10.47, 11.46, 11.28, 10.49, 10.47, 10.985, 13.345, 10.745, 14.405, 11.214, 13.726, 12.28, 10.45, 16.97, 17.256, 10.913, 11.191, 14.41, 25.109, 18.051, 16.86, 11.9, 10.609, 13.431, 11.38, 33.69, 10.89, 11.07, 17.27, 10.66, 12.17, 10.79, 10.88, 13.78, 13.139, 12.359, 12.452, 11.659, 11.801, 12.715, 10.065, 12.5, 12.81, 12.67, 11.59], "stet": [[0, 11.39], [11.39, 23.740000000000002], [23.740000000000002, 34.89], [34.89, 46.019], [46.019, 59.69], [59.69, 72.19], [72.19, 83.0], [83.0, 93.34], [93.34, 104.57000000000001], [104.57000000000001, 116.459], [116.459, 126.979], [126.979, 139.39], [139.39, 153.73999999999998], [153.73999999999998, 165.29999999999998], [165.29999999999998, 180.58999999999997], [180.58999999999997, 191.962], [191.962, 203.17], [203.17, 217.356], [217.356, 227.638], [227.638, 238.079], [238.079, 251.511], [251.511, 262.25], [262.25, 273.14], [273.14, 283.62], [283.62, 303.64300000000003], [303.64300000000003, 314.28000000000003], [314.28000000000003, 324.28000000000003], [324.28000000000003, 339.05], [339.05, 350.58], [350.58, 363.83], [363.83, 375.52], [375.52, 388.04999999999995], [388.04999999999995, 399.60999999999996], [399.60999999999996, 410.09], [410.09, 424.44199999999995], [424.44199999999995, 434.67999999999995], [434.67999999999995, 445.30999999999995], [445.30999999999995, 456.66499999999996], [456.66499999999996, 467.52], [467.52, 479.15999999999997], [479.15999999999997, 489.59], [489.59, 502.33], [502.33, 515.84], [515.84, 527.0400000000001], [527.0400000000001, 537.9800000000001], [537.9800000000001, 558.1300000000001], [558.1300000000001, 569.0060000000001], [569.0060000000001, 579.1600000000001], [579.1600000000001, 589.69], [589.69, 604.672], [604.672, 616.38], [616.38, 627.4399999999999], [627.4399999999999, 639.4399999999999], [639.4399999999999, 656.0899999999999], [656.0899999999999, 668.8999999999999], [668.8999999999999, 680.2149999999999], [680.2149999999999, 691.0699999999999], [691.0699999999999, 701.89], [701.89, 712.91], [712.91, 725.0699999999999], [725.0699999999999, 747.9399999999999], [747.9399999999999, 760.4699999999999], [760.4699999999999, 770.7599999999999], [770.7599999999999, 785.0099999999999], [785.0099999999999, 809.5399999999998], [809.5399999999998, 826.7399999999999], [826.7399999999999, 838.1599999999999], [838.1599999999999, 853.7699999999999], [853.7699999999999, 866.9699999999999], [866.9699999999999, 879.3799999999999], [879.3799999999999, 890.4499999999999], [890.4499999999999, 900.8349999999999], [900.8349999999999, 915.2299999999999], [915.2299999999999, 930.3], [930.3, 950.42], [950.42, 961.3399999999999], [961.3399999999999, 974.7099999999999], [974.7099999999999, 986.1099999999999], [986.1099999999999, 1002.4599999999999], [1002.4599999999999, 1015.439], [1015.439, 1028.359], [1028.359, 1039.03], [1039.03, 1049.85], [1049.85, 1061.05], [1061.05, 1073.61], [1073.61, 1084.25], [1084.25, 1099.636], [1099.636, 1126.45], [1126.45, 1138.39], [1138.39, 1150.21], [1150.21, 1163.58], [1163.58, 1174.3], [1174.3, 1185.0], [1185.0, 1198.39], [1198.39, 1212.0400000000002], [1212.0400000000002, 1224.3200000000002], [1224.3200000000002, 1235.6200000000001], [1235.6200000000001, 1247.0400000000002], [1247.0400000000002, 1257.9600000000003], [1257.9600000000003, 1268.5400000000002], [1268.5400000000002, 1281.4300000000003], [1281.4300000000003, 1292.0700000000004], [1292.0700000000004, 1305.6900000000003], [1305.6900000000003, 1316.1500000000003], [1316.1500000000003, 1327.0400000000004], [1327.0400000000004, 1339.3700000000003], [1339.3700000000003, 1353.6000000000004], [1353.6000000000004, 1364.6600000000003], [1364.6600000000003, 1375.6900000000003], [1375.6900000000003, 1387.6700000000003], [1387.6700000000003, 1398.6900000000003], [1398.6900000000003, 1415.3000000000002], [1415.3000000000002, 1426.8360000000002], [1426.8360000000002, 1441.9900000000002], [1441.9900000000002, 1456.9070000000002], [1456.9070000000002, 1473.3490000000002], [1473.3490000000002, 1483.42], [1483.42, 1495.8500000000001], [1495.8500000000001, 1509.0800000000002], [1509.0800000000002, 1533.7], [1533.7, 1545.64], [1545.64, 1556.18], [1556.18, 1568.75], [1568.75, 1581.92], [1581.92, 1601.63], [1601.63, 1613.5100000000002], [1613.5100000000002, 1654.7800000000002], [1654.7800000000002, 1664.9200000000003], [1664.9200000000003, 1677.7300000000002], [1677.7300000000002, 1688.6800000000003], [1688.6800000000003, 1701.4300000000003], [1701.4300000000003, 1714.3100000000004], [1714.3100000000004, 1730.5000000000005], [1730.5000000000005, 1745.8900000000006], [1745.8900000000006, 1761.7120000000004], [1761.7120000000004, 1773.6360000000004], [1773.6360000000004, 1787.1100000000004], [1787.1100000000004, 1798.8300000000004], [1798.8300000000004, 1812.9400000000003], [1812.9400000000003, 1824.6400000000003], [1824.6400000000003, 1834.9800000000002], [1834.9800000000002, 1846.1000000000001], [1846.1000000000001, 1857.97], [1857.97, 1873.3600000000001], [1873.3600000000001, 1885.23], [1885.23, 1911.71], [1911.71, 1921.91], [1921.91, 1945.278], [1945.278, 1956.71], [1956.71, 1968.55], [1968.55, 1978.85], [1978.85, 1989.24], [1989.24, 2003.32], [2003.32, 2013.925], [2013.925, 2024.3999999999999], [2024.3999999999999, 2037.07], [2037.07, 2051.5299999999997], [2051.5299999999997, 2061.8979999999997], [2061.8979999999997, 2077.8929999999996], [2077.8929999999996, 2090.8999999999996], [2090.8999999999996, 2106.1399999999994], [2106.1399999999994, 2117.4499999999994], [2117.4499999999994, 2129.8499999999995], [2129.8499999999995, 2143.0399999999995], [2143.0399999999995, 2153.0499999999997], [2153.0499999999997, 2163.2499999999995], [2163.2499999999995, 2173.6399999999994], [2173.6399999999994, 2185.7999999999993], [2185.7999999999993, 2196.209999999999], [2196.209999999999, 2210.399999999999], [2210.399999999999, 2223.399999999999], [2223.399999999999, 2239.869999999999], [2239.869999999999, 2250.149999999999], [2250.149999999999, 2261.369999999999], [2261.369999999999, 2273.459999999999], [2273.459999999999, 2287.079999999999], [2287.079999999999, 2309.579999999999], [2309.579999999999, 2323.749999999999], [2323.749999999999, 2335.559999999999], [2335.559999999999, 2346.129999999999], [2346.129999999999, 2358.0349999999994], [2358.0349999999994, 2370.1699999999996], [2370.1699999999996, 2380.2299999999996], [2380.2299999999996, 2390.3499999999995], [2390.3499999999995, 2402.2099999999996], [2402.2099999999996, 2412.8799999999997], [2412.8799999999997, 2428.2099999999996], [2428.2099999999996, 2441.2099999999996], [2441.2099999999996, 2451.2699999999995], [2451.2699999999995, 2464.0999999999995], [2464.0999999999995, 2476.2399999999993], [2476.2399999999993, 2490.0199999999995], [2490.0199999999995, 2501.1799999999994], [2501.1799999999994, 2517.169999999999], [2517.169999999999, 2529.209999999999], [2529.209999999999, 2540.909999999999], [2540.909999999999, 2555.059999999999], [2555.059999999999, 2574.166999999999], [2574.166999999999, 2593.289999999999], [2593.289999999999, 2610.8109999999992], [2610.8109999999992, 2622.209999999999], [2622.209999999999, 2633.309999999999], [2633.309999999999, 2668.029999999999], [2668.029999999999, 2683.239999999999], [2683.239999999999, 2698.8999999999987], [2698.8999999999987, 2711.0599999999986], [2711.0599999999986, 2724.339999999999], [2724.339999999999, 2737.134999999999], [2737.134999999999, 2751.009999999999], [2751.009999999999, 2772.7299999999987], [2772.7299999999987, 2783.8499999999985], [2783.8499999999985, 2794.0999999999985], [2794.0999999999985, 2805.8299999999986], [2805.8299999999986, 2819.6899999999987], [2819.6899999999987, 2830.9599999999987], [2830.9599999999987, 2841.5799999999986], [2841.5799999999986, 2853.9199999999987], [2853.9199999999987, 2870.4199999999987], [2870.4199999999987, 2880.489999999999], [2880.489999999999, 2891.589999999999], [2891.589999999999, 2902.279999999999], [2902.279999999999, 2919.9399999999987], [2919.9399999999987, 2935.699999999999], [2935.699999999999, 2947.739999999999], [2947.739999999999, 2970.999999999999], [2970.999999999999, 2983.949999999999], [2983.949999999999, 2994.219999999999], [2994.219999999999, 3008.273999999999], [3008.273999999999, 3021.419999999999], [3021.419999999999, 3032.3399999999992], [3032.3399999999992, 3052.3359999999993], [3052.3359999999993, 3071.3099999999995], [3071.3099999999995, 3083.2899999999995], [3083.2899999999995, 3094.6899999999996], [3094.6899999999996, 3114.0499999999997], [3114.0499999999997, 3126.81], [3126.81, 3140.17], [3140.17, 3205.11], [3205.11, 3216.4700000000003], [3216.4700000000003, 3229.4700000000003], [3229.4700000000003, 3242.2500000000005], [3242.2500000000005, 3252.9950000000003], [3252.9950000000003, 3266.1400000000003], [3266.1400000000003, 3277.3100000000004], [3277.3100000000004, 3287.3500000000004], [3287.3500000000004, 3309.8600000000006], [3309.8600000000006, 3322.1600000000008], [3322.1600000000008, 3333.230000000001], [3333.230000000001, 3345.560000000001], [3345.560000000001, 3364.090000000001], [3364.090000000001, 3378.740000000001], [3378.740000000001, 3390.2900000000013], [3390.2900000000013, 3414.530000000001], [3414.530000000001, 3428.590000000001], [3428.590000000001, 3442.840000000001], [3442.840000000001, 3455.040000000001], [3455.040000000001, 3465.550000000001], [3465.550000000001, 3476.280000000001], [3476.280000000001, 3489.000000000001], [3489.000000000001, 3532.770000000001], [3532.770000000001, 3552.750000000001], [3552.750000000001, 3566.010000000001], [3566.010000000001, 3579.180000000001], [3579.180000000001, 3591.150000000001], [3591.150000000001, 3604.469000000001], [3604.469000000001, 3615.070000000001], [3615.070000000001, 3628.020000000001], [3628.020000000001, 3640.500000000001], [3640.500000000001, 3650.730000000001], [3650.730000000001, 3661.350000000001], [3661.350000000001, 3672.957000000001], [3672.957000000001, 3685.1100000000006], [3685.1100000000006, 3695.4200000000005], [3695.4200000000005, 3706.6700000000005], [3706.6700000000005, 3716.8200000000006], [3716.8200000000006, 3728.2900000000004], [3728.2900000000004, 3743.1100000000006], [3743.1100000000006, 3756.0200000000004], [3756.0200000000004, 3766.0600000000004], [3766.0600000000004, 3779.8200000000006], [3779.8200000000006, 3790.8800000000006], [3790.8800000000006, 3803.7800000000007], [3803.7800000000007, 3819.0200000000004], [3819.0200000000004, 3830.4400000000005], [3830.4400000000005, 3851.2200000000007], [3851.2200000000007, 3863.9000000000005], [3863.9000000000005, 3880.9800000000005], [3880.9800000000005, 3891.4500000000003], [3891.4500000000003, 3902.9100000000003], [3902.9100000000003, 3914.1900000000005], [3914.1900000000005, 3924.6800000000003], [3924.6800000000003, 3935.15], [3935.15, 3946.135], [3946.135, 3959.48], [3959.48, 3970.225], [3970.225, 3984.63], [3984.63, 3995.844], [3995.844, 4009.57], [4009.57, 4021.8500000000004], [4021.8500000000004, 4032.3], [4032.3, 4049.27], [4049.27, 4066.526], [4066.526, 4077.439], [4077.439, 4088.6299999999997], [4088.6299999999997, 4103.04], [4103.04, 4128.149], [4128.149, 4146.200000000001], [4146.200000000001, 4163.06], [4163.06, 4174.96], [4174.96, 4185.569], [4185.569, 4199.0], [4199.0, 4210.38], [4210.38, 4244.07], [4244.07, 4254.96], [4254.96, 4266.03], [4266.03, 4283.3], [4283.3, 4293.96], [4293.96, 4306.13], [4306.13, 4316.92], [4316.92, 4327.8], [4327.8, 4341.58], [4341.58, 4354.719], [4354.719, 4367.078], [4367.078, 4379.530000000001], [4379.530000000001, 4391.189], [4391.189, 4402.990000000001], [4402.990000000001, 4415.705000000001], [4415.705000000001, 4425.77], [4425.77, 4438.27], [4438.27, 4451.080000000001], [4451.080000000001, 4463.750000000001], [4463.750000000001, 4475.340000000001]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [283, 1209, 2002, 2398, 3531, 4476]}
{"example_id": "mit126@@MIT2_003SCF11_lec23_300k", "text": ["PROFESSOR: So Professor Gossard gave the lecture last week.  I'm going to pick up where he left off.  But let's talk about the concept questions from the homework ", "you've been working on.  So the first one is our cart.  You'd expect to be able eliminate the terms involving  gravity in the equations of motion  by choosing coordinates with respect ", "to the static equilibrium position.  So we've talked about that.  And with this one does the restoring force  on the pendulum, what makes it come back ", "to zero after it's a damped out and hanging straight down.  AUDIENCE: Gravity.  PROFESSOR: What?  Gravity does.  And that gravity term varies with the torque ", "that the gravity puts around the pivot is MgL over 2 sine theta.  So the gravity term is involved with the motion variable theta. ", "So in this case, gravity is going  to be involved in the natural frequency  and in the equations of motion, no matter what,  So you will not be able to eliminate the gravity terms. ", "Next, this one, this is a vibration isolation question.  Will the addition of damping increase or reduce  the vibration of the table in response ", "to the floor motion at 30 Hertz?   I guess this depends on what the natural frequency of the system ", "is.  But we're trying to do vibration isolation.  And presuming, if you read the problem,  you're supposed to find a a stiffness such  that you can reduce the response of the table by 12 dB, ", "I think it said, from the motion of the floor.  So that's something substantially less than 1.  And you will be-- this one takes a, best described ", "with a picture.   The transfer function for response of the table ", "over the motion of the floor, the magnitude  of that transfer function, that's  just the ratio of x to y.  That looks like this, if the damping is zero. ", "And as you add damping, all points cross right here.  Some damping does that.  More damping because of this. ", "And in order to accomplish what's been described--  this is 1.0 here. ", "If you're trying to make this table respond less  than the floor, you must be somewhere out here  where you're below 1.  So this is omega over omega n. ", "And right here at resonance, you're at 1.0.  So this is, you know, two or three or four for this value  out here.  Let's say here's where you find the answer to B. ", "And without damping, you're there.  And that's 12 dB down.  If you add damping, it pushes you up these curves.  Does make the response larger, the undesirable response, ", "the motion of the table larger or smaller  as you add damping at that operating point?  It increases it, right?  OK, so in this case, will the addition of damping ", "increase or reduce the vibration?  It'll increase it.  But damping's a necessary evil.  You need some damping in the system.  So if you bump it, it doesn't sit there and oscillate all day  long.  Next. ", "OK, this is a platform.  Do you think I could actually do it?  Did you read this?  So this is a Coast Guard light station off of Cuttyhunk  down off of Woods Hole-- basically, ", "I was doing this-- in time with the motion of the platform.  Resonance is a wonderful thing.  If you can make the force be right  at the natural frequency of the structure,  it actually doesn't take a lot of force ", "to drive the amplitude to pretty large amplitudes,  if the damping is small.  So I think the damping in this cases is about 1%.  And that means the amplification, ", "the dynamic amplification 1 over 2 zeta is about 50.  So I actually could do this.  This is a true story.  OK, next.  For small motions about the horizontal,  you expect the natural frequency to be a function of gravity. ", "So this is, oh, some of you, about equal, yes no.  But it's just horizontal, the torque that gravity provides  is some Mg pulling down on the center of mass ", "somewhere in that body.  Not at the pivot, but let's say some distance A away.  So the torque, the gravity, the restoring torque  is some Mg cross r cross Mg, Mgr if r is the distance. ", "And that's the torque.  And that length of that moment arm might vary.  It's going to vary like cosine theta.  Around horizontal line, if theta is what's, for small angles, ", "what's cosine?  It goes to 1.  So you find out that this just looks like Mgr.  It's for small angle of vibration.  And you can in fact get it out of-- it  doesn't enter into the equation for the natural frequency. ", "So the natural frequency of a thing  won't be a function of gravity because of this small angle  vibration around a horizontal point. ", "OK.  One, when the acceleration of the system  is one half that required to make the mass slide, what's  the magnitude of the friction force?  ", "So friction is one of those things that is only  as big as you need it to be.  So even the largest friction that this thing can sustain ", "is in fact mu mg-- answer A. But f equals ma  if the acceleration is half of what  is required to have that thing be just slip. ", "It will just slip when you are at a force which is mu mg.  And so that force is equal to mass times acceleration. ", "The acceleration then you can figure out  what that will be just when it slips.  But now if you reduce acceleration to half that,  the friction force required to keep it in place is only half  as big. ", "And it will be that friction force  and it will be half of mu mg.  So it's actually B.  And next-- is that it?  No.  OK. ", "This is a simple but actually sometimes  hard to see through question.  What initial conditions will be required? ", "This problem can be solved by initial conditions.  This mortar launches its shell.  And the trick to this question, the key to this question ", "is for your mathematical model of the system--  your equation in motion-- is write the equation of motion  without the shell.   Because once it shoots this thing, the shell's gone. ", "And it's vibrating.  It's now a system without that 25 kilogram mortar  shell part of the system.  It's gone.  Now it's just the mass of the system  without the mortar shell. ", "And there are two initial conditions  that then you can say when you shot the mortar shell, that was  a certain amount of momentum.  And from conservation of momentum you can figure out  what the momentum of the main mass has to be-- equal ", "and opposite to the shell you shot.  So that gives you an initial velocity.  But there's also an initial displacement in this problem.  So that's the key to figuring this out. ", "So what initial conditions would be required?  And it's C-- both an initial velocity  and an initial displacement.  But the key is to make your mathematical model ", "about the system without the shell.  OK?  Good.  Is that it?  All right.  So today we're going to pick up where ", "Professor Gossard left off.  But I'm also going to do a bit of a summary  right now about vibration and modeling ", "the different kinds of systems that we talk about when  we talk about vibration.  They vary from simple, single degree of freedom oscillators, ", "like a simple pendulum-- one degree  of freedom-- to continuous systems-- beams and vibrate.  So I'm going to try to give you just  sort of an overview of vibration just ", "to sort of give you a little map of information.   Kind of to let you know what the body of vibration analysis is ", "and what part of it we're covering in this course.  So I think I will use a little more board. ", "", "So we classify dynamics problems into,  for convenience, rigid bodies-- rigid body dynamics ", "and flexible bodies.  One way to think of it.   And this course is basically about rigid body dynamics. ", "And under this we then have two categories  that are convenient-- single degree of freedom systems  and multiple degree of freedom systems. ", " For the purposes of vendors-- talking about vibration.   Single degree of freedom systems have one equation of motion. ", "And if they vibrate, they have-- and if I'll put over here--  if vibration occurs then you have one natural frequency. ", " And it's sort of silly to talk about a mode  shape for a single degree of freedom system, ", "because it's only relative to itself.  So one natural frequency and one sort of degenerate mode shape.  Multiple degree of freedom systems  have n equations of motion for the number of degrees ", "of freedom.  And if they vibrate they have n omega i's, or m values ", "of omega i for i equals 1 to n.  You get n natural frequencies of the system. ", "And you will get with it n mode shapes.   So a n degree of freedom, this is ", "equal to the number of degrees of freedom.  An n degree of freedom system will  have n natural frequencies and n mode  shapes that go along with it.  Now, what about what about flexible bodies? ", "So a taut string like a guitar string.  ", "And actually I should say over here these rigid body  things-- we have found what kind of equations of motion?  These are ordinary differential equations. ", " And there's a finite number of them and so forth.  The flexible bodies like taut strings ", "are described by partial differential equations.  ", "The number of degrees of freedom n  here is the number of degrees of freedom  actually goes to infinity.  ", "And you get an infinite number of omega i's,  the natural frequencies, and an infinite number ", "of corresponding mode shapes.   So just about everything in the world can be made to vibrate. ", " So how do you tell if a-- you've got a mechanical system, ", "rigid bodies, you've got three degrees of freedom.  How do you know whether or not it's going to vibrate?   It will exhibit vibration?  ", "Well, one thing you could do is figure out  all the equations of motion and solve them  and see if cosine omega t is a solution.  Right?  That's the hard way. ", "The other way is to go up to it and give it a smack  and see if it vibrates.  That's the simple way.  If you have the mechanical system just give it a whack.  And if it oscillates around some stable equilibrium position, ", "it exhibits vibration.  So this is a flexible system.  You can actually probably see this from there.  Just by giving this frame a smack, it will sit and vibrate.  And it does it at some natural frequency. ", "But that's a continuous system.   This continuously improving little demo--  so Professor Gossard for his lecture last weekend ", "had done this really neat embellishment,  which allows you to figure out and excite the two  different natural modes.  But this system you have equations of motion for it.  You could write it. ", "And if you come up and give it a whack, it oscillates.  And you could also find out that sure enough cosine omega t sine  omega t are solutions to the equations of motion.  So systems that vibrate are systems ", "that oscillate about static equilibrium positions.  And another way you can say that is  when mechanical vibration occurs,  there's always an exchange of energy ", "between kinetic and potential, kinetic and potential.  So our pendulum it goes-- when it  reaches zero velocity up here, it's all potential energy. ", "It reaches maximum velocity down here, it's all kinetic.  And it goes back and forth.  As it sloshes back and forth the energy system  from kinetic to potential and back again.  All vibration has that property. ", "So that sets some basic properties of vibration.  And now there's a whole body of knowledge about vibration. ", "And we choose, or for the purposes of this class,  we choose to break it down into two kinds of vibration.  ", "And one is what we call free vibration.  ", "And that we've learned already is response, only a response.  It's a response to initial conditions ", "and what we call forced vibrations.   Now, forces can come of all kinds. ", "And for the purposes of this course  we look at a particular kind of force.  So we focus on harmonic excitation. ", " So excitation that is of the form cosine omega t, ", "or e to the i omega t.  These are external excitations.  ", "So we choose to break down the analysis  of the vibration of systems into response  to initial conditions called free vibration,  no external forces, and force vibration. ", "But we focus on a particular kind-- harmonic.  And we go even one step further and say we're only  going to study steady state.  ", "And steady state means you've waited a long time.  Turned it on, let it shake for quite awhile.  All the initial startup transients  have been damped out.  And you're left with a steady state vibration. ", "And that leads to things like the transfer functions  for single degree of freedom systems  that we've talked about.   Now, there's one other breakdown or subdivision ", "that we need to talk about.  And that is whether systems are linear or non-linear.   And this is all set up so you can see it. ", "This is a double pendulum.  How many degrees of freedom?  Two.  And in general, do you think the equations of motion  of this thing are going to be non-linear? ", "Right.  Just a simple pendulum is the restoring torque  is Mgl sine theta.  So you know it's got sine theta and that.  And this one gets quite messy. ", "And especially if you give it large amplitudes.   And that really isn't vibration. ", "It's not.  It's looping all over itself and then doing other things.  So cosine omega t is not a solution.  It's not a solution to this.  It's got to be more complicated than that. ", "So when this thing is exhibiting large motions,  the equations of motion are completely non-linear.  And you're going to need a computer  to crank out the full solution to integrate ", "these non-linear equations of motion.  But as the amplitude settles down to something pretty small, ", "now it's vibrating about an equilibrium position.  The equilibrium position is straight down.  And the damping of it has made it such  that the only motion left is what's called ", "its first mode of vibration.  And so if we linearize the equations of motion,  assuming small amplitudes around static equilibrium positions, ", "then we can find a vibration solution  and work it out by hand probably.  That's first mode for this system.  And if I'm careful-- there's second mode. ", " And for small oscillations it has  a very clear single frequency that it vibrates at.  The amplitude decays over time because of damping. ", "And for every natural frequency there  is a particular mode shape that goes along  with that natural frequency.  The first one for this system-- I  have to wait for this thing to damp out. ", "It's got a little mix of the two,  but as it-- the second natural frequency motion  dies out faster than the first because it  has more cycles per unit time. ", "So it settles down.  This is now mostly first mode vibration.  And you can see that both move in the same direction,  the bottom one a little more than the top.  And that's the first mode. ", "It has a unique natural frequency.  And a mode shape that is specific that goes along  with that natural frequency.  ", "So this further break down here, I'll call it, ", "is basically into non-linear and linearized.  ", "So in our discussions of vibration in this course  we basically only talk about this.  So we're only doing-- so that's quite a breakdown. ", "You start at all possible vibration systems,  rigid bodies, single degree of freedom,  multidegree of freedom, finite number of degrees of freedom  or continuous. ", "They can have linear or non-linear equations of motion.  But if we require them to be linear,  and that's what we're going to look at then ", "you sort of narrow this down what we're looking at to this.  So there's lots of other things possible to look  at it, like that really non-linear motion of that two  dimensional thing.  But our study of vibration is here. ", "So this is what we're doing in 2003.  But there's a lot of important problems  that are covered by that.   Lots of real things in nature that ", "are problematic for engineers and problematic for design  can be analyzed with linear equations of motion.  And even if they're not linear, if you do the linear solution ", "first, it gives you a starting point  to think about what's the behavior  of the non-linear systems.  But this is our study of vibration.  And we're going to do that for-- and what we had ", "started doing-- in two ways.  We look at the response to initial conditions called  free vibration. ", "And we look at response, steady state  response of now these linear systems to force vibration.  And last week you were looking for the first time ", "at Professor Gossard's lecture about the free vibration  response of basically a two degree freedom system.  So why do two degree of freedom systems? ", "Well, it's the simplest next step up from a single degree.  And they're sort of mathematically tractable.  You can do them on paper.  We emphasize looking at two degree freedom systems ", "because we can do the math on the board,  do the math on the paper.  But as you get to more degrees of freedom,  you basically are going to have to do-- it's easier  to do it using the computer.  And in order to do that you need to know some linear algebra. ", "So I'm kind curious.  In terms of linear algebra, like multiplying two matrices  together, or finding the determinant of a matrix,  or inverting a matrix, how many of you ", "actually have been taught that?  How may perhaps have it?  Do you do that in 1803 now?  Is that where you do it? ", "OK.  Good.  So that's helpful.  I wasn't sure whether or not.  I can assume that you at least know what  the determinant of a matrix is.  That's great.  That's really helpful. ", "OK.   Let's talk.  So we want linear equations of motion.  And I've done a little bit about linearization but not much. ", "So let's talk a little bit about that for a second.   For a pendulum we know the equation of motion for it. ", "And actually we could make this a more complicated pendulum.  It could be a stick or any rigid body swinging about this point  A. ", "We know that we can write the equation of motion Izz  with respect to A, theta double dot, plus Mgl-- omega L. ", "The distance here to wherever g is, Mgl sine theta. ", "And for free vibration that's all there is to it.  And to linearize this equation we just say,  well, we know that sine theta is equal to theta minus theta ", "cubed over 3 factorial plus theta to the fifth over 5  factorial.  And the cosine theta-- just to have it available here--  is 1 minus theta squared over 2 factorial and so forth. ", "And when we say linearize, we really  mean we want our equations to involve the motion variables  at most to first order.  So the first order term for sine is theta. ", "There's no first order term for cosine.   Theta squared is non-linear.  So the small angle approximation to cosine ", "is it's approximately 1.  And to sine is it's approximately  theta for small motions.  Theta-- small.  ", "So when we linearize this equation,  we just substitute in for sine theta its linear approximation.  And we get Mgl theta.  So we've seen that one many times. ", " And that's your linearized equation of motion.  But on this week's homework you've got a harder problem. ", "And that's our cart.  ", "And here you have a theta and an x are your two equations.  And you've worked this problem before.  And you know with the previous homeworks you've ", "gotten the equation of motion.  I'll write one of them down here.  So one of the equations of motion  is-- this is m1, m1, k, b. ", " And this is a stick, it's l long, g in the middle. ", "So the equation of motion for this looks like m1 plus m2, x  double dot plus m2 l over 2, theta double dot, ", "minus m2 l over 2 theta dot squared theta, ", "and then plus bx dot, plus kx, and equals,  and in fact, this one has a force on it. ", "It's equal to F of t.   Now, is that a non-linear equation?  ", "So this is the force equation mass  times acceleration or forces.  You know you've got another equation of motion  in here, which is the torque one.  This is just one of them.  So is it linear or non-linear?  ", "How many think it's non-linear?  OK.  If I have number the terms here-- one, two, three, four, ", "five.  And that's not a motion.  This doesn't involve motion.  So if one through five, which ones have a non-linear term?  AUDIENCE: Three.  J. KIM VANDIVER: Three.  OK.  So how do you linearize that thing? ", " AUDIENCE: You make it zero, because it's second order.  J. KIM VANDIVER: In fact, it's third order. ", "So the reason I wanted to mention this today--  if you haven't thought about being confronted  with linearization problems before-- we're  trying to linearize the system so that we ", "can by making it linear we can make cosine omega t a solution.  Right?  We want cosine omega t to be a solution to this thing. ", "So if you let-- so you've got a term that  looks like ml over m2l over 2, theta dot squared theta. ", "Well, theta in this problem of some function of time  we're hoping-- we want to find a solution that  has some amplitude times, say, a cosine omega t. ", "And theta dot is minus omega theta naught sine omega t.  And so that expression up there, the magnitude ", "of that expression or the magnitude of theta dot  squared theta is proportional to-- you get a theta  naught here and you get omega squared ", "theta naught squared here.  So this term is proportional to theta naught cubed.  And if the angle theta is small, then a small angle cubed ", "is really small.  And so the way you linearize this equation  is to throw this out.  So when you've done all your tricks you can, ", "like replacing sine theta with theta and cosine theta  with one, and you still end up with terms have a higher  order than one in the motion variable, theta or x, ", "you throw it out.   So if you throw that term out then you  end up with a nice linear equation in motion. ", "", "OK.  So now for the rest of today we're  going to talk about free vibration solution. ", "So we're not going to worry for the moment about the force  vibration steady state transfer function stuff.  We're talking just about free vibration.  And this is of linear equations of motion. ", "", "So vibration is a pretty big body of knowledge.  And we're doing an introduction to vibration in about half  a dozen lectures here.  So there's lots of things that I'm not ", "going to have time to teach you, but there  are a few things I really want you to go away with  and understanding.  And one of these key concepts is that the vibration ", "of a multiple degree of freedom system--  say this is a two degree of freedom system.  That the vibration of this system, the free vibration,  can be made up of the sum of two parts ", "at any vibration of this system at all.  So at any arbitrary set of initial conditions  I give it-- I let it go.  The key concept is the response will ", "be made up of two pieces-- vibration  in each of the two modes.  And if you can solve the vibration that's  in first mode-- first mode is the one where they're ", "going kind of together, second mode  they're opposite one another.  That the total solution can be made up  of a contribution for mode one and a contribution  from mode two. ", "So this is this concept called mode superposition. ", "It's really quite powerful.  So you can figure out the response of the first mode  in the system, figure out the response of the second mode's  contribution, add them together, and that's the total solution. ", "And this concept works-- there's all sorts of caveats  that one gets into-- but basically this is true ", "for all lightly damped systems. ", "You get into heavy damping and strange damping,  you have to make some adjustments.  But for lightly damped systems you'll  find that this concept of mode superposition ", "works out just fine.  So an illustration of this, a really simple illustration--  in some ways easier than this one. ", "I don't know if I can get this where you can see it  in the picture or not.  Maybe not really.  This is just two little lead weights.  This is a double pendulum.  It has two natural frequencies. ", "One is that one.  You can see the two weights going the same direction.  The bottom weight at a little bit more larger angle  than the top weight. ", "And it's at a particular frequency.  And that's the mode shape that goes through this frequency.  So another key concept is that for free vibration ", "the total solution is made up of the free vibration  of each mode.  And each mode has a particular frequency  and a particular shape to it. ", "So that's the first mode frequency and the first mode  shape.  The second mode-- I have a little harder time getting it  started-- it looks like that. ", "Masses move in opposite directions.  It's kind of rotating around where you can't see it.  I have to do it in the plane.  It's hard to do here. ", "It doesn't want to behave like it's confined to a plane.   They're going opposite directions.  And the frequency is higher. ", "But this motion, that mode shape,  is a fixed feature of this mode of vibration  along with this natural frequency.  So this idea of mode superposition-- ", "and a second concept here is that for free vibration ", "of each mode it oscillates at a unique frequency for this two ", "degree of freedom system.  You have two natural frequencies--  omega 1 and omega 2.  And at each omega n there is a corresponding mode shape. ", " So any vibration of a linear system, free vibration of it,  any vibration at all is composed of a superposition of the two ", "modes.  Part of this motion is in the first mode  at its natural frequency and in its shape.  And part of the motion has a second contribution, ", "which is at the natural frequency of the second mode  and in its shape.   So I'm going to give you a quick demo  and ask you-- let's if you can use what I just ", "said to analyze a motion.  ", "So this is just a block on some strings.  And I'm going to show you a motion.  And I want you to tell me whether or not ", "it could possibly be a natural frequency motion in one mode,  or the other answer is it's a sum of multiple modes. ", "But I'm going to show you a motion,  and I want you to tell me and argue  on the basis of what I've just told you whether or not  you are seeing a single mode of vibration.  ", "And maybe I'll use the clamp here  so I don't have to stand there and hold it.  ", "I'm going to just place this.  So the way you do free vibration is  you give it an initial displacement,  some initial conditions, and let go.  So I'm going to pull this over and back and let go. ", " And just watch closely what you see it do.  ", "All right, now it's doing more of what I want.  It's like it's going in a circle right now.  And now it looks like it's just going back and forth  on a diagonal.  And then it's going to start circling the other way. ", "It's going in a circle.  And now it goes to on the diagonal-- left and right.  And then it starts back into a circle again. ", "Are you observing a natural mode of vibration?  It looks like it's single frequency, right?  This looks like it's all happening at one frequency.  But is it a natural mode, a unique natural mode? ", " Who wants to make a case for whether it is or isn't?  How many believe that you're seeing ", "a natural mode of vibration?  None.  How many think you're not seeing a natural mode of vibration?  Let's see if you're awake.  OK.  So you don't believe that it's natural mode.  Make the case.  Why? ", "How do you use sort of this definition of a natural mode  to tell me why this can't be?  AUDIENCE: It looks like a superposition  of at least two different kinds of vibration. ", "J. KIM VANDIVER: OK.  The evidence that you see is because what does it do?  AUDIENCE: It circled sometimes.  And sometimes it goes straight back and forth on a diagonal.  J. KIM VANDIVER: OK.  So it circled around part of the time ", "and then goes straight back and forth part of the time.  Is it a constant mode shape of vibration?  No.  And that's all you need to observe. ", "If the thing doesn't keep a constant single shape  at a single frequency, it's not a natural mode.  So let's do a different case.  I'll deflect it just this way. ", "And ignore that little bit of torsion.  So it's just going back and forth in line.  Other than slowly damping out, that has just one motion to it,  and it's at one natural frequency. ", "So do you think that's a mode?  That probably is two.  And so is this one.   And ignore that high frequency.  Now it's just back and forth. ", "It's just a pendulum.  And it just stays in just pendular motion, no circling  around or any of that.  So that's also natural, and it occurs  at a particular frequency. ", "So these are two individual pendular emotions--  one this way and one that way.  And what I was doing at the beginning  is I pulled it to the side, which ", "would start one of those modes.  And I pulled it back, which will put  some energy into the other mode, and let it go.  And now what you have is the sum of these two different motions ", "adding up.  It goes in circles and then in straight lines.  And the fact that they-- this is a phenomenon called beading. ", "And it is because these two pendulums,  even though they have strings of the same length,  they actually have slightly different natural frequencies. ", "They're each single degree of freedom systems.  They're two independent single degree of freedom systems,  each with their own natural frequency.  But if you mix them then they're going to exhibit this motion. ", "So that's something really important to remember.  A quiz question that I like to ask is-- it's easy to grade  and it's no math required-- is to literally-- I've often ", "done this in exams-- walk in with something  like that block of wood and say, is this a natural mode?  ", "Time to do one-- let me see here.  ", "So now let's pick up where Professor Gossard left off.  Let's go talking about natural frequencies and mode  shapes of linearized two degree of freedom systems.  But I want to generalize a little bit on what he did. ", "So he, in his lecture, analyzed this system like this.   I'll just kind of put the highlights here. ", "", "And this is now solving for natural frequencies and mode ", "shapes.   He came up with a set of equations of motion for this.  This was, I guess, M1, M2. ", "And the equations of motion for this are m1 in matrix form.  ", "Now I'm going to do this to emphasize something.   In general there could be damping  in our linearized system. ", "And we have a stiffness matrix-- K1 plus K2 minus K2.  ", "And in general there could be forces,  which are functions of time on that system.  Now, if we want to find natural frequencies in mode shapes, ", "we go looking for what we call with the undamped natural  frequencies in mode shapes.  So this problem doesn't even have dampers in it.  But if it did for the purpose of finding  natural frequencies in mode shapes, you just set to 0. ", "And with the forces you do the same thing.   And now you have undamped, unforced equations of motion. ", " And this is then of the form of mass matrix times  an acceleration vector, X1, X2, plus a stiffness matrix, ", "times a displacement vector equals 0.  So in matrix notation it looks like that.   This is the way you would do any rigid body vibration problem. ", "This is two degrees of freedom.  But this is the general expression  for an n degree of freedom system.  If we had three masses here, then these would be 3 by 3 ", "matrices instead of 2 by 2's.  So that's the basic formulation.  And you went through last time with 2 by 2. ", "You can actually go through and find the fourth order equation  in omega and solve for two roots of omega squared. ", "And you've got the two natural frequencies, plug them back in.  You've got the two mode shapes that go along with them.  So you did it that way by hand so you  can see how you can work out the natural frequencies. ", "How can you do-- I'm going to show an approach that you'd  more likely use on a computer.  And if you get the larger order n degree of freedom systems, ", "you're going to want to do this-- instead of by hand--  have a computer do the work for you.  So this is the generic form.  And let's just assume for a minute ", "it's an n degree of freedom system.  So these are n by n matrices.  ", "How would we find the natural frequencies and mode  shapes of this general system?  So you assume solutions of the form ", "of what I've been describing-- a natural mode.  Any natural mode of the system has a particular shape  to it and a particular frequency. ", "And that's the key.  That's the key assumption here.  You assume solutions of the form that this vector x--  instead of writing it in brackets like this,  I'm going to make this. ", "So X here is just with a line underneath it.  So x is of the form X1 of t down to Xn ", "if you have n degrees of freedom.  You're looking for a solution for that thing.  And it's going to have an amplitude to it--  A1 down to An. ", "And this is any one mode.  So any one mode will look like a set of amplitudes  that govern its mode shape. ", "And it will oscillate.  We can write the oscillation as cosine omega.  And I'll put an i here, it's the i-th natural frequency  minus some phase angle. ", "So in general, each mode-- assume solutions--  I'll say here for each mode.  ", "So each mode, any mode, mode I will look like this.  It will have a shape to it governed by this.  And these are basically on constants.  Once determined, this is just a constant. ", "And here's your time dependence.  And it's going to-- I left out my t-- oscillate  at some natural frequency.  So we know this is what the solution has to look like. ", "And we can take this and plug it in to this equation.  ", "This vector of responses is some vector of amplitude  times the cosine omega t minus phi. ", "And just plug that into this set of matrix equations.  Note that x double dot is just a-- you get minus omega squared ", "a cosine omega t.   And we now substitute these into here. ", " You get minus omega squared for the first term. ", "Minus omega squared times the mass  matrix a cosine omega t minus phi, ", "plus this stiffness matrix a-- better consistent notation  here, excuse me-- a cosine omega t minus phi. ", "And all that's equal to zero.   So these go away.  You can cancel them out.  And we can factor out this a quantity. ", "And we have minus omega squared m, plus k times a equals 0. ", "So you can do this with any linearized n  degree of freedom system that you know  has a vibration solution to it.  ", "These are the unknown mode shapes.  And so in order to satisfy this equation,  either this a has to be 0, which is a trivial solution. ", "There's no motion, no mode shape--  or which this is trivial, not too useful. ", "Either a has to be 0, or the determinant of this quantity ", "has to be 0.  ", "But the way you do that on a computer--  so that would be beginning the way  you would analyze this by hand.  You find the determinant of that matrix.  And if it is a two degree of freedom system, ", "you'll get an equation n omega to the fourth, which has  two roots for omega squared.  If it's a three degree of freedom system,  you'll get an equation of omega to the sixth when you write out ", "that determinant.  And it has three roots for omega squared.  An n degree of freedom system has  an equation that's of order 2n omega to the 2nth power.  And it'll have n solutions or roots ", "for the natural frequency for omega squared.  But that would be if you're trying  to grind this out by hand.  ", "The way you do this on a computer-- maybe I  can get a little bit more on here.  ", "Come back here.  ", "So I'll go back to the earlier form I had here plus ka  equals 0.  And I'm going to multiply by m inverse. ", "So if I invert the mass matrix, if I  multiply a matrix by its inverse, what do you get?  So if I multiply m times m inverse? ", "AUDIENCE: A unit matrix.  J. KIM VANDIVER: You get a unit matrix, right?  It has ones on the diagonal.  So I'm going to multiply through here by this.  And so this gives me a minus omega squared. ", "And m times m inverse gives me the unit matrix--  ones on the diagonal.  Times a plus M inverse times ka equals 0. ", "And this product is just a matrix product-- m inverse  times k.  And I'm going to call it the a matrix.   And I'm going to move this to the other side. ", "So I have a linear algebraic expression  of the form a times the vector equals omega squared ", "times the unit matrix times a.   And I could go ahead and multiply this out. ", "For example, this times that and I'll get a vector.  So this just looks like omega squared  a if you multiply it out.  ", "The vector times the matrix is a vector on the left side.  A vector times a matrix gives me back a vector.  It's just the unit matrix.  So it gives me back the vector times omega squared. ", "This is in what is known as standard eigenvalue  formulation.  It's a standard eigenvalue problem now.  It's a problem of the form a times a vector equals ", "something lambda times a.  A parameter which we know happens  to be the frequency squared.  But this is standard eigenvalue formulation. ", "Yeah?  AUDIENCE: I was just asking if you wrote down  omega squared a because it's equal to the length up there.  J. KIM VANDIVER: Ah, good.  Omega squared a. ", "So a times the unit vector you get a back as a vector.  And I got the omega squared in front of it.  And oftentimes in a manual for Matlab or something  they'll describe this as some parameter. ", "It's a constant times a.  And this is standard what they call eigenvalue formulation.  And in Matlab if you say, for example, E equals EIG of A. ", "This returns a vector, which is the natural frequency squared. ", " It will return these lambdas.  And the first one is omega 1 squared down  to omega n squared.  ", "And if you go with this function,  if you go a little further, if you say V comma D is EIG A, ", "then this gives you two matrices back.  It gives you V. And V is a matrix, which  its columns are the mode shape. ", "So A1 to An, this is mode 1 over to A1 to An for mode n. ", "It gives you two matrices.  One that's that.  And another one a D matrix, which has the lambdas-- lambda ", "1 lambda n on the diagonals.  And it's a diagonal matrix.  So it gives you two matrices back. ", "One that has the eigenvectors, the mode shapes.  And another matrix whose diagonal elements are  the natural frequency squared. ", "And that's all there is to it if you do this numerically.  And there's lots of different programs.  There's multiple ways of doing this in Matlab. ", "When you do it this way it doesn't come out sometimes  nicely ordered and what I call normalized.  But it does produce the eigenvalues. ", "They're called eigenvalues and eigenvectors.  The eigenvalues are the lambdas, the natural frequencies  squared.  And the eigenvectors are these mode shapes that  go with each natural frequency. ", "Once you know the natural frequencies and mode shapes,  now we want to get back to talking about solutions.  This idea of mode superposition.  And if you give it a set of initial conditions, what  is the response? ", "How do you add these two modes together?  So let's go back now.  We'll return to two degree of freedom systems ", "like this one to do an example.   And we assume that the solution was sum A1, A2, cosine omega ", "t minus a phase angle.  That each mode would have this character to it.  And I'm going to normalize my mode shapes. ", "", "So for each mode shape of the system-- so  this could be for mode one.  This is the mode shape for mode one.  This is natural frequency one and phase angle one. ", "Each mode shape-- I could write this then  as-- I could factor out the A1.  Just pull out A1, divide each member by A1.  So this can be written as A1 times 1 and A2 over A1. ", "So I've just factored out.   So for mode one it's normalized mode shape-- ", "by normalize you just pick some way that you repeatedly use,  consistent in its use.  I often say let's make the top element of the vector 1. ", "And to make the top one 1 you factor out  whatever its value is that you get back from the computer  or from your calculation.  You factor that out of every member.  Now you have a normalized mode shape whose top element is 1. ", "There's lots of other normalization schemes.  That's just one way to do it.  And that's one of the mode shapes. ", "The total solution is X1, X2-- and this ", "is where the mode superposition part comes in--  is some undetermined constant A1 times the mode shape ", "A2 over A1 for mode 1 cosine omega 1 t minus phi 1.  And I'm going to run out of room. ", "", "And now the responses to initial conditions-- this  has got another term.  I'm just going to rewrite it here.  So we're looking at-- our total motion response  now by mode superposition will be A1, 1 A2 over A1, mode 1. ", "", "So the free vibration response of any two degree  of freedom system, linearized equation, any two  degree of freedom linear system can be made up ", "of the sum of two terms.  The motion at its first natural frequency in its first mode  shape. ", "And another term is the motion at a second natural frequency  and its second mode shape.  But now you have two undetermined constants  out here-- A1 and A2. ", "Where do they come from?   You have to use your initial conditions to get those.  I'll write down-- let's see. ", "I have just maybe enough time to write this down.   These are functions of time.  ", "So A1 and A2 come from the ICs, the initial conditions. ", "So at t equals 0, for example, plug in t equals 0 into here.  You get cosine phi. ", "And over here another phi 1 and another way over here.  Cosine of minus phi 1 is cosine phi 1.  So if you put in t equals 0, you find out the X1 ", "at 0, which I'll write X1 0, and X2 of 0  is equal to-- I'll actually write them out. ", "This is going to be A1 times 1 cosine phi 1, plus A2 times ", "1 cosine phi 2.  And the second equation that this gives you is A1-- ", "and now to keep from writing these many, many times,  I'm going to let this first A2 over A1 for mode 1 ", "be R1, and the second one A2 over A1 for mode 2.  I'll just call it R2.  And then I can write this out. ", "So the second equation, this is R1 cosine phi 1,  plus A2 R2 cosine phi 2. ", "And now I have initial conditions  that are normally given.  This is an initial displacement on 1  and a initial displacement on 2. ", "The phis I don't know.  And the A's I don't know.  I have four unknowns and two equations.  How do I get two more equations?  I take the derivative of this expression to get velocity. ", "And I get an A omega here and an A omega here.  And I plug in t equals 0.  And I get two more equations. ", "So X1 dot and X2 dot equal at t equals 0. ", "This gives me two more equations.  And if I have a place to write them-- for example, ", "X1 dot-- or X1 0 dot, the initial condition on velocity.  X2 dot-- this is two equations. ", " I've only got time to write down one of them.  And you could do the other for exercise.  You find this is A1 omega 1 sine phi 1, plus A2 omega ", "2 sine phi 2.  And the second equation is you get A1 R1 omega 1 sine phi 1, ", "plus A2 R2 omega 2 sine phi 2.  So now you have one, two. ", "And this is the initial conditions on velocity.  These are initial values of velocity.  Now you have one, two, three, four equations and one,  two, three, four unknowns-- the A1, A2, phi 1, phi 2. ", "And I guess I will give you the answer, so you have it once. ", "", "So a little tedious but this is sort of in the spirit of we  do two degree of freedom systems so  that we can see how it works.  And then for larger degrees of freedom systems ", "you would do this with a computer.  But the solution for A1 is 1 over R2 minus R1.  ", "It's all in terms now of things you know.  These R2's and R1's are part of the mode shape,  and the rest is initial conditions. ", "R2 x1 0, minus X2 0 squared, plus R2 V1 0, ", "minus V2 0 quantity squared, over omega 1  squared, the whole thing square root. ", "But now this is all stuff you know.  The given initial conditions on velocity,  given initial conditions on displacement.  You know the natural frequency.  You know the pieces of the mode shapes. ", "Just plug it in, you're going to get a number.  The magnitude of A1 for the given initial conditions.  A2-- a very similar expression-- minus R1 X1 0 plus x2 0 ", "squared And you'd solve for A2 and phi ", "1-- it's a little simpler-- minus tangent inverse,  phi 2 0 minus R2 V1 0, all over omega 1 R2 x1 0, minus x2 0. ", "That's one of the phase angles.  And the other phase angle, a very similar expression.  Minus tangent inverse, minus R1 V1 0, plus V2 0 omega ", "2 R1 x1 0, minus x2 0.  So just expressions in terms of the initial conditions and you ", "can get all four quantities.  You can also do this on the computer.  But in the few short lectures that we have  we're not going to get into that.  But this just shows you where it goes. ", "You could do this now.  There are straightforward ways of doing it  with matrix algebra on the computer.  Next time I'll do maybe just a quick example-- I didn't quite ", "get to it today-- of a response to initial conditions problem.  Plug it in there.  See what happens.  But we're out of time. ", "See you on Thursday. "], "vid_duration": [10.26, 11.83, 13.11, 13.56, 12.17, 14.16, 10.48, 13.91, 14.58, 16.18, 11.52, 12.8, 10.24, 10.58, 11.59, 10.5, 14.36, 12.32, 11.61, 10.43, 12.339, 10.721, 14.42, 13.5, 16.77, 11.85, 14.882, 10.868, 11.64, 10.29, 12.68, 15.28, 11.424, 10.496, 11.36, 10.27, 12.78, 11.03, 14.61, 10.11, 10.43, 11.64, 10.81, 10.12, 11.83, 14.86, 11.523, 22.977, 14.75, 10.86, 13.735, 13.985, 16.165, 11.515, 12.43, 10.37, 10.13, 10.6, 12.58, 11.67, 19.325, 11.025, 16.21, 11.25, 14.91, 13.53, 11.78, 14.98, 11.46, 13.89, 11.01, 11.2, 10.241, 14.019, 11.64, 12.3, 13.59, 21.81, 27.342, 11.617, 16.351, 11.85, 12.49, 21.43, 13.53, 12.13, 12.609, 10.921, 14.57, 12.85, 12.42, 11.592, 12.698, 10.54, 10.02, 11.78, 10.87, 12.56, 14.28, 13.315, 13.375, 10.969, 10.731, 23.78, 16.28, 16.34, 28.91, 10.68, 10.06, 12.246, 10.914, 10.85, 12.33, 10.56, 13.18, 10.92, 10.534, 12.876, 12.82, 10.19, 11.321, 14.909, 14.801, 10.139, 10.13, 12.75, 12.64, 16.27, 11.35, 10.91, 10.46, 10.27, 13.202, 11.358, 12.04, 13.96, 11.65, 22.0, 10.38, 14.07, 22.18, 13.13, 11.93, 11.26, 11.4, 13.26, 10.38, 18.74, 12.4, 11.53, 13.95, 15.4, 12.495, 13.535, 11.41, 13.48, 17.319, 15.75, 18.36, 12.69, 15.981, 16.51, 10.97, 11.33, 10.99, 10.24, 13.03, 14.81, 14.82, 10.03, 11.61, 12.58, 11.46, 10.25, 10.95, 10.82, 10.31, 11.65, 13.02, 22.77, 33.43, 22.48, 13.65, 10.57, 15.01, 14.52, 10.46, 13.122, 12.258, 32.992, 14.173, 34.819, 11.146, 10.27, 14.13, 11.26, 10.86, 12.65, 10.38, 12.19, 13.01, 11.5, 10.588, 10.752, 11.05, 10.96, 10.16, 10.954, 11.135, 11.061, 15.03, 35.58, 14.42, 10.59, 15.39, 12.24, 11.505, 15.831, 12.154, 17.79, 11.47, 14.43, 12.57, 13.87, 14.95, 10.1, 10.89, 11.52, 11.47, 10.2, 13.73, 11.17, 20.17, 12.599, 12.013, 17.548, 14.69, 11.84, 12.36, 10.55, 10.11, 10.14, 13.94, 12.98, 12.9, 11.865, 12.115, 10.71, 13.877, 12.793, 17.79, 12.37, 10.18, 16.41, 12.82, 10.45, 13.58, 10.38, 13.18, 10.34, 10.25, 18.67, 19.74, 10.61, 10.52, 19.67, 11.88, 14.71, 12.8, 11.64, 12.69, 16.39, 13.56, 10.74, 12.09, 26.31, 10.735, 11.325, 11.39, 13.14, 11.11, 12.91, 10.79, 10.07, 10.15, 10.727, 14.443, 10.44, 12.72, 19.17, 11.805, 12.145, 11.93, 18.71, 11.49, 13.18, 12.33, 12.91, 14.45, 11.29, 11.13, 25.245, 25.06, 21.645, 11.78, 10.05, 10.36, 11.11, 10.879, 12.401, 12.64, 11.36, 13.328, 12.682, 11.17, 12.355, 10.435, 16.59, 11.88, 11.34, 12.79, 16.74, 12.51, 10.315, 20.094, 11.461, 11.96, 15.36, 10.32, 17.74, 12.55, 12.125, 10.785, 16.75, 13.06, 10.94, 23.58, 25.17, 24.77, 18.11, 11.45, 10.45, 11.919, 10.791, 3.38], "stet": [[0, 10.26], [10.26, 22.09], [22.09, 35.2], [35.2, 48.760000000000005], [48.760000000000005, 60.93000000000001], [60.93000000000001, 75.09], [75.09, 85.57000000000001], [85.57000000000001, 99.48], [99.48, 114.06], [114.06, 130.24], [130.24, 141.76000000000002], [141.76000000000002, 154.56000000000003], [154.56000000000003, 164.80000000000004], [164.80000000000004, 175.38000000000005], [175.38000000000005, 186.97000000000006], [186.97000000000006, 197.47000000000006], [197.47000000000006, 211.83000000000004], [211.83000000000004, 224.15000000000003], [224.15000000000003, 235.76000000000005], [235.76000000000005, 246.19000000000005], [246.19000000000005, 258.52900000000005], [258.52900000000005, 269.25000000000006], [269.25000000000006, 283.6700000000001], [283.6700000000001, 297.1700000000001], [297.1700000000001, 313.94000000000005], [313.94000000000005, 325.7900000000001], [325.7900000000001, 340.6720000000001], [340.6720000000001, 351.5400000000001], [351.5400000000001, 363.18000000000006], [363.18000000000006, 373.4700000000001], [373.4700000000001, 386.1500000000001], [386.1500000000001, 401.43000000000006], [401.43000000000006, 412.85400000000004], [412.85400000000004, 423.35], [423.35, 434.71000000000004], [434.71000000000004, 444.98], [444.98, 457.76], [457.76, 468.78999999999996], [468.78999999999996, 483.4], [483.4, 493.51], [493.51, 503.94], [503.94, 515.58], [515.58, 526.39], [526.39, 536.51], [536.51, 548.34], [548.34, 563.2], [563.2, 574.7230000000001], [574.7230000000001, 597.7], [597.7, 612.45], [612.45, 623.3100000000001], [623.3100000000001, 637.0450000000001], [637.0450000000001, 651.0300000000001], [651.0300000000001, 667.195], [667.195, 678.71], [678.71, 691.14], [691.14, 701.51], [701.51, 711.64], [711.64, 722.24], [722.24, 734.82], [734.82, 746.49], [746.49, 765.815], [765.815, 776.84], [776.84, 793.0500000000001], [793.0500000000001, 804.3000000000001], [804.3000000000001, 819.21], [819.21, 832.74], [832.74, 844.52], [844.52, 859.5], [859.5, 870.96], [870.96, 884.85], [884.85, 895.86], [895.86, 907.0600000000001], [907.0600000000001, 917.301], [917.301, 931.32], [931.32, 942.96], [942.96, 955.26], [955.26, 968.85], [968.85, 990.66], [990.66, 1018.002], [1018.002, 1029.619], [1029.619, 1045.9699999999998], [1045.9699999999998, 1057.8199999999997], [1057.8199999999997, 1070.3099999999997], [1070.3099999999997, 1091.7399999999998], [1091.7399999999998, 1105.2699999999998], [1105.2699999999998, 1117.3999999999999], [1117.3999999999999, 1130.0089999999998], [1130.0089999999998, 1140.9299999999998], [1140.9299999999998, 1155.4999999999998], [1155.4999999999998, 1168.3499999999997], [1168.3499999999997, 1180.7699999999998], [1180.7699999999998, 1192.3619999999999], [1192.3619999999999, 1205.06], [1205.06, 1215.6], [1215.6, 1225.62], [1225.62, 1237.3999999999999], [1237.3999999999999, 1248.2699999999998], [1248.2699999999998, 1260.8299999999997], [1260.8299999999997, 1275.1099999999997], [1275.1099999999997, 1288.4249999999997], [1288.4249999999997, 1301.7999999999997], [1301.7999999999997, 1312.7689999999998], [1312.7689999999998, 1323.4999999999998], [1323.4999999999998, 1347.2799999999997], [1347.2799999999997, 1363.5599999999997], [1363.5599999999997, 1379.8999999999996], [1379.8999999999996, 1408.8099999999997], [1408.8099999999997, 1419.4899999999998], [1419.4899999999998, 1429.5499999999997], [1429.5499999999997, 1441.7959999999998], [1441.7959999999998, 1452.7099999999998], [1452.7099999999998, 1463.5599999999997], [1463.5599999999997, 1475.8899999999996], [1475.8899999999996, 1486.4499999999996], [1486.4499999999996, 1499.6299999999997], [1499.6299999999997, 1510.5499999999997], [1510.5499999999997, 1521.0839999999998], [1521.0839999999998, 1533.9599999999998], [1533.9599999999998, 1546.7799999999997], [1546.7799999999997, 1556.9699999999998], [1556.9699999999998, 1568.2909999999997], [1568.2909999999997, 1583.1999999999998], [1583.1999999999998, 1598.0009999999997], [1598.0009999999997, 1608.1399999999996], [1608.1399999999996, 1618.2699999999998], [1618.2699999999998, 1631.0199999999998], [1631.0199999999998, 1643.6599999999999], [1643.6599999999999, 1659.9299999999998], [1659.9299999999998, 1671.2799999999997], [1671.2799999999997, 1682.1899999999998], [1682.1899999999998, 1692.6499999999999], [1692.6499999999999, 1702.9199999999998], [1702.9199999999998, 1716.1219999999998], [1716.1219999999998, 1727.4799999999998], [1727.4799999999998, 1739.5199999999998], [1739.5199999999998, 1753.4799999999998], [1753.4799999999998, 1765.1299999999999], [1765.1299999999999, 1787.1299999999999], [1787.1299999999999, 1797.51], [1797.51, 1811.58], [1811.58, 1833.76], [1833.76, 1846.89], [1846.89, 1858.8200000000002], [1858.8200000000002, 1870.0800000000002], [1870.0800000000002, 1881.4800000000002], [1881.4800000000002, 1894.7400000000002], [1894.7400000000002, 1905.1200000000003], [1905.1200000000003, 1923.8600000000004], [1923.8600000000004, 1936.2600000000004], [1936.2600000000004, 1947.7900000000004], [1947.7900000000004, 1961.7400000000005], [1961.7400000000005, 1977.1400000000006], [1977.1400000000006, 1989.6350000000004], [1989.6350000000004, 2003.1700000000005], [2003.1700000000005, 2014.5800000000006], [2014.5800000000006, 2028.0600000000006], [2028.0600000000006, 2045.3790000000006], [2045.3790000000006, 2061.129000000001], [2061.129000000001, 2079.489000000001], [2079.489000000001, 2092.179000000001], [2092.179000000001, 2108.160000000001], [2108.160000000001, 2124.6700000000014], [2124.6700000000014, 2135.6400000000012], [2135.6400000000012, 2146.970000000001], [2146.970000000001, 2157.960000000001], [2157.960000000001, 2168.2000000000007], [2168.2000000000007, 2181.230000000001], [2181.230000000001, 2196.040000000001], [2196.040000000001, 2210.860000000001], [2210.860000000001, 2220.8900000000012], [2220.8900000000012, 2232.5000000000014], [2232.5000000000014, 2245.0800000000013], [2245.0800000000013, 2256.5400000000013], [2256.5400000000013, 2266.7900000000013], [2266.7900000000013, 2277.740000000001], [2277.740000000001, 2288.5600000000013], [2288.5600000000013, 2298.8700000000013], [2298.8700000000013, 2310.5200000000013], [2310.5200000000013, 2323.5400000000013], [2323.5400000000013, 2346.3100000000013], [2346.3100000000013, 2379.740000000001], [2379.740000000001, 2402.220000000001], [2402.220000000001, 2415.8700000000013], [2415.8700000000013, 2426.4400000000014], [2426.4400000000014, 2441.4500000000016], [2441.4500000000016, 2455.9700000000016], [2455.9700000000016, 2466.4300000000017], [2466.4300000000017, 2479.5520000000015], [2479.5520000000015, 2491.8100000000013], [2491.8100000000013, 2524.8020000000015], [2524.8020000000015, 2538.9750000000013], [2538.9750000000013, 2573.7940000000012], [2573.7940000000012, 2584.9400000000014], [2584.9400000000014, 2595.2100000000014], [2595.2100000000014, 2609.3400000000015], [2609.3400000000015, 2620.6000000000017], [2620.6000000000017, 2631.460000000002], [2631.460000000002, 2644.110000000002], [2644.110000000002, 2654.490000000002], [2654.490000000002, 2666.680000000002], [2666.680000000002, 2679.6900000000023], [2679.6900000000023, 2691.1900000000023], [2691.1900000000023, 2701.7780000000025], [2701.7780000000025, 2712.5300000000025], [2712.5300000000025, 2723.5800000000027], [2723.5800000000027, 2734.5400000000027], [2734.5400000000027, 2744.7000000000025], [2744.7000000000025, 2755.6540000000027], [2755.6540000000027, 2766.789000000003], [2766.789000000003, 2777.850000000003], [2777.850000000003, 2792.8800000000033], [2792.8800000000033, 2828.460000000003], [2828.460000000003, 2842.8800000000033], [2842.8800000000033, 2853.4700000000034], [2853.4700000000034, 2868.8600000000033], [2868.8600000000033, 2881.100000000003], [2881.100000000003, 2892.605000000003], [2892.605000000003, 2908.4360000000033], [2908.4360000000033, 2920.5900000000033], [2920.5900000000033, 2938.3800000000033], [2938.3800000000033, 2949.850000000003], [2949.850000000003, 2964.280000000003], [2964.280000000003, 2976.850000000003], [2976.850000000003, 2990.720000000003], [2990.720000000003, 3005.670000000003], [3005.670000000003, 3015.7700000000027], [3015.7700000000027, 3026.6600000000026], [3026.6600000000026, 3038.1800000000026], [3038.1800000000026, 3049.6500000000024], [3049.6500000000024, 3059.850000000002], [3059.850000000002, 3073.580000000002], [3073.580000000002, 3084.7500000000023], [3084.7500000000023, 3104.9200000000023], [3104.9200000000023, 3117.5190000000025], [3117.5190000000025, 3129.5320000000024], [3129.5320000000024, 3147.080000000002], [3147.080000000002, 3161.7700000000023], [3161.7700000000023, 3173.6100000000024], [3173.6100000000024, 3185.9700000000025], [3185.9700000000025, 3196.5200000000027], [3196.5200000000027, 3206.630000000003], [3206.630000000003, 3216.7700000000027], [3216.7700000000027, 3230.7100000000028], [3230.7100000000028, 3243.690000000003], [3243.690000000003, 3256.590000000003], [3256.590000000003, 3268.4550000000027], [3268.4550000000027, 3280.5700000000024], [3280.5700000000024, 3291.2800000000025], [3291.2800000000025, 3305.1570000000024], [3305.1570000000024, 3317.9500000000025], [3317.9500000000025, 3335.7400000000025], [3335.7400000000025, 3348.1100000000024], [3348.1100000000024, 3358.2900000000022], [3358.2900000000022, 3374.700000000002], [3374.700000000002, 3387.5200000000023], [3387.5200000000023, 3397.970000000002], [3397.970000000002, 3411.550000000002], [3411.550000000002, 3421.930000000002], [3421.930000000002, 3435.110000000002], [3435.110000000002, 3445.450000000002], [3445.450000000002, 3455.700000000002], [3455.700000000002, 3474.370000000002], [3474.370000000002, 3494.110000000002], [3494.110000000002, 3504.720000000002], [3504.720000000002, 3515.240000000002], [3515.240000000002, 3534.910000000002], [3534.910000000002, 3546.7900000000022], [3546.7900000000022, 3561.5000000000023], [3561.5000000000023, 3574.3000000000025], [3574.3000000000025, 3585.9400000000023], [3585.9400000000023, 3598.6300000000024], [3598.6300000000024, 3615.0200000000023], [3615.0200000000023, 3628.580000000002], [3628.580000000002, 3639.320000000002], [3639.320000000002, 3651.410000000002], [3651.410000000002, 3677.720000000002], [3677.720000000002, 3688.455000000002], [3688.455000000002, 3699.780000000002], [3699.780000000002, 3711.170000000002], [3711.170000000002, 3724.3100000000018], [3724.3100000000018, 3735.420000000002], [3735.420000000002, 3748.3300000000017], [3748.3300000000017, 3759.1200000000017], [3759.1200000000017, 3769.190000000002], [3769.190000000002, 3779.340000000002], [3779.340000000002, 3790.067000000002], [3790.067000000002, 3804.510000000002], [3804.510000000002, 3814.950000000002], [3814.950000000002, 3827.670000000002], [3827.670000000002, 3846.840000000002], [3846.840000000002, 3858.645000000002], [3858.645000000002, 3870.790000000002], [3870.790000000002, 3882.7200000000016], [3882.7200000000016, 3901.4300000000017], [3901.4300000000017, 3912.9200000000014], [3912.9200000000014, 3926.1000000000013], [3926.1000000000013, 3938.430000000001], [3938.430000000001, 3951.340000000001], [3951.340000000001, 3965.790000000001], [3965.790000000001, 3977.080000000001], [3977.080000000001, 3988.210000000001], [3988.210000000001, 4013.455000000001], [4013.455000000001, 4038.515000000001], [4038.515000000001, 4060.1600000000008], [4060.1600000000008, 4071.940000000001], [4071.940000000001, 4081.990000000001], [4081.990000000001, 4092.3500000000013], [4092.3500000000013, 4103.460000000001], [4103.460000000001, 4114.339000000001], [4114.339000000001, 4126.740000000001], [4126.740000000001, 4139.380000000001], [4139.380000000001, 4150.740000000001], [4150.740000000001, 4164.068000000001], [4164.068000000001, 4176.750000000001], [4176.750000000001, 4187.920000000001], [4187.920000000001, 4200.275000000001], [4200.275000000001, 4210.710000000001], [4210.710000000001, 4227.300000000001], [4227.300000000001, 4239.180000000001], [4239.180000000001, 4250.520000000001], [4250.520000000001, 4263.310000000001], [4263.310000000001, 4280.050000000001], [4280.050000000001, 4292.560000000001], [4292.560000000001, 4302.875000000001], [4302.875000000001, 4322.969000000001], [4322.969000000001, 4334.430000000001], [4334.430000000001, 4346.390000000001], [4346.390000000001, 4361.750000000001], [4361.750000000001, 4372.070000000001], [4372.070000000001, 4389.81], [4389.81, 4402.360000000001], [4402.360000000001, 4414.485000000001], [4414.485000000001, 4425.27], [4425.27, 4442.02], [4442.02, 4455.080000000001], [4455.080000000001, 4466.02], [4466.02, 4489.6], [4489.6, 4514.77], [4514.77, 4539.540000000001], [4539.540000000001, 4557.650000000001], [4557.650000000001, 4569.1], [4569.1, 4579.55], [4579.55, 4591.469], [4591.469, 4602.26], [4602.26, 4605.64]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [513, 1571, 2027, 2827, 3805, 4606]}
{"example_id": "mit126@@MIT2_003SCF11_lec04_300k", "text": ["PROFESSOR: So we were doing velocities and accelerations.  We came up with-- I guess I ought to continue to remind us. ", "We're talking about velocities and accelerations  of a point with respect to another point, to which we've  attached-- I'll make this point here-- ", "a reference frame, x prime, y prime, z prime.  And there's a vector that goes between these two  and a vector that goes there so that we can say r of B ", "with respect to O, my inertial frame, is r of A  with respect to O plus r of B with respect  to A. These are all vectors. ", "And then from these, we derive velocities and acceleration  formulas.  And so we've come up with a couple of very handy formulas.  The velocity formula, velocity of B with respect to O, ", "is the velocity of A with respect  to O plus you have to take a time derivative of this.  And so I'm going to give you just the general expression ", "here just as a brief reminder.  It's the derivative of B with respect  to A as seen in the Axyz frame plus omega with respect to O ", "cross rBA.  These are all vectors.   So that's the velocity formula, remember?  This is if you're in the frame rotating ", "and translating with it, this is the change  of length of the vector.  And this, then, is the contribution to the velocity  that you see in the fixed frame that comes from the rotation. ", "And we then got into polar coordinates.  And we found out that if you use polar coordinates,  then you can express this as the velocity of A  with respect to O plus r dot r hat. ", "And I should really say cylindrical coordinates,  z dot k hat plus r theta dot theta hat. ", "So that's exactly the same thing.  This is full 3D vector notation.  This is a special case of a coordinate system which  we call polar coordinates. ", "And we came up with another formula for accelerations,  the full 3D vector version of that, A with respect ", "to O plus-- this is the acceleration of B  with respect to A, but as seen in the Axyz frame. ", " 2 omega cross-- and this is v, the velocity, ", "as seen in the xyz frame.  So these things, this is no contribution from acceleration.  This is no contribution from acceleration.  ", "Plus omega naught cross rBA plus omega cross  omega cross rBA-- all vectors. ", " This is a movement of the frame, the acceleration of it  with respect to this.  This is pure translation. ", "This is the acceleration of the dog on the merry go  round with respect to the center of the coordinate system there.  It does not involve rotation. ", "This is this term that we call Coriolis.  This is a term we call Euler.  This is the angular speed up of the system, the angular  acceleration. ", "And this is centripetal.   And if you do these, if you want to go  to cylindrical coordinates-- and what we're going to do next  is just do some applications here. ", "The acceleration of B with respect to O and cylindrical  coordinates-- it's a translation piece.  Plus now in cylindrical, it's useful to group these. ", " So I'm going to put together this term and this term. ", "Because they're both in the r hat direction.  And I'm going to put together these two terms.  Because they're both in the theta hat direction.  And I need a z double dot k, because it's cylindrical. ", "And then I have the theta hat piece,  r theta double dot plus 2r dot theta dot theta hat. ", "This is the same thing as this.  Except this is expressed in cylindrical coordinates.  And cylindrical coordinates are particularly ", "good for doing the kind of problems that are mostly  done at the level of this course, which we call planar  motion problems, confined to an x, y plane, ", "and confined to single axis rotation in z.  This is a coordinate system that's ideally suited  to do problems like that.  And that's why we use it. ", "So now let's do some examples.  This is really quite a powerful-- ", "now that you have these two equations,  you can do a lot of kinematics and dynamics.  ", "So we started last time right at the very end.  I said, OK, let's do this problem really quickly, right? ", "Constant rotation rate, constant radius,  no angular acceleration, no change  in length of the thing-- pretty simple problem.  And we zipped it off really fast. ", "And I wanted to start there, do that really quickly.  So this is my case one.  It's my ball on the string.  ", "Here's point A. Here's point B. Here's the theta hat  direction, r hat direction. ", "And it has some constant length R here.  So r dot r double dot are 0. ", "There's no also z, z dot, z double dot, no z motion at all.  Those are all 0. ", "Theta dot is a constant.  I'll call it cap omega in the k hat direction, right hand rule.  Theta double dot is 0. ", "So the easy way to use these formulas  is you just start knocking out all the terms  that you don't need.  But let's, just to give you a little quick review of how ", "to use these things, use the vector full  3D version of the velocity equation for a second.  The full 3D version says the velocity of A ", "with respect to O, what's that in this problem?  That's the translating term.  So I was standing still, not going anywhere. ", "But if I were walking along, I'd still spin that thing.  OK, so this problem, this term is 0.  This problem, r dot-- let's go here. ", "This is the rate of change of the length  of the string in the coordinate system of the string walking  along.  So what's r dot?  OK, so that term is 0. ", "And omega cross rBA-- well, r is in the R hat, capital R R hat,  cross with omega k. ", "k cross R is-- k cross of R hat?  STUDENT: Theta.  PROFESSOR: Theta hat.  So we get our familiar-- this first term is 0. ", "The second term is 0.  The third term, we just get our R omega  in the theta hat direction.  We know that to be true.  The point I'm just trying to make here ", "is you can always just fall back and use the vector formula,  full 3D formulas of both.  Just plug it in, and everything will just drop out.  You can also then go to the cylindrical coordinate terms ", "when you happen to have it all expressed  in coordinates of that kind to make it simpler for you.  OK, so now let's quickly then do the acceleration of B ", "with respect to O. And let's use the formulation already  in cylindrical coordinates.  What's A with respect to O? ", "0.  What's r double dot?  How about the r theta dot squared term, 0 or not?  Nope.  Let's go on-- z double dot? ", "STUDENT: 0.  PROFESSOR: r theta double dot?  STUDENT: 0.  PROFESSOR: r dot theta dot?  STUDENT: 0  PROFESSOR: OK, we only end up with one term.  Actually, I'm going to keep this one for a second-- A  with respect to O minus. ", "And we came up with our R theta dot squared r hat term.  I leave this in here because I actually don't have to say. ", "If I wanted now to do this problem,  if I asked you to do a problem where I'm doing this,  and I start accelerating, do you know how to do it? ", "There's the answer-- still there, right?   All right, let's do a quick free body diagram. ", " Here's our mass, my master coordinate system out here. ", "Let's draw-- let's say it's right here at 90 degrees.   What are the external forces on the mass in this problem? ", " STUDENT: [INAUDIBLE].  PROFESSOR: So there's tension in the string, right?  OK, so now this is a really trivially simple problem. ", "So the emphasize here is on the concept.  So now when you're asked to come up with an equation of motion  or compute the forces on a mass, use Newton's second law, ", "F equals mass times acceleration.  You now have the complete 3D vector formulation  for acceleration of a particle in a translating rotating ", "coordinate system.  That's all you need to compute accelerations for lots  and lots of difficult problems.  And so if you can write down the acceleration, ", "you say it's equal to what?  Mass-- if you multiply mass times that acceleration,  what's that equal to?  STUDENT: The force. ", "PROFESSOR: The forces that must be acting on the system.  And that's the point here.  So now I want to know the forces on the system, the summation  of the external forces.  And then these are vectors. ", "And you can do them component by component.  Some of the external forces in the r hat direction  must be equal to the mass-- in this case, just  a particle-- times the acceleration of that particle. ", "And in this problem, then that would  be the mass times the acceleration of A with respect  to O minus R theta dot squared r hat. ", "And this would have to be the r hat component of this thing.  I said I just want the R component.  I'd have to figure out if I was running along,  if I had it in the same direction as r hat. ", "What part of that acceleration is in that direction?  That would come here.  If there's 0, you just make it 0.  So let's just let the acceleration of A ", "with respect to O be 0.  Then that says the sum of the forces in the r direction  is equal to the mass minus mR theta dot squared. ", "And if we were to draw a free body diagram,  we would find out that, ahh, there  must be a tension on the string pulling  in on the mass sufficient to give it ", "the acceleration that you've computed.  So every problem, when you're asked  to compute the force, or the next step up,  find the equation of motion, the equation of motion  is just writing this thing out. ", " OK, now I want to move on to a more interesting problem. ", "", "All right, I'm going to do this problem.  So it's a hollow tube. ", "And we're going to look at things like, I put a ping pong  ball in it.  And if I swing this tube around, the ping pong ball  is going to come out. ", " OK, there must be some forces on that thing  to cause it to come out. ", "There must be some accelerations on them.  And so I could conceivably have an R,  a theta double dot acceleration.  It certainly is going to have theta dot rotation rates. ", "The ball is allowed to move.  So there can be nonzero r dots, r double dots--  a lot going on inside of this simple little tube.  So that's what I want to figure out. ", "Let's see if we can come up with a model for this problem.  ", "So here's my z-axis.  I have a rotation around it, some theta dot k hat direction.  Here's my tube.  It's rotating around. ", "So this is sort of a side view, your view of the tube.  Here's that ping pong ball in there.  And I'm going to idealize that ping pong ", "ball for a minute, a little more general problem.  Let's say I have kind of a nut on this thing, a disk,  something hanging onto the outside. ", "And I can control the rate, the speed  at which this thing goes out.  The ping pong ball, this is going  to be an application of this. ", "But I want to be able to do several other versions,  like make the speed constant for a second.  OK, and looking down on this thing, ", "top view, here's our inertial frame,  maybe out here like this.  Here's my mass. ", "So in polar coordinates, here's your theta.  The r is this.  This is your r hat. ", "This is your theta hat directions.   I'm going to let the velocity of A with respect to O be 0, ", "so there's no translational of this system.  And z, z dot, z double dot, those are all 0.  So nothing's happening in the z direction. ", "So I want to first compute the velocity of B  with respect to O.  And you ought to be able to do that sort of by inspection. ", "It comes only from-- oh, I haven't told you enough.  What do I want to make happen in this problem?  I want to let r dot-- it's going to be some vr, ", "and it's constant.   I'm not going to go quite to my ping pong shooter here yet.  I'm going to do a slightly simpler problem first.  So this is a constant.  That means r double dot is 0. ", "So this thing is just-- let's say  you had threads on this thing, and it's a screw,  and it's just moving its way out at a constant rate.  And I'm going to have constant angular, so theta dot. ", "I'll call that cap omega k hat.  So the angular rate is also constant.  All right, if that's the case, can you tell me, ", "what's v of B with respect to my fixed frame O?   Well, any time you're not sure, you go back to this formula, ", "throw out terms.  There's no z dot term.  This is constant.  This is 0, 0, 0.  You have this term.  It's some vr in the r hat direction. ", "You have this term, wherever it happens to be in the theta hat  direction.  ", "r dot in the r hat direction plus r theta  dot in the theta hat direction-- OK,  we need acceleration next, B with respect to O. ", "And now you can crank through the terms again.  This time, the first term is 0.  The second term is 0, because it's constant.  The third term is definitely not 0. ", "The fourth term is 0.  Fifth term?   0.  This term?  Not 0. ", "Let me just write them.   So you get a minus r theta dot squared r hat-- that's ", "the radial direction term-- plus 2r dot theta dot theta hat.  That's the accelerations.  ", "So you have an acceleration now in the r hat direction  and in the theta hat direction.  If there's acceleration to those directions,  there must be forces.  ", "Newton's second law now says, again, the force  is the mass times acceleration.  And this is a vector.  This is a vector. ", "It has two components.  And the nice thing about these Newton's laws and vectors  is you can break the problems down into their vector  components and treat the r direction  as one equation of motion, and the theta ", "direction as a separate one.  So we might want to draw a free body diagram.  Here's this block working its way out. ", "We know that there's probably some axial force.  I'm just going to call it T. And there's  some other unknown force here in the theta hat direction.  So this is my theta hat. ", "I've drawn this just intentionally in the positive r  hat direction.  The sign that comes out will tell us  which direction it really is if you're not certain.  Just draw it positive, in the positive r hat direction. ", "And that's your free body diagram.  If I wanted to put gravity in there, I might have.  But we're doing this in the horizontal plane.  Gravity is in and out this way. ", "It's in the z direction.  And we know it's constrained, can't move. z double dot is 0.  So there's certainly a support force that picks up the weight.  But this is in our horizontal plane. ", "There's your free body diagram.  And we can write two equations to solve for these things.  So the sum of the forces in the r hat direction is T. ", "And that must be equal to the mass times the acceleration  in the r, minus mr theta dot squared in the r hat direction. ", "Sure enough, the tension has to pull inwards  in the minus r hat direction.  And that's the full result. ", "STUDENT: Where are the T and F forces exactly?  PROFESSOR: Where are they?  OK, so I'm going to bring the ball to the outside ", "where you can see it.  This thing is going in this direction, horizontal plane, x,  y plane.  It's moving its fixed rate out. ", "So its speed when it's in here is r  over 2 omega in that direction.  And the speed when it's out here is r omega in that direction.  So clearly it's picking up speed.  If it's picking up speed, is it picking up kinetic energy? ", "Is there work being done on it somehow  to build up that energy?  So there must be some forces at play.  So there's a normal force from the wall  of this thing pushing this ball sideways to speed it up, ", "for sure.  That's one force.  And the other force is because I'm not allowing this thing  just to go freely out.  I'm constraining it to constant speed out. ", "It would really like to go a lot faster than that.  So what's holding it back?  At any instance in time, it has centripetal acceleration.  And what's making it go in the circle ", "is a force that is-- in this case,  if that were a nut with threads, in the threads are applying  to the nut to keep it from running away. ", "STUDENT: In that free body diagram,  F, doesn't F act similar between theta and r hat?  And then there's like a component  of theta hat in there? ", "PROFESSOR: Well, I've broken down.  I've chosen.  The total force acting on this thing  is some combination of a force in that direction ", "and a combination in the axial direction.  So it has some net direction that's neither this nor that.  STUDENT: From that equation, it looks like what you drew, ", "F has an r hat component.  PROFESSOR: So this thing is rotating  about some center over here. ", "So this is theta dot.  Theta is going in this direction, theta dot.  And we've chosen a coordinate system that has unit vectors r  hat and theta hat. ", "And so it makes sense.  We can express the acceleration in terms  of those two components.  It makes sense to express the forces in the same direction.  So I've just arbitrarily said, I have some unknown force ", "that's in this direction.  And I have another unknown force in that direction.   Then I'm saying, they account for all forces  in this direction, whatever their source. ", "That tells me that the sum of the external forces  in the theta hat direction in this case is this unknown F.  But I know from Newton that that's ", "got to be equal to the mass times the acceleration  in that direction.  In this case, then, that is 2mr dot theta dot theta hat. ", " So just from applying the equation  and applying Newton's second law, ", "I can find out what that force must be.  It would've been a lot more work if I  had drawn it in some arbitrary in between direction.  Because then I'd have to break it down into its compounds ", "to write this.  So I've made it as easy as possible for myself.  So there's a force like this.  And there is another force like that.  This one is caused by the centripetal acceleration. ", "Or this force causes the centripetal acceleration.  In order to make something go in a circular path,  you have to exert a force on it. ", "That's the force.  In order to accelerate something angularly,  you have to apply a force.  That comes from the Euler term.  And this is a curious term. ", "This is the Coriolis term.   So where does it come from?   That's the crux of the matter here. ", "Where does it come from?   So part of the reading that you need to do now is Chapter 15. ", "Chapter 15, most of it is going to be complete review.  It just says the conservation of a linear momentum, impulse  and momentum.  But it also gets into angular momentum.  So we're going to talk quite a lot about angular momentum. ", " And I want to do a very brief little review right now so ", "that it applies to this problem.   So we've come up with an expression  that the force in the theta direction  here comes-- there's got to be that, 2mr dot theta dot. ", " So here's my point O, and A for that matter. ", "But looking down on our problem, here's  my mass at some instant in time.  My rotation rate is theta dot-- or actually it's constant. ", "So it's k hat like that, cap omega k hat.  This is my r hat direction, theta hat. ", "Now, I'm going to treat this as a particle.  Not long-- we're going to be talking about the dynamics  of rigid bodies.  We're just doing particles for the moment.  We think of them just as point masses ", "and don't deal with their finite extent.  So we're still thinking of this as a particle.  And I'm going to write down the definition of the angular  momentum of a particle. ", "This is B out here with respect to my fixed frame here at O.  And I'm going to use a lowercase h to describe  angular momentum of particles.  And I'll use capital H to describe the angular ", "momentum of rigid bodies.  So this is a particle, the definition  of the angular momentum of a particle with respect  to a fixed point. ", "We're going to come back to that.  That'll turn out to have some significance.  The definition of this is it's RBO, the position vector, ", "crossed with the linear momentum evaluated in the fixed frame.  So that's the definition of angular momentum, which  is you have linear momentum, and it's ", "the cross product with the position vector out to it.  So in this case, the RBO is capital R R hat.  ", "Well, it's not-- this varies, excuse me.  So I'm not going to use-- this I use as a constant.  I better keep it as the variable.  Pardon that, so it's r, whatever the local position is, ", "in the r hat direction crossed with the linear momentum.  What's the linear momentum of that particle?  Mass times velocity. ", "What's the velocity?  STUDENT: [INAUDIBLE].   PROFESSOR: Theta dot-- where did we write it up here? ", "Someplace-- the total velocity is r dot r hat plus r theta ", "dot theta hat.   And we need a mass in here.  So mass times velocity would be the momentum. ", "And we need the cross products of those.  r hat cross r hat, you get nothing from that.  And r hat cross theta hat-- positive or negative? ", "Positive k, right?  So this becomes mr squared theta dot in the k hat direction. ", " And this one is a constant.  We'll write this as cap omega. ", " So this is my angular momentum of my particle with respect  to this fixed reference frame. ", "And so one final step that you know  from your previous physics is-- how's torque  related to angular momentum?  ", "Take a guess.  What do you remember?  Time derivative-- so d by dt of hBO here. ", "The time rate of change of this vector  is the torque with respect to this point, with respect to O.  So what are constants in this thing? ", "We don't have to deal with their derivatives.  k hat is-- does the direction of the angular momentum change?  It's upwards. ", "The derivative of k, the unit vector k,  does it change in this problem?  No, so its time derivative is 0.  Its time derivative is 0.  The m time derivative is 0. ", "The only thing you have to take the derivative of  is r, so 2rr dot.  ", "So the torque is 2mrr dot cap omega.  And it's all in the k direction.  And that had better be rBO cross F. Torque comes ", "as a force times a moment arm, right?  And we computed here a force in the theta direction.  So what would give us a torque in the k direction?  An r cross a theta. ", "r hat cross theta hat gives you a k.  r cross-- and this force, the part of the force.  We have two forces, one in the r direction  and one in the theta direction. ", "The cross product, this term up here, the T gives you nothing,  r cross r hat cross r hat.  So the only force that matters here is this Coriolis one. ", "And so that force is 2mr dot theta dot.  And we have the r cross. ", "We know this comes out in the k direction.  And we get an r in here when we compute this product.  And this, to me, looks an awful lot like this. ", "Except I missed an r squared.  How did I do that?   STUDENT: [INAUDIBLE]. ", " PROFESSOR: Oh no, it's not r squared.  It started off over here as the angular momentum has an r  squared, took the derivative. ", "It dropped down to 2rr dot.  And that's right.  So the Coriolis force, what's it got  to do with the angular momentum? ", " That's kind of the point of the exercise here.  In order for this ping pong ball to be accelerated, ", "as it goes slowly out this tube, the angular momentum  is increasing.  In order to change angular momentum with time,  you have to apply a torque.  The torque that you have to apply ", "is 2mrr dot in the k direction.  And that is r cross the Coriolis force.  So the Coriolis force, in this case, ", "is the force that's necessary to increase the angular  momentum of a system.  That's very often the reason-- that's  what Coriolis force is about. ", "So when you shoot an artillery piece on the Earth,  you've got that projectile going out there.  It has angular momentum with respect to the Earth. ", "And you'll find out that this little term pops up.  And in fact, the projectile doesn't go straight.  It curves.   There's lots of things that because of conservation ", "of angular momentum, you end up with this term popping up.  In this case, angular momentum is not conserved.  It's increasing.  So you have this force to make it happen. ", "Any questions about this?  You're going to use this one a lot.  You're going to work with it a lot.  ", "So anytime you see changes in angular momentum happening  in a problem, in these problems with circular motion,  velocities of parts increasing in radius, ", "you'll almost always see this term pop up.  Any time you see these changes in angular momentum,  you'll often see the Coriolis term.  All right, now we're going to do another interesting problem-- ", "simple but interesting.  And that is really to go-- let's go do this problem  where the thing is really allowed to come freely out.  ", "All right, you ready to defend yourself?   A little short stick is pretty effective at throwing candy. ", " You got your safety glasses on?  You want me to see if I can get one up there?  Aww, also, I obviously haven't practiced this. ", " All right, last one.  ", "Actually, there's two more.  ", "What makes this work?  Let's do this problem.   So let's look at our candy shooter. ", "", "So I'm whipping this thing around.  Candy is coming out of here.  It's at B.  Again, I get no z, not mess with the z part. ", "The z part is trivial to usually deal with.  Because it's totally independent,  just separate equations.  It doesn't complicate things much at all,  even when you have z.  Now, in this case, the velocity-- and here's ", "my O frame here.  The velocity B with respect to O,  well, now it's got-- I'm not going to move. ", "I'm standing still when I do it.  So the first term is 0.  It's got an r term, r dot in the r hat direction.  And it has an r theta dot theta hat term. ", " And these can now-- this might be changing.  This might have a time derivative, r double dot. ", "It certainly does.  It's accelerating coming out of that tube.  And my theta, angular motion, it can be accelerating, too.  So we're going to have to deal with those.  I need to know the accelerations. ", " Now, I haven't emphasized it till now,  but I find it conceptually useful to-- when ", "you work with polar coordinates, you  can have this ability to aggregate  the terms in these two component directions. ", "So you have this.  All the r terms go together.  And we've let the z double dot term--  it's just separate by itself. ", "It drops out easily.  And you have the theta hat term.  And that's the r theta double dot plus 2r dot theta dot. ", "And these are in the theta hat direction.  There's your Coriolis term, your Euler acceleration  term, centripetal term.  Yeah?  STUDENT: [INAUDIBLE].  ", "PROFESSOR: Well, I don't know if I ought  to tell you secrets about me.  Because it's going to give you an advantage on the quiz.   But I've almost never, ever been known ", "to ask a question that says, \"derive.\"  But I'll sure ask you concept questions.  I really want you to understand the principles. ", "I don't get real hung up on having you do  the grungy grind it out things.  Do I want you to remember the formula  for how to take the derivative of a vector in rotating frame? ", "Yeah, that's where these have come from.   You had better remember this.  These two formulas, the velocity formula and this, ", "the acceleration formula, are just core to this course.  Now, the way quizzes are done-- first quiz,  you come in, one sheet of paper.  What had better be on your paper? ", "OK?  And second quiz, two sheets, final, three sheets,  that kind of thing.  But conceptually, you've got forces in the r,  forces in the z, accelerations in r theta ", "and z, forces r theta and z.   And for these planar motion problems,  this one is sure easy to use. ", "So let's think about this problem.  I'm going to let this be frictionless just  to make it easy. ", "All right, so what possible forces act  on the hunk of candy?  Let's do a free body diagram of the hunk of candy  coming out of here. ", "What are the forces?  And let's keep it planar.  We can get gravity into this.  But let's just do it in a plane.  So I'm just going horizontal and slinging this thing.  Gravity's in the z direction, and I've ", "constrained it in the z.  So it's something supporting the gravity in the tube.  So definitely there's an mg on this thing downwards.  But it's in the z direction, and we're not ", "letting it move in the z.  What about the horizontal, this direction?  The r-- this is my r hat direction. ", "This is my theta hat direction.  Whoops, not either-- theta is going this way.  So I've drawn this as a side view.  What's the force in the r hat direction? ", "STUDENT: [INAUDIBLE].   PROFESSOR: OK, in order to do the problem,  you have to figure that out.  What are the forces?  ", "What are the source of forces in the r direction?  Here's the r direction.  STUDENT: [INAUDIBLE].  PROFESSOR: Say what?   Come on, you guys. ", "Somebody be-- yeah.  STUDENT: [INAUDIBLE].  PROFESSOR: There are not any.  Is that what you said?  There aren't any.  And why's that?  STUDENT: [INAUDIBLE].  PROFESSOR: Right, so there's no forces in the r direction. ", "So there's no forces on this thing in the r.  And so then this is a side view.  We could do the top view looking down.  Top view, you've got your x, y. ", "You also have your-- here's the ball.  Here's the r hat.  Here's the theta hat.  Now, free body diagram in the top view-- ", "well, there's some force here probably.  STUDENT: I was going to ask that the fact that we  have no forces in the r hat direction, but we do ", "have acceleration.  PROFESSOR: Absolutely.  She's commenting that we do have accelerations  in the r direction, right?  STUDENT: And we have no force.  PROFESSOR: And no force.  So that's the conundrum of this problem. ", "That's the point of this problem.  So let me continue.   Free body diagram-- I'm looking down on it.  I'm allowing for some force.  It's the normal force that comes from the pipe exerting ", "the force on the candy.  And since it's frictionless, it can only be normal to the pipe.  OK, so there's the free body diagram in the top view. ", "So we can write two equations.  We can write three questions-- this one  equal to 0, this one in the r hat direction,  this one in the theta hat direction.  ", "Sum of the forces r hat direction must be 0.  And we have a mass.  We have an acceleration.  ", "Solve for r double dot.  ", "Remarkable-- there's no force in the r hat direction.  The position of the object, the r ", "coordinate, it has a velocity.  It has an acceleration.   But the total acceleration in the r hat directions ", "are actually 0.  The rate of change of the velocity  of this thing in the radial direction, r double dot, ", "is nonzero.  But there are no forces on it.   I have pondered another way to explain this. ", "I'm still thinking about it.  And you think about this, too.  How do you explain this in the absence of forces?  And it's partly where the concept  comes from of fictitious forces, that centrifugal force is ", "a force.  It's not.  It's an acceleration.  This is just saying that-- let's go back to this problem.  In order to make something go in a circle, ", "you have to put a force on it to cause  the centripetal acceleration.  You have to allow the thing to go out if you're not ", "forcing it to go in a circle.  You have to allow it to go out at that rate in order  for there to be no centripetal accelerations on the object.  Yeah?  STUDENT: So I was going to say, when you start it, ", "you push it in the y direction.  So that's a force.  It's not in the r hat, but it's in the y.  PROFESSOR: To get it started.  STUDENT: Right, and there's no force opposing it  in that direction [INAUDIBLE]. ", "PROFESSOR: Does it experience centripetal acceleration?  So there's no rotation.  Does it experience centripetal acceleration? ", " What do you think?  Yeah, because it goes through curved motion.  At any instance in time when it's doing that, ", "there is a radius of curvature.  You can at that instant in time think of it  as being in a circular path.  And sometimes it's just really easy  to do these kind of problems with normal and tangential ", "coordinates.  So I'm looking down on the x, y plane. ", "Gravity is into the Earth.  So I'm looking down on a vehicle, a car.  And that car, the guy is kind of drunk.  He's going down the road like this. ", "So here's my y.  Here's my x.  And y equals some A sine 2 pi over the wavelength, ", "2 pi over lambda, times x at some A sine kx.  And as he drives down-- if you're in a car, ", "and you're doing that, you get thrown side to side in the car.  So you are being accelerated.  And so we want to be able to calculate  the acceleration due to the fact that you're going  down and doing a curved path. ", "And we deal with these things sometimes  with a convenient little set of coordinates  that are our normal and tangential unit ", "vectors, u normal and u tangential,  at any instant in time.  ", "And we know that if this is along the path,  at any instant in time you're right here,  what direction is your velocity? ", "Just definition of velocity-- tangent to the path, right?  So at any instant in time, the velocity  has got to be tangent to the path at that moment. ", "So velocity, the vector, has a magnitude and a unit vector ", "uT here I'll call it, tangent.  That's all there is to it.  And the acceleration of this thing ", "is your time derivative of this.   And that's going to give you a v dot uT hat plus a v. ", "And now you need a time derivative of this guy.  But this is a unit length vector.  You can plug it into that equation  for the derivative of a rotating vector ", "and calculate what this should be.  You could also just draw it out.  So I'll draw this for you.  ", "How are we doing on time?  I should just be able to finish this.  ", "Here's my unit vector in the tangential direction.  As I'm going around this curve, this ", "is my tangential direction.  There's some instant I have a radius.  We call that rho.  And in the little time, delta t, I ", "go through an angle delta theta in delta t.  And this is my uT vector here.  It changes by a little bit. ", "That's the change in the uT unit vector in this time, delta t.  And it goes perpendicular.  And it goes in the positive un direction. ", " So delta-- what's the easiest way to write this one?  ", "Delta uT equals some theta dot delta t-- that's ", "the angle-- times the length of the unit vector, 1.  That's the distance it goes, so 1. ", "So r omega, 1 theta dot is the distance  that this unit vector goes through in delta t. ", "And the direction it goes in is u normal hat.  So delta uT over delta t limit as t ", "goes to 0, you get theta dot un, just like before.  So the time derivative of this unit vector ", "in the tangential direction is just theta dot  in the normal direction.  And then from that, we can very quickly ", "derive the rest of this acceleration.  The acceleration then is that plus this.  We now know an expression for-- this is my uT dot term. ", "I'm going to plug that in here.  This then, we need an expression for v. What's v?   Well, at that instant in time, it has some radius rho. ", "It has an angular velocity theta dot.  So rho theta dot would be the v here.  ", "So I'm looking for an expression for vuT dot.  ", "So that's v theta dot un.  But theta dot is v over rho. ", " v squared-- sorry about this-- over rho un.  So this guy up here, this is v dot uT plus v squared-- ", "I'll rewrite it-- over rho un.   So if you're speeding up, if you're  going from 30 miles an hour to 40 miles an hour,  that's your tangential. ", "That's your speed along the path.  That's this term.  But because you're going around the curve,  you have an acceleration of v squared over rho.  You've run into this before in physics.  This is where it comes from. ", "This is a centripetal acceleration like term.  If you replace v with rho theta dot,  you'd get r theta dot squared.  So you can either put it in terms of v squared over rho, ", "or you can put it in terms of rho theta dot squared.  And rho theta dot squared sounds a lot like my acceleration term  right here.  ", "So with that simple little formula,  you can do-- you need one other thing.   And you just go look it up in the book. ", "There is an expression from calculus for the radius  of curvature of a path.  And it has first and second derivatives of y with respect ", "to x.  So you need a dy/dx and a d2y dx squared.  From a sine function, you can calculate that.  So you calculate rho from a formula  that's in the book for calculating ", "radius of curvature.  And then you're done, all right?  So see you on Thursday. "], "vid_duration": [12.07, 11.409, 11.941, 11.13, 14.37, 11.66, 12.91, 11.15, 12.559, 17.581, 15.47, 10.48, 10.3, 10.59, 12.7, 11.7, 16.73, 10.58, 10.84, 10.109, 12.331, 10.36, 12.68, 14.34, 12.19, 10.239, 10.771, 10.22, 11.14, 13.72, 10.83, 10.53, 14.63, 11.67, 11.21, 11.95, 13.99, 10.72, 11.13, 10.13, 11.349, 11.77, 10.851, 11.2, 10.403, 12.637, 13.13, 10.36, 10.483, 11.787, 12.36, 11.649, 26.116, 12.765, 10.38, 12.4, 13.82, 12.77, 10.38, 10.39, 10.88, 16.42, 14.18, 12.57, 11.5, 14.51, 11.0, 12.995, 17.485, 24.91, 10.03, 10.68, 11.185, 11.725, 10.37, 18.59, 11.93, 15.09, 10.17, 10.33, 11.079, 10.111, 10.35, 12.5, 13.63, 11.69, 16.023, 11.987, 15.0, 10.09, 13.41, 11.08, 16.812, 11.478, 11.71, 10.46, 10.58, 12.4, 11.68, 10.71, 10.91, 10.96, 10.444, 11.546, 10.31, 11.61, 11.88, 11.64, 11.425, 14.335, 10.07, 13.8, 12.35, 11.64, 11.98, 10.078, 10.462, 10.06, 10.845, 10.825, 10.95, 12.11, 11.15, 11.84, 10.91, 10.06, 10.08, 11.89, 10.39, 11.89, 11.07, 13.52, 12.62, 14.2, 15.18, 12.98, 13.0, 11.12, 11.34, 10.53, 12.25, 12.526, 10.794, 11.51, 15.09, 12.58, 11.91, 10.34, 12.4, 12.74, 11.97, 16.78, 10.211, 11.989, 14.23, 12.16, 11.05, 11.04, 10.039, 20.351, 17.4, 11.34, 11.38, 11.95, 12.86, 10.599, 10.045, 10.933, 10.632, 16.21, 11.361, 10.18, 10.87, 11.65, 12.26, 10.84, 12.34, 12.86, 16.01, 16.009, 12.961, 12.56, 10.78, 10.02, 10.105, 19.365, 11.1, 13.37, 10.18, 16.05, 10.81, 10.98, 12.63, 14.92, 10.36, 17.62, 13.074, 11.876, 11.09, 11.2, 11.72, 10.73, 11.42, 10.19, 12.22, 10.27, 11.48, 11.83, 10.76, 12.68, 12.6, 10.11, 12.64, 11.48, 11.54, 11.885, 12.08, 13.825, 11.68, 28.33, 17.57, 10.69, 14.36, 12.825, 10.815, 13.29, 11.61, 11.41, 10.92, 11.513, 10.487, 12.035, 10.235, 13.15, 10.16, 11.43, 14.17, 11.11, 12.1, 11.33, 10.8, 10.46, 12.93, 11.17, 11.15, 13.68, 12.7, 12.18, 12.62, 11.82, 10.335, 12.465, 12.532, 13.378, 14.57, 11.81, 10.09, 13.32, 11.88, 10.39, 17.029, 10.881, 15.98, 10.32, 10.25, 16.61, 10.36, 12.24, 12.13, 12.39, 12.68, 11.52, 11.43, 8.15], "stet": [[0, 12.07], [12.07, 23.479], [23.479, 35.42], [35.42, 46.550000000000004], [46.550000000000004, 60.92], [60.92, 72.58], [72.58, 85.49], [85.49, 96.64], [96.64, 109.199], [109.199, 126.78], [126.78, 142.25], [142.25, 152.73], [152.73, 163.03], [163.03, 173.62], [173.62, 186.32], [186.32, 198.01999999999998], [198.01999999999998, 214.74999999999997], [214.74999999999997, 225.32999999999998], [225.32999999999998, 236.17], [236.17, 246.279], [246.279, 258.61], [258.61, 268.97], [268.97, 281.65000000000003], [281.65000000000003, 295.99], [295.99, 308.18], [308.18, 318.419], [318.419, 329.19], [329.19, 339.41], [339.41, 350.55], [350.55, 364.27000000000004], [364.27000000000004, 375.1], [375.1, 385.63], [385.63, 400.26], [400.26, 411.93], [411.93, 423.14], [423.14, 435.09], [435.09, 449.08], [449.08, 459.8], [459.8, 470.93], [470.93, 481.06], [481.06, 492.409], [492.409, 504.179], [504.179, 515.03], [515.03, 526.23], [526.23, 536.633], [536.633, 549.27], [549.27, 562.4], [562.4, 572.76], [572.76, 583.2429999999999], [583.2429999999999, 595.03], [595.03, 607.39], [607.39, 619.039], [619.039, 645.155], [645.155, 657.92], [657.92, 668.3], [668.3, 680.6999999999999], [680.6999999999999, 694.52], [694.52, 707.29], [707.29, 717.67], [717.67, 728.06], [728.06, 738.9399999999999], [738.9399999999999, 755.3599999999999], [755.3599999999999, 769.5399999999998], [769.5399999999998, 782.1099999999999], [782.1099999999999, 793.6099999999999], [793.6099999999999, 808.1199999999999], [808.1199999999999, 819.1199999999999], [819.1199999999999, 832.1149999999999], [832.1149999999999, 849.5999999999999], [849.5999999999999, 874.5099999999999], [874.5099999999999, 884.5399999999998], [884.5399999999998, 895.2199999999998], [895.2199999999998, 906.4049999999997], [906.4049999999997, 918.1299999999998], [918.1299999999998, 928.4999999999998], [928.4999999999998, 947.0899999999998], [947.0899999999998, 959.0199999999998], [959.0199999999998, 974.1099999999998], [974.1099999999998, 984.2799999999997], [984.2799999999997, 994.6099999999998], [994.6099999999998, 1005.6889999999997], [1005.6889999999997, 1015.7999999999997], [1015.7999999999997, 1026.1499999999996], [1026.1499999999996, 1038.6499999999996], [1038.6499999999996, 1052.2799999999997], [1052.2799999999997, 1063.9699999999998], [1063.9699999999998, 1079.9929999999997], [1079.9929999999997, 1091.9799999999998], [1091.9799999999998, 1106.9799999999998], [1106.9799999999998, 1117.0699999999997], [1117.0699999999997, 1130.4799999999998], [1130.4799999999998, 1141.5599999999997], [1141.5599999999997, 1158.3719999999996], [1158.3719999999996, 1169.8499999999997], [1169.8499999999997, 1181.5599999999997], [1181.5599999999997, 1192.0199999999998], [1192.0199999999998, 1202.5999999999997], [1202.5999999999997, 1214.9999999999998], [1214.9999999999998, 1226.6799999999998], [1226.6799999999998, 1237.3899999999999], [1237.3899999999999, 1248.3], [1248.3, 1259.26], [1259.26, 1269.704], [1269.704, 1281.25], [1281.25, 1291.56], [1291.56, 1303.1699999999998], [1303.1699999999998, 1315.05], [1315.05, 1326.69], [1326.69, 1338.115], [1338.115, 1352.45], [1352.45, 1362.52], [1362.52, 1376.32], [1376.32, 1388.6699999999998], [1388.6699999999998, 1400.31], [1400.31, 1412.29], [1412.29, 1422.368], [1422.368, 1432.83], [1432.83, 1442.8899999999999], [1442.8899999999999, 1453.735], [1453.735, 1464.56], [1464.56, 1475.51], [1475.51, 1487.62], [1487.62, 1498.77], [1498.77, 1510.61], [1510.61, 1521.52], [1521.52, 1531.58], [1531.58, 1541.6599999999999], [1541.6599999999999, 1553.55], [1553.55, 1563.94], [1563.94, 1575.8300000000002], [1575.8300000000002, 1586.9], [1586.9, 1600.42], [1600.42, 1613.04], [1613.04, 1627.24], [1627.24, 1642.42], [1642.42, 1655.4], [1655.4, 1668.4], [1668.4, 1679.52], [1679.52, 1690.86], [1690.86, 1701.3899999999999], [1701.3899999999999, 1713.6399999999999], [1713.6399999999999, 1726.166], [1726.166, 1736.96], [1736.96, 1748.47], [1748.47, 1763.56], [1763.56, 1776.1399999999999], [1776.1399999999999, 1788.05], [1788.05, 1798.3899999999999], [1798.3899999999999, 1810.79], [1810.79, 1823.53], [1823.53, 1835.5], [1835.5, 1852.28], [1852.28, 1862.491], [1862.491, 1874.48], [1874.48, 1888.71], [1888.71, 1900.8700000000001], [1900.8700000000001, 1911.92], [1911.92, 1922.96], [1922.96, 1932.999], [1932.999, 1953.35], [1953.35, 1970.75], [1970.75, 1982.09], [1982.09, 1993.47], [1993.47, 2005.42], [2005.42, 2018.28], [2018.28, 2028.879], [2028.879, 2038.924], [2038.924, 2049.857], [2049.857, 2060.489], [2060.489, 2076.699], [2076.699, 2088.06], [2088.06, 2098.24], [2098.24, 2109.1099999999997], [2109.1099999999997, 2120.7599999999998], [2120.7599999999998, 2133.02], [2133.02, 2143.86], [2143.86, 2156.2000000000003], [2156.2000000000003, 2169.0600000000004], [2169.0600000000004, 2185.0700000000006], [2185.0700000000006, 2201.0790000000006], [2201.0790000000006, 2214.0400000000004], [2214.0400000000004, 2226.6000000000004], [2226.6000000000004, 2237.3800000000006], [2237.3800000000006, 2247.4000000000005], [2247.4000000000005, 2257.5050000000006], [2257.5050000000006, 2276.8700000000003], [2276.8700000000003, 2287.9700000000003], [2287.9700000000003, 2301.34], [2301.34, 2311.52], [2311.52, 2327.57], [2327.57, 2338.38], [2338.38, 2349.36], [2349.36, 2361.9900000000002], [2361.9900000000002, 2376.9100000000003], [2376.9100000000003, 2387.2700000000004], [2387.2700000000004, 2404.8900000000003], [2404.8900000000003, 2417.9640000000004], [2417.9640000000004, 2429.8400000000006], [2429.8400000000006, 2440.9300000000007], [2440.9300000000007, 2452.1300000000006], [2452.1300000000006, 2463.8500000000004], [2463.8500000000004, 2474.5800000000004], [2474.5800000000004, 2486.0000000000005], [2486.0000000000005, 2496.1900000000005], [2496.1900000000005, 2508.4100000000003], [2508.4100000000003, 2518.6800000000003], [2518.6800000000003, 2530.1600000000003], [2530.1600000000003, 2541.9900000000002], [2541.9900000000002, 2552.7500000000005], [2552.7500000000005, 2565.4300000000003], [2565.4300000000003, 2578.03], [2578.03, 2588.1400000000003], [2588.1400000000003, 2600.78], [2600.78, 2612.26], [2612.26, 2623.8], [2623.8, 2635.6850000000004], [2635.6850000000004, 2647.7650000000003], [2647.7650000000003, 2661.59], [2661.59, 2673.27], [2673.27, 2701.6], [2701.6, 2719.17], [2719.17, 2729.86], [2729.86, 2744.2200000000003], [2744.2200000000003, 2757.045], [2757.045, 2767.86], [2767.86, 2781.15], [2781.15, 2792.76], [2792.76, 2804.17], [2804.17, 2815.09], [2815.09, 2826.603], [2826.603, 2837.09], [2837.09, 2849.125], [2849.125, 2859.36], [2859.36, 2872.51], [2872.51, 2882.67], [2882.67, 2894.1], [2894.1, 2908.27], [2908.27, 2919.38], [2919.38, 2931.48], [2931.48, 2942.81], [2942.81, 2953.61], [2953.61, 2964.07], [2964.07, 2977.0], [2977.0, 2988.17], [2988.17, 2999.32], [2999.32, 3013.0], [3013.0, 3025.7], [3025.7, 3037.8799999999997], [3037.8799999999997, 3050.4999999999995], [3050.4999999999995, 3062.3199999999997], [3062.3199999999997, 3072.6549999999997], [3072.6549999999997, 3085.12], [3085.12, 3097.652], [3097.652, 3111.03], [3111.03, 3125.6000000000004], [3125.6000000000004, 3137.4100000000003], [3137.4100000000003, 3147.5000000000005], [3147.5000000000005, 3160.8200000000006], [3160.8200000000006, 3172.7000000000007], [3172.7000000000007, 3183.0900000000006], [3183.0900000000006, 3200.1190000000006], [3200.1190000000006, 3211.0000000000005], [3211.0000000000005, 3226.9800000000005], [3226.9800000000005, 3237.3000000000006], [3237.3000000000006, 3247.5500000000006], [3247.5500000000006, 3264.1600000000008], [3264.1600000000008, 3274.520000000001], [3274.520000000001, 3286.7600000000007], [3286.7600000000007, 3298.890000000001], [3298.890000000001, 3311.2800000000007], [3311.2800000000007, 3323.9600000000005], [3323.9600000000005, 3335.4800000000005], [3335.4800000000005, 3346.9100000000003], [3346.9100000000003, 3355.0600000000004]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [339, 1616, 2178, 2874, 3356]}
{"example_id": "mit097@@MIT6_042JS15_17_ipod", "text": [" PROFESSOR: Directed acyclic graphs  are a special class of graphs that really have and warrant  a theory of their own.  Of course, \"directed acyclic graphs\" is lot of syllables, ", "so they're called \"DAGs\" for short.  OK.  So here's why they come up all the time.  Let's look at a diagram that may be familiar to you.  This shows the prerequisite structure ", "of required courses in the 6-3 program of MIT Electrical  Engineering and Computer Science department.  There are similar charts for the other sub-majors of EECS  and in other departments as well. ", "So what does it mean?  Well, let's look at this vertex corresponding to the first term  calculus class 18.01.  And there's an edge that points to 6.042. ", "And that's because, if you look at the catalogue,  6.042 lists 18.01 as a prerequisite.  If you look at the algorithms-- introductory algorithms--  class 6.006, you'll find, if you look in the catalog, ", "that it has listed two prerequisites, 6.042 and 6.01.  And the fact that they're explicitly  listed in the catalog as prerequisites  is why there's an arrow from 6.01 to 6.006 ", "and from 6.042 to 6.006.  Now when you're planning on when you  want to take 6.006, of course, you have to attend to not just ", "the fact that you have to take 6.042 first and 6.01 first,  but you've got to take the prerequisites  of those prerequisites first.  So you really have to take 18.01 before you can take 6.006. ", "And you need to take 8.02 before you can take 6.006.  There are corequisites here.  Let's just ignore those and pretend  that they were prerequisites, because they're ", "another kind of arrow that needn't distract us.  OK.  So that's what this diagram is telling us.  And this is a DAG.  It's simply a bunch of vertices, the course ", "labels in rectangular boxes, and directed arrows  showing catalog listings.  And what I said was that when you're planning your course ", "work, you're really interested in the indirect prerequisites.  So \"one class, u, is an indirect prerequisite  of another class, v\" means that there's  a sequence of prerequisites starting from u ", "and going to v. It means that you really have to have taken u  some time before you took v. And that's a crucial fact and thing  that you need to take account of when you're planning a course ", "schedule.  So in terms of graph digraph language,  \"u is an indirect prerequisite of v\"  just means that there's a positive length walk that goes ", "from u to v in the digraph.  In this case, we're talking about the 6-3 digraph  of prerequisites.  So \"there's a positive length walk from 18.01 to 6.006\" ", "means that you really have to have taken 18.01  before you take 6.006.  And of course, we're talking, then,  about the positive length walk relation D plus of the digraph ", "D. If D is the digraph shown in the prerequisite chart--  direct prerequisite chart-- then we're interested in D plus.  And u D plus v just means there's a positive length  walk-- that's what the plus is for-- going from to u to v. ", "Now what happens if you have a closed walk?  Well, a closed walk is a walk that starts and ends  at the same vertex. ", "And we can ask this question-- suppose  there was a closed walk that started at 6.042  and ended at 6.042.  How long does it take to graduate then?  Well, it takes a long time.  Because you can't take 6.042 until you've taken 6.042 ", "and you're never going to be able to take it.  That's a bad thing.  We definitely don't want the prerequisite structure  of courses in a department to have a closed ", "walk of positive length.  And in fact, there's a faculty committee that  checks for this kind of thing.  Bugs like this occasionally creep  in when some busy curricular office of a department ", "is planning a complicated program with dozens, if not 100  courses.  And the Committee on Curricula's job  is to check for that kind of thing.  There's a whole staff that does it. ", "I used to be the chair of that committee.  And we did spend a lot of time with proposals from departments  and making sure that those proposed course requirements ", "satisfied faculty rules.  OK.  So a special case of a closed walk is a cycle.  A cycle is a walk who's only repeat vertex is its start ", "and end.   Let me remark, because we keep talking about positive length  cycles, that a single vertex all by itself is a length-0 cycle. ", "So you're never going to be able to get rid of length-0 cycles,  because they're the same as vertices.  But positive length cycles, you can hope to ensure  are not there. ", "So if you're going to represent a cycle as a path,  you'd show the sequence of vertices and edges, v0, v1, v2,  where the understanding is that all of the vertices from v0 up ", "to v n minus 1 are different-- that's  what makes it a cycle-- except that the last vertex, v0, is  a repeat of the first one.  That's the one repeat that's allowed in a cycle.  So it's natural to draw it in a circle ", "like this where you start at v0, you follow the edges around  from v1 to v i plus 1 all the way back around to v0.  And that's kind of what a cycle is going to look like. ", "So we have a very straightforward lemma  about cycles and closed walks, namely  that the shortest positive length closed  walk from a vertex to itself-- \"it's closed\" ", "means it starts and ends at v-- is a positive length  cycle starting and ending at v. And the reasoning and proof is  basically the same proof that said that the shortest  walk between one place and another ", "is a path from one place to the other.  The logic is that if I have a closed walk from v to v  and there was a repeat in it other than at v,  I could clip out the piece of the walk between the repeat ", "occurrences and I'd get a shorter walk.  So the shortest closed walk can't have any repeats.  It's got to be a positive length cycle.  So a directed acyclic graph now is defined simply ", "as a digraph that has no positive length cycles.  It's acyclic, no positive length cycles.  And of course, we can equally well  define it, since cycles are a special case ", "of closed walks and closed walks of positive length  imply cycles, as a digraph that has no positive length closed  walk.  ", "Some examples of DAGs that come up-- well,  the prerequisite graph is going to be one.  And in general, any kind of set of constraints on tasks, ", "which ones you have to do before you do other ones,  is going to be defining a DAG structure.  One that you might not have thought of  is, the successor function defines ", "a relation on the integers, say, going from n to n plus 1.  So I'm going to have an arrow that goes directly  from n to n plus 1.  And what's the walk relation then, the positive length walk ", "relation, in this graph?  Well, there's a positive length walk from n  to m precisely when n is less than m.  So the successor DAG, it's paths represent ", "the less than relation.  And of course, less than, it doesn't have any cycles.  Because if a is less than b, you're  never going to get around from b back to something  that's less than it, like back to a. ", "So there can't be any cycles in the successor DAG.  And that's why it is a DAG.  Another similar one is the proper subset relation  between sets. ", "So here I'm going to draw an arrow from this set  to that set if this set is contained in that set  but they're not equal.  So {a, b} is a subset of {a, b, d}, but {a, b,  d} has this extra element, d. ", "So the left-hand set is a proper subset of the right-hand set.  And I'm going to draw an arrow there.  And by the same reasoning, there can't  be any cycles in this graph-- a positive length cycle-- ", "because if there was, it would mean  that the set had to be a proper subset of itself, which  doesn't happen.  So this would be another basic example of a DAG.  And I hope you begin to see, from these examples, ", "why DAGs are really all-pervasive  in mathematics and in other areas  and why they merit attention. ", "So when we're looking at a DAG though,  we're basically usually interested in just the walk  relation of the DAG.  So if we're only interested in the walk relation of the DAG, ", "then it would be typically the case  that many different DAGs are going  to have the same walk relation.  And it's natural to ask, what's the most economical one.  Is there a minimum, say, DAG that ", "defines a given walk relation?  So let's look at this example.  Here's a simple DAG.  And you can check that there are no cycles in it.  What's the smallest DAG with the same relation as this one? ", "And the way I can get it is by going  through the edges one at a time and asking  whether I can get rid of the edge  because it's not contributing anything.  So look here.  There's a path from a to e that goes through b. ", "Well, that tells me that having this direct edge from a to e  is not contributing anything in terms of connectedness.  And that means I could get rid of it  and I'm still going to wind up with the same possibility ", "of walking from one place to another.  Because I can always walk from a to e  going through b instead of going directly from a to e.  I didn't need that edge.  Another example is, here's a walk from a ", "to d that goes through c.  There's no need for me to walk directly from a to d.  As long as I'm walking, I can take the longer walk  and get rid of the short circuit from a to d. ", "Likewise, if I look at this path from c to d to f,  I don't need that edge from c to f.  And as a matter of fact, now if I  look at this length 3 path from a to c to d to f, ", "there's no need for me-- in order to get from a to f,  there's no need for me-- to take the direct edge.  I can get rid of that too.  It's kind of a redundant extra edge.  Finally, if I look at the path from b to d to f, ", "I can get rid of the direct edge from b to f.  And at this point, I'm done.  I'm left with a set of edges called covering edges, which ", "have the property that the only way to get from one vertex  to another is going to have to be to use a covering ", "edge to the target for vertex.  Or more precisely, the only way to get, say, from a to b  is going to be to use that covering edge.  If there was any other path that went from a elsewhere ", "and got back to b without using this edge,  then it wouldn't be a covering edge anymore.  The fact that it's a covering edge  means that if you broke it, there's no way  anymore to get from a to b.  So that's the definition of covering edges ", "and you'll do a class problem about them, more precisely,  in a minute.  So the other edges are unneeded to define the walk relation.  And all we need to keep are the covering relations ", "to get the minimum representation of the walk   So we saw in the last video why if you represent scheduling  constraints among courses by a digraph ", "that it's critical that that digraph in fact be a DAG.  And let's now look at this scheduling issue represented  by DAGs in more detail.  So here's a chart of a selection of Course 6 prerequisites-- ", "some of them obsolete, but they serve the purposes  of being an illustrative example--  and the little arrows here are indicating  arrows in the digraph.  So what this tells me is that 18.01 ", "is listed as an immediate prerequisite  in the catalog for 6.042.  18.01 is also an immediate prerequisite of 18.02. ", "6.001 and 6.004 are both prerequisites of 6.033,  and 6.042 of 6.046, and 6.046 of 6.840. ", "So we're seeing here this indirect prerequisite issue  that I mentioned before, which is that even though the only  thing listed as a prerequisite for 6.840 in the catalog is ", "6.046, as a matter of fact in order to take 6.046 you have  to have taken 6.042.  So 6.042 is an indirect prerequisite of 6.840. ", "So in terms of graph language and path language,  a subject u is an indirect prerequisite of v  when there's is a positive length  path from u to v in the digraph that ", "describes the prerequisite structure among the classes.  It simply means that-- using our notation for R plus  is the positive length path relation  of a digraph or a binary relation R-- ", "it simply means u R plus v, which  is read as there is a positive length path from u to v.  Now, a key idea that we're going to be examining ", "in learning how to do scheduling is  the idea of a minimal subject.  So the definition of a minimal subject  is a subject that has no prerequisites,  no arrows in, a freshman subject. ", "So nothing comes in.  There are three examples of subjects  with no prerequisites in the preceding chart,  namely 18.01, 8.02, and 6.001. ", "Let me say a word about where this funny terminology minimal  comes from.  It's because another way to talk about DAGs  is in terms of things that are like order relations called ", "partial orders, which we'll be looking at shortly.  And so you think of the later subjects  as being bigger than the earlier subjects. ", "So a minimal subject is one where  there is nothing less than it.  Now, there might be several minimal subjects,  because it might be that neither one of them  is less than the other, but there's nothing ", "less than 18.01.  There's no other subject that you have to take before 18.01.  So that's the definition of minimal.  Nothing smaller. ", "Now, you could ask what's a minimum, which  you may be more familiar with.  A minimum means that not only is there nothing before it,  but it comes before everything else.  It would be the earliest of all possible subjects ", "in the indirect prerequisite chain.  There isn't any in this example, but there actually  used to be one at MIT.  For a while, we experimented with giving an orientation week  summer assignment, that is, an assignment over the summer ", "for newly admitted students in order for them  to take a subject during orientation  week in which they discussed some book that they had all  been assigned to read beforehand. ", "Seemed like a great idea to kind of pull the freshman community  together, but it turned out to be unsustainable  because they couldn't find enough faculty  and others willing to conduct these seminars. ", "So MIT stopped having a minimum subject.   So let's look at the prerequisites  again, and discuss how to do a scheduling.  And the first thing we're going to do in the schedule ", "is, as I say, identify the minimal elements.  There are the three of them that we mentioned.  And we're going to start by deciding that we'll take  those three in the first term. ", "So we're going to be operating with basically what's  called a greedy strategy.  We're going to take as many things  as we possibly can take at any term given the constraints.  So we can take all the freshman subjects in our first term ", "because they have no prerequisites.  Well, the next step, then, is just get rid of them  because they're scheduled already.  So we can get rid of all those occurrences of 18.01, 8.02,  and 6.001, not only-- there are other occurrences as well here ", "where 18.01 is a prerequisite for things.  So they're all gone, and we get a simplified diagram  where we've removed the minimal elements.  Now in the new diagram, there are now ", "things that didn't used to be minimal  before but are minimal now.  These are the new minimal elements,  and we can identify those.  Here are five subjects-- four here and one there--  that now have no more prerequisites. ", "These are kind of the second level minimal elements,  and we're going to schedule them next.  So those are all the subjects that we can possibly  take after we've taken the first set of minimal subjects. ", "They're the second level minimals.  And we'll schedule them in the next term.  This is our five subject second term schedule.  Likewise, you delete these guys, and then you ", "discover that 6.046 and 6.004 are the resulting minimal ones,  which it's now possible to take because all their prerequisites  have been satisfied.  So we schedule them in the third term, 6.840 and 6.033, ", "by the same reasoning, in the fourth term,  and 6.857 in the fifth term.  There is our complete term schedule obtained  in this particular way. ", "There's, of course, many other ways to schedule it,  but this is a particular orderly way where the strategy, again,  is greedy.  You take as many things as you possibly  can take in a given term. ", "Now, there are some concepts that  come up when you're talking about schedules  that are worth introducing.  So one of them is an antichain.  An antichain is-- in this particular example ", "means a set of subjects where there  are no indirect prerequisites among them.  They can be taken in any order, because it doesn't matter  whether you've taken one or not when you're thinking ", "about taking the others.  In technical language, again motivated  by the idea of thinking of there being a path  as though it was less than or equal to something, ", "these are elements that are incomparable.  Neither one is less than or equal to another.  So in terms of the path relation,  u is incomparable to v if and only ", "if there is no path from u to v of positive length and there's  no positive length path from v to u.  So let's look at some antichains-- and the part  of the point of defining it is we ", "have chosen antichains as our schedule for each term.  So the freshman subjects with no prerequisites,  clearly there's no path among them,  because there is no path to them at all. ", "So they are an antichain.  The next level we chose were the second level  minimal elements, which only had as prerequisites  the original minimal elements, and so certainly none of them ", "was a prerequisite of the others.  So that's another example of an antichain.  And of course the third level and the fourth level  and the fifth level are antichains. ", "But not all antichains are there in our schedule.  So for example here, is a diagonal lying antichain.  6.840, 6.004, and 6.034 have no paths between them. ", "So in fact it's possible to take them simultaneously,  because you could have taken all their prerequisites  in the upper left here and then take the three of them.  So that's what an antichain means here. ", "So the technical definition is no path between any two  of them, but in terms of the scheduling of courses,  it means it's possible to take them in the same term ", "if you've satisfied all their prerequisites,  which it is possible to do.  So let's ask about the various patterns of scheduling ", "that are possible.  We've discovered this particular greedy one,  where we take as many things as we can each term.  But suppose that I was constrained to only take  one subject per term. ", "I was going to-- I have an outside job,  I'm too busy to take more than one class a term,  and if MIT will let me dawdle so long,  that's what I'd like to do.  So can I do this?  Yeah, well sure. ", "Just schedule all the minimal elements first  in any order, one, two, three.  And then schedule the five second level minimal elements  next, and the third level, and so on. ", "And it's perfectly possible, then,  to modify the schedule that we found  into a schedule in which you only take one subject per term,  and of course you only take a subject ", "after you've taken all of its indirect  and direct prerequisites.  This is called a topological sort.  Again, the sorting word comes from the motivation ", "of thinking of there being a path as like a less  than or equal to relation.  So we're sorting things in order of increasing size.  18.01 would be, in this case, a smallest element ", "and 6.857 a biggest in this list of elements.  A chain is kind of technically, literally,  a thing called the dual of an antichain. ", "A chain is a sequence of subjects  that must be taken in order.  That is, these are subjects where for any two of them,  you know which one has to come first.  That is, between any two of them there is ", "a path in one way or the other.  Now of course, it's a DAG, so there can't  be paths in both directions.  So a chain is simply a set of comparable elements, which  implies that there's an order in which they have to be taken. ", "So here are some chains.  This one was shown pictorially as a vertical chain  with five courses in it.  Here's a vertical chain of four.  And not all of them are vertical. ", "Here's a chain where you have to take 18.01 before you take  18.03 before you take 6.004.  So they form a chain.  It's important to realize that this ", "is a chain with five subjects in it,  but a chain doesn't have to have every possible element that  could be in it.  It's still a chain even if it's only got these three subjects, ", "because there's a path from 8.02 to 6.004  and a path from 6.004 to 6.857.  But maximum length chains, chains  that are as full as possible, are important theoretically. ", "And so this in particular is a maximal length chain.  The longest chain here is of length 5.  Now, it's not the only one.  There's another chain of length 5 here if you look for it. ", "But no chain is of length longer than 5  and there is one of length 5, and that leads us  to the question of how many terms is it necessarily ", "going to take to graduate.  Well, we saw that you can graduate in five.  But given that there's a maximum chain of length 5, ", "it means that you can't do it in fewer,  because those five courses have to be taken consecutively.  The third has to be taken in a term  after the first two have been taken. ", "The second has to be taken after the first.  If you have a chain of any size, actually, the number  of terms to graduate has to be at least as big  as that chain, which means it has  to be at least as many terms as a maximum size chain. ", "So five terms are necessary, and we  saw using our minimal strategy of being  greedy that you can always do it in maximum chain length.  So five are also sufficient. ", "This is providing that you can take an unlimited number  of subjects per term.  Remember our strategy to graduate in five terms  was to take as many subjects as we possibly could each term. ", "So there's the sufficient way to take subjects  to graduate in five terms.  And of course, one consequence is  that in my second term freshman year,  I was taking five subjects because it was possible. ", "But that leaves me with a kind of heavily loaded term  compared to-- here's a term with two subjects,  and there's a term with only one subject at the very end.  So it's possible, in fact, to somewhat adjust the term load. ", "Let's just shift taking 18.02 to the third term.  It's perfectly feasible to do that,  because I will have satisfied all the prerequisites of 18.02 ", "after the first term, but I don't have  to take it in the second term.  Let's shift it off.  So now I've lightened the load in the second term  to four subjects, somewhat increasing  the load-- I had to do it somewhere-- in the third term ", "to three subjects.  So now I have to take no more than four subjects a term.  And as a matter of fact, if you fiddle,  you can actually find a graduating schedule ", "in which you can only take three subjects per term.  And we will examine what's the minimum number of subjects ", "per term in the next segment.   PROFESSOR: The example of scheduling courses in terms  is really a special case of a general problem  that you can probably see of scheduling a bunch of tasks ", "or jobs under constraints of which ones have  to be done before other ones, which  is a topic that comes up actually  in lots of applications.  But you can see applications in computer science ", "where you might have a complex calculation, pieces  of which could be done in parallel and other parts had  to be done in order because later results depended  on the results of an earlier computation. ", "It leads us to the general discussion  of parallel scheduling.  And we've already worked out some theory of that really just  from the example.  Namely, if we look at the minimum number of terms ", "to graduate, this corresponds to the minimum amount  of number of stages or the minimum amount of time  that it takes to process a bunch of tasks, ", "assuming that you can do tasks in parallel  and as many in parallel as you need  to-- that there's no limit on the amount of parallelism  allowed.  In that case, what we can say is that the minimum parallel time ", "for a bunch of constrained tasks is simply the maximum chain  size in the constraint graph.  We saw that example with the course ", "prerequisites where we had five.  And in general, this is the theorem.  Minimum parallel time is exactly equal to maximum change size  for chains in the graph that constrains ", "the order in which tasks can be completed.  Now what about the maximum term load?  Well, that corresponds to the number  of processors you need to be doing tasks in parallel. ", "So for the course scheduling example,  it means how many subjects can you take in one term?  But if you were, say, doing computations,  how many separate CPUs would you need in order ", "to be able to fully utilize the parallelism to as  much in parallel as you possibly could and abound  on the number of processors that are needed for minimum time is ", "simply the maximum antichain size, which  in the example from the previous segment on course scheduling,  it turns out there were five courses you could take  in one term, the second term. ", "And that was, in fact, the maximum antichain size.  So that's an upper bound on the number of processors that you  need to achieve minimum time. ", "But in fact, it's a course upper bound  because although the number of processors needed  to achieve minimum parallel time is at most  the maximum antichain size.  In fact, in the previous example, ", "it turns out you could get away with three processors.  It was possible to schedule the subjects  so you only took three courses a term  and still finished in minimum time. ", "So can you do better than three subjects?  Well, there's a trivial argument that says, no, you can't.  Because in that previous example,  we had 13 subjects to schedule.  The maximum chain size was 5. ", "So it was going to take at least five terms.  So that means you have to distribute these 13  subjects among five terms.  There has to be some term that has ", "at least the average number of subjects,  namely 13 divided by 5.  So that means there has to be a term in which you're taking  13 divided by 5 subjects. ", "Of course, you round up because it has to be an integer.  So the minimum number of terms to finish and graduate--  finishing these 13 subjects in five terms-- ", "is 3 because 13 divided by 5 rounded up is 3.  And this is a general phenomenon that applies.  And what we can say is that if you have a DAG with n vertices ", "and the maximum chain size is c-- so that's  how deep it can be at most-- and the maximum antichain size is  a-- that's the largest number of things ", "that you could ever possibly do in parallel-- then clearly,  the total number of vertices is c times a, at most.  So the total number of tasks that you ", "can do where you are going to finish  in c steps using at most a processors is bounded  by c times a.  So what that tells you is that you can't both ", "have the antichain size and the chain size  be too small because their product has to be at least n.  That can be rephrased as a lemma that is credited ", "to a guy named Dilworth.  Dilworth is actually famous for Dilworth's theorem of which  this Dilworth's lemma is a special case,  but we don't need the general theorem.  Dilworth's lemma says that if you have an n-vertex DAG, then ", "for any number t, it either has a chain of size bigger than t,  or it has an antichain of size greater than  or equal to n over t.  And we proved this on the previous slide. ", "The product of these two things has to be at least n,  and the general case is t times n over t  is greater than or equal to n.  And this holds for all t between 1 and n. ", "Well, let's think of a simple application of that.  If I choose the t that balances antichain size from chain size,  then I choose t to be the square root of n.  So over here, I have square root of n, ", "and here I have n divided by the square root of n,  which is also square root of n.  And what we can conclude is that every end vertex  DAG has either a chain of size at least the square root of n ", "or an anti chain of size at least square root of n.  This turns out to actually have a few applications,  but we're just going to look at a fun  application of this remark that you ", "have to have a chain or an antichain of size  at least square root of n.  You might have only one of these.  You might have both.  But one or the other has to be at least as big ", "as square root of n.  Let's think of a new DAG that I'm  going to construct as follows.  I'm going to draw an edge between students in the class, ", "and I'm going to think of one student  as having a direct edge to another student  if the first student is both shorter and younger-- actually  meaning no taller than and no older than the other. ", "Let's just say shorter-- meaning shorter or possibly  the same height-- younger or possibly the same age.  And so the rule is if I think of a student  as being represented by their shortness s and their age ", "a, then a student with a height s 1  and age a 1 has a direct arrow to another student with height  s 2 and age a 2, providing that the first pair is less than ", "or equal to the second pair in both coordinates.  S 1 is less than or equal to s 2.  And A 1 is less than or equal to A 2.  Now, we don't want ties here because that  would break the DAG property if I ", "have two students with exactly the same age and height.  So let's assume that we're measuring age in microseconds  and the height in micrometers.  And with that kind of a fineness, ", "the likelihood of a tie is pretty low.  So then it becomes a DAG again.  So this is the definition of taking a DAG built out ", "of pairs-- there's a pure DAG for height,  and there's a pure DAG for age.  And I combine them into pairs, and I get a new DAG  by looking at how the coordinates behave together. ", "This is called the product graph.  It's a general construction that comes up,  and we will talk a little bit more  about when we reexamined DAGs in the context ", "of the language of relations and partial orders.  Anyway, this is the product graph.  According to Dilworth's lemma, in a class like ours  of 141 students, it means that we're ", "going to have a chain or an antichain in this product  DAG of size square root of 141 rounded up, or 12.  ", "According to Dilworth's lemma, in  this particular age-height graph, what does  it mean for this to be an antichain? ", "Suppose I take a bunch of students  and I line them up in order of size  with the tallest on the left and the shortest on the right.  If this is going to be an antichain, ", "it means that they have to be getting older  as they get shorter.  Because if I ever had a case where somebody to the right ", "was both shorter and younger than somebody to the left,  it wouldn't be an antichain because they'd be comparable.   So an antichain-- according to Dilworth's ", "lemma-- if you'd sort the students by height,  they have to be getting older and as they get shorter.  If it was a chain, they would be getting younger ", "as they got shorter.  But the more interesting one is the antichain  in this height-birthday example.  So we should be looking at-- we'll either have a chain ", "or an antichain in this class according to this product DAG.  As a matter of fact, we really had an antichain.  Here's a quick list of a dozen students. ", "And indeed, if you look at the birthdays,  there's somebody who's 6'1 was born in August '94 and then  somebody who was born in April '94 and is 6'0 all the way down ", "to somebody who was born in 1991 and who's five feet tall.  So we lucked out.  We could have only had to chain, but we actually  had the antichain in this case. "], "vid_duration": [11.78, 10.08, 11.69, 10.06, 12.58, 12.938, 10.182, 11.0, 10.34, 12.44, 10.32, 12.32, 12.27, 10.1, 12.09, 11.27, 14.97, 11.2, 13.72, 10.73, 11.03, 10.2, 10.73, 12.05, 11.055, 10.225, 11.47, 11.63, 10.22, 12.49, 11.36, 13.23, 13.36, 11.39, 11.73, 10.115, 10.815, 13.02, 12.27, 12.49, 10.03, 10.79, 11.152, 11.678, 11.42, 10.66, 10.85, 10.61, 11.44, 12.46, 11.06, 10.96, 12.07, 12.11, 12.41, 10.99, 10.75, 11.78, 10.7, 11.6, 15.089, 10.821, 11.449, 12.261, 10.589, 11.231, 11.909, 12.221, 11.87, 12.209, 10.56, 10.9, 12.651, 11.011, 10.249, 13.189, 12.4, 10.051, 11.14, 12.12, 11.57, 11.76, 14.589, 11.29, 12.081, 12.87, 11.1, 11.689, 10.01, 10.157, 10.384, 12.82, 11.45, 10.4, 10.08, 11.34, 13.41, 10.817, 12.403, 11.48, 10.73, 10.93, 10.19, 10.1, 10.0, 10.839, 11.031, 12.18, 11.22, 11.69, 12.689, 11.46, 11.27, 10.091, 14.08, 11.65, 10.36, 12.01, 11.72, 13.31, 11.21, 10.43, 12.71, 12.63, 11.83, 11.51, 11.06, 10.14, 11.912, 10.311, 11.939, 11.49, 11.061, 13.82, 11.0, 12.0, 14.859, 13.52, 10.221, 11.39, 10.18, 11.841, 10.229, 11.8, 10.77, 11.4, 10.649, 13.081, 11.29, 11.49, 12.09, 10.48, 12.099, 11.741, 11.259, 11.708, 12.262, 11.131, 10.48, 10.02, 13.08, 11.27, 16.65, 10.49, 10.75, 10.61, 11.685, 10.245, 12.21, 11.596, 10.283, 10.831, 10.07, 10.2, 10.8, 11.12, 11.81, 11.85, 8.127], "stet": [[0, 11.78], [11.78, 21.86], [21.86, 33.55], [33.55, 43.61], [43.61, 56.19], [56.19, 69.128], [69.128, 79.31], [79.31, 90.31], [90.31, 100.65], [100.65, 113.09], [113.09, 123.41], [123.41, 135.73], [135.73, 148.0], [148.0, 158.1], [158.1, 170.19], [170.19, 181.46], [181.46, 196.43], [196.43, 207.63], [207.63, 221.35], [221.35, 232.07999999999998], [232.07999999999998, 243.10999999999999], [243.10999999999999, 253.30999999999997], [253.30999999999997, 264.03999999999996], [264.03999999999996, 276.09], [276.09, 287.145], [287.145, 297.37], [297.37, 308.84000000000003], [308.84000000000003, 320.47], [320.47, 330.69000000000005], [330.69000000000005, 343.18000000000006], [343.18000000000006, 354.5400000000001], [354.5400000000001, 367.7700000000001], [367.7700000000001, 381.1300000000001], [381.1300000000001, 392.5200000000001], [392.5200000000001, 404.2500000000001], [404.2500000000001, 414.3650000000001], [414.3650000000001, 425.1800000000001], [425.1800000000001, 438.2000000000001], [438.2000000000001, 450.4700000000001], [450.4700000000001, 462.9600000000001], [462.9600000000001, 472.99000000000007], [472.99000000000007, 483.7800000000001], [483.7800000000001, 494.9320000000001], [494.9320000000001, 506.61000000000007], [506.61000000000007, 518.0300000000001], [518.0300000000001, 528.69], [528.69, 539.5400000000001], [539.5400000000001, 550.1500000000001], [550.1500000000001, 561.5900000000001], [561.5900000000001, 574.0500000000002], [574.0500000000002, 585.1100000000001], [585.1100000000001, 596.0700000000002], [596.0700000000002, 608.1400000000002], [608.1400000000002, 620.2500000000002], [620.2500000000002, 632.6600000000002], [632.6600000000002, 643.6500000000002], [643.6500000000002, 654.4000000000002], [654.4000000000002, 666.1800000000002], [666.1800000000002, 676.8800000000002], [676.8800000000002, 688.4800000000002], [688.4800000000002, 703.5690000000003], [703.5690000000003, 714.3900000000003], [714.3900000000003, 725.8390000000003], [725.8390000000003, 738.1000000000003], [738.1000000000003, 748.6890000000003], [748.6890000000003, 759.9200000000003], [759.9200000000003, 771.8290000000003], [771.8290000000003, 784.0500000000003], [784.0500000000003, 795.9200000000003], [795.9200000000003, 808.1290000000002], [808.1290000000002, 818.6890000000002], [818.6890000000002, 829.5890000000002], [829.5890000000002, 842.2400000000001], [842.2400000000001, 853.2510000000001], [853.2510000000001, 863.5000000000001], [863.5000000000001, 876.6890000000001], [876.6890000000001, 889.089], [889.089, 899.1400000000001], [899.1400000000001, 910.2800000000001], [910.2800000000001, 922.4000000000001], [922.4000000000001, 933.9700000000001], [933.9700000000001, 945.7300000000001], [945.7300000000001, 960.3190000000002], [960.3190000000002, 971.6090000000002], [971.6090000000002, 983.6900000000002], [983.6900000000002, 996.5600000000002], [996.5600000000002, 1007.6600000000002], [1007.6600000000002, 1019.3490000000002], [1019.3490000000002, 1029.3590000000002], [1029.3590000000002, 1039.516], [1039.516, 1049.9], [1049.9, 1062.72], [1062.72, 1074.17], [1074.17, 1084.5700000000002], [1084.5700000000002, 1094.65], [1094.65, 1105.99], [1105.99, 1119.4], [1119.4, 1130.217], [1130.217, 1142.6200000000001], [1142.6200000000001, 1154.1000000000001], [1154.1000000000001, 1164.8300000000002], [1164.8300000000002, 1175.7600000000002], [1175.7600000000002, 1185.9500000000003], [1185.9500000000003, 1196.0500000000002], [1196.0500000000002, 1206.0500000000002], [1206.0500000000002, 1216.8890000000001], [1216.8890000000001, 1227.92], [1227.92, 1240.1000000000001], [1240.1000000000001, 1251.3200000000002], [1251.3200000000002, 1263.0100000000002], [1263.0100000000002, 1275.6990000000003], [1275.6990000000003, 1287.1590000000003], [1287.1590000000003, 1298.4290000000003], [1298.4290000000003, 1308.5200000000002], [1308.5200000000002, 1322.6000000000001], [1322.6000000000001, 1334.2500000000002], [1334.2500000000002, 1344.6100000000001], [1344.6100000000001, 1356.6200000000001], [1356.6200000000001, 1368.3400000000001], [1368.3400000000001, 1381.65], [1381.65, 1392.8600000000001], [1392.8600000000001, 1403.2900000000002], [1403.2900000000002, 1416.0000000000002], [1416.0000000000002, 1428.6300000000003], [1428.6300000000003, 1440.4600000000003], [1440.4600000000003, 1451.9700000000003], [1451.9700000000003, 1463.0300000000002], [1463.0300000000002, 1473.1700000000003], [1473.1700000000003, 1485.0820000000003], [1485.0820000000003, 1495.3930000000003], [1495.3930000000003, 1507.3320000000003], [1507.3320000000003, 1518.8220000000003], [1518.8220000000003, 1529.8830000000003], [1529.8830000000003, 1543.7030000000002], [1543.7030000000002, 1554.7030000000002], [1554.7030000000002, 1566.7030000000002], [1566.7030000000002, 1581.5620000000001], [1581.5620000000001, 1595.082], [1595.082, 1605.303], [1605.303, 1616.6930000000002], [1616.6930000000002, 1626.8730000000003], [1626.8730000000003, 1638.7140000000002], [1638.7140000000002, 1648.9430000000002], [1648.9430000000002, 1660.7430000000002], [1660.7430000000002, 1671.5130000000001], [1671.5130000000001, 1682.9130000000002], [1682.9130000000002, 1693.5620000000001], [1693.5620000000001, 1706.643], [1706.643, 1717.933], [1717.933, 1729.423], [1729.423, 1741.513], [1741.513, 1751.993], [1751.993, 1764.0919999999999], [1764.0919999999999, 1775.8329999999999], [1775.8329999999999, 1787.0919999999999], [1787.0919999999999, 1798.8], [1798.8, 1811.062], [1811.062, 1822.193], [1822.193, 1832.673], [1832.673, 1842.693], [1842.693, 1855.773], [1855.773, 1867.043], [1867.043, 1883.693], [1883.693, 1894.183], [1894.183, 1904.933], [1904.933, 1915.543], [1915.543, 1927.2279999999998], [1927.2279999999998, 1937.4729999999997], [1937.4729999999997, 1949.6829999999998], [1949.6829999999998, 1961.2789999999998], [1961.2789999999998, 1971.5619999999997], [1971.5619999999997, 1982.3929999999996], [1982.3929999999996, 1992.4629999999995], [1992.4629999999995, 2002.6629999999996], [2002.6629999999996, 2013.4629999999995], [2013.4629999999995, 2024.5829999999994], [2024.5829999999994, 2036.3929999999993], [2036.3929999999993, 2048.2429999999995], [2048.2429999999995, 2056.3699999999994]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [680, 1474, 2056]}
{"example_id": "mit097@@MIT6_042JS15_35_ipod", "text": [" PROFESSOR: Random walks provide probabilistic models  for a bunch of settings.  In fact, we've seen a couple already,  so let's examine what they are in general.  So the set up for a random walk is that you have a digraph, ", "and we can also often think and talk about the digraph  as though it was a state diagram for a machine with state,  so here's a three-state digraph-- blue, orange, ", "and green-- and the part that becomes probabilistic  is that we think of the process of which edge  to follow when you're at a given state ", "is made probabilistically.  And the only rules are that we're  going to assign probabilities to the edges in a way  like this where, for example, what I'm  telling you is there's a 1/3 probability that I'll follow ", "the edge from O to O, and a 2/3 probability that I'll follow  the edge from O to green, and the rule  is simply that the sum of the probabilities  on the outgoing edges has to sum to 1. ", "So let's fill in the rest of the graph in a legal way.  So here we have B with a 1/2 probability  of going from B to B, a 1/4 from B to O, and a quarter from B ", "to G. And the green state is certain in one step  if you're at green to go to blue next.  There's only one edge out.  It has probability 1. ", "Now, gambler's ruin can be seen as an example  of this kind of a random walk.  The states where the amount of money that you had,  ranging from 0 when you're bankrupt to T when you've  reached your target and N is the start state, which ", "is your initial stake, the green edges are weighted  with a probability P of winning a bet,  so we have transitions from K to K plus 1 for K ", "less than T, with a weight probability P  and, likewise, the red edges are weighted with the probability  of losing a bet, Q, or 1 minus P.  So there is a digraph, or a state machine, ", "that describes the gambler's ruin problem  as a probabilistic walk on a graph.  And the typical kind of question that we  would ask about a random walk on a graph ", "would be, what's the probability of reaching T,  the target, before reaching 0, bankrupt, given that you're  starting at some state And. ", "So in walks come up in a bunch of quite different settings.  For example, in physics Brownian motion  is the random motion of a particle that's ", "being buffeted by atomic forces, and its  modeled by saying that this particle can  move in any direction in 3D space  and chosen uniformly at random. ", "And the theory of Brownian motion--  it had been observed first without being understood.  Einstein was the first one to come up with a random walk  model and corresponding theorems about the behavior of particles ", "under Brownian motion.  In fact, that was one of the main components of his Nobel  Prize.  He wasn't given a Nobel Prize for relativity  at the time, because it had not yet been firmly proven, ", "although it was widely celebrated.  Another case is in finance.  We've already seen how gambler's ruin reflects, or seems  to reflect, the biased random oscillation of stock ", "prices over time, and we will see  at the end of this set of videos an application  of random walks on a graph to model ", "web search and clustering of a focus on vertices in a digraph.  So the general kinds of questions ", "that come up when you're talking about random walks on graphs  are illustrated by this simple three-state example  with blue, orange, and green.  We might ask, for example, starting ", "at state B, what's the probability of reaching  state O in seven steps?  And that would be easy enough to calculate  in this small example, but it would be a typical question. ", "A more interesting general question would be,  what's the average number of steps that it  takes to get from B to O?  I mean, you could with probability of 1/4,  you go there in one step, but with probability an 1/8, ", "you go there in three steps, and so on.  You can calculate again explicitly and easily enough  what the average number of steps from B to O  is in this simple example, and we'll shortly ", "remark about general ways to solve that problem.  And finally, you can ask a gambler's ruin type question,  what's the probability of starting  at B of getting to G before O?  Well, in this trivial example, you ", "can just read off the answer.  You are going to get to G before O with 50-50 probability, ", "because from B you have to go one place or the other  with equal probability.  But in general, this becomes a more  interesting and complicated question,  which you can solve by methods that we're about to lay out. ", "Let me just remind you that we've already seen  an interesting and illustrative example of random walk  on a graph when we were looking at coin tosses.  The problem, for example, of if I toss a fair coin ", "and I wait for three consecutive tosses that form the pattern  HTH or the pattern TTH, and I want  to know what's the probability of winning because HTH comes ", "before TTH, I can model that with a-- we said  with an infinite tree diagram, using our tree  method for forming probability spaces, ", "but the tree was very recursively defined.  Sub-trees were isomorphic to the original tree, which  allowed us, in fact, to come up with a finite description ", "of the infinite tree that amounted to a finite state  machine or finite graph.  So let's look at that example in more detail.  If I'm trying to model the coin flipping thing, ", "we start off in a state where the previous two  flips don't exist.  I haven't flipped anything yet.  The state's going to record the values of the previous two  flips, and with no prior flips, there's ", "a 50-50 chance that the first flip will be H, in which case  I'm in the state with just an H and nothing preceding,  or there's a 50-50 chance I flip a T, in which case  I'm in the state in which there's ", "been a T and nothing previous.  But I can already say something then  about the probability of tossing HTH before TTH,  namely the probability of winning. ", "The probability of winning is, of course,  the probability of winning, given that I start at the start  state with no prior flips, but the probability  that I win starting here is simply ", "the probability that I win starting at the state nothing H  and where the probability that I win at the state  started nothing T, with the two probabilities weighted equally ", "since this is a fair coin, and there's a 50-50 chance  of going each way.  That is the probability of winning  given no prior tosses is 1/2 the probability of winning ", "if the first toss is an H plus 1/2  the probability of winning if the first toss is  a T. This is just an application of the Law of Total  Probability.  So continuing in this way, let's expand more of the digraph. ", "So suppose that I have tossed a head and then after that I toss  a head, and I go to state HH or I toss a T,  and I go to state HT.  So here I'm just recording the previous two flips, ", "with the most recent one on the right.   This structure of the state diagram  tells us that if I want to know what  the probability of winning, given that I flipped exactly ", "one head at the start, the probability is simply  by, again, total probability.  The probability of winning from HH weighted by 1/2  and the probability of winning from HT weighted by 1/2, ", "and I wind up again with a simple linear equation that  connects the probability of winning in one state  with the probability of winning in the states that it goes to. ", "Let's continue and do another example.  So, likewise, if I expand what happens  after I flip a T or an H after having flipped the first head,  I get a corresponding equation that the probability ", "of winning after a single tail is the same as 1/2  the probability of winning with a tail followed  by an H or a tail followed by a tail.  This is a more interesting part of the diagram, ", "where suppose that my past two flips have been two H's.  Well, if I flip an H again, then I'm  back in state where the previous two flips where H's, or if I ", "flip a T, then I'm in this state HT,  where the previous flips were an H and a T, in that order.  And that tells me, if I want to know  about the probability of winning given HH, ", "now it's the probability of winning  given HH plus the probability of winning given HT.  And, again, it's a linear equation connecting up ", "the probability of winning in one state  with the probability of winning in other states, possibly  itself, but there's no circularity here.  It's just a system of linear equations. ", "Well, there's what the whole diagram looks like.  In particular, once you flipped HT,  if you then flip an H you've won because you got to HTH first,  and you stay in the win state forever ", "or, alternatively, once you flip TT, if you flip an H  you've lost because TT has come up first.  If you flip the T again, you stay in state TT.  And what we can say is the probability ", "of winning if we're in the win state is 1,  and the probability of winning if you're in a lose state is 0.  And overall, I simply have this system  of linear equations for the probability of winning ", "in one state given other states, and I  can solve these linear equations to find  the probability of winning in the start state, which  is simply the probability of winning. ", "So looking back at our questions for random walks,  where we ask whether the probability of reaching  O in seven steps starting at B, what's the probability of that?  What's the average number of steps to go from B to O? ", "What's the probability of reaching G  before O, starting at B?  In every case, these questions can be formulated simply  as solving systems of linear equations ", "whose structure directly reflects   PROFESSOR: So some of the standard questions  that we've examined already about random graphs  are the probability of getting from one place to another, ", "or the expected time to get from one place to another.  But a different kind of question that  comes up in a fundamental way is the probability  of being someplace.  So let's examine that. ", "Here is the graph with states blue, orange, and green  that we've seen before.  And suppose that I start at state B. ", "And I ask, what's the probability of being at each  of these states after one step?  So to start with, I'm interested in p B, p O, ", "and p G-- which is the probability of being at state  B, the probability of being at state O,  and the probability of being at state  G. The sum of the probabilities is going to be 1. ", "And initially when I tell you that I'm at state B,  it means the probability of being at B is 1,  and the other two is 0.  And I'm interested in the way that these probabilities  update after one step. ", "If p prime B is the probability of being in state B  after one step, and p prime O is the probability  of being in the orange state one step later-- and likewise ", "for green-- what are these probabilities?  Well it's easy to see just reading off this graph  that the only place you're at is B. So the only way  to get probability of being somewhere ", "is by following an edge out of B.  So the probability of being at one step at the orange vertex  is 1/4.  And it's likewise 1/4 for being at the green state. ", "And it's 1/2 for staying at the blue state.  So what we can say is that the updated probabilities  of being at these different states  is 1/2, 1/4, and 1/4, as we've just reasoned. ", "OK.  Let's keep going.  Given that the probability that I'm at the states blue,  orange, and green are given by this vector of probabilities, ", "what's the distribution after two steps?  So let p double-prime B be the probability of being at state B  after two steps, starting from B. Well, ", "the way we can figure that out is  by using conditional probabilities.  Let's look at the example of calculating  the probability of being in the orange state two ", "steps after you've started at the blue state.  So here was the probabilities of being at the different states  after one step.  How do I get to the orange state?  Well I can get to the orange state from the blue state. ", "And so the probability of being in the orange state  after two steps is the probability  of being at the blue state after one step times the probability ", "that I take this edge to the orange state.  That is, it's the probability of going from B to O-- given  that I'm at B-- times the probability of being ", "in B after one step.  This then is the probability of being in O after two steps.  And likewise, another component of the probability ", "of being at O is that if you're at O, and what's  the probability of going from O to O?  And that is this 1/3 times the probability ", "of being at O at all, which is 1/4.  And the final case, using again the law of total probability,  breaking it up into cases, the third way that I  can get to the orange state on step two ", "is by being at the green state on step one following  the green to O edge-- of which there isn't any,  so that's going to be probability  0-- times the probability of being at the green state, which ", "is 1/4, but it won't matter.  So let's just fill in these amounts  looking at the first term.  The probability of going from B to O when you're at B  is simply the probability of this edge. ", "It's 1/4.  And likewise, the probability of going from O  to O given that you're at O is the probability  of this edge-- namely 1/3. ", "So we can fill that term in.  And finally the probability of going from G to O  is 0, given that you're at G, because there  isn't any vertex there. ", "And then you fill in those probabilities  and do the arithmetic.  You come out with 5/24 probability  of being in the orange state after two steps. ", "Well the same calculation, you can figure out  what's the probability of being at the blue state  or the green step after two steps.  And there's the answer.  There's a 50/50 chance of being at the blue state  after two steps, 5/24 as we saw at the orange state, ", "and the rest of it is 7/24 is the probability  of being at the green state.  OK.  So what's going on in general? ", "And we can explain how to do these calculations by using  a little bit of linear algebra.  So let's define the edge probability  matrix of a random walk graph is just ", "the adjacency matrix of the graph,  except that instead of using 0's and 1's to indicate  whether an edge is not present or present,  I'll use in the I, J position of the matrix-- ", "the probability of the edge that goes from I to J--  if there is an edge-- and 0 if there isn't any edge.  Let's look at an example.  So here is the way we'd fill it in abstractly ", "for our three-state graph.  It'll be a 3 by 3 matrix with the probabilities  of the successive edges in the corresponding position.  So this is the position in the B, ", "B coordinate is the probability of the edge from B to B. The O,  B coordinate, if you think of the columns  as labeled blue, orange, green; and the rows as labeled ", "blue, orange, green.  And this is the orange, blue coordinate.  And it's the probability of the edge from 0 to B.  Let's fill in the first row, which was-- this ", "is just read directly off the graph.  It was the edges out of B that went from B to B,  from B to O, and from B to green-- G.  And it had those weights. ", "And if I fill in the rest of it, I  get the edge probability matrix for  our simple three-state graph.  And there it is.  So this last one shows the fact that there is a certain edge ", "from green to blue.  The only place you can go from green is to blue,  and you can't go to either orange or green in one step.  OK. ", "So why are we bringing up the matrix?  Well if you looked at the way we updated the state  to go from the one-step distribution  to the two-step distribution, it was really a matrix multiply. ", "And in general, to do an update, you're  just going to do a vector matrix multiplication.  If you have the probabilities of being in the successive states  B, O, and G, and you do a vector matrix multiplication using ", "the probability matrix of the graph,  you get the updated vector of distributions.  And that's easy to check just from the definitions, ", "and from the definition of vector times matrix,  which I assume you're familiar with.  So now we can ask what's the distribution after t steps,  starting from some particular given distribution-- say, ", "starting at state B, or starting at any possible distribution  of probabilities to the different states.  And the way that we can figure that out-- so I'm  interested in other words is the probability ", "of being in O after t steps G after t steps in B  after t steps, say, starting from state B.  And what happens also as t approaches infinity? ", "And these are sort of two basic questions  that we're going to be asking.  So first of all, how do you calculate  starting at a given distribution p  B, p O, p G where you're going to be after t steps? ", "Well, you're just continually updating, which  means multiplying by M t times.  So the distribution after t steps ", "is gotten by taking the initial distribution times  the t-th power of M.  Now this is actually already useful computationally,  because it means that since you can compute a matrix ", "power by successive squarings, you actually  only need about log of t matrix multiplications  in order to be able to figure out  what's the distribution of probabilities ", "after t steps of the graph.  Then the crucial concept that we want to examine--  and we'll make a lot of use of in the next video when ", "we talk about a page rank-- is the idea  of a stationary distribution.  So a stationary distribution means  that once you're in the stationary distribution, ", "it's stable.  You're going to stay in that distribution.  You're not going to be in any particular state,  but you'll have a vector of probabilities of being ", "in the different states.  And one step later, that vector's not going to change.  So what it means is that the next-step distribution  is the same as the current distribution. ", "What's the stationary distribution here?  Well, the way we're going to have to calculate  that is here's how you update.  This is the result of the vector matrix multiplication. ", "But let's just spell it out in terms  of the conditional probabilities.  After one step, if the original distribution  is p B, p O, p G, then the new probability ", "of being in state B, the only way  you can get there is by following the edge from B  to B with probability 1/2.  And that's times the probability of being at B. ", "And the other way you can get to B  is by being at the green state.  And then one step later you're certain to be at B. So  that adds a contribution of 1 times p G. ", "And likewise for p-- the updated probability of being  at the orange state and the green state.  And what we want is that these updated probabilities ", "are the same as the ones that I'm starting with.  That's the definition of stability.  You update the vector p B, p O, p G,  and you get the same vector.  That's what makes it stable. ", "And of course, a side constraint.  Since you can always solve a system of equations like this  by letting all the p's be 0, which is degenerate,  we add the constraint that the sum  of the probabilities of being in the states has to be 1. ", "Well if we solve that simple 3 by 3 system of equations,  then it turns out that the stable distribution is there's  an 8/15 chance of being in state B, ", "a 3/15 chance of being in state orange,  and a 4/15 chance of being in state green.  And you should check that yourself  by asking what's the probability of being in p B after one step ", "given these probabilities?  And I'm not going to talk you through that.  But just to verify and imprint the idea of stability,  that's one that's worth stopping the video for a moment  to check and do a little arithmetic with a pencil ", "and paper.  OK.  So in general, what we're going to do  is we're trying to find the stationary distribution  vector-- call it s bar, for vector. ", "And we get this by solving the vector matrix equation--  that the distribution vector times the edge probability ", "matrix is equal to that same distribution vector.  We want to solve this system of equations.  If there are n states, then this is  an n by n system of equations, with an additional constraint ", "that we want the norm of the stable vector to be 1,  because that's to avoid the degenerate 0 solution.  Well there are some problems with stationary distributions ", "that we want to think about.  First of all, what happens in this example where you have  just two states, and the probability of being  in the first state at 1 and the second state is 0?  Well if you update that state, what happens ", "is you just go to the second state with probability 1.  And you can keep doing that.  And there may be a stable distribution here,  but this particular pattern doesn't converge to it. ", "As you go through time, at every other step  you're at state 1, and every other step you're at state 0.  But you never get to a stable distribution ", "where step after step you are at equal probability  of being at these two places.  I'm assuming here that this is a certain edge,  and that's a certain edge.  It has to be. ", "There's only one edge out.  So a stable distribution would be 1/2, 1/2.  But this thing doesn't converge to it.  OK.  Here's a slightly more complicated example, ", "where again assume that all the edges are equally likely.  There's exactly two edges out of each of these vertices  so that each edge has weight 1/2. ", "And the problem with this graph is  that when you ask what's the stable distribution  and, well, if you look at it, if you assume  that the probability of being in the middle is 0, ", "and the two places that you get stuck at have probability p  and 1 minus p, then that's stable,  because once you're at this state with probability p  you're following the one certain edge that goes back around ", "to this vertex.  And therefore there's probability  of p of being there one step later,  and likewise probability q of one step later.  So the split between p and q is a stable distribution ", "for this thing, with probability 0 and 0 there.  And of course p and q can be any real numbers between 0 and 1.  So there's actually an uncountable number  of stable distributions for this graph. ", "Problem here is it's not strongly connected.  And that turns out to be a sufficient condition  that it's got a single stable distribution whenever ", "it's strongly connected.  So in general we can ask the question,  is there always a stationary distribution  for any random graph? well, if the graph is finite, yes, ", "there's guaranteed to be a stationary distribution.  But is it unique?  Well sometimes, sometimes not.  If the graph is strongly connected, it will be unique. ", "But we've seen examples in the previous slide  where it's not unique.  In fact, it could be uncountably many.  And another crucial question is, does a random walk ", "approach the stable distribution no matter how you start?  And that first example was one where  you went between the first state and the second state  and oscillated. ", "And it never converged on the stable distribution  of 1/2 and 1/2.  In general, it's nice when you can say that no matter  how you start, after a while things stabilize, ", "and you wind up at the unique stable distribution.  So sometimes it'll be the case that every initial distribution  will eventually converge on the stable one ", "or the stationary one.  Sometimes not.  And then another crucial question  will be, how quickly does this convergence happen?  If we start off at some arbitrary probability ", "distribution, or some particular state,  how long does it take before by and large  the probabilities that were in the different states  has become pretty stationary? ", "And the rate at which that happens again   PROFESSOR: PageRank is a measure of the importance of a web  page.  But let me immediately correct my own confusion ", "that I suffered from for some time  until very recently, which is that even though PageRank  is used for ranking pages, it's called PageRank  after its discoverer, developer, Larry Page, ", "was one of the co-founders along with Serg Brin of Google.  So the motivation is that when you-- at least before Google, ", "when you did a standard retrieval on a web page  using keyword Search and similar kinds of criteria,  you'd get back millions of hits, most of which  were really low quality and you weren't ", "interested in, and with a few useful pages buried  in the millions.  And the question was, all of these documents  are indistinguishable in terms of keyword search and textual ", "patterns, how do you figure out which are the important ones.  And the idea that Page came up with  was to use the web structure itself,  the structure of the worldwide web, ", "to identify the important documents.  So we can think of the whole internet as a graph  where a user is on a page, and we think of a URL as a link ", "to another page, as a directed edge.  And users are kind of randomly traveling around  in the worldwide web.  They're at a page, they randomly click a link  to get to another page, and they keep ", "doing a walk on the web graph.  And every once in a while, they're  going to find that the thread that they're on  is kind of losing steam, where they find themselves  in some kind of a cycle and they will randomly start over again ", "at some other page.  And we want to argue or hypothesize  that a page is more important when  it's viewed a large fraction of the time ", "by these random browsers and random users.  So to be formal, we're going to take  the entire worldwide web, trillions of vertices,  as a digraph. ", "And there's going to be an edge from one URL to another,  from V to W, if there's a link from the page V to the page W, ", "or the URL W. W might not even be a page,  it might be a document, which means it  doesn't have any links on it.  But for the real vertices are the web pages  that have links on them. ", "OK, that's the model.  And we're going to make it into a random walk graph  by saying that if you look at a URL V, at a vertex V,  all of the edges out of it are equally likely. ", "It's a simple model, and it might or might not work.  But in fact, it did work pretty well.  That is the model of the worldwide web as a random walk ", "graph.  So to be more precise, the probability  of the edge that goes from V to W  is 1 over the out degree of V. That  is, all of the out degree of V edges ", "leaving vertex V get equal weight.  Now to model this aspect that the users start over  again if they get bored or they get stuck,  we can formally add to the digraph ", "a hypothetical super-node, which-- and with the property  that there's an edge from the super-node to every other node  with equally likelihood.  So once you hit the super-node then ", "following an edge is tantamount to saying, pick a random page  and start over again.  To get to the super-node, we have  edges back from other nodes in the graph ", "back to the super-node.  In the reading, we said that we were  going to have nodes back from terminal nodes that  had no edges out. ", "For example, a document or something like that.  That's actually not sufficient, because-- for the PageRank  to work in the theoretical way that we want it  to because even if there is no dead nodes, ", "you might be in a clump of nodes which you can't get out of.  And you'd want to be able to-- and even though none of them  was a dead end, because they all had arrows going out  to each other.  And so you'd really want a node from a-- an edge ", "from a clump like that back to the super-node  to model starting over there.  The simplest way to do it really is  to simply say that there's an edge to the super-node  from every vertex. ", "So wherever you are, you can randomly decide to start over.  And Page and Brin and their co-authors  in the original paper on PageRank ", "suggested that the edge back from a vertex  to the super vertex might get a special probability.  It might be customized, as opposed  to being equally likely with all of the other edges leading ", "a vertex.  In fact, I think they decided that there should  be a 0.15 probability from each vertex of jumping  at random to the super-node. ", "OK.  Let's just illustrate this with an example.  This is a random walk graph that we've seen before modeling coin  flipping.  And when I add the super-node, there's  this one new vertex super, and there's ", "an edge from the super vertex to every other one  of the vertices in the graph.  And from each vertex in the graph,  there is an edge going back.  I've illustrated that with two-way arrows. ", "So this is really an arrow with two arrowheads.  It represents an arrow in each direction.  Now in the original paper, actually, Page  didn't talk about a super vertex. ", "Instead, he talked about each vertex randomly jumping  to another vertex.  But that would just get the whole state diagram completely  clogged up with edges, so it's more  economical to have everybody jump to the super vertex ", "and the super vertex jump back to everybody.  And that saves a significant number of edges.  So PageRank, then, is obtained by computing ", "a stationary distribution for the worldwide web.  So s bar is a vector of length trillions  that the coordinates are indexed by the web pages. ", "And we want to calculate the stable distribution.  And then we'll simply define the page rank of a page  is its probability of being there ", "in the stationary distribution, the v  component of the stable-- stationary distribution, s.  And of course, we'll rank v above s  when the probability of being in v ", "is higher than the probability of being in w.  By the way, I don't have the latest figures, ", "but there were-- I guess I've heard people who've  worked for Google say, and in some of the Wikipedia articles,  that it takes a few weeks for the crawlers ", "to create a new map of the web, to create the new graph.  And then it takes some number of hours,  I think under days, to calculate the stationary distribution ", "on the graph, doing a lot of parallel computation.  So a useful feature about using the stationary distribution ", "is that ways to hack the links in the worldwide web  to make a page look important are-- will not work  very well against PageRank. ", "So for example, one way to look more important  is to create a lot of nodes pointing  to yourself, fake nodes.  But that's not going to matter, because the fake nodes are not  going to have much weight since they're fake ", "and nobody's pointing to them.  So even though a large number of fake nodes point to you,  their cumulative weight is low, and they're not adding a lot  to your own probability. ", "Likewise, you could try taking links to important pages  and try to make yourself look important that way,  but PageRank won't make you look important  at all if none of those important nodes ", "are pointing back.  So both of these simple-minded ways  to try to look important by manipulating links  won't improve your page rank. ", "The super-node is playing a technical role  in making sure that the stationary distribution exists.  So it guarantees that there's a unique stationary distribution, ", "s bar.  By the way, I sometimes use the word stable  and sometimes stationary.  They're kind of synonyms, although I  think officially we should stick to the word  stationary distribution. ", "As I've mentioned before, when a digraph is strongly connected,  that is a sufficient condition for there  to be a unique stable distribution. ", "That's actually proved in one of the exercises in the text  at the end of the chapter.  The super-node mechanism also ensures  something even stronger, that every initial distribution ", "p converges to the stationary distribution,  to that unique stationary distribution.  Stated precisely mathematically, if you start off ", "at an arbitrary distribution of probabilities  of being in different states, p, and you  look at what happens to p after t steps-- remember,  that you get by multiplying the vector p by the matrix M raised ", "to the power t-- and you take the limit as t approaches  infinity, that is to say, what distribution  do you approach as you do more and more updates. ", "And it turns out that that limit exists,  and it is that stationary distribution.  So it doesn't matter where you start,  you're going to wind up stable.  And as a matter of fact, the convergence is rapid.  What that means is that you can actually ", "calculate the stable distribution reasonably  quickly, because you don't need a very large t in order  to arrive at a very good approximation  to the stable distribution. ", "Now the actual Google rank and ranking  is more complicated than just PageRank.  PageRank was the original idea that got a lot of attention.  And in fact, the latest information from Google ", "is that they think it gets overattention today  in the modern world by too many commentators and people trying  to simulate ranking.  So the actual rank rules are a closely-held trade secret ", "for Google-- by Google.  They use text, they use location, they use payments,  because advertisers can pay to have their search  results listed more prominently, and lots of other criteria ", "that have evolved over 15 years.  And they continue to evolve.  As people find ways to manipulate the ranking,  Google revises its ranking criteria and algorithms. ", "But nevertheless, PageRank continues  to play a significant role in the whole story. "], "vid_duration": [13.65, 10.33, 10.04, 12.91, 11.39, 10.24, 11.95, 12.57, 12.36, 13.83, 11.79, 11.96, 11.38, 12.45, 11.8, 12.27, 14.3, 10.84, 11.769, 10.861, 10.06, 13.48, 11.43, 12.88, 10.26, 13.76, 13.09, 11.05, 11.34, 10.07, 11.47, 11.06, 10.93, 10.68, 11.04, 13.26, 10.35, 13.13, 13.04, 12.62, 11.36, 11.54, 11.86, 12.02, 10.09, 11.89, 10.54, 10.55, 11.48, 11.47, 10.78, 10.31, 11.32, 10.19, 10.163, 11.33, 10.159, 11.731, 10.31, 11.31, 11.07, 10.88, 10.92, 13.901, 11.049, 10.95, 11.81, 13.65, 11.63, 13.72, 10.819, 10.101, 12.33, 13.15, 13.39, 12.19, 10.23, 10.82, 13.4, 10.46, 11.34, 13.63, 11.19, 13.042, 12.718, 11.529, 10.141, 13.849, 10.041, 12.8, 14.87, 10.7, 13.81, 11.06, 10.585, 11.035, 10.73, 10.07, 14.23, 11.87, 11.92, 10.38, 10.46, 10.57, 10.95, 10.64, 10.94, 10.78, 11.01, 13.36, 10.54, 14.52, 12.71, 11.779, 10.621, 12.71, 12.76, 13.85, 11.57, 12.86, 10.03, 10.26, 10.77, 12.4, 13.79, 10.43, 12.39, 14.89, 10.06, 10.839, 10.891, 10.44, 10.32, 12.73, 11.74, 10.28, 11.079, 12.151, 10.599, 12.161, 10.71, 10.889, 13.921, 10.339, 13.091, 10.31, 11.859, 10.73, 11.831, 12.38, 10.64, 11.989, 12.351, 11.37, 13.209, 10.881, 13.04, 11.48, 10.629, 10.891, 13.69, 11.959, 14.331, 13.05, 11.039, 14.101, 12.53, 12.359, 10.401, 11.095, 10.004, 11.961, 13.529, 11.08, 11.22, 10.644, 10.306, 11.531, 11.1, 12.119, 10.37, 10.221, 13.44, 10.85, 15.049, 11.111, 11.4, 10.41, 10.81, 12.87, 11.66, 10.0, 4.307], "stet": [[0, 13.65], [13.65, 23.98], [23.98, 34.019999999999996], [34.019999999999996, 46.92999999999999], [46.92999999999999, 58.31999999999999], [58.31999999999999, 68.55999999999999], [68.55999999999999, 80.50999999999999], [80.50999999999999, 93.07999999999998], [93.07999999999998, 105.43999999999998], [105.43999999999998, 119.26999999999998], [119.26999999999998, 131.05999999999997], [131.05999999999997, 143.01999999999998], [143.01999999999998, 154.39999999999998], [154.39999999999998, 166.84999999999997], [166.84999999999997, 178.64999999999998], [178.64999999999998, 190.92], [190.92, 205.22], [205.22, 216.06], [216.06, 227.829], [227.829, 238.69], [238.69, 248.75], [248.75, 262.23], [262.23, 273.66], [273.66, 286.54], [286.54, 296.8], [296.8, 310.56], [310.56, 323.65], [323.65, 334.7], [334.7, 346.03999999999996], [346.03999999999996, 356.10999999999996], [356.10999999999996, 367.58], [367.58, 378.64], [378.64, 389.57], [389.57, 400.25], [400.25, 411.29], [411.29, 424.55], [424.55, 434.90000000000003], [434.90000000000003, 448.03000000000003], [448.03000000000003, 461.07000000000005], [461.07000000000005, 473.69000000000005], [473.69000000000005, 485.05000000000007], [485.05000000000007, 496.5900000000001], [496.5900000000001, 508.4500000000001], [508.4500000000001, 520.4700000000001], [520.4700000000001, 530.5600000000002], [530.5600000000002, 542.4500000000002], [542.4500000000002, 552.9900000000001], [552.9900000000001, 563.5400000000001], [563.5400000000001, 575.0200000000001], [575.0200000000001, 586.4900000000001], [586.4900000000001, 597.2700000000001], [597.2700000000001, 607.58], [607.58, 618.9000000000001], [618.9000000000001, 629.0900000000001], [629.0900000000001, 639.2530000000002], [639.2530000000002, 650.5830000000002], [650.5830000000002, 660.7420000000002], [660.7420000000002, 672.4730000000002], [672.4730000000002, 682.7830000000001], [682.7830000000001, 694.0930000000001], [694.0930000000001, 705.1630000000001], [705.1630000000001, 716.0430000000001], [716.0430000000001, 726.9630000000001], [726.9630000000001, 740.864], [740.864, 751.913], [751.913, 762.863], [762.863, 774.673], [774.673, 788.323], [788.323, 799.953], [799.953, 813.673], [813.673, 824.492], [824.492, 834.593], [834.593, 846.923], [846.923, 860.073], [860.073, 873.463], [873.463, 885.653], [885.653, 895.883], [895.883, 906.7030000000001], [906.7030000000001, 920.1030000000001], [920.1030000000001, 930.5630000000001], [930.5630000000001, 941.9030000000001], [941.9030000000001, 955.5330000000001], [955.5330000000001, 966.7230000000002], [966.7230000000002, 979.7650000000002], [979.7650000000002, 992.4830000000002], [992.4830000000002, 1004.0120000000002], [1004.0120000000002, 1014.1530000000001], [1014.1530000000001, 1028.0020000000002], [1028.0020000000002, 1038.0430000000001], [1038.0430000000001, 1050.843], [1050.843, 1065.713], [1065.713, 1076.413], [1076.413, 1090.223], [1090.223, 1101.283], [1101.283, 1111.868], [1111.868, 1122.903], [1122.903, 1133.633], [1133.633, 1143.703], [1143.703, 1157.933], [1157.933, 1169.8029999999999], [1169.8029999999999, 1181.723], [1181.723, 1192.103], [1192.103, 1202.563], [1202.563, 1213.133], [1213.133, 1224.083], [1224.083, 1234.7230000000002], [1234.7230000000002, 1245.6630000000002], [1245.6630000000002, 1256.4430000000002], [1256.4430000000002, 1267.4530000000002], [1267.4530000000002, 1280.813], [1280.813, 1291.353], [1291.353, 1305.873], [1305.873, 1318.583], [1318.583, 1330.362], [1330.362, 1340.9830000000002], [1340.9830000000002, 1353.6930000000002], [1353.6930000000002, 1366.4530000000002], [1366.4530000000002, 1380.303], [1380.303, 1391.873], [1391.873, 1404.733], [1404.733, 1414.763], [1414.763, 1425.023], [1425.023, 1435.793], [1435.793, 1448.193], [1448.193, 1461.983], [1461.983, 1472.413], [1472.413, 1484.803], [1484.803, 1499.6930000000002], [1499.6930000000002, 1509.7530000000002], [1509.7530000000002, 1520.592], [1520.592, 1531.4830000000002], [1531.4830000000002, 1541.9230000000002], [1541.9230000000002, 1552.2430000000002], [1552.2430000000002, 1564.9730000000002], [1564.9730000000002, 1576.7130000000002], [1576.7130000000002, 1586.9930000000002], [1586.9930000000002, 1598.0720000000001], [1598.0720000000001, 1610.2230000000002], [1610.2230000000002, 1620.8220000000001], [1620.8220000000001, 1632.9830000000002], [1632.9830000000002, 1643.6930000000002], [1643.6930000000002, 1654.582], [1654.582, 1668.5030000000002], [1668.5030000000002, 1678.842], [1678.842, 1691.933], [1691.933, 1702.243], [1702.243, 1714.1019999999999], [1714.1019999999999, 1724.8319999999999], [1724.8319999999999, 1736.6629999999998], [1736.6629999999998, 1749.043], [1749.043, 1759.683], [1759.683, 1771.672], [1771.672, 1784.0230000000001], [1784.0230000000001, 1795.393], [1795.393, 1808.602], [1808.602, 1819.4830000000002], [1819.4830000000002, 1832.5230000000001], [1832.5230000000001, 1844.0030000000002], [1844.0030000000002, 1854.632], [1854.632, 1865.5230000000001], [1865.5230000000001, 1879.2130000000002], [1879.2130000000002, 1891.1720000000003], [1891.1720000000003, 1905.5030000000002], [1905.5030000000002, 1918.553], [1918.553, 1929.592], [1929.592, 1943.6930000000002], [1943.6930000000002, 1956.2230000000002], [1956.2230000000002, 1968.582], [1968.582, 1978.9830000000002], [1978.9830000000002, 1990.0780000000002], [1990.0780000000002, 2000.082], [2000.082, 2012.0430000000001], [2012.0430000000001, 2025.5720000000001], [2025.5720000000001, 2036.652], [2036.652, 2047.872], [2047.872, 2058.516], [2058.516, 2068.822], [2068.822, 2080.353], [2080.353, 2091.453], [2091.453, 2103.572], [2103.572, 2113.942], [2113.942, 2124.163], [2124.163, 2137.603], [2137.603, 2148.453], [2148.453, 2163.502], [2163.502, 2174.613], [2174.613, 2186.013], [2186.013, 2196.423], [2196.423, 2207.2329999999997], [2207.2329999999997, 2220.1029999999996], [2220.1029999999996, 2231.7629999999995], [2231.7629999999995, 2241.7629999999995], [2241.7629999999995, 2246.0699999999993]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [632, 1590, 2246]}
{"example_id": "mit097@@MIT6_042JS15_13_ipod", "text": [" PROFESSOR: The idea of congruence  was introduced to the world by Gauss  in the early 18th century.  You've heard of him before, I think. ", "He's responsible for some work on magnetism also.  And it turns out that this idea, after several centuries,  remains an active field of application and research. ", "And in particular, in computer science  it's used significantly in crypto,  which is what we're going to be leading up to now in this unit. ", "It's plays a role in hashing, which  is a key method for managing data in memory.  But we are not going to go into that application. ", "Anyway, the definition of congruence is real simple.  Congruence is a relation between two numbers, a and b.  It's determined by another parameter  n, where n is considered to be greater than one. ", "All of these, as usual, are integers.  And the definition is simply that a  is congruent to b mod n if n divides a minus b or a minus  b is a multiple of n. ", "So that's a key definition to remember.  There's other ways to define it.  We'll see very shortly an equivalent formulation  that could equally well have been used as a definition.  But this is a standard one. ", "A is equivalent to b means that a minus b is a multiple of n.  Well let's just practice.  30 is equivalent to 12 mod 9 because 30 minus 12 is 18, ", "and 9 divides 18.  OK.  An immediate application is that does  this number with a lot of 6's is ending in a 3  is equivalent to 788253 modulo 10. ", "Now why is that?  Well, there's a very simple reason.  If you think about subtracting the 6 number ending  in 3 from the 7 number ending in 3, what you can immediately  see without doing much of any of the subtraction-- ", "just do the low order digits-- when you subtract these,  you're going to get a number that ends in 0.  Which means that it's divisible by 10.  And therefore those two numbers are congruent. ", "It's very easy to tell when two numbers are congruent  mod 10 because they just have the same lower digit.  OK.  Another way to understand congruency and what it's really ", "all about is the so-called remainder lemma,  which sets that a is congruent to b mod n, if  and only if a and b have the same remainder on division  by n. ", "So let's work with that definition.  We can conclude using this formulation, equivalent  formulation, that 30 is equivalent to 12  mod 9 because the remainder of 30 divided by 9, ", "well it's 3 times 9 is 27, remainder 3.  And the remainder of 12 by 9 is 3.  So they do indeed have the same remainder 3.  And they're congruent. ", "By the way, this equivalent sign with the three horizontal bars  is read as both equivalent and congruent.  And I will be bouncing back between the two pronunciations ", "indiscriminately.  They are synonyms.  OK, let's think about proving this remainder lemma just  for practice.  And in order to fit on the slide,  I'm going to have to abbreviate this idea of the remainder of b ", "divided by n with a shorter notation r sub b n.  Just to fit.  OK.  So the if direction of proving the remainder  limit that they're congruent if and only if they ", "have the same remainder.  The if direction here in an if and only if  is from right to left.  I've got to prove that if they have the same remainder, then ", "they're congruent.  So there are the two numbers, a and b.  By the division theorem, or division algorithm,  they can each be expressed as a quotient of a divided by n ", "times the quotient sub a plus the remainder of a divided  by n.  And likewise, b can be expressed in terms  of quotient and remainder.  And what we're given here is that the remainders are equal. ", "But if the remainders are equal, then clearly  when I subtract a minus b, I get qa minus qb times n.  Sure enough, a minus b is a multiple of n.  And that takes care of that one. ", "The only if direction now goes from left to right.  So in the converse, I'm going to assume  that n divides a minus b, where a and b are expressed  in this form by the division algorithm or division theorem. ", "So if n divides a minus b, looking at a minus b  in that form what we're seeing is that n divides  this qa minus qb times n, plus the difference ", "of the remainders.  That's what I get just by subtracting a and b.  But if you look at this n divides that term,  the quotient times n. ", "And it therefore has to divide the other term as well.  Because the only way that n can divide  a sum, when it divides one of the sum ands,  is if it divides the other sum and. ", "So n divides ra minus the remainder of 8 divided by n  from b divided by n.  But remember, these are remainders.  So that means that they're both in the interval from 0 ", "to n minus 1 inclusive.  And the distance between them has got to be less than 1.  So if n divides a number that's between 0 and n minus 1, ", "that number has to be 0.  Because it's the only number that n divides in there.  So in fact, the difference of the remainders is 0.  And therefore, the remainders are equal.  And we've knocked that one off. ", "So there it is restated.  The remainder lemma says that they're congruent if  and only if they have the same remainders.  And that's worth putting a box around ", "to highlight this crucial fact, which  could equally well have used as the definition of congruence.  And then you'd prove the division definition  that we began with.  Now some immediate consequences of this remainder lemma ", "are that a congruence inherits a lot of properties of equality.  Because it means nothing more than that  the remainders are equal.  So for example, we can say the congruence is symmetric, ", "meaning that if a is congruent to b, then b is congruent to a.  And that's obvious cause a congruent to b  means that a and b have the same remainder.  So b and a have the same remainder. ", "One that would actually take a little bit of work  to prove from the division definition--  not a lot, but a little bit-- would  be that if a is congruent to b, and b is congruent to c, then a  is congruent to c. ", "But we can read it is saying the first says that a and b have  the same remainder.  The second says that b and c have the same remainder.  So obviously a and c have the same remainder.  And we've prove this property that's known ", "as transitivity of congruence.   Another simple consequence of the remainder theorem  is a little technical result that's  enormously useful called remainder lemma, which ", "says simply that a number is congruent to its own remainder,  modulo n.  The proof is easy.  Let's prove it by showing that a and the remainder of a ", "have the same remainder.  Well, what if I take remainders of both sides,  the left hand side becomes the remainder of a divided by n.  The right hand side is the remainder of the remainder. ", "But the point is that the remainder  is in the interval from 0 to n.  And that means when you take its remainder mod and its itself.  And therefore the left hand side is the remainder ", "of a divided by n, and the right hand side  is also the remainder of the a divided by n.  And we have proved this corollary  that's the basis of remainder arithmetic. ", "Which will basically allow us whenever  we feel like it to replace numbers by their remainders,  and that way keep the numbers small.   And that also merits a highlight. ", "OK.  Now, in addition to these properties like equality  that congruence has, it also interacts very well  the operations.  Which is why it's called a congruence. ", "A congruence is an equality-like relation  that respects the operations that  are relevant to the discussion.  In this case, we're going to be talking about plus and times.  And the first fact about congruent ", "says that if a and b are congruent,  then a plus c and b plus c are congruent.  The proof of that follows trivially from the definition.  Because the a congruent to b mod, ", "n says that n divides a minus b.  And if n divides a minus b, obviously n divides a plus  c minus b plus c.  Because a plus c minus b plus c is equal to a minus b. ", "That one is deceptively trivial.   It's also the case that if a is congruent to b, then a times  c is congruent to b times c. ", "This one takes a one line proof.  We're given that n divides a minus b.  That certainly implies that n divides  any multiple of a minus b. ", "So multiply it by c and then apply distributivity,  and you discover that n divides ac  minus bc, which means ac is congruent to bc modulo n. ", "It's a small step that I'm going to omit  to go from adding the same constant  to both sides to adding any two congruent  numbers to the same sides.  So if a is congruent to b and c is congruent to d, then ", "in fact, a plus c is congruent to b plus d.  So again, congruence is acting a lot like ordinary equality.  If you add equals to equals, you get equals. ", "And of course the same fact applies to multiplication.  If you multiply equals by equals, you get equals.  A corollary of this is that if I have two numbers that ", "are congruent modulo n, then if I have any kind of arithmetic  formula involving plus and times and minus--  and what I want to know is what it's equivalent to modulo n-- ", "I can figure that out freely substituting  a by a prime or a prime by a.  I can replace any number by a number that it's congruent to,  and the final congruence result of the formula ", "is going to remain unchanged.  So overall what this shows is that arithmetic modulo n is  a lot like ordinary arithmetic. ", "And the other crucial point thought  that follows from this fact about remainders  is that because a is congruent to the remainder of a divided ", "by n, then when I'm doing arithmetic on congruences,  I can always keep the numbers involved in the remainder  interval.  That is, in the remainder range from 0 to n minus 1. ", "And we use this standard closed open interval notation to mean  the interval from 0 to n.  So it's sometimes used in analysis ", "to mean the real interval of reals.  But we're always talking about integers.  So this means-- the integers that square bracket  means 0 is included.  And a round parenthesis means that n is excluded. ", "So that's exactly a description of the integers that  are greater and equal to 0 and less than n.  Let's do an application of this remainder arithmetic idea. ", "Suppose I want to figure out what's 287 to the ninth power  modulo 4?  Well, for a start but if I take the remainder of 287 ", "divided by 4, it's not very hard to check that that's 3.  And that means that 287 to the ninth is congruent mod 4 to 3 ", "to the ninth.  So already I got rid of the three digit number,  the base of the exponent, and replaced it  just by a one digit number, 3.  That's progress.  Well, we can make more progress because 3 to the ninth ", "can be expressed as 3 squared, squared, squared times 3,  right?  Because when you iterate taking powers,  it means that the exponents multiply.  So this is 3 to the 2 times 2 times 2, or 8, times 3-- ", "which adds 1 to the exponent-- or 9.  So that's simple exponent arithmetic.  But notice that 3 squared is 9. ", "And 9 is congruent to 1 mod 4.  So that means I can replace 3 squared by 1,  and the outer 2 squared stays. ", "It becomes 1 squared squared, but that's 1 times 3.  And the punchline is that 287 to the ninth is congruent to 3 mod  4 by a really easy calculation that did not involve taking ", " PROFESSOR: So, now we come to the place where arithmetic,  modulo n or remainder arithmetic,  starts to be a little bit different and that involves  taking inverses and cancelling. ", "Let's look at that.  So first of all, we've already observed  that we have these basic congruence rules  that if a and b are congruent then c and d are congregant,  then a plus c and b plus d are congruent, ", "a times c and b times d are congruent.  So, that's the sense in which arithmetic mod n is  a lot like ordinary arithmetic.  But here's the main difference. ", "Let's look at this one.  8 times 2 is 16, which means it's  congruent to 6 mod 10, which is the same as 3 times 2.  So, 8 times 2 is congruent to 3 times 2. ", "And you'd be tempted, maybe, to cancel the twos.  And what happens then, well then you could discover that you  think that 8 is congruent to 3 mod 10, which it ain't. ", "So in short, you can't cancel arbitrarily.  You can't cancel two, in this case in particular.  So, that leads, naturally, to the question of when can you  cancel a number? ", "When can you cancel a number k when both sides of inequality  are multiplied by k and I'd like to cancel k?  And the answer is simple, when k has no common factors  with a modulus n. ", "So, the proof of that is based on the following idea.  Let's say that a number k prime is an inverse of k mod n.  If k prime times k is congruent to 1 mod n. ", "So, k prime is like 1 over k with respect to mod n.  But of course, 1 over k is going to be a fraction unless k is 1.  And so, k prime is going to be an integer that ", "simply acts like 1 over k.  So, how are we going to prove this?  And it's going to turn out to be an easy consequence of the fact  that the gcd is a linear combination. ", "So, how am I going to prove-- find this k  prime that's an inverse of k?  Well remember, given the gcd of k and n is 1,  I have a linear combination of k and n is 1.  So, s times k plus t times n is 1. ", "But if you stare at that for a moment, what that means  is that k prime is simply the coefficient s of k.  So, all you have to do is apply the pulverizer to k and n ", "to get the coefficient s of k in the linear combination of k  and n is equal to 1.  Let's look at that slightly more carefully  and see what's going on. ", "I have that sk plus tn is 1.  So, that means in particular, since they're equal,  they're certainly congruent to each other, modulo n.  sk plus tn is congruent to 1 mod n. ", "But, n is congruent to 0 mod n.  So, this becomes t times 0, and we're left with sk congruent  1 mod n, which is exactly the definition of s ", "being an inverse of k.   Now, I can also cancel k if it's relatively prime to n. ", "And the reason is that if I have ak equivalent to bk mod n  and the gcd of k and n is 1, then  I have this k prime that's an inverse of k. ", "So, I just multiply both sides by the inverse  of k, namely k prime.  And I get that the left hand side is a times k, k inverse. ", "And the right hand side is b times k, k inverse.  And of course, that's a times 1 is equivalent to b times 1.  And so, a is congruent to b mod n.  So I can cancel, in that case, trivially. ", "And in fact, you can work out the converse implications.  The punch line of this-- well first of all, this  is the cancellation rule.  You can cancel providing that the gcd of k and n ", "is 1 if k is relatively prime to n.  So, this is the summary.  [? k is ?] cancelable mod n if and only  if k has an inverse mod n, if and only if the gcd of k and n ", "is 1, which I can restate as k is relatively prime to n.  And that's the story. "], "vid_duration": [10.07, 11.14, 11.47, 12.23, 12.16, 12.83, 10.93, 14.49, 14.09, 11.96, 13.94, 11.46, 11.1, 12.77, 11.42, 11.687, 13.333, 10.21, 10.761, 10.959, 12.61, 11.92, 15.03, 11.02, 11.52, 11.25, 11.84, 12.56, 12.92, 11.22, 14.02, 11.73, 10.94, 11.23, 11.19, 12.57, 12.46, 10.83, 11.96, 10.92, 12.48, 11.34, 12.359, 11.461, 10.48, 11.61, 11.43, 13.07, 11.22, 11.36, 13.1, 10.47, 13.53, 10.42, 11.26, 13.25, 11.24, 10.88, 13.24, 13.48, 10.419, 10.811, 13.62, 12.03, 10.2, 16.323, 12.308, 10.262, 10.832, 10.757, 11.76, 11.051, 11.87, 13.49, 12.75, 13.29, 14.01, 13.0, 10.63, 11.08, 11.949, 11.511, 11.09, 10.58, 14.199, 10.53, 11.181, 6.307], "stet": [[0, 10.07], [10.07, 21.21], [21.21, 32.68], [32.68, 44.91], [44.91, 57.06999999999999], [57.06999999999999, 69.89999999999999], [69.89999999999999, 80.82999999999998], [80.82999999999998, 95.31999999999998], [95.31999999999998, 109.40999999999998], [109.40999999999998, 121.36999999999998], [121.36999999999998, 135.30999999999997], [135.30999999999997, 146.76999999999998], [146.76999999999998, 157.86999999999998], [157.86999999999998, 170.64], [170.64, 182.05999999999997], [182.05999999999997, 193.74699999999999], [193.74699999999999, 207.07999999999998], [207.07999999999998, 217.29], [217.29, 228.051], [228.051, 239.01], [239.01, 251.62], [251.62, 263.54], [263.54, 278.57], [278.57, 289.59], [289.59, 301.10999999999996], [301.10999999999996, 312.35999999999996], [312.35999999999996, 324.19999999999993], [324.19999999999993, 336.75999999999993], [336.75999999999993, 349.67999999999995], [349.67999999999995, 360.9], [360.9, 374.91999999999996], [374.91999999999996, 386.65], [386.65, 397.59], [397.59, 408.82], [408.82, 420.01], [420.01, 432.58], [432.58, 445.03999999999996], [445.03999999999996, 455.86999999999995], [455.86999999999995, 467.8299999999999], [467.8299999999999, 478.74999999999994], [478.74999999999994, 491.22999999999996], [491.22999999999996, 502.56999999999994], [502.56999999999994, 514.929], [514.929, 526.39], [526.39, 536.87], [536.87, 548.48], [548.48, 559.91], [559.91, 572.98], [572.98, 584.2], [584.2, 595.5600000000001], [595.5600000000001, 608.6600000000001], [608.6600000000001, 619.1300000000001], [619.1300000000001, 632.6600000000001], [632.6600000000001, 643.08], [643.08, 654.34], [654.34, 667.59], [667.59, 678.83], [678.83, 689.71], [689.71, 702.95], [702.95, 716.4300000000001], [716.4300000000001, 726.849], [726.849, 737.6600000000001], [737.6600000000001, 751.2800000000001], [751.2800000000001, 763.3100000000001], [763.3100000000001, 773.5100000000001], [773.5100000000001, 789.8330000000001], [789.8330000000001, 802.1410000000001], [802.1410000000001, 812.403], [812.403, 823.235], [823.235, 833.992], [833.992, 845.752], [845.752, 856.803], [856.803, 868.673], [868.673, 882.163], [882.163, 894.913], [894.913, 908.203], [908.203, 922.213], [922.213, 935.213], [935.213, 945.843], [945.843, 956.923], [956.923, 968.872], [968.872, 980.3829999999999], [980.3829999999999, 991.473], [991.473, 1002.053], [1002.053, 1016.252], [1016.252, 1026.782], [1026.782, 1037.963], [1037.963, 1044.27]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [790, 1044]}
{"example_id": "mit097@@MIT6_042JS15_15_ipod", "text": [" The RSA crypto systems is one of the lovely and really important  applications of number theory in computer science.  So let's start talking about it. ", "The RSA crypto system is what is known  as a public key cryptosystem, which has the following really  amazing properties-- namely, anyone ", "can send a secret encrypted message  to a designated receiver.  This is without there being any prior contact using only  publicly available information. ", "Now, if you think about that, it's  really terrific because it means that you  can send a secret message to Amazon that nobody but Amazon  can read even though the entire world knows ", "what you know and can see what you sent to Amazon.  And Amazon knows that it's the only one can  decrypt the message you sent.  This in fact is hard to believe if you think about it. ", "It sounds paradoxical.  How can secrecy be possible using only public info?  And in fact, the existence of this public key cryptosystem  has some genuinely paradoxical consequence, which kind of ", "are a mind bender.  So let me tell you about one of them.  I don't know if you've heard of mental chess,  but it's a standard thing in the chess world.  Chess masters are so talented and have such deep insight ", "into the game that they don't need a chessboard,  and they don't need chess pieces.  They can just go for walk on a country  lane talking to each other and saying  pond to king 4 and knight to bishop 3 ", "and just talking chess code and play an entire chess  game that way.  That's known as mental chess.  It's quite impressive.  In fact, the grand masters can play multiple games ", "of mental chess against opponents  who are staring at the chessboard  and win the great majority of the games.  Of course, these are not against other grand masters, but still.  OK.  So now, this is what I propose. ", "How about playing mental poker?  If you know how to play poker, we deal our cards  and we bet and so on.  And my only condition is that I'll deal.  Now, that sounds like a joke and an absurd thing ", "for you to agree to do, but it's amazing.  It's actually possible.  One of the famous papers of Rivest and Shamir  was how to play mental poker using public key crypto. ", "So I once tried to persuade an eminent MIT dean who's  a physicist researcher about this,  and he just wouldn't believe it. ", "He argued that it was just impossible logically.  And what he was thinking about was  that if you know how to compute a function, then of course ", "you can figure out how to invert it.  That is to say if I know how to compute some function f  of a number and let's say that the function is ", "one arrow in-- that is an injection-- then  if I know what f of n, there's a unique n that it came from.  So how can I not be able to find n?  And it's an insight of computer science and complexity theory ", "that says it's quite possible.  It's not that you can't find the n that produced f of n.  It's that the search for it will be prohibitive.  There are, in short, one-way. ", "That is, functions that are easy to compute in one direction  but hard to invert.  They're easy to compute but hard to invert.  In particular, we're thinking about multiplying ", "and factoring.   It's an observation that it's easy to compute the product  of two large prime numbers.  We all know how to multiply.  And in fact, there are faster ways to multiply than you know. ", "But the current state of our knowledge  of number theory and complexity theory  is that given a number n that happens  to be the product of two primes, it ", "seems to be hopelessly hard in general to factor  n into the components p and q.  Now, this is an open problem.  It's similar to the p equals np question-- ", "that famous open problem.  It's actually a weaker-- it's quite possible  that you could factor, and np would not equal to np. ", "But nevertheless, it's the same kind of problem.  And more generally, the existence  of one way functions is closely related to that p  equals np question.  Nevertheless, even though it's an open problem ", "and theoretically has not been settled either way,  it's widely believed-- the banks, the governments,  and the commercial world have really bet the family jewels ", "on the difficulty of factoring when they use the RSA protocol.  So I like to make the joke that my most important contribution ", "to MIT was being involved in the hiring of our S and A.  So this is A, Adi Shamir, R, Ron Rivest, and A, Len Adleman ", "back in the late '70s when they first came up with these ideas.  So let's look at the way this RSA protocol actually works. ", "So here's what happens.  To begin with, you have to make some information public  so that people can communicate with you.  We're looking at two players here. ", "There's a receiver who's going to get encrypted messages,  and there's a sender who is trying  to send an encrypted message to the receiver.  So what the receiver does before hand is ", "generates two primes, p and q.  Now, in practice, you want these to be pretty big primes--  hundreds of digits.  And we'll examine it in a moment, the question  of how you find them. ", "But the receiver's job is to find two quite substantial  large primes, p and q, chosen more or less  randomly because if you have any kind of predictable procedure ", "for how you got them, that would be a vulnerability.  But if you just choose them at random,  then there's enough primes in the hundreds of digits  that it's hopeless that people would guess ", "which one you wound up with.  OK.  What do you do to begin with is multiply p and q together,  which is easy to do.  Let's call that number n.  And now the other thing the receiver is going to do ", "is find a number e that's relatively  prime to this peculiar number p minus 1, q minus 1.  Now as a hint, you might notice that p minus 1, q minus 1 ", "is in fact Euler's function of n-- phi of n.  But for now, we don't need to understand  that this is Euler's function.  It's just the recipe of what the receiver has to do. ", "Find a number e that's relatively prime to p minus 1,  q minus 1.  Again, you don't want e to be too small,  and we'll discuss in a moment how do you find such an e.  But the receiver's job is to find such an e. ", "This pair of numbers e and n will  be the public key which the receiver publishes widely  where it can easily be found by anyone ", "who cares to look for it.  Basically there's a phone directory  where if you want to know how to send somebody a secret message,  you look them up, and you find the receivers name in there.  And then you see his public e and n, ", "and that's what you use to send him a message.   Now, how do you use it to send him a message?  Well, I'll explain that in a minute,  but let's look at one more thing that the receiver needs ", "to do to set himself up.  The receiver is going to find an inverse of this number e that  he's published-- the part of his public -- modulo p minus 1, ", "q minus 1.  That is, this e since it's relatively prime to p minus 1,  q minus 1, it will have an inverse in Z star p  minus 1, q minus 1. ", "Let's let that inverse be d.  And of course, we know how to find d because you  can do that with a Pulverizer.  D is the private key.  That's this crucial piece of information ", "that the receiver has and that the receiver is not  going to tell anybody.  Only the receiver knows that because the receiver  chose the p and the q and the e more or less randomly-- ", "maybe even as randomly as they can manage--  and then they find the d.  And that's their secret.  OK.  That's what the receiver does.  How does the sender send a message? ", "Well, to send a message, what the sender wants to do  is choose a message that is in fact a number in the range  from 1 to n where-- we're thinking again, of n, ", "if it's a product of two primes of a couple of hundred  digits each, then the product is around 400 digits.  And so you can pick any message m ", "that can be represented by a 400 digit number.  Now, there's a lot of messages that  will fit within 400 digits.  And of course, if it's bigger, you just  break it up into 400 digit pieces. ", "So that's the kind of message you're going to send.  So the message is going to be a number  in this range from 1 to n.  And what the sender is going to do is look up the public key e ", "and the other part of the public key  n and raise the secret message to the power e in Z n.  So we're going to compute m to the e in Zn ", "and send that encoded message m hat.  So m hat is what we think of as the encrypted version  of the message m. ", "So then we have the problem if that's  what the sender sends to the receiver,  how does the receiver decode the m hat,  and the answer is the receiver just computes ", "m hat to the power d-- the secret key-- also  in the ring Zn.  And the claim is that in fact, that's equal to m.  Now, you can check in class problem, ", "and it's easy to see that the reason why  that method of decrypting works is precisely  an application of Euler's theorem-- at least  when m happens to be relatively prime to n. ", "Now, the odds of finding an m that's  not relatively prime to n are basically  negligible because if you'd find such an m,  it would enable you to factor them. ", "And we believe factoring is very hard.  But in fact, it actually works for all m, which  is a nice theoretical results.  And you'll work this out in class problem. ", "OK.  That's how it works.  The receiver publishers e and n, keeps a secret key d. ", "The sender exponentiates the message to the power e.  The receiver simply decodes by raising  the received message to the power  d and reads off what the original was. ", "OK.  So we need to think about the feasibility of all of this  because we believe that it's impossible to decrypt,  but there's a lot of other stuff going on there that the players ", "have to be able perform.  And let's examine what their responsibilities and abilities  have to be.  So the receiver to begin with has  to be able to find large primes.  And how on earth do they do that? ", "Well, without going into too much detail,  we can make the remark that there are lots of primes.  That is to say by appealing to the prime number theorem, ", "we know that among the n digit numbers, about log n of them  are going to be primes so that you ", "don't have to go too long before you  stumble upon a random prime.  That is, if you're dealing with a 200 digit n ", "and you're searching for a prime of around that size,  you're not going to have to search  more than a few hundred numbers before you're  likely to stumble on a prime. ", "And of course, how do you know that you stumbled on a prime?  Well, you need to be able to check whether a number is prime  or not-- and efficientlY-- in order for this whole thing  to be feasible.  So we'll have to discuss that brieflY-- ", "how do you test whether or not a number is  prime in an efficient way?  The other thing the receiver has to do  is find an e that's relatively prime to p minus 1, q minus 1. ", "But that's easy.  Well, it's easy because first of all,  if you just kind of randomly guess a medium sized e  and then search consecutively from some random number you've ", "chosen somewhere in the middle of the interval  up to p minus 1, q minus 1.  Again, you're very likely to find in a few steps a number ", "e that is relatively prime to p minus 1, q minus 1.  How do you recognize that it's relatively prime?  Well, you just compute the GCD, which  we know how to do using Euclid's algorithm. ", "So that's really quite efficient.  Recognizing that it's relatively prime is easy,  you just don't have to search very many numbers  until you stumble on an e.  OK.  The other thing you have to do is find the d that an e inverse ", "modulo p minus 1, q minus 1.  And again, that is the extended Euclidean algorithm,  the extended GCD, namely the Pulverizer. ", "So those are the pieces that the receiver has to do.  Now, let's look at this a little bit more  and think about the information about the prime.  So the famous theorem about the primes  is their density, which is if you let a pi of n ", "be the number of primes less than or equal to n,  then it's a deep theorem of number theory  that pi event actually approaches ", "a limit in an asymptotic sense-- which we'll discuss in more  detail-- that pi of n as n grows gets to be  very close to n over log n.  That's the natural log of n. ", " Now, that's a deep theorem.  But in fact, if we want a self-contained treatment  for our purposes, there's an exercise  that will be in the text where we ", "can derive Chebyshev's bound, which is weaker than they tight  prime number theorem.  But Chebyshev's bound, which can be  proved by more elementary means that's within our own ability ", "at this point with the number theory we have--  to be able to show that n over 4 log n  is a lower bound on pi of n.  So basically that says that if you're ", "dealing with numbers of size n, which  means they're of length log n a few hundred digits,  then you only have to search maybe 1,000 ", "digits before your very likely to stumble on a prime.  And if you search 2,000 digits, it becomes extremely likely  that you'll stumble on a prime.  So the primes are dense enough that we ", "can afford to look for them, providing  we can have a reasonably fast way to recognize  when a number is prime.  Well, one simple way that it almost  is perfect-- but works pragmatically ", "pretty well-- is called the Fermat test.  But let me just reemphasize this -- I got ahead of myself--  that if I'm dealing with 200 digit numbers,  then about one in 1,000 is prime using just the weaker ", "Chebyshev's bound.  And that says that I don't have to search  too long-- only a few thousand numbers  to be able to find a prime.  And a few thousand numbers is well  within the ability of a computer to carry out, ", "providing that the test for recognizing that a number is  prime isn't too time consuming.  So one naive way that the really almost  works to be a reliable primality test ", "is to check whether Fermat's theorem is obeyed.  Fermat's theorem-- the special case of Euler's theorem--  says that if n is prime, then if I  compute a number a to the n minus 1, ", "it's going to equal 1 in Z n.  And that's going to be the case for all a  that are not 0 if n is prime.  Now that means that if this equality fails in Z n, ", "then I immediately know a is not prime.  Go on.  Search for another one.  OK.  So suppose I'm unlucky-- or lucky--  and I choose an a to test and it turns out ", "that a to the n minus 1 is 1, does that mean that n is prime?  Unfortunately not.  It might be that I just hit an n that  happened to satisfy Fermat's equation even though n was not ", "prime.  But it's not a very hard thing to prove  that if n is not prime, then half of the numbers from 1 to n ", "are not going to pass the Fermat test.  So if half of the numbers are not  going to pass the Fermat test, then what I can do  is just choose a random nonzero number in the interval ", "from 1 to n, raise it to the n minus first power,  and see what happens.  And if n is not prime, the probability  that this random numbers that I've chosen fails this test ", "is at least a half.  So I try it 50 times.  And if in fact 50 randomly chosen a's in the interval 1  to n all satisfy Fermat's theorem, ", "then there's one chance in 2 to the 50th that n is not prime. ", "That's a great bet.  Leap for it.  So that basically is the idea of a probabilistic primarily test.  Now, there's a small complication  which is that there are certain numbers n where ", "this property that half the numbers will fail to satisfy  Fermat's theorem doesn't hold.  They're known as the Carmichael numbers,  and they're known to be pretty sparse. ", "So that really if you're choosing an n  at random, which is kind of what we're doing when we choose  random primes p and q, the likelihood  that you'll stumble on a Carmichael number  is another thing that you just don't have to worry about. ", "So really, the Fermat primality test  is a plausible pragmatic test that you  could use to pretty reliably detect whether or not  a number was prime-- what was the last component ", "of the powers that we needed the receiver to have.  OK.  So now we come to the question of why  do we believe that the RSA protocol is secure? ", "And the first thing to notice is that if you could factor n,  then it's easy to break.  Because if you can factor n, then you have the p and the q. ", "And that means you know what p minus 1 times q minus 1 is.  And therefore you can use the Pulverizer  in exactly the same way the receiver did  to find the inverse of the public key e. ", "You could find d easily.  So surely if you can factor, then RSA breaks.  No question about that.  What about the converse?  Well, what you can approve-- and there's an argument that's ", "sketched in class problem, not fully, in the book--  is that if I could find the private key d, then in fact,  I can also factor n. ", "So if I believe that factoring is hard,  then in fact finding the secret key is also hard.  And we could try to be confident that our secret key is not  going to be found even given the public. ", "Now, unfortunately this is not the strongest kind  of security guaranteed you'd like because there's  a logical possibility that you might ", "be able to decrypt messages without knowing the secret key.  Maybe there's some other walk around whereby  you can decrypt the secret message m hat by a method other  than raising it to the dth power. ", "And what you'd really like is a theorem of security  that said that breaking RSA-- reading  RSA messages by any means whatsoever-- ", "would be as hard as factoring.  That's not known for RSA.  It's an open problem.  And so RSA doesn't have the theoretically most desirable  security assurance, but we really believe in it. ", "And the reason we really believe in it  is that for 100 or more years, mathematicians and number  theorists have been trying to find efficient ways to factor.  And more pragmatically, the most sophisticated cryptographers ", "and decoders in the world using the most powerful networks  of supercomputers have been attacking RSA for 35 years  and have yet to crack it. ", "Now, the truth is that in the course of the 35 years,  various kinds of glitches were found  that required some added rules about how you found ", "the p and the q and how you found the e,  but they were easily identified and fixed.  And RSA really is a robust public key encryption ", "method that has withstood attack for all these years.  That's why we believe in it.  ", " PROFESSOR: We've mentioned the P equals NP question  a number of times now as the most important question  in theoretical computer science, and we've  said that one way to formulate it is exactly ", "to ask whether there's an efficient that  is polynomial-time procedure to test whether or not  a formula in propositional logic is satisfiable. ", "Now, why is that such an important problem?   We're not just logicians and we want to know whether or not  some formula is satisfiable.  How did it take on this enormous importance ", "and apply to so many fields?  And illustrating how you could use a satisfiability tester  to factor efficiently is a good hint  about why it is that all sorts of things reduce to SAT ", "and why it, in fact, is such a centrally important problem.  So let's suppose that we have a satisfiability tester  and use it to find how to factor a number n. ", "Now, the observation begins with how  you use a SAT solver is that you can begin  by writing or observing that it's easy enough  to design a digital circuit that multiplies, ", "that does arithmetic multiplications.  In other words, it's got some number  of bits reserved for an input x, a k bits,  and another k bits for an input y,  and it's got 2k output lines that produce ", "the digits of x times y.  You might need one extra digit, but never mind that.  So this is a multiplier circuit takes an x, a k bit x in  and a k bit y in and it spits out the product, which ", "is another 2k bit number, and this is not  a terribly big circuit.  The naive way to design it would use a number of gates  and a number of wires that was about quadratic in the number ", "k.  It's easy enough to design one of these things  where the size is literally bounded by 5 times k squared,  maybe plus a constant.  And so this definitely a small polynomial. ", "Given the number of bits that I'm working with,  it's easy enough to build this multiplier circuit.  Now, suppose that I have a way to test satisfiability ", "of circuits.  How am I going use this multiplier circuit to factor?  Well, the first thing I'm going to do  is let's suppose the number that I'm factoring is n  and is the product of two primes, p and q. ", "Those are the kinds of n's that we've been using in RSA,  and let me also observe that it's very easy to design  an n tester-- that is, a little digital circuit that ", "has 2k input lines and produces on its one output line  precisely when the input is the binary representation of n. ", "So let's attach this equality tester that does nothing  but ask whether it's being fed the digits of n as input  and it produces an output, 1 for n and 0 ", "if the input pattern is and the digital representation,  the binary representation of anything other than n.  That's another trivial circuit to build.  So we put those two together, and now watch what happens. ", "I'm going to take the circuit and set the first of the input  bits to 0, and then I'm going to ask the SAT  solver the following question-- is there ", "a way to set the remaining input bits other than 0?  So I've set the first one to 0.  What about these other bits?  The SAT solver can tell me whether or not ", "it's possible to get a 1 out of this circuit  with the 0 there fixed.  So let's ask the SAT solver what happens,  and the SAT solver says, hey, yes, there ", "is a way to fill in the remaining digits  and get an output 1.  Well, what does that tell me?  Well, it tells me that there is a factor that starts with 0, ", "so let's fix the 0 based on the fact that it's possible for me  to fill in the remaining digits with the bits of factors x ", "and y that equal n.  Let's try to set the second input bit to 0  and see what happens.  Well, we'll ask the SAT tester, is it possible ", "now to fill in the remaining digits  to get the two numbers x and y that multiply and produce  n and therefore output 1?  And the SAT tester says, no, this ", "is an unsatisfiable circuit.  You can't get a 1 out of it any more.  That tells me that I have to set the second bit to 1 in order  to have a factor of n where the x and y will multiply together ", "to be n.  All right, fine.  Go to the third bit, ask whether or not 0 works.  The SAT tester says, let's say, yes.  So then I could fix 0.  I now know the first all three bits of x. ", "And of course, I go on and in 2k SAT tests,  I know exactly what p and q are, and I have, in fact, found  the factors p and q. ", "So that wraps that one up.  That's how you use a SAT tester.  You just do the SAT test 2k times  and you factored this 2k bit number.  And of course, if the SAT test is polynomial in k, ", "then doing it 2k times just is also polynomial in k  with one degree higher.  Now, the satisfiability problem, as we formulated, ", "was a problem about formulas that as you wrote out  a propositional formula and asked whether or not  it was satisfiable, and I'm instead  asking about satisfiability of binary circuits. ", "But in fact, as we did in some early exercises,  you can describe a binary circuit  by assigning a fresh variable to every wire in the circuit ", "and then writing a little formula around each gate which  explains how the input wires to that gate  are related to the output wire of that gate.  And that little formula explains that wiring of that gate, ", "and you take the \"and\" of all those formulas  and you have a formula that is describing  the structure of the circuitry, and in fact the formula ", "is satisfiable if and only if the circuit  can produce an output 1.  So we really have by assuming that I  could test satisfiability of formulas, ", "I can therefore test satisfiability of circuits,  and therefore I can factor.  So that's the simple trick to find a propositional formula ", "that's equisatisfiable to the circuit--  if the circuit produces output 1 if  and only if this formula of about the same size  as the circuit is satisfiable. ", "And that's the last piece that I needed in order  to completely reduce the factoring  to the satisfiability problem, and you  could see that this is actually a general method that ", "will enable you to reduce most any kind of one-way function  to a few SAT tests. "], "vid_duration": [12.14, 11.36, 12.804, 10.366, 12.23, 13.11, 11.17, 13.24, 10.29, 11.76, 12.86, 14.87, 10.64, 10.1, 11.07, 13.83, 12.71, 12.972, 12.428, 10.52, 12.19, 10.18, 10.21, 13.43, 12.4, 13.25, 12.34, 10.23, 11.7, 10.595, 12.055, 11.13, 11.61, 11.29, 11.47, 13.41, 15.325, 10.874, 13.281, 12.64, 11.18, 10.13, 10.95, 10.38, 14.241, 10.109, 11.13, 13.08, 12.68, 10.499, 10.081, 11.89, 13.17, 10.457, 10.023, 10.15, 12.7, 11.605, 11.365, 12.06, 10.57, 10.21, 11.7, 11.415, 12.125, 12.99, 13.21, 10.79, 12.67, 11.42, 13.57, 11.75, 10.84, 11.7, 11.47, 11.33, 10.58, 11.84, 11.89, 11.41, 12.89, 12.06, 12.44, 14.78, 12.26, 13.71, 12.31, 10.91, 13.41, 12.16, 10.48, 11.69, 10.6, 12.46, 11.77, 10.56, 10.76, 11.56, 12.49, 11.29, 12.78, 11.5, 11.75, 10.1, 13.35, 14.46, 11.11, 10.97, 12.23, 12.622, 12.134, 11.396, 11.46, 12.12, 12.56, 12.07, 13.49, 14.91, 11.68, 15.36, 10.86, 11.31, 10.7, 11.66, 11.61, 14.29, 11.74, 10.03, 10.2, 10.01, 10.1, 11.0, 10.75, 14.96, 13.3, 11.45, 11.16, 10.54, 10.35, 10.32, 13.095, 12.025, 10.91, 10.63, 10.42, 10.3, 6.698], "stet": [[0, 12.14], [12.14, 23.5], [23.5, 36.304], [36.304, 46.67], [46.67, 58.900000000000006], [58.900000000000006, 72.01], [72.01, 83.18], [83.18, 96.42], [96.42, 106.71000000000001], [106.71000000000001, 118.47000000000001], [118.47000000000001, 131.33], [131.33, 146.20000000000002], [146.20000000000002, 156.84000000000003], [156.84000000000003, 166.94000000000003], [166.94000000000003, 178.01000000000002], [178.01000000000002, 191.84000000000003], [191.84000000000003, 204.55000000000004], [204.55000000000004, 217.52200000000005], [217.52200000000005, 229.95000000000005], [229.95000000000005, 240.47000000000006], [240.47000000000006, 252.66000000000005], [252.66000000000005, 262.84000000000003], [262.84000000000003, 273.05], [273.05, 286.48], [286.48, 298.88], [298.88, 312.13], [312.13, 324.46999999999997], [324.46999999999997, 334.7], [334.7, 346.4], [346.4, 356.995], [356.995, 369.05], [369.05, 380.18], [380.18, 391.79], [391.79, 403.08000000000004], [403.08000000000004, 414.55000000000007], [414.55000000000007, 427.9600000000001], [427.9600000000001, 443.2850000000001], [443.2850000000001, 454.1590000000001], [454.1590000000001, 467.4400000000001], [467.4400000000001, 480.0800000000001], [480.0800000000001, 491.2600000000001], [491.2600000000001, 501.3900000000001], [501.3900000000001, 512.3400000000001], [512.3400000000001, 522.7200000000001], [522.7200000000001, 536.9610000000001], [536.9610000000001, 547.0700000000002], [547.0700000000002, 558.2000000000002], [558.2000000000002, 571.2800000000002], [571.2800000000002, 583.9600000000002], [583.9600000000002, 594.4590000000002], [594.4590000000002, 604.5400000000002], [604.5400000000002, 616.4300000000002], [616.4300000000002, 629.6000000000001], [629.6000000000001, 640.0570000000001], [640.0570000000001, 650.0800000000002], [650.0800000000002, 660.2300000000001], [660.2300000000001, 672.9300000000002], [672.9300000000002, 684.5350000000002], [684.5350000000002, 695.9000000000002], [695.9000000000002, 707.9600000000002], [707.9600000000002, 718.5300000000002], [718.5300000000002, 728.7400000000002], [728.7400000000002, 740.4400000000003], [740.4400000000003, 751.8550000000002], [751.8550000000002, 763.9800000000002], [763.9800000000002, 776.9700000000003], [776.9700000000003, 790.1800000000003], [790.1800000000003, 800.9700000000003], [800.9700000000003, 813.6400000000002], [813.6400000000002, 825.0600000000002], [825.0600000000002, 838.6300000000002], [838.6300000000002, 850.3800000000002], [850.3800000000002, 861.2200000000003], [861.2200000000003, 872.9200000000003], [872.9200000000003, 884.3900000000003], [884.3900000000003, 895.7200000000004], [895.7200000000004, 906.3000000000004], [906.3000000000004, 918.1400000000004], [918.1400000000004, 930.0300000000004], [930.0300000000004, 941.4400000000004], [941.4400000000004, 954.3300000000004], [954.3300000000004, 966.3900000000003], [966.3900000000003, 978.8300000000004], [978.8300000000004, 993.6100000000004], [993.6100000000004, 1005.8700000000003], [1005.8700000000003, 1019.5800000000004], [1019.5800000000004, 1031.8900000000003], [1031.8900000000003, 1042.8000000000004], [1042.8000000000004, 1056.2100000000005], [1056.2100000000005, 1068.3700000000006], [1068.3700000000006, 1078.8500000000006], [1078.8500000000006, 1090.5400000000006], [1090.5400000000006, 1101.1400000000006], [1101.1400000000006, 1113.6000000000006], [1113.6000000000006, 1125.3700000000006], [1125.3700000000006, 1135.9300000000005], [1135.9300000000005, 1146.6900000000005], [1146.6900000000005, 1158.2500000000005], [1158.2500000000005, 1170.7400000000005], [1170.7400000000005, 1182.0300000000004], [1182.0300000000004, 1194.8100000000004], [1194.8100000000004, 1206.3100000000004], [1206.3100000000004, 1218.0600000000004], [1218.0600000000004, 1228.1600000000003], [1228.1600000000003, 1241.5100000000002], [1241.5100000000002, 1255.9700000000003], [1255.9700000000003, 1267.0800000000002], [1267.0800000000002, 1278.0500000000002], [1278.0500000000002, 1290.2800000000002], [1290.2800000000002, 1302.9020000000003], [1302.9020000000003, 1315.0360000000003], [1315.0360000000003, 1326.4320000000002], [1326.4320000000002, 1337.8920000000003], [1337.8920000000003, 1350.0120000000002], [1350.0120000000002, 1362.5720000000001], [1362.5720000000001, 1374.642], [1374.642, 1388.132], [1388.132, 1403.0420000000001], [1403.0420000000001, 1414.7220000000002], [1414.7220000000002, 1430.082], [1430.082, 1440.942], [1440.942, 1452.252], [1452.252, 1462.952], [1462.952, 1474.612], [1474.612, 1486.222], [1486.222, 1500.512], [1500.512, 1512.252], [1512.252, 1522.282], [1522.282, 1532.482], [1532.482, 1542.492], [1542.492, 1552.5919999999999], [1552.5919999999999, 1563.5919999999999], [1563.5919999999999, 1574.3419999999999], [1574.3419999999999, 1589.302], [1589.302, 1602.6019999999999], [1602.6019999999999, 1614.052], [1614.052, 1625.212], [1625.212, 1635.752], [1635.752, 1646.1019999999999], [1646.1019999999999, 1656.4219999999998], [1656.4219999999998, 1669.5169999999998], [1669.5169999999998, 1681.542], [1681.542, 1692.452], [1692.452, 1703.082], [1703.082, 1713.5020000000002], [1713.5020000000002, 1723.8020000000001], [1723.8020000000001, 1730.5000000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1303, 1731]}
{"example_id": "mit097@@MIT6_042JS15_06_ipod", "text": [" PROFESSOR: We're going to look at the most  fundamental of all mathematical data types, namely sets,  and let's begin with the definitions.  ", "So informally, a set is a collection  of mathematical objects, and the idea  is that you treat the collection of objects as one new object. ", "And that's a working definition.  But of course, it might help a little bit,  but it's a circular definition.  This is not math yet because I haven't defined  what a collection is, and a collection ", "is no clearer or easier to define than a set is.  So let's try to work up the idea of sets  by looking at some examples.  So we've already talked about some familiar ones. ", "There's the real numbers for which  we had this symbol R in a special font,  and the complex numbers C, and the integers  Z. And we might have mentioned, and you ", "might have seen already, the idea of the empty set for which  we use this symbol that looks like a zero with a line  through it.  Let's look at an example to pin things down. ", "Let's look at this set of four things.  Namely, it's got two numbers, pi/2 and 7, a character  string in quotes, \"Albert R,\" and the Boolean value true. ", "So those are the four different things in it.  They're of mixed type.  And you might not like to have a mixed type like this  in a programming language.  But mathematicians don't worry about such things very much, ", "rarely.  Anyway, the first observation is that the order  in which these elements are listed doesn't matter.  This set-- the braces indicates that it's ", "the set of these things-- is the same if I  listed T first, then the string, and the two numbers last.  There is no notion of order in a set. ", "Now, to a computer scientist this is a little unnatural.  The most natural thing to be would  be to define a sequence of things,  like the sequence that began with 7, then  had the character string, then had the number, ", "then had the Boolean.  And you could get by with working with lists of things  as long as they're finite.  But they very quickly get out of hand ", "when you have to talk about, say, a set of lists.  Then it's not clear how to make a list out of those,  and you wind up making sets again.  So sets, in fact, are an unavoidable kind of idea. ", " So another basic thing to understand  about the notion of a set is that an element  is either in a set or not in a set.  So if I write down 7, pi/2, 7, this ", "is the same description of the same set 7, pi/2.  I'm just telling you the same thing twice here.  That 7 is in the set, and the 7 is in the set again.  So no notion of being in the set more than once. ", "Now, sometimes, technically you want  to add a notion of so-called multisets  in which elements can be in a set  a certain number of times, an integer number of times.  But there's no real need for that. ", "It's a secondary idea.  And from our point of view, you're in or out of a set.  If you repeat elements, it's the same as mentioning them once.  So the most fundamental feature of a set is what's in it. ", "And for that, there's a special notation.  So we'll say that x is a member of A, where A is a set,  and use this epsilon symbol to indicate membership.  It's read x is a member of A. So for example, pi/2 ", "is a member of that set that we saw before that had pi/2 in it.  14/2 is also a member of that set because 14/2 is just  another description of 7. ", "When I write 7 here, I don't mean the character 7.  I mean the number 7.  And so 14/2 is the description of the same number.  It's in that set.  On the other hand, pi/3 is a number ", "that's simply not in that set.  So I'm using the epsilon with a vertical bar through it,  or some kind of a line through it, to mean not a member of. ", "Membership is so basic that there's a lot of different ways  to say it.  Besides using the membership symbol x is a member of A,  you can sometimes say x is an element of A,  or x is in A, as well as x is a member of A. ", "They're all synonyms.  So for example, 7 is a member of the integers.  Z is our symbol for the integers.  2/3 is not a member of the integers ", "because it's a fraction that's not an integer.  And on the other hand, the set Z of integers  itself is a member of this three-element set consisting  of the truth value T, the set of all integers, ", "and the element 7.  So here's an example where a set can contain sets, quite  big ones even, and that's fine.  That's not any problem mathematically. ", "Related to membership is another fundamental notion of subset.  So A is a subset of B, it's pronounced.  So that horizontal U with a line under it ", "is meant to resemble a less than or equal to symbol.  So you can think of it as being A is less than or equal to B.  But don't overload the symbols.  Less than or equal to is used on numbers and other things ", "that we know how to order.  And this is a relation that's only allowed between sets.  So A is a subset of B-- A synonym is that A is contained  in B-- simply means that every element of A ", "is also an element of B. If I wrote  that out in predicate logic notation  as a predicate formula, I'd say for every x, x is in A implies ", "x is in B. If it's in A, then it's in B. Everything in A  is in B.  So some examples of the subset relation ", "are that the integers are a kind of-- an integer  is a special case of a real number.  So the set of integers is a subset of the real numbers.  A real number is a special case of a complex number, ", "so the real numbers are a subset of the complex numbers.  And here's a concrete example, where  I have a set of three things, 5, 7, and 3,  and this is the set with just the element 3 in it. ", "Now, we sometimes are sloppy about distinguishing  the element 3 from the set that's consisting of just 3  as its only element.  But in fact, it's a pretty important distinction ", "to keep track of.  In this case, 3 is not a subset of this set on the right.  But the set consisting of 3 is a subset of the set on the right ", "because, after all, the only member of this set is 3,  and that is a member of this set.  A consequence of this general definition is that every set is ", "a subset of itself because everything in A is in A .  That's not really very interesting.  Another important general observation  is that the empty set is a subset of everything. ", "The empty set is a subset of every set.  Let's look at why that is in more detail.  So the claim is that the empty set is a subset of everything.  Let B be any old set, then the empty set ", "is a subset of B. What exactly does that mean according  to the definition of subset?  Well, it says that everything that's in the empty set,  if it's in the empty set, then it ", "implies that it's in B. For every element,  if it's in the empty set, then it's in B.  Well, what do we know about this?  The assertion that x is in the empty set is false. ", "No matter what x is, there's nothing in the empty set.  And now I have an implication that  implies where the left-hand side, the hypothesis, is false. ", "That means that the whole implication is true,  and it doesn't depend on what B is.  I'm not even going to look at B. I  can see that x is in empty set is false,  so the whole implication is true. ", "And so what I'm saying is that for every x,  something that's true has to be true.  Well, it is.  And that's why the empty set is a subset of B  satisfies this definition in a formal way. ", "And this is an example of why that convention  that false implies anything is convenient and is made  use here.  ", "So when you're defining sets, if they're small,  you can just list the elements, as we  did with that set with 7 and pi/2 and \"Albert R.\" ", "Sometimes we can even describe infinite sets  as some kind of a list.  Like I might describe the set of integers as saying,  well, it's 0, 1, minus 1, 2, minus 2, and so on, ", "and you would understand that.  But in general, if I'm describing  a set that is not so easy to list,  say the real numbers, then what I'm going to do ", "is define a set by a defining property of in the set.  So I'm interested in a property P of elements,  and I'm going to look at the set of elements ", "x that are in some set A such that P of x is true,  and that's the notation we use.  So this would be read as the set of x in A such that P of x ", "holds, that x has property P. So notice this vertical bar is  read as \"such that.\"  It's just a mathematical abbreviation.  This is those elements in A that have property P that P of x ", "holds for, and that defines a set of those elements.  Let's look at a simple example.  The set E of even integers is simply the set of numbers n  that are integers such that n is even. ", "So in this case, the property P of n means that n is even.   One last concept is the concept of the power set. ", "So the power set of a set A is all of the subsets of A.  So we could define it using set notation  as it's the set of B such that B is ", "a subset of A. An example would be--  let's take the power set of the two Boolean values  true and false. ", "So the power set of true and false,  of that set consisting of two elements,  is-- well, what are some of its subsets?  The set consisting of just true is a subset of true, false. ", "So is the set consisting of false,  and so is the whole thing.  It's a subset of itself.  And one final element, the empty set,  is a subset of the set of Boolean values true and false. ", "So the power set of this two-element set  is a set that has four things in it-- two elements of size 1,  one element of size 2, one element of size 0.  And that's going to be a general phenomenon ", "that we'll examine more later.  How big is the power set of a set?   The even numbers, E that we just defined on the previous slide, ", "is a member of the power set of Z because it's  a subset of integers.  Even integers are a special case of integers.  And the integers are a member of the power set of R. ", "That's just a synonym for saying that integers  are a subset of reals.  Every integer is a real, so the integers  are a subset of reals, which means  they're a member of the power set of reals. ", "So the general property is that a set B  is a member of the power set of A if and only  if B is a subset of A. That was the defining  condition for power set. ", "And that's a fact to remember, and it may potentially  confuse you.  But it's a good exercise in keeping  track of the difference between is a member of ", "and is a subset of.   PROFESSOR: Let's define a few familiar  and standard operations on sets.  So here's a picture of two sets A and B,  where the idea is that the circle represents ", "the points in A. The other circle represents  the points in B. The overlapping area, this lens-shaped region,  are the points that are in both A and B.  And the background are the points that ", "are in neither A and B.  So this sort of a general picture  allows you to classify points with respect to And B,  and it's called a Venn diagram, in this case for two sets. ", "It's still useful for three sets.  It gets more complicated for four sets.  And after that point, they're not really very useful.  But a lot of the basic operations  can be illustrated nicely in terms ", "of the Venn diagram for two sets,  and that's what we're about to do.  So the first operation is union.  It's the set of points shown here in magenta. ", "It's the set of points that are in either A or B, all of them.  And so if we were defining this in terms  of set-theoretic notation or predicate notation,  the union symbol-- the U is the union symbol. ", "So A union B is defined to be those points x that are in A OR  are in B.  And you can already begin to see an intimate relationship  between the union operation and the propositional OR ", "connective.  But don't confuse them.  If you apply an OR to sets, your compiler  is going to give you a type error.  And if you apply union to propositional variables, ", "your compiler is also going to give you a type error.  So let's keep the propositional operators  and the set-theoretic operators separate  [? and ?] clearly distinct even though they ", "resemble each other.  All right.  Next basic operation is intersection where, again, it's  the points that are both in A and B,  the points in common, which are now highlighted in blue. ", "So the definition of A intersection B--  we use an upside-down union symbol for intersection--  it's the set of points that are in A and are in B. ", "So let's stop for a minute and make  use of the similarity between the set-theoretic operations  and the propositional operators.  Let's look at a set-theoretic identity, which I claim ", "holds no matter what sets A, B, and C you're talking about.  And we're going to prove it by making  the connection between set-theoretic operations  and propositional operators.  And so let's read the thing. ", "It says that if you take A union the set B intersection  C, that's equal to the set A union B intersected  with A union C. Now, let's not think through yet ", "how to make this an intuitive argument.  It's going to really crank out in an automatic way  in a moment.  But we can remember it as saying that you ", "can think of this as union distributing over intersection.  So if you think of union as times here  and intersection as plus, then we've ", "got a rule that says that A times B plus C is  A times B plus A times C.  Now, it's also true that if you reverse the role of union ", "and intersection, you get another distributive law  that AND distributes over union, but never mind that.  Let's just look at this one.  We're trying to prove the distributive law for union  over intersection. ", "How shall we prove it just from the definitions?  Well, the way we're going to do it  is by showing that the two sets on the left-hand side  and the right-hand side have the same set of elements. ", "Namely, if I have an element x that  appears in the set described on the left-hand side,  then that point is in the right-hand side.  And it's an if and only if.  So that says that the left-hand side and the right-hand side ", "expressions defines sets with the same set of points.  This holds for all x.  And it turns out that the proof is  going to follow by analogy to a propositional formula ", "that we're going to make use of in the proof.  That was a propositional equivalence  that we proved in an earlier talk, namely  that OR distributes over AND. ", "So P OR Q AND R is equivalent to P OR Q AND P OR R.  So you can see this equivalence in purple ", "has the same structure as the set-theoretic equality in blue,  except that union's replaced by OR,  intersection's replaced by AND, and set  variables A, B, C is replaced by propositional variables ", "P, Q, R.  So let's just remember that we've already  proved this propositional equivalence,  and we're going to make use of it in the middle of this proof ", "that these two sets are equal.  So again, we said we were going to prove  the two sets are equal by showing  they have the same points.  So here's the proof.  It's going to be a lovely if and only if argument the whole way.  So looking at the left-hand side, a point x is in A union ", "B intersection C by definition of union  if and only if x is an A OR x is in B intersection C.  I've just applied the definition of union there. ", "OK.  Now, let's look at this expression.  x is in B intersection C. That's the same  as x is in B AND x is in C, again, just using  the definition of intersection. ", "And now I have a propositional formula involving OR and AND  and the basic assertions about sets of x is a member of one  of those A's, B's, C's. ", " Now, at this point, I can immediately  apply my propositional equivalence  and say that the assertion x is an A OR x is in B AND x is in C ", "holds if and only if this expression, x is  an A OR x is in B AND x is in A OR x is in C. Why is that?  Well, I'm just invoking the propositional equivalence. ", "Let's look at it.  That if I think of the x is in A as proposition P--  and let's replace all the x [? over ?] A's by P-- ", "and I think of x is in B as a Q and x is in C as an R,  then I can see that the first set-theoretic assertion has  the form of P OR Q AND R. ", "And I can transform it by the propositional equivalence  into P OR Q AND P OR R. And then remember  what P and R are to get back to the set-theoretic membership, ", "basic membership assertions.  So now we've just proved that x is  in A OR x is in B AND x is in A OR x is in C.  And that's if and only if it was in the left-hand side set. ", "Well, now I'm going to go back the other way.  Namely, this OR, that x is in A OR x is in B,  is the same as saying that x is in A union B,  likewise here just by applying the definition of union. ", "And this assertion that x is in this set AND x  is in this set is the same as saying that x  is in their intersection.  And I've completed my proof, namely ", "the point that was in the left-hand side if and only  if it's in the right-hand side.  You have to remember that that was the right-hand side  of the identity.  So this is a general method actually, ", "where you can take any set-theoretic equality  involving union and intersection and the operations  of difference and complement that we'll talk about  in a moment, and we can convert any such set-theoretic equality ", "into a propositional equality or a propositional equivalence  so we can check that the propositional assertion is  an equivalence.  And from that, using this method of converting the membership ", "statements in the set expression into a propositional  combination, we can check, and automatically check,  any kind of set-theoretic identity involving  union, intersection, and minus. ", "And that, in fact, is the way that automatic engines  like Mathematica can prove these set-theoretic identities.  So let's just for the record put down that last operation. ", "The difference operation is the set  of elements that are in A AND not in B.  So we'd write it as A minus B is the set of points that  are in A AND not in B. and it's Illustrated ", "by this region that's highlighted in orange.  And a special case of the minus operation or the difference  operation is complement. ", "When you know the overall domain that you expect all your sets  to be part of, then you can define a complement  to be everything that's not in A-- the set of x such ", "that x is not in A, where x is understood to be ranging  over some domain of discourse.  So if we're going to picture that, we're  looking at the whole orange region, all of the stuff that's ", "not in A if we think of the whole slide  as representing the domain of discourse D. "], "vid_duration": [12.07, 10.28, 10.58, 11.65, 14.27, 11.89, 14.336, 12.574, 10.82, 10.795, 10.415, 11.82, 12.16, 13.14, 12.73, 10.5, 12.84, 13.48, 10.09, 11.35, 11.39, 13.46, 11.57, 12.88, 12.39, 10.64, 11.4, 13.65, 11.58, 12.43, 10.56, 12.49, 10.41, 10.27, 10.44, 11.03, 11.1, 10.48, 13.15, 10.0, 12.21, 11.96, 10.91, 13.43, 12.08, 10.7, 10.32, 10.92, 11.22, 12.16, 10.875, 13.065, 10.61, 10.69, 13.71, 11.89, 10.89, 12.6, 11.73, 14.09, 11.58, 11.9, 10.38, 10.169, 10.351, 10.519, 13.221, 13.23, 11.84, 10.3, 12.23, 12.33, 12.599, 10.211, 14.559, 11.431, 11.36, 11.587, 10.743, 11.879, 12.791, 14.14, 11.319, 12.26, 12.841, 10.01, 14.7, 11.959, 10.971, 10.245, 12.475, 10.87, 12.469, 11.741, 10.23, 12.16, 12.48, 11.05, 10.35, 15.95, 11.829, 13.281, 11.52, 13.61, 11.21, 11.31, 12.279, 6.761], "stet": [[0, 12.07], [12.07, 22.35], [22.35, 32.93], [32.93, 44.58], [44.58, 58.849999999999994], [58.849999999999994, 70.74], [70.74, 85.076], [85.076, 97.64999999999999], [97.64999999999999, 108.47], [108.47, 119.265], [119.265, 129.68], [129.68, 141.5], [141.5, 153.66], [153.66, 166.8], [166.8, 179.53], [179.53, 190.03], [190.03, 202.87], [202.87, 216.35], [216.35, 226.44], [226.44, 237.79], [237.79, 249.18], [249.18, 262.64], [262.64, 274.21], [274.21, 287.09], [287.09, 299.47999999999996], [299.47999999999996, 310.11999999999995], [310.11999999999995, 321.5199999999999], [321.5199999999999, 335.1699999999999], [335.1699999999999, 346.7499999999999], [346.7499999999999, 359.1799999999999], [359.1799999999999, 369.7399999999999], [369.7399999999999, 382.2299999999999], [382.2299999999999, 392.63999999999993], [392.63999999999993, 402.9099999999999], [402.9099999999999, 413.3499999999999], [413.3499999999999, 424.3799999999999], [424.3799999999999, 435.4799999999999], [435.4799999999999, 445.9599999999999], [445.9599999999999, 459.1099999999999], [459.1099999999999, 469.1099999999999], [469.1099999999999, 481.3199999999999], [481.3199999999999, 493.27999999999986], [493.27999999999986, 504.1899999999999], [504.1899999999999, 517.6199999999999], [517.6199999999999, 529.6999999999999], [529.6999999999999, 540.4], [540.4, 550.72], [550.72, 561.64], [561.64, 572.86], [572.86, 585.02], [585.02, 595.895], [595.895, 608.96], [608.96, 619.57], [619.57, 630.2600000000001], [630.2600000000001, 643.9700000000001], [643.9700000000001, 655.8600000000001], [655.8600000000001, 666.7500000000001], [666.7500000000001, 679.3500000000001], [679.3500000000001, 691.0800000000002], [691.0800000000002, 705.1700000000002], [705.1700000000002, 716.7500000000002], [716.7500000000002, 728.6500000000002], [728.6500000000002, 739.0300000000002], [739.0300000000002, 749.1990000000002], [749.1990000000002, 759.5500000000002], [759.5500000000002, 770.0690000000002], [770.0690000000002, 783.2900000000002], [783.2900000000002, 796.5200000000002], [796.5200000000002, 808.3600000000002], [808.3600000000002, 818.6600000000002], [818.6600000000002, 830.8900000000002], [830.8900000000002, 843.2200000000003], [843.2200000000003, 855.8190000000003], [855.8190000000003, 866.0300000000003], [866.0300000000003, 880.5890000000003], [880.5890000000003, 892.0200000000003], [892.0200000000003, 903.3800000000003], [903.3800000000003, 914.9670000000003], [914.9670000000003, 925.7100000000004], [925.7100000000004, 937.5890000000004], [937.5890000000004, 950.3800000000005], [950.3800000000005, 964.5200000000004], [964.5200000000004, 975.8390000000004], [975.8390000000004, 988.0990000000004], [988.0990000000004, 1000.9400000000004], [1000.9400000000004, 1010.9500000000004], [1010.9500000000004, 1025.6500000000003], [1025.6500000000003, 1037.6090000000004], [1037.6090000000004, 1048.5800000000004], [1048.5800000000004, 1058.8250000000003], [1058.8250000000003, 1071.3000000000002], [1071.3000000000002, 1082.17], [1082.17, 1094.6390000000001], [1094.6390000000001, 1106.38], [1106.38, 1116.6100000000001], [1116.6100000000001, 1128.7700000000002], [1128.7700000000002, 1141.2500000000002], [1141.2500000000002, 1152.3000000000002], [1152.3000000000002, 1162.65], [1162.65, 1178.6000000000001], [1178.6000000000001, 1190.429], [1190.429, 1203.71], [1203.71, 1215.23], [1215.23, 1228.84], [1228.84, 1240.05], [1240.05, 1251.36], [1251.36, 1263.639], [1263.639, 1270.3999999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [718, 1271]}
{"example_id": "mit097@@MIT6_042JS15_24_ipod", "text": [" PROFESSOR: The issue of the approximate rate  at which things happen is a common in a lot of sciences,  the rate at which things fall, or the rate  at which reactions occur. ", "And in computer science, typical concern about growth rates  comes up in looking at the efficiency of algorithms,  and whether they're growing linearly, or quadratically, ", "or more.  And we're going to look today at four notations that  describe relations between the growth rates of functions.  The first of these relations is the simplest one. ", "It's called asymptotic equivalence,  or asymptotic equality.  So this is tilde symbol is read as asymptotically equal to.  So f of n is asymptotically equal to g of n, ", "if and only if the limit of the quotient of f of n over g of n  is 1.  Let's look at an example.  ", "N squared is asymptotically equal to n squared plus n.  Why is that?  Well, it follows trivially by manipulating the algebra.  The limit of n squared plus n over n squared, ", "simplifying, is just the same as the limit of 1 plus 1 over n.  But as n goes to infinity, 1 over n  goes to 0, so the limit is 1 as claimed.  Those two expressions, or the functions they define, ", "n squared and n squared plus 1 are asymptotically equal.  So there's some easy properties of asymptotic equality  that follow immediately from the definition. ", "One of them is that it's symmetric,  namely, suppose that f is asymptotically equal to g.  I want to prove that g is asymptotically equal to f. ", "Well, what's going on here?  Let's look at the limit of g over f, which  is what I'd like to prove as 1.  Well, the limit of g over f, by algebra, g over f ", "is the same as 1 over f over g, so just moving a limit  across the division, that's the same as 1  over the limit of f over g, which is 1 over 1. ", "And we've proved in other words, the g  is asymptotically equal to f, given that f is asymptotically  equal to g.  It's symmetric.  There's a similar argument for transitivity. ", "Let's just crank through it for practice on the definition.  Suppose that f is asymptotically equal to g,  and g is asymptotically equal to h,  I'd like to prove that f it's asymptotically equal to h. ", "Well, again, we just plug into the algebra  and distribute limits.  Let's just look at this.  We're given that 1 is the limit of f over g,  because f is asymptotic to g. ", "But f over g can be expressed as f over h divided by g over h.  That's just algebra.  The h's cancel.  So this limit, now, I can distribute the limits ", "to the numerator and denominator,  assuming both exist, and the numerator limit  is what I'm interested in.  The denominator limit is going to be 1, ", "because the limit of g over h is 1.  Since g is asymptotically equal to h,  the conclusion is indeed that the limit of f over h  is equal to 1. ", "This is not really very interesting stuff,  and the top level message is that  many of these elementary properties  of asymptotic equality and the other asymptotic relations ", "that we're going to see follow by this kind  of elementary algebra, and distributing the limits  over sub expressions.  Anyway, the corollary of this is that asymptotic equality ", "is in fact an equivalence relation.  We've proved it's symmetric and transitive,  and it's trivially reflexive.  It's an equivalence relation.  By the way, it's worth noting that it's ", "an equivalence relation on functions of one variable, when  we write sometimes that f of n is asymptotically  equal to g of n.  But we mean that f of n is the description of the function f. ", "We're not talking about the number that f of n  happens to have for some particular value of f.  So we'll sometimes write f of n is  asymptotically equal to g of n.  For descriptive purposes, the proper thing ", "we should be writing is that f is asymptotically equal to g.  Asymptotic equality is a relation between functions.  OK.  The next asymptotic relation we're going to look at ", "is called asymptotically smaller than, and the notation for it  is this little o notation.  So you'd write that f of n is equal to little o of g of n, ", "if and only if the limit of f of n over g of n goes to 0 as n'  approaches infinity.  So let's look at an example of that. ", "N squared is little o of n cubed,  because trivially, the limit of n squared over n cubed  is the same as the limit of 1 over n.  It's equal to zero.  ", "And by similar kind of reasoning that we  did for asymptotic equality being an equivalence relation,  it's not very hard to prove that little o defines  a strict partial order on functions. ", " So the third asymptotic relation is the most complicated  of the three.  It's arguably the most important in computer science. ", "It's called the asymptotic order of growth, o.  And the definition is that if function  f is big o of a function g, what it means  is that the limit of f over g is finite. ", "So it might be other than 0 or 1, but it's finite.  And that means that f is big o of g. ", "Now, there's a technicality there  where the expression actually says the limsup of f of n  over g of n.  Let's just ignore that for now, and we'll look at it ", "and explain why the limsup is there a little later.  So as an example, 3n squared is big o  of n squared, because the quotient of 3n ", "squared over n squared is 3, which is less than infinity.  So what big o is doing is kind of saying that constant factors  don't matter.  And that turns out to be particularly useful in computer ", "science, where you can't really talk about the time  that a procedure takes, because that's going  to depend on the hardware.  So when you implement it on faster hardware, ", "it may grow at the same rate, but the time  will actually change.  And that's why big o plays a prominent role.  The final relation of the four is called ", "theta, or same order of growth.  The definition of f is theta of g  is simply that f is o of g and g is o of f. ", "And it's easy to show from the definition  that theta is an equivalence relation.  So to summarize, there are these four relations. ", "F asymptotically equal to g means informally  that f and g are nearly equal.  F equals little o of g informally means ", "that f is much less than g.  F equals o of g means that f is roughly less  than or equal to g, where roughly  means that we're not concerned about constant factors.  And f equals theta of g means that f is roughly equal to g. ", "And we'll examine these properties   PROFESSOR: An advantage of expressing  the asymptotic notations, in terms of limits, ", "is that a bunch of their properties  then become immediately obvious.  Here's one.  If f is little o of g, or f is asymptotically equal to g,  then, in fact, f is big o of g. ", "Or we can reason about this informally  by saying that the first one means  that f is much less than g, and the second one  means that f is about the same as g,  and the final one means that f is roughly less. ", "So being about the same and definitely less,  and certainly this implies roughly less.  But we can in fact be entirely precise  just using the definitions, because f equals o of g ", "means the limit of f over g is 0.  And f is asymptotically equal to g means  that the limit of f over g is 1.  And the definition of f equals big o of g ", "is that the limit is finite.  And clearly, if it's 0 or 1, then it's finite.  Another such property is that if f is much less than g,  then g is not roughly less than f. ", "More precisely, if f is a little o of g,  then g is not big o of f.  The left hand side says that the limit of f over g is 0.  But that implies that the limit of g over f is 1 over 0, ", "or infinity, which means it's not finite,  so g is not a big o of f.  PROFESSOR: Now, the usual way that big o ", "is defined in the literature doesn't mention limits at all.  And, in fact, as I said, the definition really  isn't a limit, it's a limsup.  And let me show you the standard definition and then ", "explain why the limsup soup captures it and is needed.  So the official definition of f is big o of g  is that there's some constant multiplier, c, that you can ", "amplify g by, such that once g is amplified by the factor c,  then, in fact, f is less than or equal to c times g. ", "But this may not hold right at the beginning.  There's a certain point, n 0, after which it holds forever.  Let's try to illustrate this complicated alternation ", "of quantifiers expression with a diagram that  may make it clearer.  So suppose that I want to express  the fact that f is big o of g, where f is it a green line. ", "So that green line is the graph of f of x, the function.  And g in blue is shown-- and as a matter of fact,  g of x is less than or equal to f of x. ", "But nevertheless, f is going to be big o of g,  because if you multiply g by a constant,  it becomes sort of shifting it up to be this constant times g. ", "It becomes this purple curve, and the purple curve,  it gets to be above the green curve, from a certain point on.  That's n 0.  So by raising up the blue curve, g, by an amount c, ", "to get it to be this purple curve,  the purple curve gets above f from a certain point n 0 on.  And that's why f is big o of g. ", "Now, of course, multiplying the blue curve, g, by a constant  doesn't raise it up a fixed amount.  It alters it, but if we imagine that our curve was a log ", "scale, than, in fact, multiplying g by c  is the same as adding log c on a log scale.  So the picture is actually accurate  if the vertical scale is logarithmic. ", "So using this standard definition,  I can explain why in the equivalent definition of terms  of limit, I couldn't say limit, I needed to say limsup.  Here's what limsup does for us. ", "Suppose I have a function, f, that's say, less than  or equal to 2g.  Which means that, surely, f is big o of g,  according to the previous definition, because you amplify  g by 2 and you get above f. ", "The problem is that f of n over g of n may have no limits,  so I can't simply say that f is o of g,  because the limit of f over g is finite. ", "Let's see how that could happen.  Suppose that f is in fact equal to g times a number that  varies between 1 and 2.  That's an example where sin of n pi over 2 ", "varies between 0, 1, and minus 1.  And you square it, it becomes 0 or 1.  And you add 1 to it, it becomes 1 or 2.  So this is an expression, which as n grows, alternates ", "between the values 1 and 2.  And I'm multiplying g of n by this factor  that's either 1 or 2.  But the limit of f of n over g of n does not exist, ", "it's alternating between 1 and 2.  On the other hand, the limsup f of n over g ", "is 2, which is finite, and therefore,  according to the limsup definition, indeed f is o of g.  Now, the technical definition of limsup ", "is one that you can read in the text  or find in a calculus book.  It's basically the largest limit point of the fraction  f of n over g of n. ", "And if you don't know what a limit point is,  it's stuff that we don't need to go into.  But I did want you to understand why formally, we need limsup.  In most cases, the limit exists, and we ", "can use the simpler limit definition, rather than  the exists a constant, such that for every number n  greater than or equal to n 0, et cetera, which is  a more complicated definition. ", " OK.  Let's collect a couple of more basic facts  about little o and big o that we're going to need. ", "Namely, that if a is less than b--  I know they can be negative numbers.  I don't care, but real numbers.  If a is less than b, then x to the a ", "is little o of x to the b.  The [? proof file ?] is almost immediately  from the definitions, because to prove that x to the a  is little o of x to the b, we want ", "to look at the quotient of x to the a over x to the b.  But, of course, the quotient of x to the a over x to the b  is equal to 1 over x to the b minus a.  And since a is less than b, b minus a is positive. ", "So that means that as x approaches infinity,  the denominator is x to a positive power also goes  to infinity.  And therefore, 1 over x to that positive power  goes to 0, which is the definition of x to the a being ", "little o of x to the b.  Another crucial fact is that logarithms grow slower  than roots.  So if you think of epsilon as like a half or a third, ", "saying that the log of x is less than  or equal to the square root, it's  less than equal to the cube root,  it's less than or equal to the 50th root doesn't matter.  OK.  This is a proof that just falls back on elementary calculus. ", "And I guess I've highlighted it, because it's definitely worth  remembering.  Logarithms grow slower than roots.  The proof begins with the immediately obvious remark ", "that 1 over y is less than or equal to y,  because they're equal when y is greater to 1.  1 over y is equal to y when y is greater than or equal to 1.  And as y increases, y gets bigger, and 1 over y ", "gets smaller, so the inequality is preserved.  That's easy, OK.  Well that means that I can integrate both sides starting  at 1.  So if I take the integral of 1 over y from 1 to z, ", "it's going to be less than or equal to the integral of y  from 1 to z.  Well, integral of 1 over y is log z,  and the integral of y to z is z square over 2. ", "So what we get is this new inequality, the log of z  is less than or equal to z squared over 2, for z greater  or equal to one.  So we're on the way there.  We've got log of z is less than z squared, ", "but not z to any epsilon power.  But we'll get that just by making a smart substitution  for z, so that's the next step.  We have that log of z is less than ", "equal to z squared over 2 for any z greater than  or equal to 1.  Let's let z be the square root of x to the delta, where delta  is simply some positive number. ", "So in that case, what's the log of z?  Well the log of the square root of x to the delta,  the square root means it's half of log of x to the delta, which  is delta log x. ", "So log of z is delta log of x over 2.  And, of course, z squared is just x to the delta,  so z squared over 2 is x to the delta over 2. ", "Now, I can just cancel the denominators too.  And I get that log of x, and then  transpose the delta log of x is less than or equal to x  to the delta over delta. ", "But as long as delta is less than epsilon, x to the delta  is going to be a little o of x to the epsilon, which  means that x to the delta times a constant, ", "namely 1 over delta, is also going to be  little o of x to the epsilon.  And I've just figured out that I've shown that log of x  is little o of x to the epsilon as required. ", "One more crucial fact that I'm going to not prove,  but I'll state is that polynomials grow slower  than exponentials.  This is closely related to the fact that ", "logs grow slower than roots.  But in particular, if c is any constant and a  is greater than 1, then x to the c is little o of a to the x. ", "And there's a bunch of ways to prove this using a L'Hopital's  Rule, or McLaurin Series, and I'll leave it to you  to look up your 1801 calculus text  to find a proof of that fact. ", " ALBERT R. MEYER: Let's take a quick look at some blunders  that people regularly make in dealing  with asymptotic notation, in particular with big O  notation, which tends to confuse people. ", "So the most important thing to remember  is that this notation, something equals O of something  else-- 1/x equals O of 1, say-- is actually ", "to be understood as just a not such attractive notation,  misleading notation for a binary relation between two functions.  This is supposed to be a function there, ", "and this is supposed to be a function there.  And this is saying that there's a relation between the growth  rates of these two functions.  O of f is not quantity. ", "And you mustn't treat it as such.  So, for example-- and the equality, of course,  is not an inequality.  Once upon a time, we tried to get the equality replaced  by an epsilon, which makes much better sense-- ", "that is, a membership symbol.  But there was a sense that this notation was so deeply embedded  in the mathematical culture-- multiple mathematical  communities-- that there was no way we were going to change it. ", "In particular, a confusion where you think that that equality  sign means some kind of an equality  is to write instead of f equals O of g,  well, if f equals O of g by symmetry, O of g ", "ought to equal f.  Don't write that.  The reason is that it's a recipe for confusion,  because look at this.  I know that x is O of x trivially,  which would suggest that O of x is ", "equal to x, if you believe in symmetry  and you think of O of x as being quantity.  Well, remember, though, that 2x is also  equal to O of x by definition of O. ", "So what we wind up with is combining 2x equals  O of x with O of x equals x is I get 2x is equal to this thing,  is equal to x.  I conclude that 2x is equal to x, which is absurd. ", "So that's nonsense.  It's the kind of trouble that you  can get into if you start thinking of this equality  as meaning equality between two quantities,  as opposed to just being a part of the name of a relation. ", "Another mistake that people make is less serious  but it's sloppy, is to think that big O  corresponds to a lower bound, so that people will say things ", "like f is at least O of n squared.  Well, again, at least O of n squared  is starting to treat O of n squared like a quantity.  You could say that f is equal to O of n square, ", "but that means that n squared is an upper bound  on f to within a constant factor after a certain point.  If you want to say intuitively that n squared is a lower ", "bound on f, then all you have to do  is say that n squared is O of f.  And that is a proper use of O of f of getting a lower ", "bound on a function, by saying that the lower bound is  O of the function.   Another example of the kind of nonsense  that you see-- this is a stretch, but let's ", "look at it as a reminder of things not to do.  I'm going to prove to you that the sum from i equals 1 to n  of i-- that is that 1 plus 2 plus 3 up to n-- is O of n. ", "Now, of course, it's not.  We know that the sum of the first n  integers n times n plus 1 over 2,  which is O of n squared-- theta of n squared actually.  So I'm going to prove something false. ", "Watch carefully how I do it.  Here's the false proof.  Let's, first of all, notice that any constant is O of 1.  So 0 is O of 1, 1 is O of 1, 2 is O of 1, and so on. ", "Any constant function is O of the constant function 1.  OK, that's true.  So that means that each i in this sum, i is a number, ", "so that means it might be 1, it might be 2, it might be 3,  it might be 50.  Whatever it is, it's O of 1.  And that means that I could think of this sum from i ", "equals 1 to n as O of 1 plus O of 1 plus O of 1.  And that's, of course, n times O of 1, which is O of n.  Now, there's all kinds of weird arithmetic  rules of things being used here, none of which are justified. ", "But it's just a heads up.  You do see stuff like this from inexperienced students.  And I hope that you won't fall into this kind  of a sloppy trap. ", "O of something is not a quantity.  It's part of the name of a relation. "], "vid_duration": [10.35, 11.0, 11.65, 12.97, 13.44, 11.84, 12.4, 10.4, 10.58, 10.85, 10.23, 10.762, 11.318, 11.25, 10.73, 11.39, 11.96, 12.36, 12.92, 10.87, 13.1, 10.76, 11.91, 10.61, 10.26, 11.7, 12.39, 13.07, 14.87, 10.29, 10.62, 12.82, 13.48, 10.7, 12.04, 11.81, 11.59, 10.33, 15.14, 10.88, 12.05, 11.21, 10.87, 10.05, 13.48, 13.09, 10.35, 11.079, 12.551, 10.73, 10.85, 11.67, 13.15, 13.38, 13.65, 10.42, 10.43, 12.9, 11.5, 11.7, 12.8, 14.35, 11.04, 13.19, 11.35, 10.12, 10.59, 12.86, 10.745, 11.274, 10.571, 10.13, 12.67, 14.27, 12.64, 11.76, 12.25, 10.91, 11.86, 13.04, 11.95, 10.56, 12.4, 10.97, 10.95, 11.62, 10.37, 15.39, 10.1, 12.11, 11.51, 11.67, 13.01, 10.24, 10.939, 10.071, 13.359, 11.151, 11.23, 11.83, 11.309, 14.89, 10.321, 11.349, 10.241, 10.64, 11.02, 12.119, 10.271, 14.149, 11.941, 10.505, 13.175, 10.47, 4.6], "stet": [[0, 10.35], [10.35, 21.35], [21.35, 33.0], [33.0, 45.97], [45.97, 59.41], [59.41, 71.25], [71.25, 83.65], [83.65, 94.05000000000001], [94.05000000000001, 104.63000000000001], [104.63000000000001, 115.48], [115.48, 125.71000000000001], [125.71000000000001, 136.472], [136.472, 147.79000000000002], [147.79000000000002, 159.04000000000002], [159.04000000000002, 169.77], [169.77, 181.16000000000003], [181.16000000000003, 193.12000000000003], [193.12000000000003, 205.48000000000002], [205.48000000000002, 218.4], [218.4, 229.27], [229.27, 242.37], [242.37, 253.13], [253.13, 265.04], [265.04, 275.65000000000003], [275.65000000000003, 285.91], [285.91, 297.61], [297.61, 310.0], [310.0, 323.07], [323.07, 337.94], [337.94, 348.23], [348.23, 358.85], [358.85, 371.67], [371.67, 385.15000000000003], [385.15000000000003, 395.85], [395.85, 407.89000000000004], [407.89000000000004, 419.70000000000005], [419.70000000000005, 431.29], [431.29, 441.62], [441.62, 456.76], [456.76, 467.64], [467.64, 479.69], [479.69, 490.9], [490.9, 501.77], [501.77, 511.82], [511.82, 525.3], [525.3, 538.39], [538.39, 548.74], [548.74, 559.819], [559.819, 572.37], [572.37, 583.1], [583.1, 593.95], [593.95, 605.62], [605.62, 618.77], [618.77, 632.15], [632.15, 645.8], [645.8, 656.2199999999999], [656.2199999999999, 666.6499999999999], [666.6499999999999, 679.5499999999998], [679.5499999999998, 691.0499999999998], [691.0499999999998, 702.7499999999999], [702.7499999999999, 715.5499999999998], [715.5499999999998, 729.8999999999999], [729.8999999999999, 740.9399999999998], [740.9399999999998, 754.1299999999999], [754.1299999999999, 765.4799999999999], [765.4799999999999, 775.5999999999999], [775.5999999999999, 786.1899999999999], [786.1899999999999, 799.05], [799.05, 809.795], [809.795, 821.069], [821.069, 831.64], [831.64, 841.77], [841.77, 854.4399999999999], [854.4399999999999, 868.7099999999999], [868.7099999999999, 881.3499999999999], [881.3499999999999, 893.1099999999999], [893.1099999999999, 905.3599999999999], [905.3599999999999, 916.2699999999999], [916.2699999999999, 928.1299999999999], [928.1299999999999, 941.1699999999998], [941.1699999999998, 953.1199999999999], [953.1199999999999, 963.6799999999998], [963.6799999999998, 976.0799999999998], [976.0799999999998, 987.0499999999998], [987.0499999999998, 997.9999999999999], [997.9999999999999, 1009.6199999999999], [1009.6199999999999, 1019.9899999999999], [1019.9899999999999, 1035.3799999999999], [1035.3799999999999, 1045.4799999999998], [1045.4799999999998, 1057.5899999999997], [1057.5899999999997, 1069.0999999999997], [1069.0999999999997, 1080.7699999999998], [1080.7699999999998, 1093.7799999999997], [1093.7799999999997, 1104.0199999999998], [1104.0199999999998, 1114.9589999999998], [1114.9589999999998, 1125.0299999999997], [1125.0299999999997, 1138.3889999999997], [1138.3889999999997, 1149.5399999999997], [1149.5399999999997, 1160.7699999999998], [1160.7699999999998, 1172.5999999999997], [1172.5999999999997, 1183.9089999999997], [1183.9089999999997, 1198.7989999999998], [1198.7989999999998, 1209.1199999999997], [1209.1199999999997, 1220.4689999999996], [1220.4689999999996, 1230.7099999999996], [1230.7099999999996, 1241.3499999999997], [1241.3499999999997, 1252.3699999999997], [1252.3699999999997, 1264.4889999999996], [1264.4889999999996, 1274.7599999999995], [1274.7599999999995, 1288.9089999999994], [1288.9089999999994, 1300.8499999999995], [1300.8499999999995, 1311.3549999999996], [1311.3549999999996, 1324.5299999999995], [1324.5299999999995, 1334.9999999999995], [1334.9999999999995, 1339.5999999999995]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [460, 1069, 1339]}
{"example_id": "mit001@@ocw-18.01-f07-lec32_300k", "text": ["PROFESSOR: Today we're going to continue our discussion  of parametric curves.  I have to tell you about arc length.  And let me remind me where we left off last time. ", "This is parametric curves, continued. ", "Last time, we talked about the parametric representation  for the circle.  Or one of the parametric representations for the circle. ", "Which was this one here.  And first we noted that this does parameterize, ", "as we say, the circle.  That satisfies the equation for the circle.  And it's traced counterclockwise. ", "The picture looks like this.  Here's the circle.  And it starts out here at t = 0 and it gets up to  here at time t = pi / 2. ", "So now I have to talk to you about arc length. ", "In this parametric form.  And the results should be the same as arc length around  this circle ordinarily.  And we start out with this basic differential ", "relationship. dx ^2 is dx ^2 + dy ^2.  And then I'm going to take the square root, divide by dt, so ", "the rate of change with respect to t of s is going to  be the square root.  Well, maybe I'll write it without dividing.  Just write it as ds. ", "So this would be (dx / dt)^2 + (dy / dt)^2 dt.  So this is what you get formally from this equation. ", "If you take its square roots and you divide by dt squared in  the inside, the square root and you multiply by dt outside.  So that those cancel.  And this is the formal connection between the two. ", "We'll be saying just a few more words in a few minutes about  how to make sense of that rigorously.  Alright so that's the set of formulas for the infinitesimal, ", "the differential of arc length.  And so to figure it out, I have to differentiate  x with respect to t.  And remember x is up here.  It's defined by a cos t, so its derivative is - a sin t. ", "And similarly, dy / dt = a cos t.  And so I can plug this in. ", "And I get the arc length element, which is the  square root of )- a sin t) ^2 (+ a cos t) ^2 dt. ", "Which just becomes the square root of a ^2 dt, or a dt.  Now, I was about to divide by t. ", "Let me do that now.  We can also write the rate of change of arc length  with respect to t.  And that's a, in this case.  And this gets interpreted as the speed of the ", "particle going around.  So not only, let me trade these two guys, not only do we  have the direction is counterclockwise, but we also ", "have that the speed is, if you like, it's uniform.  It's constant speed.  And the rate is a.  So that's ds / dt. ", "Travelling around.  And that means that we can play around with the speed.  And I just want to point out. ", "So the standard thing, what you'll have to get used to,  and this is a standard presentation, you'll  see this everywhere.  In your physics classes and your other math classes, if you  want to change the speed, so a new speed going around this ", "would be, if I set up the equations this way.  Now I'm tracing around the same circle. ", "But the speed is going to turn out to be, if you figure it  out, there'll be an extra factor of k.  So it'll be a k. ", "That's what we'll work out to be the speed.  Provided k is positive and a is positive.  So we're making these conventions. ", "The constants that we're using are positive.  Now, that's the first and most basic example. ", "The one that comes up constantly.  Now, let me just make those comments about notation  that I wanted to make.  And we've been treating these squared differentials here for ", "a little while and I just want to pay attention a little  bit more carefully to these manipulations.  And what's allowed and what's not.  And what's justified and what's not.  So the basis for this was this approximate calculation that we ", "had, that delta s ^2 was delta x ^2 + delta y ^2.  This is how we justified the arc length formula before. ", "And let me just show you that the formula that I have up  here, this basic formula for arc length in the parametric  form, follows just as the other one did. ", "And now I'm going to do it slightly more rigorously.  I do the division really in disguise before I take the  limit of the infinitesimal. ", "So all I'm really doing is I'm doing this.  Dividing through by this, and sorry this is still  approximately equal.  So I'm not dividing by something that's 0  or infinitesimal. ", "I'm dividing by something non-0.  And here I have (delta x/ delta t) ^2 + (delta y / delta t) ^2. ", "And then in the limit, I have ds / dt = to the square  root of this guy.  Or, if you like, the square of it, so. ", "So it's legal to divide by something that's almost  0 and then take the limit as we go to 0.  This is really what derivatives are all about.  That we get a limit here. ", "As the denominator goes to 0.  Because the numerator's going to 0 too.  So that's the notation.  And now I want to warn you, maybe just a little bit, ", "about misuses, if you like, of the notation.  We don't do absolutely everything this way.  This expression that came up with the squares, you should ", "never write it as this.  This, put it on the board but very quickly, never. ", "OK.  Don't do that.  We use these square differentials, but we don't do  it with these ratios here. ", "But there was another place which is slightly confusing.  It looks very similar, where we did use the square of the  differential in a denominator.  And I just want to point out to you that it's different. ", "It's not the same.  And it is OK.  And that was this one.  This thing here. ", "This is a second derivative, it's something else.  And it's got a dt squared in the denominator.  So it looks rather similar.  But what this represents is the quantity d / dt ^2. ", "And you can see the squares came in.  And squared the two expressions.  And then there's also an x over here.  So that's legal. ", "Those are notations that we do use.  And we can even calculate this.  It has a perfectly good meaning.  It's the same as the derivative with respect to t of the  derivative of x, which we already know was - sine. ", "Sorry, a sine t, I guess.  Not this example, but the previous one.  Up here.  So the derivative is this and so I can differentiate ", "a second time.  And I guess - a cosine t.  So that's a perfectly legal operation.  Everything in there makes sense.  Just don't use that. ", "There's another really unfortunate thing, right which  is that the 2 creeps in funny places with signs.  You have sin^2.   It would be out here, it comes up here for ", "some strange reason.  This is just because typographers are lazy or  somebody somewhere in the history of mathematical  typography decided to let the 2 migrate. ", "It would be like putting the 2 over here.  There's inconsistency in mathematics right.  We're not perfect and people just develop these notations. ", "So we have to live with them.  The ones that people accept as conventions.  The next example that I want to give you is just ", "slightly different.  It'll be a non-constant speed parameterization.  Here x = 2 sine t.  And y = say, cosine t. ", "And let's keep track of what this one does.  Now, this is a skill which I'm going to ask you  about quite a bit.  And it's one of several skills.  You'll have to connect this with some kind of ", "rectangular equation.  An equation for x and y.  And we'll be doing a certain amount of this today.  In another context.  Right here, to see the pattern, we know that the relationship ", "we're going to want to use is that sin^2 + cos^2 = 1.  So in fact the right thing to do here is to take  1/4 x ^2 + y ^2. ", "And that's going to turn out to be sin ^2 t + cos ^2 t.  Which is 1.  So there's the equation.  Here's the rectangular equation for this parametric curve. ", "And this describes an ellipse.  That's not the only information that we can get here. ", "The other information that we can get is this qualitative  information of where we start, where we're going,  the direction.  It starts out, I claim, at t = 0. ", "That's when t = = 0, this is (2 sine 0, cosine 0), right? (2  sine 0, cosine 0) = the point (0, 1). ", "So it starts up, up here.  At (0, 1).  And then the next little place, so this is one thing that  certainly you want to do. t = pi / 2 is maybe the next ", "easy point to plot.  And that's going to be (2 sine pi / 2, cosine pi / 2). ", "And that's just (2, 0).  And so that's over here somewhere.  This is (2, 0). ", "And we know it travels along the ellipse.  And we know the minor axis is 1, and the major axis  is 2, so it's doing this.  So this is what happens at t = 0. ", "This is where we are at t = pi / 2.  And it continues all the way around, etc.  To the rest of the ellipse.  This is the direction. ", "So this one happens to be clockwise. ", "Alright, now let's keep track of its speed.  Let's keep track of the speed, and also the arc length. ", "So the speed is the square root of the derivatives here.  That would be (2 cosine t) ^2 + (sine t) ^2. ", "And the arc length is what?  Well, if we want to go all the way around, we need to know  that that takes a total of 2 pi. ", "So 0 to 2 pi.  And then we have to integrate ds, which is this expression.  Or ds/ dt, dt.  So that's the square root of 4 cosine^2 t + sine ^2 t dt. ", "The bad news, if you like, is that this is not an  elementary integral. ", "In other words, no matter how long you try to figure out how  to antidifferentiate this expression, no matter how  many substitutions you try, you will fail. ", "That's the bad news.  The good news is this is not an elementary integral.  It's not an elementary integral.  Which means that this is the answer to a question. ", "Not something that you have to work on.  So if somebody asks you for this arc length, you stop here.  That's the answer, so it's actually better than it looks. ", "And we'll try to -- I mean, I don't expect you to know  already what all of the integrals are that  are impossible.  And which ones are hard and which ones are easy. ", "So we'll try to coach you through when you  face these things.  It's not so easy to decide.  I'll give you a few clues, but. ", "OK.  So this is the arc length.  Now, I want to move on to the last thing that we did.  Last type of thing that we did last time. ", "Which is the surface area. ", "And yeah, question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: The question, this is a good question.  The question is, when you draw the ellipse, do you not take  into account what t is.  The answer is that this is in disguise. ", "What's going on here is we have a trouble with plotting in the  plane what's really happening.  So in other words, it's kind of in trouble. ", "So the point is that we have two functions of t, not  one. x ( t) and y ( t).  So one thing that I can do if I plot things in the plane.  In other words, the main point to make here is that we're not ", "talking about the situation. y is a function of x.  We're out of that realm now.  We're somewhere in a different part of the universe  in our thought.  And you should drop this point of view. ", "So this depiction is not y as a function of x.  Well, that's obvious because there are two values  here, as opposed to one.  So we're in trouble with that.  And we have that background parameter, and that's ", "exactly why we're using it.  This parameter t.  So that we can depict the entire curve.  And deal with it as one thing.  So since I can't really draw it, and since t is nowhere on ", "the map, you should sort of imagine it as time, and there's  some kind of trajectory which is travelling around.  And then I just labelled a couple of the places.  If somebody asked you to draw a picture of this, well, I'll ", "tell you exactly where you need the picture in just  one second, alright.  It's going to come up right now in surface area.  But otherwise, if nobody asks you to, you don't even have to ", "put down t = 0 and t = pi / 2 here.  Because nobody demanded it of you.  Another question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: So, another very good question which is exactly  connected to this picture.  So how is it that we're going to use the picture, and how is  it we're going to use the notion of the t. ", "The question was, why is this from t = 0 to t = 2 pi?  That does use the t information on this diagram. the point is,  we do know that t starts here. ", "This is pi / 2, this is pi, this is 3 pi /  2, and this is 2 pi.  When you go all the way around once, it's going  to come back to itself.  These are periodic functions of period 2 pi. ", "And they come back to themselves exactly at 2 pi.  And so that's why we know in order to get around once, we  need to go from 0 to 2 pi.  And the same thing is going to come up with surface ", "area right now.  That's going to be the issue, is what range of t we're going  to need when we compute the surface area. ", "STUDENT: [INAUDIBLE]  PROFESSOR: In a question, what you might be asked is what's  the rectangular equation for a parametric curve? ", "So that would be 1/4 x^2 + y ^2 = 1.  And then you might be asked, plot it.  Well, that would be a picture of the ellipse.  OK, those are types of questions that are ", "legal questions.  STUDENT: [INAUDIBLE] ", "PROFESSOR: The question is, do I need to know  any specific formulas?  Any formulas that you know and remember will help you.  They may be of limited use.  I'm not going to ask you to memorize anything except, ", "I guarantee you that the circle is going to come up.  Not the ellipse, the circle will come up everywhere  in your life.  So at least at MIT, your life at MIT.  We're very round here. ", "Yeah, another question.  STUDENT: I'm just a tiny bit confused back to the basics.  This is more a question from yesterday, I guess.  But when you have your original ds^2= dx^2 + dy ^2, and then ", "you integrate that to get arc length, how are you, the  integral has dx's and dy's. ", "So how are you just integrating with respect to dx?  PROFESSOR: OK, the question is how are we just integrating  with respect to x? ", "So this is a question which goes back to last time.  And what is it with arc length. so.  I'm going to have to answer that question in connection ", "with what we did today.  So this is a subtle question.  But I want you to realize that this is actually an important  conceptual step here.  So shhh, everybody, listen. ", "If you're representing one-dimensional objects, which  are curves, maybe, in space.  Or in two dimensions.  When you're keeping track of arc length, you're going to ", "have to have an integral which is with respect  to some variable.  But that variable, you get to pick.  And we're launching now into this variety of choices of ", "variables with respect to which you can represent something.  Now, there are some disadvantages on the circle  to representing things with respect to the variable x.  Because there are two points on the circle here. ", "On the other hand, you actually can succeed  with half the circle.  So you can figure out the arc length that way.  And then you can set it up as an integral dx.  But you can also set it up as an integral with respect ", "to any parameter you want.  And the uniform parameter is perhaps the easiest one.  This one is perhaps the easiest one.  And so now the thing that's strange about this perspective, ", "and I'm going to make this point later in the  lecture as well.  Is that the letters x and y, as I say, you should drop this  notion that y is a function of x. ", "This is what we're throwing away at this point.  What we're thinking of is, you can describe things in terms  of any coordinate you want.  You just have to say what each one is in terms of the others. ", "And these x and y over here are where we are in the  Cartesian coordinate system.  They're not, and in this case they're functions ", "of some other variable.  Some other variable.  So they're each functions.  So the letters x and y just changed on you.  They mean something different. x is no longer the variable. ", "It's the function.  Right?  You're going to have to get used to that.  That's because we run out of letters.  And we kind of want to use all of them the way we want. ", "I'll say some more about that later.  So now I want to do this surface area example.  I'm going to just take the surface area of the ellipsoid. ", "The surface of the ellipsoid formed by revolving ", "this previous example, which was Example 2.  Around the y axis. ", "So we want to set up that surface area integral  here for you.  Now, I remind you that the area element looks like this. ", "If you're revolving around the y axis, that means you're  going around this way and you have some curve.  In this case it's this piece of an ellipse.  If you sweep it around you're going to get what's  called an ellipsoid. ", "And there's a little chunk here, that you're  wrapping around.  And the important thing you need besides this ds, this arc ", "length piece over here, is the distance to the axis.  So that's this horizontal distance here.  I'll draw it in another color. ", "And that horizontal distance now has a name.  And this is, again, the virtue of this coordinate system.  The t is something else. ", "This has a name.  This distance has a name.  This distance is called x.  And it even has a formula.  Its formula is 2 sin t. ", "In terms of t.  So the full formula up for the integral here is, I have to  take the circumference when I spin this thing around. ", "And this little arc length element.  So I have here 2 pi ( 2 sin t).  That's the x variable here.  And then I have here ds, which is kind of a mess. ", "So unfortunately I don't quite have room for it.  Plan ahead.  Square root of 4 cos^2 t + sin^2 t, is that ", "what it was, dt?  Alright, I guess I squeezed it in there.  So that was the arc length, which I re-copied from  this board above.  That was the ds piece. ", "It's this whole thing including the dt.  That's the answer except for one thing.  What else do we need?  We don't just need the integrand, this is half of ", "setting up an integral.  The other half of setting up an integral is the limits.  We need specific limits here.  Otherwise we don't have a number that we can get out. ", "So we now have to think about what the limits are.  And maybe somebody can see.  It has something to do with this diagram of  the ellipse over here.  Can somebody guess what it is? ", "0 to pi.  Well, that was quick.  That's it.  Because we go from the top to the bottom, but we don't  want to continue around.  We don't want to go from 0 to 2 pi, because that would be ", "duplicating what we're going to get when we spin around.  And we know that we start at 0.  It's interesting because it descends when you change  variables to think of it in terms of the y variable it's ", "going the opposite way.  But anyway, just one piece of this is what we want.  So that's this setup.  And now I claim that this is actually a doable integral. ", "However, it's long.  I'm going to spare you, I'll just tell you how  you would get started.  You would use the substitution u = cos t.  And then the du is going to be - sin t dt. ", "But then, unfortunately, there's a lot more.  There's another trig substitution with some  other multiple of the cosine and so forth.  So it goes on and on.  If you want to check it yourself, you can. ", "There's an inverse trig substitution which isn't  compatible with this one.  But it can be done. ", "Calculated.  In elementary terms.  Yeah, another question. ", "STUDENT: [INAUDIBLE]  PROFESSOR: So, if you get this on an exam, I'm going to have  to coach you through it.  Either I'm going to have to tell you don't evaluate it  or, you're going to have to work really hard.  Or here's the first step, and then the next step ", "is, keep on going.  Or something.  I'll have to give you some cues.  Because it's quite long.  This is way too long for an exam, this particular one. ", "OK.  It's not too long for a problem set.  This is where I would leave you off if I were giving it  to you on a problem set.  Just to give you an idea of the order of magnitude.  Whereas one of the ones that I did yesterday, I wouldn't even ", "give you on a problem set, it was so long.  So now, our next job is to move on to polar coordinates. ", "Now, polar coordinate involve the geometry of circles.  As I said, we really love circles here.  We're very around.  Just as I love 0, the rest of the Institute loves circles. ", "So we're going to do that right now. ", "What we're going to talk about now is polar coordinates. ", "Which are set up in the following way.  It's a way of describing the points in the plane.  Here is a point in a plane, and here's what we think  of as the usual x-y axes. ", "And now this point is going to be described by a different  pair of coordinates, different pair of numbers.  Namely, the distance to the origin. ", "And the second parameter here, second number here,  is this angle theta.  Which is the angle of ray from origin with the ", "horizontal axis.  So that's what it is in language.  And you should put this in quotation marks, because ", "it's not a perfect match.  This is geometrically what you should always think of, but the  technical details involve dealing directly with formulas. ", "The first formula is the formula for x.  And this is the fundamental, these two are the  fundamental ones.  Namely, x = r cos theta. ", "The second formula is the formula for y, which  is r sin theta.  So these are the unambiguous definitions  of polar coordinates. ", "This is it.  And this is the thing from which all other almost correct  statements almost follow. ", "But this is the one you should trust always.  This is the un ambiguous statement.  So let me give you an example something that's close to ", "being a good formula and is certainly useful in its way. ", "Namely, you can think of r as being the square  root of x ^2 + y ^2.  That's easy enough to derive, it's the ", "distance to the origin.  That's pretty obvious.  And the formula for theta, which you can also derive,  which is that it's the inverse tangent of y / x. ", "However, let me just warn you that these formulas  are slightly ambiguous.  So somewhat ambiguous. ", "In other words, you can't just apply them blindly.  You actually have to look at a picture in order  to get them right.  In particular, r could be plus or minus here. ", "And when you take the inverse tangent, there's an ambiguity  between, it's the same as the inverse tangent of - y / - x. ", "So these minus signs are a plague on your existence.  And you're not going to get a completely unambiguous answer  out of these formulas without paying attention ", "to the diagram.  On the other hand, the formula up in the box  there always works.  So when people mean polar coordinates,  they always mean that. ", "And then they have conventions, which sometimes match things up  with the formulas over on this next board. ", "Let me give you various examples here first.  But maybe first I should I should draw the two  coordinate systems. ", "So the coordinate system that we're used to is the  rectangular coordinate system.  And maybe I'll draw it in orange and green here. ", "So these are the coordinate lines y = 0, y = 1, y = 2. ", "That's how the coordinate system works.  And over here we have the rest of the coordinate system.  And this is the way we're thinking of x and y now. ", "We're no longer thinking of y as a function of x and x as a  function of y, we're thinking of x as a label of a  place in a plane.  And y as a label of a place in a plane. ", "So here we have x = 0, x = 1, x = 2, etc.  Here's x = - 1. ", "So forth.  So that's what the rectangular coordinate system looks like.  And now I should draw the other coordinate system that we have. ", "Which is this guy here.  Well, close enough.  And these guys here. ", "Kind of this bulls-eye or target operation.  And this one is, say, theta = pi / 2.  This is theta = 0.  This is theta = - pi / 4. ", "For instance, so I've just labeled for you three of  the rays on this diagram. ", "It's kind of like a radar screen.  And then in pink, this is maybe r = 2, the radius 2. ", "And inside is r = 1.  So it's a different coordinate system for the plane. ", "And again, the letter r represents measuring how far  we are from the origin.  The theta represents something about the angle,  which ray we're on. ", "And they're just two different variables.  And this is a very different kind of coordinate system. ", "OK so, our main job is just to get used to this.  For now.  You will be using this a lot in 18.02.  It's very useful in physics. ", "And our job is just to get started with it.  And so, let's try a few examples here.  Tons of examples. ", "We'll start out very slow.  If you have (x, y) = (1, - 1), that's a point in the plane. ", "I can draw that point.  It's down here, right?  This is - 1 and this is 1, and here's my point, (1, - 1).  I can figure out what the representative is of this ", "in polar coordinates.  So in polar coordinates, there are actually a  bunch of choices here. ", "First of all, I'll tell you one choice.  If I start with the angle horizontally, I wrap  all the way around.  That would be to this ray here, let's do it in green again. ", "Alright, I labeled it actually as - pi / 4, but another way of  looking at over here it is that it's this angle here.  So that would be r = square root of 2. ", "Theta = 7 pi / 4.  So that's one possibility of the angle and the distance. ", "I know the distance is a square root of 2, that's not hard.  Another way of looking at it is the way which was suggested  when I labeled this with a negative angle. ", "And that would be r = square root of 2, theta = - pi / 4.  And these are both legal.  These are perfectly legal representatives.  And that's what I meant by saying that these ", "representations over here are somewhat ambiguous.  There's more than one answer to this question, of what  the polar representation is.  A third possibility, which is even more dicey but also legal, ", "is r = - square root of 2.  Theta = 3 pi / 4.  Now, what that corresponds to doing is going around to here. ", "We're pointing out 3/4 pi, direction.  But then going negative square root of 2, distance.  We're going backwards.  So we're landing in the same place. ", "So this is also legal.  Yeah.  STUDENT: [INAUDIBLE]  PROFESSOR: The question is, don't the radiuses have to be ", "positive because they represent a distance to the origin?  The answer is I lied to you here.  All of these things that I said are wrong, except for this. ", "Which is the rule for what polar coordinates mean.  So it's maybe plus or minus the distance, is what it is always. ", "I try not to lie to you too much, but I do succeed.  Now, let's do a little bit more practice here. ", "There are some easy examples, which I will run through very  quickly. r = a, we already know this is a circle.  And the 3 theta = a constant is a ray. ", "However, this involves an implicit assumption, which I  want to point out to you.  So this is Example 3.  Theta's equal to a constant as a ray. ", "But this implicitly assumes 0 <= r < infinity. ", "If you really wanted to allow minus infinity < r < infinity  in this example, you would get a line.  Gives the whole line. ", "It gives everything behind.  So you go out on some ray, you go backwards on that ray and  you get the whole line through the origin, both ways.  If you allow r going to minus infinity as well. ", "So the typical conventions, so here are the  typical conventions. ", "And you will see people assume this without even telling you.  So you need to watch out for it.  The typical conventions are certainly this one, which  is a nice thing to do. ", "Pretty much all the time, although not all the time.  Most of the time.  And then you might have theta ranging from minus pi to ", "pi, so in other words symmmetric around 0.  Or, another very popular choice is this one.  Theta's >= 0 and strictly less than 2 pi. ", "So these are the two typical ranges in which all of these  variables are chosen.  But not always.  You'll find that it's not consistent. ", "As I said, our job is to get used to this.  And I need to work up to some slightly more  complicated examples.  Some of which I'll give you on next Tuesday. ", "But let's do a few more.  So, I guess this is Example 4. ", "Example 4, I'm going to take y = 1.  That's awfully simple in rectangular coordinates. ", "But interestingly, you might conceivably want to deal with  it in polar coordinates.  If you do, so here's how you make the translation.  But this translation is not so terrible. ", "What you do is, you plug in y = r sin theta.  That's all you have to do.  And so that's going to be equal to 1. ", "And that's going to give us our polar equation.  The polar equation is r = 1 / sin theta.  There it is. ", "And let's draw a picture of it.  So here's a picture of the line y = 1.  And now we see that if we take our rays going out from ", "here, they collide with the line at various lengths.  So if you take an angle, theta, here there'll be a distance r ", "corresponding to that and you'll hit this in  exactly one spot.  For each theta you'll have a different radius.  And it's a variable radius.  It's given by this formula here. ", "And so to trace this line out, you actually have to realize  that there's one more thing involved.  Which is the possible range of theta. ", "Again, when you're doing integrations you're going  to need to know those limits of integration.  So you're going to need to know this.  The range here goes from theta = 0, that's sort of when  it's out at infinity. ", "That's when the denominator is 0 here.  And it goes all the way to pi.  Swing around just one half-turn.  So the range here is 0 < theta < pi. ", "Yeah, question.  STUDENT: [INAUDIBLE]  PROFESSOR: The question is, is it typical to express r as a  function of theta, or vice versa, or does it matter? ", "The answer is that for the purposes of this course, we're  almost always going to be writing things in this form.  r as a function of theta. ", "And you can do whatever you want.  This turns out to be what we'll be doing in this  course, exclusively. ", "As you'll see when we get to other examples, it's the  traditional sort of thing to do when you're thinking about  observing a planet or something like that. ", "You see the angle, and then you guess far away it is.  But it's not necessary.  The formulas are often easier this way. ", "For the examples that we have.  Because it's usually a trig function of theta.  Whereas the other way, it would be an inverse trig function.  So it's an uglier expression. ", "As you can see.  The real reason is that we choose this thing that's  easier to deal with. ", "So now let me give you a slightly more complicated  example of the same type.  Where we use a shortcut.  This is a standard example. ", "And it comes up a lot.  And so this is an off-center circle.  A circle is really easy to describe, but not necessarily ", "if the center is on the rim of the circle.  So that's a different problem. ", "And let's do this with a circle of radius a.  So this is the point (a, 0) and this is (2a, 0). ", "And actually, if you know these two numbers, you'll be able  to remember the result of this calculation.  Which you'll do about five or six times and then finally  you'll memorize it during 18.02 when you will need it a lot. ", "So this is a standard calculation here.  So the starting place is the rectangular equation.  And we're going to pass to the polar representation. ", "The rectangular representation is (x - a) ^2 + y ^2 = a ^2.  So this is a circle centered at (a, 0) of radius a. ", "And now, if you like, the slow way of doing this would be to  plug in x = r cos theta, y = r sin theta. ", "The way I did in this first step.  And that works perfectly well.  But I'm going to do it more quickly than that.  Because I can sort of see in advance how it's going to work. ", "I'm just going to expand this out.  And now I see the a ^2's cancel. ", "And not only that, but x^2 + y &2 = r ^2.  So this becomes r ^2.  That's x ^2 + y ^2 - 2ax = 0. ", "The r came from the fact that r ^2 = x ^2 + y ^2.  So I'm doing this the rapid way.  You can do it by plugging in, as I said. r equals. ", "So now that I've simplified it, I am going to  use that procedure.  I'm going to plug in.  So here I have r ^2 - 2a r cos theta = 0. ", "I just plugged in for x.  As I said, I could have done that at the beginning.  I just simplified first.  And now, this is the same thing as r ^2 = 2ar cos theta. ", "And we're almost done.  There's a boring part of this equation, which is r = 0.  And then there's, if I divide by r, there's the interesting ", "part of the equation.  Which is this.  So this is or r = 0.  Which is already included in that equation anyway. ", "So I'm allowed to divide by r because in the case of r = 0,  this is represented anyway.  Question.  STUDENT: [INAUDIBLE] ", "PROFESSOR: r = 0 is just one case.  That is, it's the union of these two.  It's both.  Both are possible.  So r = 0 is one point on it.  And this is all of it. ", "So we can just ignore this.  So now I want to say one more important thing.  You need to understand the range of this. ", "So wait a second and we're going to figure out  the range here.  The range is very important, because otherwise you'll never  be able to integrate using this representation here. ", "So this is the representation.  But notice when theta = 0, we're out here at 2a.  That's consistent, and that's actually how you remember  this factor 2a here. ", "Because if you remember this picture and where  you land when theta = 0.  So that's the theta = 0 part.  But now as I tip up like this, you see that when we get ", "to vertical, we're done.  With the circle.  It's gotten shorter and shorter and shorter, and at theta  = pi / 2, we're down at 0.  Because that's cos pi / 2 = 0. ", "So it swings up like this.  And it gets up to pi / 2.  Similarly, we swing down like this.  And then we're done.  So the range is - pi / 2 < theta < pi / 2. ", "Or, if you want to throw in the r = 0 case, you can throw  in this, this is repeating, if you like, at the ends.  So this is the range of this circle. ", "And let's see.  Next time we'll figure out area in polar coordinates.  "], "vid_duration": [11.0, 12.0, 10.0, 10.0, 12.0, 14.0, 10.0, 13.0, 10.0, 11.0, 12.0, 12.0, 16.0, 16.0, 11.0, 14.0, 10.0, 15.0, 13.0, 12.0, 10.0, 16.0, 13.0, 11.0, 14.0, 10.0, 12.0, 14.0, 10.0, 10.0, 10.0, 10.0, 10.0, 17.0, 11.0, 14.0, 11.0, 12.0, 11.0, 10.0, 11.0, 16.0, 11.0, 12.0, 12.0, 15.0, 11.0, 10.0, 11.0, 12.0, 14.0, 12.0, 11.0, 11.0, 13.0, 11.0, 11.0, 14.0, 12.0, 10.0, 12.0, 11.0, 12.0, 12.0, 16.0, 17.0, 11.0, 27.0, 18.0, 12.0, 13.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 12.0, 13.0, 13.0, 12.0, 11.0, 12.0, 11.0, 12.0, 12.0, 10.0, 11.0, 10.0, 11.0, 11.0, 12.0, 12.0, 18.0, 11.0, 14.0, 12.0, 10.0, 10.0, 11.0, 14.0, 12.0, 11.0, 12.0, 10.0, 14.0, 12.0, 11.0, 10.0, 12.0, 11.0, 15.0, 16.0, 13.0, 10.0, 10.0, 10.0, 11.0, 11.0, 16.0, 11.0, 13.0, 13.0, 11.0, 12.0, 10.0, 12.0, 10.0, 10.0, 18.0, 17.0, 13.0, 11.0, 14.0, 11.0, 10.0, 10.0, 15.0, 11.0, 19.0, 11.0, 12.0, 16.0, 17.0, 10.0, 13.0, 10.0, 11.0, 10.0, 10.0, 10.0, 10.0, 14.0, 12.0, 10.0, 13.0, 11.0, 10.0, 10.0, 11.0, 11.0, 10.0, 11.0, 10.0, 10.0, 11.0, 13.0, 13.0, 10.0, 11.0, 10.0, 12.0, 20.0, 10.0, 11.0, 10.0, 13.0, 11.0, 14.0, 12.0, 10.0, 10.0, 12.0, 14.0, 13.0, 12.0, 11.0, 11.0, 17.0, 15.0, 15.0, 10.0, 13.0, 14.0, 11.0, 10.0, 11.0, 12.0, 13.0, 18.0, 14.0, 13.0, 10.0, 12.0, 10.0, 12.0, 15.0, 11.0, 10.0, 10.0, 11.0, 12.0, 13.0, 11.0, 10.0, 11.0, 10.0, 10.0, 11.0, 12.0, 14.0, 11.0, 10.0, 11.0, 10.0, 13.0, 10.0, 10.0, 13.0, 15.0, 14.0, 15.0, 14.0, 11.0, 11.0, 11.0, 12.0, 10.0, 12.0, 11.0, 11.0, 11.0, 13.0, 10.0, 8.0], "stet": [[0, 11.0], [11.0, 23.0], [23.0, 33.0], [33.0, 43.0], [43.0, 55.0], [55.0, 69.0], [69.0, 79.0], [79.0, 92.0], [92.0, 102.0], [102.0, 113.0], [113.0, 125.0], [125.0, 137.0], [137.0, 153.0], [153.0, 169.0], [169.0, 180.0], [180.0, 194.0], [194.0, 204.0], [204.0, 219.0], [219.0, 232.0], [232.0, 244.0], [244.0, 254.0], [254.0, 270.0], [270.0, 283.0], [283.0, 294.0], [294.0, 308.0], [308.0, 318.0], [318.0, 330.0], [330.0, 344.0], [344.0, 354.0], [354.0, 364.0], [364.0, 374.0], [374.0, 384.0], [384.0, 394.0], [394.0, 411.0], [411.0, 422.0], [422.0, 436.0], [436.0, 447.0], [447.0, 459.0], [459.0, 470.0], [470.0, 480.0], [480.0, 491.0], [491.0, 507.0], [507.0, 518.0], [518.0, 530.0], [530.0, 542.0], [542.0, 557.0], [557.0, 568.0], [568.0, 578.0], [578.0, 589.0], [589.0, 601.0], [601.0, 615.0], [615.0, 627.0], [627.0, 638.0], [638.0, 649.0], [649.0, 662.0], [662.0, 673.0], [673.0, 684.0], [684.0, 698.0], [698.0, 710.0], [710.0, 720.0], [720.0, 732.0], [732.0, 743.0], [743.0, 755.0], [755.0, 767.0], [767.0, 783.0], [783.0, 800.0], [800.0, 811.0], [811.0, 838.0], [838.0, 856.0], [856.0, 868.0], [868.0, 881.0], [881.0, 892.0], [892.0, 902.0], [902.0, 912.0], [912.0, 922.0], [922.0, 932.0], [932.0, 942.0], [942.0, 954.0], [954.0, 967.0], [967.0, 980.0], [980.0, 992.0], [992.0, 1003.0], [1003.0, 1015.0], [1015.0, 1026.0], [1026.0, 1038.0], [1038.0, 1050.0], [1050.0, 1060.0], [1060.0, 1071.0], [1071.0, 1081.0], [1081.0, 1092.0], [1092.0, 1103.0], [1103.0, 1115.0], [1115.0, 1127.0], [1127.0, 1145.0], [1145.0, 1156.0], [1156.0, 1170.0], [1170.0, 1182.0], [1182.0, 1192.0], [1192.0, 1202.0], [1202.0, 1213.0], [1213.0, 1227.0], [1227.0, 1239.0], [1239.0, 1250.0], [1250.0, 1262.0], [1262.0, 1272.0], [1272.0, 1286.0], [1286.0, 1298.0], [1298.0, 1309.0], [1309.0, 1319.0], [1319.0, 1331.0], [1331.0, 1342.0], [1342.0, 1357.0], [1357.0, 1373.0], [1373.0, 1386.0], [1386.0, 1396.0], [1396.0, 1406.0], [1406.0, 1416.0], [1416.0, 1427.0], [1427.0, 1438.0], [1438.0, 1454.0], [1454.0, 1465.0], [1465.0, 1478.0], [1478.0, 1491.0], [1491.0, 1502.0], [1502.0, 1514.0], [1514.0, 1524.0], [1524.0, 1536.0], [1536.0, 1546.0], [1546.0, 1556.0], [1556.0, 1574.0], [1574.0, 1591.0], [1591.0, 1604.0], [1604.0, 1615.0], [1615.0, 1629.0], [1629.0, 1640.0], [1640.0, 1650.0], [1650.0, 1660.0], [1660.0, 1675.0], [1675.0, 1686.0], [1686.0, 1705.0], [1705.0, 1716.0], [1716.0, 1728.0], [1728.0, 1744.0], [1744.0, 1761.0], [1761.0, 1771.0], [1771.0, 1784.0], [1784.0, 1794.0], [1794.0, 1805.0], [1805.0, 1815.0], [1815.0, 1825.0], [1825.0, 1835.0], [1835.0, 1845.0], [1845.0, 1859.0], [1859.0, 1871.0], [1871.0, 1881.0], [1881.0, 1894.0], [1894.0, 1905.0], [1905.0, 1915.0], [1915.0, 1925.0], [1925.0, 1936.0], [1936.0, 1947.0], [1947.0, 1957.0], [1957.0, 1968.0], [1968.0, 1978.0], [1978.0, 1988.0], [1988.0, 1999.0], [1999.0, 2012.0], [2012.0, 2025.0], [2025.0, 2035.0], [2035.0, 2046.0], [2046.0, 2056.0], [2056.0, 2068.0], [2068.0, 2088.0], [2088.0, 2098.0], [2098.0, 2109.0], [2109.0, 2119.0], [2119.0, 2132.0], [2132.0, 2143.0], [2143.0, 2157.0], [2157.0, 2169.0], [2169.0, 2179.0], [2179.0, 2189.0], [2189.0, 2201.0], [2201.0, 2215.0], [2215.0, 2228.0], [2228.0, 2240.0], [2240.0, 2251.0], [2251.0, 2262.0], [2262.0, 2279.0], [2279.0, 2294.0], [2294.0, 2309.0], [2309.0, 2319.0], [2319.0, 2332.0], [2332.0, 2346.0], [2346.0, 2357.0], [2357.0, 2367.0], [2367.0, 2378.0], [2378.0, 2390.0], [2390.0, 2403.0], [2403.0, 2421.0], [2421.0, 2435.0], [2435.0, 2448.0], [2448.0, 2458.0], [2458.0, 2470.0], [2470.0, 2480.0], [2480.0, 2492.0], [2492.0, 2507.0], [2507.0, 2518.0], [2518.0, 2528.0], [2528.0, 2538.0], [2538.0, 2549.0], [2549.0, 2561.0], [2561.0, 2574.0], [2574.0, 2585.0], [2585.0, 2595.0], [2595.0, 2606.0], [2606.0, 2616.0], [2616.0, 2626.0], [2626.0, 2637.0], [2637.0, 2649.0], [2649.0, 2663.0], [2663.0, 2674.0], [2674.0, 2684.0], [2684.0, 2695.0], [2695.0, 2705.0], [2705.0, 2718.0], [2718.0, 2728.0], [2728.0, 2738.0], [2738.0, 2751.0], [2751.0, 2766.0], [2766.0, 2780.0], [2780.0, 2795.0], [2795.0, 2809.0], [2809.0, 2820.0], [2820.0, 2831.0], [2831.0, 2842.0], [2842.0, 2854.0], [2854.0, 2864.0], [2864.0, 2876.0], [2876.0, 2887.0], [2887.0, 2898.0], [2898.0, 2909.0], [2909.0, 2922.0], [2922.0, 2932.0], [2932.0, 2940.0]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [320, 598, 1346, 1669, 2088, 2421, 2637, 2940]}
{"example_id": "mit001@@ocw-18.01-f07-lec38_300k", "text": ["PROFESSOR: Last time we left off with a question having to  do with playing with blocks.  And this is supposed to give us a visceral feel for  something anyway, having to do with series. ", "And the question was whether I could stack these blocks,  build up a stack so that I'm going to try here up.  I'm already off balance here, see. ", "The question is can I build this so that the--  let's draw a picture of it so that the first ", "block is like this.  The next block is like this.  And maybe the next block is like this.  And notice there is no visible means of  support for this block.  It's completely to the left of the first block. ", "And the question is, will this fall down?   Or at least, or more precisely, eventually we'll ", "ask you know, how far can we go?  Now before you answer this question, the claim is it that  this is a kind of a natural, physical question, which ", "involves some important answer.  No matter whether the answer is, you can  do it or you can't.  So this is a good kind of math question where no matter what  the answer is, when you figure out the answer, you're going ", "to get something interesting out of it.  Because they're two possibilities.  Either there is a limit to how far to the left we can go-- in  which case that's a very interesting number-- ", "or else there is no limit.  You can go arbitrarily far.  And that's also interesting and curious.  And that's the difference between convergence and  divergence, the thing that we were talking about up to now ", "concerning series.  So my first question is, do you think that I can get it so  that this thing doesn't fall down with, well you see I have ", "about eight blocks here or so.  So you can vote now.  How many in favor that I can succeed in doing this sort of  thing with maybe more than three blocks.  How many in favor? ", "All right somebody is voting twice.  That's good.  I like that.  How about opposed?   So that was really close to a tie. ", "All right.  But I think the there was slightly more opposed.  I don't know.  You guys who are in the back maybe could tell.  Anyway it was pretty close. ", "All right.  So now I'm going--  because this is a real life thing--  I'm going to try to do it.  All right?  All right.  So now I'm going to tell you what the trick is. ", "The trick is to do it backwards.  When most people are playing with blocks, they decide to  build it from the bottom up. ", "Right?  But we're going to build it from the top down,  from the top down.  And that's going to make it possible for us to do the  optimal thing at each stage. ", "So when I build it from the top down, the best I can do is  well, it'll fall off.  I need to have it you know, halfway across.  That's the best I can do. ", "So the top one I'm going to build like that.  I'm going to take it as far to the left as I can.  And then I'm going to put the next one down as far to the  left as I can. ", "And then the next one as far to the left as I can.  That was a little too far.  And then I'm going to do the next one as far to  the left as I can. ", "And then I'm going to do the next one-- well  let's line it up first--  as far to the left as I can.  OK?  And then the next one as far to the left as I can. ", "All right.  Now those of you who are in this line can see, all right,  I succeeded.  All right, that's over the edge.  All right? ", "So it can be done.  All right.   All right.  So now we know that we can get farther than you know, we can ", "make it overflow.  So the question now is, how far can I get?  OK.  Do you think I can get to here?  Can I get to the end over here? ", "So how many people think I can get this far over to here?  How many people think I can get this far?  Well you know, remember. ", "I'm going to have to use more than just this one more block  that I've got.  I don't, right?  Obviously I'm thinking, actually I do have some more  blocks at home.  But, OK.  We're not going to. ", "But anyway, do you think I can get over to here?  How many people say yes?  And how many people say no?  More people said no then yes. ", "All right.  So maybe the stopping place is some mysterious number in  between here.  All right?  Well OK.  So now we're going to do the arithmetic.  And we're going to figure out what ", "happens with this problem.  OK?  So let's do it.  All right, so now again the idea is, the idea is we're ", "going to start with the top, the top block.   We'll call that block number one. ", " And then the farthest if you like to the right, that you  can put a block underneath it, is exactly halfway. ", " All right well, that's the best job I can do.  Now in order to make my units work out easily, I'm going to ", "decide to call the length of the block 2.  All right?  And that means if I start at location 0, then the first  place where I am is supposed to be halfway. ", "And that will be 1.   OK so the first step in the process is  1 more to the right.  Or if you like, if I were building up-- which is what ", "you would actually have to do in real life--  it would be 1 to the left.  OK now the next one.  Now here is the way that you start figuring out the ", "arithmetic.  The next one is based on a physical principle.  Which is that the farthest I can stick this next block  underneath is what's called the center of mass of these ", "two, which is exactly halfway here.  That is there's 1/4 of this guy, and a 1/4 of that guy  balancing each other.  Right?  So that's as far as I can go.  If I go farther than that, it'll fall over. ", "So that's the absolute farthest I can do.  So the next block is going to be over here.  And 1/4 of 2 is 1/2.  So this is 3/2 here. ", "All right so we went to 1.  We went to it 3/2 here.  And then I'm going to keep on going with this eventually.  All right so we're going to figure out what happens with ", "this stack.  Question?  AUDIENCE: How do you know that this is  the best way to optimize?  PROFESSOR: The question is how do I know that this is the  best way to optimize? ", "I can't answer that question.  But I can tell you that it's the best way if I start with a  top like this, and the next one like this.  Right, because I'm doing the farthest  possible at each stage. ", "That actually has a name in computer science that's called  the greedy algorithm.  I'm trying to do the best possible at each stage.  The greedy algorithm starting from the bottom, is an  extremely bad strategy. ", "Because when you do that, you stack it this way, and it  almost falls over.  And then the next time you can't do anything.  So the greedy algorithm is terrible from the bottom.  This is the greedy algorithm starting from the top, and it ", "turns out to do much better then the greedy algorithm  starting from the bottom.  But of course I'm not addressing whether there might  not be some other incredibly clever strategy where I wiggle  around and make it go up. ", "I'm not addressing that question.  All right?  It turns out this is the best you can do.  But that's not clear.  All right so now, here we have this thing. ", "And now I have to figure out what the arithmetic pattern  is, so that I can figure out what I was  doing with those shapes.   So let's figure out a thought experiment here. ", "All right?  Now the thought experiment I want to imagine for you is,  you've got a stack of a bunch of blocks, and this is the ", "first N blocks.   All right?  And now we're going to put one underneath it. ", "And what we're going to figure out is the center of mass of  those N blocks, which I'm going to call C sub N. OK. ", "And that's the place where I'm going to put  this very next block.  I'll put it in a different color here.  Here's the new, the next block over.  And the next block over is the N plus 1st block. ", " And now I want you to think about what's going on here. ", "If the center of mass of the first N blocks is this number,  this new one, it's of length 2.  And its center of mass is 1 further to the right than the ", "center of mass that we had before.  So in other words, I've added to this configuration of N  blocks, 1 more block, which is shifted.  Whose center mass is not lined up with the center of mass of ", "this, but actually over farther to the right.  All right so the new center of mass of this new block--  and this is the extra piece of information ", "that I want to observe--  is that this thing has a center of mass at C N plus 1.  It's 1 unit over because this total length is 2. ", "So right in the middle there is 1 over,  according to my units.  All right now this is going to make it possible for me to  figure out what the new center of mass is. ", "So C N plus 1 is the center of mass of N plus 1 blocks. ", "Now this is really only in the horizontal variable, right?  I'm not keeping track of the center of mass.  Actually this thing is hard to build because the center of  mass is also rising.  It's getting higher and higher. ", "But I'm only keeping track of its left and right  characteristic.  So this is the x-coordinate of it.  ", "All right so now here's the idea.  I'm combining the white ones, the N blocks, with the pink  one, which is the one on the bottom.  And there are N of the white ones. ", "And there's 1 of the pink one.  And so in order to get the center of mass of the whole, I  have to take the weighted average of the two.  That's N times C N plus 1, times the center of mass of ", "the pink one, which is C N plus 1.  And then I have to divide if it's the weighted average of  the total of N plus 1 blocks, by N plus 1. ", "This is going to give me the new center of mass of my  configuration at the N plus 1st stage.   And now I can just do the arithmetic and figure ", "out what this is.  And the two C Ns combine.  I get N plus 1, times C N plus 1, divided by N plus 1. ", "And if I combine these two things and do the  cancellation, that gives me this recurrence formula, C N  plus 1 is equal to C N plus, there's a little extra. ", "These two cancel.  That gives me the C N. But then I also have  1 over N plus 1.  ", "Well that's how much gain I can get in the center of mass  by adding one more block.  That's how much I can shift things over, depending on how  we're thinking of things to the left or the right, ", "depending on which direction we're building them.   All right, so now I'm going to work out the formulas.  First of all C 1, that was the center of the first block. ", "I put its left-end at 0, the center of the  first block is at 1.  That means that C 1 is 1.  OK?  C 2, according to this formula-- ", "and actually I've worked it out, we'll check it in a--  C 2 is C 1 plus 1 over 2.  All right, so that's the case, N equals 1.  So this is 1 plus 1/2.  That's what we already did. ", "That's the 3/2 number.  Now the next one is C sub 2 plus 1/3.  That's the formula again. ", "And so that comes out to be 1 plus 1/2 plus 1/3.  And now you can see what the pattern is.  C N, if you just keep on going here, C N is going to be 1 ", "plus 1/2 plus 1/3 plus 1/4 plus 1/N. ", "So now I would like you to vote again.  Do you think I can-- now that we have the formula--  do you think I can get over to here?  How many people think I can get over to here? ", " How many people think I can't get over to here?  There's still a lot of people who do.  So it's still almost 50/50. ", "That's amazing.  Well so we'll address that in a few minutes.  So now let me tell you what's going on.  This C N of course, is the same as what we called last  time S N. And remember that we actually estimated the ", "size of this guy.  This is related to what's called the harmonic series.  And what we showed was that log N is less than S N, which ", "is less than S N plus 1.  All right?   Now I'm going to call your attention to the red part, ", "which is the divergence part of this estimate, which is  this one for the time being, all right.  Just saying that this thing is growing.  And what this is saying is that as N goes to infinity, ", "log N goes to infinity, So that means that S N goes to ", "infinity, because of this inequality here.  It's bigger than log N. And so if N is big enough, we can get  as far as we like. ", "All right?  So I can get to here.  And at least half of you, at least the ones who voted, that  was I don't know.  We have a quorum here, but I'm not sure.  We certainly didn't have a majority on either side. ", "Anyway this thing does go to infinity.  So in principle, if I had enough blocks, I could get it  over to here.  All right, and that's the meaning of ", "divergence in this case.   On the other hand, I want to discuss with you, and the  reason why I use this example, is I want to discuss with you ", "also what's going on with this other inequality here, and  what its significance is.  Which is that it's going to take us a lot of numbers N, a ", "lot of blocks, to get up to a certain level.  In other words, I can't do it with just eight  blocks or nine blocks.  In order to get over here, I'd have to use  quite a few of them. ", "So let's just see how many it is.   So I worked this out carefully.  And let's see what I got.  ", "So to get across the lab tables, all right. ", "This distance here, I already did this secretly.  But I don't actually even have enough of these to show you.  But, well 1, 2, 3, 4, 5, 6, and 1/2. ", "I guess that's enough.  So it's 6 and 1/2.  So it's two lab tables is 13 of these blocks.  All right.  So there are 13 blocks, which is equal to 26 units. ", "OK, that's how far to get across I need.  And the first one is already 2.  So it's really 26 minus 2, which is 24.  Which that's what I need. ", "OK.  So I need log N to be equal to 24, roughly speaking, in order ", "to get that far.  So let's just see how big that is.  All right.  I think I worked this out.  ", "So let's see.  That means that N is equal to e to the 24th--  and if you realize that these blocks are ", "3 centimeters high--   OK let's see how many that we would need here.  That's kind of a lot.  Let's see, it's 3 centimeters times e to the 24th, which is ", "about 8 times 10 to the 8th meters.  OK.  And that is twice the distance to the moon. ", "", "So OK, so I could do it maybe.  But I would need a lot of blocks.  Right?  So that's not very plausible here, all right.  So those of you who voted against this were actually ", "sort of half right.  And in fact, if you wanted to get it to the wall over there,  which is over 30 feet, the height would be about the  diameter of the observable universe. ", "That's kind of a long way.  There's one other thing that I wanted to point out to you  about this shape here. ", "Which is that if you lean to the left, right?  If you put your head like this-- of course you have to  be on your side to look at it-- this curve is the shape ", "of a logarithmic curve.  So in other words, if you think of the vertical as the  x-axis, and the horizontal that way, is the vertical, is  the up direction, then this thing is growing very, very, ", "very, very slowly.  If you send the x-axis all the way up to the moon, the graph  still hasn't gotten across the lab tables here. ", "It's only partway there.  If you go twice the distance to the moon up that way, it's  gotten finally to that end.  All right so that's how slowly the logarithm grows.  It grows very, very slowly. ", "And if you look at it another way, if you stand on your  head, you can see an exponential curve.  So you get some sense as to the growth  properties of these functions. ", "And fortunately these are protecting us from all kinds  of stuff that would happen if there weren't exponentially  small tails in the world. ", "Like you know, I could walk through this wall which I  wouldn't like doing.  OK, now so this is our last example. ", "And the important number, unfortunately we didn't  discover another important number.  There wasn't an amazing number place where this stopped.  All we discovered again is some property of infinity. ", "So infinity is still a nice number.  And the theme here is just that infinity isn't just one  thing, it has a character which is a rate of growth. ", "And you shouldn't just think of there being  one order of infinity.  There are lots of different orders.  And some of them have different meaning from others.  All right so that's the theme I wanted to do, and just have ", "a visceral example of infinity.  Now, we're going to move on now to some other kinds of  techniques. ", "And this is going to be our last subject.  What we're going to talk about is what are  known as power series. ", "And we've already seen our first power series.   And I'm going to remind you of that.  ", "Here we are with power series.   Our first series was this one. ", " And we mentioned last time that it was equal to 1 over 1  minus x, for x less than 1. ", " Well this one is known as the geometric series.  You didn't use the letter x last time, I  used the letter a.  But this is known as the geometric series. ", " Now I'm going to show you one reason why this is true, why ", "the formula holds.  And it's just the kind of manipulation that was done  when these things were first introduced.  And here's the idea of a proof. ", "So suppose that this sum is equal to some number S, which  is the sum of all of these numbers here. ", " The first thing that I'm going to do is I'm going  to multiply by x.  OK, so if I multiply by x-- ", "let's think about that--  I multiply by x on both the left and the right-hand side.  Then on the left side, I get x plus x-squared plus x-cubed ", "plus, and so forth.  And on the right side, I get S times x.   And now I'm going to subtract the two equations, ", "one from the other.  And there's a very, very substantial cancellation.  This whole tail here gets canceled off.  And the only thing that's left is the 1.  So when I subtract, I get 1 on the left-hand side. ", "And on the right-hand side, I get S minus S times x.  All right?  ", "And now that can be rewritten as S times 1 minus x.  And so I've got my formula here.  This is 1 over 1 minus x is equal to S. All right. ", " Now this reasoning has one flaw. ", "It's not complete.  And this reasoning is basically correct.  But it's incomplete because it requires that S exists. ", " For example, it doesn't make any sense in the  case x equals 1.  So for example in the case x equals 1, we have 1 plus 1 ", "plus 1 plus et cetera, equals whatever we call S. And then  when we multiply through by 1, we get 1 plus 1 plus 1 plus,  equals S times 1. ", "And now you see that the subtraction gives us infinity  minus infinity is equal to infinity minus infinity.  That's what's really going on in the  argument in this context.  So it's just nonsense. ", "I mean it doesn't give us anything meaningful.  So this argument, it's great.  And it gives us the right answer, but not always.  And the times when it gives us the answer, the correct ", "answer, is when the series is convergent.  And that's why we care about convergence.  Because we want manipulations like this to be allowed.  ", "So the good case, this is the red case that we were  describing last time, that's the bad case.  But what we want is the good case, the convergent case. ", "And that is the case when x is less than 1.  So this is the convergent case.  ", "Yep.  OK, so they're much more detailed things to check  exactly what's going on.  But I'm going to just say general words about how you  recognize convergence.  And then we're not going to worry about so much about ", "convergence, because it works very, very well.  And it's always easy to diagnose when there's  convergence with a power series.  All right so here's the general setup. ", "", "The general setup is that we have not just the coefficients  1 all the time, but any numbers here, dot, dot, dot. ", "And we abbreviate that with the summation notation.  This is the sum a n x to the n, n equals 0 to infinity.  And that's what's known as a power series. ", " Fortunately there is a very simple rule about how power ", "series converge.  And it's the following.  There's a magic number R which depends on these numbers here ", "such that--  and this thing is known as a radius of convergence--   and the problem that we had, it's this number 1 here. ", "This thing works for x less than 1.  In our case, it's maybe x less R. So that's some symmetric  interval, right?  That's the same as minus R, less then x, less than R, and ", "so where there's convergence.  OK, where the series converges.  Converges.  ", "And then there's the region where every computation that  you give will give you nonsense.  So x greater than R is the sum a sub n x to the n, diverges. ", " And x equals R is very delicate, borderline, and will ", "not be used by us.   OK, we're going to stick inside the radius of  convergence. ", "Now the way you'll be able to recognize  this, is the following.  What always happens is that these numbers tend to 0 ", "exponentially fast, fast for x in R, and doesn't even tend to ", "0 at all for x greater than R. All right so  it'll be totally obvious. ", "When you look at this series here, what's happening when x  less than R is that the numbers are getting smaller  and smaller, less than 1.  When x is bigger than 1, the numbers are  getting bigger and bigger.  There's no chance that the series converges. ", "So that's going to be the case with all power series.  There's going to be a cut off.  And it'll be one particular number.  And below that it'll be obvious that you have  convergence, and you'll be able to do computations. ", "And above that every formula will be wrong  and won't make sense.  So it's a very clean thing.  There is this very subtle borderline, but we're not  going to discuss that in this class. ", "And it's actually not used in direct  studies of power series.  AUDIENCE: How can you tell when the numbers are declining  exponentially fast, whereas just, in other words 1 over x ", "[INAUDIBLE]?  PROFESSOR: OK so, the question is why was I able to tell you  this word here?  Why was I able to tell you not only is it going to 0, but  it's going exponentially fast? ", "I'm telling you extra information.  I'm telling you it always goes exponentially fast. You can  identify it.   In other words, you'll see it. ", "And it will happen every single time.  I'm just promising you that it works that way.  And it's really for the same reason that it works that way  here, that these are powers.  And what's going on over here is there are, it's close to ", "powers with this a n's.  All right?  There's a long discussion of radius of  convergence in many textbooks.  But really it's not necessary, all right, for this purpose? ", "Yeah?  AUDIENCE: How do you find R?  PROFESSOR: The question was how do you find R?  Yes, so I just said, there's a long discussion for how you  find the radius of convergence in textbooks.  But we will not be discussing that here. ", "And it won't be necessary for you.  Because it will be obvious in any given  series what the R is.  It will always either 1 or infinity.  It will always work for all x, or maybe it'll ", "stop at some point.  But it'll be very clear where it stops, as it is for the  geometric series.  All right? ", "OK, so now I need to give you the basic facts, and give you  a few examples.   So why are we looking at these series? ", " Well the answer is we're looking at these series  because the role that they play is exactly the reverse of ", "this equation here.  That is, and this is a theme which I have tried to  emphasize throughout this course, you can read  equalities in two directions. ", "Both are interesting, typically.  You can think, I don't know what the value of this is.  Here's a way of evaluating.  And in other words, the right side is a formula ", "for the left side.  Or you can think of the left side as being a formula for  the right side.   And the idea of series is that they're flexible enough to ", "represent all of the functions that we've  encountered in this course.  This is the tool which is very much like the decimal  expansion which allows you to represent numbers like the  square root of 2. ", "Now we're going to be representing all the numbers,  all the functions that we know, e to the x, arctangent,  sine, cosine.  All of those functions become completely flexible, and ", "completely available to us, and computationally available  to us directly.  So that's what this is a tool for.  And it's just like decimal expansions giving you handle  on all real numbers. ", " So here's how it works.  The rules for convergent power series are just like ", "polynomials.   All of the manipulations that you do for power series are ", "essentially the same as for polynomials.  So what kinds of things do we do with polynomials?  We add them.   We multiply them together. ", " We do substitutions.  Right?  We take one function of another function. ", "We divide them.   OK.  And these are all really not very surprising operations. ", "And we will be able to do them with power series too.  The ones that are interesting, really interesting for  calculus, are the last two.  We differentiate them, and we integrate them. ", " And all of these operations we'll be able to do for power  series as well.  ", "So now let's explain the high points of this.  Which is mainly just the differentiation and the  integration part. ", "So if I take a series like this and so forth, the formula ", "for it's derivative is just like polynomials.  That's what I just said, it's just like polynomials.  So the derivative of the constant is 0.  The derivative of this term is a 1. ", "This one is plus 2 a 2 x.  This one is 3a 3 x-squared, et cetera.  That's the formula. ", "Similarly if I integrate, well there's an unknown constant ", "which I'm going to put first rather than last. Which  corresponds sort of to the a 0 term which, is going  to get wiped out.  That a 0 term suddenly becomes a 0 x.  And the anti-derivative of this next term is a sub 1 ", "x-squared over 2.  And the next term is a 2 x-cubed over 3, and so forth.   Yeah, question? ", "AUDIENCE: Is that a series or a polynomial?  PROFESSOR: Is this a series or a polynomial?  Good question.  It's a polynomial if it ends.  If it goes on infinitely far, then it's a series. ", "They look practically the same, polynomials and series.  There's this little dot, dot, dot here.  Is this a series or a polynomial?  It's the same rule.  If it stops at a finite stage, this one ", "stops at a finite stage.  If it goes on forever, it goes on forever.  AUDIENCE: So I thought that the series  add up finite numbers.  You can add up terms of x in series? ", " PROFESSOR: So an interesting question.  So the question that was just asked is I thought that a  series added up finite numbers. ", "You could add up x?  That was what you said, right?  OK now notice that I pulled that off on you by changing  the letter a to the letter x at the very beginning of this ", "commentary here.  This is a series.  For each individual value of x, it's a number.  So in other words, it I plug in here x equals 1/2, I'm ", "going to add 1 plus 1/2 plus 1/4 plus 1/8; and I'll get a  number which is 2.  And I'll plug in a number over here, and I'll get a number.  On the other hand, I can do this for each value of x.  So the interpretation of this is that it's a function of x. ", "And similarly this is a function of x.  It works when you plug in the possible values x between  minus 1 and 1. ", "So there's really no distinction there, it's just I  slipped it passed you.  These are functions of x.   And the notion of a power series is this idea that you ", "put coefficients on a series, but then you allow yourself  the flexibility to stick powers here.  And that's exactly what we're doing.  OK there are other kinds of series where you stick other ", "interesting functions in here like sines and cosines.  There are lots of other series that people study.  And these are the simplest ones.  And all those examples are extremely helpful for  representing functions. ", "But we're only going to do this example here.  All right, so here are the two rules.  And now there's only one other complication here which I have ", "to explain to you before giving you a bunch of examples  to show you that this works extremely well. ", "And the last thing that I have to do for you is explain to  you something called Taylor's formula.  ", "Taylor's formula is the way you get from the  representations that we're used to a functions, to a  representation in the form of these coefficients. ", "When I gave you the function e to the x, it didn't look like  a polynomial.  And we have to figure out which of these guys it is, if  it's going to fall into our category here. ", "And here's the formula.  I'll explain to you how it works in a second.  So the formula is f of x, turns out there's a formula in  terms of the derivatives of f.  Namely, you differentiate n times, and you evaluate it at ", "0, and you divide by n factorial, and  multiply by x to the n.  So here's Taylor's formula.  This tells you what the Taylor series is. ", "Now about half of our job for the next few minutes is going  to be to give examples of this.  But let me just explain to you why this has to be. ", "If you pick out this number here, this is the a n, the  magic number a n here.  So let's just illustrate it.  If f of x happens to be a zero plus a 1 x plus a 2 x-squared ", "plus a 3 x-cubed plus dot, dot, dot.  And now I differentiate it, right?  I get a 1 plus 2 a 2x plus 3 a 3 x. ", "If I differentiate it another time, I  get 2 a 2, plus 3--sorry--  3 times 2 a 3 x plus dot, dot, dot. ", "And now a third time, I get 3 times 2 a 3 plus et cetera.  So this next term is really in disguise, 4 ", "times 3 times 2 x--  a sorry-- a 4x.  That's what really comes down if I kept track of the fourth  term there. ", "So now here is my function.  But now you see if I plug in x equals 0, I can pick off the ", "third term.  f triple prime of 0 is equal to 3 times 2 times a 3. ", "Right, because all the rest of those terms when I plug in 0  are just 0.  Here's the formula.  And so the pattern here is this.  And what's really going on here is this is really 3 times ", "2 times 1, a 3.  And in general a n is equal to f nth derivative ", "divided by n factorial.  And of course, n factorial, I remind you, is n times n minus  1 times n minus 2, all the way down to 1.  ", "Now there's one more crazy convention  which is always used.  Which is that there's something very strange here  down at 0, which is that 0 factorials turns out, has to ", "be set equal to 1.  All right, so that's what you do in order to make this  formula work out.  And that's one of the reasons for this convention.  ", "All right.  So my next goal is to give you some examples.  And let's do a couple. ", " So here's, well you know, I'm going to have to let you see a  few of them next time. ", "But let me just tell you this one, which is by far the most  impressive.  ", "So what happens with e to the x, if the function of f of x  is e to the x, is that it's derivative is also e to the x. ", "And its second derivative is also e to the x.  And it just keeps on going that way.  They're all the same.  So that means that these numbers in Taylor's formula, ", "in the numerator, the nth derivative is  very easy to evaluate.  It's just e to the x.  And if I evaluated at x equals 0, I just get 1. ", "So all of those numerators are 1.  So the formula here, is the sum n equals 0 to infinity, of  1 divided by n factorial x to the n. ", " In particular, we now have an honest formula for e to the  first power. ", "Which is just e.  Which if I plug it in, x equals 1, I get 1.  This is the n equals 0 term plus 1.  This is the n equals 1 term plus 1 over 2 factorial plus 1 ", "over 3 factorial plus 1 over 4 factorial.   Right?  So this is our first honest formula for e. ", "And also, this is how you compute  the exponential function.  ", "Finally if you take a function like sine x, what you'll  discover is that we can complete the sort of strange ", "business that we did at the beginning of the course--  or cosine x--   where we took the linear and quadratic approximations. ", "Now we're going to get complete  formulas for these functions.  Sine x turns out to be equal to x minus x-cubed over 3 ", "factorial plus x to the 5th over 5 factorial minus x to  the 7th over 7 factorial, et cetera.  And cosine x is equal to 1, minus x-squared over 2 ", "factorial--  that's the same as this 2 here--  plus x to the 4th over 4 factorial minus x to the 6th  over 6 factorial, plus et cetera. ", "Now these may feel like they're hard to memorize  because I've just pulled them out of a hat.   I do expect you to know them. ", "They're actually extremely similar formulas.  The exponential here just has this collection of factorials.  The sine is all the odd powers with alternating sines. ", "And the cosine is all the even powers with alternating sines.  So all three of them form part of the same family.  So this will actually make it easier for you to remember, ", "rather than harder.   And so with that, I'll leave the practice on  differentiation for next time.  And good luck, everybody. ", "I'll talk to you individually.  "], "vid_duration": [10.82, 10.1, 10.46, 14.93, 12.98, 12.19, 11.975, 10.945, 13.7, 11.37, 10.569, 11.411, 10.36, 10.43, 10.18, 10.66, 10.39, 10.69, 10.222, 12.654, 11.014, 12.94, 10.27, 10.13, 10.695, 11.285, 10.64, 10.77, 11.67, 10.62, 10.37, 13.11, 11.49, 10.92, 12.84, 10.825, 12.927, 13.238, 12.08, 10.6, 11.95, 12.43, 12.41, 10.39, 13.481, 10.419, 10.46, 11.95, 11.4, 12.02, 11.34, 10.84, 10.5, 12.81, 12.1, 12.89, 10.97, 11.93, 13.26, 14.25, 11.29, 10.1, 13.59, 10.79, 13.19, 10.9, 12.55, 12.87, 12.87, 10.11, 15.12, 12.76, 11.77, 13.24, 13.65, 10.23, 12.85, 18.12, 10.96, 11.772, 12.468, 10.45, 12.92, 13.18, 12.98, 12.15, 13.61, 12.089, 16.461, 11.14, 11.79, 18.77, 11.02, 16.77, 11.01, 11.5, 13.19, 11.86, 11.98, 14.58, 12.72, 10.9, 11.11, 11.77, 11.33, 10.66, 11.75, 10.3, 11.13, 10.62, 11.11, 16.66, 10.0, 12.45, 10.48, 14.89, 14.45, 11.11, 10.966, 11.269, 11.555, 14.8, 12.95, 14.653, 12.787, 19.34, 13.72, 11.24, 10.7, 10.97, 15.47, 11.04, 12.47, 11.08, 11.08, 11.25, 11.96, 10.6, 11.12, 10.1, 11.61, 15.3, 11.82, 17.53, 19.04, 10.97, 10.62, 14.13, 10.7, 12.65, 10.41, 11.09, 13.09, 10.11, 10.07, 11.81, 15.24, 11.13, 10.05, 10.22, 10.35, 13.64, 11.81, 10.19, 12.29, 10.78, 10.31, 10.06, 28.1, 10.36, 10.57, 10.439, 10.071, 14.75, 13.16, 10.16, 10.74, 12.0, 11.22, 14.75, 13.39, 11.246, 13.034, 10.97, 11.275, 11.325, 14.29, 10.498, 13.922, 10.56, 10.96, 10.83, 10.395, 16.005, 10.75, 14.01, 10.9, 12.91, 13.09, 12.09, 12.54, 15.8, 14.32, 11.63, 11.44, 10.98, 10.13, 10.48, 11.27, 15.62, 14.12, 12.61, 14.26, 15.81, 10.84, 10.25, 11.82, 11.82, 13.88, 12.097, 10.813, 12.64, 11.92, 10.39, 11.03, 12.17, 10.23, 14.33, 13.08, 13.04, 11.23, 10.04, 10.67, 2.99], "stet": [[0, 10.82], [10.82, 20.92], [20.92, 31.380000000000003], [31.380000000000003, 46.31], [46.31, 59.290000000000006], [59.290000000000006, 71.48], [71.48, 83.455], [83.455, 94.4], [94.4, 108.10000000000001], [108.10000000000001, 119.47000000000001], [119.47000000000001, 130.03900000000002], [130.03900000000002, 141.45000000000002], [141.45000000000002, 151.81], [151.81, 162.24], [162.24, 172.42000000000002], [172.42000000000002, 183.08], [183.08, 193.47000000000003], [193.47000000000003, 204.16000000000003], [204.16000000000003, 214.38200000000003], [214.38200000000003, 227.03600000000003], [227.03600000000003, 238.05000000000004], [238.05000000000004, 250.99000000000004], [250.99000000000004, 261.26000000000005], [261.26000000000005, 271.39000000000004], [271.39000000000004, 282.08500000000004], [282.08500000000004, 293.37000000000006], [293.37000000000006, 304.01000000000005], [304.01000000000005, 314.78000000000003], [314.78000000000003, 326.45000000000005], [326.45000000000005, 337.07000000000005], [337.07000000000005, 347.44000000000005], [347.44000000000005, 360.55000000000007], [360.55000000000007, 372.0400000000001], [372.0400000000001, 382.9600000000001], [382.9600000000001, 395.80000000000007], [395.80000000000007, 406.62500000000006], [406.62500000000006, 419.5520000000001], [419.5520000000001, 432.7900000000001], [432.7900000000001, 444.87000000000006], [444.87000000000006, 455.4700000000001], [455.4700000000001, 467.4200000000001], [467.4200000000001, 479.8500000000001], [479.8500000000001, 492.2600000000001], [492.2600000000001, 502.6500000000001], [502.6500000000001, 516.1310000000001], [516.1310000000001, 526.5500000000001], [526.5500000000001, 537.0100000000001], [537.0100000000001, 548.9600000000002], [548.9600000000002, 560.3600000000001], [560.3600000000001, 572.3800000000001], [572.3800000000001, 583.7200000000001], [583.7200000000001, 594.5600000000002], [594.5600000000002, 605.0600000000002], [605.0600000000002, 617.8700000000001], [617.8700000000001, 629.9700000000001], [629.9700000000001, 642.8600000000001], [642.8600000000001, 653.8300000000002], [653.8300000000002, 665.7600000000001], [665.7600000000001, 679.0200000000001], [679.0200000000001, 693.2700000000001], [693.2700000000001, 704.5600000000001], [704.5600000000001, 714.6600000000001], [714.6600000000001, 728.2500000000001], [728.2500000000001, 739.0400000000001], [739.0400000000001, 752.2300000000001], [752.2300000000001, 763.1300000000001], [763.1300000000001, 775.6800000000001], [775.6800000000001, 788.5500000000001], [788.5500000000001, 801.4200000000001], [801.4200000000001, 811.5300000000001], [811.5300000000001, 826.6500000000001], [826.6500000000001, 839.4100000000001], [839.4100000000001, 851.1800000000001], [851.1800000000001, 864.4200000000001], [864.4200000000001, 878.07], [878.07, 888.3000000000001], [888.3000000000001, 901.1500000000001], [901.1500000000001, 919.2700000000001], [919.2700000000001, 930.2300000000001], [930.2300000000001, 942.0020000000002], [942.0020000000002, 954.4700000000001], [954.4700000000001, 964.9200000000002], [964.9200000000002, 977.8400000000001], [977.8400000000001, 991.0200000000001], [991.0200000000001, 1004.0000000000001], [1004.0000000000001, 1016.1500000000001], [1016.1500000000001, 1029.76], [1029.76, 1041.849], [1041.849, 1058.31], [1058.31, 1069.45], [1069.45, 1081.24], [1081.24, 1100.01], [1100.01, 1111.03], [1111.03, 1127.8], [1127.8, 1138.81], [1138.81, 1150.31], [1150.31, 1163.5], [1163.5, 1175.36], [1175.36, 1187.34], [1187.34, 1201.9199999999998], [1201.9199999999998, 1214.6399999999999], [1214.6399999999999, 1225.54], [1225.54, 1236.6499999999999], [1236.6499999999999, 1248.4199999999998], [1248.4199999999998, 1259.7499999999998], [1259.7499999999998, 1270.4099999999999], [1270.4099999999999, 1282.1599999999999], [1282.1599999999999, 1292.4599999999998], [1292.4599999999998, 1303.59], [1303.59, 1314.2099999999998], [1314.2099999999998, 1325.3199999999997], [1325.3199999999997, 1341.9799999999998], [1341.9799999999998, 1351.9799999999998], [1351.9799999999998, 1364.4299999999998], [1364.4299999999998, 1374.9099999999999], [1374.9099999999999, 1389.8], [1389.8, 1404.25], [1404.25, 1415.36], [1415.36, 1426.3259999999998], [1426.3259999999998, 1437.5949999999998], [1437.5949999999998, 1449.1499999999999], [1449.1499999999999, 1463.9499999999998], [1463.9499999999998, 1476.8999999999999], [1476.8999999999999, 1491.5529999999999], [1491.5529999999999, 1504.34], [1504.34, 1523.6799999999998], [1523.6799999999998, 1537.3999999999999], [1537.3999999999999, 1548.6399999999999], [1548.6399999999999, 1559.34], [1559.34, 1570.31], [1570.31, 1585.78], [1585.78, 1596.82], [1596.82, 1609.29], [1609.29, 1620.37], [1620.37, 1631.4499999999998], [1631.4499999999998, 1642.6999999999998], [1642.6999999999998, 1654.6599999999999], [1654.6599999999999, 1665.2599999999998], [1665.2599999999998, 1676.3799999999997], [1676.3799999999997, 1686.4799999999996], [1686.4799999999996, 1698.0899999999995], [1698.0899999999995, 1713.3899999999994], [1713.3899999999994, 1725.2099999999994], [1725.2099999999994, 1742.7399999999993], [1742.7399999999993, 1761.7799999999993], [1761.7799999999993, 1772.7499999999993], [1772.7499999999993, 1783.3699999999992], [1783.3699999999992, 1797.4999999999993], [1797.4999999999993, 1808.1999999999994], [1808.1999999999994, 1820.8499999999995], [1820.8499999999995, 1831.2599999999995], [1831.2599999999995, 1842.3499999999995], [1842.3499999999995, 1855.4399999999994], [1855.4399999999994, 1865.5499999999993], [1865.5499999999993, 1875.6199999999992], [1875.6199999999992, 1887.4299999999992], [1887.4299999999992, 1902.6699999999992], [1902.6699999999992, 1913.7999999999993], [1913.7999999999993, 1923.8499999999992], [1923.8499999999992, 1934.0699999999993], [1934.0699999999993, 1944.4199999999992], [1944.4199999999992, 1958.0599999999993], [1958.0599999999993, 1969.8699999999992], [1969.8699999999992, 1980.0599999999993], [1980.0599999999993, 1992.3499999999992], [1992.3499999999992, 2003.1299999999992], [2003.1299999999992, 2013.4399999999991], [2013.4399999999991, 2023.499999999999], [2023.499999999999, 2051.599999999999], [2051.599999999999, 2061.959999999999], [2061.959999999999, 2072.5299999999993], [2072.5299999999993, 2082.968999999999], [2082.968999999999, 2093.039999999999], [2093.039999999999, 2107.789999999999], [2107.789999999999, 2120.949999999999], [2120.949999999999, 2131.1099999999988], [2131.1099999999988, 2141.8499999999985], [2141.8499999999985, 2153.8499999999985], [2153.8499999999985, 2165.0699999999983], [2165.0699999999983, 2179.8199999999983], [2179.8199999999983, 2193.209999999998], [2193.209999999998, 2204.4559999999983], [2204.4559999999983, 2217.4899999999984], [2217.4899999999984, 2228.459999999998], [2228.459999999998, 2239.7349999999983], [2239.7349999999983, 2251.059999999998], [2251.059999999998, 2265.349999999998], [2265.349999999998, 2275.847999999998], [2275.847999999998, 2289.769999999998], [2289.769999999998, 2300.329999999998], [2300.329999999998, 2311.289999999998], [2311.289999999998, 2322.119999999998], [2322.119999999998, 2332.514999999998], [2332.514999999998, 2348.519999999998], [2348.519999999998, 2359.269999999998], [2359.269999999998, 2373.2799999999984], [2373.2799999999984, 2384.1799999999985], [2384.1799999999985, 2397.0899999999983], [2397.0899999999983, 2410.1799999999985], [2410.1799999999985, 2422.2699999999986], [2422.2699999999986, 2434.8099999999986], [2434.8099999999986, 2450.6099999999988], [2450.6099999999988, 2464.929999999999], [2464.929999999999, 2476.559999999999], [2476.559999999999, 2487.999999999999], [2487.999999999999, 2498.979999999999], [2498.979999999999, 2509.109999999999], [2509.109999999999, 2519.5899999999992], [2519.5899999999992, 2530.859999999999], [2530.859999999999, 2546.479999999999], [2546.479999999999, 2560.599999999999], [2560.599999999999, 2573.209999999999], [2573.209999999999, 2587.4699999999993], [2587.4699999999993, 2603.2799999999993], [2603.2799999999993, 2614.1199999999994], [2614.1199999999994, 2624.3699999999994], [2624.3699999999994, 2636.1899999999996], [2636.1899999999996, 2648.0099999999998], [2648.0099999999998, 2661.89], [2661.89, 2673.987], [2673.987, 2684.8], [2684.8, 2697.44], [2697.44, 2709.36], [2709.36, 2719.75], [2719.75, 2730.78], [2730.78, 2742.9500000000003], [2742.9500000000003, 2753.1800000000003], [2753.1800000000003, 2767.51], [2767.51, 2780.59], [2780.59, 2793.63], [2793.63, 2804.86], [2804.86, 2814.9], [2814.9, 2825.57], [2825.57, 2828.56]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1307, 1609, 1934, 2336, 2587, 2829]}
{"example_id": "mit039@@MIT8_20IAP21_lec06_300k", "text": [" PROFESSOR: Welcome back to 8.20.  In this section and the following ones,  we talk about paradoxes in special relativity.  A paradox is something which is absurd or self-contradictory. ", "So we have statements which don't really make  any sense when put together.  The pole in the barn paradox is rather interesting. ", "And we will analyze this, and at the end of the discussion,  we hopefully agree that there is no paradox here.  It's a pseudo paradox.  So the situation is as follows. ", "We have Alice.  She has a pole.  The pole is 10 meters long in her reference frame.  And Bob is very proud of his New England  barn which is, in his reference frame, 8 meters long. ", "Alice, however, is moving with a velocity of 0.6 times  the speed of light, which gives us a gamma factor of 1.25.  Does the pole fit into the barn is the question, or not? ", "So stop here and think about this for a second,  and we will continue with an analysis of this.  So here is the analysis for Alice's frame ", "and the analysis for Bob's frame.  For Alice, the barn in her reference frame  is Lorentz contracted.  It's 6.4 meters long, but her pole is 10 meters long. ", "So we should clearly answer this question  by saying it doesn't fit.  In Bob's frame, the barn is 8 meters long,  and the pole is Lorentz contracted-- ", "also 8 meters long.  So Bob will say, yeah, it fits-- it just barely fits.  They're exactly the same size, so yes, it all  fits into the barn.  And here is where you might think ", "this is an absurd statement.  They cannot be both right.  We will see they can.  They can both be right.  They just disagreed on the fact that events ", "happen simultaneously.  What are the crucial events here?  When does the barn hit the end-- does  the pole hit the end of the barn,  and when does the back of the pole hit the front of the barn? ", "Those are the two things we have to study in detail.  But let's get to it.  How can they, or why can they disagree?  So the idea is that you draw space-time diagrams ", "for the pole in the barn, and show  that there's no paradox by using the world lines of the pole.  Before we do this, we're going to analyze this a little bit ", "more.  So assume that the front of the pole enters the barn at time ", "equals 0 for both Bob and Alice.  Then Bob observes the pole entering his barn,  and it takes 44.4 nanoseconds-- ", "8 meters divided by 0.6 times the speed of light--  for the front of the pole to reach the back of the barn,  and the back of the pole to reach the front of the barn. ", "So after 44 nanoseconds, in Bob's reference frame,  the pole is in the barn.  Alice, however, sees the barn Lorentz contracted. ", "It's 6.4 meters long.  She moves this 0.6 times the speed of light.  So for her, she reaches the back after 35.6 nanoseconds, ", "in which case, Bob's clock only shows  28.4 nanoseconds, because Alice's clock  time is Lorentz contracted. ", "So we can clearly conclude here that that's not  enough time for Bob such that the pole actually entered  the barn for the full length.  So the back of the pole is still outside. ", "So we want to consider three different events.  The first event is after 44 nanoseconds,  and in the space of 8 meters in Bob's reference frame.  For Alice-- this is the situation we just analyzed-- ", "36.6-- 35.6 nanoseconds passed.  And in her reference frame, the front of the pole  is at 0 meters.  The second event is then the other side ", "of the barn in Bob's reference frame  after 44.4 nanoseconds 0 meters.  He sees-- or she sees that 55 nanoseconds have passed. ", "We use Lorentz transformation here,  but the position is minus 10 meters.   And the last point is 28.49 nanoseconds and 0 meters. ", "That is the observation when Alice sees the end  of the-- front of the barn--  the front of the pole at the end of the barn.  That translates into Alice's frame  a 35.6 nanoseconds, and minus 6.4 meters. ", "So the minus 6.4 meters tells you very clearly  what we just already said.  The back of the pole is still outside.  So that's the quantitative or numerical kind of evaluation. ", "And we can also show the very same thing  in the space-time diagram.  So we show the space-time diagram here,  and this is Bob's reference frame.  So the pole just touched the front of his barn, ", "and the barn is located at 8 meters--  the end of the barn is located 8 meters.  The front of the barn is located at 0 meters.  After 44 nanoseconds, there's event number one and event ", "number two.  The pole is fully in the barn.   But we can also show the pole in event number three.  So one-- where is the end of the pole? ", "We look at this diagram here.  Where is the end of the pole when the front of the pole  hits the end of the barn?  You see clearly there's a piece sticking out. ", "We saw that there's--  in this event here, 6.6 meters in Alice's  frame still seeking out.  ", "So we see that event number three is located here,  and not all of the pole is actually contained within the. ", "So Bob and Alice disagree on whether the front  and the back of the pole are in the barn simultaneously.  That's where the situation becomes contradictory. ", "They don't agree that two events which happened at the same time  in their reference frame--  in Bob's reference frame occurs at the same time  in Alice's reference. ", "In this section, we talk about the famous twin paradox.  It's probably the most famous paradox in special relativity.  I want to get to the bottom of this,  and understand really where there ", "is a conflicting or contradictory statement  in this story.  Let me just first say that this is personal to me.  I do have a twin brother, and you  can see three pictures of myself and my twin brother here. ", "We were very little on our first day of school in Germany.  You get a little box of candy when  you go to schools to make it more attractive to actually  learn and study. ", "And then a picture, which is probably already  about 10 years old.  What you can take away from here is clearly  moving clocks are slow.  It turns out that my twin brother ", "lives in the very same village in Germany  where I grew up, where we both grew up,  while I traveled the world constantly and constantly  on the road between France and Geneva ", "and Switzerland and the United States.  And again, I think there is no dispute here.  It can be seen from this picture that your professor looks  much younger. ", "I even have a more recent picture.  This is two years ago.  The German Kris Kringle Market, where I asked my brother  to take this picture for this class, for 8.20.  And again, I think the answer to the question is clear. ", "Professor Klute has aged less.  All right.  On a more serious note, we're going  to quantitatively understand and analyze the situation.  And we use Bob and Alice again. ", "In this situation, here Bob stays local.  Alice has a spacecraft, and she moves with the velocity of 0.6,  six times the speed of light, a gamma factor of 1.25. ", "The travel takes her to a distant star,  which is in this example It's three light years away  from Bob, measured by Bob.  The journey takes her, on Bob's clock, five years, ", "and the return takes another five years.  She doesn't spend much time.  She wants to go home as quickly as possible.  If you analyze this, from Alice's perspective,  we see that for Alice, the journey takes four years, ", "and the distance traveled for her in a spacecraft is 0.  From Bob's perspective, the journey, as seen by Alice, ", "is only 3.2 years long.  And so we find that there's already a conflict.  If you add the times together, both ways, the inbound  and the outbound ways, 6.4 years is not equal to 10 years. ", "So there's already a contradictory statement  in this story.  But the key to the understanding of this problem  is that Alice, in order to return, ", "has to change reference points.  And there, we do have to resynchronize the clocks,  if you want, or add a specific extra factor.  And we'll go back to this when we  look at space and [INAUDIBLE]. ", "So the time, as seen by Bob, is 3.2 years  for the outbound journey, and then 3.6 years  in order to resynchronize the clocks on the return, ", "on the turning around.  And then 3.2 years on the return, which makes 10 years.  And so that observation of Bob, of Alice, ", "is in agreement with Bob's own clock.  All right.  So we saved the day here.  Let's look at space-time diagrams.  The outbound journey is shown here. ", "You see I've got it--  in addition to Bob's reference frame,  I've plotted Alice's reference, and it makes it easier  to understand what's going on. ", "So we see in Alice's reference frame,  the journey takes four years.  If you then go back to the position in which Bob is, ", "3.2 years have passed.   So this is iffy.   At the time when Alice arrives we go back ", "to the position of Bob, 3.2 years have passed.  We then turn around and ask the very same question.  At that time-- it's still four years-- ", "we go back the other direction now to Bob,  we are already much further ahead,  3.2 years plus 3.6 years. ", "And then the journey continues, and we add another 3.2 years  to the journey.   When Alice and Bob reunite, Alice ", "aged by eight years, 2 times 4, and Bob aged by 10 years.  So the question now is, there may be a paradox here. ", "Is it possible that we missed somehow that by--  and try to understand why this is a probably not symmetric.  Why can I not just use the other reference frame, ", "and just declare that Alice stayed stationary  in her spacecraft while Bob moved away with Earth  and then came back?  Why are those two things not consistent? ", "The answer is that it's not Bob who  has to change reference frame, but Alice.  It's Alice who has to do this.  There is where the asymmetry is.  You can argue if you want that, in order for Alice to do that, ", "she actually has to accelerate.  But we don't have any sort of discussion  of how the acceleration actually went about.  It's really the change in reference frame  which is crucial in this discussion, ", "and causes the asymmetry between Bob and Alice.  In this section, we want to talk and investigate  a bit more length contraction.  We have seen length contraction a few times ", "already in this class.  We have derived it.  We have seen it in application.  But we want to get some sort of feeling to  how can we actually understand what's ", "happening to the objects.  Later in this section, in this video,  we'll talk about another paradox, spacecraft on a rope. ", "So let's get to it.  So the situation here is as we have seen a few times already.  We have Alice being at rest, and Bob  is moving with a velocity v. And what we are interested in ", "is this object here, which might be a rod of some sort.  You can think about a spacecraft if you want, ", "but a specific object, which, at rest, has a length LB.  For Alice, this object is Lorentz contracted,  and it appears shorter. ", "So now what happens now if Bob accelerates from his velocity v  to a velocity v plus delta v with respect to Alice? ", "How does the acceleration occur?  And how can we understand then the further shrinking  of the spacecraft?  Bob tries really, really hard to accelerate such ", "that all elements of this rod or spacecraft  are being accelerated simultaneously  in his framework.  You can think about splitting up the spacecraft ", "into small elements.  They're all getting a little bit of a kick,  a little bit of an extra momentum at the very same time.  So, if now Alice observes the same situation, ", "we find that she looks at the spacecraft.  And, because the leading clock in the spacecraft,  in Bob's spacecraft, lags, she observes ", "that the spacecraft's back is being accelerated first.  And, because it's accelerated first,  she observes that the spacecraft shrinks ", "just a little bit because of the additional velocity.  Well, that's kind of an interesting picture  to think about how we can understand length contraction  and how we can understand length contraction ", "once there's acceleration involved.  OK, so the next question now or the next topic  here in this video is the spacecraft on a rope paradox. ", "This was phrased by Bell in the 1950s and '60s.  He was working at CERN at the time and roaming the corridors,  discussing with his colleagues.  The situation here is related to the one we just discussed, ", "but slightly different.  So let me explain.  So again we have Alice as an observer, observer  in a reference frame A, observing two spacecrafts.  They are identical spacecrafts. ", "They have the same engines.  And they are separated by distance D.  So now Alice gives a signal to both spacecrafts  simultaneously in her reference frame ", "to accelerate at the same time such  that the distance between B and C remains constant.  So they're asked to accelerate such that the distance remains ", "constant.  Well, the question now is, when those two spacecrafts  are connected with a rope, will this rope break? ", "So I'll let you think about this a bit  and come up with your own answer.  In the meantime, this is not such a hard problem actually. ", "In order to keep the distance constant for A,  the distance in the BC reference frame,  in the reference frame of the two spacecrafts,  needs to expand. ", "So LA, so the distance as observed by Alice or reference  frame A, is equal to 1 over gamma,  the distance between the two [? planes. ?] ", "And for this to stay-- for LA to stay constant  while there's acceleration going on, LBC needs to increase.  That's why the rope will break. "], "vid_duration": [13.07, 10.36, 10.51, 12.45, 12.37, 10.58, 11.98, 10.83, 10.71, 10.59, 11.67, 12.03, 11.4, 10.07, 10.17, 13.54, 12.37, 11.38, 11.61, 12.69, 13.56, 12.329, 12.481, 12.83, 17.74, 13.79, 14.1, 11.85, 13.73, 12.13, 14.68, 11.26, 13.57, 12.153, 10.79, 12.509, 10.561, 10.48, 12.69, 10.45, 12.21, 11.97, 12.454, 11.246, 13.98, 10.8, 15.1, 11.47, 11.81, 10.23, 10.05, 11.32, 10.38, 11.12, 13.709, 10.541, 14.28, 10.93, 13.76, 11.85, 12.49, 13.56, 11.28, 10.463, 11.431, 10.24, 13.58, 10.5, 10.65, 10.51, 11.71, 10.92, 14.51, 10.709, 10.161, 10.9, 14.24, 14.72, 11.58, 10.65, 10.74, 10.16, 11.13, 10.77, 12.239, 7.634], "stet": [[0, 13.07], [13.07, 23.43], [23.43, 33.94], [33.94, 46.39], [46.39, 58.76], [58.76, 69.34], [69.34, 81.32000000000001], [81.32000000000001, 92.15], [92.15, 102.86000000000001], [102.86000000000001, 113.45000000000002], [113.45000000000002, 125.12000000000002], [125.12000000000002, 137.15], [137.15, 148.55], [148.55, 158.62], [158.62, 168.79], [168.79, 182.32999999999998], [182.32999999999998, 194.7], [194.7, 206.07999999999998], [206.07999999999998, 217.69], [217.69, 230.38], [230.38, 243.94], [243.94, 256.269], [256.269, 268.75], [268.75, 281.58], [281.58, 299.32], [299.32, 313.11], [313.11, 327.21000000000004], [327.21000000000004, 339.06000000000006], [339.06000000000006, 352.7900000000001], [352.7900000000001, 364.9200000000001], [364.9200000000001, 379.6000000000001], [379.6000000000001, 390.86000000000007], [390.86000000000007, 404.43000000000006], [404.43000000000006, 416.5830000000001], [416.5830000000001, 427.3730000000001], [427.3730000000001, 439.8820000000001], [439.8820000000001, 450.4430000000001], [450.4430000000001, 460.9230000000001], [460.9230000000001, 473.6130000000001], [473.6130000000001, 484.0630000000001], [484.0630000000001, 496.2730000000001], [496.2730000000001, 508.2430000000001], [508.2430000000001, 520.6970000000001], [520.6970000000001, 531.9430000000001], [531.9430000000001, 545.9230000000001], [545.9230000000001, 556.7230000000001], [556.7230000000001, 571.8230000000001], [571.8230000000001, 583.2930000000001], [583.2930000000001, 595.1030000000001], [595.1030000000001, 605.3330000000001], [605.3330000000001, 615.383], [615.383, 626.7030000000001], [626.7030000000001, 637.0830000000001], [637.0830000000001, 648.2030000000001], [648.2030000000001, 661.912], [661.912, 672.4530000000001], [672.4530000000001, 686.7330000000001], [686.7330000000001, 697.663], [697.663, 711.423], [711.423, 723.273], [723.273, 735.763], [735.763, 749.323], [749.323, 760.603], [760.603, 771.0659999999999], [771.0659999999999, 782.497], [782.497, 792.737], [792.737, 806.317], [806.317, 816.817], [816.817, 827.467], [827.467, 837.977], [837.977, 849.687], [849.687, 860.607], [860.607, 875.117], [875.117, 885.8259999999999], [885.8259999999999, 895.9869999999999], [895.9869999999999, 906.8869999999998], [906.8869999999998, 921.1269999999998], [921.1269999999998, 935.8469999999999], [935.8469999999999, 947.4269999999999], [947.4269999999999, 958.0769999999999], [958.0769999999999, 968.8169999999999], [968.8169999999999, 978.9769999999999], [978.9769999999999, 990.1069999999999], [990.1069999999999, 1000.8769999999998], [1000.8769999999998, 1013.1159999999999], [1013.1159999999999, 1020.7499999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [417, 765, 1021]}
{"example_id": "mit039@@MIT8_20IAP21_lec11_300k", "text": ["PROFESSOR: Welcome back to 8.20, special relativity.  In this section, and also the next time,  we talk about electromagnetism.  Electromagnetism is not part of the core of 8.20. ", "We are not requiring electromagnetism  as part of the prerequisite.  I will not test or include electromagnetism in the final.  But nevertheless, it's interesting to discuss ", "electromagnetic effects in the context of special relativity,  as they led to the development of special relativity  in the first.  After all, the paper which describes ", "the theory of special relativity is about the electrodynamics  of moving bodies.  And so let's have a look at the natural dynamics of moving  bodies.  And so here, we have a source-- ", "a charge which is moving with a velocity V.  And moving charges, or currents, create magnetic fields.  You can use your right-hand and see particles are  moving in this direction here. ", "The electric field lines are curling around you.  Good.  So now I have a second charge-- a test charge which  is moving with the velocity u.  That test charge will experience the magnetic force. ", "The force is equal to the test charge itself,  qt, times u cross B, the velocity  cross the magnetic field.  So there's clearly a magnetic force ", "acting on this [INAUDIBLE] charge in this reference frame.  However, if I now move into a reference frame  where the source charge is stationary, ", "a stationary charge is not creating magnetic field,  so the magnetic field is 0.  Hence the magnetic force on the test charge is 0.  I can, alternatively, look at the reference frame in which ", "the test charge is stationary.  And so also here, because u is equal to 0,  the magnetic force is 0.  So clearly, we do have to treat magnetic and electric fields ", "in sort of a consistent manner as we  treated time and space, and energy momentum  in a consistent manner.  But we need a concept of electromagnetic fields.  And previously in this class, we looked at electromagnetic field ", "light before.  The difference here is-- and that's the context of the next  section--  is that you want to understand how we create those fields--  how we can create electric and magnetic fields, and how ", "that all works together.  Now the first activity, I want you  to consider a cube of length L with n electrons.  There's n charges inside, and everything is at rest. ", "And what I want you to figure out  is what is the charge and current density [INAUDIBLE]  and j0 of this cube?  There's a second step. ", "As you can imagine, I ask you to consider the very same thing  from a moving reference frame, S prime, with some velocity  u which is the velocity of S prime with respect to S. ", "What is the charge in the current density now  in this new reference frame?  I'd like you to figure this out.  So now we look at this cube, and the total number of charges ", "is N. The length--  or the volume is l0 cubed.  And so the density is N divided by l0 cubed.  The current 0.  Nothing is moving. ", "There's no moving charges [INAUDIBLE]..  All right, this one is more straightforward.  But now in our moving reference frame, the situation changes.  Here, one of the directions-- the direction in which we are ", "moving--  is Lorentz contracted.  So we have lx equal to lx 0 or l0, times--  divided by gamma, or times square root 1 minus u ", "squared over c squared.  The volume then of the same cube in the S prime reference frame  is l0 cubed divided by gamma. ", "The number of electrons, however,  is unchanged, so the charge density is the previous charge  density divided by the volume.  And if you compare-- ", "sorry, it's the charge divided by the new volume which  is the density times gamma.  For the new charge density, we simply ", "have to multiply the current density.  For the current density, we have to multiply the charge  density times the velocity. ", "And again, we find ro 0 times 0, times gamma.   Good.  So if you look at those relations,  they look very much like the relationship ", "between the current and the charge density.  They look very much like the relations  we had between momentum and energy, and time and space.  And Lorentz transformation looks very similar. ", "So we can, motivated by this, write  a 4 vector, which is the first component c times the density.  And as the first, second, and third component, the current. ", "And you find that the invariant here  is very similar to time and space, energy and momentum  given as the density where the charges are addressed. ", "And that's the invariant, and you can calculate this  from multiplying the 4 vector [INAUDIBLE] square [INAUDIBLE].. ", "So concept questions.  Is the electric charge conserved in the Lorentz transformation,  or did we actually change the charge?  So we have the charge density here and the current here, ", "but did we actually change the charge  on the Lorentz [INAUDIBLE]?  The answer is, no, we did not change them,  so the charge is conserved.  The charge is invariant in the Lorentz transformation. ", "Is electric current conserved in Lorentz transformation,  or invariant on the Lorentz transformation?  Should rather use invariant [INAUDIBLE]..  And the answer is, no, it's not. ", "So we have seen from the very first example  that you start with the current which is 0,  and then in the S prime frame, the current  is of a certain value.  So certainly, the current was seen  from two different observers is changed. ", "to electromagnetism [? already. ?] So first I just  want to remind you how we relate electric and magnetic fields  and how we can describe them from a different moving  reference [? point. ?] So if the reference point moving in x ", "direction, then the x component of the fields do not change.  But the transverse components do change,  as we have discussed before.  The core of this section is about how ", "the fields-- the electric and magnetic fields  are actually generated by charges  and their distributions.  And this relation is described by Maxwell's equation.  The entirety of 8.02 are classes on electromagnetism ", "is about how to understand Maxwell's equations.  So I'll do this here in a very short and brief manner.  So you can write Maxwell equations  in four different equations. ", "The first one is called Gauss's law.  And if you read the equation, it just  says that the divergence of an electric field  gives the density of the source or the charge  density of the source. ", "You can also read this equation by saying a charge density  generates an electric field.  So charges generate electric fields. ", "Similarly, Gauss's law for magnetism  can be read as magnetic charges generate magnetic fields.  Or the diversion of the magnetic field ", "is the density of the magnetic source.  However in nature, we haven't observed magnetic monopoles  or at least not yet.  And so therefore, there's no such thing. ", "There's no magnetic density.  You can read this equation also saying that all magnetic field  lines need to be closed.  And so that's another way to look at this. ", "And we have Faraday's law, which means  that we can induce electric fields  in a coil equal to negative change of the magnetic field.  In other way, if you want to create an electric field, ", "you can do this with a charge.  Or you can do this by changing, as a function of time,  the magnetic field.  Changing magnetic fields generate electric fields. ", "And very similarly, we can look at Ampere's law  and saying that changing electric fields generate  magnetic fields.  And you can also generate magnetic fields with a current, ", "as we have seen in the previous [? section. ?]  So this is how we can understand [INAUDIBLE] Maxwell's  equations.  The difficulty now, 8.02, is often  to understand the concept of fields, the fact ", "that there is a [? vector ?] describing  the strengths of this abstract thing,  of an electric or magnetic field somewhere in space or  [INAUDIBLE] are changing this time.  That's [? complicated. ?] ", "And then there is also a little bit  of functional analysis needed in order to understand  and how to apply the electric field by a specific charge. ", "Those cases can often be simplified by having  symmetric configurations, like a charged atmosphere,  or a point charge, or a cylinder,  or charges along the line. ", "In those cases, those integrals or those divergences  can be calculated in a straightforward manner.  OK, so then there's another aspect  which is relating [? charge/discharge ?] ", "distributions or fields to forces.  And that's done by Lorentz force.  So the force of the charged particles  which is moving in electromagnetic field  is given by the strength of the charge itself ", "times the electric field, plus the velocity of the charge,  plus the strength of the magnetic field.  OK, what that means is I can--  if I put a charge in an electric field, it's being pulled. ", "It's being accelerated.  If I have a moving charge in a magnetic field,  it's being bend around or the force bending it around.  And then I can have this relativistic equation ", "of motion, which uses our relativistic equation of motion  and sets it equal to our Lorentz force. "], "vid_duration": [10.399, 12.181, 11.77, 12.7, 11.42, 11.85, 11.76, 11.05, 11.75, 12.27, 12.388, 12.442, 12.035, 10.105, 13.57, 13.11, 10.83, 12.48, 10.95, 12.44, 10.738, 11.851, 10.121, 11.18, 10.48, 14.33, 11.815, 10.125, 11.29, 14.11, 10.14, 11.929, 11.41, 11.09, 12.99, 11.13, 11.449, 13.561, 11.12, 11.01, 10.766, 11.854, 13.449, 12.791, 12.26, 11.34, 11.41, 11.43, 12.75, 12.24, 12.51, 11.15, 6.771], "stet": [[0, 10.399], [10.399, 22.58], [22.58, 34.349999999999994], [34.349999999999994, 47.05], [47.05, 58.47], [58.47, 70.32], [70.32, 82.08], [82.08, 93.13], [93.13, 104.88], [104.88, 117.14999999999999], [117.14999999999999, 129.53799999999998], [129.53799999999998, 141.98], [141.98, 154.015], [154.015, 164.11999999999998], [164.11999999999998, 177.68999999999997], [177.68999999999997, 190.79999999999995], [190.79999999999995, 201.62999999999997], [201.62999999999997, 214.10999999999996], [214.10999999999996, 225.05999999999995], [225.05999999999995, 237.49999999999994], [237.49999999999994, 248.23799999999994], [248.23799999999994, 260.08899999999994], [260.08899999999994, 270.2099999999999], [270.2099999999999, 281.38999999999993], [281.38999999999993, 291.86999999999995], [291.86999999999995, 306.19999999999993], [306.19999999999993, 318.01499999999993], [318.01499999999993, 328.13999999999993], [328.13999999999993, 339.42999999999995], [339.42999999999995, 353.53999999999996], [353.53999999999996, 363.67999999999995], [363.67999999999995, 375.6089999999999], [375.6089999999999, 387.01899999999995], [387.01899999999995, 398.1089999999999], [398.1089999999999, 411.09899999999993], [411.09899999999993, 422.2289999999999], [422.2289999999999, 433.67799999999994], [433.67799999999994, 447.2389999999999], [447.2389999999999, 458.3589999999999], [458.3589999999999, 469.3689999999999], [469.3689999999999, 480.13499999999993], [480.13499999999993, 491.9889999999999], [491.9889999999999, 505.43799999999993], [505.43799999999993, 518.2289999999999], [518.2289999999999, 530.4889999999999], [530.4889999999999, 541.829], [541.829, 553.2389999999999], [553.2389999999999, 564.6689999999999], [564.6689999999999, 577.4189999999999], [577.4189999999999, 589.6589999999999], [589.6589999999999, 602.1689999999999], [602.1689999999999, 613.3189999999998], [613.3189999999998, 620.0899999999998]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [376, 620]}
{"example_id": "mit038@@MIT8_06S18_L18_300k", "text": ["PROFESSOR: We began our introduction  to molecules last time and tried to get  a picture of the scales that are involved.  In these objects we spoke of a lattice of nuclei and clouds ", "of electrons in which a molecule had some scale,  A. Then we had electronic energies E, electronic. ", " We had vibrational energies.  ", "This is from the nuclei.  And we had rotational energies.  ", "And they were one bigger than the other  and bigger than the last.  In fact, the electronic energies were  bigger than the vibrational energies of the nuclei ", "and bigger than the rotational energies of the whole molecule  when it rotates as a solid body.  In fact, the ratio was like 1 to square root of little m over M, ", "where little m represents electron mass, and capital M,  the nuclear mass.  And so this number could be 10 to the minus 2, ", "and then you have m over M. So that's the proportions.  So this is larger than the second one, like 1  is larger than that, and the ratio between these two ", "is this.   So that's what we've discussed.  And we said that, in some sense, there ", "was an adiabatic approximation in the vibration of the nuclei.  As the nuclei vibrate, they pull the electronic clouds with it ", "in an adiabatic way.  That is, if you solved for the electronic cloud  as a function of position, that would  be a family of eigenstates. ", "Say the ground state of the electronic cloud  is a function of position, this would be a family of states.  If the positions of the nuclei change in time, ", "you could use those as instantaneous eigenstates.  And there is a sense in which this is a good approximation,  given that the timescale associated ", "to the vibrations of the nuclei is  much bigger than the timescale associated  to any variation in the electronic configuration.  This is just because of the scales of the energies. ", "So let's implement this idea in an approximation that  is used to solve molecules.  And we'll discuss it in all detail. ", "I'll skip one step of the derivation.  One calculation will be in the notes,  but I don't want to go through the details in class. ", "And we will appreciate the form of the nuclear Hamiltonian, how  it behaves.  So this is going to be the Born-Oppenheimer approximation. ", " And we will consider the situation ", "where we have N, nuclei--   capital N, nuclei-- and little m, electrons. ", " So it's a many-body wavefunction and a many-body situation. ", " In such cases, your notation is important.  You have to define labels that help  you distinguish this situation. ", "So here are the labels we're going  to use for the nuclei, P alpha and R alpha, where alpha ", "denotes which nuclei you're talking about.  So it goes from 1 up to capital N,  because there are capital N nuclei ", "for each nucleus, the first, the second, the third.  There is a momentum operator and a position operator,  each one of which is three components, because molecules ", "live in three dimensions.  So this is one vector and another vector  for each value of alpha.  In fact, these are operators. ", "We're doing quantum mechanics, so these  are our canonical pairs for the nuclei,  canonical pairs for the nuclei. ", "We need similar variables for the electrons,  and we'll use little p and little r,  both vectors, both operators. ", "And this time this i runs from 1 to lower case n.  And these are the canonical pairs for the electrons. ", " So when we write the Hamiltonian,  it should be a Hamiltonian that depends on all those variables. ", "And we can write the Hamiltonian,  because we know the physics of this situation.  We think of this is a lattice of nuclei, ", "and there is the cloud of the electrons,  and we have a coordinate system.  Here is maybe capital R1 and capital R2. ", "They're all there.  And well, when we write Hamiltonian,  we think of the electrons at some points and write things.  So let's write the Hamiltonian. ", "So this is going to be the total Hamiltonian.  What should I include?  I should include kinetic terms for each of the nuclei.  So I should put sum over alpha. ", "I don't have to repeat here from 1 to capital N.  You know already what alpha runs over.  P alpha vector squared over 2M alpha. ", "M alpha is the mass of alpha nucleus.  It could be a collection of protons and neutrons. ", "Then there's going to be--  and we get a little more schematic-- a potential that  depends nucleus with nucleus. ", "So the nucleus, among each other,  have a Coulomb potential.  So there's going to be a potential that represents here,  and it will depend on the various R's. ", "I could write-- this looks funny.  You say, which R?  Well, it depends on all the capital R's.  So I could write depends on this set  that, but it's a little too cumbersome. ", "I'll just write V of R, like this.  And this is, if the nuclei lived alone, that would be it. ", "This would be the kinetic energies and the potential  between the nuclei.  Then there's going to be what we can call a Hamiltonian that ", "only involves the electrons.   In some sense, that gives dynamics to the electrons--  not only involves electrons, gives ", "dynamics to the electrons.  And this Hamiltonian, H e, is going to depend on--  well, this big Hamiltonian for all the molecules ", "depends on the two canonical pairs  for times N times little n.  This Hamiltonian for the electron will depend ", "on the p's, will depend on the r's, and it will also depend  on the capital R's.  And you can think of it, and that's reasonable. ", "Suppose you're an electron.  Who affects you?  Well, you get affected by your electron friends,  and you get affected by the nuclei ", "and therefore, by the positions of the nuclei, as well.  So this is the electron part of the Hamiltonian.  And it would be given by a sum of kinetic energy, as usual. ", "So i, sum over i this time, little p, i squared over 2m.  Let's assume, of course, all the electrons are the same mass. ", "And then we would have, just in this shorthand, a potential  that represents the interaction of the electrons ", "with the nuclei.  And that potential would depend on the R's, on the R's.  ", "And finally-- my picture maybe should be moved the little  to the right--   there's a term, the electron potential that just depends ", "on the R's.   So all these potentials are Coulomb potentials,  Coulomb from nucleus-nucleus, nucleus-electron, ", "electron-electron.  So here it is.  You've written the Hamiltonian.  And if you have three nuclei and five electrons, ", "you could write all the equations.  And it's a nice thing that you can write the Hamiltonian,  and you could dream of putting it into a computer,  and it will tell you what the molecule is, ", "and that's roughly true.  But even for a good computer nowadays, this is difficult.  So you have to try to think how you can simplify this problem. ", "So one way to think about it is to think again  of the physics of the situation.  We'll have a separation of scales.  It's lucky we have that separation of scales, ", "very light electrons, very heavy nuclei.  So let's think of a fixed nuclear skeleton, ", "and consider electron states associated  to that fixed nuclear skeleton.  The nuclear skeleton is not fixed. ", "In principle, the nuclei are not classical particles  with fixed positions.  They're going to vibrate.  But we're trying to understand this problem,  and to some approximation, we can roughly ", "think of them localized.  So let's exploit that and use the vibrations.  So for large M alpha, this [INAUDIBLE] to large M ", "alpha, consider a fixed nuclear skeleton.  ", "So that means fixed R alpha, all the R alphas, and fix.  And now calculate the electron states ", "as a function of our alpha.  ", "So you simplify the problem.  Ignore all this dynamics of the nuclei,  all this nuclear-nuclear interaction. ", "Focus on the electrons as if the nuclear  are completely fixed, and try to figure out the dynamics.  So there are going to be many electronic states. ", "This is electrons in some fixed potential.  Any particle in quantum mechanics in a fixed potential.  There are many energy eigenstates.  So these electrons are going to have many energy eigenstates. ", "So let's try to decide on a name for this wavefunction.  So I will call them phi for electrons. ", "If there are wavefunctions that are wavefunctions  of the electrons, naturally, they just  depend on the electron positions, nothing else. ", " A wavefunction for a particle depends on the position.  Now, this r hides a little of-- ", "thing.  This really means that phi of r1, r2, r3, r4,  because they're little n electrons,  so it's not just one variable. ", "So I can say this is r1, r2, all of them, r little n. ", "That's a wavefunction.  Now, we said there are many of those states.  So there will be the ground state, the next one,  the next one, the next one.  So we should put an i in this. ", "Maybe an i in this is the wrong letter,  given that they have i there--  k in this.  ", "But there is more dependence here.  There is implicit dependence on the positions of the lattice,  because these wave functions depend ", "on what lattice square did you place the nuclei.  At this moment, you're placing them arbitrarily.   So this means that this wavefunction really ", "depends, of course, of how did you build the lattice?  Did you build the lattice this way,  or did you build it this way?  It makes a difference.  So it depends on the capital R's, as well, ", "which is the position of the lattice.  So here is our wavefunction.  I will simplify the writing by writing  phi of capital R, little r, and k here, see. ", " So what equation do we demand from this?  Well we have the electron Hamiltonian. ", "So that's what we should solve.  We should solve H electron, on phi R, k of r. ", "We'll have some energies, and those energies  will be electronic energies.  That's for electronic energy. ", "It will depend on k-- those are the various energies, as well--  and what else?  Certainly the energies don't depend on r. ", "That's your eigenstate.  But they can depend and will depend  on capital R. Capital R is the parameters that ", "define your lattice.  Clearly they should depend on that.  And then you have phi k, R, r. ", " So this is the equation you should solve in order ", "to find electronic states associated with a skeleton.   And now suppose you wanted to find a complete solution ", "of the Schrodinger equation.  You say, ah, approximations.  Why should they do approximations?  I can solve things exactly, which is almost never possible, ", "but we can imagine that.  So what would be a possible way to write an [? n-set ?] would  be the following. ", "You could write a psi for the whole thing now that depends  on the R's.  And the R's wavefunction for the whole degrees of freedom ", "of the molecule could be written as a sum over k  of phi K, R of r times solutions, eta k, that ", "depend on capital R.  That is, I'm saying we can try to write ", "the solution in which the full wavefunction for the molecule  is the sum of states of this form, a solution here ", "and a solution there.  ", "This is correct, but then how do you determine the etas?  The only way to determine the etas ", "is to plug into the full Schrodinger equation--  this is the full Hamiltonian.  So you would have to plug this into the full Schrodinger ", "equation and see what you get.  So what are you going to get?  Presumably, you did solve this first part. ", "So the phis are known.  So if the phis are known, you're going  to find differential equations for the etas.  ", "So this problem has become now a problem of finding solutions  for the etas.  And there are many etas, and they are all coupled ", "by the Schrodinger equation.  So by the time you plug this into H, ", "the total H, capital psi Rr equals  sum Eq, sum energy eigenstate-- ", "I don't have to put the thing--  psi Rr, to find the energy eigenstates of the molecules.  This equation is going to imply a set of differential ", "equations, a couple differential equations for the etas.  And that's not so easy to do.  That's pretty hard in general. ", "So this is very difficult.  On the other hand, there is a way  to think of this in a simpler context. ", "We can try-- and now we are approximating--  so try to believe that you can get an approximate solution, ", "approximate.  And I will justify this solution using  just one term in this equation, and psi phi R of r. ", "And this may be the ground state of the electronic system.  That's why I don't put an index here.  I could put a 0 there, but let's think ", "of this as the ground state.  And then, well, this would be accompanied,  if there is some solution, by sum eta of R. ", "And I can try to say that your wavefunction is this, ", "one term in this equation, the one in which I pick the ground  state and leave it there.  Now, this is definitely not going ", "to be an exact solution ever of the Schrodinger equation.  So you really are--  if you just take one of these terms-- ", "out of luck in terms of solving this exactly,  because this differential equation,  this Hamiltonian, has terms mixing ", "the two degrees of freedom.  It doesn't separate.  You cannot show that the Schrodinger equation has  a solution which is one thing that solves an equation and one ", "thing that solves another equation that are products like  that.  It will not happen.  That's why in this equation when you plug in, ", "the various etas get coupled.  But this is the spirit of the adiabatic approximation,  in which we sort of have an electronic cloud ", "and a nuclear state, and when the nuclear state changes  slowly, the electronic cloud adjusts,  and you don't have to jump to a state  with another electronic cloud. ", "The electronic cloud adjusts.  So this is in the spirit of the adiabatic approximation,  to try to find the solution of this kind, in which ", "an electronic cloud is not forced  to jump, because the coupling between those states,  saying that if you start with one eta of one phi, ", "you need all the rest, as the Schrodinger equation tells you.  It is a statement that the electronic cloud just cannot  stay by itself where it is. ", "So here we go.  This is what we're going to try.  And you can say, well, all right.  So you're giving up the Schrodinger equation, ", "because exact Schrodinger equation is not solved by this.  How are you going to try to understand now the eta?  Because we found these guys, so how about the etas? ", "How are we going to find them?  PROFESSOR: All right, so how do we solve this?  This is a very interesting thing,  and I think it points to all kinds of important things ", "that people find useful in physics.  So here it is, the way, maybe, we can think about it.  Think variational method. ", "What is the variational method?  You write a wave function and you  try to see what is the expectation  value of the Hamiltonian and that wave function. ", "You calculate it, and now you know that the ground state  energy is below that number.  Because for the real ground state  expectation value of the Hamiltonian  is the ground state energy. ", "For an arbitrary state it's more than that.  So the variational method says, OK,  if you want to figure out what is a good wave ", "function, compute the expectation value of your wave  function in the Hamiltonian, and then you will see, ", "you will get some energy.  If you tinker with your wave function  you can get to the right energy.  So this is what we're going to do  we're going to try to take this psi of r, r ", "and put the total Hamiltonian here.  And now that psi of r, r is going to be this one from now  on.  This is psi of r, r. ", "We'll put it here, and then I'll put another psi of r, r.  ", "And I have to compute that.  But think of it-- it's actually pretty nice, the situation. ", "Computing this, you could say how can I  compute that if I don't know the etas, the single eta that  is there?  I know the Hamiltonian but I don't know the eta, ", "so I can't compute this.  But think of this really, this is an integral, because there's  an [INAUDIBLE] over all the capital R's, ", "an integral over the little r's, and you can say,  oh, I know the little r's here.  I know them very well. ", "I found them.  I found this phi r.  I've determined it.  Some way you did.  So if I know that, I know the little r dependence, ", "and I can do all the little r integrals.  If I can do all the little r integrals, ", "means that this wave function is a product,  this wave function is a product, this  I can reduce to the following. ", "Eta of r, because this one I don't know, and then eta of r,  and I claim that all the part that ", "had to do with the phi of r, we can take care,  and then there's going to be some Hamiltonian here left.  And this we're going to call h effective of the r ", "degrees of freedom.   So a lot of physics in that step. ", "Seems like we did nothing, but look,  I'm supposed to minimize this by adjusting my trial wave ", "functions.  OK, but I don't have room to adjust the phi,  because I determined that it's a good one.  So I put it in and I calculate this. ", "Now I have to minimize this.  But if I have to minimize this for just v nuclear wave  function, I have found the effective Hamiltonian ", "for the nuclei, in which the electron has essentially  disappeared from this interaction. ", "It just doesn't play a role anymore.  This is the idea of effective Hamiltonians  for slow degrees of freedom when you integrate ", "fast degrees of freedom.  The fast degrees of freedom are your electrons.  We're getting rid of them, we're integrating them.  We're going to try to do that.  So this will be an effective Hamiltonian ", "for the nuclear degrees of freedom.  So let me do one term in here.  One term, you can play trying to do other terms, ", "and the notes will deal with that.  So let's consider the term He.  This Hamiltonian is some terms plus He. ", "It's over there.  So let's calculate what He does.  So I now have to put effect of He. ", "So I have to put here eta of r--  so let me put the whole thing.  It's integral over all the R's-- ", "R1, R2, R3-- integral over all the little r's.  That's an overlap.   Eta star of all the R's-- that's the [INAUDIBLE],, ", "phi star R of little r, He, then etas of capital R, phi R of r. ", " Everybody happy?  That's my term.  That's the contribution of He to the left hand side. ", " Good? ", "Now He is an operator and looks at this thing and says,  well, I don't think derivatives with respect to capital R, ", "so I'm there.  I take the derivatives with respect to little r,  I have a multiplicative factor, another multiplicative factor.  So I basically act just directly on this. ", "But He already acting on that gives you  the electronic energy.  So this would be the electronic energy in the ground state. ", "That depends on R times phi R. And lots of vectors.  ", "OK.   So this integral now becomes integral dR eta star of R. ", "Then I'll put the other integral, integral dr, phi  of r, star of r. ", "And then I have just this number times eta of R. ", "All right, so what is this integral?  Happily, this is just a number.  It goes out of this, it's an orthonormal state.  So this whole thing is dR eta star of R, Ee of R, eta of R, ", "which you could say is eta of R, the number Ee of R times ", "eta of R, and therefore you've confirmed  that the contribution to the effective Hamiltonian of all ", "this electron cloud is just this number, the electronic energy  like that.  So in the effective Hamiltonian, h effective, ", "there will be some terms and there will  be Ee of R. That's one term. ", " OK, so what is the whole answer for the effective Hamiltonian? ", " No way to guess it, I think, unless you're--  well, you have incredible intuition. ", " It's going to be a little complicated.  If you think about it, why?  Suppose this term is going to create no trouble whatsoever. ", "It's just going to copy itself.  This thing doesn't act on the electronic wave function,  so the electronic wave function's going to cancel,  is just going to contribute by itself. ", "So this term we've done.  This term is easy.  It just gives itself.  But this term is tough, because this term takes derivatives ", "with respect to capital R, and your wave function  depends on capital R. So it's going to be interesting. ", "So what is the answer?  I want to give you the answer rather than  do that calculation.  ", "And it's almost like sometimes physics  seems to have just a limited bag of tricks, ", "and things come out in some way or another in a simple way.  So what is the effective Hamiltonian? ", "You could say, OK, it's going to be the sum of kinetic terms,  2m alpha over alpha, and you have p alpha squared. ", "Well, it's not going to be just p alpha squared.  There's going to be a little more.  And then there's going to be a potential, a great potential  of R, and that great potential of R ", "is going to include the nuclear nuclear R potential.  We said that this nuclear nuclear term would just  copy along. ", "The He we calculated, and that gives us the Ee of R.  And you say, well, maybe that's it,  but no, it's not that, that's it. ", "So let's see what it gives you.  OK, so here it comes.  You remember electromagnetism, you  could change this thing here? ", "Well, it gets changed, and it will become p minus a alpha.  Like if there would be a connection. ", "Like if there would be an electromagnetic field.  There's no electromagnetic field here, nothing whatsoever.  But there is one thing, and what is it? ", "As we'll write here, it turns out to be a Berry connection.  Because you have the adiabatic thing  and you have your states that depend on R, ", "the Berry connection shows up.  So it shows up like this here.  And here it shows up in a couple of funny terms. ", "A term of the form alpha h squared over  2m alpha, integral vr, gradient sub r ", "alpha of phi r squared, minus sum over alpha ", "a alpha squared over 2m alpha.   So that's the whole thing, but I haven't defined the a. ", "", "What is the a?  Well, it's sort of a Berry connection.  So you know what a Berry connection is.  It's a v with a R in configuration space of a wave ", "function with the star wave function, integrated.  That was kind of a Berry connection.  So it turns out to be very similar here. ", "The a alpha vector of R is ih bar,  the integral over the little space-- the electron space. ", "That's where you integrate things--  of the electric wave function star times  the gradient with respect to R alpha of the electron wave ", "function of R.  That is the Berry connection.  If you remember, it's an overlap of wave function, wave function ", "and the gradient with respect to the configuration space.  So that's a good Hamiltonian for a molecule ", "in the adiabatic approximation.  If this looks complicated, it's already  much simpler than what the real problem is, because  of the adiabatic approximation. ", "If you have these wave functions,  these electronic wave functions you can calculate these a's.  And this plays the role of the effective Hamiltonian ", "for the nuclei in this approximation.  So the variational principle essentially told us  what is the right way to describe ", "the interactions of the nuclei, given that the electrons have  already been fixed into a class of wave functions. ", "Now in general, this is the complete solution,  but in general it's hard to do it, still complicated. ", "So many times, people simplify.  Well, it might happen, for example,  if you have a simple enough molecule that your wave  functions phi r are real. ", "Now you remember that the Berry phase vanishes when  the wave functions are real.  These things have to be imaginary.  With another i they have to be real. ", "Connections are always real operators in the sense of r.  So if the electronic wave functions are real, forget it, ", "there's no Berry connection.  So many times the Berry connections are not there.  Even if there are no Berry connections,  this term might be there. ", "This is the gradient of this wave function with respect  to the R. And this term can be important,  even if there is no Berry connection. ", "So in some cases, the lowest order approximation of this-- ", "I think that's what this classically called  the [INAUDIBLE] Oppenheimer--   ignores the Berry phase and ignores this extra term. ", "So in that approximation, the lowest order approximation,  the effective Hamiltonian, is just  the sum over alpha minus h squared ", "over 2m alpha, Laplacian R alpha plus the nuclear nuclear  potential, plus the electronic contribution to the potential. ", "So you keep-- basically, forget about Berry.  That's higher approximation, higher order approximation, ", "higher order approximation.  Keep just the p, keep the nuclear nuclear,  keep the electronic.  And people have done a lot with this. ", "So that's how our treatment of molecules.  A pretty interesting thing. ", "And perhaps the most important lesson of all of this  is your way in which you can see how light degrees of freedom ", "impose dynamics in slow degrees of freedom.  And that's something you do in physics, in quantum field  theory, all the time.  You have the slow-moving degrees of freedom ", "and the fast-moving degrees of freedom.  And you integrate the fast-moving degrees of freedom,  and you find an effective Hamiltonian for the big things.  You may have quarks and all kinds of complicated things. ", "But at the end of the day, they form protons and neutrons,  and you can integrate the interactions of the quarks  to sort of find the dynamics of the particle that you observe. ", "PROFESSOR: So our example is a well-known one.  But it's important to understand it.  And it's a good example. ", "It's a familiar one.  It's the hydrogen molecule ionized.   And we spoke a little about it last time. ", "So let's do that now.   So H2 plus, hydrogen ion. ", "So what is this system?  Well, it is two protons sharing one electron. ", " That's basically it.  It's the fact that if you have a hydrogen atom-- ", " this is hydrogen-- you could bring another proton ", "and form a bound state.  That's an important thing in order to think about it-- ", "you see, you can ask what is the bound state  energy of your system?  It's the energy you need to dissociate your system.  But this system, if you have two protons-- ", "proton, proton-- and one electron,  it can be dissociated in many ways.  It can be dissociated by just totally separating ", "it and destroying it.  But it can be dissociated or liberated  by just removing the proton.  So this is already a bound state. ", "So if you think of energies, you have  the bound state the energy of hydrogen here, hydrogen itself, ", "and the H2 ion--  H2 plus-- must be lower because you could imagine ", "taking the proton out and somehow this system is  a configuration in which this proton is captured here.  So you should get lower energy than the hydrogen atom energy. ", "So that's the hydrogen ion.  And that should be still more energy  than if you bring another electron, which  is the H2 molecule. ", "You bring another electron.  This should bind this and the other electron  and lower its energy even more.  So how does one solve for this hydrogen ion? ", "Well, as we discussed, you first solve for the electronic wave  function when the protons are separated at distance r. ", " So we said fix the lattice.  So here it is.  The lattice is fixed.  It's a separation capital R. And now ", "I'm supposed to find the electron wave function.   Easy?  No.  It already is hard. ", "We spent several lectures-- you've been studying this three  times already, maybe, in quantum mechanics, the hydrogen atom,  one proton, one electron. ", "To protons, one electron is much harder.  I don't think there's a simple analytical way to solve it.  So already at this step we have trouble solving it. ", "What is the electron, Hamiltonian in this case?  The electron Hamiltonian is just one Laplacian here  minus h squared over 2m for the electron variable, ", "and then the potential that is the interactions  of the electron with the two nuclei.  So if we call this distance r1 and this distance r2, ", "that is the whole electron Hamiltonian.  Now, don't think of r1 and r2 as you have  two variables, two positions.  No, there is just one position. ", "The dynamical variables for this electron, this p  and r for this electron--  r is the position of the electron.  It happens to be that r is equal to r1. ", "And if you know-- so r1 is really  the length of r, the position of the electron.  And r2 is the length of capital R, ", "if we wish, all the way here, minus r.   r is the vector here, as well. ", " So there is r1 and r2, but it's not  two electrons or two variables.  It's just two distances that depend on the single position ", "of the electron.  And this is the momentum operator of the electron.   OK, so you can't solve this. ", "That's life.  It can't be solved.  But we can do something and we can do something variational.  We can try to find some kind of approximation ", "for the state of electrons and use that.  ", "So there is an [INAUDIBLE] that you  could try, a variational wave function,  for even the electron.  You see, in our argument in this lecture,  we did the variation and approximation ", "for the nuclear degrees of freedom or for that thing.  But even for the electron wave function, I can't solve them.  So I have to do a variational method.  Now, these variational methods have ", "become extremely sophisticated.  People do this with a series of Eigenfunctions  and find answers that converge with 15 digits accuracy. ", "It's just unbelievable what people can do by now with this.  It's a very nice and developed field.  But we'll do a baby version of it. ", "So this baby version is going to stay.  My wave function for the electron  as a function of position and as a function of the separation ", "is going to be simple.  It's going to be a sum of ground state wave functions.  It's going to be a number--  a, that's just a number--  times the ground state wave function ", "based on the first proton plus the ground state wave  function based on the second proton.  So these psis, or psi0 of r is the ground state wave function ", "of hydrogen pi a 0 cubed e to the minus r over a0.  ", "This is called-- people have given it a name,  even though it's--  you would say it's not that original to put some wave  function like that. ", "This is a simple approximation.  And the technique is called LCAO technique. ", " And this calls for Linear Combination of Atomic Orbitals. ", " A big name for a rather simple thing.  ", "It has some nice things about this wave function.  This system is invariant. ", "This molecule is invariant.  And they're taking a reflection around this thing changing ", "the first proton and the second proton.  So that's the symmetry of your Hamiltonian.  And it's the symmetry of [INAUDIBLE] ", "with the Hamiltonian.  So you can demand that your wave functions have that symmetry.  And this is nice here because if you change r1 and r2, ", "the wave function is invariant.  So that's a very nice thing about this wave function. ", "It shows-- you see, you can put in the variational method  anything and it will still give you some answer.  But if you put something that mimics the real wave  functions and the real wave function of this system ", "is going to have a symmetry under the exchange of the two  protons.  They're identical.  So this lattice that you've created has a symmetry.  So the electron configuration has to respect that symmetry. ", "So that's very nice.  Now, this is electronic wave function.  So I ask you, is this wave function better ", "where the protons are far away or when the protons  are very close to each other?  Give you a minute to think about it.  When is this approximation or this wave function better? ", " If the distance between the protons  is very little or the distance between the protons  is very large?  ", "You're right in that when the two things collapse,  this looks like a true wave function  because this is a solution when there's ", "a single nucleus and a single electron.  But this is the solution for hydrogen.  And it gives you the ground state of hydrogen.  But when the two protons collapse, ", "it has become helium nucleus.  It has two protons.  So it doesn't have the right decay rate.  It doesn't have the right Born radius. ", "On the other hand, when they're far apart,  it does have the right thing.  So this is very good.  It's excellent when the things are far away. ", "But it's not great when they're close together.  So here you go.  You have to normalize this wave function.  Even that takes some effort. ", "It turns out that the value of a for normalization--   the value of a is 1 over 2 1 plus a constant i. ", "And that constant i is e to the minus capital  R over a not times 1 plus r over a not plus 1/3 ", "of r over a not squared.  Wow, so very funny.  It's not so easy to even calculate the normalization ", "of this thing.  But that's the normalization.   And then recall that what we have to do ", "is just put the electronic Hamiltonian inside this wave  function, this phi of r. ", "And this is going to give us an energy which  is approximately the electronic energy as a function of r. ", "So you have to evaluate the Hamiltonian--  I'm sorry, that Hamiltonian there-- ", "should have a square here.   And now we evaluate this. ", "We have to go even more into gross  and get what is the potential energy contributed ", "by the electronic cloud.   So here is the function that you get. ", "So our plot here I'll call--  this calls for a variable x, which ", "is going to be the separation divided by a not.  This is the separation between the protons divided by a not.  So here is going to be the electronic energy ", "as a function of x.  And here is x.   And all right. ", "So as x goes to 0, means the nuclei  are going on top of each other.  That's the place where the wave function is not all that great. ", "And that's not so good.  It turns out that here you get minus 3 Rydbergs.  Remember, the Rydberg was e squared over 2 a not. ", "And it's about 13.6 ev.  It's just the ground state energy of the hydrogen.  You do get that the energy due to the electronic configuration ", "is negative and it goes to this value.  And then it starts to grow quadratically and goes up.  And I want to know, in your opinion, what's ", "going to be the next asymptote?  So what is it going to asymptote as x goes to infinity?  ", "Let let's make the analogy.  The right answer is it actually stops here.   And you'll remember this problem that you've solved many times, ", "probably.  If you have a--  suppose a square well.  You have a wave function that is like that.  Now, if you have two square well-- and it ", "has a ground state energy.  If you have two square wells like that and you ask,  what is the ground state energy? ", "The ground state energy is roughly equal to the ground  state energy for a single square well because what happens  is that the wave function goes like that and then like-- ", "well, actually, like that.  So yes, the wave function spends equal time.  But it's the same energy as if there ", "would be a single square well.  So here it is.  The protons are very far away in the symmetric state, the ground  state.  The electron is half the times here, half the times there. ", "But the energy is the same energy  as if it would be in either one.  So this is an intuition that you may have from 804 or 805. ", "So here it is.  That's what it does.  That's good.  In fact, if you ride the ee of x over Rydbergs, ", "it behaves here like minus 3 plus x  squared plus dot, dot, dot.  So it starts growing and then asymptotes ", "with an exponential there.  OK, but what did we say was the Born-Oppenheimer approximation  was the idea that then you have dynamics of the nuclei based ", "on--   so Born-Oppenheimer tells you that the Hamiltonian ", "for the nuclear degrees of freedom is given by h.  This h effective is capital P over 2m squared ", "plus the nuclear nuclear potential,  plus this electronic energy. ", "So this electronic energy we already calculated.   The nuclear nuclear potential, in this case,  is the proton proton potential, v m n is e squared over r. ", "It is repulsive.  You see, this-- if you wanted to minimize the electronic energy,  you still don't get anything.  You get a system that collapses to zero. ", "That's certainly not the molecule.  But this n n is this, so we can write it as e squared over 2a0 ", "and then put a 2 over r over a 0 to get  all these numbers nicely.  So the nvv is a Rydberg times 2 over x. ", "So in terms of x there, vnn is a 2 over x--  oops-- a 2 over x potential like that. ", "So now you have the possibility of getting a stable grounding,  so the potential for the nucleons.  So the total potential for the nucleons ", "is the sum of these two potentials.   And how does it look? ", "Well, some of the two potential--  so ee of x plus vnn of x. ", "Let's divide by Rydberg as a function of x, goes--  here is minus 1.  ", "And it goes more or less like--  OK.  Let me try to get this right.  1, 2, 3, 4, 5. ", "OK.  It goes up here, down, crosses the minus 1 line, ", "and moves to a minimum here.  And then it goes like that. ", "Pretty much it's something like that.  It's a rather little quadratic minimum.  It's rather flat. ", "And these are the numbers you care for.  This is the minimum.  Maybe it doesn't look like that in my graph too well.  But it's a very flat minimum. ", "And r over a0 at the minimum is, in fact, 2.49. ", "And e over Rydberg at the minimum is minus 1.297. ", "Those are results.  Now, you have a potential.  You could calculate the quadratic term  around the potential.  And then you get an approximate oscillation Hamiltonian ", "that those would be the nuclear vibrations.  You could calculate the frequency  of the nuclear vibrations and the energy  of the nuclear vibration.  It's a very simple but nice model. ", "You can calculate everything pretty much about this molecule  and compare with experiments.  So how does it do the comparison with experiment? ", "It does OK.  It doesn't do very well.  So let me tell you what's happening.  So again, we do get this system. ", "Happily, the minimum was below minus 1.  The minus 1 was the situation in which you have a hydrogen  atom and a free proton. ", "So there is a bound state energy but the bounds state energy  is not conceptually right to think of it as this big energy. ", "It's just this little part here in which  this is the extra binding that you  can have when you bring a proton near to the hydrogen atom. ", "So this extra part--  so the bound state energy--   I'll write a couple of words here and we'll stop. ", " The bound state energy is E. This E that we determined here ", "at the minimum is minus 1 Rydberg  minus 0.1297 Rydbergs which is minus 1 Rydberg minus 1.76 ev. ", "So this is what you would call the bound state  energy of this system because it's the least energy you need  to start to dissociate it-- ", "not to dissociate it completely, but to start to dissociate it.  1.76.  True value is 2.8 ev, so not great, ", "but sort of order of magnitude.  Another thing that you can ask is,  what is the separation between the nuclei in this ion? ", "How far away are they?  And this gives a prediction that it's about 2.49 a0.  So separation is r equal 2.49 a0, which is 2.49 times ", "0.529 angstroms.  It's about 1.32 angstroms.  And through value's 2.8. ", "Experimental value, the value of r, our experiment  is not that far. ", "It's 106 angstroms.  So it's 20% there, 25% there.  But it gives you a way to think about this system. ", "You get all the physics.  You understand the physics.  The Born-Oppenheimer physics is that the electron  energy in the fixed lattice is a potential term for the nuclei. ", "Added to the nucleus nucleus repulsion  gives you the total potential term for the nuclear degrees  of freedom.  You can find the stable situation.  And if you want to do quantum mechanics and vibrations ", "of the nuclei, well, do the harmonic oscillator  associated with this thing.  The nice thing is you can complicate  these wave functions a little and get ", "better and better answers.  And it's fun.  It's things that can be done numerically.  And you have a remarkably powerful tool ", "to understand these things.  So with this, we'll close our whole chapter  in adiabatic physics.  And next time, we will begin with scattering. "], "vid_duration": [18.1, 13.778, 10.312, 11.85, 12.96, 18.92, 11.83, 12.66, 11.02, 12.03, 11.14, 12.05, 12.45, 14.04, 12.84, 10.2, 10.83, 11.4, 12.34, 10.34, 11.63, 14.71, 10.92, 12.06, 12.33, 15.88, 12.38, 11.73, 10.26, 12.85, 13.9, 12.18, 10.75, 16.45, 10.28, 10.43, 15.86, 11.45, 11.54, 11.25, 10.65, 13.219, 13.531, 12.27, 11.01, 14.64, 14.13, 11.51, 12.57, 15.3, 13.04, 13.97, 10.44, 14.19, 10.77, 11.01, 10.14, 12.12, 12.9, 14.84, 20.82, 11.15, 10.59, 15.33, 11.58, 10.38, 12.735, 10.616, 11.089, 10.29, 13.44, 11.4, 10.08, 12.71, 17.84, 15.53, 12.54, 11.76, 12.52, 11.07, 11.67, 10.229, 11.651, 15.63, 12.07, 10.2, 11.72, 23.48, 12.01, 11.34, 11.06, 10.08, 11.85, 10.02, 11.38, 10.32, 11.7, 12.44, 14.34, 11.69, 15.34, 12.35, 19.78, 13.19, 12.336, 15.524, 12.27, 13.02, 12.24, 11.1, 10.74, 15.12, 11.45, 11.29, 11.64, 10.23, 13.43, 11.55, 16.933, 12.85, 12.35, 11.16, 10.23, 10.34, 16.56, 10.112, 12.338, 10.62, 12.96, 11.04, 10.91, 11.99, 10.08, 10.03, 11.21, 14.75, 11.77, 10.26, 10.39, 13.67, 12.17, 10.5, 13.77, 12.21, 16.29, 13.56, 10.2, 14.07, 21.69, 12.4, 10.76, 12.45, 12.78, 15.33, 14.971, 24.919, 12.03, 24.8, 25.69, 10.58, 11.34, 13.83, 10.56, 12.32, 10.26, 15.47, 10.41, 14.25, 12.91, 10.2, 12.56, 11.28, 12.27, 14.16, 10.98, 11.68, 11.49, 12.75, 10.65, 10.38, 12.24, 12.96, 10.5, 12.69, 10.332, 11.798, 11.426, 12.994, 13.14, 12.23, 15.61, 10.96, 13.53, 13.97, 12.06, 12.84, 14.07, 10.77, 13.08, 12.34, 10.98, 13.09, 15.39, 12.32, 15.33, 10.62, 11.68, 10.34, 10.41, 13.41, 12.82, 11.16, 11.76, 11.06, 17.17, 12.135, 16.94, 16.105, 11.38, 14.67, 11.97, 11.67, 11.76, 11.43, 14.58, 13.11, 13.06, 10.505, 12.555, 10.29, 10.83, 12.51, 18.22, 17.54, 11.43, 12.09, 11.1, 11.275, 13.715, 13.5, 12.2, 15.18, 11.52, 11.25, 13.68, 12.84, 11.81, 13.12, 17.14, 15.03, 10.11, 11.46, 15.44, 12.94, 11.55, 11.25, 10.82, 10.205, 10.815, 12.45, 13.93, 10.95, 12.32, 13.59, 10.47, 10.47, 11.58, 11.27, 12.57, 18.04, 14.0, 11.76, 12.69, 11.74, 10.53, 10.32, 11.39, 10.11, 14.68, 11.22, 13.86, 10.55, 14.55, 15.6, 14.77, 14.88, 11.45, 14.99, 10.22, 12.07, 13.5, 10.49, 12.75, 11.28, 13.65, 10.11, 18.735, 10.215, 12.69, 10.45, 18.92, 13.89, 11.82, 15.48, 17.84, 12.65, 11.03, 15.13, 12.7, 12.42, 17.14, 11.05, 10.12, 12.2, 10.34, 20.34, 11.34, 12.06, 10.37, 13.18, 10.89, 10.93, 11.07, 12.41, 11.32, 18.33, 10.83, 18.66, 12.03, 21.33, 13.17, 10.95, 13.2, 15.02, 12.13, 11.4, 10.71, 9.827], "stet": [[0, 18.1], [18.1, 31.878], [31.878, 42.19], [42.19, 54.04], [54.04, 67.0], [67.0, 85.92], [85.92, 97.75], [97.75, 110.41], [110.41, 121.42999999999999], [121.42999999999999, 133.45999999999998], [133.45999999999998, 144.59999999999997], [144.59999999999997, 156.64999999999998], [156.64999999999998, 169.09999999999997], [169.09999999999997, 183.13999999999996], [183.13999999999996, 195.97999999999996], [195.97999999999996, 206.17999999999995], [206.17999999999995, 217.00999999999996], [217.00999999999996, 228.40999999999997], [228.40999999999997, 240.74999999999997], [240.74999999999997, 251.08999999999997], [251.08999999999997, 262.71999999999997], [262.71999999999997, 277.42999999999995], [277.42999999999995, 288.34999999999997], [288.34999999999997, 300.40999999999997], [300.40999999999997, 312.73999999999995], [312.73999999999995, 328.61999999999995], [328.61999999999995, 340.99999999999994], [340.99999999999994, 352.72999999999996], [352.72999999999996, 362.98999999999995], [362.98999999999995, 375.84], [375.84, 389.73999999999995], [389.73999999999995, 401.91999999999996], [401.91999999999996, 412.66999999999996], [412.66999999999996, 429.11999999999995], [429.11999999999995, 439.3999999999999], [439.3999999999999, 449.8299999999999], [449.8299999999999, 465.68999999999994], [465.68999999999994, 477.13999999999993], [477.13999999999993, 488.67999999999995], [488.67999999999995, 499.92999999999995], [499.92999999999995, 510.5799999999999], [510.5799999999999, 523.799], [523.799, 537.3299999999999], [537.3299999999999, 549.5999999999999], [549.5999999999999, 560.6099999999999], [560.6099999999999, 575.2499999999999], [575.2499999999999, 589.3799999999999], [589.3799999999999, 600.8899999999999], [600.8899999999999, 613.4599999999999], [613.4599999999999, 628.7599999999999], [628.7599999999999, 641.7999999999998], [641.7999999999998, 655.7699999999999], [655.7699999999999, 666.2099999999999], [666.2099999999999, 680.4], [680.4, 691.17], [691.17, 702.18], [702.18, 712.3199999999999], [712.3199999999999, 724.4399999999999], [724.4399999999999, 737.3399999999999], [737.3399999999999, 752.18], [752.18, 773.0], [773.0, 784.15], [784.15, 794.74], [794.74, 810.07], [810.07, 821.6500000000001], [821.6500000000001, 832.0300000000001], [832.0300000000001, 844.7650000000001], [844.7650000000001, 855.3810000000001], [855.3810000000001, 866.4700000000001], [866.4700000000001, 876.7600000000001], [876.7600000000001, 890.2000000000002], [890.2000000000002, 901.6000000000001], [901.6000000000001, 911.6800000000002], [911.6800000000002, 924.3900000000002], [924.3900000000002, 942.2300000000002], [942.2300000000002, 957.7600000000002], [957.7600000000002, 970.3000000000002], [970.3000000000002, 982.0600000000002], [982.0600000000002, 994.5800000000002], [994.5800000000002, 1005.6500000000002], [1005.6500000000002, 1017.3200000000002], [1017.3200000000002, 1027.5490000000002], [1027.5490000000002, 1039.2000000000003], [1039.2000000000003, 1054.8300000000004], [1054.8300000000004, 1066.9000000000003], [1066.9000000000003, 1077.1000000000004], [1077.1000000000004, 1088.8200000000004], [1088.8200000000004, 1112.3000000000004], [1112.3000000000004, 1124.3100000000004], [1124.3100000000004, 1135.6500000000003], [1135.6500000000003, 1146.7100000000003], [1146.7100000000003, 1156.7900000000002], [1156.7900000000002, 1168.64], [1168.64, 1178.66], [1178.66, 1190.0400000000002], [1190.0400000000002, 1200.3600000000001], [1200.3600000000001, 1212.0600000000002], [1212.0600000000002, 1224.5000000000002], [1224.5000000000002, 1238.8400000000001], [1238.8400000000001, 1250.5300000000002], [1250.5300000000002, 1265.8700000000001], [1265.8700000000001, 1278.22], [1278.22, 1298.0], [1298.0, 1311.19], [1311.19, 1323.526], [1323.526, 1339.05], [1339.05, 1351.32], [1351.32, 1364.34], [1364.34, 1376.58], [1376.58, 1387.6799999999998], [1387.6799999999998, 1398.4199999999998], [1398.4199999999998, 1413.5399999999997], [1413.5399999999997, 1424.9899999999998], [1424.9899999999998, 1436.2799999999997], [1436.2799999999997, 1447.9199999999998], [1447.9199999999998, 1458.1499999999999], [1458.1499999999999, 1471.58], [1471.58, 1483.1299999999999], [1483.1299999999999, 1500.0629999999999], [1500.0629999999999, 1512.9129999999998], [1512.9129999999998, 1525.2629999999997], [1525.2629999999997, 1536.4229999999998], [1536.4229999999998, 1546.6529999999998], [1546.6529999999998, 1556.9929999999997], [1556.9929999999997, 1573.5529999999997], [1573.5529999999997, 1583.6649999999997], [1583.6649999999997, 1596.0029999999997], [1596.0029999999997, 1606.6229999999996], [1606.6229999999996, 1619.5829999999996], [1619.5829999999996, 1630.6229999999996], [1630.6229999999996, 1641.5329999999997], [1641.5329999999997, 1653.5229999999997], [1653.5229999999997, 1663.6029999999996], [1663.6029999999996, 1673.6329999999996], [1673.6329999999996, 1684.8429999999996], [1684.8429999999996, 1699.5929999999996], [1699.5929999999996, 1711.3629999999996], [1711.3629999999996, 1721.6229999999996], [1721.6229999999996, 1732.0129999999997], [1732.0129999999997, 1745.6829999999998], [1745.6829999999998, 1757.8529999999998], [1757.8529999999998, 1768.3529999999998], [1768.3529999999998, 1782.1229999999998], [1782.1229999999998, 1794.3329999999999], [1794.3329999999999, 1810.6229999999998], [1810.6229999999998, 1824.1829999999998], [1824.1829999999998, 1834.3829999999998], [1834.3829999999998, 1848.4529999999997], [1848.4529999999997, 1870.1429999999998], [1870.1429999999998, 1882.543], [1882.543, 1893.3029999999999], [1893.3029999999999, 1905.753], [1905.753, 1918.533], [1918.533, 1933.8629999999998], [1933.8629999999998, 1948.8339999999998], [1948.8339999999998, 1973.753], [1973.753, 1985.783], [1985.783, 2010.5829999999999], [2010.5829999999999, 2036.273], [2036.273, 2046.8529999999998], [2046.8529999999998, 2058.1929999999998], [2058.1929999999998, 2072.0229999999997], [2072.0229999999997, 2082.5829999999996], [2082.5829999999996, 2094.903], [2094.903, 2105.163], [2105.163, 2120.633], [2120.633, 2131.0429999999997], [2131.0429999999997, 2145.2929999999997], [2145.2929999999997, 2158.2029999999995], [2158.2029999999995, 2168.4029999999993], [2168.4029999999993, 2180.9629999999993], [2180.9629999999993, 2192.2429999999995], [2192.2429999999995, 2204.5129999999995], [2204.5129999999995, 2218.6729999999993], [2218.6729999999993, 2229.6529999999993], [2229.6529999999993, 2241.332999999999], [2241.332999999999, 2252.822999999999], [2252.822999999999, 2265.572999999999], [2265.572999999999, 2276.222999999999], [2276.222999999999, 2286.602999999999], [2286.602999999999, 2298.842999999999], [2298.842999999999, 2311.802999999999], [2311.802999999999, 2322.302999999999], [2322.302999999999, 2334.992999999999], [2334.992999999999, 2345.324999999999], [2345.324999999999, 2357.1229999999987], [2357.1229999999987, 2368.5489999999986], [2368.5489999999986, 2381.5429999999988], [2381.5429999999988, 2394.6829999999986], [2394.6829999999986, 2406.9129999999986], [2406.9129999999986, 2422.522999999999], [2422.522999999999, 2433.482999999999], [2433.482999999999, 2447.012999999999], [2447.012999999999, 2460.982999999999], [2460.982999999999, 2473.0429999999988], [2473.0429999999988, 2485.882999999999], [2485.882999999999, 2499.952999999999], [2499.952999999999, 2510.722999999999], [2510.722999999999, 2523.802999999999], [2523.802999999999, 2536.142999999999], [2536.142999999999, 2547.122999999999], [2547.122999999999, 2560.2129999999993], [2560.2129999999993, 2575.602999999999], [2575.602999999999, 2587.9229999999993], [2587.9229999999993, 2603.2529999999992], [2603.2529999999992, 2613.872999999999], [2613.872999999999, 2625.552999999999], [2625.552999999999, 2635.892999999999], [2635.892999999999, 2646.302999999999], [2646.302999999999, 2659.712999999999], [2659.712999999999, 2672.532999999999], [2672.532999999999, 2683.692999999999], [2683.692999999999, 2695.452999999999], [2695.452999999999, 2706.512999999999], [2706.512999999999, 2723.682999999999], [2723.682999999999, 2735.8179999999993], [2735.8179999999993, 2752.7579999999994], [2752.7579999999994, 2768.8629999999994], [2768.8629999999994, 2780.2429999999995], [2780.2429999999995, 2794.9129999999996], [2794.9129999999996, 2806.8829999999994], [2806.8829999999994, 2818.5529999999994], [2818.5529999999994, 2830.3129999999996], [2830.3129999999996, 2841.7429999999995], [2841.7429999999995, 2856.3229999999994], [2856.3229999999994, 2869.4329999999995], [2869.4329999999995, 2882.4929999999995], [2882.4929999999995, 2892.9979999999996], [2892.9979999999996, 2905.5529999999994], [2905.5529999999994, 2915.8429999999994], [2915.8429999999994, 2926.6729999999993], [2926.6729999999993, 2939.1829999999995], [2939.1829999999995, 2957.4029999999993], [2957.4029999999993, 2974.9429999999993], [2974.9429999999993, 2986.372999999999], [2986.372999999999, 2998.4629999999993], [2998.4629999999993, 3009.562999999999], [3009.562999999999, 3020.8379999999993], [3020.8379999999993, 3034.5529999999994], [3034.5529999999994, 3048.0529999999994], [3048.0529999999994, 3060.2529999999992], [3060.2529999999992, 3075.432999999999], [3075.432999999999, 3086.952999999999], [3086.952999999999, 3098.202999999999], [3098.202999999999, 3111.882999999999], [3111.882999999999, 3124.722999999999], [3124.722999999999, 3136.532999999999], [3136.532999999999, 3149.652999999999], [3149.652999999999, 3166.7929999999988], [3166.7929999999988, 3181.822999999999], [3181.822999999999, 3191.932999999999], [3191.932999999999, 3203.392999999999], [3203.392999999999, 3218.832999999999], [3218.832999999999, 3231.7729999999992], [3231.7729999999992, 3243.3229999999994], [3243.3229999999994, 3254.5729999999994], [3254.5729999999994, 3265.3929999999996], [3265.3929999999996, 3275.5979999999995], [3275.5979999999995, 3286.4129999999996], [3286.4129999999996, 3298.8629999999994], [3298.8629999999994, 3312.792999999999], [3312.792999999999, 3323.742999999999], [3323.742999999999, 3336.062999999999], [3336.062999999999, 3349.6529999999993], [3349.6529999999993, 3360.122999999999], [3360.122999999999, 3370.592999999999], [3370.592999999999, 3382.172999999999], [3382.172999999999, 3393.442999999999], [3393.442999999999, 3406.012999999999], [3406.012999999999, 3424.052999999999], [3424.052999999999, 3438.052999999999], [3438.052999999999, 3449.812999999999], [3449.812999999999, 3462.5029999999992], [3462.5029999999992, 3474.242999999999], [3474.242999999999, 3484.7729999999992], [3484.7729999999992, 3495.0929999999994], [3495.0929999999994, 3506.4829999999993], [3506.4829999999993, 3516.5929999999994], [3516.5929999999994, 3531.2729999999992], [3531.2729999999992, 3542.492999999999], [3542.492999999999, 3556.352999999999], [3556.352999999999, 3566.9029999999993], [3566.9029999999993, 3581.4529999999995], [3581.4529999999995, 3597.0529999999994], [3597.0529999999994, 3611.8229999999994], [3611.8229999999994, 3626.7029999999995], [3626.7029999999995, 3638.1529999999993], [3638.1529999999993, 3653.142999999999], [3653.142999999999, 3663.362999999999], [3663.362999999999, 3675.432999999999], [3675.432999999999, 3688.932999999999], [3688.932999999999, 3699.422999999999], [3699.422999999999, 3712.172999999999], [3712.172999999999, 3723.452999999999], [3723.452999999999, 3737.102999999999], [3737.102999999999, 3747.2129999999993], [3747.2129999999993, 3765.9479999999994], [3765.9479999999994, 3776.1629999999996], [3776.1629999999996, 3788.8529999999996], [3788.8529999999996, 3799.3029999999994], [3799.3029999999994, 3818.2229999999995], [3818.2229999999995, 3832.1129999999994], [3832.1129999999994, 3843.9329999999995], [3843.9329999999995, 3859.4129999999996], [3859.4129999999996, 3877.2529999999997], [3877.2529999999997, 3889.903], [3889.903, 3900.933], [3900.933, 3916.063], [3916.063, 3928.763], [3928.763, 3941.183], [3941.183, 3958.323], [3958.323, 3969.373], [3969.373, 3979.493], [3979.493, 3991.6929999999998], [3991.6929999999998, 4002.033], [4002.033, 4022.373], [4022.373, 4033.713], [4033.713, 4045.773], [4045.773, 4056.143], [4056.143, 4069.323], [4069.323, 4080.2129999999997], [4080.2129999999997, 4091.1429999999996], [4091.1429999999996, 4102.213], [4102.213, 4114.623], [4114.623, 4125.942999999999], [4125.942999999999, 4144.272999999999], [4144.272999999999, 4155.102999999999], [4155.102999999999, 4173.762999999999], [4173.762999999999, 4185.792999999999], [4185.792999999999, 4207.122999999999], [4207.122999999999, 4220.292999999999], [4220.292999999999, 4231.242999999999], [4231.242999999999, 4244.442999999998], [4244.442999999998, 4259.462999999999], [4259.462999999999, 4271.592999999999], [4271.592999999999, 4282.992999999999], [4282.992999999999, 4293.702999999999], [4293.702999999999, 4303.529999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1487, 2687, 4307]}
{"example_id": "mit038@@MIT8_06S18_L12_300k", "text": ["PROFESSOR: Today, let's catch up with what we were doing before.  And last time, we were talking about hydrogen ionization.  And we went through a whole discussion ", "of how it would happen.  It was ionized because there would  be an electromagnetic wave within the hydrogen atom.  The initial state was the ground state of the hydrogen atom. ", "The final state was a plane wave.  Our main work was computing this matrix element,  and that's what we did last time.  It took us some work, because there ", "is a spatial integral here that was quite complicated, given  the various directions that are going on.  But that was our result. Here is the formula. ", "And a few things to notice here were  that there's an angle theta that we recognized  as the angle between the electric field polarization ", "and the momentum of the electron.   So k is the momentum of the electron,  and when k doesn't have a narrow, ", "it's the magnitude of the electron momentum.  As any k-- well, it's a little bit of an exaggeration. h bar k  is a momentum. ", "But we understand when we say that k's a momentum.  k times a, it has no units, which  is appropriate of the units of this quantity, ", "our units of energy.  And then another quantity here, E naught,  is the magnitude of the electric field defined by this formula,  with a 2 E naught here. ", "We discussed that the photon had to have an energy that it  was not supposed to be too big, so  that the wavelength of the photon ", "would be smaller, or much smaller  than the atom, in which case the spatial dependence  of the electromagnetic field would be relevant.  So for simplicity, with took photons ", "not to be too energetic.  And we also took photons to be energetic enough  that, when they would ionize the atom, ", "the electron that would go out would not be too affected  by the cooling potential, and we could treat it like a plane  wave to a good approximation-- ", "a free plane wave.  Otherwise, you would have to use more complicated plane  waves associated with a hydrogen atom.  So under this ranges, these ranges ", "translate to this ranges for the momentum of the electron.   And if the-- as required, the energy of the photon ", "is significantly bigger than a Rydberg, which is the 13.6 eV.  This is like 10 Rydbergs in here. ", "Then the momentum of the electron  is given by this formula to a good approximation.  It's essentially the energy of the photon, then  the square root of that. ", "The last ingredient in our computation  is the density of states.  This was calculated also a couple of weeks ago,  so you have to keep track of some formulas here. ", "There's some formulas that they're a little complicated,  but we'll have to box them and just be ready to use them,  or to spend five minutes really writing them. ", "And this was the formula for the density  of states with some energy E. With that energy E,  these were free plane wave states. ", "Energy E, momentum k associated with E, and being shot  into some solid angle in space. ", "And this is the solid angle.  So I wrote it as a solid angle in here.  So this is basically where we stood and, at this moment, ", "we want to complete the discussion  and get a simple expression, and simplify it, and get what  we need to have for the ray. ", "So, if you remember, Fermi's golden rule  expresses a rate omega in terms of 2  pi over h bar, rho parenthesis E, times Hfi squared. ", "So that's Fermi's golden rule.  And this is what we want to apply.  Well, we've calculated the matrix element.  ", "This would be Hfi prime here.  That's what we have up there.  We have rho.  We have this quantity, 2 pi over h bar is just a constant. ", "So we can simply plug this here, square that.  There's lots of h bars and things  that I don't think you'll benefit  if I go through them in front of your eyes. ", "So I'll write the answer.  But in writing the answer, remember  this rho is a differential, in some sense.  Some people might put you in a d rho ", "here, because there is a d omega.  So think of this, when I substitute rho,  I have the d omega, and I think of this ", "as the d w, a little rate.  So dw, d omega.  So I simply pass from w to I called it dw, ", "and substituted the rho here for d omega.  And here is what we get--  256 over pi, e E naught a naught squared over ", "h bar, m a naught squared over h bar squared,  k a naught cubed over 1 plus k a naught squared ", "to the 6th, and cosine squared theta.  ", "OK, it's still a little complicated.   But it's mainly complicated because of constants ", "that have been grouped in the best possible way,  in my opinion, to make it understandable.  This is an energy.  ", "And this is an h bar.  This is actually a Rydberg with a factor of 2.  So in a second, you can see that this thing ", "has units of 1 over time.  There's also an important factor here,  and that's an intuitively interesting fact, ", "that the emission of the electron  is preferentially in the direction  that the electric field is polarized.  There's a cosine squared theta. ", "There's no electrons emitted orthogonally  to the electric field.  And that's kind of intuitive.  It's almost like the electric field is shaking, ", "the electron, well, it kicks it out.   OK, this is a differential rate. ", "So the total rate w is the integral of this differential  rate over solid angle. ", "And for that, you need to know that the integral  over solid angle of cosine squared theta is 4 pi. ", " If you didn't have the cosine squared,  you would have the 4 pi.  But usually cosine squared, this is multiplied by 1/3. ", " You can do the calculation.  It just doesn't take any real time.  But many people remember this by thinking ", "of the sphere, or planet Earth.  Cosine squared theta is large near the North Pole.  It's large near the South Pole. ", "That doesn't amount to much.  As opposed to sine squared theta,  which is large all over the big equatorial region.  So it's a little bigger, and it turns out cosine squared, ", "the average over the sphere is 1/3.  And sine squared, the average over the sphere is 2/3.  Well, it's kind of not a bad thing to know, ", "because it saves you a minute or two from doing this integral.  And now, I'm also going to apply something that basically-- ", "you know, a formula sometimes gives you more things  than you should really trust.  And I would say here, this 1 is not to be trusted basically, ", "because k a naught must be significantly bigger  than this number probably for this to be accurate.  So under most circumstances, this 1 is not worth it. ", "In fact, if you calculate this thing  using different approximations, people sometimes  don't get this 1.  And you may see that in books.  So let's ignore this 1. ", "And then this answer is 512 over 3 e E naught a naught squared, ", "over h bar Rydberg, 1 over k a naught to the 9th.  Pretty high power. ", "And the answer starts to be reasonably simple.  This 9 arises because of 12 minus 3 here.  ", "This is still probably not ideal,  if you want to play intuition about what's going on,  and the scale of the effects. ", "You know, once you have a formula,  and you've worked so hard to get it--  this calculation is doing it reliably  is a couple of hours of work-- ", "and you might as well manipulate it  and try to make it look reasonably nice.  And this is what people that do atomic physics ", "do with this rate.  So they write it in the following way.  Again, a short calculation to get this 256 over 3. ", "And they put in atomic units, Ep over E star--  I will explain what these numbers are--  squared, 1 over t star, 1 over k a naught to the 9th. ", " I think it's important to notice as well that you could say, OK,  so how did the photon energy, or photon frequency, ", "affect this result?  Well, actually, the photon omega doesn't  seem to be anywhere here.  It has disappeared. ", "But it is implicit in the electron momentum,  because basically the momentum of the electron  is what is obtained from using the energy of the photon. ", "It ionizes the electron, liberates electron, and then  gives it some kinetic energy.  And, roughly, k equals like the square root of omega. ", "So there is an omega dependence here.  Now, what are these other quantities?  These quantities are simple.  Ep is the peak electric field. ", "It's peak electric in the wave that you've sent in.  So it's 2 E naught. ", "E star is the atomic electric field.  And that's defined as the electric field ", "that the proton creates at the electron.  So it's equal to E over a 0 squared. ", " That's the definition.  Or, if you want, in terms of Rydbergs,  2 Rydbergs over E a naught, and it's about 5.14 times 10 ", "to the 11 volts per meter.   So it's a nice quantity.  ", "It's in the land you're comparing your electric field  from your laser to the typical electric field in the atom.  And that ratio is meaningful. ", "And then t star is the time the electron takes  to travel a distance a naught. ", "So it's a naught over the velocity  of the electron, which is roughly the fine structure  constant times c.  You remember the electron roughly ", "has a beta parameter equal to 1 over 137.  This is [INAUDIBLE] alpha equal beta,  meaning the fine structure constant in alpha ", "is the beta of the electron.  So this is t star.  And it's actually two Rydbergs over h bar, ", "and it's 2.42 times 10 to the minus 17 seconds.  ", "That's the time the electron, which is not moving that fast,  takes to move a Bohr radius.  So this is the last form we'll take. ", "Atomic physics books would consider  that the best way to describe the physics of the problem.  ", "And this is really all we're going to say about ionization.  It's kind of a precursor of field theory calculations ", "you will do soon--  not in 806-- in which you do reasonably  complicated calculations, matrix elements, Feynman diagrams. ", "And, at the end of the day, by the time you're all done,  the answer simplifies to something rather reasonable, ", "PROFESSOR: Let's turn to our next subject then.  So this is still time dependent perturbation theory.  We will be doing time dependent perturbation theory a little ", "longer, all of today's lecture and a little of next time's  lecture.  So we're going to be talking now about light and atoms. ", "So this is a classic application of what time  dependent perturbation theory does, the problem of radiation ", "interacting with atoms is more and more detailed applications  and their ionization.  So light and atoms, and we think one ", "of the situations we will be considering  is a collection of atoms and they're interacting with light. ", "But the way they interact with light  is maybe not as controlled as we had in hydrogen ionization,  in which you send in a wave.  But rather, it's interacting with light ", "in thermal equilibrium.  So there's black body radiation.  There's all these photons, unpolarized, in all directions, ", "coming at the atoms in all ways.  And they can produce transitions in the atoms.  And for that purpose, we will consider a collection of atoms. ", " And we will assume that relevant to our situation,  we have two energy levels. ", " This state will be called b.  Still we'll call a, Ea and Eb. ", " So this is interacting with light or with photons ", "at a temperature T.  So a little bit of statistical mechanics today. ", "In order to discover what Einstein did,  basically, we're going to go through Einstein's argument  of balance of radiation rates and emission rates ", "and things like that.  And we need to use some statistical physics for that.  Einstein was very good at using statistical physics. ", "And the frequency associated with this transition  is Eb minus Ea over h-bar. ", "And we'll take it to be greater than 0.  The state b will be considered to be higher than the state a.  ", "So the question we ask is, what happens to these atoms  when light shines?  And in particular, suppose the light contains photons ", "with a frequency omega b-a.   That's the frequency associated with the transition. ", "So what will happen?  And basically, a couple of things can happen.  These are things we already know from time ", "dependent perturbation theory.  And surprisingly, as we will see,  Einstein, when he went through his argument  that we're going to go through soon, ", "came with a different angle and saw things  a little differently.  But let's follow up the direction  that is based on the evidence we've presented so far. ", "So there will be two possibilities, two cases.   In the first case, the atom is initially ", "with its electron on level a, electron in a.  ", "So what happens?  Well, we've coupled, a system with two levels, two harmonic  perturbations.  And we saw that sometimes the particle or the system goes up ", "and sometimes goes down.  And now we're going to see the source a little bit more  realistically.  Before it was a perturbation.  Now we're going to identify the perturbation. ", "The electron is in state a.  And here comes photons.  And what's going to happen is a process  of absorption of the photon. ", " And the electron goes to state b. ", " So we'll draw it here.  So this is before. ", " And here is after.   So before, you had this thing and the electron ", "was on state a.  There was a photon coming here with energy h omega b-a.  And then after, the electron has been pushed up. ", "And there's no photon anymore.  The photon was absorbed.  That's physically what we would expect.  The other possibility is associated to the process ", "of stimulated emission.  This is absorption.  And here we have electron in b initially. ", "And we have stimulated emission.  ", "And in this case of the electron goes to a. ", "And another photon is released.  ", "It's a very surprising thing if you think about it.  And here, this is the absorption process. ", "Now this stimulated emission process,  you have the electron originally in b.  And here comes the photon.  ", "And the end result is an electron in a and two photons.  ", "We notice that, when we're doing perturbation  theory between the two energy levels  and we have the harmonic perturbation,  we even notice the probability to go from the bottom ", "to the top or going from the top to the bottom  was the same in perturbation theory.  And you would have said, look, I understand ", "that when you have an electron in the bottom level,  you need some energy from the source to kick it up.  But why do you need this source to make it go down? ", "It's just there.  It should go down by itself.  Well, you still need to couple the system to something.  Because if you are in an energy eigenstate, ", "you stay there forever.  The reason it goes down is because it  couples to something.  And somehow, the coupling through the electromagnetic  field helps this go down. ", "That's why it's called stimulated emission,  because it's stimulated by the radiation itself.  And so this doesn't seem to play too much of a role, ", "but actually does, in which just by the presence  of a photon at the right energy difference,  it stimulates this to go down. ", "And now you have two photons.  So this is, of course, something that  is used in technology a lot. ", "This is the principle of lasers.   And therefore, this discussion of stimulated emission,  which was a lot due to Einstein, is the idea of a laser. ", "So laser is Light Amplification by Stimulated Emission  of Radiation.  So what do you need for a laser? ", "You need something that is kind of a little strange  to begin with.  Because from the viewpoint of statistical physics,  if you have a two-level system, particles ", "will tend to be in the lower level.  So why would they go here?  Well, they won't go there by themselves.  That's the term called population inversion. ", "You need to get the electrons that  are in the bottom to go up to the next level  and put them there.  That's a technical difficulty, of course. ", "And it's usually solved by optical pumping.  We are not going to be doing engineering here today.  But there is a third level here in a typical laser. ", "And you can send the electrons, that  are sitting originally here, with light  again into the third level. ", " And then it turns out that that third level,  if you have the right atom, has a transition to this level that ", "is rather quick.  So the electrons fall here, fall very quickly.  And the lifetime of this state here is very long. ", "So they pretty much stay there.  So this is the principle.  This extra level is sometimes called the pump level. ", "And so this is done by optical pumping, so optical pumping ", "to create population inversion.  That you get more states in the upper state ", "than you would get in thermodynamic equilibrium.  And then, you now have, say, the levels here-- ", "I'm going to draw them this way.  It makes it a little easier.  I think of one electron here, maybe two here,  maybe four here. ", "And then comes a photon and stimulates this electron  to go down.  And now you have two photons. ", "And they stimulate these two electrons to go down.  And now they have four photons.   They can stimulate these four electrons to go down. ", "Have now eight photons.   And that's the amplification process of stimulation. ", "Each time you stimulate one down, you achieve this.  In fact, technically speaking, apparently in good lasers, ", "this transition doesn't produce light.  You would say, oh, it produces more photons.  But there's some energy levels that  radiate by communicating vibrational energies ", "to the atoms.  So apparently these transitions are not electromagnetic.  And you don't mix more light.  So basically, stimulated emission of radiation ", "is the thing that gets this process going.  And that's what we're going to try to understand now.  The whole discussion that follows ", "and what we have to understand about light and atoms  will make all this quantitative and allow  PROFESSOR: Einstein's argument, we consider again our atoms. ", "And this time we're going to use the thermal equilibrium.  We're going to really make use of that fact.  So, again, we have level b and level a. ", "And this is Einstein's argument.  ", "And we're going to have no populations.  If we discuss equilibrium, we can consider a system in a box.  And there's a few billion atoms. ", "And there's some atoms whose electron  is going to be in state b.  Some atoms whose electrons are going to be in state a.  Let's call these numbers Nb and Na. ", "And we also have photons at temperature T ", "and have a beta parameter 1 over the Boltzmann constant times T.  So this is the process we're going to consider. ", "So what's going to happen?   If we came up from the edition that we've built from 806, ", "we would think, OK, there's going  to be absorption process and stimulated emission process.  And between the two, they're going ", "to be able to reach equilibrium.  We don't believe this is not a process that can equilibrate.  So this would be our intuition.  The intuition for people that lived ", "at the beginning of last century was rather different.  They felt that there would be absorption process ", "and there was spontaneous emission.  The thing that you probably intuitively would think,  if you are at a high level, you spontaneously decay. ", "So the thing that was not known to them  was this stimulated emission.  That is what Einstein is credited for discovering here. ", "People felt, and I think the paper finds that makes clear  that the intuition, is that you have  spontaneous emission, in which spontaneously ", "by some kind of instability, the higher state goes  to the bottom.  And you have absorption.  But then Einstein figured out that you couldn't achieve ", "equilibrium in that way.  Well, the way we're going to do it,  we're going to put the two things we know--  the absorption and the stimulated  emission-- and see that we don't get it ", "to work, the equilibrium.  But then when we add the spontaneous emission, we will.  And as it turns out, the spontaneous emission ", "is a little harder to calculate.  If we were to do it in 806, it probably  would be a matter of two lectures involving  an electromagnetic field. ", "So we will not do it.  But the good thing is that Einstein's argument tells you  the speed of spontaneous emission, the rate ", "of spontaneous emission, in terms  of this rate of stimulated emission or absorption.  So it does the calculation for you ", "by some other thermodynamical means.  So we're going to use here three facts.  ", "One is that the--  three facts-- one is the populations are in equilibrium.  ", "So Na dot is they stop changing is equal to 0.  And Nb dot is equal to 0.  They don't stop changing because nothing happens. ", "All the time there will be emission,  and there will be absorption.  But if you reach equilibrium, the number of atoms  remain the same on every state. ", "So that's our statement that the populations  achieve equilibrium.  The second statement is that the equilibrium is thermodynamical. ", "So it's thermal equilibrium.   That is Nb over Na, for example, is the Boltzmann factor e ", "to the minus beta, Eb over e to the minus beta Ea.  And this is equal to e to the minus beta h bar omega ba. ", "You get e to the minus beta, eb minus ea.  But eb minus ea is h bar omega ba.  So that's thermal equilibrium. ", "And the last thing that we need is  a statement about the photons.  What do they do when they have equilibrium? ", "And that was known already due the work of Planck  and others, black body equilibrium.  So we need to know something about the thermal radiation. ", " And the way one describes this is in terms of a function ", "U of omega d omega.  In the black body radiation, there  are at a given temperature, there  are photons with very little energy. ", "There are some largest number of photons  with some energy associated with temperature,  and then it decays.  So you have photons of all energy. ", "So if you want a description of what's going on in black body  radiation, you can consider the energy  in the photons in the frequency range. ", "But you even must be more precise.  It is the energy per unit volume in a frequency range.  Because if it's different, the energy of the black body ", "cavities, this room or it's a little box.  So it's an energy per volume per frequency range.  And that's what this quantity is. ", "So let me write it.  Energy per unit volume in the frequency range dw. ", "In other words, it's kind of a proxy for the number of photons  available.  All the photos have at some value of the frequency, ", "of energy e omega.  So if you know the energy, you basically  are getting here the number of photons with frequency omega  in that range per unit volume, all that stuff. ", " So this has a formula.  And the formula that was known to people ", "was this quantities and then omega cube, d omega, over e  to the beta h bar omega minus 1. ", " So this is the basis of the calculation. ", " What do we do?  We have to consider the possible processes.   OK, so our processes are absorption. ", " And in this case, we go from a to b.  And let's try to write a rate for them. ", " So what would the rate depend on?  Well, here's some little assumptions. ", "Certainly, if you don't have particles in the a state,  you cannot have this process.  So this process, the total rate that we observe in the box ", "will depend on an Na.  The more particles you have in this state  a, the larger the probability that you get the transitions, ", "and the larger the rate.   It will also be affected by the number of photons ", "available at that frequency that can  produce a transition in proportional to that. ", "And finally, the quantity that our study of perturbation  theory will tell us about, but at that time, ", "finds that was not known, it's a transition coefficient, Bab,  he called it. ", "And this is the unknown one.   And this is what we don't know.  We know U. We assume we know Na.  This is the transition rate per atom ", "and then multiplied by the number of atoms.  So this is transition rate per atom.  ", "Then we have the process of spontaneous emission.  And then we will be another coefficient, Bba. ", "And it would depend on the number of particles  that are in the state b, because spontaneous emissions  that transition from b to a. ", " We call it-- oh, not spontaneous stimulated.  I'm sorry-- stimulated emission.  ", "This is the one we're considering.  It's stimulated by the radiation.  So it's also proportional to the number  of photons present and proportional ", "to the number of atoms that can be  convinced to do the transition times another coefficient, Bba.  So this is, I think, what we in 806 would do. ", "We would consider this two processes  and attempt to make it work.  And let's see what we get then.  ", "We're trying to get equilibrium.  So we want the transitions to equilibrate and, therefore,  the populations not to change. ", "So let's look-- for example--  you could look at either one, but you can look at Nb dot.  It should be 0. ", "But it's equal to the rate of absorption  minus the rate of stimulated emission. ", " You see because the number of particles in b  change because you get some new particles in state ", "b due to the absorption process.  And it happens with this rate.  And you lose some particle because some atoms  do the transition from the higher level to the lower ", "level.  So what is the rate of absorption?  We have it here.  It's this one, Bab U of omega ba Na. ", "And this one is Bba, the same U of omega ba Nb.   And we can factor the U out. ", "And this is the wrong calculation, I must say,  because we're missing that extra process that  was intuitive to Einstein, but to us it's ", "a little less clear--  Nb times U of omega ba.  ", "OK, I can do a one more little thing.  I can factor an Na.  And this becomes Bab minus Bba to the minus beta h bar omega ", "Ba U of omega ba.  OK, I use the ratio of Na over Nb being thermodynamical. ", "So Nb over Na was used from point two to get this.  And this should be equal to 0.  ", "But this equation can't be satisfied.   What do you have here?  You should be able to equilibrate at any temperature. ", "On the other hand, what is our intuition  about these quantities, Bab and Bba?  They should be temperature independent.  These are properties of the geometry of those states ", "and the overlaps of the wave functions.  These are atomic physics properties  of the levels of the particles.  We will calculate them. ", "And here is the input of how many photons there  are, how many atoms there are.  And the number of photons certainly  depend on the temperature.  The number of atoms for equilibrium ", "depend on the temperature.  But this is a factor that says, well,  how likely is the transition once you have a photon  and once you have an atom? ", "And that depends like we did for the ionization, calculated  some matrix elements that are totally  independent of temperature.  So these numbers are totally independent of temperature. ", "And we're asking this to be 0, which  requires this factor to be 0.  And this depends on temperature.  So you cannot attain equilibrium with this way. ", "So it's impossible to satisfy for all temperatures given ", "that Bab and Bba are constants.  ", "So we're missing a process.  This is the process that Einstein thought was intuitive,  the process of spontaneous emission. ", " So we add one more process.  It's called spontaneous emission. ", " And it's a process also from b to a. ", " And it's going to have a rate.  But it's not going to depend, that rate, ", "on the number of photons, because it's happening  independently of the photons.  So we don't have this U factor.  We do have the Nb because each of the b atoms ", "can spontaneously decay.  But we don't have the U factor.   So what do we have?  A rate, which is the term by a coefficient ", "that Einstein called it a, that's why the name a and b  coefficients of Einstein, a times and b.  ", "So that's the spontaneous emission rate  per atom multiplied by the number of atoms.  So we go back to our equation-- ", "rate of absorption minus rate of stimulated emission  minus the rate of spontaneous emission.  So I'll write it here. ", "0 is equal to Nb dot equal minus A Nb--  that's the spontaneous emission. ", "We write it first.  And then we'll write the other two--  Bba and Nb U omega ba plus Bab U of omega ba Na. ", " PROFESSOR: OK, so that's our equation.  Three terms-- first term, spontaneous emission,  second term, stimulated emission proportional to Nb, ", "third term increases Nb's absorption.  Our strategy now is, so what do you do with this?  This looks like a good equation, but what are we to do? ", "We haven't used three, really.  So we can solve for U. And this time, the equation  won't want to make U equal 0.  It will give us something. ", "And then we can compare with a thermal equilibrium relation  to get something.  So that's our goal.  So how do we solve for U? ", "Let's divide by Nb.   So divide by Nb. ", "So a 0 here, pass this to that side, and divide by Nb.  So you get A on the left-hand side equals-- ", " let's see, should I put the--  well, minus Bba Nb. ", "Actually, I'll do it like this--  the second term first.  Bab Na over Nb times U-- ", "so I'll put it here, a U of omega Ba--  minus Bba.  ", "OK, so I moved the first term to the left-hand side, grouped  the U. Why did I group the U?  Because I said, let's find what U ", "is, and try to compare with other things that we have.  So now we can solve for the U. U of omega ba ", "is equal to A divided by this quantity.  So it's A divided by a big thing. ", "Let me factor out the Bab.   So now we have here Na over Nb minus Bba over Bab, ", "or A over Bab 1 over Na over Nb is there, ", "is e to the beta h bar omega ba--   It's a minus sign with respect to number 2-- ", "minus Bba over Bab.   OK, this is great. ", "We're in very good shape.   In fact, we're here. ", "Let's compare with our thermal radiation.  So here is what we got.  And we have to compare with fact number ", "three, which is the thermal radiation formula, which  is h bar over pi squared C cubed omega cubed 1 over e ", "to the beta h omega.  And I'm comparing with the thermal radiation,  U of omega ab. ", "I canceled the D omegas, because this is U without the D omegas.  So omega ba minus 1. ", "All right.  It's perfectly nice and ready.  We need to compare this formula with this one. ", "They have to be equal.  Well, this factor, must be equal to this factor, given  that here you have e to the beta h bar omega ba. ", "These are constants.  And the first thing that you discover is Bba equal Bab.  And so yes, very nice.  This is what we learn in perturbation theory. ", "These two processes have identical rates.  So the first statement that this equality requires ", "is that Bab is equal to Bba. ", "So there's just one B coefficient,  just like there's one A coefficient.  And the second thing that you learn is that A over Bab ", "is this ratio--   is h bar omega ba cubed over pi squared C cubed. ", " So we will be able to calculate the B coefficients, ", "because they represent the familiar properties  of harmonic perturbations transitions,  and we've done already.  Calculating A is harder, in principle. ", "The process of spontaneous emission is a harder process.  But this relation says that we don't have to worry about it.  We already, if we know B, these are constants, we know A. ", "So many times, even in problems in the homework,  you will be asked, what is the spontaneous transition  rate for this decay? ", "You have an oscillator.  It's in an excited state.  What is the rate of spontaneous transition?  And then you say, OK, this is complicated.  But you calculate the stimulated transition rate, ", "and then plug in this coefficient.  So it will not be difficult.  Now, spontaneous emission, as we discussed there in the top, ", "doesn't include the factor having  to do with the density of photons, the U that tells you  how many photons there are.  Because the photons play no deep role ", "in producing the transition.  But at some level, this transition--  while it's not stimulated by the photons that are flying ", "around--  when you calculate it, in a serious, detailed calculation,  you can think of them as stimulated ", "by the vacuum fluctuations of the electromagnetic field.  So if you were to quantize the electromagnetic field,  there are vacuum fluctuations. ", "And those vacuum fluctuations, you could say,  they are stimulating what we call \"spontaneous emission.\" ", "So at the end of the day, the electromagnetic field  is a quantum field.  And therefore, it has zero point energies, Casimir effects,  vacuum fluctuations. ", "You can't get away from it.  So in some sense, everything is stimulated emission,  stimulated by a lot of photons or stimulated ", "by the vacuum fields.  Anyway, we'll still remain with the name  \"spontaneous emission,\" and keep those things very distinct. ", "These rates have different effects  at different temperatures, as well.  So we'll consider that, for example, ", "in that at low temperatures, the black body radiation has a very  little number of photons.  So most of the transitions, if they occur, ", "are happening due to spontaneous transitions.  On the other hand, as you increase the temperature,  the number of photons that are available per unit volume ", "increases, and stimulated emission takes over.  So these are the different contributions to the rates. ", "And it gives you a perspective-- at very low temperature,  spontaneous dominates.   PROFESSOR: So atom-light interactions. ", " So we will focus just on the electric field, E field. ", " Magnetic field effects are suppressed by the velocity ", "of the electrons divided by c.  And that you know is the fine-structure constant.  So magnetic field effects are suppressed. ", " Ignore magnetic v over c corrections. ", " With v over c, again, of the order  of the fine-structure constant. ", "We will also think of typically optical frequencies.  Lambda in the optical range. ", "So from about 4,000 to 8,000 angstroms.  And that's much, much bigger than a 0, ", "which is about 0.5 angstrom.  So that's good for our approximation.  That the wave is relatively constant, ", "being the wavelength so large it's  constant over the extent of the atom.   So we will think of the electric field ", "of the atom, E at the atom.   Our electric field, a bit of notation, will depend on time ", "and it will be a real function of time times a unit vector  to begin with.  This will get more interesting because we're ", "going to be dealing with thermal radiation.  So eventually, this vector, n, will be pointing  and we will average it over all directions ", "because thermal radiation comes with all polarizations  and in all directions.  So there will be a little bit of averaging necessary for that. ", "That will happen next time as we wrap up this discussion.   So this picture is of an atom sitting here. ", " And in particular, its electron, which is the particle  that reacts the most in the electric field. ", "And there is a unit vector, n.  And there's E of t here.   So the electric field, E of t, is ", "2 E not in our conventions cosine omega 3 times  the vector, n.  ", "So what is the vector on the scalar potential r, t.  It's minus r times E of t. ", "This is the formula that gives you  E as minus the gradient of phi.  This formula is not true in the presence of magnetic fields ", "in general.  There is a time derivative of the vector potential.  But again, we're ignoring magnetic effects.  So this is good enough for us. ", "If you take the gradient of this formula,  the only r dependence is here.  There's no r dependence in this electric field. ", "And in particular, we consider the wavelengths to be very big.  And this is good enough.  So what is the perturbing Hamiltonian ", "due to the coupling of the electric field  to the charged particle?  And we'll say atom, and we'll put an electron or something, ", "and we'll say the charge is q.  Eventually it will be minus E for the electron.  But let's keep it at q. ", "Delta H is q times phi of r and t.  So this is minus q times r times E of t vector. ", "Or minus q times r times n times E of t. ", "So so far, simple things.  We're just considering the electric field and how  it adds on a charged particle.  This is, of course, the simplest situation. ", "We will be considering in this course soon, in fact,  starting next lecture, the general interaction  of charged particles with electromagnetic fields. ", " But for the time being and in this approximation,  this is enough.  And we will define now a dipole operator. ", "It's something that you should keep in mind.  It's the usual thing when you define  dipoles is you sum or integrate over charges times position ", "vectors.  So this is a dipole operator.  ", "And I emphasized the operator because of the r.  When you have matrix elements, transitions between states,  everything will have to deal with those matrix ", "elements of r.  And that's why we'll have a dipole term there.  So delta H at this moment has become what? ", " Minus the dipole times the electric field.  ", "So let's do this.  Minus the dipole.  I'll do it here.   Minus the dipole dotted with electric field. ", " Vector.  Or minus d dot n with 2 times the magnitude ", "of the electric field.  Or minus v dot n times 2 E not cosine of omega t. ", " Factors of 2 keep us busy always.  And we have to get them right.  Remember when we did our definition of perturbed ", "Hamiltonian we said that delta H was going to be equal to 2H  prime cosine of omega t.  And our transition, amplitudes, and everything ", "were written in terms of H prime.  So this was our definition.  So at this moment, we can isolate H prime here. ", "So H prime is everything except for the 2  and the cosine of omega t.  So H prime, for our problem of atoms ", "interacting with electromagnetic fields,  is a dipole interaction.  And it's given by this nice simple formula. ", "That's our kind of important end result.  So if we have this Hamiltonian, we ", "have calculated the probability for transitions, for example, ", "from b to a, as a function of time.   When we have a harmonic perturbation  coupled to a two level system, we have a probability. ", "We don't have yet a rate.  We just have a probability.  And this is equal to the other one, to the reverse one.  It's 4Hab prime squared over h squared sine squared ", "of omega ba minus omega over 2 t over omega ba minus omega ", "squared.  That was the formula we had.  In our case now, H prime ab is that.  So we'll get the following. ", "4 E0 squared.  The E0 factor here goes out.  And then we will have the matrix elements ", "of the dipole operator, d.n ab.   So it will all be matter of the dipole operator. ", "H squared.  And these same factors.  Sine squared omega ba minus omega over 2T  over omega ba minus omega squared. ", "So this is the transition probability.  We don't have a rate.  But the rate will come when we integrate over all the photons ", "that contribute to this process.  And we'll get an exact analog of Fermi golden rule. "], "vid_duration": [11.42, 11.79, 13.03, 12.64, 12.22, 11.09, 10.57, 12.59, 14.1, 12.45, 11.4, 10.44, 12.09, 11.88, 14.19, 11.52, 12.81, 11.34, 12.01, 11.81, 10.77, 10.94, 11.5, 20.16, 12.57, 12.64, 12.88, 10.21, 10.56, 13.32, 14.46, 15.08, 10.46, 11.1, 14.93, 10.68, 11.19, 10.4, 10.39, 12.45, 12.32, 12.315, 11.805, 11.58, 11.61, 12.24, 12.09, 12.09, 12.51, 13.59, 12.78, 11.55, 12.21, 12.3, 10.97, 11.62, 10.02, 11.37, 15.425, 15.035, 10.21, 13.46, 11.95, 15.675, 10.775, 10.63, 11.22, 19.57, 11.46, 14.39, 10.92, 12.82, 12.68, 12.58, 10.85, 13.2, 10.53, 11.08, 14.04, 10.033, 11.72, 12.01, 10.13, 21.95, 10.109, 11.491, 10.52, 11.07, 11.435, 13.315, 22.03, 10.82, 12.629, 10.201, 10.54, 10.64, 21.25, 12.84, 10.49, 11.19, 13.54, 13.51, 12.8, 12.75, 11.79, 15.375, 12.465, 13.315, 10.685, 17.22, 16.54, 15.67, 11.31, 12.06, 11.81, 11.99, 12.75, 21.09, 11.31, 10.68, 12.21, 10.19, 13.45, 11.68, 10.88, 10.349, 16.741, 10.98, 15.34, 13.89, 12.27, 14.58, 10.679, 15.0, 13.411, 10.48, 13.67, 12.37, 10.569, 13.0, 12.011, 10.79, 13.57, 10.29, 13.35, 12.39, 10.97, 14.198, 15.229, 12.7, 10.731, 14.97, 11.819, 12.361, 11.01, 10.31, 13.87, 10.17, 11.19, 11.7, 10.29, 12.42, 11.969, 11.881, 11.21, 10.69, 10.14, 11.929, 17.5, 14.311, 11.77, 12.23, 16.5, 20.89, 13.26, 10.17, 10.65, 13.11, 10.3, 10.12, 12.229, 12.471, 10.344, 23.366, 10.5, 12.855, 11.485, 13.939, 10.161, 13.73, 16.2, 11.739, 11.721, 11.46, 10.0, 10.12, 10.55, 10.03, 15.7, 16.69, 13.149, 10.561, 11.41, 11.51, 17.7, 12.02, 13.81, 11.81, 16.5, 13.0, 12.86, 15.286, 12.754, 11.9, 13.4, 19.33, 14.81, 10.77, 11.819, 16.471, 11.39, 12.19, 10.11, 14.94, 13.68, 12.09, 20.768, 11.846, 13.531, 11.05, 11.325, 14.67, 16.53, 12.17, 12.14, 12.389, 10.221, 20.093, 13.289, 10.25, 11.651, 13.08, 12.76, 11.785, 10.955, 16.929, 12.38, 11.531, 14.469, 10.14, 20.641, 12.81, 13.239, 11.63, 11.66, 10.951, 20.719, 10.65, 11.31, 11.29, 12.46, 11.941, 10.259, 10.32, 17.43, 11.316, 10.535, 12.239, 12.736, 10.815, 12.659, 14.23, 11.671, 12.09, 12.14, 11.069, 10.391, 11.699, 11.25, 12.241, 13.29, 12.69, 11.04, 11.239, 15.474, 12.8, 11.329, 10.681, 12.952, 10.458, 10.63, 15.91, 13.05, 10.22, 14.938, 10.502, 10.17, 12.335, 15.475, 10.32, 13.58, 12.64, 15.15, 10.739, 10.201, 10.919, 13.0, 11.551, 10.77, 20.79, 12.329, 11.971, 12.029, 13.951, 10.89, 10.4, 12.719, 12.076, 13.375, 11.16, 20.679, 11.371, 14.25, 11.559, 11.221, 12.203, 10.956, 12.601, 13.569, 14.16, 19.111, 10.05, 11.85, 10.35, 12.54, 16.179, 10.551, 6.993], "stet": [[0, 11.42], [11.42, 23.21], [23.21, 36.24], [36.24, 48.88], [48.88, 61.1], [61.1, 72.19], [72.19, 82.75999999999999], [82.75999999999999, 95.35], [95.35, 109.44999999999999], [109.44999999999999, 121.89999999999999], [121.89999999999999, 133.29999999999998], [133.29999999999998, 143.73999999999998], [143.73999999999998, 155.82999999999998], [155.82999999999998, 167.70999999999998], [167.70999999999998, 181.89999999999998], [181.89999999999998, 193.42], [193.42, 206.23], [206.23, 217.57], [217.57, 229.57999999999998], [229.57999999999998, 241.39], [241.39, 252.16], [252.16, 263.1], [263.1, 274.6], [274.6, 294.76000000000005], [294.76000000000005, 307.33000000000004], [307.33000000000004, 319.97], [319.97, 332.85], [332.85, 343.06], [343.06, 353.62], [353.62, 366.94], [366.94, 381.4], [381.4, 396.47999999999996], [396.47999999999996, 406.93999999999994], [406.93999999999994, 418.03999999999996], [418.03999999999996, 432.96999999999997], [432.96999999999997, 443.65], [443.65, 454.84], [454.84, 465.23999999999995], [465.23999999999995, 475.62999999999994], [475.62999999999994, 488.0799999999999], [488.0799999999999, 500.3999999999999], [500.3999999999999, 512.7149999999999], [512.7149999999999, 524.5199999999999], [524.5199999999999, 536.0999999999999], [536.0999999999999, 547.7099999999999], [547.7099999999999, 559.9499999999999], [559.9499999999999, 572.04], [572.04, 584.13], [584.13, 596.64], [596.64, 610.23], [610.23, 623.01], [623.01, 634.56], [634.56, 646.77], [646.77, 659.0699999999999], [659.0699999999999, 670.04], [670.04, 681.66], [681.66, 691.68], [691.68, 703.05], [703.05, 718.4749999999999], [718.4749999999999, 733.5099999999999], [733.5099999999999, 743.7199999999999], [743.7199999999999, 757.18], [757.18, 769.13], [769.13, 784.805], [784.805, 795.5799999999999], [795.5799999999999, 806.2099999999999], [806.2099999999999, 817.43], [817.43, 837.0], [837.0, 848.46], [848.46, 862.85], [862.85, 873.77], [873.77, 886.59], [886.59, 899.27], [899.27, 911.85], [911.85, 922.7], [922.7, 935.9000000000001], [935.9000000000001, 946.4300000000001], [946.4300000000001, 957.5100000000001], [957.5100000000001, 971.5500000000001], [971.5500000000001, 981.5830000000001], [981.5830000000001, 993.3030000000001], [993.3030000000001, 1005.3130000000001], [1005.3130000000001, 1015.4430000000001], [1015.4430000000001, 1037.393], [1037.393, 1047.502], [1047.502, 1058.993], [1058.993, 1069.513], [1069.513, 1080.5829999999999], [1080.5829999999999, 1092.0179999999998], [1092.0179999999998, 1105.3329999999999], [1105.3329999999999, 1127.3629999999998], [1127.3629999999998, 1138.1829999999998], [1138.1829999999998, 1150.8119999999997], [1150.8119999999997, 1161.0129999999997], [1161.0129999999997, 1171.5529999999997], [1171.5529999999997, 1182.1929999999998], [1182.1929999999998, 1203.4429999999998], [1203.4429999999998, 1216.2829999999997], [1216.2829999999997, 1226.7729999999997], [1226.7729999999997, 1237.9629999999997], [1237.9629999999997, 1251.5029999999997], [1251.5029999999997, 1265.0129999999997], [1265.0129999999997, 1277.8129999999996], [1277.8129999999996, 1290.5629999999996], [1290.5629999999996, 1302.3529999999996], [1302.3529999999996, 1317.7279999999996], [1317.7279999999996, 1330.1929999999995], [1330.1929999999995, 1343.5079999999996], [1343.5079999999996, 1354.1929999999995], [1354.1929999999995, 1371.4129999999996], [1371.4129999999996, 1387.9529999999995], [1387.9529999999995, 1403.6229999999996], [1403.6229999999996, 1414.9329999999995], [1414.9329999999995, 1426.9929999999995], [1426.9929999999995, 1438.8029999999994], [1438.8029999999994, 1450.7929999999994], [1450.7929999999994, 1463.5429999999994], [1463.5429999999994, 1484.6329999999994], [1484.6329999999994, 1495.9429999999993], [1495.9429999999993, 1506.6229999999994], [1506.6229999999994, 1518.8329999999994], [1518.8329999999994, 1529.0229999999995], [1529.0229999999995, 1542.4729999999995], [1542.4729999999995, 1554.1529999999996], [1554.1529999999996, 1565.0329999999997], [1565.0329999999997, 1575.3819999999996], [1575.3819999999996, 1592.1229999999996], [1592.1229999999996, 1603.1029999999996], [1603.1029999999996, 1618.4429999999995], [1618.4429999999995, 1632.3329999999996], [1632.3329999999996, 1644.6029999999996], [1644.6029999999996, 1659.1829999999995], [1659.1829999999995, 1669.8619999999996], [1669.8619999999996, 1684.8619999999996], [1684.8619999999996, 1698.2729999999997], [1698.2729999999997, 1708.7529999999997], [1708.7529999999997, 1722.4229999999998], [1722.4229999999998, 1734.7929999999997], [1734.7929999999997, 1745.3619999999996], [1745.3619999999996, 1758.3619999999996], [1758.3619999999996, 1770.3729999999996], [1770.3729999999996, 1781.1629999999996], [1781.1629999999996, 1794.7329999999995], [1794.7329999999995, 1805.0229999999995], [1805.0229999999995, 1818.3729999999994], [1818.3729999999994, 1830.7629999999995], [1830.7629999999995, 1841.7329999999995], [1841.7329999999995, 1855.9309999999996], [1855.9309999999996, 1871.1599999999996], [1871.1599999999996, 1883.8599999999997], [1883.8599999999997, 1894.5909999999997], [1894.5909999999997, 1909.5609999999997], [1909.5609999999997, 1921.3799999999997], [1921.3799999999997, 1933.7409999999998], [1933.7409999999998, 1944.7509999999997], [1944.7509999999997, 1955.0609999999997], [1955.0609999999997, 1968.9309999999996], [1968.9309999999996, 1979.1009999999997], [1979.1009999999997, 1990.2909999999997], [1990.2909999999997, 2001.9909999999998], [2001.9909999999998, 2012.2809999999997], [2012.2809999999997, 2024.7009999999998], [2024.7009999999998, 2036.6699999999998], [2036.6699999999998, 2048.551], [2048.551, 2059.761], [2059.761, 2070.451], [2070.451, 2080.591], [2080.591, 2092.52], [2092.52, 2110.02], [2110.02, 2124.331], [2124.331, 2136.101], [2136.101, 2148.331], [2148.331, 2164.831], [2164.831, 2185.721], [2185.721, 2198.981], [2198.981, 2209.1510000000003], [2209.1510000000003, 2219.8010000000004], [2219.8010000000004, 2232.9110000000005], [2232.9110000000005, 2243.2110000000007], [2243.2110000000007, 2253.3310000000006], [2253.3310000000006, 2265.5600000000004], [2265.5600000000004, 2278.0310000000004], [2278.0310000000004, 2288.3750000000005], [2288.3750000000005, 2311.7410000000004], [2311.7410000000004, 2322.2410000000004], [2322.2410000000004, 2335.0960000000005], [2335.0960000000005, 2346.5810000000006], [2346.5810000000006, 2360.5200000000004], [2360.5200000000004, 2370.6810000000005], [2370.6810000000005, 2384.4110000000005], [2384.4110000000005, 2400.6110000000003], [2400.6110000000003, 2412.3500000000004], [2412.3500000000004, 2424.0710000000004], [2424.0710000000004, 2435.5310000000004], [2435.5310000000004, 2445.5310000000004], [2445.5310000000004, 2455.6510000000003], [2455.6510000000003, 2466.2010000000005], [2466.2010000000005, 2476.2310000000007], [2476.2310000000007, 2491.9310000000005], [2491.9310000000005, 2508.6210000000005], [2508.6210000000005, 2521.7700000000004], [2521.7700000000004, 2532.3310000000006], [2532.3310000000006, 2543.7410000000004], [2543.7410000000004, 2555.2510000000007], [2555.2510000000007, 2572.9510000000005], [2572.9510000000005, 2584.9710000000005], [2584.9710000000005, 2598.7810000000004], [2598.7810000000004, 2610.5910000000003], [2610.5910000000003, 2627.0910000000003], [2627.0910000000003, 2640.0910000000003], [2640.0910000000003, 2652.9510000000005], [2652.9510000000005, 2668.2370000000005], [2668.2370000000005, 2680.9910000000004], [2680.9910000000004, 2692.8910000000005], [2692.8910000000005, 2706.2910000000006], [2706.2910000000006, 2725.6210000000005], [2725.6210000000005, 2740.4310000000005], [2740.4310000000005, 2751.2010000000005], [2751.2010000000005, 2763.0200000000004], [2763.0200000000004, 2779.4910000000004], [2779.4910000000004, 2790.8810000000003], [2790.8810000000003, 2803.0710000000004], [2803.0710000000004, 2813.1810000000005], [2813.1810000000005, 2828.1210000000005], [2828.1210000000005, 2841.8010000000004], [2841.8010000000004, 2853.8910000000005], [2853.8910000000005, 2874.6590000000006], [2874.6590000000006, 2886.5050000000006], [2886.5050000000006, 2900.0360000000005], [2900.0360000000005, 2911.0860000000007], [2911.0860000000007, 2922.4110000000005], [2922.4110000000005, 2937.0810000000006], [2937.0810000000006, 2953.611000000001], [2953.611000000001, 2965.781000000001], [2965.781000000001, 2977.9210000000007], [2977.9210000000007, 2990.310000000001], [2990.310000000001, 3000.531000000001], [3000.531000000001, 3020.6240000000007], [3020.6240000000007, 3033.913000000001], [3033.913000000001, 3044.163000000001], [3044.163000000001, 3055.8140000000008], [3055.8140000000008, 3068.8940000000007], [3068.8940000000007, 3081.654000000001], [3081.654000000001, 3093.4390000000008], [3093.4390000000008, 3104.3940000000007], [3104.3940000000007, 3121.323000000001], [3121.323000000001, 3133.703000000001], [3133.703000000001, 3145.234000000001], [3145.234000000001, 3159.703000000001], [3159.703000000001, 3169.8430000000008], [3169.8430000000008, 3190.484000000001], [3190.484000000001, 3203.294000000001], [3203.294000000001, 3216.533000000001], [3216.533000000001, 3228.163000000001], [3228.163000000001, 3239.823000000001], [3239.823000000001, 3250.774000000001], [3250.774000000001, 3271.493000000001], [3271.493000000001, 3282.143000000001], [3282.143000000001, 3293.453000000001], [3293.453000000001, 3304.743000000001], [3304.743000000001, 3317.203000000001], [3317.203000000001, 3329.1440000000007], [3329.1440000000007, 3339.4030000000007], [3339.4030000000007, 3349.723000000001], [3349.723000000001, 3367.1530000000007], [3367.1530000000007, 3378.4690000000005], [3378.4690000000005, 3389.0040000000004], [3389.0040000000004, 3401.2430000000004], [3401.2430000000004, 3413.9790000000003], [3413.9790000000003, 3424.7940000000003], [3424.7940000000003, 3437.4530000000004], [3437.4530000000004, 3451.6830000000004], [3451.6830000000004, 3463.3540000000003], [3463.3540000000003, 3475.4440000000004], [3475.4440000000004, 3487.5840000000003], [3487.5840000000003, 3498.6530000000002], [3498.6530000000002, 3509.0440000000003], [3509.0440000000003, 3520.7430000000004], [3520.7430000000004, 3531.9930000000004], [3531.9930000000004, 3544.2340000000004], [3544.2340000000004, 3557.5240000000003], [3557.5240000000003, 3570.2140000000004], [3570.2140000000004, 3581.2540000000004], [3581.2540000000004, 3592.4930000000004], [3592.4930000000004, 3607.9670000000006], [3607.9670000000006, 3620.7670000000007], [3620.7670000000007, 3632.096000000001], [3632.096000000001, 3642.777000000001], [3642.777000000001, 3655.729000000001], [3655.729000000001, 3666.1870000000013], [3666.1870000000013, 3676.8170000000014], [3676.8170000000014, 3692.727000000001], [3692.727000000001, 3705.7770000000014], [3705.7770000000014, 3715.997000000001], [3715.997000000001, 3730.9350000000013], [3730.9350000000013, 3741.4370000000013], [3741.4370000000013, 3751.6070000000013], [3751.6070000000013, 3763.9420000000014], [3763.9420000000014, 3779.4170000000013], [3779.4170000000013, 3789.7370000000014], [3789.7370000000014, 3803.3170000000014], [3803.3170000000014, 3815.9570000000012], [3815.9570000000012, 3831.1070000000013], [3831.1070000000013, 3841.8460000000014], [3841.8460000000014, 3852.0470000000014], [3852.0470000000014, 3862.9660000000013], [3862.9660000000013, 3875.9660000000013], [3875.9660000000013, 3887.517000000001], [3887.517000000001, 3898.287000000001], [3898.287000000001, 3919.077000000001], [3919.077000000001, 3931.4060000000013], [3931.4060000000013, 3943.3770000000013], [3943.3770000000013, 3955.4060000000013], [3955.4060000000013, 3969.3570000000013], [3969.3570000000013, 3980.247000000001], [3980.247000000001, 3990.6470000000013], [3990.6470000000013, 4003.3660000000013], [4003.3660000000013, 4015.4420000000014], [4015.4420000000014, 4028.8170000000014], [4028.8170000000014, 4039.977000000001], [4039.977000000001, 4060.6560000000013], [4060.6560000000013, 4072.0270000000014], [4072.0270000000014, 4086.2770000000014], [4086.2770000000014, 4097.836000000001], [4097.836000000001, 4109.057000000001], [4109.057000000001, 4121.260000000001], [4121.260000000001, 4132.216000000001], [4132.216000000001, 4144.817000000001], [4144.817000000001, 4158.386000000001], [4158.386000000001, 4172.546000000001], [4172.546000000001, 4191.657000000001], [4191.657000000001, 4201.707000000001], [4201.707000000001, 4213.557000000002], [4213.557000000002, 4223.907000000002], [4223.907000000002, 4236.447000000002], [4236.447000000002, 4252.626000000002], [4252.626000000002, 4263.177000000002], [4263.177000000002, 4270.170000000003]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [982, 1852, 3021, 3602, 4271]}
{"example_id": "mit038@@MIT8_06S18_L07_300k", "text": ["PROFESSOR: Today, we continue with our discussion of WKB.  So a few matters regarding the WKB  were explained in the last few segments. ", "We discussed there would be useful to define  a position-dependent momentum for a particle that's ", "moving in a potential.  That was a completely classical notion,  but helped our terminology in solving the Schrodinger ", "equation and set up the stage for some definitions.  For example, a position-dependent de Broglie  wavelength that would be given in terms ", "of the position-dependent momentum by the classic formula  that de Broglie used for particles that move  with constant momentum.  ", "Then in this language, the time independent Schrodinger  equation took the form p squared on psi ", "is equal to p squared of x times psi.  This is psi of x.  And we mentioned that it was kind of nice that the momentum ", "operator ended up sort of in the style of an eigenvalue.  The eigenvalue p of x. ", "We then spoke about wave functions  that in the WKB approximation would  take a form of an exponential with a phase and a magnitude-- ", "so the usual notation we have for complex numbers.  So the psi of x and p would be written as rho of x and t ", "e to the i over h bar s of x and t.   That's a typical form of a WKB wave function ", "that you will see soon.  And for such wave functions, it's  kind of manifest that rho here is the charge density. ", "Because if you take the norm squared of psi,  that gives you exactly rho.  The phase cancels.  On the other hand, the computation of the current ", "was a little more interesting.  And it gave you rho times gradient of s over m--  the mass of the particle. ", " So we identified the current as perpendicular  to the surfaces of constant s or constant phase in the exponent ", "of the WKB equation.  Our last comment had to do with lambda.  And we've said that we suspect that the semiclassical ", "approximation is valid in some way  when lambda is small compared to a physical length of a system ", "or when lambda changes slowly as a function of position.  And those things we have not quite yet  determined precisely how they go. ", "And some of what you have to do today  is understand more concretely the nature  of the approximation.  So the semiclassical approximation ", "has something to do with lambda slowly varying and with lambda ", "small, in some sense.   And since you have an h bar in here  that would make it small if h bar is small, ", "we also mentioned we would end up  considering the limit as a sort of imaginary or fictitious  limit in which h bar goes to 0. ", " So it's time to try to really do the approximation. ", "Let let's try to write something and approximate the solution.  Now, we had a nice instructive form of the wave function ", "there, but I will take a simpler form  in which the wave function will be just a pure exponential. ", "So setting the approximation scheme--  so approximation-- scheme.  ", "So before I had the wave function  that had a norm and a phase.  Now, I want the wave function that ", "looks like it just has a phase.  You would say, of course, that's impossible.  So we will for all the time independent Schrodinger  equation. ", "So we will use an s of x.  And we will write the psi of x in the form  e to the i h bar s of x. ", " And you say, no, that's not true.  My usual wave functions are more than just phases.  They're not just faces. ", "We've seen wave functions have different magnitudes.  Here that wave function will have always density equal to 1.  But that is voided--  that criticism is voided-- ", "if you just simply say that s now may be a complex number.  So if s is itself a complex number, the imaginary part of s ", "provides the norm of the wave function.  So it's possible to do that.  Any rho up here can be written as the exponential ", "of the log of something and then can be brought in the exponent.  And there's no loss of generality in writing something  like that if s is complex. ", " Now, we have the Schrodinger equation.  And the Schrodinger equation was written there.  So it's minus h squared d second d x squared of psi of x. ", " It's equal to p squared of x e to the i over h bar s. ", " Now, when we differentiate an exponential,  we differentiate it two times. ", "We will have a couple of things.  We can differentiate the first time-- brings an s prime down.  And the second time you can differentiate the exponent ", "or you can differentiate what is down already.  So it's two terms.  The first one would be--  imagine differentiating the first one. ", "The s goes down and then the derivative acts on the s.  So you get i over h bar s double prime.  Let's use prime notation. ", " And the other one is when you differentiate the ones here.  It brings the factor down, again, there.  So it's plus i over h bar s prime squared. ", " And then the phase is still there,  and it can cancel between the left and the right. ", "So this is equal to p squared of x.  ", "So I took the derivative and cancelled the exponentials.  So cleaning this up a little bit, ", "we'll have this term over here.  The h's cancel, the sine cancels,  and you get s prime of x squared minus i h bar s double prime. ", "It's equal to p squared of x.   OK. ", "Simple enough.  We have a derivation of that equation.  And the first thing that you say is,  it looks like we've gone backwards. ", "We've gone from a reasonably simple equation,  the Schrodinger equation-- second order,  linear differential equation-- ", "to a nonlinear equation.   Here is the function squared, the derivative squared, second ", "derivative, no--  there's nothing linear about this equation in s.  If you have one solution for an s and another solution,  you cannot add them. ", "So this happens because we put everything in the exponential.  When you take double derivatives of an exponential  you get a term with double derivatives ", "and a term with a derivative squared.  There's nothing you can do.  And this still represents progress in some way, ", "even though it has become an equation that  looks more difficult. It can be tracked in some other way.  So the first and most important thing ", "we want to say about this equation  is that it's a nonlinear differential equation.  ", "The h bar term appears in just one position here.  And let's consider a following claim-- ", "I will claim that i h bar s double prime--  this term-- is small when v of x is slowly varying. ", " You see, we're having in mind the situation  with which a particle is moving in a potential-- a quantum ", "particle.  So there it s, b of x is well-defined.  That's a term that goes into this equation.  So this is partly known. ", "You may not know the energy, but the potential you know.  And my claim-- and perhaps a very important claim about this ", "equation that sets you going clearly--  is that when v of s is slowly varying,  this term is almost irrelevant. ", "That's the first thing we want to make sure we understand.  So let's take v of x is equal to v0 at constant. ", "So this is the extreme case of a slowly varying potential.  It just doesn't vary at all.  In that case, p of x is going to be a constant. ", "And that constant is the square root of 2m e minus V0.  ", "And what do we have here?  We have a free particle.  This v of x is a constant.  So the solution of the Schrodinger equation,  that you know in general, is that psi ", "of x is e to the i p0 x over h bar.  That solves the Schrodinger equation.  Now, we're talking about this equation. ", "So to connect to that equation in this situation  of constant potential constant, momentum  in the classical sense, and a free particle  with that constant momentum, remember that s is a term here ", "in the exponential.  So for this solution here, s of x is equal to p0 x. ", "That's all it is.  It's whatever is left when you single out the i over h bar.  And let's look at that thing. ", "That should be a solution.  We've constructed the solution of the momentum.  equation for constant potential.  We've read what s of x is. ", "That should solve this equation.  And how does it manage to solve it?  It manages to solve it because s prime of x is equal to p0. ", "s double prime of x is equal to 0.  And the equation works out with the first term squared-- ", "p0 squared-- equal to p of x squared--  which is p0 squared.  So this term, first term in the left-hand side,  is equal to the right-hand side This term is identically 0. ", "So when the potential is constant,  that term, i h bar s double prime, plays no role, It's 0.  ", "So the term i h bar s double prime is equal to 0. ", "So the claim now follows from a fairly intuitive result.  If the potential is constant, that term in the solution is 0. ", "If the potential will be extremely,  slowly varying, that term should be very small.  You cannot expect that the constant potential has  a solution. ", "And you now do infinitesimal variation of your potential,  and suddenly this term becomes very big.  So for constant v, i h bar is double prime equal 0. ", "So for slowly varying v of x i h bar is double prime, ", "it should be small in the sense that this solution  is approximately correct.  So if we do say that, we've identified the term ", "in the equation that is small when potentials are slowly  varying.  Therefore, we will take that term  as being the small term in that equation. ", "And this will be nicely implemented by considering,  as we said, h bar going to 0, or h as a small parameter. ", " We will learn, as we do the approximation, ", "how to quantify what something that we call slowly varying is.  But we will take h now as a small parameter--  that makes that term small-- ", "and setup an expansion to solve this equation.  That is our goal now.  So how do we set it up?  We set it up like this-- we say s of x, ", "as you've learned in perturbation theory,  is s0 of x plus h bar s1 of x-- the first correction-- ", " plus h bar squared is s2 of x and higher order. ", "Now, s already has units of h bar--  ", "so s0 will have units of h bar too.  s1, for example, has no units.  So each term has a different set of units. ", "And that's OK, because h bar has units.  And this will go like 1 over h bar units ", "and so forth and so on.  So we have an expansion.  And this we'll call our semiclassical expansion.  As we apply now this expansion to that equation, ", "we should treat h as we treated lambda in perturbation theory.  That is, we imagine that this must be hauled order ", "by order in h bar, because we imagine  we have the flexibility of changing h bar.  So let's do this. ", " What do we have in the equation?  We have s prime.  So the equation has s0 prime plus h bar s1 prime. ", "Now, I will keep terms up to order h bar.  So I will stop here-- plus order h bar squared minus i h ", "bar s double prime.  So that should be s0 double prime plus order  h bar equal b squared of x. ", " So let's organize our terms.  ", "We have s0 prime primed squared on the left-hand side.  Minus p squared of x-- ", "I bring the p to the left-hand side--  plus h bar.  So these are terms that have no h bar. ", "And when we look at the h bar from the first term there,  we square this thing.  So you get the cross product between the s0 prime ", "and the s1 prime.  So you get 2--  the h prime already is there-- ", "s0 prime s1 prime.   And from the second term, you get ", "minus i s0 double prime plus order h squared equals 0. ", " So I just collected all the terms there. ", " So if we're believing in this expansion,  the first thing we should say is that each coefficient ", "in the power series of h bar is 0.  So we'll get two equations.   First one is s0 prime squared is equal to p squared of x. ", "That's one.  That's this term equal to 0.  And here, we get-- ", "let's write it in a way that we solve for the unknown.  Supposedly from this first equation we, can solve for s0.  If you know s0, what do you want now to know is s1 prime. ", "So let's write this as s1 prime is equal to i s0  double prime over 2 s0 zero prime. ", "So these are my two equations.  So let's try to solve this.  So my classical approximation is about solving these equations. ", " So let's see what we get.   Well, the first equation is kind of simple. ", " I think everybody has the temptation there to just take  the square root, and that's what we should do, ", "s0 prime is equal to plus minus p of x.  ", "And therefore s0 of x is equal to plus/minus the integral up  to x of p of x prime dx prime. ", " You see p of x is pretty much known.  If you know the energy of your particle,  then it's completely known, and it depends on e minus v. ", "So this is a solution in terms of p of x.  We should think of solving the differential equation  in terms of p of x. ", "Now, as a first order differential equation,  there's a constant of integration.  And we'll pick it up to be a number here, x0.  So we start integrating from some place. ", "If you integrate from another place,  you're shifting the constant of integration.  The main thing is that the x derivative  here acts as the upper limit and gives you ", "the p of x of that equation.  So this is our solution.  Even the plus minus should not disturb us.  If you have the p squared, you don't ", "know if the particle is moving to the left or to the right.  So that ambiguity is perfectly reasonable.  Particle can be moving to the left or to the right. ", "Now, we look at the second equation.  So s1 prime is equal to i over 2.  s0 double prime, if you have s0 double prime, ", "you have here s0 prime, so you take another derivative.  So that's a plus minus p prime of x divided by s0 prime, ", "which is plus minus p of x.  That's kind of nice.  The sine is going to cancel.  So we have here i over 2 p prime of x over p of x or i ", "over 2 logarithm of p of x prime. ", "The derivative of the logarithm is 1 over the function,  and then by chain rule, you get the p prime there. ", "So if s1, the prime derivative is the derivative  of this thing, so s1 is going to be  i over 2 log of p of x plus a constant. ", " So let's reconstruct our solution. ", " That's not hard.   We wrote the answers up there. ", "So the wave function is e to the i over h bar times s,  and s is what we had there. ", "So our wave function is e to the i over h bar s,  and s was s0 plus i plus h bar is 1. ", " There's more.  Is it right?  But we're going to ignore it.  We didn't go that far.  In fact, nobody goes higher in the WKB approximation. ", " So what do we have here?   I'll write it. ", "This term is kind of interesting.  We have e to the i h bar of x times e to the i s1. ", "And s1 was i over 2 log of p of x plus a constant.  ", "So look at this items i is minus 1, 2.  So you have 1/2. ", "This becomes e to the minus 1/2 logarithm of b of x.  And 1/2 the logarithm of b of x is ", "e to the minus log of square root of b of x, and when you go  like that e to minus that is 1 over the function. ", "So p of x like that, and then we have e to the i over h ", "bar integral from x0 to x p of x prime dx prime.  This is the classic WKB approximation, classic result. ", "So as promised, this is of the form of a scale factor here,  a rho, the square root of rho times a phase. ", "So we did begin with what looked like a pure phase,  but then we said s of x is complicit in fact.  s0 was real, but s1 was imaginary. ", "With s1 imaginary, the rho of s1 was to provide the magnitude.  And this is an intuition, this approximation scheme. ", "The first thing you have to get right is the phase.  Once you get the phase right, the next order,  you get the amplitude of the wave right. ", "That comes to second order.  That's a next effect.  So this is our solution. ", "When I began today, I reminded you  that we have WKB solutions of the form square root of rho  e to the is, and we calculated some things for that. ", "So because of the signs, s0, I dropped  the sign, this plus or minus.  Let me write the general solutions of WKB ", "slightly more complete.   Let's be more complete.  It's important to see the whole freedom here. ", "So if we have e greater than v, remember  when e is greater than v, the p of x is a real quantity. ", "And we wrote, and we said that p of x  we would write as h bar k of x.  ", "You know, I think I should have probably, for convenience here,  let's put the constant.   We're not attempting to normalize these wave functions. ", "We could not attempt to do it, because we  don't know what p of x is.  And this function may have limited validity  as we've spoken.  But I had the constants here. ", "This constant could have a real or imaginary part.  It would affect this a.  So let's put it there.   OK. ", "So if p of x is hk of x, we can have the following solutions,  psi of x and t equal a, another constant, square root of p-- ", "let's go simpler-- square root of k.  It's a different a.  And here, e to the i, since p is h bar, it cancels here. ", "So we have a simpler integral as well,  x0 to x, k of x prime, dx prime.  So that's that term. ", "I just use the opportunity to replace p  for k, which simplifies your life,  simplifies all these constants.  So the other solution is the wave moving ", "in a different direction.  So k of x, e to the minus i x0 to x,  k of x prime v of x prime. ", "So that is your solution when you have e greater than v.  If we have e less than v, we still have a solution, ", "and we said that p of x, in that case,  would be equal to i h bar kappa of x. ", "We use that notation.  If e is less than v, this is a negative number.  So p of x is i times some positive number ", "and square root of a positive number.  And we called it kappa last time.  So this is the letter we usually use ", "for spatial dependence in regions  where the wave function decays exponentially,  which is what it's going to happen here.  So what is the psi of x and t is equal to a constant c ", "over square root of kappa of x e to the--  the i will disappear, and there will  be two solutions, one with plus, one with minus. ", "That's the reason I don't have to be very careful in saying  whether this is i or minus i.  There's, anyway, two solutions.  At this stage, we don't need to worry.  So this is from x0 to x, kappa of x prime, dx prime, ", "plus d over square root of kappa of x, e to the minus x0  to x, kappa of x prime, dx prime. ", " So this is the complete solution of WKB.  ", "If you are in the classically allowed region top  or in the classically forbidden region,  it's important to realize that this function, the second term ", "is the decaying exponential.  As x increases, the integral accumulates more and more  value, and the wave function gets more and more suppressed. ", "This is a growing kind of exponential.  In the previous iteration in your life,  kappa was a constant, if you had constant potentials. ", "And this would be e to the kappa x basically.  But here, you must think of kappa  being some positive number, positive function, ", "as you integrate and x grows, your cube-- the integral  becomes bigger.  And this is a growing exponential.  So the sign tells you that, especially because we've ", "ordered the limits properly.  So we have a decaying and growing exponential.  ", "At this moment, we're pretty much  done with what WKB does for you.  Although, we have a few things still to say. ", " So this will be in terms of comments  about the general validity of such approximation, ", "but first even some comments about the current and charge  density.  So let's consider this equation I. ", "Let's just make the comments, comments for equation I on one.  ", "What is the charge density or the probability density  in this case, rho would be psi squared, ", "and in case one, is equal to a squared over k of x?  ", "You could, if you wish, this is a perfectly nice formula,  multiply it by h bar up and down.  And that's the momentum. ", "So it's h bar a squared over p of x.  And you could say this is h bar over m ", "a squared over v of x, a local velocity, p of x  is m over a local velocity.  And this is an intuition you've had for a long time. ", "The probability density or the amplitude of the wave  is going to become bigger in the regions  where the particle has smaller velocity. ", "That's the regions of the potential where  the particle spends more time, and it's  an intuition that almost immediately comes here.  This k is essentially the momentum. ", "So that's essentially the square root of the velocity.  And this coefficient, therefore, becomes bigger,  as the velocity is smaller. ", "That's part of the intuition you've had for a long time,  regarding these quantities.  The other piece is the computation  of the current from this equation I. Remember, ", "the current is h bar over m times the imaginary part  of psi star gradient psi.  So it's a long computation. ", "But we did it for the case we had before.  We said that the current is rho times gradient of s ", "over m for the case when the wave function is  written in rho e to the s form.  So in here, rho is already determined ", "is a squared over k of x.  We have the 1 over m, and the gradient of s-- ", "s is this quantity, e to the i h bar times s.  So the gradient of s is just p of x, so h bar k of x. ", " Now, they cancel.  ", "And it's very fast.  They cancel.  Would have been a major disaster if they didn't.  This is a number. ", "It's a squared over m.  ", "The reason it cancels is that it would have failed  the conservation law otherwise.  The rho dt plus the divergence of j should be 0. ", "In our case, rho has no time dependence.  The wave function that we are considering, ", "our time independent Schrodinger equations,  we're considering energy eigenstates.  And the current must be a constant. ", "In an energy eigenstate, the current cannot be a spatially  varying constant, because then the current would accumulate  in some place, and that's inconsistent with stationary ", "states.  And in fact, this is 0, and the versions of j in this case  would be dj dx, and if it would have had some x dependence, ", "it would have destroyed this equation.  So dj dx is also 0, and that's all consistent.  PROFESSOR: So let's try to do return to seeing, ", "OK, we solved equation.  We seem to be OK.  What did we really approximate?  We didn't approximate saying h bar goes to 0. ", "We did a more serious physical approximation.  And let's try to see what we really did. ", "So I think the whole clue is in this top equation there.  You have the first term and the second term. ", "And our claim is that the second term  is smaller than the first term with h bar there.  So for example-- now of course, in this solution, ", "the first term is identically 0 and the second term,  the coefficient of h bar, is identically 0.  But we can look at one of those, for example, and say that-- ", "so the validity of the approximation.  Validity of the approximation.   It's pretty useful to do this. ", "So we say, for example there, that term, h bar ", "s0 double prime that enters into the order h bar  part of the equation, the absolute value of it ", "must be much smaller than a typical term s0 prime,  for example, s0 prime squared, in the first term. ", " So each term-- so basically, I'm saying  each term in the first bracket must be much larger ", "than each term in the second bracket.  And you could have picked any ones because they're  all equal, after all.  So let's see if that is the case. ", "So recall that s0 prime from there is really  p of x plus minus p of x.  So what do we have here? h bar and s0 double prime is dp vx. ", " Must be much smaller than p of x squared.  ", "Now it's a matter of playing with these things a little bit  until you find some way that the equality tells you story.  And the way I'll do it is by saying ", "that this is h bar 1 over p squared of x  dp vx is much smaller than 1. ", "And here I'll write this as h bar d--  no h bar.  ddx of h bar over p. ", " Look what I did.  ddx of 1 over p is 1 over p squared dp vx and the h ", "bar I put it there.   Here we go.  What does this say?  This is the local De Broglie wave length. ", "This is saying that ddx of the local  the De Broglie wave length must be much smaller than 1.  A nice result, your local De Broglie wavelength ", "must have a small derivative.  So this is the physics translation  of the semi-classical approximation. h bar going to 0 ", "is a mathematical device, but this is physical.  This is telling you what should happen.  Most of us look at that and see an easier way ", "to understand that equation.  v lambda vx.  It has the right units.  Lambda has units of length.  x has units of length.  So that derivative must have no units. ", "And if it's supposed to be small,  it should be small compared to 1.  So this is the conventional inequality.  Most of us would prefer, maybe, to write it ", "like this-- lambda d lambda dx is much smaller than lambda.  And I think this is a little clearer because this ", "is how much the De Broglie wave length changes  over a distance equal to the De Broglie wavelength. ", "So you have a De Broglie wave length and the next De Broglie  wave length.  How much did it change?  That must be small compared to the De Broglie wavelength. ", "So the change of the De Broglie wave  length after you move one De Broglie wave length  must be smaller than the De Broglie wave length.  I don't know if you like it.  Otherwise, you can take this one. ", "I'll do another one, another version of the inequalities.  And you can play with those inequalities.  It kind of takes a while until you convince yourself ", "that you're not missing anything.  Think of p squared equal to m e minus v of x.  ", "Take a derivative, vvx.  So I'll have p, p prime.  This is 2 pp prime.  But with this 2, I'm going to cancel it. ", "At some point, of course, we're taking all kinds of factors  of 2 and ignoring them.  Remember that true De Broglie wave length is h over ", "p not h bar over p.   Factors-- by the time you go to this inequality, two pis  are gone. ", "m.  We're differentiating with respect  to x and taking absolute value.  So we'll write it like this.  Or vvvx vx equals 1 over m pp prime. ", "That is so far exact.  Let me multiply by a lambda.  ", "So I'll have a lambda.   And a lambda, vv dx, is equal to lambda. ", "OK.  Lambda is h bar over p.  So I can cancel one of these p's and get h bar over m p prime. ", " OK.  H bar over m p prime.  Now, look at this equation. ", "I'm sorry.  We'll play with this a little--  like, trial and error.  You're trying to move around your inequality.  So here we have something-- h bar ", "dp dx is much less than that.  So this term is because of this inequality ", "is much smaller than p squared over m.  And now we have something nice.  I'll write it here. ", "Lambda of x dv dx is much smaller than p squared over 2m. ", " That's another nice one.  I think this one is the--  ", "and this says that the potential must be slowly varying for this  to be true because the change in the potential over at the De ", "Broglie wavelength-- dv dx times lambda of x  is an estimate for the change of the potential over the De  Broglie wavelength-- is much smaller than the kinetic energy ", "of the particle.  So that's, again, another thing that makes sense.  It's kind of nice. ", "So this is the wave at the end of the day, this h  bar going to zero approximation has  become a physical statement. ", "It is a statement of quantities varying  slowly because after all, that's what motivated the expansion ", "from the beginning.  So let's see if we ever get in trouble with this.  So we're trying to solve physical problems of particles ", "and potentials.  And most of the times we're interested in bound  states or energy eigenstates, at least the simple energy ", "eigenstates are bound states.  So here is a situation.  We have a sketch of a situation.  ", "We have a v of x--  this is x.  This is a.  v of x-- and some energy, e.  ", "And let's assume we're looking close enough  to the point x equals a so that the v of x, however it curves,  at that point is roughly straight. ", " That's a reasonable thing to do.  So we'll model v of x minus e-- ", "v of x minus e-- as being linear near x equals a.  So this is g times x minus a, where  g is some positive constant, which ", "is the slope at this point.   So look at x less than a. ", "At this point, you are in the loud region.  You're in the region to the left of the point a  where your energy is bigger than the potential. ", "And that's perfectly allowed.   So here, e minus v of x, which is the negative of that, ", "would be g a minus x.  And p is square root of 2 m e minus v of x, so g a minus x. ", "That's p of x.   So that's your position dependent momentum.  It's going to go to 0 at that point. ", "And lambda, which is h bar over p,  is h bar over square root of 2 mg 1 ", "over square root of a minus x.  So take the derivative--  d lambda d x--  take the absolute value of it. ", "That's h bar over square root of 2 mg times 1/2 1 over a minus x ", "to the three halves.  We're differentiating with respect to x.   And now you see the trouble, if you had not seen it ", "before, the validity of the semi-classical approximation  is taken and requires d lambda dx to be much smaller than 1. ", "And as you approach x equals to a, this grows without bound.  It just becomes bigger and bigger. ", "You can choose g to be large and you can choose m to be large.  But still, you get closer and closer, you eventually fail.  This thing goes to infinity as x goes to a ", "and grows without limit.  And the semi-classical approximation crashes.   You know, I would imagine that many people got this far ", "with this in my classical approximation of writing  this and that.  But this is a tremendous obstacle. ", "Why is it an obstacle?  Why can't we just forget about that region  because most of the times you dealing with bound states.  So you will have a very slowly varying potential here. ", "But if you want to find bound states,  you need the fact that there is a forbidden region where  the wave function destroys itself. ", "So whatever you can solve for the wave function  is slowly varying here.  It's not enough because you need to know how it decays. ", "And therefore, you need to face this corners  where the semi-classical approximation fails.  Our problem here is that we know how to write a solution here. ", "We probably know how to write the solution here.  Those are these ones.  But we have no idea how to write them here.  So we cannot connect the two solutions. ", "It's a serious difficulty.   So people work hard on that.  And I think that is the breakthrough ", "of the construction of this WKBP [INAUDIBLE]..  What they did is they solved the equation ", "exactly in this region, assuming a linear potential.  They solved it exactly.  And then those functions, the [INAUDIBLE] functions, show up. ", "And you know how the [INAUDIBLE] functions behave.  So they solve it here.  They related it to the solution to the right, related it  to the solution on the left. ", "And in that way, even though we don't  have to write the solution in this region,  we know how a solution on the middle  connects to a solution on the right. ", "This is the subject of the connection formulas in WKB.  We will discuss that next time, or we'll  go through some of that analysis because it's interesting ", "and fairly non-trivial.  But I will mention one of the connection formulas and use it.  PROFESSOR: So let's do a connection formula ", "and use it to solve a problem.  The derivation of such connection formulas,  we'll face it the next time.  And we'll go further applications of the methods. ", "So, yes.  AUDIENCE: So [INAUDIBLE] that problem like [INAUDIBLE] where  the wave function vanished. ", "Is that a problem of the [? our ?] perturbation  or a classical problem?  Because at that point, then it means the kinetics  and the potential are equals to each other. ", "So like the potential cannot be bigger than the energy,  then that's a classical thing.  That's not a perturbation problem.  PROFESSOR: Right.  This is not a problem of the perturbation theory. ", "It's just our lack of knowledge, our ignorance of how  the solution looks near there.  So there's nice WKB formulas for this solution ", "away from the turning points.  Those are this.  But the solutions near the turning points  violate the semiclassical approximation. ", "Therefore, you have to find the solution near the turning  points by any method you have.  That is not going to be the semiclassical method.  And then you will find the continuation. ", "Now, there's several ways people do this.  The most down to earth method, which  is I think the method we're going to use next time,  is trying to solve the thing near there, the solution. ", "People that are more sophisticated  use complex variables, methods in which they  think of the solution in the complex plane,  the x plane becomes complex. ", "And they're coming to the turning point  and they go off the imaginary axis  to avoid it and come on the other side.  It's very elegant, very nice, harder ", "to make very precise, and a little difficult to explain.  I don't know if I'll try to do that.  But it's a nice thing.  It's sort of avoiding the turning ", "point by going off the axis.  It sounds crazy.  So here is a connection formula.  Here is x equals a. ", "Here is v of x.  And here is a solution for x less than a, little a,  I'll write it like that, p of x cosine x ", "to a kappa k of x vx prime minus pi over 4 minus B  over square root of p of K of x sine x ", "to a k of x prime vx prime minus pi over 4.  So look, this is a general solution in allowed region. ", "[INAUDIBLE] no, it doesn't look like what you wrote here.  But sines and cosines are linear combinations of these things.  And why do I put this silly minus pi over 4? ", "Because that's what my solutions connect  to solutions on the other side.  Which is to say that the solution on the other side, ", "people that work this connection formulas,  discovered that takes this form, a to x ", "kappa of x prime vx prime plus b over the square root of kappa  of x e exponential a to x kappa of x prime vx prime. ", " So here it is.  Those numbers, a and b, are things  you have to keep track now.  They say if your solution for x greater [INAUDIBLE] ", "has this decaying exponential and this growing exponential  with b an a, your solution far to the left  will look like this. ", "It's a pretty strange statement.  Sometimes you don't want b to be 0.  Sometimes you do.  Let's do an example with this stuff ", "so that you can appreciate what goes on.  ", "So that's your first look at a connection condition.  There's a little bit of subtleties on how to use them.  We will discuss those subtleties next time, as well. ", "But let's use it in a case where we can make sense of this  without too much trouble.  So here is the example. ", "And somebody wants you to solve the following problem.  You have some slowly varying potential  that grows, grows indefinitely. ", "v of x.  And you wish to find the energy eigenstates.  In particular, you wish to find the energies. ", "What are the possible energies of this potential?  This potential with have a infinite wall here.  So the potential is infinite here. ", "And it grows like that up on this side.   We're going to try to write the solution for this. ", "So we'll do this with the WKB solution.  And let me do it in an efficient way. ", "So what do we have here?  This is the analog of our point x equals a.  Is that right?  This is the point where the turning solution goes funny. ", "So we will call it, for the same reason we did before,  this point a will make matters clearer.  ", "We truly don't know what that point  is because we truly don't know what are the allowed energies.  But so far we can write E as a variable that we don't know. ", "And a can be determined if you know E because you know  the shape of the potential.  OK.  So let's think of the region, x much greater than a. ", "We are here.  We're in a forbidden region.  And the potential is still slowly varying.  Let's assume that slope is small.  So a solution of this type would make sense. ", " So we must have a WKB solution on this right hand side  to the right of x equals a. ", "And that's the most general solution we'll have.  On the other hand, here there's two types  of solutions, a growing exponential and a decaying ", "exponential.  And we must have only the decaying exponential.  Because this potential never turns.  If this potential would grow here and then turn down, ", "you might have what is called the tunneling problem.  And this has to be rethought.  But this problem is still a little easier.  We have just this potential growing forever. ", "And on the right, we must have b equal to 0.  For x greater than a solution, b is equal to 0. ", "And this solution must have a different from 0.  But if the solution has a different from 0, ", "we now know the solution on this region,  x significantly less than a.  In this region we know the solution is ", "given by that formula up there.  So our solution for x much less than a, the solution  must take the form whatever a is. ", "1, 2, 3.  I kind of normalized these things yet.  So the solution, I'll write it, psi of x, will be of the form 1 ", "over square root of k of x cosine of x  to a k of x prime vx prime minus pi over 4. ", " All right.  That's what WKB predicts because of the connection condition.  On the forbidden region, you know which wave exists. ", "And therefore, far to the left of the turning point,  you'd also know the wave function.  It's the term within a. ", "So have we solved the problem?  Well, I don't think we have.  We still don't know the energy, so we must have not solved it.  In fact, it doesn't look like we've solved it at all. ", "Because at x equals 0, these wave functions  should vanish because there's a hard wall. ", "And I don't see any reason why it would vanish.  So let's do a little work here expanding this ", "and orienting it a little better.  So I want to write this integral from 0, x to a. ", "You're having an integral.  You have 0, x, and a.  Because we are in the x less than a region,  this integral is the one that we have here. ", "I'll write it as an integral from 0  to a minus an integral from 0 to x.  So integral from x to a is equal to integral ", "from 0 to a minus an integral from 0 to x.  This will make things a little clearer.  ", "In fact, we could do things still a little easier.  So what do we have here? ", "We have this exponential, the wave function.  Not an exponential, a trigonometric function.  1 over square root of k of x cosine of minus the integral ", "from 0 to x of k of x dx prime.  ", "This integral gives rise to two integrals  and I wrote the first.   Then I come with the other [? sine ?] ", "plus the integral from 0 to a of k prime of x dx  prime minus pi over 4.  ", "And let's call this thing delta.  ", "So let's explore this wave function a little more.  So things have become kind of nice.  There's no x dependence here.  That's very nice about this part of the formula. ", "This is an angle.  No x dependence.  And the x dependence is just here from this term.  And it's a nice x dependence because it's an integral from 0 ", "to x.  So it's kind of nice.  The upper limit has the x.  It's all kind of elegant.  So trigonometric function of this cosine ", "of a difference of things is equal to its cosine ", "of the first term, 0 to x k of x prime dx prime cosine delta ", "plus sine of the first term 0 to x k of x prime dx prime sine ", "delta.   You have this quantity and this delta. ", "So I use this trigonometric sum.  OK.  But now you can see something nice.  ", "What did we say about the wave function?  It had to vanish at the origin.   And let's look at these two functions. ", "Which one vanishes at the origin?  You have cosine of the integral from 0  to x when x is equal to 0 at the origin is cosine ", "of 0, which is 1.  On the other hand, when x is small, x goes to 0.  You get 0 for the integral and the sine vanishes. ", "So this is the right term.   So this wave function would be correct  if this term would be absent. ", "This is a term that you must make absent.   Psi of x without that term would be a valid wave function.  It is the wave function. ", "Therefore, the right wave function  if we demand that cosine delta be equal to 0.  So now we're imposing a very non-trivial condition. ", "This wave over there.  This contribution to the argument, to the angle  here, this delta must be such that cosine delta is 0. ", "In which case, this term would disappear  and we would have a good wave function.  Psi of x, if this is true, is 1 over square root ", "of k of x times sine times the sine delta, which  is another number.  Sine of 0 to x k of x prime dx prime. ", " So we need cosine delta equal to 0.  You know, this argument gives you ", "this wave function in a nice way here written what it is.  But we would have been able to find this even faster. ", "If you just demand that Psi at x equals 0 is 0,  you must have that this thing, the integral from 0 to a ", "of this quantity minus pi over 4 must have 0 cosine.  And that's the condition we did fine.  The advantage of our rearrangement ", "is that when that happens, the whole wave function  looks like that.  And that's kind of nice.  That gives you the picture of the wave function.  A fairly accurate picture of the wave function in this region. ", " Not very near the turning point, but you got that.  So what is this cosine delta going to 0? ", " Well then delta must be 2n plus 1 times pi over 2. ", "So the places where the cosine is 0 is pi over 2.  That's for n equals 0.  3 pi over 2.  ", "So for n equal 1.  And it just goes.  The vertical axis and the unit circle.  So this is for n equals 0, 1, 2, 3, goes on and on. ", "And this is a very wonderful condition.  This says that the integral from 0 to a of k of x prime dx ", "prime minus pi over 4.  So actually, we have here you can multiply the 2 here.  You get an n.  And then you have pi over 2. ", "And the pi over 4 that comes from that term  becomes n plus 3/4 pi. ", "It's a Bohr-Sommerfeld quintessential condition.  Look, I box that equation because that really  gives you the answer.  Now, why? ", "Because you know what k is.  k p of x is equal to h bar k is square root  of 2n E minus v of x. ", " And if you know E, you know a.  So you have now an integral. ", "And you take, for example, n equals 0.  So you want the integral to be equal to 3/4 pi.  But you will have to start changing the value  of the energy with your computer if you cannot do the integral ", "analytically and find, oops, for this value of the energy  the integral of what I know, this is a known function,  gives me this value.  So this is a very practical way of finding the energy levels. ", "It does give you the approximate energy levels.  And it's remarkably accurate in many cases.  It also has a little intuition this ", "is for n equals 0 would be like the ground state.  n equal 1 first take on excited states.  And indeed, that makes sense.  Because this integral from 0 to a of k ", "is the total phase of the wave function  as you move from 0 to a.  And that wave is a number of factor n ", "times pi plus a little bit.  So it has time for m 0s.  The phase as you move from 0 to a in the wave function, ", "the sine function will have n 0s if this condition  is satisfied consistent with that solution.  So that's it.  We'll continue next time. ", "Find the solution of WKB exactly.  All right. "], "vid_duration": [12.47, 11.13, 10.95, 15.66, 11.34, 15.22, 11.64, 12.33, 11.39, 11.23, 12.03, 10.53, 12.24, 10.055, 16.835, 13.74, 11.22, 10.14, 10.5, 12.07, 13.4, 12.02, 11.57, 11.84, 11.94, 13.9, 10.43, 10.69, 10.99, 12.05, 14.25, 11.82, 12.06, 10.08, 17.24, 13.02, 10.52, 12.025, 11.42, 10.345, 14.78, 10.47, 10.219, 10.211, 18.11, 11.81, 11.36, 10.96, 10.26, 12.24, 11.34, 11.19, 13.07, 10.92, 10.05, 18.035, 10.935, 11.82, 10.95, 12.61, 19.73, 14.85, 15.77, 14.1, 11.98, 15.41, 16.52, 10.93, 10.22, 17.85, 10.28, 12.91, 12.29, 11.85, 14.46, 10.56, 21.475, 12.225, 15.71, 12.51, 12.8, 11.83, 11.52, 12.18, 10.65, 14.57, 12.35, 16.2, 14.72, 16.31, 10.5, 10.45, 18.39, 12.93, 15.1, 12.37, 11.59, 12.34, 11.82, 11.33, 10.94, 13.085, 10.745, 10.7, 17.134, 10.646, 12.61, 13.01, 12.398, 10.645, 12.715, 10.43, 14.175, 15.905, 10.71, 12.76, 10.5, 12.63, 11.19, 13.44, 11.61, 17.98, 10.3, 11.4, 13.35, 11.12, 11.94, 10.6, 14.105, 13.655, 10.19, 16.7, 14.42, 11.86, 12.81, 11.46, 12.27, 27.18, 14.19, 13.34, 13.09, 10.26, 10.17, 13.99, 15.28, 11.8, 14.81, 12.92, 12.26, 11.28, 10.23, 12.45, 13.38, 11.59, 12.66, 12.54, 16.89, 15.13, 13.46, 10.87, 16.28, 13.92, 18.41, 12.945, 10.105, 13.47, 14.76, 12.81, 11.01, 10.56, 12.58, 13.44, 13.94, 10.08, 12.0, 11.41, 11.37, 10.76, 12.846, 14.034, 13.36, 11.06, 11.07, 14.76, 10.3, 11.3, 12.21, 12.336, 14.433, 10.851, 10.23, 10.75, 14.07, 10.71, 10.41, 12.15, 14.19, 16.018, 10.04, 12.12, 12.16, 14.38, 17.6, 10.98, 10.09, 10.38, 12.12, 14.55, 11.37, 16.89, 12.69, 12.32, 14.07, 10.98, 12.49, 12.95, 14.51, 10.13, 13.94, 11.7, 11.76, 11.46, 10.71, 11.04, 13.45, 13.02, 10.69, 13.89, 10.92, 10.82, 18.85, 10.63, 29.32, 10.435, 10.245, 10.34, 13.61, 11.27, 10.23, 10.92, 12.36, 10.68, 10.2, 11.08, 10.04, 10.92, 10.01, 12.15, 18.44, 11.19, 13.88, 11.67, 18.64, 11.24, 14.53, 19.67, 14.79, 12.87, 13.1, 11.86, 12.8, 15.24, 12.27, 14.01, 15.48, 10.84, 14.91, 10.01, 10.86, 14.34, 12.99, 10.22, 10.02, 12.15, 10.98, 11.55, 10.32, 12.708, 12.15, 10.11, 12.04, 12.18, 13.88, 10.64, 12.75, 14.88, 10.98, 11.88, 11.4, 12.12, 13.08, 20.84, 12.056, 12.094, 11.7, 11.37, 22.295, 14.145, 10.99, 13.06, 14.95, 14.32, 10.25, 11.97, 10.55, 11.76, 12.18, 13.53, 14.6, 13.94, 11.49, 14.12, 13.605, 13.985, 11.22, 14.13, 12.72, 12.779, 11.821, 11.52, 11.7, 10.44, 16.12, 14.18, 10.67, 14.13, 10.99, 15.48, 10.47, 13.48, 12.98, 26.79, 11.55, 16.78, 10.36, 10.8, 11.73, 12.92, 12.07, 13.43, 12.12, 11.156, 14.724, 10.601, 13.109, 13.63, 12.82, 11.61, 10.24, 11.59, 12.47, 12.47, 13.69, 10.41, 13.595, 10.735, 11.16, 10.47, 10.288, 13.067, 11.305, 13.19, 11.64, 12.93, 13.38, 12.4, 11.26, 11.4, 13.575, 12.685, 12.6, 14.43, 13.14, 15.18, 11.58, 11.64, 10.17, 3.166], "stet": [[0, 12.47], [12.47, 23.6], [23.6, 34.55], [34.55, 50.209999999999994], [50.209999999999994, 61.55], [61.55, 76.77], [76.77, 88.41], [88.41, 100.74], [100.74, 112.13], [112.13, 123.36], [123.36, 135.39], [135.39, 145.92], [145.92, 158.16], [158.16, 168.215], [168.215, 185.05], [185.05, 198.79000000000002], [198.79000000000002, 210.01000000000002], [210.01000000000002, 220.15000000000003], [220.15000000000003, 230.65000000000003], [230.65000000000003, 242.72000000000003], [242.72000000000003, 256.12], [256.12, 268.14], [268.14, 279.71], [279.71, 291.54999999999995], [291.54999999999995, 303.48999999999995], [303.48999999999995, 317.38999999999993], [317.38999999999993, 327.81999999999994], [327.81999999999994, 338.50999999999993], [338.50999999999993, 349.49999999999994], [349.49999999999994, 361.54999999999995], [361.54999999999995, 375.79999999999995], [375.79999999999995, 387.61999999999995], [387.61999999999995, 399.67999999999995], [399.67999999999995, 409.75999999999993], [409.75999999999993, 426.99999999999994], [426.99999999999994, 440.0199999999999], [440.0199999999999, 450.5399999999999], [450.5399999999999, 462.5649999999999], [462.5649999999999, 473.9849999999999], [473.9849999999999, 484.3299999999999], [484.3299999999999, 499.1099999999999], [499.1099999999999, 509.5799999999999], [509.5799999999999, 519.799], [519.799, 530.01], [530.01, 548.12], [548.12, 559.93], [559.93, 571.29], [571.29, 582.25], [582.25, 592.51], [592.51, 604.75], [604.75, 616.09], [616.09, 627.2800000000001], [627.2800000000001, 640.3500000000001], [640.3500000000001, 651.2700000000001], [651.2700000000001, 661.32], [661.32, 679.355], [679.355, 690.29], [690.29, 702.11], [702.11, 713.0600000000001], [713.0600000000001, 725.6700000000001], [725.6700000000001, 745.4000000000001], [745.4000000000001, 760.2500000000001], [760.2500000000001, 776.0200000000001], [776.0200000000001, 790.1200000000001], [790.1200000000001, 802.1000000000001], [802.1000000000001, 817.5100000000001], [817.5100000000001, 834.0300000000001], [834.0300000000001, 844.96], [844.96, 855.1800000000001], [855.1800000000001, 873.0300000000001], [873.0300000000001, 883.3100000000001], [883.3100000000001, 896.22], [896.22, 908.51], [908.51, 920.36], [920.36, 934.82], [934.82, 945.38], [945.38, 966.855], [966.855, 979.08], [979.08, 994.7900000000001], [994.7900000000001, 1007.3000000000001], [1007.3000000000001, 1020.1], [1020.1, 1031.93], [1031.93, 1043.45], [1043.45, 1055.63], [1055.63, 1066.2800000000002], [1066.2800000000002, 1080.8500000000001], [1080.8500000000001, 1093.2], [1093.2, 1109.4], [1109.4, 1124.1200000000001], [1124.1200000000001, 1140.43], [1140.43, 1150.93], [1150.93, 1161.38], [1161.38, 1179.7700000000002], [1179.7700000000002, 1192.7000000000003], [1192.7000000000003, 1207.8000000000002], [1207.8000000000002, 1220.17], [1220.17, 1231.76], [1231.76, 1244.1], [1244.1, 1255.9199999999998], [1255.9199999999998, 1267.2499999999998], [1267.2499999999998, 1278.1899999999998], [1278.1899999999998, 1291.2749999999999], [1291.2749999999999, 1302.0199999999998], [1302.0199999999998, 1312.7199999999998], [1312.7199999999998, 1329.8539999999998], [1329.8539999999998, 1340.4999999999998], [1340.4999999999998, 1353.1099999999997], [1353.1099999999997, 1366.1199999999997], [1366.1199999999997, 1378.5179999999996], [1378.5179999999996, 1389.1629999999996], [1389.1629999999996, 1401.8779999999995], [1401.8779999999995, 1412.3079999999995], [1412.3079999999995, 1426.4829999999995], [1426.4829999999995, 1442.3879999999995], [1442.3879999999995, 1453.0979999999995], [1453.0979999999995, 1465.8579999999995], [1465.8579999999995, 1476.3579999999995], [1476.3579999999995, 1488.9879999999996], [1488.9879999999996, 1500.1779999999997], [1500.1779999999997, 1513.6179999999997], [1513.6179999999997, 1525.2279999999996], [1525.2279999999996, 1543.2079999999996], [1543.2079999999996, 1553.5079999999996], [1553.5079999999996, 1564.9079999999997], [1564.9079999999997, 1578.2579999999996], [1578.2579999999996, 1589.3779999999995], [1589.3779999999995, 1601.3179999999995], [1601.3179999999995, 1611.9179999999994], [1611.9179999999994, 1626.0229999999995], [1626.0229999999995, 1639.6779999999994], [1639.6779999999994, 1649.8679999999995], [1649.8679999999995, 1666.5679999999995], [1666.5679999999995, 1680.9879999999996], [1680.9879999999996, 1692.8479999999995], [1692.8479999999995, 1705.6579999999994], [1705.6579999999994, 1717.1179999999995], [1717.1179999999995, 1729.3879999999995], [1729.3879999999995, 1756.5679999999995], [1756.5679999999995, 1770.7579999999996], [1770.7579999999996, 1784.0979999999995], [1784.0979999999995, 1797.1879999999994], [1797.1879999999994, 1807.4479999999994], [1807.4479999999994, 1817.6179999999995], [1817.6179999999995, 1831.6079999999995], [1831.6079999999995, 1846.8879999999995], [1846.8879999999995, 1858.6879999999994], [1858.6879999999994, 1873.4979999999994], [1873.4979999999994, 1886.4179999999994], [1886.4179999999994, 1898.6779999999994], [1898.6779999999994, 1909.9579999999994], [1909.9579999999994, 1920.1879999999994], [1920.1879999999994, 1932.6379999999995], [1932.6379999999995, 1946.0179999999996], [1946.0179999999996, 1957.6079999999995], [1957.6079999999995, 1970.2679999999996], [1970.2679999999996, 1982.8079999999995], [1982.8079999999995, 1999.6979999999996], [1999.6979999999996, 2014.8279999999997], [2014.8279999999997, 2028.2879999999998], [2028.2879999999998, 2039.1579999999997], [2039.1579999999997, 2055.4379999999996], [2055.4379999999996, 2069.3579999999997], [2069.3579999999997, 2087.7679999999996], [2087.7679999999996, 2100.7129999999997], [2100.7129999999997, 2110.8179999999998], [2110.8179999999998, 2124.2879999999996], [2124.2879999999996, 2139.048], [2139.048, 2151.8579999999997], [2151.8579999999997, 2162.868], [2162.868, 2173.428], [2173.428, 2186.008], [2186.008, 2199.448], [2199.448, 2213.388], [2213.388, 2223.468], [2223.468, 2235.468], [2235.468, 2246.8779999999997], [2246.8779999999997, 2258.2479999999996], [2258.2479999999996, 2269.008], [2269.008, 2281.854], [2281.854, 2295.888], [2295.888, 2309.248], [2309.248, 2320.308], [2320.308, 2331.378], [2331.378, 2346.1380000000004], [2346.1380000000004, 2356.4380000000006], [2356.4380000000006, 2367.7380000000007], [2367.7380000000007, 2379.948000000001], [2379.948000000001, 2392.2840000000006], [2392.2840000000006, 2406.7170000000006], [2406.7170000000006, 2417.5680000000007], [2417.5680000000007, 2427.7980000000007], [2427.7980000000007, 2438.5480000000007], [2438.5480000000007, 2452.618000000001], [2452.618000000001, 2463.328000000001], [2463.328000000001, 2473.7380000000007], [2473.7380000000007, 2485.888000000001], [2485.888000000001, 2500.078000000001], [2500.078000000001, 2516.096000000001], [2516.096000000001, 2526.136000000001], [2526.136000000001, 2538.2560000000008], [2538.2560000000008, 2550.4160000000006], [2550.4160000000006, 2564.7960000000007], [2564.7960000000007, 2582.3960000000006], [2582.3960000000006, 2593.3760000000007], [2593.3760000000007, 2603.466000000001], [2603.466000000001, 2613.846000000001], [2613.846000000001, 2625.966000000001], [2625.966000000001, 2640.516000000001], [2640.516000000001, 2651.886000000001], [2651.886000000001, 2668.7760000000007], [2668.7760000000007, 2681.466000000001], [2681.466000000001, 2693.786000000001], [2693.786000000001, 2707.856000000001], [2707.856000000001, 2718.836000000001], [2718.836000000001, 2731.326000000001], [2731.326000000001, 2744.2760000000007], [2744.2760000000007, 2758.786000000001], [2758.786000000001, 2768.916000000001], [2768.916000000001, 2782.856000000001], [2782.856000000001, 2794.556000000001], [2794.556000000001, 2806.316000000001], [2806.316000000001, 2817.776000000001], [2817.776000000001, 2828.4860000000012], [2828.4860000000012, 2839.526000000001], [2839.526000000001, 2852.976000000001], [2852.976000000001, 2865.996000000001], [2865.996000000001, 2876.686000000001], [2876.686000000001, 2890.576000000001], [2890.576000000001, 2901.496000000001], [2901.496000000001, 2912.316000000001], [2912.316000000001, 2931.166000000001], [2931.166000000001, 2941.796000000001], [2941.796000000001, 2971.1160000000013], [2971.1160000000013, 2981.5510000000013], [2981.5510000000013, 2991.796000000001], [2991.796000000001, 3002.1360000000013], [3002.1360000000013, 3015.7460000000015], [3015.7460000000015, 3027.0160000000014], [3027.0160000000014, 3037.2460000000015], [3037.2460000000015, 3048.1660000000015], [3048.1660000000015, 3060.5260000000017], [3060.5260000000017, 3071.2060000000015], [3071.2060000000015, 3081.4060000000013], [3081.4060000000013, 3092.4860000000012], [3092.4860000000012, 3102.526000000001], [3102.526000000001, 3113.4460000000013], [3113.4460000000013, 3123.4560000000015], [3123.4560000000015, 3135.6060000000016], [3135.6060000000016, 3154.0460000000016], [3154.0460000000016, 3165.2360000000017], [3165.2360000000017, 3179.116000000002], [3179.116000000002, 3190.786000000002], [3190.786000000002, 3209.4260000000017], [3209.4260000000017, 3220.6660000000015], [3220.6660000000015, 3235.1960000000017], [3235.1960000000017, 3254.866000000002], [3254.866000000002, 3269.6560000000018], [3269.6560000000018, 3282.5260000000017], [3282.5260000000017, 3295.6260000000016], [3295.6260000000016, 3307.4860000000017], [3307.4860000000017, 3320.286000000002], [3320.286000000002, 3335.5260000000017], [3335.5260000000017, 3347.7960000000016], [3347.7960000000016, 3361.806000000002], [3361.806000000002, 3377.286000000002], [3377.286000000002, 3388.126000000002], [3388.126000000002, 3403.036000000002], [3403.036000000002, 3413.046000000002], [3413.046000000002, 3423.906000000002], [3423.906000000002, 3438.2460000000024], [3438.2460000000024, 3451.236000000002], [3451.236000000002, 3461.456000000002], [3461.456000000002, 3471.476000000002], [3471.476000000002, 3483.626000000002], [3483.626000000002, 3494.606000000002], [3494.606000000002, 3506.156000000002], [3506.156000000002, 3516.4760000000024], [3516.4760000000024, 3529.1840000000025], [3529.1840000000025, 3541.3340000000026], [3541.3340000000026, 3551.4440000000027], [3551.4440000000027, 3563.4840000000027], [3563.4840000000027, 3575.6640000000025], [3575.6640000000025, 3589.5440000000026], [3589.5440000000026, 3600.1840000000025], [3600.1840000000025, 3612.9340000000025], [3612.9340000000025, 3627.8140000000026], [3627.8140000000026, 3638.7940000000026], [3638.7940000000026, 3650.6740000000027], [3650.6740000000027, 3662.074000000003], [3662.074000000003, 3674.1940000000027], [3674.1940000000027, 3687.2740000000026], [3687.2740000000026, 3708.1140000000028], [3708.1140000000028, 3720.170000000003], [3720.170000000003, 3732.264000000003], [3732.264000000003, 3743.9640000000027], [3743.9640000000027, 3755.3340000000026], [3755.3340000000026, 3777.6290000000026], [3777.6290000000026, 3791.7740000000026], [3791.7740000000026, 3802.7640000000024], [3802.7640000000024, 3815.8240000000023], [3815.8240000000023, 3830.774000000002], [3830.774000000002, 3845.0940000000023], [3845.0940000000023, 3855.3440000000023], [3855.3440000000023, 3867.314000000002], [3867.314000000002, 3877.8640000000023], [3877.8640000000023, 3889.6240000000025], [3889.6240000000025, 3901.8040000000024], [3901.8040000000024, 3915.3340000000026], [3915.3340000000026, 3929.9340000000025], [3929.9340000000025, 3943.8740000000025], [3943.8740000000025, 3955.3640000000023], [3955.3640000000023, 3969.484000000002], [3969.484000000002, 3983.089000000002], [3983.089000000002, 3997.0740000000023], [3997.0740000000023, 4008.294000000002], [4008.294000000002, 4022.4240000000023], [4022.4240000000023, 4035.144000000002], [4035.144000000002, 4047.923000000002], [4047.923000000002, 4059.744000000002], [4059.744000000002, 4071.264000000002], [4071.264000000002, 4082.9640000000018], [4082.9640000000018, 4093.404000000002], [4093.404000000002, 4109.524000000002], [4109.524000000002, 4123.704000000002], [4123.704000000002, 4134.3740000000025], [4134.3740000000025, 4148.504000000003], [4148.504000000003, 4159.494000000002], [4159.494000000002, 4174.974000000002], [4174.974000000002, 4185.444000000002], [4185.444000000002, 4198.924000000002], [4198.924000000002, 4211.904000000001], [4211.904000000001, 4238.694000000001], [4238.694000000001, 4250.2440000000015], [4250.2440000000015, 4267.024000000001], [4267.024000000001, 4277.384000000001], [4277.384000000001, 4288.184000000001], [4288.184000000001, 4299.914000000001], [4299.914000000001, 4312.834000000001], [4312.834000000001, 4324.904], [4324.904, 4338.334000000001], [4338.334000000001, 4350.454000000001], [4350.454000000001, 4361.610000000001], [4361.610000000001, 4376.334000000001], [4376.334000000001, 4386.935], [4386.935, 4400.044000000001], [4400.044000000001, 4413.674000000001], [4413.674000000001, 4426.494000000001], [4426.494000000001, 4438.104], [4438.104, 4448.344], [4448.344, 4459.934], [4459.934, 4472.404], [4472.404, 4484.874000000001], [4484.874000000001, 4498.564], [4498.564, 4508.974], [4508.974, 4522.569], [4522.569, 4533.304], [4533.304, 4544.464], [4544.464, 4554.934], [4554.934, 4565.222], [4565.222, 4578.289], [4578.289, 4589.594], [4589.594, 4602.784], [4602.784, 4614.424], [4614.424, 4627.354], [4627.354, 4640.734], [4640.734, 4653.134], [4653.134, 4664.394], [4664.394, 4675.794], [4675.794, 4689.369], [4689.369, 4702.054], [4702.054, 4714.654], [4714.654, 4729.084000000001], [4729.084000000001, 4742.224000000001], [4742.224000000001, 4757.404000000001], [4757.404000000001, 4768.984000000001], [4768.984000000001, 4780.624000000002], [4780.624000000002, 4790.794000000002], [4790.794000000002, 4793.960000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1369, 2508, 3527, 4794]}
{"example_id": "mit038@@MIT8_06S18_L06_300k", "text": ["PROFESSOR: Good morning.  Today's lecture will deal with Zeeman effect.  And then we'll get started with a semi-classical approximation.  So Zeeman in effect is the last topic ", "we do with respect to the hydrogen  atom and the corrections of perturbation theory  and with WKB or the semi-classical approximation, ", "we begin a new chapter in 806.  Zeeman effect.  So this is an effect having to do  with an atom in a magnetic field. ", "It was discovered by a Dutch physicist, Peter Zeeman,  who lived from 1865 to 1943, who was a Dutch. ", "The work was actually done in 1896  at a time where there was very little idea of quantum  mechanics to be, and he got a Nobel Prize ", "for in the year 1902.  So what he discovered was the spectral lines  seemed to split in the presence of a magnetic field. ", "It's an old result, therefore, 100 years old.  Its explanation and understanding  took about a couple of decades, because you couldn't do it ", "without quantum mechanics.  So nobody could quite figure out what  had happened, but was very, very important in its time.  It still remains very important. ", "People use the Zeeman effect all the time.  In fact, it's used nowadays in studies  of astrophysics, studies of the sun, the sunspots. ", "You know, there are places in the sun,  where the temperature is a little lower,  and that's places where the magnetic field lines in the sun  sort of breakout from the interior to the exterior. ", "And it's interesting, because the sun produces  this cycle of solar spots, and it  happens, because the sun doesn't rotate uniformly, ", "has a different rotation speed in the equator,  faster than in the poles, so the magnetic field lines that  go from north to south in the sun get tangled up, ", "and they start breaking up and doing all these things.  So people want to know what is the magnetic field  in the solar sunspot.  And in fact, they observe the weak magnetic fields away ", "from the solar sunspots, and then they  see the spectrum of an atom.  And suddenly, as you move inside the spot, the field, ", "the spectrum, the lines split.  And they can measure the magnetic fields  very accurately.  They're of the order of 3,000 Gauss, 2,000, 3,000 Gauss. ", "And it's pretty interesting work.  So this Zeeman effect remains very important.  So what is the Zeeman effect? ", "We have Zeeman effect here.  ", "We have the magnetic field interacting with the electron,  and the electron now has two magnetic moments,  a magnetic moment associated with the orbital motion. ", " This looks completely like the classical formula ", "of the magnetic moment due to a particle that goes in circles.  It produces a current, and that current  is proportional to the angular momentum of the rotating ", "particle.  And of course, there is the magnetic moment  due to the spin that has a factor of 2 here.  This g factor, we've discussed before. ", "S.  So H Zeeman, you put an external magnetic field  into the atom, a constant uniform external magnetic ", "field, and you have a minus mu dot b,  so you have a interaction mu l plus mu s, ", "dot B. So this is e over 2mc.  That's the typical factor here, and a recognizable l plus 2s. ", "So it's not l plus s.  It's l plus 2s times b.  And many times, we think of B, align the axis ", "so that it is in the z direction.  So this turns out to be e over 2mc lz plus 2sz times ", "B. So this is the Zeeman Hamiltonian.  ", "But this is part of a story of an atom.  So if we want to think of the hydrogen atom properly, ", "we must consider and reconsider what was the Hamiltonian there.  And we had an H for the hydrogen atom.  That was an H 0. ", "That was the familiar one, p squared  over 2m minus e squared over r.  Then we had a fine structure Hamiltonian, ", "delta H, fine structure.   Let's put fs for fine structure. ", "Those were the relativistic terms, the Darwin term,  and the spin orbit coupling.  The three of them constituted what we call  defined structure Hamiltonian. ", "And now we have a Zeeman effect.  I probably should go delta H Zeeman,  because it's an addition here to the term we had before. ", "It refers to what I call just H Zeeman.  But in the context of the hydrogen atom,  we should call it delta H Zeeman.  And now, we have to rethink. ", "And the reason the Zeeman effect is non-trivial for us,  and it's a very interesting and somewhat challenging example ", "of what we have to do in perturbation theory,  is that we cannot forget about the fine structure.  So if it would be just this, it would be kind of simple. ", "But we have the whole thing.  So we have to make an approximation sometimes.  And we're going to consider two interesting cases, ", "the very weak Zeeman effect and the very strong Zeeman effect.  I will not consider the intermediate Zeeman effect, ", "not because it's not interesting,  but because there's very little you can do to simplify it,  and to think about it.  You basically have to go ahead and diagonalize ", "the large matrix.  So while it's important, and if your life depended on this,  and your research dependent on this, you would do it. ", "For us, we have a lot to learn from the weak case  and the strong case, lots of concepts,  and we'll leave the intermediate one for later. ", "So how can we decide how to treat these terms?  Well, we should look physically at what's happening.  We have a magnetic field, an external magnetic field. ", "But the fine structure constant taught you  that there is something like an internal magnetic field  in the atom.  It's that magnetic field responsible for spin orbit ", "coupling is that magnetic field that the electron sees when  it's going around the proton.  There's a static electric field, but whenever you are in motion, ", "a static electric field in the lab  also has a magnetic field by relativity,  and you do see a magnetic field.  You could also imagine it as you are the electron, ", "and the problem is going around you,  and creates at the center of the loop, a magnetic field.  In any case, you've looked at that magnetic field.  And we can call it the internal magnetic field ", "due to spin orbit.   As one exercise in the homework, you've  been asked to estimate the value of that internal magnetic ", "field.  Is it a Gauss, 1,000 Gauss, 10,000 Gauss?  How much it is for a typical level?  So there's a number here that this interest. ", "And now we can decide whether we have a weak Zeeman  effect or a strong Zeeman effect,  by looking how your external magnetic field compares ", "with this little magnetic field.  So we'll have a weak Zeeman effect, A. Zeeman.  ", "When B is much smaller than B internal.   And therefore, the effects of Zeeman ", "is going to be smaller than fine structure.  So really, when you look at this line,  and you have the first two terms, ", "you should think of these two terms  as your new known Hamiltonian. ", "And the Zeeman term, at its perturbation.   Yes.  You've solved for the fine structure ", "coupling and the shift.  So this is the known thing.  These are going to be the known states with known energies.  You only know them the first order, but you know them. ", "And then the Zeeman effect will be  a perturbation theory on this.  This is the weak Zeeman effect.  How about the strong Zeeman effect? ", "So B will be strong Zeeman.   This time, the magnetic field associated ", "with the Zeeman effect, the external magnetic field,  is much smaller than the magnetic field  responsible for spin orbit coupling. ", "And this time, what are we going to do?  Well, we will take the Hamiltonian. ", "It will be H 0.   The strong Zeeman effect means this Zeeman Hamiltonian ", "is a lot more important than the spin orbit coupling.  So we'll add delta H Zeeman here.  ", "And we hope this will be our known Hamiltonian,  because anyway, the Zeeman stuff is much stronger now ", "than fine structure.  So this should be our non-Hamiltonian.  You should complain, no, this is not known.  I haven't done Zeeman, but we'll look at it. ", "And once we have our known Hamiltonian here,  spin orbit has to be rethought.  Fine structure has to be rethought as a perturbation. ", "PROFESSOR: So case A-- weak Zeeman effect.   So what are our states here? ", "We discovered that and we know those are the coupled basis  states.  And the states of H0 tilde eigenstates--  ", "they are approximate eigenstates--  are the states n, l, j, mj. ", "And the energies were energies dependent on n and j.  ", "So the 1S 1/2, 2S 1/2, 2P 1/2, and 2P 3/2. ", "Roughly, to remind you of what happened,  the original states were shifted,  and we used the j quantum number in here. ", " And those are our multiplets.  Those are our multiplets.  And we have a lot of degeneracy as usual. ", "So this is degeneracy here and degeneracy here  because a multiplet P 3/2 is j equal 3/2. ", "And that's four states.  Here you have two states, and here you  have two states as well.  So quite a bit of states that are degenerate. ", "So in principle, when we do the Zeeman splitting,  we may have to consider the full matrix n, l, j, mj, delta H ", "Zeeman, nl prime j m prime j. ", "So what are our degeneracies?  Our degeneracies are when you have a given value of j. ", "So a degenerate subspace can have different l's--  for example, here-- but the same j,  and therefore different mj's. ", "Or within a given j multiplet, it might have different mj's.  So this is the scope of the degeneracy. ", "And in principle, we may have to diagonalize a matrix like that  by looking at the degenerate spaces.  If you're doing the level two, you  would have to discuss these four states here. ", "You would have to discuss this other four states.  Happily, we don't have to do that much  because, as usual, delta H Zeeman is proportional to l z ", "plus 2Sz.  And this commutes with l squared with delta H Zeeman.  ", "l squared commutes with any l operator.  It certainly commutes with any S operator.  They don't even talk to each other.  And therefore, l squared commutes ", "with l Zeeman, which means that when  l is different from l prime, this matrix element has  to vanish.  This is our remark from perturbation theory long, ", "long ago.  You have another operator for which  the states have different eigenvalues, commutes  with your perturbation.  The matrix element of the perturbation ", "must vanish between those states.  So we don't have eigenstates like that.  And when l is equal to l prime already-- ", "so we focus on l equals to l prime--  we only need to worry within multiplets.  So you have n, l, j, mj, delta H Zeeman now, and l, j, mj prime. ", "It's an issue of mj prime now.  But Zeeman thing commutes with Jz.  Jz commutes with delta H Zeeman. ", " Jz is Lz plus Sz, and z components  in angular momentum-- two identical components ", "always commute, of course.  So Jz commutes with delta H Zeeman.  So this thing will vanish unless m is equal to m prime. ", "And that's great because you're back  to nondegenerate perturbation theory.  The whole matrix, this Zeeman thing ", "could have turned out to be complicated matrices.  No.  It's perfectly diagonal in this basis.  There's nothing to worry about here, ", "except that it's still not easy to compute, as we will see.  So what do we need to compute?  We'll have the first order corrections ", "due to Zeeman on the n, l, j, mj basis is equal--  well, the Zeeman Hamiltonian had an e over 2mc. ", "So let's put it there.  e.  Let's put the B close to the e.  2mc.  And now we have to do n l j mj Lz plus 2Sz n l j mj. ", "Perfectly diagonal.   And that's nondegenerate perturbation theory.  It's going to give us all the energies we want. ", "All the splittings we want.  So basically what's going to happen, as you can see here,  is that the things down mix.  Everything is there.  Honestly, these two levels are going to split. ", "These two levels are going to split.  These four levels are going to split.  Everything is going to split here.  The remarkable thing of this formula, ", "and it's going to keep us busy for about 10, 15 more minutes,  is that this thing, this matrix element, is proportional to mj. ", "So the states split proportional to the m quantum number.  The state with the m equal 3/2 will split three times as much  as the state with m equal 1/2. ", "And that's not obvious here.  It's a remarkable result. It's part  of what's called the Wigner-Eckart theorem, ", "something that you study in graduate quantum mechanics.  But we're going to see a bit of it, the beginning of it,  in this computation.  And it's a fairly remarkable result. ", "So the remarkable result here--  remarkable-- is that E [INAUDIBLE] ", "are proportional to mj.   And that defines a linear splitting  because it's linearly proportional to the magnitude ", "of the magnetic field and divides the states nicely.  So we want to understand this matrix element.  And there's a little thing we can do. ", "Notice that Lz plus 2Sz is equal to Jz plus Sz.  You can take one of the Sz's and complete Jz, ", "and you're left with that.   So the matrix element n l j m Lz plus 2Sz n l j mj is equal-- ", "if you have a Jz, that gives you just something proportional  to Hmj plus n l j mj Sz n l j mj. ", "So OK.  A little bit of the mystery maybe  seems to you at least consistent here.  I said this matrix element turns out to be proportional to mj. ", "And certainly, this piece, having  to do with the J component here, is proportional to mj. ", "The mystery that remains is why this matrix element  would be proportional to mj.  ", "PROFESSOR: The story begins with a statement  that we will verify to some degree in the homework that ", "is due on Wednesday of vector operators.  This operator Sz, the one-line summary  is that this operator is a vector ", "operator under angular momentum--  under the total angular momentum.  And as such, its matrix elements will behave  like the matrix elements of Jz. ", "So how is that true?  What does it mean to say that S is a vector operator under J? ", "It is to say that for J, S is like a vector.  And that is a concrete statement that you  should check whether it's true. ", "The statement is that Ji Sj--   here, this i and j run from 1 to 3--  is equal to ih bar epsilon ijk Sk. ", " That is the statement that S is a vector operator. ", "You may have seen this in a previous course,  in 805, where you might have proven that X and P are vector ", "operators for L. And here, the proof ", "is not all that difficult. In fact,  it's almost obvious this is true, isn't it?  Ji is Li plus Si. ", "Li doesn't talk to Sj.  But Si with Sj satisfy the algebra of angular momentum  that is precisely this one. ", "So this is almost no calculation.  You will check-- you'll remind yourself--  that if you have a vector, that L-- for L-- ", "X and P are vector operators.  So for example, Li Pj is ih bar epsilon ijk Pk. ", "And this, you do by calculating the commutator.  But after you calculate the commutator a few times,  it's better to just remember, oh, it's a vector operator. ", "That's a good way of thinking about this.  OK.  If you have vector operators, they  have very peculiar properties sometimes. ", "One that may sound a little unmotivated,  but it's very useful, is the following.  Suppose you form the double commutator of J squared ", "with the vector operator S.  Here, you will find an identity.  And to make it fun for you, I will not tell you ", "the number that appears here.  It's some number.  But with some number here, this is  identical to the following SJ times J minus 1/2 ", "J squared S plus SJ squared.  Well, it's important to look at this equation,  even to make sure everything is in order. ", "This is a vector equation, so it's three equations.  So J squared, despite all this arrow, is a scalar,  has no indices.  It's J1 squared plus J2 squared plus J3 squared. ", "S, on the other hand, has an arrow, and it's a vector.  So you could look at this equation  for the third component, for the first component,  for the second.  So here is a vector, the three things. ", "Here is also a vector.  It's S dot J and J. So the vector index  is carried by the J here. ", "The vector index is carried by S here--  once to the left of J squared, once to the right of J squared. ", "Also, maybe you should notice that SJ  is the same thing as JS, not because these operators commute ", "but because SX and JX commute.  Sy and Jy commute.  And Sz and Jz commute. ", "Different components would not commute.  But here, these ones do commute.  So this is a formula you will show by computation. ", "I don't think there's a simple way to derive this formula.  But it's true and false by computation.  This formula implies a result that is quite pretty. ", "It's sometimes called a projection lemma.  So all we're doing is trying to compute a matrix element, ", "and we're forced to consider a lot of structure.  We're just trying to show this simple matrix  element, with an Sz here, is proportional to mj. ", "This is our goal.  And we're going to do that.  So suppose you take that interesting equation  and find its expectation value on a state that ", "is an eigenstate of j.  So suppose you take a j mj and put this whole equation inside ", "this-- left-hand side, then right-hand side--  a state that is an eigenstate of j.  ", "Now, that state may be an eigenstate of other operators,  as well.  It doesn't matter.  Now, look at your left-hand side.  ", "It's a commutator.  You have a j squared on the left, a commutator  on the right minus commutator on the left, j  squared on the right. ", "In both cases, there will be either a j squared near the bra  or a j squared near the ket.  Those two terms come with opposite signs. ", "Since those are eigenstates with the same eigenvalues, that's  what we're doing-- an expectation value here,  the left-hand side is 0.  So the left-hand side contributes nothing. ", "So left-hand side is 0, on this thing, is 0.  And let's look at the right-hand side. ", "It's equal to j mj S dot J J jmj and minus-- ", " so that was the first term.  Now, we have to compute this thing on this Jm Jm state. ", "Again, a J squared is either to the left or to the right.  Therefore, this gives a number which  is h squared j times j plus 1. ", "This gives the same number, as I showed you, on the bra.  You have two terms.  The factor of 1/2 cancels.  And you're left just with the expectation value of S, which ", "is kind of what we wanted here.  So this is minus h squared j times j  plus 1, which is the expectation value of J ", "squared times the expectation value jmj of S on the jmj. ", " OK.  You have this term minus that term equal to 0. ", "So what have we learned?  We have learned that this term that we can call expectation  value of S vector on a j eigenstate ", "is equal to the expectation value of this quantity,  S dot J J on the eigenstate divided by this number, which ", "turns out to be the expectation value of J  squared on that eigenstate.  This formula looks like a projection formula in which you ", "say the expectation value of S is the expectation  value of the projection of the vectored S onto the vector  J. Remember, if you have, for example, projection ", "of a vector a into a unit vector n,  what is the projection of a vector a into a unit vector n? ", "Well, the projection is a dot n times n.  That's the component of a along the vector n. ", "But if n is not a unit vector, the projection of a along b  is a dot b times b over b squared. ", " Because, in fact, the projection along a vector  or along a unit vector is the same thing. ", "It's just a projection.  And here, you have unit vectors.  So this is the projection lemma.  ", "It's a very nice result--  pretty striking, in fact.  This result is also mentioned in Griffiths. ", "It doesn't give a derivation of this result. It's just quoted.  But it's a beautiful and important result.  It's conceptually interesting. ", "It's valid for any vector operator under J.  And this will answer our question.  Because now, we can use this formula ", "to compute the matrix element.  So what do we have for our case?  We have that nljmj Sz nljmj is what? ", "Well, we have the expectation value of Jz on this state.  So it's going to be h bar mj over h ", "squared j times j plus 1.  That's the denominator.  And you still have here what may look like a small challenge, ", "or a big challenge--  happily, it's a small challenge.  S dot L mljmj.  ", "Here, this is called the scalar operator.  This is a variant on the rotations.  And scalar operators are independent of mj. ", "We got the mj dependence here.  We want to claim that this expectation  value is proportional to mj.  And we have the result here, unless there is mj dependence ", "here.  But there is no mj dependence here because, as I said,  this has to do with the fact that this is a scalar operator. ", "So let's calculate this part to finish this whole computation.  How do you do that?  Well, you have to remember you have J equal to L plus S. ", "So in here, we'll do the following.  I'm sorry.  I had the confusion here. ", "S dot J-- it's S dot J here.  It's starting to look wrong.  So I mean the dot product of J and S. ", "So here, I'll take l equals to J minus S.  And L squared is equal to J squared plus S squared ", "minus 2S dot J. Here, it's important  that S dot J and J dot S are the same. ", "And therefore, this S dot J is 1/2 of J squared plus S squared  minus L squared. ", " So with S dot J being this, you see immediately  what is this number. ", "This is h bar mj h squared j times j plus 1.  And now, 1/2-- so I have a 1/2 here, I'll put it in front-- ", "J squared-- so this is j times j plus 1,  there's an h squared that's in addition--  h squared here-- j times j plus 1 ", "S squared, which is 3/4, for it's  been 1/2, minus L squared, which is minus l times l plus 1. ", " OK, almost there.  Wow, this takes time.  But we have a result. So what is the result? ", "The matrix element nljmj lz--  oops, I'll put the whole thing together-- lz plus 2Sz-- ", "back to the whole matrix element.  Remember, we had one piece--   hmj and, now, this part.  So adding the hmj to this new part, ", "we have hmj 1 plus j times j plus 1 minus l times l ", "plus 1 plus 3/4 over 2j times j plus 1.  Phew. ", "OK.  I'm sorry.  It's all here.  I just copied that term, hopefully without mistakes.  So we have our matrix element. ", "And that matrix element in the top blackboard  there gives us the splitting.  It's probably a good time to introduce notation.  And there's a notation here where ", "this is called g sub J of l.  And it's called the Land g-factor.  ", "It's a g-factor in the sense that affects the energy  levels as if you were modifying the magnetic moment ", "of the particle.  So this number tells you how the level split.  They split proportional to mj--  all the various levels. ", "And for the full multiplate, the multiplate  is an eigenstate of j and an eigenstate of l.  So throughout all the states in the multiplate,  this is a single number. ", "And just, you have the hmj.  End result is the weak Zeeman splitting  nljm is eh bar over 2mc times B times gJ of l times mj. ", " And this number is about 579 times 10 ", "to the minus 9 eV per Gauss.  It's small.   So wow.  It took us some effort.  But here we are. ", "PROFESSOR: So B strong field Zeeman. ", "So what did we say we would do?  We would have H0 plus e over 2mc B Lz plus 2Lz ", "B. This would be our H0 check I call it,  plus delta H fine structure 1. ", " And we said what we have to do now  is strong field Zeeman is more important than fine structure. ", "So we first have to get the strong field  Zeeman figured out, with the bare bones hydrogen  atom, what it does.  And then on those states, we will do perturbation theory ", "for fine splitting.  So it is redoing fine splitting.  And you say oh my god, that's hard.  We spent a whole lecture doing that.  Well, second time you do things, they go a little faster. ", "So it's not that bad.  But here there is something quite remarkable.  This was supposed to be your known Hamiltonian. ", "And you say no, it's not known.  I never solved this before.   On the other hand, when we had H0 plus delta  H1, a fine structure, we did struggle. ", "And we found those states--  approximate states.  Here the situation happily is surprisingly simple.  ", "And one reason for that is the following.  That again, perhaps your initial impression ", "this can be solved exactly.  You don't even need perturbation theory to add this term.  What?  Yes!  This Hamiltonian commutes with H0. ", "Isn't that right?  H0 is rotational invariant.  So it commutes with any j.  Uncertain H0 has nothing for a spin. ", "It's a one matrix there.  So this commutes with Hamiltonian.  So it's possible that you can diagonalize this completely. ", "Simultaneous-- eigenstates of the first part  and the second part, so simultaneous eigenstates  from all of those!  But the news is even better.  Your uncoupled states-- uncoupled states n, l, m, l, ", "m, s, those were eigenstates except eigenstates of H0, ", "the all good ole hydrogen atom.  But actually they are exact eigenstates of lZ,  and exact eigenstates of sz. ", "So they're exact eigenstate of the Zeeman Hamiltonian.  So they state are it.  These are the exact states of H0 hat! ", "These are exact eigenstates--   eigenstates of H0 check-- ", "I'm sorry.  Its was not hat with eigenenergies as follows. ", " There are no mystery, the eigenenergies,  they're very simple.  The eigenenergies are e, n, l, ml, l, m, s. ", "Exact are e, m, 0, the ones that the hydrogen atom has  that don't depend on any of these other things plus eB ", "over 2mc eh bar B over 2mc ml plus 2ms. ", " So this serves perfectly the name of known Hamiltonian. ", "That was not the case for weak Zeeman.  And weak Zeeman who had this one and this one, and the other  was the approximately known Hamiltonian, to which  we added the weak Zeeman. ", "Here, it's this perfectly known Hamiltonian, to which we  have to now add fine structure.  So maybe the last thing that helps ", "you visualize what's going on is to understand  what happens to the splittings.  Because you're going to have to fine structure splitting. ", "And fine structure again, you will have to ask,  can I use non- degenerate perturbation theory or can  I not use it?  So you need to know what happened with the degeneracies ", "after you add this term.  Are all that the degeneracies of the hydrogen atom  broken by this term, or do some survive?  If they survive, is fine splitting diagonal ", "in those degenerate subspaces or not?  So the most important thing is figuring out  what are the degenerates spaces after you've added this term. ", "This is intuitively what you have to do.  If you approach this problem OK, I now  have to compute fine structure on a new basis,  and you have no idea what the new basis is, ", "you are proceeding a little bit with your eyes covered.  You should always try to make things a little more concrete.  So look at the n equal 2 states. ", " You have l equals 0 and l equals 1.  Here, you have six states. ", "Remember, their spin.  There's two states here.   The two states of l equals 0 have ms equal 1/2 ", "and ms equal to minus 1/2.  So they're going to split.  This number is going to be either plus 1 or minus 1,  and they're going to split. ", " And here-- so this is plus 1 on this factor here, this number, ", "or minus 1 for that number.  For this states of l equals 1, ml for example,  can be 1, and ms plus 1/2-- ", "so 1 plus 1 is 2.  So there is a state of 2.  Ml equals minus 2 minus 1, and this minus 1/2 ", "gives you minus 2.  So that's another state.   You can have more states. ", "For example, if you take ml equals 1 and ms equals  2 minus 1/2, you get the 0. ", " But you can also have ml equals minus 1 and this plus 1/2-- ", "plus 1/2, which also gives you 0.  So here there's a degeneracy.  There are six states.  You will see that there is one here and one there. ", "So here is the nature of the degeneracy.  The six states have split like that.  There's a degeneracy across l multiplets.  ", "And there's a degeneracy within l multiplets.  So two types of degeneracy.  And that's what you will have to consider when you  think of the fine splitting. ", "In fact, the problem in the homework  gives you some sort of trickery to evaluate this expectation  value with a little less work than the traditional method, ", "but still asks the question whether you  can use the generator or non-degenerate perturbation  theory.  And that's an interesting question.  And this example, can help you visualize a little better what ", "kind of degeneracies you have.   OK, we're concluding a chapter in the history of [INAUDIBLE]  six. ", "We're done with perturbation theory,  PROFESSOR: So, WKB approximation, ", "or semiclassical approximation.  ", "So this is work due to three people--  Wentzel, Kramers, and Brillouin--  in that incredible year, 1926, where so much of quantum ", "mechanics was figured out.  As it turns with many of these discoveries,  once the discoveries were made, people figured out  that somebody did them before. ", "And that person was a mathematician, Jeffreys,  who did it three years earlier, in 1923.  The work had not become very popular. ", "So some people write JWKB.   But we will not do that.  We'll note Jeffreys, but we'll follow this more ", "standard notation.  So these people were dealing with differential equations  with slowly-varying spatial coefficients. ", "That was the main thing.  So we're continuing our approximation methods.  We've done perturbation theory.  We will add little pieces to the Hamiltonian. ", "Now we consider things that are slowly varying in space.  You might have a very simple Hamiltonian  where nothing varies in space-- ", "a constant potential.  But as soon as the potential starts varying slowly,  you have approximation methods.  Those are the methods we're considering now. ", "We will also consider, after we've  finished WKB, time-dependent perturbation theory, where  still things start slowly varying in time. ", "So we'll have many, many things to do still.  So this is called, also, the semiclassical approximation. ", "Because classical physics gives you intuition about the quantum  wave function.  So it is a lesson in which you want to learn something ", "about the quantum wave function, and you learn it  by using classical physics.  A quantity that is relevant here is that the Broglie ", "wavelength of a particle.  This is the Broglie.  And many people say that semiclassical approximation ", "has to do with the fact that the quantum mechanic effects are  not that important.  That may happen.  The Broglie wavelength is much smaller ", "than the physically relevant sizes of your apparatus.  So you have a particle like an electron.  And if the Broglie wavelength is very small ", "compared to the aperture in the screen,  the letter will go almost like a classical particle.  When the Broglie wavelength is comparable with the size ", "of the aperture in the screen, you  will get diffraction effects, and the electrons  will do quantum mechanical things.  So the semiclassical approximation  has to do with lambda being smaller ", "than the length scale, L, of your physical problem.   We will refine this.  In fact, the whole search of understanding ", "the semiclassical approximation is  all about understanding this better.  Because it's a little subtle.  We will end up deciding that what you need ", "is that the Broglie wavelength, suitably generalized,  varies very slowly.  We'll have to generalize the concept of the Broglie ", "wavelength.  We might get to it today.  Mathematically, you can say, OK, I want  this to be sufficiently small. ", "So semiclassical limit was just take h going to 0.  You should complain, of course. ", "h is a constant of nature.  I cannot take it equal to 0.  But on the other hand, they could imagine other universes,  maybe, where h has different smaller and smaller values ", "in which quantum mechanical effects don't set in  until much smaller scales.  But at the end of the day, I will ", "try to consider h to be small as an idea underlying  a semiclassical approximation.  And the intuition is that for h small-- ", "we cannot tune it, but we can say it--  h small lambda becomes small.   The lambda, the Broglie, dB. ", " You're taking a quantity with units--  h bar is units. ", "And saying it's small.  It goes against lots of things.  Things with units are not supposed to be small.  ", "You should compare it with the situation we had before.  We had a very nice and clean situation  with perturbation theory, where we had a unit-free thing ", "that we consider it to be small.  This time, we're going to try to consider h to be small.  And it's going to be more delicate because it has units. ", "It's going to be a more complicated story.  The physics is interesting, and that's  why this approximation is harder in some ways  to understand than the ones we've ", "done in perturbation theory.  So how does this begin?  It begins by thinking of a particle in a potential, V ", "of x.  And the particle has some energy, E.  And then, if it's classical, as we're imagining now, ", "it could be a three-dimensional potential.  My sketch of course is just for one-dimensional.  This is E. And you can solve for p squared, 2m, E ", "minus V. This is a notion of local momentum ", "because it depends on x.  It's the momentum the particle would have.  When it is at some position, x, you  will have momentum, p, of x. ", " And now, nobody forbids you from declaring ", "that you're going to define a position-dependent Broglie  wavelength, which is going to be h over p  of x is your definition, which is equal to 2 pi h bar over p ", "of x.  And it's going to be local the Broglie.  ", "You see that the Broglie wavelength, when you first  started in 804, was considered for a free particle--  always the [INAUDIBLE].  You have a free particle with some momentum it ", "has at the Broglie wavelength.  Why was the Broglie wavelength important?  Because when you write the wave function,  it's a wave with wavelength equal to the Broglie ", "wavelength.  The wave function with the Broglie wavelength  solves the Schrodinger equation.  That's sort of how it all came about. ", "But it was all defined for a free particle.  The Broglie defined it for a free particle  with some momentum, p.  And it all made sense, because you could write a wave function ", "using the Broglie momentum.  It was in fact E to the ipx over h bar.  That was your wave function.  But here, you have a particle moving with varying momenta. ", "And we don't know how to write the solution of the Schrodinger  equation, but there's classically this concept,  and we could define the local, the Broglie wavelength,  and we will have to discover what it means ", "or how it shows up.  But it probably shows up in some way.  So there's two cases that probably we should consider. ", "But before that, we looked at the Schrodinger equation--  the time-independent Schrodinger equation. ", "So it's minus h squared over 2m Laplacian  of psi of x is equal to E minus v of x, psi of x. ", "All these vectors-- that's why I'm Laplacian, not  second derivatives.  But the right-hand side--  ", "well, if I put the 2m to the other side,  I get minus h squared Laplacian of psi of x, ", "is equal to 2m E minus vx.  That's p squared of x, psi of x.  That's the local momentum squared.  ", "Maybe it's a curiosity, but it's now nice that the left-hand  side is the momentum operator squared--  so it's p hat squared on the wave function-- ", "is equal to p squared of x times a wave function.  Kind of a nice result. Nice-looking Schrodinger ", "equation.  I don't know if you've seen it like that before.  It's an operator on the left.  And on the right, almost like an eigenvalue. ", "It's an illegal eigenvalue.  If it were a real eigenvalue problem,  there should be a number, not a function here.  But it's a function that acts a little like an eigenvalue. ", "It's a nice way of thinking of the Schrodinger equation  in the semiclassical approximation.  Well, no.  No approximation here so far in the semiclassical language, ", "in which you call this the local momentum.  And thus defined, it certainly is an exact statement-- ", "no approximation whatsoever.   OK, now I want to know these two circumstances of course. ", "If you have E greater than v, you're in an allowed region.  ", "And p squared is really 2m E minus v of x.  And it's convenient to define h squared k squared ", "of x, the wave number.  You remember that p equal hk was good notation.  We use the wave number sometimes.  We'll have here a local wave number as well. ", " And if you're in the forbidden region,  which energy is less than v--  forbidden region-- then minus p squared ", "is positive, is 2m v minus E. That is positive  this time, because v is greater than E. ", "And that, we always used to call the penetration  constant, the kappa, for wave functions  that decay exponentially.  So we call this h squared kappa squared of x. ", "A local decaying factor wave number.  It can be thought as an imaginary wave number.  But that's notation.  ", "So, so far, so good.  We will need one more piece of intuition  as we work with this semiclassical approximation.  We have not done any approximation yet. ", "The approximation will come soon,  as we will begin solving the Schrodinger equation  under those circumstances.  And we will take h bar as an expansion parameter-- ", " will be fine and correct, but a little subtle.  So the thing that will help us many times ", "to understand these things is to write the wave function  as a complex number.  So suppose you have a wave function.  ", "We will write it as a complex number in the polar form--  radius times face.  So the radius is going to be rho of x. ", "The probability density, I claim, is this.  And there is a phase that I will write as E to the i  over h bar, S of x and t. ", "It looks a little like an action.  And it's, to some degree, the beginning of the path  into rule formulation.  It has lots of connections with the action principle. ", "So here, rho and s are going to be real.  So this is truly scale factor in front ", "that determines the value.  This is a pure phase, because it's an imaginary number  times a real thing.  S has units of h bar, or angular momentum. ", "And indeed, psi squared is equal to rho of x and t.  If you loop psi squared. ", "The reason we focus on this wave function  is that our solutions of WKB are going  to have exactly that form.  So we need to have an intuition as to what ", "the observables of this wave function are.  So the other observable is the current density.  If you remember, it's h bar over m, imaginary part of psi star ", "gradient psi.  So this must be calculated.  ", "So what is this?  Gradient of psi-- we must take the gradient of this.  Gradient's a derivative, so it acts on one, acts on the other. ", "When it acts on the first, it first  acts as the relative 1 over 2 squared of rho of x and t,  times the gradient of rho, times the phase factor, plus now ", "I have to take the gradient on this quantity,  and this will bring down an i, an h bar, the gradient of S, ", "and then multiplied by the whole wave function,  because this factor remains and the exponential remains.  ", "Now we can multiply by psi star to form what  we need to get for the current.  ", "So psi star [INAUDIBLE] psi.  If I multiply by that, I'm multiplying by the top line. ", "For the first factor, I get 1/2 gradient of rho.  The exponentials cancel.  And for the second part, we get plus i ", "over h bar, gradient of S, times psi squared, which is rho.  The imaginary part of this is equal 1 ", "over h bar, rho gradient of s.   So finally, the current, which is  h bar over m, times that imaginary part, ", "is rho gradient of s, over m.   A very nice formula. ", "Basically, it says that the phase factor in the wave  function determines the probability current.  And it also says that if you want to think of this, ", "here are the surfaces of constant phase.  Here is our space.  And S constant.  So here is one valley of the phase, ", "another valley of the phase.  Those are surfaces in space of constant phase.  The current is orthogonal to that.  So the current is proportional to the gradient. ", "The gradient of a function is always proportional.  It's a normal vector to the surfaces of constant values.  So the current is orthogonal to the surfaces of constant phase. ", " If you have a fluid mechanics interpretation,  J is rho v in fluids. ", " So, so far, everything I've said could have been said in 804.  These are properties of a general wave function. ", "This is how you compute the current.  The useful thing is that our WKB wave  functions are going to be presented in that language.  So if you think of the analogy with fluid mechanics. ", "The current is the charge density times the velocity,  and therefore the velocity would be identified  with gradient of S over m. ", "Or the momentum would be identified with gradient of S.  That's not a quantum mechanical rigorous identification. ", "Because gradient of S is a function.  And therefore, p there would be a function.  And a function of momentum--  momentum in quantum mechanics is an operator, ", "and it has eigenvalues, which are numbers.  They're not functions.  But we already have seen the beginning  of some momentum function. ", "So that analogy is actually quite nice.  Let me give you an example, and conclude with that.  If you have a free particle, you have a wave function psi ", "of x and t, which is E, to the ipx over h bar,  times minus iEt over h bar. ", " So in this case, rho is equal to 1, an S--  remember, S is read by having an i over an h bar out. ", "And that gives you p dot x minus Et.   So for a free particle, the gradient of S ", "is indeed just the momentum.  You take this gradient, and it's that.  And therefore, that's a rigorous interpretation  when you have a free particle, that the gradient of S ", "is going to be the momentum.  Interestingly, the derivative of S with respect to time  is minus the energy.  ", "What will happen in the semiclassical approximation  is that this S over there will depend on x,  and this p will depend on x, and it will be ", "this p that depends on x here.  And we will see how to solve this equation  in an approximation scheme where the changes are a little slow. ", "And the notation S here is also motivated  because actions in classical mechanics  actually have this property. ", "The gradient of the action-- if you  think of the action as a function of coordinates,  which is something you don't usually do, but if you do,  in somewhat advanced classical mechanics, ", "you see that the derivatives of the action-- spatial  derivatives are the momentum, and the time derivatives  are the energy.  It's a nice relation between classical mechanics, ", "and justifies once more the name of semiclassical approximation,  which we will continue to develop next time. "], "vid_duration": [13.64, 13.05, 12.91, 12.51, 13.77, 14.27, 10.51, 12.9, 10.77, 13.49, 11.89, 11.37, 14.13, 10.17, 11.34, 11.19, 10.8, 11.505, 12.655, 11.79, 11.83, 13.96, 11.91, 15.39, 15.97, 13.5, 13.22, 10.14, 12.96, 11.22, 10.87, 12.48, 15.56, 11.73, 10.17, 13.39, 10.15, 11.74, 10.87, 11.3, 11.83, 12.809, 12.711, 12.0, 10.59, 14.97, 10.721, 11.979, 10.38, 11.51, 13.61, 13.92, 11.44, 11.98, 14.46, 12.78, 12.63, 11.68, 10.386, 12.324, 11.25, 13.54, 10.06, 12.003, 14.539, 15.851, 13.149, 10.25, 20.39, 12.271, 13.31, 11.26, 16.159, 12.301, 11.9, 12.45, 12.63, 12.15, 12.87, 13.53, 13.2, 10.77, 12.719, 10.171, 10.889, 20.041, 12.235, 12.675, 14.0, 10.049, 11.701, 11.13, 12.36, 22.5, 10.32, 12.63, 10.89, 13.58, 12.9, 11.9, 11.25, 11.35, 11.58, 10.3, 13.87, 22.029, 21.671, 11.66, 11.43, 11.888, 10.232, 14.458, 13.23, 17.74, 11.35, 15.89, 13.719, 13.081, 12.75, 11.361, 10.469, 10.98, 12.849, 13.5, 11.401, 16.96, 11.639, 18.28, 15.241, 13.259, 12.101, 10.48, 10.89, 11.2, 10.41, 12.149, 14.851, 10.23, 13.889, 14.681, 17.059, 10.861, 12.86, 11.45, 11.49, 12.72, 12.869, 13.391, 13.98, 10.868, 10.402, 11.669, 10.391, 10.77, 14.7, 17.03, 12.69, 17.97, 14.51, 11.06, 15.675, 11.594, 11.34, 12.901, 10.65, 12.6, 19.91, 13.639, 10.291, 18.69, 12.99, 13.14, 11.48, 19.23, 10.25, 11.55, 12.36, 10.83, 11.55, 10.28, 14.33, 15.785, 10.225, 21.979, 15.121, 13.879, 10.031, 10.39, 11.97, 13.169, 15.281, 10.32, 11.02, 11.24, 19.86, 13.88, 11.64, 13.139, 13.741, 12.779, 15.861, 14.78, 13.529, 11.011, 12.69, 10.54, 10.299, 13.02, 10.841, 12.159, 21.27, 11.44, 12.94, 14.33, 11.056, 10.85, 18.295, 13.56, 10.37, 11.449, 11.88, 13.02, 11.85, 12.871, 13.44, 10.839, 11.071, 10.23, 10.779, 12.4, 10.29, 12.241, 14.219, 13.671, 13.739, 11.11, 11.201, 11.92, 13.75, 12.64, 11.419, 14.161, 12.07, 16.435, 11.98, 15.029, 11.64, 10.991, 10.579, 12.5, 12.301, 10.009, 10.381, 10.449, 11.181, 11.37, 10.239, 13.551, 12.5, 10.84, 10.109, 16.331, 12.569, 11.44, 10.589, 10.812, 10.219, 12.641, 10.469, 12.54, 12.48, 11.43, 10.621, 11.64, 10.039, 11.89, 11.721, 14.19, 14.79, 20.239, 10.891, 11.18, 17.639, 10.441, 11.619, 10.621, 10.26, 11.4, 14.06, 11.65, 11.1, 12.28, 14.72, 10.9, 12.049, 12.571, 11.4, 15.719, 10.21, 13.531, 12.239, 10.02, 12.351, 10.649, 12.031, 13.259, 18.62, 12.61, 15.571, 13.98, 13.42, 13.91, 11.86, 10.77, 13.06, 13.699, 12.15, 11.031, 12.509, 12.861, 12.119, 18.941, 10.809, 11.601, 22.16, 12.899, 13.981, 12.269, 11.58, 12.571, 14.78, 14.1, 11.75, 14.25, 11.084, 11.776, 12.689, 10.561, 13.24, 12.31, 14.31, 12.0, 13.29, 10.079, 15.561, 12.88, 15.55, 12.873, 12.657, 14.599, 10.92, 11.16, 12.061, 11.939, 11.34, 7.352], "stet": [[0, 13.64], [13.64, 26.69], [26.69, 39.6], [39.6, 52.11], [52.11, 65.88], [65.88, 80.14999999999999], [80.14999999999999, 90.66], [90.66, 103.56], [103.56, 114.33], [114.33, 127.82], [127.82, 139.70999999999998], [139.70999999999998, 151.07999999999998], [151.07999999999998, 165.20999999999998], [165.20999999999998, 175.37999999999997], [175.37999999999997, 186.71999999999997], [186.71999999999997, 197.90999999999997], [197.90999999999997, 208.70999999999998], [208.70999999999998, 220.21499999999997], [220.21499999999997, 232.86999999999998], [232.86999999999998, 244.65999999999997], [244.65999999999997, 256.48999999999995], [256.48999999999995, 270.44999999999993], [270.44999999999993, 282.35999999999996], [282.35999999999996, 297.74999999999994], [297.74999999999994, 313.71999999999997], [313.71999999999997, 327.21999999999997], [327.21999999999997, 340.44], [340.44, 350.58], [350.58, 363.53999999999996], [363.53999999999996, 374.76], [374.76, 385.63], [385.63, 398.11], [398.11, 413.67], [413.67, 425.40000000000003], [425.40000000000003, 435.57000000000005], [435.57000000000005, 448.96000000000004], [448.96000000000004, 459.11], [459.11, 470.85], [470.85, 481.72], [481.72, 493.02000000000004], [493.02000000000004, 504.85], [504.85, 517.659], [517.659, 530.37], [530.37, 542.37], [542.37, 552.96], [552.96, 567.9300000000001], [567.9300000000001, 578.6510000000001], [578.6510000000001, 590.6300000000001], [590.6300000000001, 601.0100000000001], [601.0100000000001, 612.5200000000001], [612.5200000000001, 626.1300000000001], [626.1300000000001, 640.0500000000001], [640.0500000000001, 651.4900000000001], [651.4900000000001, 663.4700000000001], [663.4700000000001, 677.9300000000002], [677.9300000000002, 690.7100000000002], [690.7100000000002, 703.3400000000001], [703.3400000000001, 715.0200000000001], [715.0200000000001, 725.4060000000001], [725.4060000000001, 737.73], [737.73, 748.98], [748.98, 762.52], [762.52, 772.5799999999999], [772.5799999999999, 784.583], [784.583, 799.122], [799.122, 814.973], [814.973, 828.122], [828.122, 838.372], [838.372, 858.762], [858.762, 871.0329999999999], [871.0329999999999, 884.3429999999998], [884.3429999999998, 895.6029999999998], [895.6029999999998, 911.7619999999998], [911.7619999999998, 924.0629999999999], [924.0629999999999, 935.9629999999999], [935.9629999999999, 948.4129999999999], [948.4129999999999, 961.0429999999999], [961.0429999999999, 973.1929999999999], [973.1929999999999, 986.0629999999999], [986.0629999999999, 999.5929999999998], [999.5929999999998, 1012.7929999999999], [1012.7929999999999, 1023.5629999999999], [1023.5629999999999, 1036.282], [1036.282, 1046.453], [1046.453, 1057.3419999999999], [1057.3419999999999, 1077.3829999999998], [1077.3829999999998, 1089.6179999999997], [1089.6179999999997, 1102.2929999999997], [1102.2929999999997, 1116.2929999999997], [1116.2929999999997, 1126.3419999999996], [1126.3419999999996, 1138.0429999999997], [1138.0429999999997, 1149.1729999999998], [1149.1729999999998, 1161.5329999999997], [1161.5329999999997, 1184.0329999999997], [1184.0329999999997, 1194.3529999999996], [1194.3529999999996, 1206.9829999999997], [1206.9829999999997, 1217.8729999999998], [1217.8729999999998, 1231.4529999999997], [1231.4529999999997, 1244.3529999999998], [1244.3529999999998, 1256.253], [1256.253, 1267.503], [1267.503, 1278.8529999999998], [1278.8529999999998, 1290.4329999999998], [1290.4329999999998, 1300.7329999999997], [1300.7329999999997, 1314.6029999999996], [1314.6029999999996, 1336.6319999999996], [1336.6319999999996, 1358.3029999999997], [1358.3029999999997, 1369.9629999999997], [1369.9629999999997, 1381.3929999999998], [1381.3929999999998, 1393.2809999999997], [1393.2809999999997, 1403.5129999999997], [1403.5129999999997, 1417.9709999999998], [1417.9709999999998, 1431.2009999999998], [1431.2009999999998, 1448.9409999999998], [1448.9409999999998, 1460.2909999999997], [1460.2909999999997, 1476.1809999999998], [1476.1809999999998, 1489.8999999999999], [1489.8999999999999, 1502.9809999999998], [1502.9809999999998, 1515.7309999999998], [1515.7309999999998, 1527.0919999999999], [1527.0919999999999, 1537.561], [1537.561, 1548.541], [1548.541, 1561.3899999999999], [1561.3899999999999, 1574.8899999999999], [1574.8899999999999, 1586.291], [1586.291, 1603.251], [1603.251, 1614.8899999999999], [1614.8899999999999, 1633.1699999999998], [1633.1699999999998, 1648.4109999999998], [1648.4109999999998, 1661.6699999999998], [1661.6699999999998, 1673.771], [1673.771, 1684.251], [1684.251, 1695.141], [1695.141, 1706.3410000000001], [1706.3410000000001, 1716.7510000000002], [1716.7510000000002, 1728.9], [1728.9, 1743.7510000000002], [1743.7510000000002, 1753.9810000000002], [1753.9810000000002, 1767.8700000000001], [1767.8700000000001, 1782.5510000000002], [1782.5510000000002, 1799.6100000000001], [1799.6100000000001, 1810.4710000000002], [1810.4710000000002, 1823.3310000000001], [1823.3310000000001, 1834.7810000000002], [1834.7810000000002, 1846.2710000000002], [1846.2710000000002, 1858.9910000000002], [1858.9910000000002, 1871.8600000000001], [1871.8600000000001, 1885.2510000000002], [1885.2510000000002, 1899.2310000000002], [1899.2310000000002, 1910.0990000000002], [1910.0990000000002, 1920.5010000000002], [1920.5010000000002, 1932.1700000000003], [1932.1700000000003, 1942.5610000000004], [1942.5610000000004, 1953.3310000000004], [1953.3310000000004, 1968.0310000000004], [1968.0310000000004, 1985.0610000000004], [1985.0610000000004, 1997.7510000000004], [1997.7510000000004, 2015.7210000000005], [2015.7210000000005, 2030.2310000000004], [2030.2310000000004, 2041.2910000000004], [2041.2910000000004, 2056.9660000000003], [2056.9660000000003, 2068.5600000000004], [2068.5600000000004, 2079.9000000000005], [2079.9000000000005, 2092.8010000000004], [2092.8010000000004, 2103.4510000000005], [2103.4510000000005, 2116.0510000000004], [2116.0510000000004, 2135.9610000000002], [2135.9610000000002, 2149.6000000000004], [2149.6000000000004, 2159.8910000000005], [2159.8910000000005, 2178.5810000000006], [2178.5810000000006, 2191.5710000000004], [2191.5710000000004, 2204.7110000000002], [2204.7110000000002, 2216.1910000000003], [2216.1910000000003, 2235.4210000000003], [2235.4210000000003, 2245.6710000000003], [2245.6710000000003, 2257.2210000000005], [2257.2210000000005, 2269.5810000000006], [2269.5810000000006, 2280.4110000000005], [2280.4110000000005, 2291.9610000000007], [2291.9610000000007, 2302.241000000001], [2302.241000000001, 2316.571000000001], [2316.571000000001, 2332.3560000000007], [2332.3560000000007, 2342.5810000000006], [2342.5810000000006, 2364.5600000000004], [2364.5600000000004, 2379.6810000000005], [2379.6810000000005, 2393.5600000000004], [2393.5600000000004, 2403.5910000000003], [2403.5910000000003, 2413.981], [2413.981, 2425.951], [2425.951, 2439.12], [2439.12, 2454.401], [2454.401, 2464.721], [2464.721, 2475.741], [2475.741, 2486.9809999999998], [2486.9809999999998, 2506.841], [2506.841, 2520.721], [2520.721, 2532.361], [2532.361, 2545.5], [2545.5, 2559.241], [2559.241, 2572.02], [2572.02, 2587.881], [2587.881, 2602.661], [2602.661, 2616.19], [2616.19, 2627.201], [2627.201, 2639.891], [2639.891, 2650.431], [2650.431, 2660.73], [2660.73, 2673.75], [2673.75, 2684.591], [2684.591, 2696.75], [2696.75, 2718.02], [2718.02, 2729.46], [2729.46, 2742.4], [2742.4, 2756.73], [2756.73, 2767.786], [2767.786, 2778.636], [2778.636, 2796.931], [2796.931, 2810.491], [2810.491, 2820.861], [2820.861, 2832.31], [2832.31, 2844.19], [2844.19, 2857.21], [2857.21, 2869.06], [2869.06, 2881.931], [2881.931, 2895.371], [2895.371, 2906.21], [2906.21, 2917.281], [2917.281, 2927.511], [2927.511, 2938.29], [2938.29, 2950.69], [2950.69, 2960.98], [2960.98, 2973.221], [2973.221, 2987.44], [2987.44, 3001.111], [3001.111, 3014.85], [3014.85, 3025.96], [3025.96, 3037.161], [3037.161, 3049.081], [3049.081, 3062.831], [3062.831, 3075.471], [3075.471, 3086.89], [3086.89, 3101.051], [3101.051, 3113.121], [3113.121, 3129.556], [3129.556, 3141.536], [3141.536, 3156.565], [3156.565, 3168.205], [3168.205, 3179.196], [3179.196, 3189.775], [3189.775, 3202.275], [3202.275, 3214.576], [3214.576, 3224.585], [3224.585, 3234.966], [3234.966, 3245.415], [3245.415, 3256.596], [3256.596, 3267.966], [3267.966, 3278.205], [3278.205, 3291.756], [3291.756, 3304.256], [3304.256, 3315.096], [3315.096, 3325.205], [3325.205, 3341.536], [3341.536, 3354.105], [3354.105, 3365.545], [3365.545, 3376.134], [3376.134, 3386.946], [3386.946, 3397.165], [3397.165, 3409.806], [3409.806, 3420.275], [3420.275, 3432.815], [3432.815, 3445.295], [3445.295, 3456.725], [3456.725, 3467.346], [3467.346, 3478.986], [3478.986, 3489.025], [3489.025, 3500.915], [3500.915, 3512.636], [3512.636, 3526.826], [3526.826, 3541.616], [3541.616, 3561.855], [3561.855, 3572.746], [3572.746, 3583.926], [3583.926, 3601.565], [3601.565, 3612.006], [3612.006, 3623.625], [3623.625, 3634.246], [3634.246, 3644.5060000000003], [3644.5060000000003, 3655.9060000000004], [3655.9060000000004, 3669.9660000000003], [3669.9660000000003, 3681.6160000000004], [3681.6160000000004, 3692.7160000000003], [3692.7160000000003, 3704.9960000000005], [3704.9960000000005, 3719.7160000000003], [3719.7160000000003, 3730.6160000000004], [3730.6160000000004, 3742.6650000000004], [3742.6650000000004, 3755.2360000000003], [3755.2360000000003, 3766.6360000000004], [3766.6360000000004, 3782.3550000000005], [3782.3550000000005, 3792.5650000000005], [3792.5650000000005, 3806.0960000000005], [3806.0960000000005, 3818.3350000000005], [3818.3350000000005, 3828.3550000000005], [3828.3550000000005, 3840.7060000000006], [3840.7060000000006, 3851.3550000000005], [3851.3550000000005, 3863.3860000000004], [3863.3860000000004, 3876.6450000000004], [3876.6450000000004, 3895.2650000000003], [3895.2650000000003, 3907.8750000000005], [3907.8750000000005, 3923.4460000000004], [3923.4460000000004, 3937.4260000000004], [3937.4260000000004, 3950.8460000000005], [3950.8460000000005, 3964.7560000000003], [3964.7560000000003, 3976.6160000000004], [3976.6160000000004, 3987.3860000000004], [3987.3860000000004, 4000.4460000000004], [4000.4460000000004, 4014.1450000000004], [4014.1450000000004, 4026.2950000000005], [4026.2950000000005, 4037.3260000000005], [4037.3260000000005, 4049.8350000000005], [4049.8350000000005, 4062.6960000000004], [4062.6960000000004, 4074.8150000000005], [4074.8150000000005, 4093.7560000000003], [4093.7560000000003, 4104.5650000000005], [4104.5650000000005, 4116.166], [4116.166, 4138.326], [4138.326, 4151.225], [4151.225, 4165.206], [4165.206, 4177.475], [4177.475, 4189.055], [4189.055, 4201.626], [4201.626, 4216.406], [4216.406, 4230.506], [4230.506, 4242.256], [4242.256, 4256.506], [4256.506, 4267.59], [4267.59, 4279.366], [4279.366, 4292.055], [4292.055, 4302.616], [4302.616, 4315.856], [4315.856, 4328.166], [4328.166, 4342.476000000001], [4342.476000000001, 4354.476000000001], [4354.476000000001, 4367.7660000000005], [4367.7660000000005, 4377.845], [4377.845, 4393.406], [4393.406, 4406.286], [4406.286, 4421.836], [4421.836, 4434.709], [4434.709, 4447.366], [4447.366, 4461.965], [4461.965, 4472.885], [4472.885, 4484.045], [4484.045, 4496.106], [4496.106, 4508.045], [4508.045, 4519.385], [4519.385, 4526.737]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [785, 1392, 2539, 3126, 4533]}
{"example_id": "mit075@@MIT14_01SCF10_lec03_300k", "text": ["PROFESSOR: So today what we're going to do is continue our  discussion of supply and demand.  This is sort of introduction week, if you will.  We've kind of talked about supply and demand, and you ", "guys, rightly, immediately were on to where do those  curves come from.  And that's what we'll start next week.  But what I want to do today is talk some more about what  determines the shapes of supply and demand curves and ", "just think about an overview of how we think about supply  and demand interacting in a market and what determines how  responsive individuals and firms are to prices. ", " And, once again, remember everyone should have a handout  that you should have picked up in the back on your way in.  So everyone should have a handout.  What we talked about last time was the sort of qualitative ", "effects, the qualitative version of the supply and  demand model.  We talked about what happens when a supply curve shifts,  what happens when a demand curve shifts.  We talked about how either a supply shock or a demand shock ", "could lead to the price being increased.  But they could have very different effects on  quantity, et cetera.  What we didn't talk about is how big these effects are.  I made up some numbers.  I threw them on the graphs.  But I didn't talk about where the size of those ", "effects come from.  And where they come from is the shapes of the supply and  demand curve.  And that's what we'll talk about today is what determines  the shapes of supply and demand curves. ", "And that will be the focus of today's lecture.  I'll talk both theoretically about what determines these  shapes and empirically about how economists go about  figuring out the shapes of supply and demand curves. ", "So, to think about this, let's start with Figure 3-1, which  is a standard market diagram we had last time.  With an initial equilibrium at point E1, with an initial ", "price P1 and a quantity Q1.  That's the equilibrium that's stable.  Because at that price P1, consumers demand Q1 units, and ", "suppliers are willing to provide Q1 units.  So that's a stable equilibrium.  Now we have some supply shift.  Last time we talked about somehow a  pork-specific drought.  ", "That leads the supply to shift inward.  So the supply curve rises to S2.  At that new price, initially, you would have excess demand. ", "But quickly the price increases to shut off that  excess demand.  And you end up with a new equilibrium with a higher  price, P2, and a lower quantity Q2, and new  equilibrium point E2. ", "OK?  And we talked that through last time.  What I want to talk about this time is well, what determines  the size of that shift from Q1 to Q2 and that price increase  from P1 to P2? ", "What's going to determine it is the elasticity of supply  and demand. ", "The elasticity of supply and demand is how much do supply  and demand respond?  Do the quantities supplied and the quantities demanded  respond when the price changes? ", "When we say, how elastic is demand, what we mean is how  sensitive to price is the quantity demanded.  Or, alternatively, what is the slope of that demand curve? ", "So the slope of the demand curve will be the sensitivity  of quantity demanded to the price consumers face.  And that will determine the market responsiveness. ", "In economics, it's always true that the best way to think  about things is to go to extremes.  You have to remember that extremes don't exist in the  real world.  But it's a useful teaching device ", "to think about extremes.  So let's think about one extreme case in Figure 3-2.  Let's think about the case of perfectly inelastic demand.  Perfectly inelastic demand, that's where there's no ", "elasticity of demand.  What that means is that demand for a good is unchanged  regardless of the price.  So perfectly inelastic demand is a case where demand for the ", "good is unchanged regardless of the price.  That would lead you to have a vertical demand curve at a  given quantity.  What this says is regardless of the price, people always  demand Q. ", "Can anyone tell me what would cause demand to  be perfectly inelastic?  In what types of situations would demand be--  it's never perfectly inelastic-- ", "would demand be relatively inelastic?  Yeah?  AUDIENCE: [INAUDIBLE PHRASE].  PROFESSOR: It's all about substitutes.  When there's no substitutes, when there's nowhere to go, it ", "doesn't matter what the price is.  When there's no substitutes, demand will be perfectly  inelastic, because you have to have Q. It doesn't matter what  the price is. ", "Because there's no substitute for that good.  So if you wanted amount Q of that good for any reason,  you're always going to want that amount Q  no matter the price.  So a perfectly inelastic good would have no substitutes. ", "So you'd always want Q no matter what.  Can anyone think of an example?  There's no perfectly inelastic good in the world.  But what sorts of goods?  Yeah?  AUDIENCE: Medicines.  PROFESSOR: Medicines.  Now, not necessarily all medicines. ", "So give me an example of a medicine which would be more  or less inelastic.   So I don't even need a medical name. ", "What sort of treatments?  AUDIENCE: Like heart attack maybe?  PROFESSOR: Yeah, something which is sort of lifesaving.  The best thing that we often use is insulin for diabetics.  Diabetics without getting that insulin to manage their ", "diabetes will die.  That seems like that's something where there's not a  whole lot of substitutes.  The substitute is dying.  So basically that's where demand  is relatively inelastic.  Or a heart transplant, when you get a heart transplant or ", "any kind of transplant, you have medicine you take so you  don't reject the transplanted organ.  That sort of medicine demand should be very inelastic.  Elastic drug, well, our favorite  example is always Viagra. ", "It's something where you'd think that you can probably  survive without it.   And people would want less Viagra if you charged a lot  more for it than if you charged less for it. ", "So elasticity is going to be about substitutability.  And that's going to determine inelastic demand.  Now, what happens with inelastic demand when there's ", "a supply shock?  When supply increases, what happens?  Well, in that case, there can never be excess demand,  because demand doesn't change. ", "So all that happens is price just increases.  If there's inelastic demand, and there's a supply shock,  then all that happens is an increase in price and no ", "change in quantity.  So with inelastic demand, quantity doesn't change for a  price increase.  Price just goes up.  From a supply shock, prices just goes up. ", "Now, let's consider the opposite.  Let's look at Figure 3-3 and think about  perfectly elastic demand.   Perfectly elastic demand is demand where consumers, ", "essentially, don't care about the quantity.  They just care about the price.  That is, there are infinitely good substitutes.  A perfectly elastically demanded good would be one ", "where there are, essentially, perfect substitutes.  An inelastic good is where there's no substitute.  A perfectly elastic good would be where there's perfect  substitutes.  Technically, if a good is perfectly elastically ", "demanded, then you are completely indifferent between  that good and a substitute.  Well, if you're completely indifferent, then if the price ", "changed at all, you would immediately switch.  And so the price can't change.  What's an example?  Once again, there's no good example of a ", "perfectly elastic good.  Yeah?  AUDIENCE: Candy.  PROFESSOR: What?  AUDIENCE: Candy.  PROFESSOR: Candy.  OK.  So you've got your Wrigley's gum.  I like the sugar-free, minty gum.  You've got Orbit and Eclipse. ", "And I go to the store, and they're all pretty much the  same price.  If Orbit was more than Eclipse, I just buy Eclipse.  They're the same.  They're minty gum.  It doesn't make a difference.  So basically the price is the same. ", " If there's a supply shock, I don't know, they're made with  the same shit.  But let's say that Eclipse has some magic ingredient.  And let's say the Eclipse magic ingredient got more ", "expensive, so the supply curve shifted up.  Well, Eclipse could not respond by raising its price.  Because I just switched to Orbit.  Or we often think of McDonald's and Burger King. ", "Now, they're less perfect  substitutes, but pretty perfect.  If McDonald's started charging $10 for a hamburger, you  wouldn't go there anymore.  You'd go to Burger King.  ", "So if there's a supply shock to a provider that's facing a  perfectly elastic demand curve, they cannot raise their  price, because people will just switch. ", "So quantity will fall a lot.  Because if I'm supplying Eclipse gum, and it suddenly  costs a lot more to produce Eclipse gum, but I can't raise  my price, because I will lose all my business to Orbit, I'm ", "just going to produce a lot less Eclipse.  Because I'm losing money now.  So with perfectly inelastic demand, the  quantity didn't change.  With perfectly elastic demand, we saw a big quantity change. ", "So, more generally, what determines the quantity change  in response to a price change is the elasticity.  More generally, we're between these two cases of perfectly ", "elastic and perfectly inelastic.  And what's going to determine the price change is going to  be the price elasticity of demand epsilon which is going ", "to be the percentage change in quantity for each percentage  change in price or, in calculus terms, dQ/dP. ", " So it's, basically, the percentage change in quantity  for the percentage change in price.  So, for example, if for every 1% increase in price quantity ", "falls 2%, that is a price elasticity of  demand of minus 2.  The price elasticity of demand is the percentage change in ", "quantity for the percentage change in price.  So inelastic demand is an epsilon of 0. ", "There is no change in quantity when price changes.  Perfectly elastic demand is an epsilon of negative infinity.  Any epsilon change in price leads to a negative infinite ", "change in quantity.  Immediately, the quantity goes to 0 if you try  to raise your price.  So the price elasticity of demand will typically be  between 0 and negative infinity.  And the larger it is the more quantity will change when ", "prices change.   Questions about that?  Yeah?  AUDIENCE: So that formula, shouldn't it be dQ/dP times ", "P/Q because dQ/dP just refers to the change of the quantity  with respect to price, not  necessarily the percent change.  ", "PROFESSOR: Yeah, you're right.  I was trying to get too fancy with my calculus.  You're right.  Let's just stick with the non-calculus formula.  I never should deviate from my notes.  So let's just stick with the non-calculus formula. ", "OK, other questions about this?  OK.  So, basically, that's the elasticity.  That's going to be the elasticity. ", "Now, an interesting point about elasticity is now, we're  not going to get into producer theory  for a couple of lectures.  But as a little peek ahead about producer theory, let's  think about how elasticity determines the money that ", "producers make from selling their goods.  Well, if a producer sells Q goods at a price P, they make  revenues R. Revenues are the price times the quantity. ", "The amount of money a producer makes when it sells goods, its  revenues, this isn't its profits.  We're not having profits.  It's just the amount of money it makes, not the amount of ", "money it takes home at the end of the day.  I'm ignoring the cost of making the goods.  The amount of total revenues it makes  is price times quantity.  Well, we can then say that the change in revenues with ", "respect to price is what?  It's Q plus dQ, plus delta Q-- let me put it this way to make ", "my math clearer--  plus P times delta Q over delta P. That's how revenues  change with respect to price. ", "Or, in other words, plugging in from the elasticity  formula, delta R over delta P equals Q times 1 plus epsilon. ", " So, in other words, what this says is that if you're a  producer, and you're trying to decide whether to raise your ", "price, whether that will increase revenues, it all  depends on the elasticity.  If the elasticity is between 0 and minus 1, then raising ", "prices will raise revenues.  If the elasticity is greater than minus 1, then raising  prices will lower revenues. ", "We're often faced with the issue of why did they charge  this much for this good, or should they raise their prices  or not raise their price.  Well, that's all about the elasticity of demand.  The elasticity of demand will determine whether they're ", "going to make more money by raising their price or lose  money by raising their price.  For Eclipse gum, their elasticity of demand is well  above minus 1 in absolute value, so they're going to  lose money by raising their price. ", "If they take the current level of Eclipse, for every penny  they raise, they'll lose money.  For insulin, for every penny they raise,  they'll make money.  And then you might say well, then how come the price of ", "insulin isn't infinity and the price of  Eclipse gum isn't zero?  Well, that's what we'll talk about in a few weeks.  Because it also depends on the costs of producing it.  But at the end of the day, that's what's going to ", "determine the money that's made by producers when they  change their prices.  Questions about that?   OK.  So now, that's how we think about the shape ", "of supply and demand.  The shape of supply and demand is determined by these  elasticities.  So now we have to get into OK, well, where do we get these  elasticities from? ", "And that is the main topic of empirical economics which is ", "estimating these kinds of elasticities, estimating these  types of elasticities.  ", "So one of the first distinctions I drew in the  lectures is between theoretical economics and  empirical economics.  Theoretical economics can tell us this is what a graph looks ", "like and supply and demand.   Theoretical economics can't really tell us how big, for  example, an elasticity is going to be.  It can tell us, there's more substitutes or less ", "substitutes so we can rank them.  We know the elasticity for Eclipse gum has got to be  higher than the elasticity for insulin.  But from the theoretical model, we can't say what the ", "elasticity actually is.  To say what an elasticity actually is, we need to go to  an empirical model.  We actually need to bring data to bear on the question.  And this is very difficult. ", "Because here we face the fundamental conundrum facing  the empirical economist which is distinguishing causation  from correlation.  ", "And the whole guts of empirical economics is all  about this question, distinguishing causation from  correlation.  ", "The classic story that illustrates this, it's due to  my colleague, Frank Fisher, from a textbook many years  ago, was the story of in ancient Russia there was a  cholera outbreak, and many people were dying. ", "So the government decided to send doctors out to try to  solve the problem.  And where there were more people sick,  they sent more doctors.  Well, the peasants said, wait a second. ", "We observe that where there's more doctors, more people are  dying from cholera.  So the doctors must be causing the cholera.  So they rose up and killed the doctors. ", "The peasants confused causation with correlation.  They thought that the fact that you saw more people dying  where there's more doctors meant that doctors were  causing the disease.  Clearly that's wrong. ", "That's why they were peasants.   But it's not just peasants that make this mistake.   For example, in 1988, Harvard University, our illustrious ", "neighbor to the south, I guess, west,  east, I don't know.  Which way is Harvard?  I don't know directions, down the street.   A Harvard University dean conducted an interview with a  set of freshmen. ", "And they found that those that had taken  SAT preparation courses--  now, you all took SAT preparation courses.  But in 1988, not everyone did.  Those who'd taken SAT preparation courses scored an ", "average of 63 points lower--  this was back when the SAT was 1600 points--  63 points lower on their SATs then those that had not taken  preparation courses. ", "The dean concluded that preparation courses were  unhelpful, and that the testing industry was preying  on the insecurities of students to  provide a useless service. ", "Why was the dean confusing causation with correlation?  What did the dean get wrong in drawing that conclusion?  Yeah?  AUDIENCE: What had probably happened is the students who ", "got worse scores realized that they wanted to try and improve  their scores by taking an SAT prep class.  So that's why there is a lower average score for the people  who had taken the class.  PROFESSOR: Generally, the people who needed the help the ", "most took the most courses.  And so they had an underlying lower score.  So, in fact, you can't tell anything from the fact that  the people who took the prep course scored worse. ", " It's just another excellent example of confusing causation  with correlation. ", "And that's another example.  Another example I like quite a lot is studies of  breastfeeding.  There are numbers of studies of breastfeeding, especially ", "in developing countries, where they found that the longer  children were breastfed the sicker they were.  So they concluded that  breastfeeding was bad for kids. ", "Well, that's not the truth.  The truth is the sicker kids need to be breastfed more,  because breastfeeding is actually good for kids.  And they just confused the causation with the ", "correlation.  Now, these are all fun examples.  But the truth is this is a common mistake made by  citizens, policy makers, everyone in the real world. ", "It's taking two things that move together and assuming one  causes the other.  And this is the fundamental conundrum facing empirical  economics in trying to address these kinds of things like ", "measuring elasticities.  So to understand that, let's think about the issue of  trying to estimate the elasticity of demand for pork. ", "Let's say you have the exciting job of estimating the  elasticity of demand for pork.  That's your assignment.  Well, you say, wait a second. ", "What we learned in class, as shown in Figure 3-4, is that  the price of pork can rise for very different reasons. ", "Figure 3-4, we start at an initial equilibrium like E1  with a quantity like Q1 and a price P1.  ", "Now, imagine that there was a shift in demand, because the  price of beef rose, remember?  The price of beef rose.  That shifted demand from D1 to D2. ", "What did that lead to?  A higher price and a higher quantity.  So if you took that diagram--  forget the supply shift for a minute, just imagine that's ", "the change--  and you said, aha.  I can measure the elasticity.  I see here there's a change in price.  I can then look at how quantity changed. ", "And I'll get the elasticity right after all.  It's delta Q over Q or delta P over P.  So I just look, and I take Q2 prime minus Q1 over Q1.  That's the percentage change in Q. I take P2 ", "over P1 over P1.  That's the percentage change in price.  And what do I get?  A wrong signed elasticity is what I get.  I get a positive elasticity, because Q is going up  and P is going up. ", "Why?  Because I'm confusing causation with correlation.  It's not the price change that caused quantity to change. ", "In fact, it's the opposite.  It's a taste shift, which caused quantity to increase  which drove up the price.  It was a demand increase which caused the quantity demanded ", "to increase which drove up the price.  So it's the quantity driving the price, not the price  driving the quantity.  So if you looked at that simple example, as many people  in the real world do, they'd say, hey, look.  Higher prices cause higher quantities. ", "You're getting the wrong answer.  Because you're confusing correlation which is the  higher price is correlated with the higher quantity.  Because there was a common factor causing both of them  which is the demand shift and not causation. ", "The higher price did not cause the higher quantity.   What do we need to do?  We need to distinguish why the price increased. ", "We need to distinguish why the price  increased to measure this.  If, instead, we looked at a shift in supply such as the ", "case that's shifting from S1 to S2 and moving the  equilibrium from E1 to E2, then you would  get the right answer.  Because then you'd say, look.  Something independent to consumers ", "shifted up the price.  Some shock to the supply of pork shifted up the price.  And we saw that their quantity fell as a result.   What's the key? ", "The key is that to measure an elasticity of demand, you're  measuring the slope of the demand curve.  So you need to shift along a demand curve, not shift the ", "demand curve itself.  So if you look at this figure, what's the concept we want?  We want the slope of the demand curve.  Well, you get that by shifting from E1 to E2, because you ", "shift along the demand curve.  So by looking at what happens to quantity as price rises  from E1 to E2, you get the slope of the demand curve.  You get that delta Q over delta P you want. ", "But from E1 to E2 prime, you're not shifting along the  demand curve.  You're actually measuring the elasticity of supply.  You're measuring the elasticity of supply.  You're shifting along a supply curve. ", "So you're actually answering a different question, a relevant  question, but a different one.  That question is, what's the elasticity of supply?  How willing are pork producers to supply pork as ", "the price goes up?  So it's the same delta Q over delta P. But here we did the  elasticity of demand.  There's a corresponding elasticity of supply which is ", "measured the same way.  It's delta Q over delta P, but it's for a  different kind of shock.  It's what you get from moving along the supply curve.  So if we went from E1 to E2 prime, we can use that to ", "measure the elasticity of supply or the slope of the  supply curve.  And we do that if something shifts demand to move us along  the supply curve.  From E1 to E2, we measure the elasticity of demand as ", "something shifts supply and moves us  along the demand curve.  So what we need to measure the elasticity of demand is  something which shifts supply but does not, ", "itself, affect demand.  And the best example of this that we use in economics, a  great example, is government policy which comes along and ", "changes the supply conditions for a good.  So, for example, let's think about a tax on pork.  So if you go to Figure 3-5, imagine the government came ", "along and taxed pork.   The government comes along and taxes pork.  Let's think about what a tax on pork does. ", "The government comes along, and let's say the pork market  is initially in equilibrium at $3.30 with 220 million  kilograms of pork sold. ", "Now the government comes along and says that it's going to  charge $1.05 in tax for every kilogram of pork. ", "So it's going to impose a tax of $1.05  per kilogram on producers.  So it's saying to producers of pork, for every kilogram of  pork you sell, you have to send a check to the ", "government for $1.05.  For every kilogram of pork you sell, you have to send a check  to the government for $1.05.  Now, somebody talk me through how a supplier ", "thinks through that.  How does a supplier react to that?  What do they think?  They're initially happy at E1 selling 220 million  kilograms at $3.30. ", "What happens when the government comes in and says  you have to pay $1.05 for every  kilogram of pork you sell?  What happens?  Yeah. ", "AUDIENCE: The producer decides that the current amount of  money they have will not be able to buy as much inputs to  create their products.  So they can produce less.  PROFESSOR: Exactly.  So, in other words, the cost of producing just rose. ", "So what do they do?  So, in other words, what they say is look, effectively, if I  was happy before selling 220 million kilograms at $3.30, to ", "keep me equally happy selling 220 million kilograms, I'm  going to have to raise the price.  We should add this to graph, actually.  If you draw a vertical line up for me, one to the S2 curve. ", "Draw a little dashed line up from the E1 to the S2 curve  and then over.  That price intersection will be $4.35.  So in other words, if you want me to keep producing 220 ", "million kilograms of pork, I'm going to have  to get $4.35 a kilogram.  And you might say, what gives you the right to get that?  And it's not about rights.  It's about what producers are willing to do. ", "That same mathematics, that same supply curve that tells  us they're willing to sell 220 million kilograms at $3.30  says, if you want them to keep selling 220 million kilograms ", "but also pay $1.05 to the government, they're going to  have to get $4.35 a kilogram.  So what happens is that's a supply shift.  And with the same reaction we saw last time with the ", "drought, the price goes up, consumers demand less, and you  reach a new equilibrium at the price E2.  You reach a new equilibrium where you sell 206 million ", "kilograms for a price of $4.00.  So someone tell me how I use this example to find  elasticity of demand. ", "Yeah.  AUDIENCE: I guess you need to know that the change in price  traveled along the demand curve.  So you know that it's not [INAUDIBLE PHRASE].  ", "PROFESSOR: OK, so tell me.  You don't have to do the math in your head.  But how would I compute it?  AUDIENCE: You would take E1 and E2, and then you would do  the price over the quantity change.  PROFESSOR: Right, exactly. ", "So the quantity change delta Q over Q, is what?   It's minus 14 over 220. ", "It fell by 14 million kilograms over 220.  The price change, delta P over P, the price rose ", "from $3.30 to $4.00.  So the price change is $0.70 over $3.30.  And using those, you end up with a price ", "elasticity of minus 0.3.  Or, in other words, there's a 6.4% change in quantity. ", "This is minus 6.4% for a 21% change in price.  So quantity falls by 6.4% when price goes up by 21%. ", "That's a price elasticity of minus 0.3.  Or that's a relatively inelastic demand.  It's not perfectly inelastic, but it's relatively inelastic.  In other words, at that point, pork producers could make ", "money by raising the price.  Now, you might say well, why didn't they?  That's something we'll discuss in a couple weeks.  But at that point, demand is relatively inelastic. ", "And you've got a convincing estimate, because you moved  along that demand curve.  You used the supply shift.  Now, we're going to talk about taxation much, much later in  the semester. ", "Let me just talk for one minute about what we learned  from this graph.  What happens?  Well, the shaded area is the money the government raises  from its tax.  The government has a tax of $1.05 at 206 million ", "kilograms. So it raises $1.05 times 206 million kilograms  which is that shaded area.  There are two points to note the we'll come back to later  in the semester.  The first point to note is the amount of money the government ", "raises will depend directly on the elasticity of demand.  Can anyone tell me how much money the government would  raise if you had a perfectly inelastic demand? ", " Yeah.  AUDIENCE: [INAUDIBLE PHRASE].   PROFESSOR: Right. ", "If we think about this demand curve being perfectly flat, if  we think about this demand curve being perfectly flat,  then basically the producer can't charge any more for ", "their good.  So it's going to depend on whether the producer is  willing to sell at $1.05 less and how much less they're  willing to sell. ", "If they're willing to sell a lot less, they're going to  make a lot less money.  It's going to be where that second supply curve intersects  a flat demand curve.  So that quantity is going to be a lot smaller. ", "We don't have it on the diagram.  But you see where that dashed line at $3.30 intersects S2,  that's way to the left.  Quantity is going to fall a ton in this market. ", "When quantity falls, the government is going to raise a  lot less money.  Because the government raises $1.05 on every  unit sold at the end.  So if the government taxes very elastically demanded ", "goods, it's going to raise less money.  If it taxes inelastically demanded goods like insulin,  it's going to raise more money, because the quantity  doesn't change.  Yeah.  AUDIENCE: So cigarettes are relatively inelastic. ", "PROFESSOR: Yes, exactly.  Cigarettes are relatively inelastic.  The elasticity is around minus 0.5.  So the government will actually raise money by  raising the cigarette tax. ", " Those of us, as good liberals, think we should tax yachts.  Let's tax yachts.  Only rich guy have yachts. ", "The problem is yachts are  incredibly elastically demanded.  So you raise a lot less money taxing yachts than you think.  Because guys buy fewer yachts, and you don't raise as much ", "money as you think you would.  You still raise some, and it still may be worth it.  But you raise less than you think.  So that's one sort of observation about this. ", "It's basically how much money you'll raise will be a  function of how elastic the demand is.  The other important observation to make is why ", "it's actually hard for governments to figure out how  much money they're going to raise for a tax.  Because, to figure it out, they need to know these  elasticities.  That is, the naive thing to do would have been to say what? ", "Well, we're selling 220 million kilograms of pork.  That's $1.05.  We're going to tax each kilogram.  So that's 220 million times $1.05.  And that's how much money we raise.  Well, that's wrong, we know, because that ", "assumes inelastic demand.  If demand's elastic, they'll raise less than that.  Well, if we want to figure out how much a government is going  to raise from a tax, they've got to know what these  elasticities are.  And those are actually pretty hard things to know. ", "So that's why there's uncertainty.  That's why when politicians will say, this tax will raise  x and you'll hear the New York Times report, the tax will  raise x, that is a guess. ", "Those are guesses, because they depend on our best  estimate of the key elasticities that determine  how people respond.  Yeah.  AUDIENCE: But in Washington you have tax  cuts that raise money.  PROFESSOR: Well, some claim you do. ", "You don't actually.  But some claim you have tax cuts that raise money.  That's because they think the elasticity is very large.  If the elasticity is large enough, a tax  cut can raise money. ", "So, basically, that's all about that some people think  that elasticities are large enough that tax  cuts can raise money.  Those people are wrong.  But that's what they claim. ", "Yeah.  AUDIENCE: [INAUDIBLE PHRASE].   PROFESSOR: Yes.  Excellent point.  You'll go through that in section on Friday.  So what I've done is I've done an example of a constant ", "elasticity curve.  Actually, I've done something here which is logically  inconsistent.  This curve is linear which means it can't be constant  elasticity.  If it's constant elasticity, it would have to curve. ", "So what I've estimated here is a local elasticity.  I have estimated the elasticity  around that price change.  But the elasticity, if this curve is true, would be ", "different at different points on this curve.  If the elasticity is going to be constant all over the  curve, and you're going to do a constant elasticity of  demand, that's going to be a curve that bends, ", "not a linear curve.  So a linear demand curve is not constant  elasticity of demand.  We will typically ignore that issue and focus on local  elasticities.  But that is an important issue.  We'll discuss that in section on Friday, the difference ", "between constant elasticity of demand curves and linear  demand curves.  But, typically, we're think about local changes.  So if it's local enough, it doesn't really matter.  But, for a broad change, it will matter what the shape of ", "the curve is.  Good point.  Other questions?  OK.  Let me then turn to another problem we face  in empirical economics. ", "So this is an example of a problem we're facing in  empirical economics.  Let me turn to an example of another problem we face in  empirical economics estimating elasticities.  It is that individuals often choose the price they face. ", " Individuals, typically, often don't just face a price that's  given to them.  And then you can say, OK, they're given a price, and we  see how they respond.  They often choose the price they face. ", "Let me explain what I mean by that.  A classic example of an elasticity that matters a lot  for policies is the elasticity of demand for medical care,  the elasticity of demand for medical care. ", "That is how much less medical care will you use if you have  to pay for it?  So, for example, most of us have insurance through MIT or  maybe through our parents.  And the way health insurance works is you pay a certain ", "amount per month or your parents do, and, in return,  that health insurance covers the cost of your medical care,  most of it.  But, typically, you have to pay some of it. ", "So how many people have gone to the doctor in  the last six months?  Did you have to pay something?  How much did you pay?  Did you pay a copayment?  No?  None of you? ", "Yeah.  How much did you pay?  AUDIENCE: I think like $20.  PROFESSOR: $20, $10, $5, that's what's called the  copayment, or $0.  Most insurance these days has what's called copayments. ", "A copayment is what you pay when you go to the doctor.  Insurance picks up the rest. You don't know.  You didn't know how much the whole doctor visit cost. You  just went, you gave them your card.  They said your copayment is $20.  You gave them $20.  You don't know. ", "The visit might have cost $100, $200, $500, $1,000.  You don't know.  Your insurer picks up the rest. You pay the copayment.  Copayments are rapidly on the rise in health insurance. ", "There's a rapid rise in copayments.  Increasingly, insurers are saying, look, health care  costs are out of control.  One way we're going to combat them is by making people bear  more of the cost that they use. ", "I could go on forever about how I'm a health care  economist. I could go on about health care forever.  But just to fix ideas on why this is an issue, in 1950, the  US economy spent 5% of our gross domestic product, 5% of ", "our size of the economy went to health care.  Today it's 17%.  By 2075, it's projected to be 40%.  That is of every dollar that's made in America, $0.40 will go ", "to medical care.  By 100 years later, it's about 100%.  Literally, if we do nothing, the entire economy will be  health care.  Obviously, that can't happen.  We've got to deal with this. ", "And one way that insurers and some policy makers are saying  we need to deal with this is we need to make consumers bear  more of the costs of their medical care.  We need to make consumers pay more when they go to the  doctor, so that they understand the consequences of ", "their decision.  Well, if we're going to do that, a key question we need  to know is well, does it affect their behavior?  If we make consumers pay more, and it doesn't at all affect ", "their demand for medical care-- it's just a tax on  them, essentially--  then that's different than if it causes them to use less  medical care.  It may be good, may be bad.  We'll come back to that. ", "But the key empirical question is what is the elasticity of  demand for medical care?  If you pay $20 and you pay $0, how much less like are you to  use the doctor when you pay $20 versus when you pay $0. ", "Well, we can all introspect this and think about it.  But, in fact, to answer this we have to go to the data and  ask, well, what's the difference?  So people, for many years, went to the data. ", "And they said, look, there's all sorts of differences out  there across people and what they pay for their copayments.  Some people have insurance where they pay nothing, some  where they have $20.  Some people have what they call high-deductible plans. ", "A deductible plan is where you pay the full cost of your  visits until you reach some limit.  So a $2000 deductible plan will be one where you pay all  of your medical costs until you've spent $2,000. ", "It's a big copayment.  So we look across those people, and people did.  And they found, look, the people that have plans where  they spend more for health care, where they have a high  copayment, use a lot less health care than where they ", "don't have to spend anything.  The elasticity of demand looks very, very high.  What is wrong with those studies?  What is wrong with the conclusion those people drew? ", "They drew it by comparing people who had plans where  they paid a lot to go to the doctor, and therefore use a  lot less care to people who didn't pay anything when they  went to the doctor and used a lot more care. ", "I pick the $20 person, because I picked on you already.  AUDIENCE: Probably they chose to have a high-deductible  plan, because they don't often go to the doctor already. ", "PROFESSOR: The rational choice, if you're young and  healthy, for almost everyone in this room, is going to be a  very high-deductible, high copayment plan.  Because it will cost you less money, because the insurer is ", "shifting the money to you.  But you don't use the doctor anyway.  So who cares?  So the healthier people are going to choose the plans  where they pay more.  So, of course, you're going to find in the plans where people ", "pay more they use less medical care.  But is it because they're paying more, or is it because  healthy guys choose those plans? ", "It's causation versus correlation.  We don't know.  Well, how can we figure that out?  Well, if we were doctors, what we'd do-- real doctors, not a ", "doctor like me, a real doctor, a medical doctor--  what we'd do is we'd run a randomized trial.  So if doctors want to figure out whether a drug works or ", "not, they don't just look at guys who take the drug versus  guys who don't.  They run a randomized trial.  They randomly assign some people to take the drug and ", "some people not.  Now, when you run a randomized trial, by definition, you get  a causal effect.  Well, this room isn't quite big enough. ", "We all know the law of large numbers.  But imagine there were four times as many people in this  room or five times as many people in this room.  OK?  And I had you come up to the front.  I flipped a coin and said half of you are going to take the ", "drug, and half of you are not, randomly by  the flip of a coin.  Then, by definition, any statistically noticeable  differences I get between the group the takes the drug and ", "the group that doesn't is caused by the drug.  And how do I know that?  Because I know the groups are otherwise identical by the law  of large numbers.  By the law of large numbers, I know that as long as I have  enough people, they're identical. ", "So if the only difference between them is that one's  taking the drug and one's not, that's a randomized trial.  That would be how I could solve the causation versus  correlation problem.  In medicine, thousands of randomized trials every day ", "are being run.  In fact, the FDA, before it will approve a drug, will  typically require a randomized trial.  Well, in the social sciences, it's harder to  run randomized trials.  Because we're actually trying to understand things like ", "people's demand for medical care, not whether a  drug works or not.  But, in fact, one of the most famous social randomized  trials in history was called the RAND Health Insurance  Experiment run in the 1970s. ", "This is where some innovative health economists who  understood this problem that we laid out about the fact  that you can't just compare more or less generous health  insurance policies, actually randomized health insurance  policies across people. ", "They recruited volunteers, and they literally said, we're  going to randomize.  Some people are going to have policies where the health care  is free, and some people are going to have policies where ", "they have to pay, essentially, all the costs of health care.  So they, essentially, randomized across these  different groups.  And, therefore, they can assess what the price ", "elasticity was.  Because they knew the price difference between groups.  For one, the price was zero.  For one, the price was one.  They actually had a range of prices they varied it across.  They could look at the quantity response, and they ", "knew that was a quantity response to the price, because  people weren't choosing their prices.  The prices were being assigned to them.  What did they find?  Well, they found that medical demand is elastic, although ", "not as elastic as the previous study.  It's somewhat elastic.  It's not as elastic as the previous studies found.  They found that the elasticity of demand for medical care is  around minus 0.2. ", "So when the price goes up, people use less medical care  but not that much less.  Now, let's be clear.  Remember what elasticity is.  That delta Q over Q. The same study showed that if you take ", "someone who paid nothing and make them pay almost  everything, their utilization of medical care falls by 45%.  That's consistent with that small elasticity. ", "Because that's a huge delta P, percent delta P. So,  basically, that's comes to the question about local versus  global elasticities.  So it's not saying that prices don't matter. ", "But it's not a very, very elastically demanded good.  So that's how they measure that price of  elasticity of demand.   That experiment, which was run over 35 years ago now, that ", "result drives much of what we do in health policy.  So a lot of the estimates that we saw for the recently passed  health reform bill derived from how  do we get that estimate. ", "We'll have to figure out how people are going to respond  with their medical care when we give them health insurance.  The recently passed health care bill just gave 32 million  people health insurance.  Well, how are they going to respond to ", "having health insurance?  We go back to the RAND estimates and say, well, we  have this elasticity of demand.  We know what we're doing to the price.  We figure out how much medical care is going to go up. ", "But here's the other thing.  Here's the question in the lecture that  that we'll close with.  Is that a good thing or a bad thing that medical care fell  when the price went up?  And how would we tell whether it's a good ", "thing or a bad thing?  So we know when we raise the price, people use  less medical care.  How can we tell if that's a good thing or a bad thing?  In the same experiment, how could we tell?  What could we do? ", "Yeah.  AUDIENCE: Maybe you'll get death rates or like--  PROFESSOR: You look at their health.  You say, look, the same trial can  answer a different question.  We know that when you charge someone for health ", "care, they use less.  Well, are they sicker?  The answer, not at all.  People use less health and were no sicker.  Why? ", "Because we waste a huge amount of health care in the US.  A huge amount of health care is wasted.  So, in fact, we could cut back quite a lot on health care,  and we'd be no sicker. ", "And that's what the RAND experiment showed, that we can  charge people to use medical providers.  And they'll use less medical care, and they won't be sicker  as a result.  Which suggests that, actually, as we try to think about ", "getting our health care costs under control in America,  making people pay something to go to the doctor is not a  crazy thing to be thinking about.  How much?  Well that depends on efficiency versus equity.  We can't make someone who has no income pay $1,000 to go to ", "the doctor.  That, clearly, is a mistake.  But we can take a rich guy like me and make me pay $50 to  go to the doctor.  There's no reason not to do that. ", "So, basically, that's a lesson of how you can use elasticity  of demand to help inform the kind of  policies we need to make.  OK, let me stop there.  By the way, if you at all find this stuff interesting, and ", "you haven't yet read Freakonomics--  how many of you have read Freakonomics?  That's amazing.  OK.  If you haven't read Freakonomics, you should.  It's a great book.  If you're lazy, the movie is coming out.  And Freakonomics the movie is premiering on ", "Friday the 30th at LSC.  So if you're interested in learning more about empirical  tools in economics, you can watch Freakonomics the movie  on Friday the 30th.  "], "vid_duration": [11.45, 10.94, 10.33, 11.21, 10.93, 11.75, 11.89, 12.49, 13.17, 10.12, 12.03, 11.61, 11.01, 11.11, 11.12, 12.7, 13.33, 11.85, 10.03, 12.02, 10.79, 12.55, 10.34, 10.39, 10.74, 11.75, 11.94, 11.04, 10.62, 12.15, 12.14, 11.18, 10.0, 11.32, 11.59, 10.36, 15.4, 10.225, 12.365, 11.42, 12.15, 11.725, 11.12, 10.615, 11.419, 10.131, 10.6, 13.18, 13.1, 10.32, 11.61, 12.628, 13.622, 10.59, 10.05, 12.14, 12.94, 11.69, 11.036, 10.914, 10.72, 12.22, 14.36, 11.01, 10.57, 10.74, 10.24, 13.125, 11.535, 10.65, 10.75, 12.81, 10.23, 11.16, 10.79, 13.99, 10.98, 12.01, 11.25, 12.04, 11.24, 11.22, 11.22, 12.56, 10.4, 13.59, 11.8, 10.0, 10.12, 12.759, 11.751, 13.49, 11.31, 12.18, 10.24, 11.75, 11.015, 10.545, 11.41, 12.78, 10.78, 10.56, 11.13, 11.14, 10.46, 12.81, 12.09, 10.24, 10.98, 10.55, 12.21, 12.44, 10.99, 12.54, 12.09, 13.07, 10.82, 12.92, 12.25, 11.0, 10.22, 12.92, 10.355, 11.935, 13.04, 11.42, 13.44, 14.31, 12.63, 11.73, 11.68, 12.95, 11.12, 10.14, 12.77, 14.25, 11.93, 10.302, 12.268, 14.88, 11.16, 12.27, 12.99, 11.14, 11.6, 13.0, 10.243, 11.832, 10.415, 11.41, 13.03, 15.34, 11.46, 13.56, 12.55, 10.97, 10.85, 14.77, 13.25, 14.8, 10.1, 14.06, 10.17, 10.37, 10.45, 11.49, 12.26, 10.23, 10.97, 10.38, 11.18, 11.71, 10.95, 10.68, 10.214, 12.276, 10.921, 10.809, 11.02, 11.109, 12.731, 11.97, 10.73, 10.71, 11.09, 10.29, 12.54, 11.92, 11.38, 11.98, 12.3, 10.206, 11.024, 10.19, 13.09, 12.66, 13.68, 11.58, 10.01, 11.81, 10.52, 10.09, 13.34, 10.92, 10.06, 11.08, 13.59, 11.32, 12.211, 10.209, 12.81, 10.445, 10.115, 10.97, 11.86, 10.81, 10.38, 10.0, 10.81, 11.73, 13.52, 12.65, 11.6, 10.49, 12.27, 10.93, 10.97, 10.46, 11.01, 13.54, 10.34, 12.23, 13.56, 10.46, 10.09, 10.67, 11.15, 10.38, 10.42, 10.41, 10.3, 10.02, 13.34, 10.4, 10.34, 11.63, 9.79], "stet": [[0, 11.45], [11.45, 22.39], [22.39, 32.72], [32.72, 43.93], [43.93, 54.86], [54.86, 66.61], [66.61, 78.5], [78.5, 90.99], [90.99, 104.16], [104.16, 114.28], [114.28, 126.31], [126.31, 137.92000000000002], [137.92000000000002, 148.93], [148.93, 160.04000000000002], [160.04000000000002, 171.16000000000003], [171.16000000000003, 183.86], [183.86, 197.19000000000003], [197.19000000000003, 209.04000000000002], [209.04000000000002, 219.07000000000002], [219.07000000000002, 231.09000000000003], [231.09000000000003, 241.88000000000002], [241.88000000000002, 254.43000000000004], [254.43000000000004, 264.77000000000004], [264.77000000000004, 275.16], [275.16, 285.90000000000003], [285.90000000000003, 297.65000000000003], [297.65000000000003, 309.59000000000003], [309.59000000000003, 320.63000000000005], [320.63000000000005, 331.25000000000006], [331.25000000000006, 343.40000000000003], [343.40000000000003, 355.54], [355.54, 366.72], [366.72, 376.72], [376.72, 388.04], [388.04, 399.63], [399.63, 409.99], [409.99, 425.39], [425.39, 435.615], [435.615, 447.98], [447.98, 459.40000000000003], [459.40000000000003, 471.55], [471.55, 483.27500000000003], [483.27500000000003, 494.39500000000004], [494.39500000000004, 505.01000000000005], [505.01000000000005, 516.4290000000001], [516.4290000000001, 526.5600000000001], [526.5600000000001, 537.1600000000001], [537.1600000000001, 550.34], [550.34, 563.44], [563.44, 573.7600000000001], [573.7600000000001, 585.3700000000001], [585.3700000000001, 597.9980000000002], [597.9980000000002, 611.6200000000001], [611.6200000000001, 622.2100000000002], [622.2100000000002, 632.2600000000001], [632.2600000000001, 644.4000000000001], [644.4000000000001, 657.3400000000001], [657.3400000000001, 669.0300000000002], [669.0300000000002, 680.0660000000001], [680.0660000000001, 690.9800000000001], [690.9800000000001, 701.7000000000002], [701.7000000000002, 713.9200000000002], [713.9200000000002, 728.2800000000002], [728.2800000000002, 739.2900000000002], [739.2900000000002, 749.8600000000002], [749.8600000000002, 760.6000000000003], [760.6000000000003, 770.8400000000003], [770.8400000000003, 783.9650000000003], [783.9650000000003, 795.5000000000002], [795.5000000000002, 806.1500000000002], [806.1500000000002, 816.9000000000002], [816.9000000000002, 829.7100000000002], [829.7100000000002, 839.9400000000002], [839.9400000000002, 851.1000000000001], [851.1000000000001, 861.8900000000001], [861.8900000000001, 875.8800000000001], [875.8800000000001, 886.8600000000001], [886.8600000000001, 898.8700000000001], [898.8700000000001, 910.1200000000001], [910.1200000000001, 922.1600000000001], [922.1600000000001, 933.4000000000001], [933.4000000000001, 944.6200000000001], [944.6200000000001, 955.8400000000001], [955.8400000000001, 968.4000000000001], [968.4000000000001, 978.8000000000001], [978.8000000000001, 992.3900000000001], [992.3900000000001, 1004.19], [1004.19, 1014.19], [1014.19, 1024.31], [1024.31, 1037.069], [1037.069, 1048.82], [1048.82, 1062.31], [1062.31, 1073.62], [1073.62, 1085.8], [1085.8, 1096.04], [1096.04, 1107.79], [1107.79, 1118.805], [1118.805, 1129.3500000000001], [1129.3500000000001, 1140.7600000000002], [1140.7600000000002, 1153.5400000000002], [1153.5400000000002, 1164.3200000000002], [1164.3200000000002, 1174.88], [1174.88, 1186.0100000000002], [1186.0100000000002, 1197.1500000000003], [1197.1500000000003, 1207.6100000000004], [1207.6100000000004, 1220.4200000000003], [1220.4200000000003, 1232.5100000000002], [1232.5100000000002, 1242.7500000000002], [1242.7500000000002, 1253.7300000000002], [1253.7300000000002, 1264.2800000000002], [1264.2800000000002, 1276.4900000000002], [1276.4900000000002, 1288.9300000000003], [1288.9300000000003, 1299.9200000000003], [1299.9200000000003, 1312.4600000000003], [1312.4600000000003, 1324.5500000000002], [1324.5500000000002, 1337.6200000000001], [1337.6200000000001, 1348.44], [1348.44, 1361.3600000000001], [1361.3600000000001, 1373.6100000000001], [1373.6100000000001, 1384.6100000000001], [1384.6100000000001, 1394.8300000000002], [1394.8300000000002, 1407.7500000000002], [1407.7500000000002, 1418.1050000000002], [1418.1050000000002, 1430.0400000000002], [1430.0400000000002, 1443.0800000000002], [1443.0800000000002, 1454.5000000000002], [1454.5000000000002, 1467.9400000000003], [1467.9400000000003, 1482.2500000000002], [1482.2500000000002, 1494.8800000000003], [1494.8800000000003, 1506.6100000000004], [1506.6100000000004, 1518.2900000000004], [1518.2900000000004, 1531.2400000000005], [1531.2400000000005, 1542.3600000000004], [1542.3600000000004, 1552.5000000000005], [1552.5000000000005, 1565.2700000000004], [1565.2700000000004, 1579.5200000000004], [1579.5200000000004, 1591.4500000000005], [1591.4500000000005, 1601.7520000000004], [1601.7520000000004, 1614.0200000000004], [1614.0200000000004, 1628.9000000000005], [1628.9000000000005, 1640.0600000000006], [1640.0600000000006, 1652.3300000000006], [1652.3300000000006, 1665.3200000000006], [1665.3200000000006, 1676.4600000000007], [1676.4600000000007, 1688.0600000000006], [1688.0600000000006, 1701.0600000000006], [1701.0600000000006, 1711.3030000000006], [1711.3030000000006, 1723.1350000000007], [1723.1350000000007, 1733.5500000000006], [1733.5500000000006, 1744.9600000000007], [1744.9600000000007, 1757.9900000000007], [1757.9900000000007, 1773.3300000000006], [1773.3300000000006, 1784.7900000000006], [1784.7900000000006, 1798.3500000000006], [1798.3500000000006, 1810.9000000000005], [1810.9000000000005, 1821.8700000000006], [1821.8700000000006, 1832.7200000000005], [1832.7200000000005, 1847.4900000000005], [1847.4900000000005, 1860.7400000000005], [1860.7400000000005, 1875.5400000000004], [1875.5400000000004, 1885.6400000000003], [1885.6400000000003, 1899.7000000000003], [1899.7000000000003, 1909.8700000000003], [1909.8700000000003, 1920.2400000000002], [1920.2400000000002, 1930.6900000000003], [1930.6900000000003, 1942.1800000000003], [1942.1800000000003, 1954.4400000000003], [1954.4400000000003, 1964.6700000000003], [1964.6700000000003, 1975.6400000000003], [1975.6400000000003, 1986.0200000000004], [1986.0200000000004, 1997.2000000000005], [1997.2000000000005, 2008.9100000000005], [2008.9100000000005, 2019.8600000000006], [2019.8600000000006, 2030.5400000000006], [2030.5400000000006, 2040.7540000000006], [2040.7540000000006, 2053.0300000000007], [2053.0300000000007, 2063.9510000000005], [2063.9510000000005, 2074.7600000000007], [2074.7600000000007, 2085.7800000000007], [2085.7800000000007, 2096.8890000000006], [2096.8890000000006, 2109.620000000001], [2109.620000000001, 2121.5900000000006], [2121.5900000000006, 2132.3200000000006], [2132.3200000000006, 2143.0300000000007], [2143.0300000000007, 2154.120000000001], [2154.120000000001, 2164.4100000000008], [2164.4100000000008, 2176.9500000000007], [2176.9500000000007, 2188.870000000001], [2188.870000000001, 2200.250000000001], [2200.250000000001, 2212.230000000001], [2212.230000000001, 2224.530000000001], [2224.530000000001, 2234.7360000000012], [2234.7360000000012, 2245.760000000001], [2245.760000000001, 2255.950000000001], [2255.950000000001, 2269.0400000000013], [2269.0400000000013, 2281.700000000001], [2281.700000000001, 2295.380000000001], [2295.380000000001, 2306.960000000001], [2306.960000000001, 2316.970000000001], [2316.970000000001, 2328.780000000001], [2328.780000000001, 2339.300000000001], [2339.300000000001, 2349.3900000000012], [2349.3900000000012, 2362.7300000000014], [2362.7300000000014, 2373.6500000000015], [2373.6500000000015, 2383.7100000000014], [2383.7100000000014, 2394.7900000000013], [2394.7900000000013, 2408.3800000000015], [2408.3800000000015, 2419.7000000000016], [2419.7000000000016, 2431.9110000000014], [2431.9110000000014, 2442.1200000000013], [2442.1200000000013, 2454.930000000001], [2454.930000000001, 2465.3750000000014], [2465.3750000000014, 2475.490000000001], [2475.490000000001, 2486.460000000001], [2486.460000000001, 2498.320000000001], [2498.320000000001, 2509.130000000001], [2509.130000000001, 2519.510000000001], [2519.510000000001, 2529.510000000001], [2529.510000000001, 2540.320000000001], [2540.320000000001, 2552.050000000001], [2552.050000000001, 2565.570000000001], [2565.570000000001, 2578.220000000001], [2578.220000000001, 2589.820000000001], [2589.820000000001, 2600.310000000001], [2600.310000000001, 2612.580000000001], [2612.580000000001, 2623.5100000000007], [2623.5100000000007, 2634.4800000000005], [2634.4800000000005, 2644.9400000000005], [2644.9400000000005, 2655.9500000000007], [2655.9500000000007, 2669.4900000000007], [2669.4900000000007, 2679.830000000001], [2679.830000000001, 2692.060000000001], [2692.060000000001, 2705.620000000001], [2705.620000000001, 2716.080000000001], [2716.080000000001, 2726.170000000001], [2726.170000000001, 2736.840000000001], [2736.840000000001, 2747.990000000001], [2747.990000000001, 2758.3700000000013], [2758.3700000000013, 2768.7900000000013], [2768.7900000000013, 2779.200000000001], [2779.200000000001, 2789.5000000000014], [2789.5000000000014, 2799.5200000000013], [2799.5200000000013, 2812.8600000000015], [2812.8600000000015, 2823.2600000000016], [2823.2600000000016, 2833.6000000000017], [2833.6000000000017, 2845.230000000002], [2845.230000000002, 2855.020000000002]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [881, 1488, 2158, 2855]}
{"example_id": "mit088@@MIT6_004S17_19-02_300k", "text": ["It's not unusual to find that an application is organized as multiple communicating processes.  What's the advantage of using multiple processes instead of just a single process? ", "Many applications exhibit concurrency, i.e., some of the required computations can be performed  in parallel.  For example, video compression algorithms represent each video frame as an array of ", "8-pixel by 8-pixel macroblocks.  Each macroblock is individually compressed by converting the 64 intensity and color values  from the spatial domain to the frequency domain and then quantizing and Huffman encoding the ", "frequency coefficients.  If you're using a multi-core processor to do the compression, you can perform the macroblock  compressions concurrently.  Applications like video games are naturally divided into the \"front-end\" user interface ", "and \"back-end\" simulation and rendering engines.  Inputs from the user arrive asynchronously with respect to the simulation and it's easiest  to organize the processing of user events separately from the backend processing. ", "Processes are an effective way to encapsulate the state and computation for what are logically  independent components of an application, which communicate with one another when they ", "need to share information.  These sorts of applications are often data- or event-driven, i.e., the processing required  is determined by the data to be processed or the arrival of external events. ", "How should the processes communicate with each other?  If the processes are running out of the same physical memory, it would be easy to arrange  to share memory data by mapping the same physical page into the contexts for both processes. ", "Any data written to that page by one process will be able to be read by the other process.  To make it easier to coordinate the processes' communicating via shared memory, we'll see ", "it's convenient to provide synchronization primitives.  Some ISAs include instructions that make it easy to do the required synchronization.  Another approach is to add OS supervisor calls to pass messages from one process to another. ", "Message passing involves more overhead than shared memory, but makes the application programming  independent of whether the communicating processes are running on the same physical processor. ", "In this lecture, we'll use the classic producer-consumer problem as our example of concurrent processes  that need to communicate and synchronize.  There are two processes: a producer and a consumer. ", "The producer is running in a loop, which performs some computation <xxx> to generate information,  in this case, a single character C. The consumer is also running a loop, which ", "waits for the next character to arrive from the producer, then performs some computation  <yyy>.  The information passing between the producer and consumer could obviously be much more ", "complicated than a single character.  For example, a compiler might produce a sequence of assembly language statements that are passed  to the assembler to be converted into the appropriate binary representation. ", "The user interface front-end for a video game might pass a sequence of player actions to  the simulation and rendering back-end.  In fact, the notion of hooking multiple processes together in a processing pipeline is so useful ", "that the Unix and Linux operating systems provide a PIPE primitive in the operating  system that connects the output channel of the upstream  process to the input channel of the downstream process. ", "Let's look at a timing diagram for the actions of our simple producer/consumer example.  We'll use arrows to indicate when one action happens before another.  Inside a single process, e.g., the producer, the order of execution implies a particular ", "ordering in time: the first execution of <xxx> is followed by  the sending of the first character.  Then there's the second execution of <xxx>, followed by the sending of the second character, ", "and so on.  In later examples, we'll omit the timing arrows between successive statements in the same  program.  We see a similar order of execution in the consumer: the first character is received, ", "then the computation <yyy> is performed for the first time, etc.  Inside of each process, the process' program counter is determining the order in which  the computations are performed. ", "So far, so good - each process is running as expected.  However, for the producer/consumer system to function correctly as a whole, we'll need  to introduce some additional constraints on the order of execution. ", "These are called \"precedence constraints\" and we'll use this stylized less-than sign  to indicate that computation A must precede, i.e., come before, computation B. ", "In the producer/consumer system we can't consume data before it's been produced, a constraint  we can formalize as requiring that the i_th send operation has to precede the i_th receive ", "operation.  This timing constraint is shown as the solid red arrow in the timing diagram.  Assuming we're using, say, a shared memory location to hold the character being transmitted ", "from the producer to the consumer, we need to ensure that the producer doesn't  overwrite the previous character before it's been read by the consumer.  In other words, we require the i_th receive to precede the i+1_st send. ", "These timing constraints are shown as the dotted red arrows in the timing diagram.  Together these precedence constraints mean that the producer and consumer are tightly  coupled in the sense that a character has to be read by the consumer before the next ", "character can be sent by the producer, which might be less than optimal if the <xxx>  and <yyy> computations take a variable amount of time. ", "So let's see how we can relax the constraints to allow for more independence between the  producer and consumer.  We can relax the execution constraints on the producer and consumer by having them communicate ", "via N-character first-in-first-out (FIFO) buffer.  As the producer produces characters it inserts them into the buffer. ", "The consumer reads characters from the buffer in the same order as they were produced.  The buffer can hold between 0 and N characters.  If the buffer holds 0 characters, it's empty; if it holds N characters, it's full. ", "The producer should wait if the buffer is full, the consumer should wait if the buffer  is empty.  Using the N-character FIFO buffer relaxes our second overwrite constraint to the requirement ", "that the i_th receive must happen before i+N_th send.  In other words, the producer can get up to N characters ahead of the consumer. ", "FIFO buffers are implemented as an N-element character array with two indices:  the read index indicates the next character to be read, the write index indicates the ", "next character to be written.  We'll also need a counter to keep track of the number of characters held by the buffer,  but that's been omitted from this diagram.  The indices are incremented modulo N, i.e., the next element to be accessed after the ", "N-1_st element is the 0_th element, hence the name \"circular buffer\".  Here's how it works.  The producer runs, using the write index to add the first character to the buffer. ", "The producer can produce additional characters, but must wait once the buffer is full.  The consumer can receive a character anytime the buffer is not empty, using the read index ", "to keep track of the next character to be read.  Execution of the producer and consumer can proceed in any order so long as the producer  doesn't write into a full buffer and the consumer doesn't read from an empty buffer. ", "Here's what the code for the producer and consumer might look like.  The array and indices for the circular buffer live in shared memory where they can be accessed  by both processes. ", "The SEND routine in the producer uses the write index IN to keep track of where to write  the next character.  Similarly the RCV routine in the consumer uses the read index OUT to keep track of the ", "next character to be read.  After each use, each index is incremented modulo N.  The problem with this code is that, as currently written, neither of the two precedence constraints ", "is enforced.  The consumer can read from an empty buffer and the producer can overwrite entries when  the buffer is full.  We'll need to modify this code to enforce the constraints and for that we'll introduce ", "a new programming construct that we'll use to provide the appropriate inter-process synchronization.   What we'd like to do is to create a single abstraction that can be used to address all ", "our synchronization needs.  In the early 1960's, the Dutch computer scientist Edsger Dijkstra proposed a new abstract data  type called the semaphore, which has an integer value greater than or equal to 0. ", "A programmer can declare a semaphore as shown here, specifying its initial value.  The semaphore lives in a memory location shared by all the processes that need to synchronize ", "their operation.  The semaphore is accessed with two operations: WAIT and SIGNAL.  The WAIT operation will wait until the specified semaphore has a value greater than 0, then ", "it will decrement the semaphore value and return to the calling program.  If the semaphore value is 0 when WAIT is called, conceptually execution is suspended until ", "the semaphore value is non-zero.  In a simple (inefficient) implementation, the WAIT routine loops, periodically testing  the value of the semaphore, proceeding when its value is non-zero. ", "The SIGNAL operation increments the value of the specified semaphore.  If there any processes WAITing on that semaphore, exactly one of them may now proceed. ", "We'll have to be careful with the implementation of SIGNAL and WAIT to ensure that the \"exactly  one\" constraint is satisfied, i.e., that two processes both WAITing on the  same semaphore won't both think they can decrement it and proceed after a SIGNAL. ", "A semaphore initialized with the value K guarantees that the i_th call to SIGNAL will precede  (i+K)_th call to WAIT.  In a moment, we'll see some concrete examples that will make this clear. ", "Note that in 6.004, we're ruling out semaphores with negative values.  In the literature, you may see P(s) used in place of WAIT(s) and V(s) used in place of ", "SIGNAL(s).  These operation names are derived from the Dutch words for \"test\" and \"increase\".  Let's see how to use semaphores to implement precedence constraints. ", "Here are two processes, each running a program with 5 statements.  Execution proceeds sequentially within each process, so A1 executes before A2, and so  on. ", "But there are no constraints on the order of execution between the processes, so statement  B1 in Process B might be executed before or after any of the statements in Process A. ", "Even if A and B are running in a timeshared environment on a single physical processor,  execution may switch at any time between processes A and B. ", "Suppose we wish to impose the constraint that the execution of statement A2 completes before  execution of statement B4 begins.  The red arrow shows the constraint we want. ", "Here's the recipe for implementing this sort of simple precedence constraint using semaphores.  First, declare a semaphore (called \"s\" in this example) and initialize its value to ", "0.  Place a call to signal(s) at the start of the arrow.  In this example, signal(s) is placed after the statement A2 in process A. ", "Then place a call to wait(s) at the end of the arrow.  In this example, wait(s) is placed before the statement B4 in process B.  With these modifications, process A executes as before, with the signal to semaphore s ", "happening after statement A2 is executed.  Statements B1 through B3 also execute as before, but when the wait(s) is executed, execution ", "of process B is suspended until the signal(s) statement has finished execution.  This guarantees that execution of B4 will start only after execution of A2 has completed. ", "By initializing the semaphore s to 0, we enforced the constraint that the first call to signal(s)  had to complete before the first call to wait(s) would succeed. ", "Another way to think about semaphores is as a management tool for a shared pool of K resources,  where K is the initial value of the semaphore.  You use the SIGNAL operation to add or return resources to the shared pool. ", "And you use the WAIT operation to allocate a resource for your exclusive use.  At any given time, the value of the semaphore gives the number of unallocated resources ", "still available in the shared pool.  Note that the WAIT and SIGNAL operations can be in the same process, or they may be in  different processes, depending on when the resource is allocated and returned. ", "We can use semaphores to manage our N-character FIFO buffer.  Here we've defined a semaphore CHARS and initialized it to 0.  The value of CHARS will tell us how many characters are in the buffer. ", "So SEND does a signal(CHARS) after it has added a character to the buffer, indicating  the buffer now contains an additional character.  And RCV does a wait(CHARS) to ensure the buffer has at least one character before reading ", "from the buffer.  Since CHARS was initialized to 0, we've enforced the constraint that the i_th call to signal(CHARS)  precedes the completion of the i_th call to wait(CHARS).  In other words, RCV can't consume a character until it has been placed in the buffer by ", "SEND.  Does this mean our producer and consumer are now properly synchronized?  Using the CHARS semaphore, we implemented *one* of the two precedence constraints we  identified as being necessary for correct operation. ", "Next we'll see how to implement the other precedence constraint.  What keeps the producer from putting more than N characters into the N-character buffer?  Nothing. ", "Oops, the producer can start to overwrite characters placed in the buffer earlier even  though they haven't yet been read by the consumer.  This is called buffer overflow and the sequence of characters transmitted from producer to ", "consumer becomes hopelessly corrupted.  What we've guaranteed so far is that the consumer can read a character only after the producer  has placed it in the buffer, i.e., the consumer can't read from an empty buffer. ", "What we still need to guarantee is that the producer can't get too far ahead of the consumer.  Since the buffer holds at most N characters, the producer can't send the (i+N)th character ", "until the consumer has read the i_th character.  Here we've added a second semaphore, SPACES, to manage the number of spaces in the buffer. ", "Initially the buffer is empty, so it has N spaces.  The producer must WAIT for a space to be available.  When SPACES in non-zero, the WAIT succeeds, decrementing the number of available spaces ", "by one and then the producer fills that space with the next character.  The consumer signals the availability of another space after it reads a character from the  buffer. ", "There's a nice symmetry here.  The producer consumes spaces and produces characters.  The consumer consumes characters and produces spaces. ", "Semaphores are used to track the availability of both resources (i.e., characters and spaces),  synchronizing the execution of the producer and consumer.  This works great when there is a single producer process and a single consumer process. ", "Next we'll think about what will happen if we have multiple producers and multiple consumers.   Let's take a moment to look at a different example.  Automated teller machines allow bank customers to perform a variety of transactions: deposits, ", "withdrawals, transfers, etc.  Let's consider what happens when two customers try to withdraw $50 from the same account  at the same time.  A portion of the bank's code for a withdrawal transaction is shown in the upper right. ", "This code is responsible for adjusting the account balance to reflect the amount of the  withdrawal.  Presumably the check to see if there is sufficient funds has already happened.  What's supposed to happen? ", "Let's assume that the bank is using a separate process to handle each transaction, so the  two withdrawal transactions cause two different processes to be created, each of which will ", "run the Debit code.  If each of the calls to Debit run to completion without interruption, we get the desired outcome:  the first transaction debits the account by $50, then the second transaction does the ", "same.  The net result is that you and your friend have $100 and the balance is $100 less.  So far, so good.  But what if the process for the first transaction is interrupted just after it's read the balance? ", "The second process subtracts $50 from the balance, completing that transaction.  Now the first process resumes, using the now out-of-date balance it loaded just before ", "being interrupted.  The net result is that you and your friend have $100, but the balance has only been debited  by $50.  The moral of the story is that we need to be careful when writing code that reads and ", "writes shared data since other processes might modify the data in the middle of our execution.  When, say, updating a shared memory location, we'll need to LD the current value, modify ", "it, then ST the updated value.  We would like to ensure that no other processes access the shared location between the start  of the LD and the completion of the ST. ", "The LD/modify/ST code sequence is what we call a \"critical section\".  We need to arrange that other processes attempting to execute the same critical section are delayed ", "until our execution is complete.  This constraint is called \"mutual exclusion\", i.e., only one process at a time can be executing  code in the same critical section. ", "Once we've identified critical sections, we'll use semaphores to guarantee they execute atomically,  i.e., that once execution of the critical section begins, no other process will be able ", "to enter the critical section until the execution is complete.  The combination of the semaphore to enforce the mutual exclusion constraint and the critical  section of code implement what's called a \"transaction\". ", "A transaction can perform multiple reads and writes of shared data with the guarantee that  none of the data will be read or written by other processes while the transaction is in ", "progress.  Here's the original code to Debit, which we'll modify by adding a LOCK semaphore.  In this case, the resource controlled by the semaphore is the right to run the code in  the critical section. ", "By initializing LOCK to 1, we're saying that at most one process can execute the critical  section at a time.  A process running the Debit code WAITs on the LOCK semaphore. ", "If the value of LOCK is 1, the WAIT will decrement value of LOCK to 0 and let the process enter  the critical section.  This is called acquiring the lock. ", "If the value of LOCK is 0, some other process has acquired the lock and is executing the  critical section and our execution is suspended until the LOCK value is non-zero. ", "When the process completes execution of the critical section, it releases the LOCK with  a call to SIGNAL, which will allow other processes to enter the critical section. ", "If there are multiple WAITing processes, only one will be able to acquire the lock, and  the others will still have to wait their turn.  Used in this manner, semaphores are implementing a mutual exclusion constraint, i.e., there's ", "a guarantee that two executions of the critical section cannot overlap.  Note that if multiple processes need to execute the critical section, they may run in any  order and the only guarantee is that their executions will not overlap. ", "There are some interesting engineering issues to consider.  There's the question of the granularity of the lock, i.e., what shared data is controlled  by the lock? ", "In our bank example, should there be one lock controlling access to the balance for all  accounts?  That would mean that no one could access any balance while a transaction was in progress. ", "That would mean that transactions accessing different accounts would have to run one after  the other even though they're accessing different data.  So one lock for all the balances would introduce unnecessary precedence constraints, greatly ", "slowing the rate at which transactions could be processed.  Since the guarantee we need is that we shouldn't permit multiple simultaneous transactions  on the same account, it would make more sense to have a separate ", "lock for each account, and change the Debit code to acquire the account's lock before  proceeding.  That will only delay transactions that truly overlap, an important efficiency consideration ", "for a large system processing many thousands of mostly non-overlapping transactions each  second.  Of course, having per-account locks would mean a lot of locks! ", "If that's a concern, we can adopt a compromise strategy of having locks that protect groups  of accounts, e.g., accounts with same last three digits in the account number. ", "That would mean we'd only need 1000 locks, which would allow up to 1000 transactions  to happen simultaneously.  The notion of transactions on shared data is so useful that we often use a separate ", "system called a database that provides the desired functionality.  Database systems are engineered to provide low-latency access to shared data, providing  the appropriate transactional semantics. ", "The design and implementation of databases and transactions is pretty interesting.  To follow up, I recommend reading about databases on the web.  Returning to our producer/consumer example, we see that if multiple producers are trying ", "to insert characters into the buffer at the same time,  it's possible that their execution may overlap in a way that causes characters to be overwritten  and/or the index to be improperly incremented. ", "We just saw this bug in the bank example: the producer code contains a critical section  of code that accesses the FIFO buffer and we need to ensure that the critical section  is executed atomically. ", "Here we've added a third semaphore, called LOCK, to implement the necessary mutual exclusion  constraint for the critical section of code that inserts characters into the FIFO buffer. ", "With this modification, the system will now work correctly when there are multiple producer  processes.  There's a similar issue with multiple consumers, so we've used the same LOCK to protect the ", "critical section for reading from the buffer in the RCV code.  Using the same LOCK for producers and consumers will work, but does introduce unnecessary ", "precedence constraints since producers and consumers use different indices,  i.e., IN for producers and OUT for consumers.  To solve this problem we could use two locks: one for producers and one for consumers. ", "Semaphores are a pretty handy swiss army knife when it comes to dealing with synchronization  issues.  When WAIT and SIGNAL appear in different processes, the semaphore ensures the correct execution ", "timing between processes.  In our example, we used two semaphores to ensure that consumers can't read from an empty  buffer and that producers can't write into a full buffer. ", "We also used semaphores to ensure that execution of critical sections -- in our example, updates  of the indices IN and OUT -- were guaranteed to be atomic.  In other words, that the sequence of reads and writes needed to increment a shared index ", "would not be interrupted by another process between the initial read of the index and  the final write.   Now let's figure out how to implement semaphores. ", "They are themselves shared data and implementing the WAIT and SIGNAL operations will require  read/modify/write sequences that must be executed as critical sections. ", "Normally we'd use a lock semaphore to implement the mutual exclusion constraint for critical  sections.  But obviously we can't use semaphores to implement semaphores!  We have what's called a bootstrapping problem: we need to implement the required functionality ", "from scratch.  Happily, if we're running on a timeshared processor with an uninterruptible OS kernel,  we can use the supervisor call (SVC) mechanism to implement the required functionality. ", "We can also extend the ISA to include a special test-and-set instruction that will let us  implement a simple lock semaphore, which can then be used to protect critical  sections that implement more complex semaphore semantics. ", "Single instructions are inherently atomic and, in a multi-core processor, will do what  we want if the shared main memory supports reading the old value and writing a new value  to a specific memory location as a single memory access. ", "There are other, more complex, software-only solutions that rely only on the atomicity  of individual reads and writes to implement a simple lock.  For example, see \"Dekker's Algorithm\" on Wikipedia. ", "We'll look in more detail at the first two approaches.  Here are the OS handlers for the WAIT and SIGNAL supervisor calls.  Since SVCs are run kernel mode, they can't be interrupted, so the handler code is naturally ", "executed as a critical section.  Both handlers expect the address of the semaphore location to be passed as an argument in the  user's R0. ", "The WAIT handler checks the semaphore's value and if it's non-zero, the value is decremented  and the handler resumes execution of the user's program at the instruction following the WAIT  SVC. ", "If the semaphore is 0, the code arranges to re-execute the WAIT SVC when the user program  resumes execution and then calls SLEEP to mark the process as inactive until the corresponding ", "WAKEUP call is made.  The SIGNAL handler is simpler: it increments the semaphore value and calls WAKEUP to mark  as active any processes that were WAITing for this particular semaphore. ", "Eventually the round-robin scheduler will select a process that was WAITing and it will  be able to decrement the semaphore and proceed.  Note that the code makes no provision for fairness, i.e., there's no guarantee that ", "a WAITing process will eventually succeed in finding the semaphore non-zero.  The scheduler has a specific order in which it runs processes, so the next-in-sequence ", "WAITing process will always get the semaphore even if there are later-in-sequence processes  that have been WAITing longer.  If fairness is desired, WAIT could maintain a queue of waiting processes and use the queue ", "to determine which process is next in line, independent of scheduling order.  Many ISAs support an instruction like the TEST-and-CLEAR instruction shown here. ", "The TCLR instruction reads the current value of a memory location and then sets it to zero,  all as a single operation.  It's like a LD except that it zeros the memory location after reading its value. ", "To implement TCLR, the memory needs to support read-and-clear operations, as well as normal  reads and writes.  The assembly code at the bottom of the slide shows how to use TCLR to implement a simple ", "lock.  The program uses TCLR to access the value of the lock semaphore.  If the returned value in RC is zero, then some other process has the lock and the program ", "loops to try TCLR again.  If the returned value is non-zero, the lock has been acquired and execution of the critical  section can proceed. ", "In this case, TCLR has also set the lock to zero, so that other processes will be prevented  from entering the critical section.  When the critical section has finished executing, a ST instruction is used to set the semaphore ", "to a non-zero value.   If the necessary synchronization requires acquiring more than one lock, there are some  special considerations that need to be taken into account. ", "For example, the code below implements the transfer of funds from one bank account to  another.  The code assumes there is a separate semaphore lock for each account and since it needs to ", "adjust the balance of two accounts, it acquires the lock for each account.  Consider what happens if two customers try simultaneous transfers between their two accounts. ", "The top customer will try to acquire the locks for accounts 6005 and 6004.  The bottom customer tries to acquire the same locks, but in the opposite order. ", "Once a customer has acquired both locks, the transfer code will complete, releasing the  locks.  But what happens if the top customer acquires his first lock (for account 6005) and the ", "bottom customer simultaneously acquires his first lock (for account 6004).  So far, so good, but now each customer will be not be successful in acquiring their second ", "lock, since those locks are already held by the other customer!  This situation is called a \"deadlock\" or \"deadly embrace\" because there is no way execution ", "for either process will resume.  Both will wait indefinitely to acquire a lock that will never be available.  Obviously, synchronization involving multiple resources requires a bit more thought. ", "The problem of deadlock is elegantly illustrated by the Dining Philosophers problem.  Here there are, say, 5 philosophers waiting to eat.  Each requires two chopsticks in order to proceed, and there are 5 chopsticks on the table. ", "The philosophers follow a simple algorithm.  First they pick up the chopstick on their left, then the chopstick on their right.  When they have both chopsticks they eat until they're done, at which point they return both ", "chopsticks to the table, perhaps enabling one of their neighbors to pick them up and  begin eating.  Again, we see the basic setup of needing two (or more) resources before the task can complete. ", "Hopefully you can see the problem that may arise  If all philosophers pick up the chopstick on their left, then all the chopsticks have  been acquired, and none of the philosophers will be able to acquire their second chopstick ", "and eat.  Another deadlock!  Here are the conditions required for a deadlock: 1.  Mutual exclusion, where a particular resource can only be acquired by one process at a time. ", "2.  Hold-and-wait, where a process holds allocated resources while waiting to acquire the next  resource.  3.  No preemption, where a resource cannot be removed from the process which acquired it. ", "Resources are only released after the process has completed its transaction.  4.  Circular wait, where resources needed by one process are held by another, and vice versa. ", "How can we solve the problem of deadlocks when acquiring multiple resources?  Either we avoid the problem to begin with, or we detect that deadlock has occurred and  implement a recovery strategy. ", "Both techniques are used in practice.  In the Dining Philosophers problem, deadlock can be avoided with a small modification to  the algorithm.  We start by assigning a unique number to each chopstick to establish a global ordering of ", "all the resources, then rewrite the code to acquire resources  using the global ordering to determine which resource to acquire first, which second, and  so on. ", "With the chopsticks numbered, the philosophers pick up the lowest-numbered chopstick from  either their left or right.  Then they pick up the other, higher-numbered chopstick, eat, and then return the chopsticks ", "to the table.  How does this avoid deadlock?  Deadlock happens when all the chopsticks have been picked up but no philosopher can eat.  If all the chopsticks have been been picked up, that means some philosopher has picked ", "up the highest-numbered chopstick and so must have earlier picked up the lower-numbered  chopstick on his other side.  So that philosopher can eat then return both chopsticks to the table, breaking the hold-and-wait ", "cycle.  So if all the processes in the system can agree upon a global ordering for the resources  they require, then acquire them in order, there will be no possibility of a deadlock ", "caused by a hold-and-wait cycle.  A global ordering is easy to arrange in our banking code for the transfer transaction.  We'll modify the code to first acquire the lock for the lower-numbered account, then ", "acquire the lock for the higher-numbered account.  Now, both customers will first try to acquire the lock for the 6004 account.  The customer that succeeds then can acquire the lock for the 6005 account and complete ", "the transaction.  The key to deadlock avoidance was that customers contented for the lock for the *first* resource  they both needed. ", "Acquiring that lock ensured they would be able to acquire the remainder of the shared  resources without fear that they would already be allocated to another process in a way that  could cause a hold-and-wait cycle. ", "Establishing and using a global order for shared resources is possible when we can modify  all processes to cooperate.  Avoiding deadlock without changing the processes is a harder problem. ", "For example, at the operating system level, it would be possible to modify the WAIT SVC  to detect circular wait and terminate one of the WAITing processes, releasing its resources ", "and breaking the deadlock.  The other strategy we mentioned was detection and recovery.  Database systems detect when there's been an external access to the shared data used ", "by a particular transaction, which causes the database to abort the transaction.  When issuing a transaction to a database, the programmer specifies what should happen ", "if the transaction is aborted, e.g., she can specify that the transaction be retried.  The database remembers all the changes to shared data that happen during a transaction ", "and only changes the master copy of the shared data when it is sure that the transaction  will not be aborted, at which point the changes are committed to  the database. ", "In summary, we saw that organizing an application as communicating processes is often a convenient  way to go.  We used semaphores to synchronize the execution of the different processes, providing guarantees ", "that certain precedence constraints would be met, even between statements in different  processes.  We also introduced the notion of critical code sections and mutual exclusion constraints ", "that guaranteed that a code sequence would be executed without interruption by another  process.  We saw that semaphores could also be used to implement those mutual exclusion constraints. ", "Finally we discussed the problem of deadlock that can occur when multiple processes must  acquire multiple shared resources, and we proposed several solutions based on  a global ordering of resources or the ability to restart a transaction. ", "Synchronization primitives play a key role in the world of \"big data\" where there are  vast amounts of shared data, or when trying to coordinate the execution of thousands of  processes in the cloud. ", "Understanding synchronization issues and their solutions is a key skill when writing most  modern applications. "], "vid_duration": [11.561, 12.18, 14.27, 14.96, 15.869, 10.47, 14.621, 14.949, 11.21, 16.471, 12.11, 12.76, 11.67, 11.31, 12.47, 14.04, 12.19, 15.23, 11.26, 13.229, 11.82, 13.25, 12.441, 11.519, 11.561, 16.08, 13.85, 10.449, 13.511, 10.03, 13.85, 11.769, 10.401, 10.58, 15.099, 12.5, 11.51, 14.291, 10.63, 11.819, 11.38, 12.591, 11.667, 14.26, 10.39, 12.1, 10.38, 12.02, 10.71, 14.97, 13.22, 12.12, 10.95, 11.05, 12.13, 10.03, 12.409, 12.29, 10.101, 14.31, 10.801, 13.848, 11.601, 13.08, 10.62, 13.55, 12.17, 13.19, 15.52, 13.76, 10.83, 13.41, 14.22, 11.52, 10.34, 11.69, 11.43, 11.17, 14.559, 13.837, 14.441, 11.98, 11.169, 13.521, 15.679, 10.431, 12.69, 12.72, 11.59, 10.22, 13.76, 11.16, 13.25, 10.53, 11.649, 12.309, 11.72, 11.181, 10.011, 12.94, 15.74, 10.089, 11.361, 13.139, 12.76, 12.071, 11.58, 10.109, 11.53, 13.04, 14.23, 13.111, 12.51, 11.399, 10.591, 10.22, 15.54, 10.74, 12.75, 14.47, 10.815, 11.169, 14.591, 12.62, 14.46, 15.25, 11.29, 14.44, 11.05, 10.85, 12.629, 14.261, 12.2, 10.4, 12.599, 11.391, 13.349, 11.01, 11.811, 10.709, 13.59, 11.548, 10.782, 11.28, 11.64, 12.239, 11.631, 10.58, 13.46, 14.629, 12.301, 12.599, 12.139, 11.782, 14.09, 11.569, 11.731, 13.9, 10.77, 11.369, 13.811, 13.54, 11.46, 12.381, 13.999, 10.28, 12.44, 12.34, 11.009, 12.07, 11.171, 11.62, 11.03, 12.31, 11.5, 12.75, 15.709, 11.831, 7.262], "stet": [[0, 11.561], [11.561, 23.741], [23.741, 38.010999999999996], [38.010999999999996, 52.971], [52.971, 68.84], [68.84, 79.31], [79.31, 93.931], [93.931, 108.88], [108.88, 120.09], [120.09, 136.561], [136.561, 148.671], [148.671, 161.43099999999998], [161.43099999999998, 173.10099999999997], [173.10099999999997, 184.41099999999997], [184.41099999999997, 196.88099999999997], [196.88099999999997, 210.92099999999996], [210.92099999999996, 223.11099999999996], [223.11099999999996, 238.34099999999995], [238.34099999999995, 249.60099999999994], [249.60099999999994, 262.8299999999999], [262.8299999999999, 274.6499999999999], [274.6499999999999, 287.8999999999999], [287.8999999999999, 300.3409999999999], [300.3409999999999, 311.8599999999999], [311.8599999999999, 323.4209999999999], [323.4209999999999, 339.50099999999986], [339.50099999999986, 353.3509999999999], [353.3509999999999, 363.7999999999999], [363.7999999999999, 377.3109999999999], [377.3109999999999, 387.3409999999999], [387.3409999999999, 401.1909999999999], [401.1909999999999, 412.9599999999999], [412.9599999999999, 423.36099999999993], [423.36099999999993, 433.9409999999999], [433.9409999999999, 449.0399999999999], [449.0399999999999, 461.5399999999999], [461.5399999999999, 473.0499999999999], [473.0499999999999, 487.3409999999999], [487.3409999999999, 497.9709999999999], [497.9709999999999, 509.7899999999999], [509.7899999999999, 521.17], [521.17, 533.761], [533.761, 545.428], [545.428, 559.688], [559.688, 570.078], [570.078, 582.178], [582.178, 592.558], [592.558, 604.578], [604.578, 615.288], [615.288, 630.258], [630.258, 643.4780000000001], [643.4780000000001, 655.5980000000001], [655.5980000000001, 666.5480000000001], [666.5480000000001, 677.5980000000001], [677.5980000000001, 689.7280000000001], [689.7280000000001, 699.758], [699.758, 712.167], [712.167, 724.457], [724.457, 734.558], [734.558, 748.8679999999999], [748.8679999999999, 759.669], [759.669, 773.5169999999999], [773.5169999999999, 785.1179999999999], [785.1179999999999, 798.198], [798.198, 808.818], [808.818, 822.3679999999999], [822.3679999999999, 834.5379999999999], [834.5379999999999, 847.728], [847.728, 863.2479999999999], [863.2479999999999, 877.0079999999999], [877.0079999999999, 887.838], [887.838, 901.2479999999999], [901.2479999999999, 915.468], [915.468, 926.9879999999999], [926.9879999999999, 937.328], [937.328, 949.018], [949.018, 960.448], [960.448, 971.6179999999999], [971.6179999999999, 986.1769999999999], [986.1769999999999, 1000.0139999999999], [1000.0139999999999, 1014.4549999999999], [1014.4549999999999, 1026.435], [1026.435, 1037.604], [1037.604, 1051.125], [1051.125, 1066.804], [1066.804, 1077.2350000000001], [1077.2350000000001, 1089.9250000000002], [1089.9250000000002, 1102.6450000000002], [1102.6450000000002, 1114.2350000000001], [1114.2350000000001, 1124.4550000000002], [1124.4550000000002, 1138.2150000000001], [1138.2150000000001, 1149.3750000000002], [1149.3750000000002, 1162.6250000000002], [1162.6250000000002, 1173.1550000000002], [1173.1550000000002, 1184.804], [1184.804, 1197.113], [1197.113, 1208.833], [1208.833, 1220.0140000000001], [1220.0140000000001, 1230.025], [1230.025, 1242.9650000000001], [1242.9650000000001, 1258.7050000000002], [1258.7050000000002, 1268.794], [1268.794, 1280.1550000000002], [1280.1550000000002, 1293.294], [1293.294, 1306.054], [1306.054, 1318.125], [1318.125, 1329.705], [1329.705, 1339.8139999999999], [1339.8139999999999, 1351.3439999999998], [1351.3439999999998, 1364.3839999999998], [1364.3839999999998, 1378.6139999999998], [1378.6139999999998, 1391.725], [1391.725, 1404.235], [1404.235, 1415.6339999999998], [1415.6339999999998, 1426.2249999999997], [1426.2249999999997, 1436.4449999999997], [1436.4449999999997, 1451.9849999999997], [1451.9849999999997, 1462.7249999999997], [1462.7249999999997, 1475.4749999999997], [1475.4749999999997, 1489.9449999999997], [1489.9449999999997, 1500.7599999999998], [1500.7599999999998, 1511.9289999999999], [1511.9289999999999, 1526.5199999999998], [1526.5199999999998, 1539.1399999999996], [1539.1399999999996, 1553.5999999999997], [1553.5999999999997, 1568.8499999999997], [1568.8499999999997, 1580.1399999999996], [1580.1399999999996, 1594.5799999999997], [1594.5799999999997, 1605.6299999999997], [1605.6299999999997, 1616.4799999999996], [1616.4799999999996, 1629.1089999999995], [1629.1089999999995, 1643.3699999999994], [1643.3699999999994, 1655.5699999999995], [1655.5699999999995, 1665.9699999999996], [1665.9699999999996, 1678.5689999999995], [1678.5689999999995, 1689.9599999999996], [1689.9599999999996, 1703.3089999999995], [1703.3089999999995, 1714.3189999999995], [1714.3189999999995, 1726.1299999999994], [1726.1299999999994, 1736.8389999999995], [1736.8389999999995, 1750.4289999999994], [1750.4289999999994, 1761.9769999999994], [1761.9769999999994, 1772.7589999999993], [1772.7589999999993, 1784.0389999999993], [1784.0389999999993, 1795.6789999999994], [1795.6789999999994, 1807.9179999999994], [1807.9179999999994, 1819.5489999999995], [1819.5489999999995, 1830.1289999999995], [1830.1289999999995, 1843.5889999999995], [1843.5889999999995, 1858.2179999999994], [1858.2179999999994, 1870.5189999999993], [1870.5189999999993, 1883.1179999999993], [1883.1179999999993, 1895.2569999999992], [1895.2569999999992, 1907.038999999999], [1907.038999999999, 1921.128999999999], [1921.128999999999, 1932.697999999999], [1932.697999999999, 1944.428999999999], [1944.428999999999, 1958.328999999999], [1958.328999999999, 1969.098999999999], [1969.098999999999, 1980.467999999999], [1980.467999999999, 1994.2789999999989], [1994.2789999999989, 2007.8189999999988], [2007.8189999999988, 2019.2789999999989], [2019.2789999999989, 2031.659999999999], [2031.659999999999, 2045.658999999999], [2045.658999999999, 2055.938999999999], [2055.938999999999, 2068.378999999999], [2068.378999999999, 2080.718999999999], [2080.718999999999, 2091.727999999999], [2091.727999999999, 2103.7979999999993], [2103.7979999999993, 2114.968999999999], [2114.968999999999, 2126.588999999999], [2126.588999999999, 2137.6189999999992], [2137.6189999999992, 2149.928999999999], [2149.928999999999, 2161.428999999999], [2161.428999999999, 2174.178999999999], [2174.178999999999, 2189.887999999999], [2189.887999999999, 2201.718999999999], [2201.718999999999, 2208.9809999999993]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [541, 992, 1497, 1753, 2209]}
{"example_id": "mit088@@MIT6_004S17_06-02_300k", "text": [" In the last chapter we developed sequential logic,  which contains both combinational logic and memory  components.  The combinational logic cloud is an acyclic graph ", "of components that obeys the static discipline.  The static discipline guarantees if we supply valid and stable  digital inputs, then we will get valid and stable  digital outputs by some specified ", "interval after the last input transition.  Theres also a functional specification that tells us  the output values for every possible combination of input  values. ", "In this diagram, there are k+m inputs and k+n outputs,  so the truth table for the combinational logic will have  2^(k+m) rows and k+n output columns. ", "The job of the state registers is  to remember the current state of the sequential logic.  The state is encoded as some number k of bits,  which will allow us to represent 2^k unique states. ", "Recall that the state is used to capture,  in some appropriate way, the relevant history of the input  sequence.  To the extent that previous input values influence  the operation of the sequential logic, ", "that happens through the stored state bits.  Typically the LOAD input of the state registers  is triggered by the rising edge of a periodic signal, which  updates the stored state with the new state calculated ", "by the combinational logic.  As designers we have several tasks:  first we must decide what output sequences  need to be generated in response to the expected input ", "sequences.  A particular input may, in fact, generate a long sequence  of output values.  Or the output may remain unchanged ", "while the input sequence is processed, step-by-step,  where the FSM is remembering the relevant information  by updating its internal state.  Then we have to develop the functional specification ", "for the logic so it calculates the correct output  and next state values.  Finally, we need to come up with an actual circuit diagram  for sequential logic system. ", "All the tasks are pretty interesting,  so lets get started!  As an example sequential system, lets make a combination lock.  The lock has a 1-bit input signal, ", "where the user enters the combination  as a sequence of bits.  Theres one output signal, UNLOCK,  which is 1 if and only if the correct combination has been  entered. ", "In this example, we want to assert UNLOCK, i.e.,  set UNLOCK to 1, when the last four input values are  the sequence 0-1-1-0.  Mr. Blue is asking a good question: ", "how many state bits do we need?  Do we have to remember the last four input bits?  In which case, wed need four state bits.  Or can we remember less information ", "and still do our job?  Aha!  We dont need the complete history of the last four  inputs, we only need to know if the most recent entries  represent some part of a partially-entered correct ", "combination.  In other words if the input sequence doesnt represent  a correct combination, we dont need to keep track of exactly  how its incorrect, we only need to know that is incorrect. ", "With that observation in mind, lets figure out how  to represent the desired behavior of our digital system.  We can characterize the behavior of a sequential system using  a new abstraction called a finite state machine, ", "or FSM for short.  The goal of the FSM abstraction is  to describe the input/output behavior  of the sequential logic, independent  of its actual implementation. ", "A finite state machine has a periodic CLOCK input.  A rising clock edge will trigger the transition  from the current state to the next state.  The FSM has a some fixed number of states, ", "with a particular state designated  as the initial or starting state when  the FSM is first turned on.  One of the interesting challenges in designing an FSM ", "is to determine the required number of states since theres  often a tradeoff between the number of state bits  and the complexity of the internal combinational logic  required to compute the next state and outputs. ", "There are some number of inputs, used  to convey all the external information  necessary for the FSM to do its job.  Again, there are interesting design tradeoffs. ", "Suppose the FSM required 100 bits of input.  Should we have 100 inputs and deliver the information  all at once?  Or should we have a single input and deliver the information ", "as a 100-cycle sequence?  In many real world situations where the sequential logic is  *much* faster than whatever physical process were trying  to control, ", "well often see the use of bit-serial inputs where  the information arrives as a sequence, one bit at a time.  That will allow us to use much less signaling hardware,  at the cost of the time required to transmit ", "the information sequentially.  The FSM has some number outputs to convey the results  of the sequential logics computations.  The comment before about serial vs. parallel inputs ", "applies equally to choosing how information should  be encoded on the outputs.  There are a set of transition rules,  specifying how the next state S-prime is  determined from the current state S and the inputs I. ", "The specification must be complete,  enumerating S-prime for every possible combination  of S and I.  And, finally, theres the specification for how  the output values should be determined. ", "The FSM design is often a bit simpler  if the outputs are strictly a function of the current state  S, but, in general, the outputs can  be a function of both S and the current inputs. ", "Now that we have our abstraction in place,   We'll describe the operation of the FSM for our combination lock using a state transition ", "diagram.  Initially, the FSM has received no bits of the combination, a state we'll call SX.  In the state transition diagram, states are represented as circles, each labeled for now ", "with a symbolic name chosen to remind us of what history it represents.  For this FSM, the unlock output U will be a function of the current state, so we'll ", "indicate the value of U inside the circle.  Since in state SX we know nothing about past input bits, the lock should stay locked and  so U = 0. ", "We'll indicate the initial state with a wide border on the circle.  We'll use the successive states to remember what we've seen so far of the input combination. ", "So if the FSM is in state SX and it receives a 0 input, it should transition to state S0  to remind us that we've seen the first bit of the combination of 0-1-1-0. ", "We use arrows to indicate transitions between states and each arrow has a label telling  us when that transition should occur.  So this particular arrow is telling us that when the FSM is in state SX and the next input ", "is a 0, the FSM should transition to state S0.  Transitions are triggered by the rising edge of the FSM's clock input. ", "Let's add the states for the remainder of the specified combination.  The rightmost state, S0110, represents the point at which the FSM has detected the specified ", "sequence of inputs, so the unlock signal is 1 in this state.  Looking at the state transition diagram, we see that if the FSM starts in state SX, the ", "input sequence 0-1-1-0 will leave the FSM in state S0110.  So far, so good.  What should the FSM do if an input bit is not the next bit in the combination? ", "For example, if the FSM is in state SX and the input bit is a 1, it still has not received  any correct combination bits, so the next state is SX again. ", "Here are the appropriate non-combination transitions for the other states.  Note that an incorrect combination entry doesn't necessarily take the FSM to state SX. ", "For example, if the FSM is in state S0110, the last four input bits have been 0-1-1-0.  If the next input is a 1, then the last four inputs bits are now 1-1-0-1, which won't lead ", "to an open lock.  But the last two bits might be the first two bits of a valid combination sequence and so  the FSM transitions to S01, indicating that a sequence of 0-1 has been entered over the ", "last two bits.  We've been working with an FSM where the outputs are function of the current state, called  a Moore machine.  Here the outputs are written inside the state circle. ", "If the outputs are a function of both the current state and the current inputs, it's  called a Mealy machine.  Since the transitions are also a function of the current state and current inputs, we'll ", "label each transition with appropriate output values using a slash to separate input values  from output values.  So, looking at the state transition diagram on the right, suppose the FSM is in state ", "S3.  If the input is a 0, look for the arrow leaving S3 labeled \"0/\".  The value after the slash tells us the output value, in this case 1. ", "If the input had been a 1, the output value would be 0.  There are some simple rules we can use to check that a state transition diagram is well  formed. ", "The transitions from a particular state must be mutually exclusive, i.e., for a each state,  there can't be more than one transition with the same input label.  This makes sense: if the FSM is to operate consistently there can't be any ambiguity ", "about the next state for a given current state and input.  By \"consistently\" we mean that the FSM should make the same transitions if it's restarted  at the same starting state and given the same input sequences. ", "Moreover, the transitions leaving each state should be collectively exhaustive, i.e., there  should a transition specified for each possible input value. ", "If we wish the FSM to stay in it's current state for that particular input value, we  need to show a transition from the current state back to itself.  With these rules there will be exactly one transition selected for every combination ", "of current state and input value.  All the information in a state transition diagram can be represented in tabular form  as a truth table. ", "The rows of the truth table list all the possible combinations of current state and inputs.  And the output columns of the truth table tell us the next state and output value associated ", "with each row.  If we substitute binary values for the symbolic state names, we end up with a truth table  just like the ones we saw in Chapter 4. ", "If we have K states in our state transition diagram we'll need log_2(K) state bits, rounded  up to the next integer since we don't have fractional bits!  In our example, we have a 5-state FSM, so we'll need 3 state bits. ", "We can assign the state encodings in any convenient way, e.g., 000 for the first state, 001 for  the second state, and so on.  But the choice of state encodings can have a big effect on the logic needed to implement ", "the truth table.  It's actually fun to figure out the state encoding that produces the simplest possible  logic.  With a truth table in hand, we can use the techniques from Chapter 4 to design logic ", "circuits that implement the combinational logic for the FSM.  Of course, we can take the easy way out and simply use a read-only memory to do the job! ", "In this circuit, a read-only memory is used to compute the next state and outputs from  the current state and inputs.  We're encoding the 5 states of the FSM using a 3-bit binary value, so we have a 3-bit state ", "register.  The rectangle with the edge-triggered input is schematic shorthand for a multi-bit register.  If a wire in the diagram represents a multi-bit signal, we use a little slash across the wire ", "with a number to indicate how many bits are in the signal.  In this example, both current_state and next_state are 3-bit signals.  The read-only memory has a total of 4 input signals - 3 for the current state and 1 for ", "the input value - so the read-only memory has 2^4 or 16 locations,  which correspond to the 16 rows in the truth table.  Each location in the ROM supplies the output values for a particular row of the truth table. ", "Since we have 4 output signals - 3 for the next state and 1 for the output value - each  location supplies 4 bits of information.  Memories are often annotated with their number of locations and the number of bits in each ", "location.  So our memory is a 16-by-4 ROM: 16 locations of 4-bits each.  Of course, in order for the state registers to work correctly, we need to ensure that ", "the dynamic discipline is obeyed.  We can use the timing analysis techniques described at the end of Chapter 5 to check  that this is so.  For now, we'll assume that the timing of transitions on the inputs are properly synchronized with ", "the rising edges of the clock.  So now we have the FSM abstraction to use when designing the functionality of a sequential  logic system, and a general-purpose circuit implementation of the FSM using a ROM and ", "a multi-bit state register.  Recapping our design choices: the output bits can be strictly a function of the current  state (the FSM would then be called a Moore machine), ", "or they can be a function of both the current state and current inputs, in which case the  FSM is called a Mealy machine.  We can choose the number of state bits - S state bits will give us the ability to encode ", "2^S possible states.  Note that each extra state bit DOUBLES the number of locations in the ROM!  So when using ROMs to implement the necessary logic, we're very interested in minimizing ", "the number of state bits.  The waveforms for our circuitry are pretty straightforward.  The rising edge of the clock triggers a transition in the state register outputs. ", "The ROM then does its thing, calculating the next state, which becomes valid at some point  in the clock cycle.  This is the value that gets loaded into the state registers at the next rising clock edge. ", "This process repeats over-and-over as the FSM follows the state transitions dictated  by the state transition diagram.  There are a few housekeeping details that need our attention. ", "On start-up we need some way to set the initial contents of the state register to the correct  encoding for the initial state.  Many designs use a RESET signal that's set to 1 to force some initial state and then ", "set to 0 to start execution.  We could adopt that approach here, using the RESET signal to select an initial value to  be loaded into the state register. ", "In our example, we used a 3-bit state encoding which would allow us to implement an FSM with  up to 2^3 = 8 states.  We're only using 5 of these encodings, which means there are locations in the ROM we'll ", "never access.  If that's a concern, we can always use logic gates to implement the necessary combinational  logic instead of ROMs. ", "Suppose the state register somehow got loaded with one of the unused encodings?  Well, that would be like being in a state that's not listed in our state transition  diagram. ", "One way to defend against this problem is design the ROM contents so that unused states  always point to the initial state.  In theory the problem should never arise, but with this fix at least it won't lead to ", "unknown behavior.  We mentioned earlier the interesting problem of finding a state encoding that minimized  the combinational logic. ", "There are computer-aided design tools to help do this as part of the larger problem of finding  minimal logic implementations for Boolean functions. ", "Mr. Blue is showing us another approach to building the state register for the combination  lock: use a shift register to capture the last four  input bits, then simply look at the recorded history to determine if it matches the combination. ", "No fancy next0state logic here!  Finally, we still have to address the problem of ensuring that input transitions don't violate  the dynamic discipline for the state register. ", "We'll get to this in the last section of this chapter.   Lets think a bit more about the FSM abstraction.  If we see an FSM that uses K state bits, ", "what can we say about the number of states in its state  transition diagram?  Well, we know the FSM can have at most 2^K states,  since thats the number of unique combinations of K bits. ", "Suppose we connect two FSMs in series,  with the outputs of the first FSM serving as the inputs  to the second.  This larger system is also an FSM  how many states does it ", "have?  Well, if we dont know the details of either  of the component FSMs, the upper bound on the number of states  for the larger system is M*N. ", "This is because it may be possible for the first FSM  to be in any of its M states while the second FSM is  any of its N states.  Note that the answer doesnt depend on X or Y, ", "the number of input signals to each of the component FSMs.  Wider inputs just mean that there are longer labels  on the transitions in the state transition diagram, ", "but doesnt tell us anything about the number of internal  states.  Finally, heres a question thats a bit trickier than it  seems.  I give you an FSM with two inputs labeled 0 and 1, ", "and one output implemented as a light.  Then I ask you to discover its state transition diagram.  Can you do it?  Just to be a bit more concrete, you ", "experiment for an hour pushing the buttons  in a variety of sequences.  Each time you push the 0 button the light turns off  if it was on. ", "And when you push the 1 button the light turns on  if it was off, otherwise nothing seems to happen.  What state transition diagram could we  draw based on our experiments? ", "Consider the following two state transition diagrams.  The top diagram describes the behavior  we observed in our experiments: pushing 0 turns the light off, ", "pushing 1 turns the light on.  The second diagram appears to do the same thing  unless you happened to push the 1 button 4 times in a row! ", "If we dont have an upper bound on the number of states  in the FSM, we can never be sure that weve explored all of its  possible behaviors.  But if we do have an upper bound, say, K, ", "on the number of states and we reset the FSM  to its initial state, we can discover its behavior.  This is because in a K-state FSM every reachable state ", "can reached in less than K transitions,  starting from the initial state.  .244 So if we try all the possible K-step input sequences  one after the other starting each trial at the initial ", "state, well be guaranteed to have visited every state  in the machine.  Our answer is also complicated by the observation  that FSMs with different number of states may be equivalent. ", "Here are two FSMs, one with 2 states, one with 5 states.  Are they different?  Well, not in any practical sense.  Since the FSMs are externally indistinguishable, ", "we can use them interchangeably.  We say that two FSMs are equivalent if  and only if every input sequence yields identical output  sequences from both FSMs. ", "So as engineers, if we have an FSM  we would like to find the the simplest (and hence the least  expensive) equivalent FSM.  Well talk about how to find smaller equivalent FSMs ", " Surprise!  We've just been given a robotic ant that has an FSM for its brain.  The inputs to the FSM come from the ant's two antennae, labeled L and R. ", "An antenna input is 1 if the antenna is touching something, otherwise its 0.  The outputs of the FSM control the ant's motion.  We can make it step forward by setting the F output to 1, and turn left or right by asserting ", "the TL or TR outputs respectively.  If the ant tries to both turn and step forward, the turn happens first.  Note that the ant can turn when its antenna are touching something, but it can't move ", "forward.  We've been challenged to design an ant brain that will let it find its way out of a simple  maze like the one shown here.  We remember reading that if the maze doesn't have any unconnected walls (i.e.,no islands), ", "we can escape using the \"right hand rule\" where we put our right hand on the wall and  walk so that our hand stays on the wall.  Let's try to implement this strategy. ", "We'll assume that initially our ant is lost in space.  The only sensible strategy to walk forward until we find a maze wall.  So our initial state, labeled LOST, asserts the F output, causing the ant to move forward ", "until at least one of the antennae touches something, i.e., at least one of the L or  R inputs is a 1.  So now the ant finds itself in one of these three situations. ", "To implement the \"right hand rule\", the ant should turn left (counterclockwise) until  it's antennae have just cleared the wall.  To do this, we'll add a rotate-counterclockwise state, which asserts the turn-left output ", "until both L and R are 0.  Now the ant is standing with a wall to its right and we can start the process of following  the wall with its right antenna. ", "So we have the ant step forward and right, assuming that it will immediately touch the  wall again.  The WALL1 state asserts both the turn-right and forward outputs, then checks the right ", "antenna to see what to do next.  If the right antenna does touch, as expected, the ant turns left to free the antenna and  then steps forward. ", "The WALL2 state asserts both the turn-left and forward outputs, then checks the antennae.  If the right antenna is still touching, it needs to continue turning. ", "If the left antenna touches, it's run into a corner and needs to reorient itself so the  new wall is on its right, the situation we dealt with the rotate-counterclockwise state. ", "Finally, if both antennae are free, the ant should be in the state of the previous slide:  standing parallel to the wall, so we return the WALL1 state. ", "Our expectation is that the FSM will alternate between the WALL1 and WALL2 states as the  ant moves along the wall.  If it reaches an inside corner, it rotates to put the new wall on its right and keeps ", "going.  What happens when it reaches an outside corner?  When the ant is in the WALL1 state, it moves forward and turns right, then checks its right ", "antenna, expecting the find the wall its traveling along.  But if its an outside corner, there's no wall to touch!  The correct strategy in this case is to keep turning right and stepping forward until the ", "right antenna touches the wall that's around the corner.  The CORNER state implements this strategy, transitioning to the WALL2 state when the  ant reaches the wall again. ", "Hey, this might even work!  Let's try it out  Meet the Roboant simulator.  On the left we see a text representation of the transition table for the FSM brain. ", "Each action line specifies an input pattern, which, if it matches, will set the next state  and output signals as specified.  This particular version of Roboant allows the ant to drop or pickup breadcrumbs, and ", "to sense breadcrumbs it comes across - these inputs and outputs aren't needed for this  demo.  The input pattern specifies a value for the current state and antenna inputs. ", "The simulator highlights the row in the table that matches the current inputs.  As you can see, initially the ant is the LOST state with neither antennae touching. ", "On the right is a map showing our green ant standing in a maze with blue walls.  We can select several different mazes to try.  To see the ant in action, let's click the STEP button several times. ", "After a few steps, the ant hits the wall, then rotates counterclockwise to free its  antenna.  Now it starts following the wall until it reaches a corner, at which point it keeps ", "turning right and stepping until it's once again in contact with the wall.  Now we'll let it run and watch as the FSM patiently pursues the programmed strategy, ", "responding to inputs and generating the appropriate output responses.  With more sensors and actuators, you can see that fairly sophisticated behaviors and responses ", "would be possible.  In essence this is exactly what modern robots do - they too have FSM brains full of pre-programmed  behaviors that let them perform their assigned tasks. ", "Neat!   Earlier we talked about about finding equivalent FSMs with fewer states.  Now we'll develop an approach for finding such FSMs by looking for two states that that ", "can be merged into a single state without changing the behavior of the FSM in any externally  distinguishable manner.  Two states are equivalent if they meet the following two criteria. ", "First, the states must have identical outputs.  This makes sense: the outputs are visible to the outside, so if their values differed  between the two states, that difference would clearly be externally distinguishable! ", "Second, for each combination of input values, the two states transition to equivalent states.  Our strategy for deriving an equivalent machine with fewer states will be to start with our ", "original FSM, find pairs of equivalent states and merge those states.  We'll keep repeating the process until we can't find any more equivalent states. ", "Let's try this on our ant FSM.  First we need to find a pair of states that have the same outputs.  As it turns out, there's only one such pair: WALL1 and CORNER, both of which assert the ", "turn-right and forward outputs.  Okay, so let's assume that WALL1 and CORNER are equivalent and ask if they transition  to equivalent states for each applicable combination of input values. ", "For these two states, all the transitions depend only on the value of the R input, so  we just have to check two cases.  If R is 0, both states transition to CORNER. ", "If R is 1, both states transition to WALL2.  So both equivalence criteria are satisfied and we can conclude that the WALL1 and CORNER ", "states are equivalent and can be merged.  This gives us the four-state FSM shown here, where we've called the single merged state  WALL1. ", "This smaller, equivalent FSM behaves exactly as the previous 5-state FSM.  The implementation of the 5-state machine requires 3 state bits; the implementation ", "of the 4-state machine only requires 2 state bits.  Reducing the number of state bits by 1 is huge since it reduces the size of the required  ROM by half! ", "Just as we were able to achieve considerable hardware savings by minimizing Boolean equations,  we can do the same in sequential logic by merging equivalent states. ", "Roboant customers are looking forward to the price cut!  Let's look at what we'd need to do if we wanted to implement the FSM using logic gates instead  a ROM for the combinational logic. ", "First we have to build the truth table, entering all the transitions in the state transition  diagram.  We'll start with the LOST state.  So if the FSM is in this state, the F output should be 1. ", "If both antenna inputs are 0, the next state is also LOST.  Assigning the LOST state the encoding 00, we've captured this information in the first ", "row of the table.  If either antenna is touching, the FSM should transition from LOST to the rotate-counterclockwise  state. ", "We've given this an encoding of 01.  There are three combinations of L and R values that match this transition, so we've added  three rows to the truth table. ", "This takes care of all the transitions from the LOST state.  Now we can tackle the transitions from the rotate-counterclockwise state.  If either antenna is touching, the next state is again rotate-counterclockwise. ", "So we've identified the matching values for the inputs and added the appropriate three  rows to the transition table.  We can continue in a similar manner to encode the transitions one-by-one. ", "Here's the final table, where we've used don't cares to reduce the number of rows for presentation.  Next we want to come up with Boolean equations for each of the outputs of the combinational ", "logic, i.e., the two next-state bits and the three motion-control outputs.  Here are the Karnaugh maps for the two next-state bits. ", "Using our K-map skills from Chapter 4, we'll find a cover of the prime implicants for S1-prime  and write down the corresponding product terms in a minimal sum-of-products equation. ", "And then do the same for the other next-state bit.  We can follow a similar process to derive minimal sum-of-products expressions for the  motion-control outputs. ", "Implementing each sum-of-products in a straight-forward fashion with AND and OR gates, we get the  following schematic for the ant brain.  Pretty neat!  Who knew that maze following behavior could be implemented with a couple of D registers ", "and a handful of logic gates?  There are many complex behaviors that can be created with surprisingly simple FSMs.  Early on, the computer graphics folks learned that group behaviors like swarming, flocking ", "and schooling can be modeled by equipping each participant with a simple FSM.  So next time you see the massive battle scene from the Lord of the Rings movie, think of  many FSMs running in parallel! ", "Physical behaviors that arise from simple interactions between component molecules can  sometimes be more easily modeled using cellular automata -  arrays of communicating FSMS - than by trying to solve the partial differential equations ", "that model the constraints on the molecules' behavior.  And here's an idea: what if we allowed the FSM to modify its own transition table? ", "Hmm.  Maybe that's a plausible model for evolution!  FSMs are everywhere!  You'll see FSMs for the rest of your life ", " Okay, it's finally time to investigate issues caused by asynchronous inputs to a sequential  logic circuit.  By \"asynchronous\" we mean that the timing of transitions on the input is completely ", "independent of the timing of the sequential logic clock.  This situation arises when the inputs arrive from the outside world where the timing of  events is not under our control. ", "As we saw at the end of Chapter 5, to ensure reliable operation of the state registers  inputs to a sequential logic system have to obey setup and hold time constraints relative ", "to the rising edge of the system clock.  Clearly if the input can change at anytime, it can change at time that would violate the  setup and hold times.  Maybe we can come up with a synchronizer circuit that takes an unsynchronized input signal ", "and produces a synchronized signal that only changes shortly after the rising edge of the  clock.  We'd use a synchronizer on each asynchronous input and solve our timing problems that way. ", "Here's a detailed specification for our synchronizer.  The synchronizer has two inputs, IN and CLK, which have transitions at time t_IN and t_C ", "respectively.  If IN's transition happens sufficiently before C's transition, we want the synchronizer to  output a 1 within some bounded time t_D after CLK's transition. ", "And if CLK's transition happens sufficient before IN's transition, we want the synchronizer  to output a 0 within time t_D after CLK's transition.  Finally, if the two transitions are closer together than some specified interval t_E, ", "the synchronizer can output either a 0 or a 1 within time t_D of CLK's transition.  Either answer is fine so long as it's a stable digital 0 or digital 1 by the specified deadline. ", "This turns out to be an unsolvable problem!  For no finite values of t_E and t_D can we build a synchronizer that's guaranteed to  meet this specification even when using components that are 100% reliable. ", "But can't we just use a D register to solve the problem?  We'll connect IN to the register's data input and connect CLK to the register's clock input.  We'll set the decision time t_D to the propagation delay of the register and the allowable error ", "interval to the larger of the register's setup and hold times.  Our theory is that if the rising edge of IN occurs at least t_SETUP before the rising ", "edge of CLK, the register is guaranteed to output a 1.  And if IN transitions more than t_HOLD after the rising edge of CLK, the register is guaranteed ", "to output a 0.  So far, so good.  If IN transitions during the setup and hold times with respect to the rising edge on CLK,  we know we've violated the dynamic discipline and we can't tell whether the register will ", "store a 0 or a 1.  But in this case, our specification lets us produce either answer, so we're good to go,  right?  Sadly, we're not good to go. ", "We're lured by the digital abstraction into assuming that even if we violate the dynamic  discipline that Q must be either 1 or 0 after the propagation delay. ", "But that isn't a valid assumption as we'll see when we look more carefully at the operation  of the register's master latch when B and C change at about the same time. ", "Recall that the master latch is really just a lenient MUX that can be configured as a  bi-stable storage element using a positive feedback loop.  When the latch is in memory mode, it's essentially a two-gate cyclic circuit whose behavior has ", "two constraints: the voltage transfer characteristic of the  two-gate circuit, shown in green on the graph, and that V_IN = V_OUT, a constraint that's  shown in red on the graph. ", "These two curves intersect at three points.  Our concern is the middle point of intersection.  If IN and CLK change at the same time, the voltage on Q may be in transition at the time ", "the MUX closes and enables the positive feedback loop.  So the initial voltage in the feedback loop may happen to be at or very near the voltage  of the middle intersection point. ", "When Q is at the metastable voltage, the storage loop is in an unstable equilibrium called  the metastable state.  In theory the system could balance at this point forever, but a small change in the voltages ", "in the loop will move the system away from the metastable equilibrium point and set it  irrevocably in motion towards the stable equilibrium points.  Here's the issue we face: we can't bound the amount of time the system will spend in the ", "metastable state.  Here's what we know about the metastable state.  It's in the forbidden zone of the digital signaling specifications and so corresponds  to an invalid logic level. ", "Violating the dynamic discipline means that our register is no longer guaranteed to produce  a digital output in bounded time.  A persistent invalid logic level can wreak both logical and electrical havoc in our sequential ", "logic circuit.  Since combinational logic gates with invalid inputs have unpredictable outputs, an invalid  signal may corrupt the state and output values in our sequential system. ", "At the electrical level, if an input to a CMOS gate is at the metastable voltage, both  PFET and NFET switches controlled by that input would be conducting, so we'd have a ", "path between V_DD and GROUND, causing a spike in the system's power dissipation.  It's an unstable equilibrium and will eventually be resolved by a transition to one of the ", "two stable equilibrium points.  You can see from the graph that the metastable voltage is in the high-gain region of the  VTC, so a small change in V_IN results in a large change in V_OUT, and once away from ", "the metastable point the loop voltage will move towards 0 or V_DD.  The time it takes for the system to evolve to a stable equilibrium is related to how ", "close Q's voltage was to the metastable point when the positive feedback loop was enabled.  The closer Q's initial voltage is to the metastable voltage, the longer it will take for the system ", "to resolve the metastability.  But since there's no lower bound on how close Q is to the metastable voltage, there's no  upper bound on the time it will take for resolution. ", "In other words, if you specify a bound, e.g., t_D, on the time available for resolution,  there's a range of initial Q voltages that won't be resolved within that time. ", "If the system goes metastable at some point in time, then there's a non-zero probability  that the system will still be metastable after some interval T, for any finite choice of ", "T. The good news is that the probability of being  metastable at the end of the interval decreases exponentially with increasing T. ", "Note that every bistable system has at least one metastable state.  So metastability is the price we pay for building storage elements from positive feedback loops. ", "If you'd like to read a more thorough discussion of synchronizers and related problems and  learn about the mathematics behind the exponential probabilities, please see Chapter 10 of the  Course Notes. ", "Our approach to dealing with asynchronous inputs is to put the potentially metastable  value coming out of our D-register synchronizer into \"quarantine\" by adding a second register ", "hooked to the output of the first register.  If a transition on the input violates the dynamic discipline and causes the first register  to go metastable, it's not immediately an issue since the metastable value is stopped ", "from entering the system by the second register.  In fact, during the first half of the clock cycle, the master latch in the second register  is closed, so the metastable value is being completely ignored. ", "It's only at the next clock edge, an entire clock period later, that the second D register  will need a valid and stable input.  There's still some probability that the first register will be metastable after an entire ", "clock period, but we can make that probability as low as we wish by choosing a sufficiently  long clock period.  In other words, the output of the second register, which provides the signal used by the internal ", "combinational logic, will be stable and valid with a probability of our choosing.  Validity is not 100% guaranteed, but the failure times are measured in years or decades, so ", "it's not an issue in practice.  Without the second register, the system might see a metastability failure every handful  of hours - the exact failure rate depends on the transition frequencies and gains in ", "the circuit.  What happens if our clock period is short but we want a long quarantine time?  We can use multiple quarantine registers in series. ", "It's the total delay between when the first register goes metastable and when the synchronized  input is used by the internal logic that determines the failure probability. ", "The bottom line?  We can use synchronizing registers to quarantine potentially metastable signals for some period  of time.  Since the probability of still being metastable decreases exponentially with the quarantine ", "time, we can reduce the failure probability to any desired level.  Not a 100% guaranteed, but close enough that metastability is not a practical issue if ", "we use our quarantine strategy. "], "vid_duration": [10.75, 11.28, 10.229, 15.131, 12.26, 11.28, 12.13, 12.27, 10.03, 11.43, 10.848, 10.642, 11.21, 12.34, 11.04, 10.93, 13.05, 12.67, 11.5, 10.68, 10.08, 12.0, 10.65, 11.83, 10.25, 12.21, 12.86, 13.39, 12.59, 12.4, 12.425, 12.271, 11.521, 11.299, 10.73, 12.9, 13.039, 10.161, 10.4, 11.679, 13.19, 11.91, 11.11, 16.131, 14.14, 12.429, 10.441, 13.139, 12.34, 11.341, 14.859, 13.391, 11.78, 13.829, 10.801, 10.09, 10.93, 16.36, 13.62, 12.469, 10.271, 12.62, 12.619, 14.591, 15.84, 14.25, 13.09, 14.04, 13.11, 10.99, 12.27, 12.93, 12.72, 12.45, 12.07, 12.3, 12.37, 12.88, 10.22, 10.4, 13.14, 10.73, 10.03, 13.98, 10.679, 11.064, 13.481, 12.069, 11.071, 12.5, 10.64, 13.96, 10.79, 10.809, 12.191, 10.2, 11.609, 12.091, 10.73, 11.86, 14.16, 12.429, 11.121, 12.2, 12.878, 14.812, 13.07, 15.92, 12.139, 14.601, 13.85, 13.29, 11.47, 10.578, 11.582, 10.07, 11.539, 10.101, 12.439, 10.99, 11.99, 10.27, 13.019, 13.891, 12.001, 12.91, 13.219, 10.881, 11.15, 10.38, 12.43, 12.506, 12.58, 14.54, 13.069, 11.851, 11.159, 14.661, 11.23, 10.27, 10.329, 11.241, 11.84, 10.91, 12.9, 12.42, 10.04, 10.119, 12.261, 14.2, 13.45, 10.55, 11.199, 12.261, 10.66, 14.299, 15.161, 13.6, 14.81, 10.38, 10.196, 12.53, 11.509, 11.0, 15.0, 12.221, 10.42, 12.54, 16.019, 14.38, 15.511, 15.12, 10.66, 11.01, 13.73, 12.25, 10.46, 10.97, 13.9, 11.94, 12.14, 12.28, 12.09, 13.31, 12.929, 12.951, 13.06, 10.449, 12.021, 13.84, 11.079, 12.121, 11.539, 12.731, 10.509, 10.0, 10.6, 11.711, 10.18, 14.129, 12.8, 12.27, 12.82, 12.551, 12.238, 11.602, 10.35, 13.53, 10.24, 2.347], "stet": [[0, 10.75], [10.75, 22.03], [22.03, 32.259], [32.259, 47.39], [47.39, 59.65], [59.65, 70.92999999999999], [70.92999999999999, 83.05999999999999], [83.05999999999999, 95.32999999999998], [95.32999999999998, 105.35999999999999], [105.35999999999999, 116.78999999999999], [116.78999999999999, 127.63799999999999], [127.63799999999999, 138.28], [138.28, 149.49], [149.49, 161.83], [161.83, 172.87], [172.87, 183.8], [183.8, 196.85000000000002], [196.85000000000002, 209.52], [209.52, 221.02], [221.02, 231.70000000000002], [231.70000000000002, 241.78000000000003], [241.78000000000003, 253.78000000000003], [253.78000000000003, 264.43], [264.43, 276.26], [276.26, 286.51], [286.51, 298.71999999999997], [298.71999999999997, 311.58], [311.58, 324.96999999999997], [324.96999999999997, 337.55999999999995], [337.55999999999995, 349.9599999999999], [349.9599999999999, 362.38499999999993], [362.38499999999993, 374.65599999999995], [374.65599999999995, 386.17699999999996], [386.17699999999996, 397.47599999999994], [397.47599999999994, 408.20599999999996], [408.20599999999996, 421.10599999999994], [421.10599999999994, 434.1449999999999], [434.1449999999999, 444.3059999999999], [444.3059999999999, 454.7059999999999], [454.7059999999999, 466.3849999999999], [466.3849999999999, 479.5749999999999], [479.5749999999999, 491.4849999999999], [491.4849999999999, 502.5949999999999], [502.5949999999999, 518.7259999999999], [518.7259999999999, 532.8659999999999], [532.8659999999999, 545.2949999999998], [545.2949999999998, 555.7359999999999], [555.7359999999999, 568.8749999999999], [568.8749999999999, 581.2149999999999], [581.2149999999999, 592.5559999999999], [592.5559999999999, 607.415], [607.415, 620.8059999999999], [620.8059999999999, 632.5859999999999], [632.5859999999999, 646.4149999999998], [646.4149999999998, 657.2159999999999], [657.2159999999999, 667.3059999999999], [667.3059999999999, 678.2359999999999], [678.2359999999999, 694.5959999999999], [694.5959999999999, 708.2159999999999], [708.2159999999999, 720.685], [720.685, 730.9559999999999], [730.9559999999999, 743.5759999999999], [743.5759999999999, 756.1949999999999], [756.1949999999999, 770.786], [770.786, 786.626], [786.626, 800.876], [800.876, 813.966], [813.966, 828.006], [828.006, 841.116], [841.116, 852.106], [852.106, 864.376], [864.376, 877.3059999999999], [877.3059999999999, 890.026], [890.026, 902.476], [902.476, 914.546], [914.546, 926.846], [926.846, 939.216], [939.216, 952.096], [952.096, 962.316], [962.316, 972.716], [972.716, 985.856], [985.856, 996.586], [996.586, 1006.616], [1006.616, 1020.596], [1020.596, 1031.275], [1031.275, 1042.3390000000002], [1042.3390000000002, 1055.8200000000002], [1055.8200000000002, 1067.8890000000001], [1067.8890000000001, 1078.96], [1078.96, 1091.46], [1091.46, 1102.1000000000001], [1102.1000000000001, 1116.0600000000002], [1116.0600000000002, 1126.8500000000001], [1126.8500000000001, 1137.659], [1137.659, 1149.8500000000001], [1149.8500000000001, 1160.0500000000002], [1160.0500000000002, 1171.659], [1171.659, 1183.75], [1183.75, 1194.48], [1194.48, 1206.34], [1206.34, 1220.5], [1220.5, 1232.929], [1232.929, 1244.0500000000002], [1244.0500000000002, 1256.2500000000002], [1256.2500000000002, 1269.1280000000002], [1269.1280000000002, 1283.94], [1283.94, 1297.01], [1297.01, 1312.93], [1312.93, 1325.069], [1325.069, 1339.67], [1339.67, 1353.52], [1353.52, 1366.81], [1366.81, 1378.28], [1378.28, 1388.858], [1388.858, 1400.44], [1400.44, 1410.51], [1410.51, 1422.049], [1422.049, 1432.15], [1432.15, 1444.5890000000002], [1444.5890000000002, 1455.5790000000002], [1455.5790000000002, 1467.5690000000002], [1467.5690000000002, 1477.8390000000002], [1477.8390000000002, 1490.8580000000002], [1490.8580000000002, 1504.7490000000003], [1504.7490000000003, 1516.7500000000002], [1516.7500000000002, 1529.6600000000003], [1529.6600000000003, 1542.8790000000004], [1542.8790000000004, 1553.7600000000004], [1553.7600000000004, 1564.9100000000005], [1564.9100000000005, 1575.2900000000006], [1575.2900000000006, 1587.7200000000007], [1587.7200000000007, 1600.2260000000008], [1600.2260000000008, 1612.8060000000007], [1612.8060000000007, 1627.3460000000007], [1627.3460000000007, 1640.4150000000006], [1640.4150000000006, 1652.2660000000008], [1652.2660000000008, 1663.4250000000009], [1663.4250000000009, 1678.086000000001], [1678.086000000001, 1689.316000000001], [1689.316000000001, 1699.586000000001], [1699.586000000001, 1709.9150000000009], [1709.9150000000009, 1721.1560000000009], [1721.1560000000009, 1732.9960000000008], [1732.9960000000008, 1743.9060000000009], [1743.9060000000009, 1756.806000000001], [1756.806000000001, 1769.226000000001], [1769.226000000001, 1779.266000000001], [1779.266000000001, 1789.385000000001], [1789.385000000001, 1801.6460000000009], [1801.6460000000009, 1815.846000000001], [1815.846000000001, 1829.296000000001], [1829.296000000001, 1839.846000000001], [1839.846000000001, 1851.045000000001], [1851.045000000001, 1863.306000000001], [1863.306000000001, 1873.966000000001], [1873.966000000001, 1888.265000000001], [1888.265000000001, 1903.426000000001], [1903.426000000001, 1917.026000000001], [1917.026000000001, 1931.836000000001], [1931.836000000001, 1942.216000000001], [1942.216000000001, 1952.412000000001], [1952.412000000001, 1964.942000000001], [1964.942000000001, 1976.451000000001], [1976.451000000001, 1987.451000000001], [1987.451000000001, 2002.451000000001], [2002.451000000001, 2014.672000000001], [2014.672000000001, 2025.092000000001], [2025.092000000001, 2037.632000000001], [2037.632000000001, 2053.6510000000007], [2053.6510000000007, 2068.031000000001], [2068.031000000001, 2083.542000000001], [2083.542000000001, 2098.6620000000007], [2098.6620000000007, 2109.3220000000006], [2109.3220000000006, 2120.332000000001], [2120.332000000001, 2134.062000000001], [2134.062000000001, 2146.312000000001], [2146.312000000001, 2156.772000000001], [2156.772000000001, 2167.7420000000006], [2167.7420000000006, 2181.6420000000007], [2181.6420000000007, 2193.582000000001], [2193.582000000001, 2205.7220000000007], [2205.7220000000007, 2218.002000000001], [2218.002000000001, 2230.092000000001], [2230.092000000001, 2243.402000000001], [2243.402000000001, 2256.331000000001], [2256.331000000001, 2269.282000000001], [2269.282000000001, 2282.342000000001], [2282.342000000001, 2292.791000000001], [2292.791000000001, 2304.8120000000013], [2304.8120000000013, 2318.6520000000014], [2318.6520000000014, 2329.7310000000016], [2329.7310000000016, 2341.8520000000017], [2341.8520000000017, 2353.391000000002], [2353.391000000002, 2366.122000000002], [2366.122000000002, 2376.631000000002], [2376.631000000002, 2386.631000000002], [2386.631000000002, 2397.231000000002], [2397.231000000002, 2408.942000000002], [2408.942000000002, 2419.1220000000017], [2419.1220000000017, 2433.2510000000016], [2433.2510000000016, 2446.0510000000017], [2446.0510000000017, 2458.3210000000017], [2458.3210000000017, 2471.141000000002], [2471.141000000002, 2483.692000000002], [2483.692000000002, 2495.9300000000017], [2495.9300000000017, 2507.5320000000015], [2507.5320000000015, 2517.8820000000014], [2517.8820000000014, 2531.4120000000016], [2531.4120000000016, 2541.6520000000014], [2541.6520000000014, 2543.9990000000016]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [356, 1034, 1258, 1591, 1954, 2546]}
{"example_id": "mit088@@MIT6_004S17_08-02_300k", "text": [" In this final chapter, were going to look into optimizing  digital systems to make them smaller, faster,  higher performance, more energy efficient, and so on. ", "It would be wonderful if we could  achieve all these goals at the same time and for some circuits  we can.  But, in general, optimizing in one dimension  usually means doing less well in another. ", "In other words, there are design tradeoffs to be made.  Making tradeoffs correctly requires  that we have a clear understanding of our design  goals for the system. ", "Consider two different design teams:  one is charged with building a high-end graphics  card for gaming, the other with building the Apple watch.  The team building the graphics card ", "is mostly concerned with performance  and, within limits, is willing to trade-off cost and power  consumption to achieve their performance goals.  Graphics cards have a set size, so theres a high priority ", "in making the system small enough to meet the required  size, but theres little to be gained in making it smaller  than that.  The team building the watch has very different goals. ", "Size and power consumption are critical since it has fit  on a wrist and run all day without leaving scorch marks  on the wearers wrist!  Suppose both teams are thinking about pipelining ", "part of their logic for increased performance.  Pipelining registers are an obvious additional cost.  The overlapped execution and higher t_CLK  made possible by pipelining would ", "increase the power consumption and the need  to dissipate that power somehow.  You can imagine the two teams might  come to very different conclusions  about the correct course of action! ", "This chapter takes a look at some of the possible tradeoffs.  But as designers youll have to pick and choose which tradeoffs  are right for your design.  This is the sort of design challenge ", "on which good engineers thrive!  Nothing is more satisfying than delivering more  than anyone thought possible within the specified  constraints.  Our first optimization topic is power dissipation, ", "where the usual goal is to either meet a certain power  budget, or to minimize power consumption while meeting  all the other design targets.  In CMOS circuits, there are several sources ", "of power dissipation, some under our control, some not.  Static power dissipation is power  that is consumed even when the circuit is idle,  i.e., no nodes are changing value. ", "Using our simple switch model for the operation of MOSFETs,  wed expect CMOS circuits to have zero static power  dissipation.  And in the early days of CMOS, we  came pretty close to meeting that ideal. ", "But as the physical dimensions of the MOSFET have shrunk  and the operating voltages have been lowered,  there are two sources of static power dissipation in MOSFETs  that have begun to loom large. ", "Well discuss the effects as they appear in n-channel  MOSFETs, but keep in mind that they appear in p-channel  MOSFETs too.  The first effect depends on the thickness of the MOSFETs gate ", "oxide, shown as the thin yellow layer in the MOSFET diagram  on the left.  In each new generation of integrated circuit technology,  the thickness of this layer has shrunk, ", "as part of the general reduction in all the physical dimensions.  The thinner insulating layer means  stronger electrical fields that cause a deeper inversion  layer that leads to NFETs that carry more current, producing ", "faster gate speeds.  Unfortunately the layers are now thin enough  that electrons can tunnel through the insulator,  creating a small flow of current from the gate to the substrate. ", "With billions of NFETs in a single circuit,  even tiny currents can add up to non-negligible power drain.  The second effect is caused by current flowing  between the drain and source of a NFET that ", "is, in theory, not conducting because V_GS is less  than the threshold voltage.  Appropriately this effect is called sub-threshold conduction  and is exponentially related to V_GS - ", "V_TH (a negative value when the NFET is off).  So as V_TH has been reduced in each new generation  of technology, V_GS - V_TH is less negative ", "and the sub-threshold conduction has increased.  One fix has been to change the geometry of the NFET  so the conducting channel is a tall, narrow fin with the gate ", "terminal wrapped around 3 sides, sometimes referred  to as a tri-gate configuration.  This has reduced the sub-threshold conduction  by an order-of-magnitude or more,  solving this particular problem for now. ", "Neither of these effects is under the control of the system  designer, except of course, if theyre free to choose an older  manufacturing process!  We mention them here so that youre aware that newer ", "technologies often bring additional costs that then  become part of the trade-off process.  A designer does have some control over the dynamic power  dissipation of the circuit, the amount of power ", "spent causing nodes to change value  during a sequence of computations.  Each time a node changes from 0-to-1 or 1-to-0,  currents flow through the MOSFET pullup and pulldown networks, ", "charging and discharging the output nodes capacitance  and thus changing its voltage.  Consider the operation of an inverter.  As the voltage of the input changes, ", "the pullup and pulldown networks turn on and off,  connecting the inverters output node to VDD or ground.  This charges or discharges the capacitance of the output ", "node changing its voltage.  We can compute the energy dissipated  by integrating the instantaneous power associated  with the current flow into and out of the capacitor ", "times the voltage across the capacitor over the time taken  by the output transition.  The instantaneous power dissipated  across the resistance of the MOSFET channel ", "is simply I_DS times V_DS.  Heres the power calculation using the energy integral  for the 1-to-0 transition of the output node,  where were measuring I_DS using the equation for the current ", "flowing out of the output nodes capacitor: I = C dV/dt.  Assuming that the input signal is a clock signal of period  t_CLK and that each transition is taking half a clock cycle, ", "we can work through the math to determine that power dissipated  through the pulldown network is 0.5 f C VDD^2,  where the frequency f tells us the number ", "of such transitions per second,  C is the nodal capacitance, and VDD (the power supply voltage)  is the starting voltage of the nodal capacitor.  Theres a similar integral for the current dissipated ", "by the pullup network when charging the capacitor and it  yields the same result.  So one complete cycle of charging then discharging  dissipates f C V-squared watts. ", "Note the all this power has come from the power supply.  The first half is dissipated when the output node is charged  and the other half stored as energy in the capacitor. ", "Then the capacitors energy is dissipated as it discharges.   These results are summarized in the lower left.  Weve added the calculation for the power dissipation ", "of an entire circuit assuming N of the circuits nodes change  each clock cycle.  How much power could be consumed by a modern integrated circuit?  Heres a quick back-of-the-envelope estimate ", "for a current generation CPU chip.  Its operating at, say, 1 GHz and will have 100 million  internal nodes that could change each clock cycle.  Each nodal capacitance is around 1 femto Farad ", "and the power supply is about 1V.  With these numbers, the estimated power consumption  is 100 watts.  We all know how hot a 100W light bulb gets!  You can see it would be hard to keep the CPU from overheating. ", "This is way too much power to be dissipated  in many applications, and modern CPUs  intended, say, for laptops only dissipate  a fraction of this energy.  So the CPU designers must have some tricks up their sleeve, ", "some of which well see in a minute.  But first notice how important its been to be able to reduce  the power supply voltage in modern integrated circuits.  If were able to reduce the power supply voltage from 3.3V ", "to 1V, that alone accounts for more than a factor of 10  in power dissipation.  So the newer circuit can be say, 5 times larger and 2 times ", "faster with the same power budget!  Newer technologies trends are shown here.  The net effect is that newer chips would naturally  dissipate more power if we could afford to have them do so. ", "We have to be very clever in how we use more and faster MOSFETs  in order not to run up against the power  dissipation constraints we face.  ", "To see what we can do to reduce power consumption,  consider the following diagram of an arithmetic and logic unit  (ALU) like the one youll design in the final lab in this part ", "of the course.  There are four independent component modules,  performing the separate arithmetic, boolean, shifting  and comparison operations typically found in an ALU. ", "Some of the ALU control signals are  used to select the desired result in a particular clock  cycle, basically ignoring the answers produced  by the other modules.  Of course, just because the other answers arent selected ", "doesnt mean we didnt dissipate energy in computing them.  This suggests an opportunity for saving power!  Suppose we could somehow turn off modules whose outputs we ", "didnt need?  One way to prevent them from dissipating power is to prevent  the modules inputs from changing,  thus ensuring that no internal nodes would change  and hence reducing the dynamic power dissipation of the off ", "module to zero.  One idea is to put latches on the inputs to each module,  only opening a modules input latch if an answer was required  from that module in the current cycle. ", "If a modules latch stayed closed,  its internal nodes would remain unchanged,  eliminating the modules dynamic power dissipation.  This could save a substantial amount of power. ", "For example, the shifter circuitry has  many internal nodes and so has a large dynamic power  dissipation.  But there are comparatively few shift operations in most  programs, so with our proposed fix, ", "most of the time those energy costs wouldnt be incurred.  A more draconian approach to power conservation  is to literally turn off unused portions of the circuit ", "by switching off their power supply.  This is more complicated to achieve,  so this technique is usually reserved  for special power-saving modes of operation,  where we can afford the time it takes to reliably power ", "the circuity back up.  Another idea is to slow the clock (reducing the frequency  of nodal transitions) when theres nothing for the circuit  to do. ", "This is particularly effective for devices  that interact with the real world,  where the time scales for significant external events  are measured in milliseconds. ", "The device can run slowly until an external event needs  attention, then speed up the clock  while it deals with the event.  All of these techniques and more are ", "used in modern mobile devices to conserve battery power  without limiting the ability to deliver bursts of performance.  There is much more innovation waiting  to be done in this area, something you may be ", "asked to tackle as designers!  One last question is whether computation  has to consume energy?  There have been some interesting theoretical speculations about ", "this question  see section 6.5 of the course notes to read   The most straightforward way to improve performance  is to reduce the propagation delay of a circuit. ", "Lets look at a perennial performance bottleneck:  the ripple-carry adder.  To fix it, we first have to figure out the path from inputs  to outputs that has the largest propagation delay, i.e., ", "the path thats determining the overall t_PD.  In this case that path is the long carry chain  following the carry-in to carry-out path  through each full adder module. ", "To trigger the path add -1 and 1 by setting the A inputs to all  1s and the B input to all 0s except for the low-order bit  which is 1. ", "The final answer is 0, but notice that each full adder has  to wait for the carry-in from the previous stage  before it produces 0 on its sum output  and generates a carry-out for the next full adder. ", "The carry really does ripple through the circuit  as each full adder in turn does its thing.  To total propagation delay along this path  is N-1 times the carry-in to carry-out delay ", "of each full adder, plus the delay  to produce the final bit of the sum.  How would the overall latency change  if we, say, doubled the size of the operands, i.e., ", "made N twice as large?  Its useful to summarize the dependency of the latency on N  using the order-of notation to give us the big picture. ", "Clearly as N gets larger the delay  of the XOR gate at the end becomes less significant,  so the order-of notation ignores terms that are relatively less  important as N grows. ", "In this example, the latency is order N,  which tells us that the latency would  be expected to essentially double  if we made N twice as large.  The order-of notation, which theoreticians ", "call asymptotic analysis, tells us  the term that would dominate the result as N grows.  The yellow box contains the official definition,  but an example might make it easier to understand whats ", "happening.  Suppose we want to characterize the growth in the value  of the equation n^2 + 2n + 3 as n gets larger.  The dominant term is clearly n^2 and the value of our equation ", "is bounded above and below by simple multiples of n^2,  except for finitely many values of n.  The lower bound is always true for n greater ", "than or equal to 0.  And in this case, the upper bound doesnt hold only for n  equal to 0, 1, 2, or 3.  For all other positive values of n the upper inequality is true. ", "So wed say this equation was order N^2.  There are actually two variants for the order-of notation.  We use the Theta notation to indicate ", "that g(n) is bounded above AND below by multiples of f(n).  The big O notation is used when g(n) is only bounded above  by a multiple of f(n).  Heres a first attempt at improving the latency ", "of our addition circuit.  The trouble with the ripple-carry adder  is that the high-order bits have to wait  for the carry-in from the low-order bits.  Is there a way in which we can get high half the adder working ", "in parallel with the low half?  Suppose we wanted to build a 32-bit adder.  Lets make two copies of the high 16 bits of the adder,  one assuming the carry-in from the low bits is 0, ", "and the other assuming the carry-in is 1.  So now we have three 16-bit adders, all of which  can operate in parallel on newly arriving A and B inputs. ", "Once the 16-bit additions are complete,  we can use the actual carry-out from the low-half  to select the answer from the particular high-half adder that  used the matching carry-in value. ", "This type of adder is appropriately  named the carry-select adder.  The latency of this carry-select adder  is just a little more than the latency  of a 16-bit ripple-carry addition. ", "This is approximately half the latency  of the original 32-bit ripple-carry adder.  So at a cost of about 50% more circuitry,  weve halved the latency! ", "As a next step, we could apply the same strategy  to halve the latency of the 16-bit adders.  And then again to halve the latency of the 8-bit adders  used in the previous step. ", "At each step we halve the adder latency and add a MUX delay.  After log2(N) steps, N will be 1 and were done. ", "At this point the latency would be some constant cost  to do a 1-bit addition, plus log2(N) times the MUX latency  to select the right answers.  So the overall latency of the carry-select adder ", "is order log(N).  Note that log2(N) and log(N) only  differ by a constant factor, so we  ignore the base of the log in order-of notation. ", "The carry-select adder shows a clear performance-size tradeoff  available to the designer.  Since adders play a big role in many digital systems,  heres a more carefully engineered version of a 32-bit ", "carry-select adder.  You could try this in your ALU design!  The size of the adder blocks has been  chosen so that the trial sums and the carry-in  from the previous stage arrive at the carry-select MUX ", "at approximately the same time.  Note that since the select signal for the MUXes is heavily  loaded weve included a buffer to make the select signal  transitions faster. ", "This carry-select adder is about two-and-a-half times faster  than a 32-bit ripple-carry adder at the cost of about twice  as much circuitry.  A great design to remember when youre looking to double ", " Here's another approach to improving the latency of our adder, this time focusing just on the  carry logic.  Early on in the course, we learned that by going from a chain of logic gates to a tree ", "of logic gates, we could go from a linear latency to a logarithmic latency.  Let's try to do that here.  We'll start by rewriting the equations for the carry-out from the full adder module. ", "The final form of the rewritten equation has two terms.  The G, or generate, term is true when the inputs will cause the module to generate a  carry-out right away, without having to wait for the carry-in to arrive. ", "The P, or propagate, term is true if the module will generate a carry-out only if there's  a carry-in.  So there only two ways to get a carry-out from the module: it's either generated by ", "the current module or the carry-in is propagated from the previous module.  Actually, it's usual to change the logic for the P term from \"A OR B\" to \"A XOR B\". ", "This doesn't change the truth table for the carry-out but will allow us to express the  sum output as \"P XOR carry-in\".  Here's the schematic for the reorganized full adder module. ", "The little sum-of-products circuit for the carry-out can be implemented using 3 2-input  NAND gates, which is a bit more compact than the implementation for the three product terms  we suggested in Lab 2. ", "Time to update your full adder circuit!  Now consider two adjacent adder modules in a larger adder circuit:  we'll use the label H to refer to the high-order module and the label L to refer to the low-order ", "module.  We can use the generate and propagate information from each of the modules to develop equations  for the carry-out from the pair of modules treated as a single block. ", "We'll generate a carry-out from the block when a carry-out is generated by the H module,  or when a carry-out is generated by the L module and propagated by the H module. ", "And we'll propagate the carry-in through the block only if the L module propagates its  carry-in to the intermediate carry-out and H module propagates that to the final carry-out. ", "So we have two simple equations requiring only a couple of logic gates to implement.  Let's use these equations to build a generate-propagate (GP) module and hook it to the H and L modules ", "as shown.  The G and P outputs of the GP module tell us under what conditions we'll get a carry-out  from the two individual modules treated as a single, larger block. ", "We can use additional layers of GP modules to build a tree of logic that computes the  generate and propagate logic for adders with any number of inputs.  For an adder with N inputs, the tree will contain a total of N-1 GP modules and have ", "a latency that's order log(N).  In the next step, we'll see how to use the generate and propagate information to quickly  compute the carry-in for each of the original full adder modules. ", "Once we're given the carry-in C_0 for the low-order bit, we can hierarchically compute  the carry-in for each full adder module.  Given the carry-in to a block of adders, we simply pass it along as the carry-in to the ", "low-half of the block.  The carry-in for the high-half of the block is computed the using the generate and propagate  information from the low-half of the block.  We can use these equations to build a C module and arrange the C modules in a tree as shown ", "to use the C_0 carry-in to hierarchically compute the carry-in to each layer of successively  smaller blocks, until we finally reach the full adder modules. ", "For example, these equations show how C4 is computed from C0, and C6 is computed from  C4.  Again the total propagation delay from the arrival of the C_0 input to the carry-ins ", "for each full adder is order log(N).  Notice that the G_L and P_L inputs to a particular C module are the same as two of the inputs ", "to the GP module in the same position in the GP tree.  We can combine the GP module and C module to form a single carry-lookahead module that  passes generate and propagate information up the tree and carry-in information down ", "the tree.  The schematic at the top shows how to wire up the tree of carry-lookahead modules.  And now we get to the payoff for all this hard work! ", "The combined propagation delay to hierarchically compute the generate and propagate information  on the way up and the carry-in information on the way down is order log(N), ", "which is then the latency for the entire adder since computing the sum outputs only takes  one additional XOR delay.  This is a considerable improvement over the order N latency of the ripple-carry adder. ", "A final design note: we no longer need the carry-out circuitry in the full adder module,  so it can be removed.  Variations on this generate-propagate strategy form the basis for the fastest-known adder ", "circuits.  If you'd like to learn more, look up \"Kogge-Stone adders\" on Wikipedia.   One of the biggest and slowest circuits in an arithmetic and logic unit is the multiplier. ", "We'll start by developing a straightforward implementation and then, in the next section,  look into tradeoffs to make it either smaller or faster.  Here's the multiplication operation for two unsigned 4-bit operands broken down into its ", "component operations.  This is exactly how we learned to do it in primary school.  We take each digit of the multiplier (the B operand) and use our memorized multiplication ", "tables to multiply it with each digit of the multiplicand (the A operand),  dealing with any carries into the next column as we process the multiplicand right-to-left. ", "The output from this step is called a partial product and then we repeat the step for the  remaining bits of the multiplier.  Each partial product is shifted one digit to the left, reflecting the increasing weight ", "of the multiplier digits.  In our case the digits are just single bits, i.e., they're 0 or 1 and the multiplication  table is pretty simple! ", "In fact, the 1-bit-by-1-bit binary multiplication circuit is just a 2-input AND gate.  And look Mom, no carries!  The partial products are N bits wide since there are no carries. ", "If the multiplier has M bits, there will be M partial products.  And when we add the partial products together, we'll get an N+M bit result if we account  for the possible carry-out from the high-order bit. ", "The easy part of the multiplication is forming the partial products - it just requires some  AND gates.  The more expensive operation is adding together the M N-bit partial products. ", "Here's the schematic for the combinational logic needed to implement the 4x4 multiplication,  which would be easy to extend for larger multipliers (we'd need more rows) or larger multiplicands ", "(we'd need more columns).  The M*N 2-input AND gates compute the bits of the M partial products.  The adder modules add the current row's partial product with the sum of the partial products ", "from the earlier rows.  Actually there are two types of adder modules.  The full adder is used when the modules needs three inputs.  The simpler half adder is used when only two inputs are needed. ", "The longest path through this circuit takes a moment to figure out.  Information is always moving either down a row or left to the adjacent column.  Since there are M rows and, in any particular row, N columns, there are at most N+M modules ", "along any path from input to output.  So the latency is order N, since M and N differ by just some constant factor. ", "Since this is a combinational circuit, the throughput is just 1/latency.  And the total amount of hardware is order N^2.  In the next section, we'll investigate how to reduce the hardware costs, or, separately, ", "how to increase the throughput.  But before we do that, let's take a moment to see how the circuit would change if the  operands were two's complement integers instead of unsigned integers. ", "With a two's complement multiplier and multiplicand, the high-order bit of each has negative weight.  So when adding together the partial products, we'll need to sign-extend each of the N-bit ", "partial products to the full N+M-bit width of the addition.  This will ensure that a negative partial product is properly treated when doing the addition.  And, of course, since the high-order bit of the multiplier has a negative weight, we'd ", "subtract instead of add the last partial product.  Now for the clever bit.  We'll add 1's to various of the columns and then subtract them later, with the goal of ", "eliminating all the extra additions caused by the sign-extension.  We'll also rewrite the subtraction of the last partial product as first complementing  the partial product and then adding 1. ", "This is all a bit mysterious but  Here in step 3 we see the effect of all the step 2 machinations.  Let's look at the high order bit of the first partial product X3Y0. ", "If that partial product is non-negative, X3Y0 is a 0, so all the sign-extension bits are  0 and can be removed.  The effect of adding a 1 in that position is to simply complement X3Y0. ", "On the other hand, if that partial product is negative, X3Y0 is 1, and all the sign-extension  bits are 1.  Now when we add a 1 in that position, we complement the X3Y0 bit back to 0, but we also get a ", "carry-out.  When that's added to the first sign-extension bit (which is itself a 1), we get zero with  another carry-out.  And so on, with all the sign-extension bits eventually getting flipped to 0 as the carry ", "ripples to the end.  Again the net effect of adding a 1 in that position is to simply complement X3Y0. ", "We do the same for all the other sign-extended partial products, leaving us with the results  shown here.  In the final step we do a bit of arithmetic on the remaining constants to end up with ", "this table of work to be done.  Somewhat to our surprise, this isn't much different than the original table for the  unsigned multiplication.  There are a few partial product bits that need to be complemented, and two 1-bits that ", "need to be added to particular columns.  The resulting circuitry is shown here.  We've changed some of the AND gates to NAND gates to perform the necessary complements.  And we've changed the logic necessary to deal with the two 1-bits that needed to be added ", "in.  The colored elements show the changes made from the original unsigned multiplier circuitry.  Basically, the circuit for multiplying two's complement operands has the same latency, ", "throughput and hardware costs as the original circuitry.   Let's see if we can improve the throughput of the original combinational multiplier design.  We'll use our patented pipelining process to divide the processing into stages with ", "the expectation of achieving a smaller clock period and higher throughput.  The number to beat is approximately 1 output every 2N, where N is the number of bits in ", "each of the operands.  Our first step is to draw a contour across all the outputs.  This creates a 1-pipeline, which gets us started but doesn't improve the throughput. ", "Let's add another contour, dividing the computations about in half.  If we're on the right track, we hope to see some improvement in the throughput.  And indeed we do: the throughput has doubled. ", "Yet both the before and after throughputs are order 1/N.  Is there any hope of a dramatically better throughput?  The necessary insight is that as long as an entire row is inside a single pipeline stage, ", "the latency of the stage will be order N since we have to leave time for the N-bit ripple-carry  add to complete.  There are several ways to tackle this problem. ", "The technique illustrated here will be useful in our next task.  In this schematic we've redrawn the carry chains.  Carry-outs are still connected to a module one column to the left, but, in this case, ", "a module that's down a row.  So all the additions that need to happen in a specific column still happen in that column,  we've just reorganized which row does the adding. ", "Let's pipeline this revised diagram, creating stages with approximately two module's worth  of propagation delay.  The horizontal contours now break the long carry chains and the latency of each stage ", "is now constant, independent of N. Note that we had to add order N extra rows  to take of the propagating the carries all the way to the end - the extra circuitry is ", "shown in the grey box.  To achieve a latency that's independent of N in each stage, we'll need order N contours.  This means the latency is constant, which in order-of notation we write as \"order 1\". ", "But this means the clock period is now independent of N, as is the throughput - they are both  order 1.  With order N contours, there are order N pipeline stages, so the system latency is order N. ", "The hardware cost is still order N^2.  So the pipelined carry-save multiplier has dramatically better throughput than the original  circuit, another design tradeoff we can remember for future use. ", "We'll use the carry-save technique in our next optimization, which is to implement the  multiplier using only order N hardware.  This sequential multiplier design computes a single partial product in each step and ", "adds it to the accumulating sum.  It will take order N steps to perform the complete multiplication.  In each step, the next bit of the multiplier, found in the low-order bit of the B register, ", "is ANDed with the multiplicand to form the next partial product.  This is sent to the N-bit carry-save adder to be added to the accumulating sum in the  P register. ", "The value in the P register and the output of the adder are in \"carry-save format\".  This means there are 32 data bits, but, in addition, 31 saved carries, to be added to ", "the appropriate column in the next cycle.  The output of the carry-save adder is saved in the P register, then in preparation for  the next step both P and B are shifted right by 1 bit. ", "So each cycle one bit of the accumulated sum is retired to the B register since it can  no longer be affected by the remaining partial products.  Think of it this way: instead of shifting the partial products left to account for the ", "weight of the current multiplier bit, we're shifting the accumulated sum right!  The clock period needed for the sequential logic is quite small, and, more importantly ", "is independent of N. Since there's no carry propagation, the latency  of the carry-save adder is very small, i.e., only enough time for the operation of a single ", "full adder module.  After order N steps, we've generated the necessary partial products, but will need to continue  for another order N steps to finish propagating the carries through the carry-save adder. ", "But even at 2N steps, the overall latency of the multiplier is still order N.  And at the end of the 2N steps, we produce the answer in the P and B registers combined, ", "so the throughput is order 1/N. The big change is in the hardware cost at  order N, a dramatic improvement over the order N^2 hardware cost of the original combinational ", "multiplier.  This completes our little foray into multiplier designs.  We've seen that with a little cleverness we can create designs with order 1 throughput, ", "or designs with only order N hardware.  The technique of carry-save addition is useful in many situations and its use can improve  throughput at constant hardware cost, or save hardware at a constant throughput. ", " This discussion of design tradeoffs completes Part 1 of the course.  We've covered a lot of ground in the last eight lectures.  We started by looking at the mathematics underlying information theory and used it to help evaluate ", "various alternative ways of effectively using sequences of bits to encode information content.  Then we turned our attention to adding carefully-chosen redundancies to our encoding to ensure that ", "we could detect and even correct errors that corrupted our bit-level encodings.  Next we learned how analog signaling accumulates errors as we added processing elements to ", "our system.  We solved the problem by using voltages \"digitally\" choosing two ranges of voltages to encode  the bit values 0 and 1.  We had different signaling specifications for our outputs and inputs, adding noise margins ", "to make our signaling more robust.  Then we developed the static discipline for combinational devices and were led to the  conclusion that our devices had to be non-linear and exhibit gains > 1. ", "In our study of combinational logic, we fist learned about the MOSFET, a voltage-controlled  switch.  We developed a technique for using MOSFETS to build CMOS combinational logic gates, which ", "met all the criteria of the static discipline.  Then we discussed systematic ways of synthesizing larger combinational circuits that could implement  any functionality we could express in the form a truth table. ", "To be able to perform sequences of operations, we first developed a reliable bistable storage  element based on a positive feedback loop.  To ensure the storage elements worked correctly we imposed the dynamic discipline which required ", "inputs to the storage elements to be stable just before and after the time the storage  element was transitioned to \"memory mode\".  We introduced finite-state machines as a useful abstraction for designing sequential logic. ", "And then we figured out how to deal with asynchronous inputs in way that minimized the chance of  incorrect operation due to metastability.  In the last two lectures we developed latency and throughput as performance measures for ", "digital systems and discussed ways of achieving maximum throughput under various constraints.  We discussed how it's possible to make tradeoffs to achieve goals of minimizing power dissipation ", "and increasing performance through decreased latency or increased throughput.  Whew!  That's a lot of information in a short amount of time. ", "Mr. Blue and the rest of the 6.004x staff hope you've found the course useful in increasing  your skills in designing digital systems and analyzing their operation. ", "You've completed several actual designs and you're well on your way to designing a complete  computer using our standard cell library.  That's quite an accomplishment.  If you'd like to continue the journey, please join us for Part 2 of the course where we'll ", "discuss programmable architectures and work out the design of a modern 32-bit processor.  See you then! "], "vid_duration": [10.65, 12.55, 10.73, 11.28, 11.73, 11.38, 11.99, 10.73, 11.6, 10.69, 12.51, 10.79, 12.89, 12.66, 11.95, 11.15, 11.71, 12.94, 11.18, 11.84, 12.63, 11.689, 10.411, 13.562, 10.238, 11.69, 11.61, 10.45, 10.37, 10.61, 10.73, 12.31, 12.83, 10.41, 12.12, 12.32, 10.38, 12.12, 11.15, 11.86, 13.94, 11.89, 11.06, 10.07, 11.44, 12.79, 10.2, 11.29, 12.51, 10.68, 12.49, 12.25, 11.08, 11.49, 10.57, 13.06, 10.96, 10.14, 10.29, 11.86, 10.4, 11.177, 11.4, 12.839, 11.35, 12.49, 12.691, 11.13, 10.459, 10.73, 11.61, 11.801, 12.49, 10.479, 11.89, 10.411, 12.299, 12.321, 11.9, 11.19, 10.339, 10.78, 10.951, 10.019, 10.55, 11.881, 10.349, 12.02, 12.661, 11.44, 11.609, 12.089, 12.591, 13.73, 11.939, 11.56, 11.541, 11.97, 13.58, 10.009, 12.451, 11.51, 13.48, 12.159, 15.171, 12.789, 12.841, 14.49, 11.08, 13.289, 10.94, 14.731, 10.03, 11.4, 13.65, 13.72, 12.612, 14.81, 11.82, 11.31, 11.51, 10.46, 13.97, 13.64, 12.39, 11.47, 12.94, 13.95, 15.379, 10.461, 13.08, 11.84, 11.04, 13.97, 10.42, 11.74, 13.249, 14.54, 14.301, 14.009, 10.241, 10.079, 13.66, 13.84, 12.591, 13.372, 11.039, 12.341, 11.05, 13.5, 10.31, 11.9, 11.21, 12.24, 10.53, 15.019, 13.781, 13.87, 13.26, 11.62, 10.98, 11.35, 12.009, 13.781, 10.63, 11.88, 13.44, 10.7, 11.41, 10.36, 14.149, 13.74, 11.69, 10.23, 13.56, 13.67, 11.44, 14.16, 13.15, 12.96, 13.579, 12.271, 11.31, 10.119, 12.97, 7.268], "stet": [[0, 10.65], [10.65, 23.200000000000003], [23.200000000000003, 33.93000000000001], [33.93000000000001, 45.21000000000001], [45.21000000000001, 56.94000000000001], [56.94000000000001, 68.32000000000001], [68.32000000000001, 80.31], [80.31, 91.04], [91.04, 102.64], [102.64, 113.33], [113.33, 125.84], [125.84, 136.63], [136.63, 149.51999999999998], [149.51999999999998, 162.17999999999998], [162.17999999999998, 174.12999999999997], [174.12999999999997, 185.27999999999997], [185.27999999999997, 196.98999999999998], [196.98999999999998, 209.92999999999998], [209.92999999999998, 221.10999999999999], [221.10999999999999, 232.95], [232.95, 245.57999999999998], [245.57999999999998, 257.269], [257.269, 267.68], [267.68, 281.242], [281.242, 291.48], [291.48, 303.17], [303.17, 314.78000000000003], [314.78000000000003, 325.23], [325.23, 335.6], [335.6, 346.21000000000004], [346.21000000000004, 356.94000000000005], [356.94000000000005, 369.25000000000006], [369.25000000000006, 382.08000000000004], [382.08000000000004, 392.49000000000007], [392.49000000000007, 404.61000000000007], [404.61000000000007, 416.93000000000006], [416.93000000000006, 427.31000000000006], [427.31000000000006, 439.43000000000006], [439.43000000000006, 450.58000000000004], [450.58000000000004, 462.44000000000005], [462.44000000000005, 476.38000000000005], [476.38000000000005, 488.27000000000004], [488.27000000000004, 499.33000000000004], [499.33000000000004, 509.40000000000003], [509.40000000000003, 520.84], [520.84, 533.63], [533.63, 543.83], [543.83, 555.12], [555.12, 567.63], [567.63, 578.31], [578.31, 590.8], [590.8, 603.05], [603.05, 614.13], [614.13, 625.62], [625.62, 636.19], [636.19, 649.25], [649.25, 660.21], [660.21, 670.35], [670.35, 680.64], [680.64, 692.5], [692.5, 702.9], [702.9, 714.077], [714.077, 725.477], [725.477, 738.316], [738.316, 749.666], [749.666, 762.1560000000001], [762.1560000000001, 774.8470000000001], [774.8470000000001, 785.9770000000001], [785.9770000000001, 796.436], [796.436, 807.166], [807.166, 818.7760000000001], [818.7760000000001, 830.5770000000001], [830.5770000000001, 843.0670000000001], [843.0670000000001, 853.5460000000002], [853.5460000000002, 865.4360000000001], [865.4360000000001, 875.8470000000001], [875.8470000000001, 888.1460000000001], [888.1460000000001, 900.4670000000001], [900.4670000000001, 912.3670000000001], [912.3670000000001, 923.5570000000001], [923.5570000000001, 933.8960000000002], [933.8960000000002, 944.6760000000002], [944.6760000000002, 955.6270000000002], [955.6270000000002, 965.6460000000002], [965.6460000000002, 976.1960000000001], [976.1960000000001, 988.0770000000001], [988.0770000000001, 998.4260000000002], [998.4260000000002, 1010.4460000000001], [1010.4460000000001, 1023.1070000000001], [1023.1070000000001, 1034.547], [1034.547, 1046.156], [1046.156, 1058.245], [1058.245, 1070.8359999999998], [1070.8359999999998, 1084.5659999999998], [1084.5659999999998, 1096.5049999999999], [1096.5049999999999, 1108.0649999999998], [1108.0649999999998, 1119.6059999999998], [1119.6059999999998, 1131.5759999999998], [1131.5759999999998, 1145.1559999999997], [1145.1559999999997, 1155.1649999999997], [1155.1649999999997, 1167.6159999999998], [1167.6159999999998, 1179.1259999999997], [1179.1259999999997, 1192.6059999999998], [1192.6059999999998, 1204.7649999999999], [1204.7649999999999, 1219.936], [1219.936, 1232.725], [1232.725, 1245.5659999999998], [1245.5659999999998, 1260.0559999999998], [1260.0559999999998, 1271.1359999999997], [1271.1359999999997, 1284.4249999999997], [1284.4249999999997, 1295.3649999999998], [1295.3649999999998, 1310.0959999999998], [1310.0959999999998, 1320.1259999999997], [1320.1259999999997, 1331.5259999999998], [1331.5259999999998, 1345.176], [1345.176, 1358.896], [1358.896, 1371.508], [1371.508, 1386.318], [1386.318, 1398.138], [1398.138, 1409.4479999999999], [1409.4479999999999, 1420.9579999999999], [1420.9579999999999, 1431.418], [1431.418, 1445.388], [1445.388, 1459.028], [1459.028, 1471.4180000000001], [1471.4180000000001, 1482.8880000000001], [1482.8880000000001, 1495.8280000000002], [1495.8280000000002, 1509.7780000000002], [1509.7780000000002, 1525.1570000000002], [1525.1570000000002, 1535.6180000000002], [1535.6180000000002, 1548.698], [1548.698, 1560.538], [1560.538, 1571.578], [1571.578, 1585.548], [1585.548, 1595.968], [1595.968, 1607.708], [1607.708, 1620.957], [1620.957, 1635.497], [1635.497, 1649.798], [1649.798, 1663.807], [1663.807, 1674.048], [1674.048, 1684.127], [1684.127, 1697.787], [1697.787, 1711.627], [1711.627, 1724.2179999999998], [1724.2179999999998, 1737.59], [1737.59, 1748.629], [1748.629, 1760.9699999999998], [1760.9699999999998, 1772.0199999999998], [1772.0199999999998, 1785.5199999999998], [1785.5199999999998, 1795.8299999999997], [1795.8299999999997, 1807.7299999999998], [1807.7299999999998, 1818.9399999999998], [1818.9399999999998, 1831.1799999999998], [1831.1799999999998, 1841.7099999999998], [1841.7099999999998, 1856.7289999999998], [1856.7289999999998, 1870.5099999999998], [1870.5099999999998, 1884.3799999999997], [1884.3799999999997, 1897.6399999999996], [1897.6399999999996, 1909.2599999999995], [1909.2599999999995, 1920.2399999999996], [1920.2399999999996, 1931.5899999999995], [1931.5899999999995, 1943.5989999999995], [1943.5989999999995, 1957.3799999999994], [1957.3799999999994, 1968.0099999999995], [1968.0099999999995, 1979.8899999999996], [1979.8899999999996, 1993.3299999999997], [1993.3299999999997, 2004.0299999999997], [2004.0299999999997, 2015.4399999999998], [2015.4399999999998, 2025.7999999999997], [2025.7999999999997, 2039.9489999999996], [2039.9489999999996, 2053.6889999999994], [2053.6889999999994, 2065.3789999999995], [2065.3789999999995, 2075.6089999999995], [2075.6089999999995, 2089.1689999999994], [2089.1689999999994, 2102.8389999999995], [2102.8389999999995, 2114.2789999999995], [2114.2789999999995, 2128.4389999999994], [2128.4389999999994, 2141.5889999999995], [2141.5889999999995, 2154.5489999999995], [2154.5489999999995, 2168.1279999999997], [2168.1279999999997, 2180.399], [2180.399, 2191.709], [2191.709, 2201.828], [2201.828, 2214.798], [2214.798, 2222.066]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [708, 1048, 1367, 1730, 2042, 2224]}
{"example_id": "mit153@@MITRES6_012S18_L10_300k", "text": [" In this lecture we complete our discussion of multiple  continuous random variables.  In the first half, we talk about the conditional  distribution of one random variable, given ", "the value of another.  We will see that the mechanics are essentially the same as in  the discrete case.  Here, we will actually face some subtle issues, because we ", "will be conditioning on any event that has 0 probability.  Nevertheless, all formulas will still have the form that  one should expect.  And in particular, we will see natural versions of the total ", "probability and total expectation theorems.  We will also define independence of continuous  random variables, a concept that has the same intuitive ", "content as in the discrete case.  That is, when we have independent random variables,  the values of some of them do not cause any revision of our  beliefs about the remaining ones. ", "Then, in the second half of the lecture, we will focus on  the Bayes rule.  This will be the methodological foundation for  when, later in this course, we dive into ", "the subject of inference.  The Bayes rule allows us to revise our beliefs about a  random variable.  That is, replace an original probability distribution by a ", "conditional one, after we observe the value of some  other random variable.  Depending on whether the random variables involved are  discrete or continuous, we will get four different ", "versions of the Bayes rule.  They all have the same form, with small differences.  And we will see how to apply them through some examples.   ", "By now, we have introduced all sorts of PMFs for  the discrete case.  The joint PMF, the conditional PMF--  given an event-- ", "and the conditional PMF of one random variable given another.  And we're moving along with the program of defining  analogous concepts for the continuous case.  We have already discussed the joint PDF and the conditional ", "PDF, given an event.  The next item in our menu is to define a conditional PDF of  one random variable, given another random variable. ", "We proceed by first looking at the definition for the  discrete case.  A typical entry of the conditional PMF is just a  conditional probability, but in different notation. ", "And using the definition of conditional probabilities,  this is equal to the ratio of the joint divided by the  probability of the conditioning event.  Unfortunately, in the continuous case, a definition ", "of this form would be problematic, because the event  that Y takes on a specific value is an event that has 0  probability.  And we know that we cannot condition on a ", "0 probability event.  However, we can take this expression as a guide on how  to define a conditional PDF in the continuous case.  And this is the definition, which just mimics the formula ", "that we have up here.  Notice that this conditional PDF-- defined this way-- is  well defined, as long as the denominator  is a positive quantity. ", "Let us now try to make sense of this definition.  Let us first recall the interpretation of the  conditional PDF, given an event, A, that has positive  probability. ", "We know that the PDF is used to determine the probability  of a small interval.  And similarly, the conditional PDF is used to calculate the  conditional probability of a small interval given the ", "conditioning event.  We would like to do something similar for the conditional  PDF, where we would like to take the event A to be  something like the event that Y is equal to some particular ", "value-- little y.  But as we said, this is problematic, because this  event does not have positive probability.  So instead, we can take A to be the event that Y is ", "approximately equal to a certain value.  So we're dealing with a little interval around this value,  little y, which in general would be an event of positive ", "probability.  And we can try to have a similar interpretation.  Let us see how this works out.  So what does it mean that Y is approximately equal to some ", "particular value, little y?  We interpret that as follows.  We're told that the random variable, Y, takes a value  that is within epsilon--  where epsilon is a small number-- ", "of a given value, little y.  And given this conditioning information, we want to  calculate the probability of a small interval.  How do we do that?  Well, here--  because this, in general, will be a ", "positive probability event--  we can use the definition of conditional probabilities.  And it would be equal to the probability of both events  happening, divided by the probability of the ", "conditioning event.  What is the probability of both events happening?  This is a probability of a small rectangle in xy space. ", "At that rectangle, the joint PDF, has a certain value.  And because we're integrating over that rectangle-- ", "and that rectangle has dimensions delta and epsilon--  of that probability, that small rectangle, is  approximately equal to this.  Then we need the denominator, which is the probability of ", "the conditioning event.  And this is approximately equal to the density of Y  evaluated at that point, times the length  of the small interval. ", "We cancel the epsilons.  And then we notice that the ratio we have here is what we  defined as the conditional PDF. ", "So we get this relation times delta.  So what do we see?  We see that the probability of a small interval is equal to a ", "PDF times the length of the small interval.  However, because we are conditioning on Y being  approximately equal to a certain value, we end up using ", "a corresponding conditional PDF, where the conditional PDF  is defined this way.  So we now have an interpretation of the  conditional PDF in terms of  probabilities of small intervals. ", " Now that we have an intuitive interpretation of the  conditional PDF, we can also use it to calculate ", "conditional probabilities of more general  events, not just intervals.  And we do this as follows.  In general, for continuous random variables, we can find ", "the probability that X belongs to a certain set by  integrating a PDF over that set.  Because here we're dealing with a conditional situation  where we're given the value of Y, we use the conditional PDF ", "instead of the true PDF.  And this way, we calculate the conditional probability.  Now, the difficulty is that this conditional probability  is not a well-defined quantity according to what we did early ", "on in this class.  We cannot condition on zero probability events.  But we can get the around this difficulty as follows.  This quantity is well-defined. ", "And we can use this quantity as the definition of this  conditional probability.  And so we have managed to provide definition of ", "conditional probabilities, given a 0 probability event of  a certain type.  It turns out that this definition is sound and  consistent with everything else that we are doing. ", "But when we're dealing with particular problems and  applications, we can generally forget about all of these  subtleties that we have been discussing here. ", "The bottom line is that we will be  treating conditional PDFs--  given the value of a random variable, Y--  just as ordinary PDFs, but given the information that ", "this random variable took on a specific value.  And in that conditional universe, we will calculate  probabilities the usual way, by using conditional PDFs  instead of ordinary PDFs. ", "  The definition of the  conditional PDF is very simple.  It is just this formula, which is analogous to the one for ", "the discrete case.  In all respects--  mathematical and intuitive--  it is very similar to the conditional PMF.  Even so, developing a solid grasp of this concept does ", "take some further thinking, so we will now make some  observations that should be helpful in this respect.  The first and obvious observation is that the ", "conditional PDF is non-negative.  It's defined when the denominator is positive, the  numerator is a non-negative quantity, so it's always a ", "non-negative quantity.  A more interesting observation is that for any given value of  little y, the conditional PDF looks like a slice ", "of the joint PDF.  Indeed, if you fix the value of little y, then the  denominator in this definition is a constant, and we have a ", "function that varies with x the same way that the joint  PDF varies with x.  Pictorially, let us consider this particular joint PDF, and ", "let this be the x-axis and let that be the y-axis.  If we fix a certain value of y, if we condition on Y having ", "taken this particular value so that our universe is now this  particular line, on that universe the value of the ", "denominator in this definition is a constant, and the  conditional PDF is going to vary according to the height  of the joint on that ", "particular conditional universe.  So the height of the joint, if we trace it, is one of those  curves up here, and [then] ", "goes down.  So it is really a slice taken out of the joint PDF.  If we condition on a different y, we get a different slice of ", "the joint PDF, and so on.  Actually, the conditional is not exactly  the same as the slice.  We also have this term on the denominator that serves as a ", "scaling factor.  It turns out that this scaling factor is exactly what we need  for the conditional PDF, given a specific value of little y, ", "to integrate to 1.  Indeed, if we fix little y and take the integral over all  x's, using the definition, and because this term is a ", "constant and does not involve x, we only need to integrate  the numerator.  And we recognize that the numerator corresponds to our  earlier formula for the marginal distribution-- ", "the marginal PDF of Y. From the joint, this is how we  recover the marginal PDF of Y.  So the numerator turns out to be the same as the ", "denominator, and so we get a ratio 1.  Therefore, the conditional PDF for a given value of the  random variable Y behaves in all respects ", "like an ordinary PDF.  It is non-negative and it integrates to 1.  A last observation is that we can take this definition and ", "move the denominator to the other side to obtain this  formula, which has the familiar form of the  multiplication rule.  The probability of two events happening is the probability ", "of the first times the probability of the second  given the first, except that here we're not really dealing  with probabilities, we're dealing with densities.  By symmetry, a similar formula must also be true when we ", "interchange the roles of X and Y. So, algebraically,  everything is similar to what we have seen for the case of  discrete random variables.  It's the same form of the multiplication rule, although ", "the interpretation is a bit different because densities  are not probabilities.    Conditional PDFs share most of the properties  of conditional PMFs. ", "All facts for the discrete case have continuous analogs.  The intuition is more or less the same, although it is much  easier to grasp in the discrete case.  For example, we have seen this version of the total ", "probability theorem.  There is a continuous analog in which we  replace sums by integrals.  And we replace PMFs by PDFs. ", "The proof of this fact is actually pretty simple.  By the multiplication rule, the integrand, here, is just  the joint PDF of X and Y. ", "And we know that if we take the joint PDF and integrate  with respect to one variable then we recover the marginal  PDF of the other random variable. ", "So this is one theorem that extends to  the continuous case.  Moving along, we have defined the conditional expectation in  this manner in the discrete case. ", "And we define it similarly for the continuous case.  So actually here we now have a new definition.  This definition is also consistent with the definition ", "of the expectation of a continuous random variable.  The expected value for continuous random variable is  the integral of X times [a]  density.  Except that here we live in a conditional universe where ", "we're conditioning on this event.  And therefore, we need to use the  corresponding conditional PDF.  Finally, we have the total expectation theorem in the ", "discrete case.  And there is the obvious analog in the continuous case  where we are using an integral and a density.  The interpretation is that we consider all possibilities for ", "Y. Under each possibility of Y we find the expected value of  X. And then we weigh those different possibilities  according to the corresponding values of the density. ", "So we're taking a weighted average of these conditional  expectations to obtain the overall expectation of the  random variable X.  The derivation of this fact is maybe a little instructive ", "because it uses various facts that we have in our hands.  So let's see how to derive it.  We start from this expression in the right-hand side and we  will show that it is equal to the expected value of X. The ", "expression on the right-hand side is equal to the  following, it's the integral of the density of Y.  And then, inside here, we have the conditional expectation ", "which is defined this way.  So we just plug-in the definition.  ", "And then what we do, is we take this term and move it  inside the integral.   Which we can do because this integral is with respect to x. ", "And therefore, this is like a constant.  ", "And we also interchange the order of integration.  Now, the inner integration is with respect to y.  As far as Y is concerned, this term, x, is a constant. ", "So we can take it and move it outside this first integral  and place it out there.  So this term disappears and goes out there. ", "What do we have here?  This part, by the previous fact, the total probability  theorem, is just the density of X. So we're left with the ", "integral of x times the density of x dx.  And this is the expected value of X. ", "Finally, we have various forms of the expected value rule,  which barely deserve writing down.  Because they're exactly what you might expect.  Consider, for example, an expression such as this one, ", "the expected value of a function of the random  variable X but conditioned on the value of the random  variable Y. How do we calculate this quantity? ", "Well, the expected value rule tells us that we should  integrate g of x times the density of X. But because, ", "here we live in a conditional universe, we should actually  use the corresponding conditional PDF of X. And  there are many other versions of the expected value rule. ", "Any version that we have seen for the discrete case has,  also, a continuous analog which looks about the same  except that we integrate and that we use densities.  ", " Independence is one of the central concepts of  probability theory, because it allows us to build large  models from simpler ones.  How should we define independence in ", "the continuous case?  Our guide comes from the discrete definition.  By analogy with the discrete case, we will say that two  jointly continuous random variables are independent if ", "the joint PDF is equal to the product of the marginal PDFs.  We can now compare with the multiplication rule, which is  always true as long as the density of Y is positive. ", "So this is always true.  In the case of independence, this is true.  So in the case of independence, we must have  that this term is equal to that term, at least whenever ", "this quantity--  the marginal of Y--  is positive.  So to restate it, independence is equivalent to having the ", "conditional, given Y, be the same as the unconditional PDF  of X. And this has to be true whenever Y has a positive  density so that this quantity is well defined, and it also ", "has to be true for all xs.  Now, what does this really mean?  The conditional PDF, as we have discussed, in terms of  pictures, is a slice of the joint PDF. ", "Therefore, independence is the same as requiring that all of  the slices of the joint have the same shape, and it is the  shape of the marginal PDF. ", "For a more intuitive interpretation, no matter what  value of Y you observe, the distribution  of X does not change.  In this sense, Y does not convey any information about ", "X. Notice also that this definition is symmetric as far  as X and Y are concerned.  So by symmetry, when we have independence, it also means ", "that X does not convey any information about Y, and that  the conditional density of Y, given X, has to be the same as  the unconditional density of Y. ", "We can also define independence of multiple  random variables.  The definition is the obvious one.  The joint PDF of all the random variables involved must  be equal to the product of the marginal PDFs. ", "Intuitively, what that means is that knowing the values of  some of the random variables does not affect our beliefs  about the remaining random variables.  Finally, let us note some consequences of independence, ", "which are identical to the corresponding properties that  we had in the discrete case, and the proofs are also  exactly the same.  So the expectation of the product of independent random  variables is the product of the expectations, the variance ", "of the sum of independent random variables is the sum of  the variances, and functions of independent random  variables are also independent, which, in  particular, implies, using the previous rule, that the ", "expected value of a product of this kind is going to be the  product of these expectations.  So independence of continuous random variables is pretty ", "much the same as independence of discrete random variables  as far as mathematics are concerned, and the intuitive  content of the independence assumption is the same as in ", "the discrete case.  One random variable does not provide any  information about the other.    We will now go through an example that brings together  all of the concepts that we have introduced. ", "We have a stick of length l.   And we break that stick at some random location, which ", "corresponds to a random variable, X.  And we assume that this random variable is uniform over the  length of the stick. ", "So its PDF has this particular shape.  And for the PDF to integrate to 1, the height of this PDF  must be equal to 1 over l.  Then we take the piece of the stick that we are left with, ", "which has length X, and we break it at a random location,  which we call Y. And we assume that this location Y is  uniformly distributed over the length of the stick that we ", "were left with.  What does this assumption mean?  It means that if the first break was at some particular  value, x, then the random variable Y has a conditional ", "distribution, which is uniform over the interval from 0 to x.  So the conditional PDF is uniform.  A conditional PDF, like any other PDF, must ", "integrate to 1.  So the height of this conditional PDF is  equal to 1 over x.  Are X and Y independent?  No.  One way to see it is that if you change little x, the ", "conditional PDF of Y would have been something different.  Whereas if we have independence, all the  conditional PDFs have to be the same when you change the ", "value of little x.  Another way to see it is that if I tell you that x is 0.5,  this gives you lots of information about Y. It tells ", "you that Y has to be less than or equal to 0.5.  So the value of the random variable X gives you plenty of  information about the other random variable.  And so we do not have independence. ", "Notice that in this example, instead of starting with a  full description of the random variables in terms of a joint  PDF, we use a marginal PDF and then a conditional PDF to ", "construct our model.  Of course, with these two pieces of information, we can  reconstruct the joint PDF using the multiplication rule. ", "The marginal is 1 over l.  The conditional is 1 over x.  So the joint is equal to 1 over lx.  But for which values of x and y is this the correct ", "expression?  It is correct only for those values that are possible.  So 0 has to be less than y, less than x, less than l. ", "This is the range of values that are possible in this  particular experiment.  And we can visualize those values.  They are those that correspond to this shaded triangle here. ", "x and y are less than or equal to l.  And y has to be less than or equal to x.  If you try to visualize the joint PDF, notice that since ", "it only depends on x not on y, if you fix a value of x and  you look at the slice of the joint PDF, the value of the  joint PDF is going to be a constant on that slice. ", "On this slice, it's going to be another constant, actually  a bigger one.  On that slice, an even bigger constant.  And actually, this constant is bigger and bigger and goes to ", "infinity as we approach 0.  Of course, the fact that the slice is constant is just a  reflection of the fact that the conditional PDF is ", "constant over the range of values that the random  variable can take.  Let us now continue with some calculations.  Let us find the marginal PDF of Y. How do we do it? ", "Since we have in our hands the joint PDF, we can find the  marginal by integrating the joint.  ", "And in our case, the joint is equal to 1 over lx.  And we integrate over all x's.  Now, what is the range of the integration? ", "If we fix a certain value of y, the joint PDF is actually 0  in this region and in that region.  So we should only integrate over x's that correspond to ", "this interval.  What is that interval?  It's the interval that ends at l.  And because this is a line of slope 1, this value ", "here is also y.  So we integrate over an interval where x  ranges from y to l.  In fact, this is just the range of x's that are possible ", "for a given value of y.  x must always be larger than or equal to y.  Now, the integral of 1 over x is a logarithm.  And using this fact, we can evaluate this integral. ", "And it's 1 over l times the logarithm of l over y.  For what y's is this a correct expression? ", "Well, it makes sense only for those y's that are possible in  this experiment.  And that's the range from 0 to l. ", "When y is equal to l, we have the logarithm of 1, which is  equal to 0.  So the value of the PDF is 0 here.  As y decreases, this ratio ", "increases and goes to infinity.  So the log of that also blows up to infinity.  And we get a shape of this form, where the function that ", "we're dealing with goes to infinity as we approach 0.  Is this a problem having a PDF that blows up to infinity?  Not really.  As long as the area under this PDF is equal to 1, it's still ", "a legitimate PDF.  And blowing up to infinity is not an issue.  Let us now calculate the expected value of Y. One way ", "of doing this is by using the definition of the expectation.  It's the integral of y times the density of y, which is 1  over l times the log of l over y. ", "And the range of integration has to be those values for  which we have a non-zero density.  So we integrate from 0 to l, which are the possible values  of the random variable Y. This is an integral ", "that's pretty messy.  One can actually integrate it using integration by parts.  But the calculation is a bit tedious.  So let us look for an alternative ", "and more clever approach.  The idea is to divide and conquer.  We're going to use the total expectation theorem, where  we're going to condition on X. The total expectation theorem ", "tells us that the expected value of Y is the integral  over all possible values of the random variable X, which  is from 0 to l. ", "The density of X, which is 1 over l, times the conditional  expectation of Y given that X is equal to some little x. ", "And we integrate over all x's.  Why is this simpler?  When we condition on X taking a specific value, Y has a ", "uniform distribution between 0 and x.  And therefore, this conditional expectation is the  expectation of a uniform, which is 1/2 the  range of that uniform. ", "So we obtain the integral from 0 to l.  1 over l times x over 2, dx.  ", "And finally, that's an integral that we  can evaluate easily.  Or we can think even in a simpler way.  This expression here is the density of x. ", " This is x itself.  So the integral of this times x gives us the expected value  of X. And there's only a factor of 1/2 ", "that's left out there.  So we obtain 1/2 the expected value of X. But now, X itself  is uniform on an interval that has length l. ", "And therefore, the expected value of x is l over 2.  And so we get the final answer, which is 1/2 times l  over 2, which is l over four. ", "This answer makes intuitive sense.  If we break a stick once, the expected value or what we're  left with is half of what we started with. ", "But if we break it once more, then we expect it on the  average to be cut by a factor again of 1/2.  And so we expect to be left with a stick that has length ", "1/4 of what we started with.   So this example is a particularly nice one, because  we used all of the concepts that we have introduced-- ", "marginal PDFs, joint PDFs, conditional PDFs, and the  relations between them, as well as expectations,  calculations of expectations, and conditional expectations, ", "as well as the total probability theorem.    Just in order to get some more familiarity with joint PDFs,  let us look at independent normals.  Actually, this is an important example because noise is often ", "modeled by normal random variables, and noise terms  that show up at different parts of a system, or at  different times, are often assumed to be independent.  Suppose that we have two standard normal random ", "variables, X and Y, with zero means and unit variances.  If their independent, their joint PDF is the product of  the marginal PDFs and takes this form. ", "This is just the PDF of a standard normal X and the PDF  of a standard normal Y and we multiply them.  If we are to plot this joint PDF we obtain this figure. ", "It looks like a bell which is centered at the origin--  at the point with coordinates zero, zero.  One way to think about what is going on here is to rewrite ", "this expression as 1 over 2pi, and then the exponential of  minus 1/2 x squared plus y squared. ", " If we look at the unit circle in xy space, which is the set ", "of points at which x squared plus y squared is equal to 1,  then, on that circle, the PDF takes a constant value because ", "this quantity is constant on that circle.  And the same is true for any other circle.  On any circle the PDF takes a constant value, of course, a ", "different constant.  So the circles centered at the origin are the so-called  contours of the joint PDF.  On each contour the joint PDF is a constant. ", "Let us now generalize.  Consider two independent normal random variables, but  with general means mu x and mu y, and variances sigma x ", "squared and sigma y squared.  The joint is, again, the product of the marginal PDFs  and, therefore, takes this form. ", "This looks intimidating but, in fact, it is pretty simple.  This part is just a normalizing constant.  It is the constant that's needed so that the joint PDF ", "integrates to 1.  What we have here is the negative exponential of a  quadratic function of x and y.  Let us plot the contours of this quadratic. ", "Remember that contour is the set of points where the  quadratic takes a constant value.  And by consequence, the joint PDF also  takes a constant value. ", "If you have set this quadratic to a constant, what you have  is the equation that describes an ellipse.  And it is an ellipse whose principal axes run along the x ", "and y directions, and those ellipses are all centered at  this particular point, mu x, mu y.  The joint PDF is largest when the exponent is equal to zero. ", "And this happens when x is equal to mu x, and y  is equal to mu y.  That is, right at the center of the ellipse.  That's where the joint PDF is largest. ", "As you move to ellipses that are further out on this outer  ellipse, this expression is a constant.  It's the exponential of the negative of  some positive numbers. ", "So you get a smaller value for the joint PDF.  If you move to a further ellipse further out, then  again, the joint PDF will be a constant, but it's going to be ", "a smaller constant.  Now, for the case of standard normals, the joint PDF was  circularly symmetric.  The contours were actually circles, instead of ellipses. ", "But this is not the case in general.  For example, suppose that the variance of Y is bigger than  the variance of X. Then you get a shape as the one shown ", "in this figure.  Since the variance of Y is larger, we expect Y to take  values over a bigger range, and to be larger typically ", "than the values of X. And so the bell shape that we have  for the joint PDF is stretched in the y direction.  It extends further out in the y direction than it does in ", "the x direction.  To conclude, the joint PDF of two independent normals has  the shape of a bell.  The center of the bell is determined by the means. ", "Furthermore, the bell is stretched in the x and y  directions by an amount that is determined by the variances  of x and y.  However, the stretching is always along ", "the coordinate axes.  If you wanted a bell that stretches in some diagonal  direction, or if you have contours that are ellipses but ", "with some different kinds of axes, then you will have  dependence between the two random variables.  In that case, we will be dealing with a so-called ", "bivariate normal distribution, but we will not pursue this  any further at this point.    If you remember our discussion from a long time ago, we said ", "that much of this class consists of variations of a  few basic skills and ideas, one of which is the Bayes  rule, the foundation of inference.  So let's look here at the Bayes rule again and its ", "different incarnations.  In a discrete setting we have a random variable with a known  PMF but whose values are not observed.  Instead we observe the value of another random variable, ", "call it Y, which has some relation with X.  And we will use the value of Y to make some inferences about  X. The relation between the two random variables is ", "captured by specifying the conditional PMF of Y given any  value of X. Think of X as an unknown state of the world and  of Y as a noisy observation of X. The conditional PMF tells ", "us the distribution of Y under each possible  state of the world.  Once we observe the value of Y we obtain some information  about X. And we use this information to make inferences ", "about the likely values of X. Mathematically, instead of  relying on the prior for X, we form some revised beliefs.  That is, we form the conditional [PMF] ", "of X given the particular observation that we have seen.  All this becomes possible because of the Bayes rule.  We have seen the Bayes rule for events. ", "But it is easy to translate into PMF notation.  We take the multiplication rule.  And we use it twice in different orders to get two  different forms-- ", "or two different expressions--  for the joint PMF.  We then take one of the terms involved here and send it to  the other side. ", "We obtain this expression, which is the Bayes rule.  What [do] we have here?  We want to calculate the conditional distribution of X  which we typically call the posterior. ", " And to do this we rely on the prior of X as well as on the ", "model that we have for the observations.  The denominator requires us to compute the marginal of Y. But  this is something that is easily done because we have ", "the joint available.  The numerator, this expression here, is just the joint PMF.  And using the joint PMF you can always find  the marginal PMF. ", "Essentially, we're using here the total probability theorem.  And we're using the pieces of information that were given to  us, the prior and the model of the observations. ", "When we're dealing with continuous random variables  the story is identical.  We still have two versions of the multiplication rule.  By sending one term--  this term--  to the other side of the equation we ", "get the Bayes rule.  And then we use the total probability theorem to  calculate the denominator term.  So as far as mathematics go, the story is pretty simple. ", "It is exactly the same in the discrete and  the continuous case.  This story will be our stepping stone for dealing  with more complex models and also when we go into more ", "detail on the subject of inference  later in this course.    We have seen two versions of the Bayes rule--  one involving two discrete random variables, and another ", "that involves two continuous random variables.  But there are many situations in real life when one has to  deal simultaneously with discrete and  continuous random variables. ", "For example, you may want to recover a discrete digital  signal that was sent to you, but the signal has been  corrupted by continuous noise so that your observation is a ", "continuous random variable.  So suppose that we have a discrete random variable K,  and another continuous random variable, Y. In order to get a ", "variant of the Bayes rule that applies to this situation, we  will proceed as in the more standard cases.  We will use the multiplication rule twice to get two ", "alternative expressions for the probability  of two events happening.  We will equate those expressions, and from these,  derive a version of the Bayes rule. ", "So we will look at the probability that the discrete  random variable takes on a certain numerical value, and, ", "simultaneously, the continuous random variable takes a value  inside a certain small interval.  So here, delta is a positive number, which we will take to ", "be very small.  And in fact, we will be interested in the limiting  case as delta goes to 0.  So now we use the multiplication rule.  The probability of two events is equal to the probability of ", "the first event times the conditional probability of the  second event given that the first event has occurred. ", " But we know that we can use the multiplication rule in any  order, so the probability of two events happening can also  be written as the probability that the second event occurs ", "times the conditional probability that the first  event occurs, given that the second event has occurred.  ", "So these two expressions that we obtain from the  multiplication rule have to be equal.  Let us rewrite those expressions using PMF notation  and PDF notation. ", "What do we have here?  The probability that a discrete random variable takes  on a certain value--  that's just the PMF of this random variable evaluated at a ", "particular point.  And what do we have here?  The probability that the random variable, Y, a  continuous random variable, takes values inside an  interval is always equal to the PDF of that random ", "variable times the length of this interval.  And this is an approximate equality.  However, because here we're talking about the probability ", "of being in a small interval conditioned on a certain  event, we should be using a conditional PDF.  It's the conditional PDF conditioned on the random ", "variable, capital K, and conditioned on the specific  event that this discrete random variable takes on a  certain value, little k. ", "Let us do a similar notation change for the second  expression.  Here we have the probability--  the unconditional probability--  that Y takes a value inside a small interval, and when delta ", "is small, this is approximately equal to the PDF  of the random variable Y times the length of the interval.  And what do we have here?  The probability that a discrete random variable takes ", "on a certain value, that just corresponds to the PMF of that  the random variable.  However, we're talking about a conditional probability given ", "that a random variable Y takes a value that's approximately  equal to a certain little y.  So this is a notation that we have not used before, but its ", "meaning should be unambiguous at this point.  But just by arguing by analogy to what we have been doing all  along, it's a PMF of a discrete random variable. ", "But it is a conditional PMF.  It describes to us the probability distribution of  the discrete random variable K when the random variable Y, ", "which happens to be a continuous one, takes on a  specific value.  So we can cancel the deltas from both sides, and we have  that this expression is approximately equal to that ", "expression, and this approximate equality is more  and more exact as we send delta to 0.  But delta has already disappeared from here, so we  can set these two expressions equal to each other. ", "At this point, now, we can take this term and move it to  the other side of the equality so it will go to the  denominator.  And we obtain this version of the Bayes rule. ", "It gives us the conditional probability of a random  variable K given that a certain continuous random  variable Y has taken on a specific value. ", "So this version is useful if we have a continuous noisy  observation, Y, on the basis of which we're trying to say ", "something, to make inferences about the discrete random  variable K. And in order to apply the Bayes rule, we need  to know the unconditional distribution of the random ", "variable K, and we also need to have a model of the noisy  observation--  a model of that observation under each possible  conditional universe. ", "So for any possibility for the random variable K, we need to  know the distribution of the random variable Y.  Or, alternatively, we can take this term and send it to the ", "denominator of the other side, and we get a different version  of the Bayes rule.  This version of the Bayes rule applies if we're trying to  make an inference about a continuous random variable Y, ", "given that we know the value of a certain related  observation, K, of a random variable, capital K. ", "In both versions of the Bayes rule, there's also a  denominator term which needs to be evaluated.  This term gets evaluated similar to the cases that we  have considered earlier, and they are determined by using a ", "suitable version of the total probability theorem.  This is a version of the total probability theory that we  have already seen.  We have a conditional density of Y under different scenarios ", "for the random variable capital K, and we get the  density of Y by considering the conditional densities and  weighing them according to the probabilities of the different ", "discrete scenarios.  This version of the total probability theorem is  something that we have not proved so far, and we ", "have not seen it.  On the other hand, it's not hard to derive.   If we fix the value of k, this is a density, and therefore it ", "must integrate to 1.  So the integral of this ratio, with respect to y, has to be  equal to 1.  Now, there's no y in the denominator, so the integral ", "of the numerator divided by the denominator has to be  equal to 1, which means that the denominator must be equal  to the integral of the numerator when we integrate ", "overall y's, and this is just what this  expression is saying.  So what we will do next will be to consider one example for  each one of these two cases of the Bayes rule that we have ", "just derived.    We will now use the Bayes rule in an important application  that involves a discrete unknown random variable and a ", "continuous measurement.  Our discrete unknown random variable will be one that  takes the values plus or minus 1 with equal probability. ", " And the measurement will be another random variable, Y,  which is equal to the discrete random variable, but corrupted ", "by additive noise that we denote by W. So what we get to  observe is the sum of K and W.  This is a common situation in digital communications. ", "We're trying to send one bit of information whether K is  plus 1 or minus 1, but the observation that we're making  is corrupted by a communication channel, by some ", "noise that is present in the channel, and on the basis of  the value of Y that we will observe, we will try to guess  what was sent.  The assumption that we will make about the noise is that ", "it is a standard normal random variable.  So suppose that we observed a specific value for the random  variable Y. We want to make a guess about the random ", "variable capital K. Of course, there's no way to guess with  complete certainty.  The only thing that we can say is to determine how likely it  is that a 1 was sent as opposed to how likely it is ", "that a minus 1 was sent.  How do we approach such a problem?  Well, we use the version of the Bayes rule that we have  already developed, which is this formula that gives us the ", "conditional probabilities that we want.  And in particular, here, we're asking a question about the  conditional probability that K takes the value of 1 given ", "that a value of y has been observed.  This is what we want to calculate.  So let us look at the various terms involved here and see ", "what each term is.  First, we need the prior probability  of K. This is simple.  The prior probabilities are 1/2 for k equal to minus 1 or ", "plus 1, because we said that the two possibilities are  equally likely.  Then we need the conditional density of Y given K. So what  does this assumption mean? ", "It means that Y is a standard normal random variable to  which we add the value of K. So if K is equal to 1, we're ", "taking a standard normal, and we add a value of plus 1.  So Y, given that K is equal to plus 1, is going to be a ", "standard normal plus 1.  What does that do?  If we take a standard normal and add a constant to it, that  changes the mean and makes the mean equal to 1, and does not ", "change the variance.  On the other hand, if K happens to be equal to minus  1, then the observation that we see is going to be a ", "standard normal plus a value of minus 1, and that changes  the mean to become minus 1, but with a variance of 1.  So if we are to plot the density of Y, that density, of ", "course, will depend on what the value of K was.  And if K is equal to 1, then we will obtain a normal that ", "has a mean of 1, so it's centered here.  But if K is equal to minus 1, then our observation will be a ", "normal with unit variance, but centered at minus 1.   So if we are to write this in terms of symbols, the ", "distribution of Y is normal with variance equal to 1.  So the PDF is given by this form, e to the minus 1/2 y ", "minus the mean of Y. But given the value of K, the mean of Y  is equal to k, plus or minus 1, depending on what k is. ", "So this is the PDF of a normal with unit variance and mean  equal to k.  And it corresponds, when you set k equal to 1, it ", "corresponds to this graph.  When you set K equal to minus 1, it  corresponds to that graph.  Let us continue with the next term in this expression. ", "We need the term in the denominator, which is obtained  by taking a sum over the different choices of k.  There are 2 choices, and each choice has a ", "probability of 1/2.  From the first choice, we have 1/2 times the density of Y  when k is equal to minus 1.  ", "And when k is equal to minus 1, we obtain this expression.  And we have another term that corresponds to the case where  k is equal to plus one, in which case we have this ", "expression here.  Once more, this expression here corresponds to this  normal with a mean of minus 1.  This expression here corresponds to a normal with a ", "mean of plus 1, which is this graph here.  So at this point, we have in our hands expressions for  everything that is involved here, and we can just apply ", "the formula and carry out a fair amount of algebra.  There are some very nice simplifications that happen  along the way, and we end up with an answer that has the ", "following form.  It's 1 divided by 1 plus e to the minus 2 y. ", "And this gives us the probability that a 1 was sent.  Let us try to make sense of this expression.  Let's see what it looks like by plotting it as ", "a function of y.   So what we're plotting here is this expression.  OK, if y is very large, as y goes to plus infinity, this ", "term disappears, and we obtain a 1.   If, on the other hand, y is very, very negative--  so y goes to minus infinity-- ", "here we get to e to the infinity, which is a very  large number.  So this ratio is going to converge to 0.  So we have a graph that starts at 0. ", "It actually rises monotonically, and in the  limit, converges to 1.  If y is equal to 0, then this term is 1, ", "and we obtain a 1/2.   Let us interpret this plot.  If y is very large, it is much more likely that y is coming ", "out of this distribution so that K is equal to 1.  So the probability that K is equal to 1, if we obtain this  observation, is almost 1. ", "We have almost certainty.  If, on the other hand, y is very, very negative, then it  is much more likely that what we're seeing is coming from  this distribution so that K is equal to minus 1. ", "And in that case, the probability that K was 1 is  going to be approximately 0.  Finally, if y is 0, then we're just in the middle of the two ", "possibilities, and by symmetry, either choice of K  is equally likely.  Therefore, the posterior probability that K is equal to  1, given that Y was equal to 0-- ", "that probability is 1/2.  When Y is equal to 0, it's equally likely that either  signal was sent.  This example is a prototype of the kind of calculations that ", "are done in the analysis of communication systems.  This is the simplest model of communication of a single bit  in the presence of additive noise, but of course, there ", "can also be more complicated models in which we have more  complicated signals that are sent, and more complicated  models of the noise.  But the general principles of the analysis are ", "always of this kind.  We're using the Bayes rule, and we need to write down the  different terms that are involved.    We now look at an application of the Bayes rule that's ", "involves a continuous unknown random variable, which we try  to estimate based on a discrete measurement.  Our model will be as follows. ", "We observe the discrete random variable K, which is  Bernoulli, so it can take two values, 1 or 0.  And it takes those values with probabilities y and 1 minus y, ", "respectively.  This is our model of K. The catch is that the value of y  is not known.  And it is modeled as a random variable by itself. ", "You can think of a situation where we are dealing with a  single coin flip.  We observe the outcome of the coin flip,  but the coin is biased.  The probability of heads is some unknown number, y. ", "And we try to infer or say something about the bias of  the coin on the basis of the observation that we have made.  So what do we assume about this y or ", "the bias of the coin?  If we know nothing about this random variable, we might as  well model it as a uniform random  variable on the unit interval. ", "And the question now is, given that we made one observation  and the outcome was 1, what can we say about the  probability distribution of Y given this particular ", "information?  So the question that we're asking is, what we can tell  about the density of Y given that the value ", "of 1 has been observed.  The way to approach this problem is by using a version  of the Bayes rule.  We want to calculate this quantity for the special case ", "where k is equal to 1.  So let us calculate the various pieces on the right  hand side of this equation.  The first piece is the density of Y. This is the prior ", "density before we obtain any measurement.  And since the random variable is uniform, this is equal to 1  for y in the unit interval. ", "And of course, it is 0 otherwise.   The next piece that we need is the distribution of K given ", "the value of Y. Well, given Y, K takes a value of 1, with  probability equal to Y-- ", "so the probability of 1, if we're told the value of y is  just a y itself.  y is the bias of the coin that we're dealing with. ", "The next term that we need is the denominator.  We will use this formula.  It is the integral of the density of Y, ", "which is equal to 1.  And it is equal to 1 only on the range from 0 to 1, times  this probability that K takes a value, a certain value. ", "In this case, we're dealing with a value of 1, so here  we're going to put 1 instead of k.  And therefore, we're dealing with this expression here,  which is just y. ", "And we integrated over y's.  So this is y squared over 2, evaluated at 0 and 1, which  gives us 1/2. ", "So this is the unconditional probability that  K is equal to 1.  If we know nothing about Y, by symmetry, higher biases are  equally likely as lower biases. ", "So we should expect that it's equally likely to give us a 1  as it is to give us a 0.  Now, we have in our hands all the pieces that go into this ", "particular formula.  And we can go ahead with the final calculation.  So in the numerator, we have 1 times this term, evaluated at ", "k equal to 1, which is equal to y.  And then in the denominator, we have a term that  evaluates to 1/2.  So the final answer is 2y. ", "Over what range of y's is this correct?  Only for those y's that are possible.  So this is for y's in the unit interval.  ", "If we are to plot this PDF, it has this shape.  ", "This is a plot of the PDF of Y given that the random variable  K takes on a value of 1.  Initially, we started with a uniform for Y. So all values ", "of Y were equally likely.  But once we observed an outcome of 1, this tells us ", "that perhaps Y is on the higher end  rather than lower end.  So after we obtain our observation, the random ", "variable Y has this distribution, with higher  values being more likely than lower values.  This example is a prototype of situations where we want to ", "estimate a continuous random variable based on discrete  measurements.  Essentially it is the same as trying to estimate the bias of  a coin based on a single measurement of the ", "result of a coin flip.  As you can imagine, there are generalizations in which we  observe multiple coin flips.  And this is an example that we will see ", "later on in this class.  "], "vid_duration": [11.16, 10.79, 12.27, 10.63, 12.74, 10.53, 10.25, 13.29, 11.168, 10.41, 12.96, 11.52, 10.94, 12.47, 11.14, 12.83, 11.14, 10.649, 13.301, 13.449, 11.411, 10.019, 12.011, 11.08, 11.895, 12.115, 10.1, 10.97, 12.52, 11.18, 10.92, 16.47, 11.759, 12.056, 10.365, 10.72, 12.91, 12.84, 10.169, 10.221, 12.979, 11.021, 14.18, 11.419, 11.1, 10.62, 10.46, 10.49, 14.78, 12.99, 15.89, 14.43, 13.41, 10.84, 10.13, 11.47, 12.54, 10.31, 12.25, 13.38, 10.63, 12.63, 12.86, 13.21, 13.07, 13.15, 11.642, 12.02, 10.71, 12.25, 13.12, 11.34, 10.9, 11.73, 11.64, 12.41, 11.3, 13.85, 13.1, 11.29, 12.56, 12.98, 14.18, 14.9, 12.74, 14.21, 13.359, 12.491, 12.46, 12.2, 11.67, 10.236, 10.41, 13.1, 15.01, 11.83, 10.78, 13.45, 13.05, 12.57, 12.43, 11.33, 13.14, 11.97, 12.15, 13.399, 13.101, 10.25, 10.84, 12.492, 10.611, 10.879, 12.871, 13.169, 13.541, 10.979, 13.431, 11.079, 11.45, 12.641, 10.48, 10.07, 12.12, 14.3, 10.619, 12.221, 12.789, 10.481, 13.289, 13.801, 11.489, 11.5, 13.591, 11.869, 11.781, 12.91, 11.91, 11.394, 10.916, 10.62, 14.38, 10.05, 15.22, 12.569, 10.171, 13.319, 11.411, 13.97, 10.04, 11.78, 10.9, 13.185, 11.764, 12.161, 13.26, 10.88, 12.139, 13.441, 11.98, 13.344, 12.24, 10.41, 12.42, 12.75, 12.68, 11.42, 11.9, 10.72, 12.91, 11.56, 10.419, 11.011, 12.94, 11.2, 10.39, 14.09, 11.76, 12.11, 10.77, 12.27, 11.8, 11.2, 11.82, 12.01, 12.45, 10.3, 10.83, 12.995, 12.509, 12.87, 11.121, 13.96, 12.459, 12.291, 10.12, 11.21, 10.1, 11.21, 11.94, 11.489, 11.421, 10.829, 12.671, 11.59, 10.41, 12.018, 10.91, 11.06, 11.1, 11.14, 10.11, 10.13, 11.75, 12.93, 14.381, 18.009, 13.69, 11.17, 10.28, 15.351, 10.319, 11.08, 11.26, 12.42, 11.25, 13.25, 13.02, 12.34, 10.58, 12.17, 13.3, 14.761, 11.899, 10.91, 12.55, 11.2, 13.58, 12.35, 11.011, 13.699, 12.591, 10.279, 11.37, 15.66, 11.88, 11.19, 14.85, 11.765, 10.74, 14.28, 12.32, 11.63, 11.98, 12.24, 12.66, 10.38, 11.91, 10.099, 12.631, 11.92, 10.38, 11.38, 11.46, 10.91, 16.12, 11.18, 11.621, 14.569, 15.471, 11.879, 10.93, 11.25, 10.34, 13.52, 16.67, 12.52, 10.11, 13.84, 10.73, 10.54, 13.87, 12.16, 13.79, 11.78, 14.4, 11.08, 12.54, 11.31, 13.09, 12.71, 10.64, 11.03, 11.261, 10.22, 12.891, 11.699, 13.381, 11.259, 11.0, 12.661, 11.169, 13.851, 13.54, 12.189, 13.436, 10.154, 10.42, 11.301, 13.359, 11.75, 12.04, 11.01, 10.24, 11.71, 11.931, 11.299, 10.21, 14.471, 11.829, 10.47, 10.57, 12.861, 10.219, 2.909], "stet": [[0, 11.16], [11.16, 21.95], [21.95, 34.22], [34.22, 44.85], [44.85, 57.59], [57.59, 68.12], [68.12, 78.37], [78.37, 91.66], [91.66, 102.828], [102.828, 113.238], [113.238, 126.19800000000001], [126.19800000000001, 137.71800000000002], [137.71800000000002, 148.65800000000002], [148.65800000000002, 161.12800000000001], [161.12800000000001, 172.26800000000003], [172.26800000000003, 185.09800000000004], [185.09800000000004, 196.23800000000006], [196.23800000000006, 206.88700000000006], [206.88700000000006, 220.18800000000005], [220.18800000000005, 233.63700000000006], [233.63700000000006, 245.04800000000006], [245.04800000000006, 255.06700000000006], [255.06700000000006, 267.0780000000001], [267.0780000000001, 278.1580000000001], [278.1580000000001, 290.05300000000005], [290.05300000000005, 302.16800000000006], [302.16800000000006, 312.2680000000001], [312.2680000000001, 323.2380000000001], [323.2380000000001, 335.7580000000001], [335.7580000000001, 346.9380000000001], [346.9380000000001, 357.8580000000001], [357.8580000000001, 374.3280000000001], [374.3280000000001, 386.0870000000001], [386.0870000000001, 398.1430000000001], [398.1430000000001, 408.5080000000001], [408.5080000000001, 419.2280000000001], [419.2280000000001, 432.13800000000015], [432.13800000000015, 444.9780000000001], [444.9780000000001, 455.1470000000001], [455.1470000000001, 465.3680000000001], [465.3680000000001, 478.3470000000001], [478.3470000000001, 489.3680000000001], [489.3680000000001, 503.5480000000001], [503.5480000000001, 514.9670000000001], [514.9670000000001, 526.0670000000001], [526.0670000000001, 536.6870000000001], [536.6870000000001, 547.1470000000002], [547.1470000000002, 557.6370000000002], [557.6370000000002, 572.4170000000001], [572.4170000000001, 585.4070000000002], [585.4070000000002, 601.2970000000001], [601.2970000000001, 615.7270000000001], [615.7270000000001, 629.1370000000001], [629.1370000000001, 639.9770000000001], [639.9770000000001, 650.1070000000001], [650.1070000000001, 661.5770000000001], [661.5770000000001, 674.1170000000001], [674.1170000000001, 684.427], [684.427, 696.677], [696.677, 710.057], [710.057, 720.687], [720.687, 733.317], [733.317, 746.177], [746.177, 759.3870000000001], [759.3870000000001, 772.4570000000001], [772.4570000000001, 785.6070000000001], [785.6070000000001, 797.2490000000001], [797.2490000000001, 809.2690000000001], [809.2690000000001, 819.9790000000002], [819.9790000000002, 832.2290000000002], [832.2290000000002, 845.3490000000002], [845.3490000000002, 856.6890000000002], [856.6890000000002, 867.5890000000002], [867.5890000000002, 879.3190000000002], [879.3190000000002, 890.9590000000002], [890.9590000000002, 903.3690000000001], [903.3690000000001, 914.6690000000001], [914.6690000000001, 928.5190000000001], [928.5190000000001, 941.6190000000001], [941.6190000000001, 952.9090000000001], [952.9090000000001, 965.469], [965.469, 978.4490000000001], [978.4490000000001, 992.629], [992.629, 1007.529], [1007.529, 1020.269], [1020.269, 1034.479], [1034.479, 1047.838], [1047.838, 1060.329], [1060.329, 1072.789], [1072.789, 1084.989], [1084.989, 1096.659], [1096.659, 1106.8950000000002], [1106.8950000000002, 1117.3050000000003], [1117.3050000000003, 1130.4050000000002], [1130.4050000000002, 1145.4150000000002], [1145.4150000000002, 1157.2450000000001], [1157.2450000000001, 1168.025], [1168.025, 1181.4750000000001], [1181.4750000000001, 1194.525], [1194.525, 1207.095], [1207.095, 1219.525], [1219.525, 1230.855], [1230.855, 1243.9950000000001], [1243.9950000000001, 1255.9650000000001], [1255.9650000000001, 1268.1150000000002], [1268.1150000000002, 1281.5140000000001], [1281.5140000000001, 1294.6150000000002], [1294.6150000000002, 1304.8650000000002], [1304.8650000000002, 1315.7050000000002], [1315.7050000000002, 1328.1970000000001], [1328.1970000000001, 1338.8080000000002], [1338.8080000000002, 1349.6870000000001], [1349.6870000000001, 1362.5580000000002], [1362.5580000000002, 1375.7270000000003], [1375.7270000000003, 1389.2680000000003], [1389.2680000000003, 1400.2470000000003], [1400.2470000000003, 1413.6780000000003], [1413.6780000000003, 1424.7570000000003], [1424.7570000000003, 1436.2070000000003], [1436.2070000000003, 1448.8480000000004], [1448.8480000000004, 1459.3280000000004], [1459.3280000000004, 1469.3980000000004], [1469.3980000000004, 1481.5180000000003], [1481.5180000000003, 1495.8180000000002], [1495.8180000000002, 1506.4370000000001], [1506.4370000000001, 1518.6580000000001], [1518.6580000000001, 1531.4470000000001], [1531.4470000000001, 1541.928], [1541.928, 1555.217], [1555.217, 1569.018], [1569.018, 1580.507], [1580.507, 1592.007], [1592.007, 1605.598], [1605.598, 1617.4669999999999], [1617.4669999999999, 1629.2479999999998], [1629.2479999999998, 1642.158], [1642.158, 1654.068], [1654.068, 1665.462], [1665.462, 1676.378], [1676.378, 1686.9979999999998], [1686.9979999999998, 1701.378], [1701.378, 1711.4279999999999], [1711.4279999999999, 1726.648], [1726.648, 1739.2169999999999], [1739.2169999999999, 1749.388], [1749.388, 1762.7069999999999], [1762.7069999999999, 1774.118], [1774.118, 1788.088], [1788.088, 1798.128], [1798.128, 1809.908], [1809.908, 1820.808], [1820.808, 1833.993], [1833.993, 1845.7569999999998], [1845.7569999999998, 1857.918], [1857.918, 1871.1779999999999], [1871.1779999999999, 1882.058], [1882.058, 1894.197], [1894.197, 1907.638], [1907.638, 1919.618], [1919.618, 1932.962], [1932.962, 1945.202], [1945.202, 1955.612], [1955.612, 1968.0320000000002], [1968.0320000000002, 1980.7820000000002], [1980.7820000000002, 1993.4620000000002], [1993.4620000000002, 2004.8820000000003], [2004.8820000000003, 2016.7820000000004], [2016.7820000000004, 2027.5020000000004], [2027.5020000000004, 2040.4120000000005], [2040.4120000000005, 2051.9720000000007], [2051.9720000000007, 2062.3910000000005], [2062.3910000000005, 2073.4020000000005], [2073.4020000000005, 2086.3420000000006], [2086.3420000000006, 2097.5420000000004], [2097.5420000000004, 2107.9320000000002], [2107.9320000000002, 2122.0220000000004], [2122.0220000000004, 2133.7820000000006], [2133.7820000000006, 2145.8920000000007], [2145.8920000000007, 2156.6620000000007], [2156.6620000000007, 2168.9320000000007], [2168.9320000000007, 2180.732000000001], [2180.732000000001, 2191.9320000000007], [2191.9320000000007, 2203.752000000001], [2203.752000000001, 2215.762000000001], [2215.762000000001, 2228.212000000001], [2228.212000000001, 2238.512000000001], [2238.512000000001, 2249.342000000001], [2249.342000000001, 2262.337000000001], [2262.337000000001, 2274.846000000001], [2274.846000000001, 2287.716000000001], [2287.716000000001, 2298.837000000001], [2298.837000000001, 2312.797000000001], [2312.797000000001, 2325.2560000000008], [2325.2560000000008, 2337.547000000001], [2337.547000000001, 2347.667000000001], [2347.667000000001, 2358.877000000001], [2358.877000000001, 2368.9770000000008], [2368.9770000000008, 2380.187000000001], [2380.187000000001, 2392.127000000001], [2392.127000000001, 2403.616000000001], [2403.616000000001, 2415.0370000000007], [2415.0370000000007, 2425.866000000001], [2425.866000000001, 2438.5370000000007], [2438.5370000000007, 2450.127000000001], [2450.127000000001, 2460.5370000000007], [2460.5370000000007, 2472.5550000000007], [2472.5550000000007, 2483.4650000000006], [2483.4650000000006, 2494.5250000000005], [2494.5250000000005, 2505.6250000000005], [2505.6250000000005, 2516.7650000000003], [2516.7650000000003, 2526.8750000000005], [2526.8750000000005, 2537.0050000000006], [2537.0050000000006, 2548.7550000000006], [2548.7550000000006, 2561.6850000000004], [2561.6850000000004, 2576.0660000000003], [2576.0660000000003, 2594.0750000000003], [2594.0750000000003, 2607.7650000000003], [2607.7650000000003, 2618.9350000000004], [2618.9350000000004, 2629.2150000000006], [2629.2150000000006, 2644.5660000000007], [2644.5660000000007, 2654.8850000000007], [2654.8850000000007, 2665.9650000000006], [2665.9650000000006, 2677.225000000001], [2677.225000000001, 2689.645000000001], [2689.645000000001, 2700.895000000001], [2700.895000000001, 2714.145000000001], [2714.145000000001, 2727.165000000001], [2727.165000000001, 2739.505000000001], [2739.505000000001, 2750.085000000001], [2750.085000000001, 2762.255000000001], [2762.255000000001, 2775.555000000001], [2775.555000000001, 2790.316000000001], [2790.316000000001, 2802.215000000001], [2802.215000000001, 2813.125000000001], [2813.125000000001, 2825.675000000001], [2825.675000000001, 2836.875000000001], [2836.875000000001, 2850.455000000001], [2850.455000000001, 2862.8050000000007], [2862.8050000000007, 2873.8160000000007], [2873.8160000000007, 2887.515000000001], [2887.515000000001, 2900.1060000000007], [2900.1060000000007, 2910.3850000000007], [2910.3850000000007, 2921.7550000000006], [2921.7550000000006, 2937.4150000000004], [2937.4150000000004, 2949.2950000000005], [2949.2950000000005, 2960.4850000000006], [2960.4850000000006, 2975.3350000000005], [2975.3350000000005, 2987.1000000000004], [2987.1000000000004, 2997.84], [2997.84, 3012.1200000000003], [3012.1200000000003, 3024.4400000000005], [3024.4400000000005, 3036.0700000000006], [3036.0700000000006, 3048.0500000000006], [3048.0500000000006, 3060.2900000000004], [3060.2900000000004, 3072.9500000000003], [3072.9500000000003, 3083.3300000000004], [3083.3300000000004, 3095.2400000000002], [3095.2400000000002, 3105.3390000000004], [3105.3390000000004, 3117.9700000000003], [3117.9700000000003, 3129.8900000000003], [3129.8900000000003, 3140.2700000000004], [3140.2700000000004, 3151.6500000000005], [3151.6500000000005, 3163.1100000000006], [3163.1100000000006, 3174.0200000000004], [3174.0200000000004, 3190.1400000000003], [3190.1400000000003, 3201.32], [3201.32, 3212.9410000000003], [3212.9410000000003, 3227.51], [3227.51, 3242.981], [3242.981, 3254.86], [3254.86, 3265.79], [3265.79, 3277.04], [3277.04, 3287.38], [3287.38, 3300.9], [3300.9, 3317.57], [3317.57, 3330.09], [3330.09, 3340.2000000000003], [3340.2000000000003, 3354.0400000000004], [3354.0400000000004, 3364.7700000000004], [3364.7700000000004, 3375.3100000000004], [3375.3100000000004, 3389.1800000000003], [3389.1800000000003, 3401.34], [3401.34, 3415.13], [3415.13, 3426.9100000000003], [3426.9100000000003, 3441.3100000000004], [3441.3100000000004, 3452.3900000000003], [3452.3900000000003, 3464.9300000000003], [3464.9300000000003, 3476.2400000000002], [3476.2400000000002, 3489.3300000000004], [3489.3300000000004, 3502.0400000000004], [3502.0400000000004, 3512.6800000000003], [3512.6800000000003, 3523.7100000000005], [3523.7100000000005, 3534.9710000000005], [3534.9710000000005, 3545.1910000000003], [3545.1910000000003, 3558.0820000000003], [3558.0820000000003, 3569.7810000000004], [3569.7810000000004, 3583.1620000000003], [3583.1620000000003, 3594.4210000000003], [3594.4210000000003, 3605.4210000000003], [3605.4210000000003, 3618.0820000000003], [3618.0820000000003, 3629.251], [3629.251, 3643.1020000000003], [3643.1020000000003, 3656.6420000000003], [3656.6420000000003, 3668.831], [3668.831, 3682.2670000000003], [3682.2670000000003, 3692.4210000000003], [3692.4210000000003, 3702.8410000000003], [3702.8410000000003, 3714.1420000000003], [3714.1420000000003, 3727.501], [3727.501, 3739.251], [3739.251, 3751.291], [3751.291, 3762.3010000000004], [3762.3010000000004, 3772.541], [3772.541, 3784.251], [3784.251, 3796.1820000000002], [3796.1820000000002, 3807.481], [3807.481, 3817.6910000000003], [3817.6910000000003, 3832.1620000000003], [3832.1620000000003, 3843.9910000000004], [3843.9910000000004, 3854.4610000000002], [3854.4610000000002, 3865.0310000000004], [3865.0310000000004, 3877.8920000000003], [3877.8920000000003, 3888.1110000000003], [3888.1110000000003, 3891.0200000000004]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [102, 518, 791, 1107, 1321, 1923, 2259, 2465, 2977, 3532, 3892]}
{"example_id": "mit153@@MITRES6_012S18_L09_300k", "text": [" In this lecture, we continue our discussion of continuous  random variables.  We will start by bringing conditioning into the picture  and discussing how the PDF of a continuous random variable ", "changes when we are told that a certain event has occurred.  We will take the occasion to develop counterparts of some  of the tools that we developed in the discrete case such as ", "the total probability and total expectation theorems.  In fact, we will push the analogy even further.  In the discrete case, we looked at the geometric PMF in ", "some detail and recognized an important memorylessness  property that it possesses.  In the continuous case, there is an entirely analogous story ", "that we will follow, this time involving the exponential  distribution which has a similar  memorylessness property.  We will then move to a second theme which is how to describe ", "the joint distribution of multiple random variables.  We did this in the discrete case by  introducing joint PMFs.  In the continuous case, we can do the same using ", "appropriately defined joint PDFs and by  replacing sums by integrals.  As usual, we will illustrate the various concepts through ", "some simple examples and also take the opportunity to  introduce some additional concepts such as mixed random  variables and the joint cumulative  distribution function. ", "  In this segment, we pursue two themes.  Every concept has a conditional counterpart.  We know about PDFs, but if we live in a conditional ", "universe, then we deal with conditional probabilities.  And we need to use conditional PDFs.  The second theme is that discrete formulas have  continuous counterparts in which summations get replaced ", "by integrals, and PMFs by PDFs.  So let us recall the definition of a conditional  PMF, which is just the same as an ordinary PMF but applied to ", "a conditional universe.  In the same spirit, we can start with a PDF, which we can  interpret, for example, in terms of probabilities of  small intervals. ", "If we move to a conditional model in which event A is  known to have occurred, probabilities of small  intervals will then be determined by a conditional  PDF, which we denote in this manner. ", "Of course, we need to assume throughout that the  probability of the conditioning event is positive  so that conditional probabilities are  well-defined. ", "Let us now push the analogy further.  We can use a PMF to calculate probabilities.  The probability that X takes [a] value in a certain set is  the sum of the probabilities of all the possible ", "values in that set.  And a similar formula is true if we're dealing with a  conditional model.  Now, in the continuous case, we use a PDF to calculate the ", "probability that X takes values in a certain set.  And by analogy, we use a conditional PDF to calculate ", "conditional probabilities.  We can take this relation here to be the definition of a  conditional PDF.  So a conditional PDF is a function that allows us to ", "calculate probabilities by integrating this function over  the event or set of interest.  Of course, probabilities need to sum to 1. ", "This is true in the discrete setting.  And by analogy, it should also be true in  the continuous setting.  This is just an ordinary PDF, except that it applies to a ", "model in which event A is known to have occurred.  But it still is a legitimate PDF.  It has to be non-negative, of course. ", "But also, it needs to integrate to 1.   When we condition on an event and without any further  assumption, there's not much we can say about the form of ", "the conditional PDF.  However, if we condition on an event of a special kind, that  X takes values in a certain set, then we can actually ", "write down a formula.  So let us start with a random variable X that has a given  PDF, as in this diagram.  ", "And suppose that A is a subset of the real line, for example,  this subset here.  ", "What is the form of the conditional PDF?  We start with the interpretation of PDFs and  conditional PDFs in terms of  probabilities of small intervals.  The probability that X lies in a small interval is equal to ", "the value of the PDF somewhere in that interval times the  length of the interval.  And if we're dealing with conditional probabilities,  then we use the corresponding conditional PDF. ", "To find the form of the conditional PDF, we will work  in terms of the left-hand side in this equation and try to  rewrite it. ", "Let us distinguish two cases.  Suppose that little X lies somewhere out here, and we  want to evaluate the conditional PDF at that point. ", "So trying to evaluate this expression, we consider a  small interval from little x to little x plus delta. ", " And now, let us write the definition of a conditional  probability.  A conditional probability, by definition, is equal to the ", "probability that both events occur divided by the  probability of the conditioning event.  ", "Now, because the set A and this little interval are  disjoint, these two events cannot occur simultaneously.  So the numerator here is going to be 0. ", "And this will imply that the conditional PDF is  also going to be 0.  This, of course, makes sense.  Conditioned on the event that X took values in this set, ", "values of X out here cannot occur.  And therefore, the conditional density out here  should also be 0.  So the conditional PDF is 0 outside the set A. And this ", "takes care of one case.  Now, the second case to consider is when little x lies  somewhere inside here inside the set A. And in that case, ", "our little interval from little x to little x plus  delta might have this form.  In this case, the intersection of these two events, that X ", "lies in the big set and X lies in the small set, the  intersection of these two events is the event that X  lies in the small set.  So the numerator simplifies just to the probability that ", "the random variable X takes values in the interval from  little x to little x plus delta.  And then we rewrite the denominator. ", "Now, the numerator is just an ordinary probability that the  random variable takes values inside a small interval.  And by our interpretation of PDFs, this is approximately ", "equal to the PDF evaluated somewhere in that small  interval times delta.  At this point, we notice that we have deltas on both sides ", "of this equation.  By cancelling this delta with that delta, we finally end up  with a relation that the conditional PDF should be  equal to this expression that we have here. ", "So to summarize, we have shown a formula for  the conditional PDF.  The conditional PDF is 0 for those values of X that cannot ", "occur given the information that we are given, namely that  X takes values at that interval.  But inside this interval, the conditional PDF has a form ", "which is proportional to the unconditional PDF.  But it is scaled by a certain constant.  So in terms of a picture, we might have ", "something like this.  And so this green diagram is the form of  the conditional PDF.  ", "The particular factor that we have here in the denominator  is exactly that factor that is required, the scaling factor  that is required so that the total area under the green ", "curve, under the conditional PDF is equal to 1.  So we see once more the familiar theme, that  conditional probabilities maintain the same relative  sizes as the unconditional probabilities. ", "And the same is true for conditional PMFs or PDFs,  keeping the same shape as the unconditional ones, except  that they are re-scaled so that the total probability ", "under a conditional PDF is equal to 1.  We can now continue the same story and revisit everything  else that we had done for discrete random variables. ", "For example, we have the expectation of a discrete  random variable and the corresponding conditional  expectation, which is just the same kind of object, except  that we now rely on conditional probabilities. ", "Similarly, we can take the definition of the expectation  for the continuous case and define a conditional  expectation in the same manner, except that we now ", "rely on the conditional PDF.  So this formula here is the definition of the conditional  expectation of a continuous random variable given a ", "particular event.  We have a similar situation with the expected value rule,  which we have already seen for discrete random variables in  both of the unconditional and in the conditional setting. ", "We have a similar formula for the continuous case.  And at this point, you can guess the form that the  formula will take in the  continuous conditional setting. ", "This is the expected value rule in the conditional  setting, and it is proved exactly the same way as for  the unconditional continuous setting, except that here in ", "the proof, we need to work with conditional probabilities  and conditional PDFs, instead of the unconditional ones.  So to summarize, there is nothing really different when ", "we condition on an event in the continuous case compared  to the discrete case.  We just replace summations with integrations.  And we replace PMFs by PDFs. ", "  Let us now look at an example.  Consider a piecewise constant PDF of the form  shown in this diagram. ", "Suppose that we condition on the event that x lies between  a plus b over 2, which is here, and b. ", "So we're conditioning on x lying in this  particular red interval.  What is the conditional PDF?  The conditional PDF is going to be 0 outside of the ", "interval on which we are conditioning.  So the conditional PDF is 0 in this range, and also, it is 0  in this range. ", " Within the range of values of x that are allowed given the  conditioning information, the conditional PDF must retain ", "the same shape as the unconditional one.  And the unconditional one is constant in that range.  So the conditional PDF will also be a constant.  ", "Because in this case the length of this interval is  half of the distance between b minus a--  so the length of this interval is b minus a over 2-- ", "in order for the area under this curve to be equal to 1,  it means that the height of this curve has to be equal to  2 over b minus a. ", " The conditional expectation in this example is just the  ordinary expectation but applied to  the conditional model.  Since the conditional PDF is uniform, the conditional ", "expectation will be the midpoint of the range of this  conditional PDF.  And in this case, the midpoint is 1/2 the left end of the ", "interval, which is a plus b over 2 plus 1/2 the right end  point of the interval, which is b.  And so this evaluates to 1/4 times a plus 3/4 times b. ", "We can also calculate the expected value of X squared in  the conditional model using the expected value rule.  According to the expected value rule, it's going to be ", "an integral of the conditional PDF, which is 2 over b minus a  multiplied by x squared. ", "And this integral runs over the range where the  conditional PDF is actually non-zero.  So it's an integral that ranges from a plus b ", "over 2 up to b.  And this an integral which is not too hard to evaluate, and  there's no point in carrying out the evaluation to the end.  ", " We now revisit the exponential random variable that we  introduced earlier and develop some intuition about what it  represents.  We do this by establishing a memorylessness property, ", "similar to the one that we established earlier in the  discrete case for the geometric PMF.  Suppose that it is known that light bulbs have a lifetime  until they burn out, which is an ", "exponential random variable.  You go to a store, and you are given two choices, to buy a  new light bulb, or to buy a used light bulb that has been ", "working for some time and has not yet burned out.  Which one should you take?  We want to approach this question mathematically.  So let us denote by capital T the lifetime of the bulb. ", "So time starts at time 0, and then at some random time that  we denote by capital T, the light bulb will burn out.  And we assume that this random variable is exponential with ", "some given parameter lambda.  In one of our earlier calculations, we have shown  that the probability that capital T is larger than some  value little x falls exponentially ", "with that value x.  We are now told that a certain light bulb has already been  operating for t time units without failing. ", "So we know that the value of the random variable capital T  is larger than little t.  We are interested in how much longer the light bulb will be ", "operating, and so we look at capital X, which is the  remaining lifetime from the current time until the light ", "bulb burns out.  So capital X is this particular random variable  here, and it is equal to capital T minus little t. ", "Let us now calculate the probability that the light  bulb lasts for another little x time units.  That is, that this random variable, capital X, is at ", "least as large as some little x.  That is, that the light bulb remains alive  until time t plus x. ", " We use the definition of conditional probabilities to  write this expression as the probability that capital X is ", "bigger than little x.  On the other hand, capital X is T minus t, so we  write it this way--  T minus t is bigger than little x, and also that T is ", "bigger than little t, divided by the probability of the  conditioning event.  ", "Just write this event in a cleaner form, capital T being  larger than little t plus x and being larger than little ", "t, again divided by the probability of the  conditioning event.   And now notice that capital T will be greater than little t ", "and also greater than little t plus x, that is, capital T is  larger than this number and this number, if and only if it ", "is larger than this second number here.  So in other words, the intersection of these two  events is just this event here, that capital T is larger ", "than little t plus x.  ", "Now, we can use the formula for the probability that  capital T is larger than something.  We apply this formula, except that instead of little x, we ", "have t plus x.  And so here we have e to the minus lambda t plus x divided  by the probability that capital T is bigger than t. ", "So we use this formula, but with little t in the place of  little x, and we obtain e to the minus lambda t.  We have a cancellation, and we're left with e to the minus ", "lambda x, which is a final answer in this calculation.  What do we observe here?  The probability that the used light bulb will live for ", "another x time units is exactly the same as the  corresponding probability that the new light bulb will be ", "alive for another x time units.  So new and used light bulbs are described by the same  probabilities, and they're probabilistically ", "identical, the same.  Differently said, the used light bulb does not remember,  and it is not affected by how long it has been running. ", "And this is the memorylessness property of  exponential random variables.   Let us now build some additional insights on ", "exponential random variables.  We have a formula for the density, the PDF.  And from this, we can calculate the probability that  T lies in a small interval. ", "For example, for a small delta, this probability here  is going to be approximately equal to the density of T  evaluated at 0 times delta, which is lambda times e to the ", "0, which is 1, times delta.  What if we are told that the light bulb has been alive for  t time units? ", "What is the probability that it burns out during the next  delta times units?  Since a used but still alive light bulb is ", "probabilistically identical to a new one, this conditional  probability is the same as this probability here that a ", "new light bulb burns out in the next delta times units.  And so this is also approximately  equal to lambda delta. ", "So we see that independently of how long a light bulb has  been alive, during the next delta time units it will have  a lambda delta probability of failing. ", "One way of thinking about this situation is that the time  interval is split into little intervals of length delta.  ", "And as long as the light bulb is alive, if it is alive at  this point, it will have probability lambda delta of  burning out during the next interval of length delta. ", "This is like flipping a coin.  Once every delta time steps, there is a probability lambda  delta that there is a success in that coin flip, where ", "success corresponds to having the light bulb actually burn  down, and the exponential random variable corresponds to  the total time elapsed until the first success. ", "In this sense, the exponential random variable is a close  analog of the geometric random variable, which was the time  until the first success in a discrete time setting. ", "This analogy turns out to be the foundation behind the  Poisson process that we will be studying  later in this course.    We now continue with the development of continuous ", "analogs of everything we know for the discrete case.  We have already seen a few versions of the total  probability theorem, one version for events and one  version for PMFs. ", "Let us now develop a continuous analog.  Suppose, as always, that we have a partition of the sample  space into a number of disjoint scenarios.  Three scenarios in this picture. ", "More generally, n scenarios in these formulas.  Let X be a continuous random variable and let us take B to  be the event that the random variable takes a value less ", "than or equal to some little x.  By the total probability theorem, this is the  probability of the first scenario times the conditional  probability of this event given that the first scenario ", "has materialized, and then we have similar terms for the  other scenarios.  Let us now turn this equation into CDF notation. ", "The left-hand side is what we have defined as the CDF of the  random variable x.  On the right-hand side, what we have is the probability of ", "the first scenario multiplied, again, by a CDF of the random  variable X. But it is a CDF that applies in a conditional  model where event A1 has occurred. ", "And so we use this notation to denote the conditional CDF,  the CDF that applies to the conditional universe.  And then we have similar terms for the other scenarios. ", "Now, we know that the derivative of a CDF is a PDF.  We also know that any general fact, such as this one that  applies to unconditional models will also apply without ", "change to a conditional model, because a conditional model is  just like any other ordinary probability model.  So let us now take derivatives of both  sides of this equation. ", "On the left-hand side, we have the derivative of a  CDF, which is a PDF.  And on the right-hand side, we have the probability of the  first scenario, and then the derivative of the conditional ", "CDF, which has to be the same as the conditional PDF.  So we use here the fact that derivatives of CDFs are PDFs,  and then we have similar terms under the different scenarios. ", "So we now have a relation between densities.  To interpret this relation, we think as follows.  The probability of falling inside the little interval  around x is determined by the probability of falling inside ", "that little interval under each one of the different  scenarios and where each scenario is weighted by the  corresponding probability. ", "Now, we multiply both sides of this equation by x, and then  integrate over all x's.  ", "We do this on the left-hand side.  And similarly, on the right-hand side to obtain a  term of this form.  ", "And we have similar terms corresponding  to the other scenarios.  What do we have here?  On the left-hand side, we have the expected value of x. ", "On the right-hand side, we have this probability  multiplied by the conditional expectation of X given that  scenario A1 has occurred. ", "And so we obtain a version of the total expectation theorem.  It's exactly the same formula as we had in the discrete  case, except that now X is a continuous random variable. ", "Let us now look at a simple example that involves a model  with different scenarios.  Bill wakes up in the morning and wants to go to the  supermarket.  There are two scenarios. ", "With probability one third, a first scenario occurs.  And under that scenario, Bill will go at a time that's  uniformly distributed between 0 and 2 hours from now. ", "So the conditional PDF of X, in this case, is uniform on  the interval from 0 to 2.  There's a second scenario that Bill will take long nap and ", "will go later in the day.  That scenario has a probability of 2/3.  And under that case, the conditional PDF of X is going ", "to be uniform on the range between 6 and 8.  By the total probability theorem for densities, the ", "density of X, of the random variable--  the time at which he goes to the supermarket--  consists of two pieces.  One piece is a uniform between 0 and 2. ", "This uniform ordinarily would have a height or 1/2.  On the other hand, it gets weighted by the corresponding  probability, which is 1/3. ", "So we obtain a piece here that has a height of 1/6.  Under the alternative scenario, the conditional  density is a uniform on the interval between 6 and 8. ", "This uniform has a height of 1/2 again, but it gets  multiplied by a factor of 2/3.  And this results in a height for this term that we have ", "here, which is 1/3.  And this is the form of the PDF of the time at which Bill  will go to the supermarket.  ", "We can now finally use the total expectation theorem.  The conditional expectation under the two scenarios can be  found as follows.  Under one scenario, we have a uniform between 0 and 2. ", "And so the conditional expectation is 1, and it gets  weighted by the corresponding probability, which is 1/3.  Under the second scenario, which has probability 2/3, the ", "conditional expectation is the midpoint of this uniform,  which is 7.  And this gives us the expected value of the  time at which he goes. ", "So this is a simple example, but it illustrates nicely how  we can construct a model that involves a number  of different scenarios.  And by knowing the probability distribution under each one of ", "the scenarios, we can find the probability  distribution overall.  And we can also find the expected value for the overall  experiment. ", "  We now look at an example similar to the previous one,  in which we have again two scenarios, but in which we  have both discrete and continuous ", "random variables involved.  You have $1 and the opportunity  to play in the lottery.  With probability 1/2, you do nothing and you're left with ", "the dollar that you started with.  With probability 1/2, you decide to play the lottery.  And in that case, you get back an amount of money which is ", "random and uniformly distributed  between zero and two.  Is the random variable, X, discrete?  The answer is no, because it takes values on ", "a continuous range.  Is the random variable, X, continuous?  The answer is no, because the probability that X takes the ", "value of exactly one is equal to 1/2.   Even though X takes values in a continuous range, this is ", "not enough to make it a continuous random variable.  We defined continuous random variables to be those that can  be described by a PDF.  And you have seen it in such a case, any individual point ", "should have zero probability.  But this is not the case here, and so X is not continuous.  We call X a mixed random variable.  More generally, we can have a situation where the random ", "variable X with some probability is the same as a  particular discrete random variable, and with some other  probability it is equal to some other ", "continuous random variable.  Such a random variable, X, does not have a PMF because it  is not discrete.  Also, it does not have a PDF because it is not continuous. ", "How do we describe such a random variable?  Well, we can describe it in terms of a cumulative  distribution function.  CDFs are always well defined for all ", "kinds of random variables.  We have two scenarios, and so we can use the Total  Probability Theorem and write that the CDF is equal to the ", "probability of the first scenario, which is p, times  the probability that the random variable Y is less than  or equal to x.  This is a conditional model under the first scenario. ", "And with some probability, we have the second scenario.  And under that scenario, X will take a value less than  little x, if and only if our random variable Z will take a ", "value less than little x.  Or in CDF notation, this is p times the CDF of the random  variable Y evaluated at this particular x plus another ", "weighted term involving the CDF of the random variable Z.  We can also define the expected value of X in a way ", "that is consistent with the Total Expectation Theorem,  namely define the expected value of X to be the  probability of the first scenario, in which case X is ", "discrete times the expected value of the associated  discrete random variable, plus the probability of the second  scenario, under which X is continuous, times the expected ", "value of the associated continuous random variable.  Going back to our original example, we have two  scenarios, the scenarios that we can call A1 and A2. ", "Under the first scenario, we have a uniform PDF, and the  corresponding CDF is as follows.  It's flat until zero, then it rises linearly. ", "And then it stays flat, and the value  here is equal to one.  So the slope here is 1/2.  So the slope is equal to the corresponding PDF. ", "Under the second scenario, we have a discrete, actually a  constant random variable.  And so the CDF is flat at zero until this value, and at that  value we have a jump equal to one. ", "We then use the Total Probability Theorem, which  tells us that the CDF of the mixed random variable will be  1/2 times the CDF under the first scenario plus 1/2 times ", "the CDF under the second scenario.  So we take 1/2 of this plot and 1/2 of that plot  and add them up.  What we get is a function that rises now at the slope of 1/4. ", " Then we have a jump, and the size of that to jump is going  to be equal to 1/2. ", "And then it continues at a slope of 1/4 until it reaches  this value.  And after that time, it remains flat.  ", "So this is a simple illustration that for mixed  random variables it's not too hard to obtain the  corresponding CDF even though this random variable does not  have a PDF or a PMF of its own. ", "  In this segment, we start a discussion of multiple  continuous random variables.  Here are some objects that we're already familiar with.  But exactly as in the discrete case, if we are dealing with ", "two random variables, it is not enough to know their  individual PDFs.  We also need to model the relation between the two  random variables, and this is done through a joint PDF, ", "which is the continuous analog of the joint PMF.  We will use this notation to indicate joint PDFs where we  use f to indicate that we're dealing with a density. ", "So what remains to be done is to actually define this object  and see how we use it.  Let us start by recalling that joint PMFs were defined in ", "terms of the probability that the pair of random variables X  and Y take certain specific values little x and little y.  Regarding joint PDFs, we start by saying that it has to be ", "non-negative.  However, a more precise interpretation in terms of  probabilities has to wait a little bit.  Joint PDFs will be used to calculate probabilities. ", "And this will be done in analogy with  the discrete setting.  In the discrete setting, the probability that the pair of  random variables falls inside a certain set is just the sum ", "of the probabilities of all of the possible pairs inside that  particular set.  For the continuous case, we introduce  an analogous formula. ", "We use the joint density instead of the joint PMF.  And instead of having a summation, we now integrate.  As in the discrete setting, we have one total unit of ", "probability.   The joint PDF tells us how this unit of probability is  spread over the entire continuous ", "two-dimensional plane.  And we use it, we use the joint PDF, to calculate the  probability of a certain set by finding the volume under ", "the joint PDF that lies on top of that set.  This is what this integral really represents.  We integrate over a particular two-dimensional set, and we ", "take this value that we integrate.  And we can think of this as the height of an object that's  sitting on top of that set. ", "Now, this relation here, this calculation of probabilities,  is not something that we are supposed to prove.  This is, rather, the definition of ", "what a joint PDF does.  A legitimate joint PDF is any function of two variables,  which is non-negative and which integrates to 1. ", "And we will say that two random variables are jointly  continuous if there is a legitimate joint PDF that can ", "be used to calculate the associated probabilities  through this particular formula.  So we have really an indirect definition.  Instead of defining the joint PDF as a probability, we ", "actually define it indirectly by saying what it does, how it  will be used to calculate probabilities.  A picture will be helpful here. ", "Here's a plot of a possible joint PDF.  These are the x and y-axes.  And the function being plotted is the joint PDF of these two ", "random variables.  This joint PDF is higher at some places and lower at  others, indicating that certain regions of the x,y  plane are more likely than others. ", "The joint PDF determines the probability of a set B by  integrating over that set B. Let's say it's this set.  Integrating the PDF over that set. ", "Pictorially, what this means is that we look at the volume  that sits on top of that set, but below the PDF, below the ", "joint PDF, and so we obtain some three-dimensional object  of this kind.  And this integral corresponds to actually finding this ", "volume here, the volume that sits on top of the set B but  which is below the joint PDF.  ", "Let us now develop some additional understanding of  joint PDFs.  As we just discussed, for any given set B, we can integrate ", "the joint PDF over that set.  And this will give us the probability of  that particular set.  Of particular interest is the case where we're dealing with ", "a set which is a rectangle, in which case the situation is a  little simpler.  So suppose that we have a rectangle where the  x-coordinate ranges from A to B and the y-coordinate ranges ", "from some C to some D. Then, the double integral over this  particular rectangle can be written in a form where we ", "first integrate with respect to one of the variables that  ranges from A to B. And then, we integrate over all possible  values of y as they range from C to D. ", "Of particular interest is the special case where we're  dealing with a small rectangle such as this one.  A rectangle with sizes equal to some delta where delta is a ", "small number.  In that case, the double integral, which is the volume  on top of that rectangle, is simpler to evaluate. ", "It is equal to the value of the function that we're  integrating at some point in the rectangle --- let's take  that corner ---  times the area of that little rectangle, which is equal to ", "delta square.  So we have an interpretation of the joint PDF in terms of  probabilities of small rectangles.  Joint PDFs are not probabilities. ", "But rather, they are probability densities.  They tell us the probability per unit area.  And one more important comment. ", "For the case of a single continuous random variable, we  know that any single point has 0 probability.  This is again, true for the case of two jointly continuous ", "random variables.  But more is true.  If you take a set B that has 0 area.  For example, a certain curve. ", "Suppose that this curve is the entire set B. Then, the volume  under the joint PDF that's sitting on top of that curve ", "is going to be equal to 0.  So 0 area sets have 0 probability.  And this is one of the characteristic features of ", "jointly continuous random variables.  Now, let's think of a particular situation.  Suppose that X is a continuous random variable, and let Y be ", "another random variable, which is identically equal to X.  Since X is a continuous random variable, Y is also a  continuous random variable.  However, in this situation, we are certain that the outcome ", "of the experiment is going to fall on the line  where x equals y.  All the probability lies on top of a line, and  a line has 0 area. ", "So we have positive probability on the set of 0  area, which contradicts what we discussed before.  Well, this simply means that X and Y are not jointly ", "continuous.  Each one of them is continuous, but together  they're not jointly continuous.  Essentially, joint continuity is something more than ", "requiring each random variable to be continuous by itself.  For joint continuity, we want the probability to be really  spread over two dimensions. ", "Probability is not allowed to be concentrated on a  one-dimensional set.  On the other hand, in this example, the probability is  concentrated on a one-dimensional set. ", "And we do not have joint continuity.    In the discrete case, we saw that we could recover the PMF ", "of X and the PMF of Y from the joint PMF.  Indeed, the joint PMF is supposed to contain a complete  probabilistic description of the two random variables. ", "It is their probability law, and any quantity of interest  can be computed if we know the joint.  Things are similar in the continuous setting.  You can easily guess the formula through ", "the standard recipe.  Replace sums by integrals, and replace PMFs by PDFs. ", "But a proof of this formula is actually instructive.  So let us start by first finding the CDF of X. ", "The CDF of X is, by definition, the probability  that the random variable X takes a value less than or  equal to a certain number little x. ", "And this is the probability of a particular set that we can  visualize on the two dimensional plane.  If here is the value of little x, then we're talking about ", "the set of all pairs x, y, for which the x component is less  than or equal to a certain number.  So we need to integrate over this two-dimensional set the ", "joint density.  So it will be a double integral of the joint density  over this particular two-dimensional set. ", "Now, since we've used the symbol x here to mean  something specific, let us use different symbols for the  dummy variables that we will use in the integration. ", "And we need to integrate with respect to the two variables,  let's say with respect to t and with respect to s.  The variable t can be anything. ", "So it ranges from minus infinity to infinity.  But the variable s, the first argument, ranges from minus  infinity up to this point, which is x. ", " Think of this double integral as an integral with respect to  the variable s of this complicated function inside ", "the brackets.  Now, to find the density of X, all we need to do is to  differentiate the CDF of X. And when we have an integral ", "of this kind and we differentiate with respect to  the upper limit of the integration, what we are left  with is the integrand.  That is this expression here. ", "It is an integral with respect to the second variable.  And it's an integral over the entire space, from minus  infinity to plus infinity. ", " Here is an example.  The simplest kind of a joint PDF is a PDF of that is  constant on a certain set, S, and is 0 outside that set. ", "So the overall probability, one unit of probability, is  spread uniformly over that set.  Because the total volume under the joint PDF must be equal to ", "1, the height of the PDF must be equal to 1 over the area.  To calculate the probability of a certain set A, we want to ", "ask how much volume is sitting on top of that set.  And because in this case, the PDF is constant, we need to  take the height of the PDF times the relevant area. ", "What is the relevant area?  Well, actually, the PDF is 0 outside the set S. So the  relevant area is only this part here, which is the ", "intersection of the two sets, S and A.  So the total volume sitting on top of this little set is ", "going to be the base, the area of the base, which is the area  of A intersection S times the height of the ", "PDF at those places.  Now, the height of the PDF is 1 over the area of S. So this  is the formula for calculating the probability of a certain ", "set, A.  Let's now look at a specific example. ", "Suppose that we have a uniform PDF over this particular set,  S. This set has an area that is equal to 4. ", "It consists of four units rectangles arranged next to  each other.  So the height of the joint PDF in this example  is going to be 1/4. ", " It is one 1/4 on that set, but of course, it's going to be 0  outside that set.  We can now find the marginal PDF at some particular x. ", "So we can fix a particular value of x,  let's say this one.  To find the value of the marginal PDF, we need to  integrate over y along that particular line. ", "And the integral is going to have a contribution only on  that segment.  On that segment, the value of the joint PDF is 1/4.  And we're integrating over an interval that ", "has a length of one.  So the integral is going to be equal to 1/4.  But if x is somewhere around here, as we integrate over ", "that line, we integrate the value of 1/4, the value of the  PDF, over an interval that has a length equal to 3. ", "And so the result turns out to be 3/4.  There's a similar calculation for the marginal PDF of y.  For any particular value of little y, to find the marginal ", "PDF, we integrate along this line the joint PDF.  The joint PDF is 0 out here.  It's nonzero only on that interval. ", "And on that interval, it has a value of 1/4.  And the interval has a length of 1, so the integral is going  to end up equal to 1/4. ", "But if we were to take a line somewhere here, we integrate  the value of 1/4 over an interval of length 2.  And so the result would be 1/2. ", "So we have recovered from the joint PDF the marginal PDF of  X and also the marginal PDF of Y.   ", "In this segment we will go very fast through a few  definitions and facts that remain true in  the continuous case.  Everything is completely analogous to  the discrete case. ", "And there are absolutely no surprises here.  So, for example, we have defined joint PMFs for the  case of more than two discrete random variables.  And we have a bunch of facts about them. ", "In a similar manor, we can define joint PDFs for more  than two random variables.  And if you have understood the material so far, you can guess  how such a joint PDF will be used. ", "For example, you can calculate the probability of a three  dimensional set by integrating the joint PDF over that three  dimensional set. ", "And there are analogs off all of the other formulas that we  have here where we follow the usual recipe.  Sums become integrals, and PMFs are replaced by PDFs. ", "Finally, when you deal with a random variable, which is  defined as a function of jointly continuous random  variables, we can use an expected value rule that takes ", "the same form as in the discrete case.  And using the expected value rule, we can establish, once  more, the usual linearity properties of expectations. ", "So absolutely no surprises here.  The derivations are either completely straightforward.  Or they follow exactly the same line of argument as in  the discrete case, with just minor changes in notation. ", "  Besides PMFs and PDFs, we can also describe the distribution  of a random variable, as we know, using a CDF. ", "A CDF is always well-defined.  And for the case of a continuous random variable,  the CDF can be found by integrating the PDF.  And conversely, we can recover the PDF from the CDF by ", "differentiating.  There is something similar that happens for the case of  multiple random variables, as well.  We can define the joint CDF as the probability that X and Y, ", "the pair X-Y, takes values that are below certain  numbers, little x and little y.  So we are talking about the probability of the blue set in ", "this diagram.   This probability can be found by integrating the joint PDF ", "over the blue set.  And, since we're using x and y to be some specific numbers,  let us use some different dummy variables to carry out ", "the integration.   What is the range of the integration?  The first variable, which is s in this integral, ranges from ", "minus infinity up to x.   And the other variable, which is the one that we're  integrating with respect to, in the outer integral-- ", "the t variable--  ranges from minus infinity to y.   Now, let us see what happens if we start taking derivatives ", "of this expression.  If we take the derivative of this expression with respect  to y, what is left is the inner integral. ", " And if we take, now, a derivative with respect to x  of this inner integral, we will be left with ", "just the joint PDF.  And it will be the joint PDF evaluated at the particular  limits of the integration. ", "So, it's going to be f sub xy at little x, little y.  So, we have this particular formula.  By taking derivative with respect to x, and then with ", "respect to y, or maybe in the opposite order.  It doesn't matter.  This particular derivative gives us back the PDF.  Let us look at an example. ", "Suppose that we have a uniform  distribution on the unit square.  So the PDF is equal to 1 on this green square. ", "And is equal to 0 otherwise.  So, in this example, if we take some x and y, so that the  xy pair falls inside the rectangle, the probability of ", "the blue set is going to be just the probability of that  little rectangle here.  Because everything outside has zero probability.  With a uniform joint PDF, which is equal to 1, the ", "probability is just the area of the set that we are  considering.  And since this set that we are considering is a rectangle  with [sides]  x and y, the joint CDF is equal to x times y. ", "Now, if we take the derivative of this expression with  respect to x, and then with respect to y, then we're left  just with a constant equal to 1-- ", " which is as it should be, so that it integrates to one.  So, we have seen that CDFs also apply to the case of ", "multiple random variables, and that we can recover the joint  PDF from the joint CDF.  "], "vid_duration": [12.19, 11.94, 10.8, 10.2, 13.08, 12.41, 10.81, 10.86, 10.368, 12.901, 14.009, 10.961, 13.63, 10.8, 13.62, 12.1, 10.179, 13.5, 10.641, 10.94, 10.34, 12.18, 10.2, 15.1, 10.66, 12.79, 10.67, 10.13, 11.71, 10.079, 12.921, 10.88, 11.5, 13.589, 15.851, 14.269, 12.211, 13.069, 10.951, 12.35, 10.74, 12.679, 10.431, 11.199, 10.381, 12.29, 11.89, 12.18, 11.04, 11.7, 12.77, 10.01, 10.1, 13.689, 11.411, 10.92, 13.11, 11.559, 10.132, 15.13, 14.92, 11.21, 14.01, 12.56, 12.68, 10.24, 13.11, 11.95, 20.58, 10.01, 10.25, 11.23, 11.23, 13.44, 10.38, 10.19, 14.49, 12.48, 11.81, 14.26, 11.67, 10.49, 12.65, 14.02, 10.39, 12.43, 11.43, 11.46, 11.6, 13.32, 10.3, 11.66, 14.78, 11.56, 12.91, 11.615, 12.465, 10.49, 12.17, 11.61, 10.66, 13.87, 18.53, 11.59, 11.7, 14.16, 10.72, 11.506, 13.664, 13.03, 10.76, 10.21, 12.52, 11.81, 11.09, 10.42, 14.47, 13.82, 11.0, 11.61, 13.42, 10.86, 11.12, 11.01, 10.86, 14.27, 13.96, 10.95, 11.9, 12.49, 10.88, 10.05, 13.3, 11.35, 14.67, 14.22, 12.45, 10.42, 11.73, 11.18, 12.1, 11.42, 13.62, 11.72, 11.16, 11.66, 11.83, 10.21, 10.946, 10.57, 10.05, 12.34, 12.67, 11.11, 11.03, 13.84, 11.37, 12.74, 10.88, 11.13, 13.01, 10.9, 14.82, 14.2, 12.03, 10.89, 14.502, 12.638, 13.17, 14.75, 11.649, 15.455, 13.066, 12.57, 11.83, 14.221, 13.69, 13.87, 10.79, 13.53, 13.3, 11.39, 11.33, 13.46, 11.01, 12.72, 12.99, 11.23, 10.76, 12.66, 11.6, 13.87, 12.49, 14.21, 12.49, 13.46, 11.85, 11.15, 10.14, 14.35, 12.03, 14.0, 10.06, 12.96, 14.51, 12.82, 13.83, 11.5, 11.05, 11.43, 10.27, 13.43, 10.61, 13.23, 13.32, 12.66, 10.96, 11.13, 11.59, 10.63, 10.297, 11.15, 11.99, 10.82, 10.0, 11.57, 12.39, 13.71, 11.72, 10.34, 12.04, 11.35, 12.71, 18.07, 13.57, 10.745, 16.905, 10.01, 14.01, 13.37, 10.45, 10.3, 10.35, 14.35, 11.02, 10.97, 10.64, 14.32, 13.09, 13.05, 10.16, 10.43, 14.82, 14.02, 10.16, 10.87, 11.169, 10.27, 12.94, 11.86, 11.46, 14.21, 11.32, 11.34, 12.77, 11.606, 13.9, 14.16, 14.54, 13.21, 10.93, 13.09, 12.99, 11.72, 10.605, 11.075, 10.78, 11.99, 11.87, 11.35, 14.52, 14.18, 14.04, 11.815, 12.775, 7.131], "stet": [[0, 12.19], [12.19, 24.13], [24.13, 34.93], [34.93, 45.129999999999995], [45.129999999999995, 58.209999999999994], [58.209999999999994, 70.61999999999999], [70.61999999999999, 81.42999999999999], [81.42999999999999, 92.28999999999999], [92.28999999999999, 102.65799999999999], [102.65799999999999, 115.55899999999998], [115.55899999999998, 129.56799999999998], [129.56799999999998, 140.529], [140.529, 154.159], [154.159, 164.959], [164.959, 178.579], [178.579, 190.679], [190.679, 200.858], [200.858, 214.358], [214.358, 224.999], [224.999, 235.939], [235.939, 246.279], [246.279, 258.459], [258.459, 268.659], [268.659, 283.759], [283.759, 294.41900000000004], [294.41900000000004, 307.20900000000006], [307.20900000000006, 317.8790000000001], [317.8790000000001, 328.00900000000007], [328.00900000000007, 339.71900000000005], [339.71900000000005, 349.79800000000006], [349.79800000000006, 362.71900000000005], [362.71900000000005, 373.59900000000005], [373.59900000000005, 385.09900000000005], [385.09900000000005, 398.68800000000005], [398.68800000000005, 414.53900000000004], [414.53900000000004, 428.80800000000005], [428.80800000000005, 441.01900000000006], [441.01900000000006, 454.0880000000001], [454.0880000000001, 465.0390000000001], [465.0390000000001, 477.3890000000001], [477.3890000000001, 488.12900000000013], [488.12900000000013, 500.8080000000001], [500.8080000000001, 511.2390000000001], [511.2390000000001, 522.4380000000001], [522.4380000000001, 532.8190000000001], [532.8190000000001, 545.109], [545.109, 556.999], [556.999, 569.179], [569.179, 580.2189999999999], [580.2189999999999, 591.919], [591.919, 604.689], [604.689, 614.699], [614.699, 624.799], [624.799, 638.4879999999999], [638.4879999999999, 649.8989999999999], [649.8989999999999, 660.8189999999998], [660.8189999999998, 673.9289999999999], [673.9289999999999, 685.4879999999998], [685.4879999999998, 695.6199999999998], [695.6199999999998, 710.7499999999998], [710.7499999999998, 725.6699999999997], [725.6699999999997, 736.8799999999998], [736.8799999999998, 750.8899999999998], [750.8899999999998, 763.4499999999997], [763.4499999999997, 776.1299999999997], [776.1299999999997, 786.3699999999997], [786.3699999999997, 799.4799999999997], [799.4799999999997, 811.4299999999997], [811.4299999999997, 832.0099999999998], [832.0099999999998, 842.0199999999998], [842.0199999999998, 852.2699999999998], [852.2699999999998, 863.4999999999998], [863.4999999999998, 874.7299999999998], [874.7299999999998, 888.1699999999998], [888.1699999999998, 898.5499999999998], [898.5499999999998, 908.7399999999999], [908.7399999999999, 923.2299999999999], [923.2299999999999, 935.7099999999999], [935.7099999999999, 947.5199999999999], [947.5199999999999, 961.7799999999999], [961.7799999999999, 973.4499999999998], [973.4499999999998, 983.9399999999998], [983.9399999999998, 996.5899999999998], [996.5899999999998, 1010.6099999999998], [1010.6099999999998, 1020.9999999999998], [1020.9999999999998, 1033.4299999999998], [1033.4299999999998, 1044.86], [1044.86, 1056.32], [1056.32, 1067.9199999999998], [1067.9199999999998, 1081.2399999999998], [1081.2399999999998, 1091.5399999999997], [1091.5399999999997, 1103.1999999999998], [1103.1999999999998, 1117.9799999999998], [1117.9799999999998, 1129.5399999999997], [1129.5399999999997, 1142.4499999999998], [1142.4499999999998, 1154.0649999999998], [1154.0649999999998, 1166.5299999999997], [1166.5299999999997, 1177.0199999999998], [1177.0199999999998, 1189.1899999999998], [1189.1899999999998, 1200.7999999999997], [1200.7999999999997, 1211.4599999999998], [1211.4599999999998, 1225.3299999999997], [1225.3299999999997, 1243.8599999999997], [1243.8599999999997, 1255.4499999999996], [1255.4499999999996, 1267.1499999999996], [1267.1499999999996, 1281.3099999999997], [1281.3099999999997, 1292.0299999999997], [1292.0299999999997, 1303.5359999999998], [1303.5359999999998, 1317.1999999999998], [1317.1999999999998, 1330.2299999999998], [1330.2299999999998, 1340.9899999999998], [1340.9899999999998, 1351.1999999999998], [1351.1999999999998, 1363.7199999999998], [1363.7199999999998, 1375.5299999999997], [1375.5299999999997, 1386.6199999999997], [1386.6199999999997, 1397.0399999999997], [1397.0399999999997, 1411.5099999999998], [1411.5099999999998, 1425.3299999999997], [1425.3299999999997, 1436.3299999999997], [1436.3299999999997, 1447.9399999999996], [1447.9399999999996, 1461.3599999999997], [1461.3599999999997, 1472.2199999999996], [1472.2199999999996, 1483.3399999999995], [1483.3399999999995, 1494.3499999999995], [1494.3499999999995, 1505.2099999999994], [1505.2099999999994, 1519.4799999999993], [1519.4799999999993, 1533.4399999999994], [1533.4399999999994, 1544.3899999999994], [1544.3899999999994, 1556.2899999999995], [1556.2899999999995, 1568.7799999999995], [1568.7799999999995, 1579.6599999999996], [1579.6599999999996, 1589.7099999999996], [1589.7099999999996, 1603.0099999999995], [1603.0099999999995, 1614.3599999999994], [1614.3599999999994, 1629.0299999999995], [1629.0299999999995, 1643.2499999999995], [1643.2499999999995, 1655.6999999999996], [1655.6999999999996, 1666.1199999999997], [1666.1199999999997, 1677.8499999999997], [1677.8499999999997, 1689.0299999999997], [1689.0299999999997, 1701.1299999999997], [1701.1299999999997, 1712.5499999999997], [1712.5499999999997, 1726.1699999999996], [1726.1699999999996, 1737.8899999999996], [1737.8899999999996, 1749.0499999999997], [1749.0499999999997, 1760.7099999999998], [1760.7099999999998, 1772.5399999999997], [1772.5399999999997, 1782.7499999999998], [1782.7499999999998, 1793.6959999999997], [1793.6959999999997, 1804.2659999999996], [1804.2659999999996, 1814.3159999999996], [1814.3159999999996, 1826.6559999999995], [1826.6559999999995, 1839.3259999999996], [1839.3259999999996, 1850.4359999999995], [1850.4359999999995, 1861.4659999999994], [1861.4659999999994, 1875.3059999999994], [1875.3059999999994, 1886.6759999999992], [1886.6759999999992, 1899.4159999999993], [1899.4159999999993, 1910.2959999999994], [1910.2959999999994, 1921.4259999999995], [1921.4259999999995, 1934.4359999999995], [1934.4359999999995, 1945.3359999999996], [1945.3359999999996, 1960.1559999999995], [1960.1559999999995, 1974.3559999999995], [1974.3559999999995, 1986.3859999999995], [1986.3859999999995, 1997.2759999999996], [1997.2759999999996, 2011.7779999999996], [2011.7779999999996, 2024.4159999999995], [2024.4159999999995, 2037.5859999999996], [2037.5859999999996, 2052.3359999999993], [2052.3359999999993, 2063.984999999999], [2063.984999999999, 2079.439999999999], [2079.439999999999, 2092.505999999999], [2092.505999999999, 2105.075999999999], [2105.075999999999, 2116.905999999999], [2116.905999999999, 2131.126999999999], [2131.126999999999, 2144.816999999999], [2144.816999999999, 2158.686999999999], [2158.686999999999, 2169.476999999999], [2169.476999999999, 2183.006999999999], [2183.006999999999, 2196.3069999999993], [2196.3069999999993, 2207.696999999999], [2207.696999999999, 2219.026999999999], [2219.026999999999, 2232.486999999999], [2232.486999999999, 2243.4969999999994], [2243.4969999999994, 2256.216999999999], [2256.216999999999, 2269.206999999999], [2269.206999999999, 2280.436999999999], [2280.436999999999, 2291.196999999999], [2291.196999999999, 2303.856999999999], [2303.856999999999, 2315.456999999999], [2315.456999999999, 2329.326999999999], [2329.326999999999, 2341.8169999999986], [2341.8169999999986, 2356.0269999999987], [2356.0269999999987, 2368.5169999999985], [2368.5169999999985, 2381.9769999999985], [2381.9769999999985, 2393.8269999999984], [2393.8269999999984, 2404.9769999999985], [2404.9769999999985, 2415.1169999999984], [2415.1169999999984, 2429.4669999999983], [2429.4669999999983, 2441.4969999999985], [2441.4969999999985, 2455.4969999999985], [2455.4969999999985, 2465.5569999999984], [2465.5569999999984, 2478.5169999999985], [2478.5169999999985, 2493.0269999999987], [2493.0269999999987, 2505.846999999999], [2505.846999999999, 2519.6769999999988], [2519.6769999999988, 2531.1769999999988], [2531.1769999999988, 2542.226999999999], [2542.226999999999, 2553.656999999999], [2553.656999999999, 2563.9269999999988], [2563.9269999999988, 2577.3569999999986], [2577.3569999999986, 2587.9669999999987], [2587.9669999999987, 2601.1969999999988], [2601.1969999999988, 2614.516999999999], [2614.516999999999, 2627.1769999999988], [2627.1769999999988, 2638.136999999999], [2638.136999999999, 2649.266999999999], [2649.266999999999, 2660.856999999999], [2660.856999999999, 2671.486999999999], [2671.486999999999, 2681.783999999999], [2681.783999999999, 2692.9339999999993], [2692.9339999999993, 2704.923999999999], [2704.923999999999, 2715.7439999999992], [2715.7439999999992, 2725.7439999999992], [2725.7439999999992, 2737.3139999999994], [2737.3139999999994, 2749.7039999999993], [2749.7039999999993, 2763.4139999999993], [2763.4139999999993, 2775.133999999999], [2775.133999999999, 2785.4739999999993], [2785.4739999999993, 2797.513999999999], [2797.513999999999, 2808.863999999999], [2808.863999999999, 2821.573999999999], [2821.573999999999, 2839.6439999999993], [2839.6439999999993, 2853.2139999999995], [2853.2139999999995, 2863.9589999999994], [2863.9589999999994, 2880.8639999999996], [2880.8639999999996, 2890.874], [2890.874, 2904.884], [2904.884, 2918.254], [2918.254, 2928.7039999999997], [2928.7039999999997, 2939.004], [2939.004, 2949.354], [2949.354, 2963.7039999999997], [2963.7039999999997, 2974.7239999999997], [2974.7239999999997, 2985.6939999999995], [2985.6939999999995, 2996.3339999999994], [2996.3339999999994, 3010.6539999999995], [3010.6539999999995, 3023.7439999999997], [3023.7439999999997, 3036.794], [3036.794, 3046.9539999999997], [3046.9539999999997, 3057.3839999999996], [3057.3839999999996, 3072.2039999999997], [3072.2039999999997, 3086.2239999999997], [3086.2239999999997, 3096.3839999999996], [3096.3839999999996, 3107.2539999999995], [3107.2539999999995, 3118.4229999999993], [3118.4229999999993, 3128.6929999999993], [3128.6929999999993, 3141.6329999999994], [3141.6329999999994, 3153.4929999999995], [3153.4929999999995, 3164.9529999999995], [3164.9529999999995, 3179.1629999999996], [3179.1629999999996, 3190.4829999999997], [3190.4829999999997, 3201.823], [3201.823, 3214.593], [3214.593, 3226.199], [3226.199, 3240.099], [3240.099, 3254.259], [3254.259, 3268.799], [3268.799, 3282.009], [3282.009, 3292.939], [3292.939, 3306.029], [3306.029, 3319.019], [3319.019, 3330.7389999999996], [3330.7389999999996, 3341.3439999999996], [3341.3439999999996, 3352.4189999999994], [3352.4189999999994, 3363.1989999999996], [3363.1989999999996, 3375.1889999999994], [3375.1889999999994, 3387.0589999999993], [3387.0589999999993, 3398.408999999999], [3398.408999999999, 3412.928999999999], [3412.928999999999, 3427.108999999999], [3427.108999999999, 3441.148999999999], [3441.148999999999, 3452.963999999999], [3452.963999999999, 3465.738999999999], [3465.738999999999, 3472.869999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [93, 688, 875, 1373, 1783, 2118, 2675, 3118, 3218, 3474]}
{"example_id": "mit153@@MITRES6_012S18_L22_300k", "text": [" In this lecture, we introduce the Poisson process, which is  a continuous time analog of the Bernoulli process.  One way of thinking about it is as follows. ", "Time is continuous, but conceptually we divide it into  a very large number of slots.  And during each slot, we have a tiny  probability of an arrival. ", "This probability is proportional to the  length of the slot.  Furthermore, we have an independence assumption for  the different slots.  ", "The Poisson process is a very elegant model of arrival  processes in continuous time.  It models many real-world phenomena.  And it also has a very clean mathematical structure that ", "allows us to calculate practically  every quantity of interest.  Our development will parallel our analysis of  the Bernoulli process. ", "For example, we will find the PMF of the number of arrivals  during a time interval and the PDF of the  time of the kth arrival. ", "We will discuss the memorylessness properties of  the Poisson process.  Similar to the case of the Bernoulli process, this is  just a consequence of the independence assumptions that ", "we are making.  We will then exploit these independence properties to  argue that the interarrival times are independent  exponential random variables. ", "And we will conclude with a comprehensive example.    We now set out to study the Poisson process, which  is a continuous time version of the Bernoulli process. ", "In the Bernoulli process, time is divided into slots.  And during each one of the slots,  we may either have an arrival or no arrival.  In the Poisson process, time is continuous. ", "And we may get arrivals at any time.  We want to define the Poisson process  by introducing some assumptions that in some ways parallel  the assumptions that we made for the Bernoulli process. ", "What where those assumptions?  The first one we made was the assumption of independence--  namely that what happens in different slots  are independent. ", "Similarly, for the Poisson process,  we will make the following independence assumption.  If we consider two intervals, two time intervals that  are disjoint, and look at the random variable that ", "stands for the number of arrivals  during this interval and that interval,  we will assume that these two random variables  are independent.  But even more than that, if we take  any collection of disjoint time intervals, ", "and we look at the associated random variables,  the associated numbers of arrivals,  that collection will also consist  of independent random variables. ", "The second assumption for the Bernoulli processes  was one of time homogeneity, namely at each slot,  we had the same probability of an arrival.  We want to make a similar assumption for the Poisson ", "process, and it's going to be the following.  The probability that we have k arrivals  during an interval of a certain duration tau  is going to be the same no matter where ", "that interval sits.  So if this is an interval that has a certain duration,  and this is an interval that has the same duration,  the probability of three arrivals in this interval ", "is going to be the same as the probability of three  arrivals in that interval.  And therefore, since this probability does not  depend on where the interval sits,  that probability will be fully defined ", "by the number of arrivals that we're interested in  and the length of the interval as  opposed to the location of the interval.  So we will be using this notation here ", "to indicate this probability.  In this notation, we think of tau as a constant.  And then, P of k corresponds to probabilities. ", "In particular, if you add over all k's  the various probabilities, what you should get  would be a value of 1, because this ", "exhausts all the possibilities.  And k here ranges from 0 to infinity,  because we allow an arbitrarily large number of arrivals  during a given time interval. ", "Now, with this assumption in place,  it would still be possible to have  arrivals that happen simultaneously,  multiple arrivals at the same time point. ", "In order to avoid this situation,  we introduce one more assumption which is the following.  It talks about the number of arrivals ", "during a time interval that has a small length delta.  During a small time interval, there  is negligible probability of having more than one arrival. ", "We will either have one or zero arrivals.  And the probability of one arrival  is a certain number, lambda times delta. ", "It's proportional to delta.  So if the interval becomes smaller and smaller,  that probability also goes to 0.  But it goes to 0 at a rate proportional to delta. ", "So you can think of lambda as probability per unit time.  These are the units of lambda.  Now here, I'm writing an approximate equality. ", "What does that mean?  It means that these are not exact expressions.  But they are exact within a second order term.  And a second order term is a term ", "that's negligible compared to the first order term  when delta is small.  More precisely, mathematically, what we mean  is that a second order term compared to a first order term ", "goes to 0 as delta goes to 0.   Finally, let me reiterate that lambda  should be interpreted as an arrival rate. ", "It is a probability per unit time.  The bigger lambda is, the bigger the probability  is that we get an arrival during a small time interval. ", "If we double lambda, then we double the probability  that we have an arrival during a small time interval.  And so we expect to have about twice as many arrivals, hence ", "the interpretation as an arrival rate.  We will see shortly that this is also justified  because lambda shows up in expressions for the expected  ", "In what kind of situations does the Poisson process arise?  In general, it arises whenever we  have events like arrivals that are somewhat rare, ", "and which happen in a completely uncoordinated manner,  so that they can show up at any particular time.  In such situations, the number of arrivals  will be often described by a certain distribution called ", "the Poisson distribution, and which  is named after the person who first studied this situation,  who is a famous French mathematician  by the name of Simon Denis Poisson. ", "An early example where the data seems  to fit the description of the Poisson process  is a curious one.  It had to do with deaths from horse  kicks, that is, accidental deaths, in the Prussian army. ", "The idea here is that a death by horse kick  can happen pretty much at any time.  And different arrivals, that is, different accidents  are completely uncoordinated from each other. ", "So the process is sort of completely random.  For more scientific applications,  it was realized that certain physical phenomena  obey the Poisson process. ", "Examples are the following.  You have some radioactive body which decays,  and the decaying happens once in awhile, ", "emitting various particles.  Different particles get emitted at completely random times  in a completely uncoordinated manner  and, therefore, this process is actually ", "described as a Poisson process.  Conversely, if you have a photo detector who  looks at a very weak light source.  So photons arrive from that weak light source one at a time. ", "And you look at the time at which photons hit the detector.  Then, the process of photon arrivals  is very well-modeled by the Poisson process.  For more modern applications, if you ", "look at the financial markets and the times at which  certain very unexpected events, like certain market shocks,  occur, a model that is commonly employed ", "is to use a Poisson process model.  Although this is not an entirely accurate model,  it provides a first approach to situations like this. ", "But these days, the predominant source  of applications for the Poisson process  is in various service operations.  You are the phone company. ", "Phone calls get placed at random times.  And because there are several people involved  who are uncoordinated with each other,  those calls get placed at completely random times. ", "And the same story goes about, let's  say, service requests to a web server,  service requests to any kind of company.  So, many applications that are being studied these days ", "and which rest on Poisson models involve service operations   The definition of the Poisson process  gives us information about the probability ", "that we get k arrivals during an interval of length delta  when delta is a very small number.  How can we find the probability of k arrivals ", "during an interval of some general length tau,  where tau is no longer a small number?  In particular, we're interested in the random variable denoted  N sub tau, which stands for the number of arrivals ", "during an interval of length tau.  And we wish to find the PMF of this random variable,  the probability that N sub tau is equal to k,  and which is what we have been denoting ", "by this particular notation in the context of the Poisson  process.  Now if, instead of the Poisson model,  we had for the Bernoulli process model, ", "we would know the answer.  S, the number of successes, or number of arrivals in n slots,  has a PMF which is given by the binomial formula. ", "Can we somehow use what we know about the Bernoulli process  to find the answer for the Poisson process?  The answer is yes, and it involves a limiting argument ", "of the following kind.  We take the interval from 0 to t and divide it  into a very large number of intervals, so many of them,  where each one of the intervals has a length of delta, ", "where delta is a small number.  And to push the analogy with the Bernoulli process,  we will be calling those little intervals as slots. ", "Now during each slot, we may get zero arrivals, one arrival,  but there's also the possibility that there  may be two arrivals, or even more than two arrivals, ", "happening during one of the slots.  Because of this, the picture that we have here  is not quite the same as for the Bernoulli process  because in the Bernoulli process, each one of the slots ", "will get only 0 or 1.  So the source of the discrepancy between the two models  is that here, a slot may obtain two or more arrivals. ", "But how likely is this?  Let us look at the probability that some slot, that  is, any one of the slots, contains two or more arrivals. ", "That is, we're dealing with the union of the events  that slot i has two or more arrivals.  ", "This event is the union of these events  and, therefore, the probability of this event is less than  or equal than the sum of the probabilities ", "of the constituents events.  This is an inequality that we have  seen at some point in the past.  And we're calling it to the union bound. ", "Now what is this summation?  i ranges over the different slots.  And we have tau over delta slots,  so there's so many terms that are being summed. ", "Now, during any particular slot, the probability  of two or more arrivals is of order delta squared, according  to the definition of the Poisson process.  And this quantity converges to 0 when ", "we let delta become smaller and smaller.  So this means that the discrepancy between the Poisson  and the Bernoulli model, which was due to the possibility ", "that we might get two or more arrivals during one  of those slots, this discrepancy is something  that happens with negligible probability. ", "In other words, the probability that we  get k arrivals in the Poisson model ", "is approximately the same as the probability  that k slots have an arrival.  ", "Since we're neglecting the possibility  that some slot has two or more arrivals,  this means that the number of arrivals in the Poisson model  will be the same as the number of slots that get an arrival. ", "This approximate equality becomes more and more exact  as we let delta go to zero.  But now what is this quantity? ", "The probability that k slots have an arrival  is something that we can calculate  using the binomial probabilities.  Each one of the slots has a certain probability ", "of having an arrival.  And different slots are independent of each other  by the defining properties of the Poisson process. ", "Therefore, this approximation that we have developed  satisfies the properties of the Bernoulli process.  We have a certain probability that each slot gets an arrival.  And we have independence across slots. ", "This means that we can use now the PMF that's  associated with the Bernoulli model  to calculate this quantity and then take the limit,  as delta goes to 0, to obtain a formula for the PMF ", "for the Poisson process.  In more detail, what we have is the number  of arrivals, which is approximately ", "the same as the number of slots that have an arrival, obeys  a binomial distribution in the limit as delta  goes to 0-- a binomial distribution in which ", "the probability of arrival during each one of the slots  is approximately lambda delta and the number of slots  goes to infinity.  And this happens in a way so that the product of the two, ", "n times p, is equal to-- this term times  this term gives us a lambda times tau.  This term times this term gives us  something that's order of delta. ", "So it's negligible.  So we have this equality, and so this  is approximately lambda tau with the approximation  becoming more and more exact as we let delta go to zero. ", "So all we need to do is to take the formula for the Bernoulli  process.  Use these values of p and n and take the limit. ", "But this is a problem that we have already encountered  and have analyzed.  If we let n go to infinity, p goes to 0  so that their product stays constant,  we have shown that the binomial PMF converges ", "to the so-called Poisson PMF that takes this form.  Notice one small difference-- n times  p here is equal to lambda, whereas here, n times  p is equal to lambda t. ", "This means that we need to apply this formula,  but with lambda replaced by lambda t,  and this gives us the final answer.  This is the probability of k arrivals during a time interval ", "of lenght t in the Poisson process.  And this is a so-called Poisson PMF with parameter lambda tau. ", "To summarize, our strategy was to argue that the Poisson  process is increasingly accurately described ", "by a Bernoulli process if we discretize  time in a very fine discretization.  And the approximation becomes exact in the limit  when the discretization is very fine. ", "So we took the corresponding binomial formula  for the Bernoulli process and took the limit  to that's associated with the parameters  that we would obtain if we have a very fine discretization. ", "And this gave us the final formula.    Now that we have in our hands the PMF  of the random variable N tau, which is the number of arrivals ", "during an interval of length tau,  we can go ahead and try to calculate  the mean and variance of this quantity.  Regarding the mean, we could use just the definition ", "of the expected value and then carry out  of this calculation, which is not too hard.  And in the end, we would obtain an answer equal to lambda times  tau. ", "This is indeed the correct formula for the expected value.  But let us understand why this formula should  be true without doing any calculation. ", "Remember that the random variable, the number  of arrivals in the Poisson process,  is well approximated by a binomial random variable ", "with those particular parameters n and p in the limit  when delta goes to zero.  And this works through a discretization argument.  Therefore, the expected value of N tau ", "should be approximately equal to the expected value of that we  get from the Bernoulli processes, that is the expected  value of the binomial random variable.  And the expected value of a binomial random variable ", "is n times p.  And n times p evaluates approximately to lambda times  tau.  The second equality here is approximate because we're ", "neglecting this order of delta squared term.  Now, these approximations are increasingly  exact as we let delta go to 0.  And when we take the limit as delta goes to 0, ", "we see that the expected value of the number of arrivals  in the Poisson process will be equal to lambda tau.  For the variance, we can follow a similar argument. ", "First do a binomial approximation  and use the formula for the variance  of a binomial random variable.  And then, when delta is small, this number p is small. ", "And it's negligible compared to 1.  n times p is approximately lambda [tau].  And so we obtain this expression  This expression here is the correct one. ", "If we were to use the formal definition of the variance  and carry out the calculations using the PMF,  this is what we would obtain, except that it  would be somewhat tedious. ", "The formulas that we have derived,  at least the first one, is quite intuitive  and has a natural form.  The expected number of arrivals is proportional to tau. ", "If we double the length of the time interval for interest,  we expect to see twice as many arrivals.  This formula also reinforces the interpretation of lambda ", "as an arrival rate.  Since lambda is the expected number of arrivals divided  by the length of time, it is, really,  the expected number of arrivals per unit time. ", "So it's natural to call lambda the arrival rate,  or the intensity of the arrival process.  Finally, regarding the variance, it is a curious fact ", "that the variance turns out to be  exactly the same as the expected value.   We will now go through a very simple example, in which we ", "just get to use the formulas that we have available.  The Poisson process is a pretty good model of email arrivals  at least during a limited part of the day. ", "For example, during daytime, emails  may be arriving as a Poisson crosses with a certain rate.  But then during night time, they may  be arriving as a Poisson process with a different rate. ", "Nevertheless, the assumption that we will make  is that, at least for this problem,  that emails arrive as a Poisson process  with a fixed rate of five messages per hour. ", "What is the mean and the variance  of the number of emails received during a day?  Well, we have formulas for the mean and the variance.  And in this problem, we have a lambda equal to 5, ", "and tau consists of 24 hours.  So the answer is 5 times 24.  And this answer applies to both of the mean and the variance, ", "because for the Poisson random variable, these are the same.  What is the probability that we get  one new message in the next hour?  This has to do with the PMF of the number of arrivals ", "during the next hour, and that PMF  is given by the Poisson probabilities.  We're asking for the probability of one new message,  so that k is equal to 1, in the next hour, ", "so that tau is equal to 1.  So we're looking for this expression here.  And using also that lambda is equal to 5,  we enter those numbers into this formula. ", "And what we obtained is 5 times e to the minus 5.  Finally, what is the probability that during each  of the next three hours, you'll obtain two messages. ", " So this is an event which is actually  the intersection of three events,  the event of two messages in this hour, ", "two messages in this hour, and two messages in that hour.  For the Poisson process, we have assumed that different time  intervals are independent of each other. ", "So what we need to do is to multiply  the probability of two messages in this hour  with the probability of two messages in that hour,  and the probability of two messages in that power. ", "On the other hand, for each one of the hours,  the probability's going to be the same,  so it's enough to take the probability of two messages  during this hour, which is in our notation this quantity, ", "and multiply it with itself three times,  so we get the third power of this.  Now this expression is equal to the following. ", "Lambda times tau is 5.  k is equal to 2, so we get 5 squared.  Then we have an e to the minus 5 term. ", "And k is equal to 2, so we're dividing by 2.   We now follow a program that parallels our development ", "for the case of the Bernoulli process.  We will study the time until the first arrival,  a random variable that we denote by T1.  We're interested in finding the probability ", "distribution of this random variable.  And later on, we will continue and try  to study the time until the kth arrival.  Now T1 is a continuous random variable, ", "because the Poisson process runs in continuous time.  And therefore, it has a PDF.  But instead of finding the PDF directly,  we will first find the CDF of this random variable. ", "So we fix a certain time, T. And we're  asking for the probability that the first arrival happens  during this interval.  Now this is 1 minus the probability ", "that the first arrival happens outside this interval.  So we can write this probability as 1 minus the probability  that T1 is bigger than t.  But what is this event? ", "The first arrival occurring after time, little t,  is the same as saying that there were no arrivals in the time  interval from 0 to little t. ", "And this probability of 0 arrivals  in a time interval of length t is  something for which we already have a formula. ", "Take this formula and replace k by 0, tau by t.  When k is equal to 0, this term is  something to the 0-th power equal to 1. ", "Using our convention, that 0 factorial is equal to 1,  we're left just with e to the minus lambda t.  And this is the answer for the CDF of the time ", "until the first arrival.  We then take the derivative.  And we find that the PDF of the time until the first arrival  has this form, which is the PDF of an exponential random ", "variable.  Of course, this calculation here is  only valid for t's that are non-negative.  For negative t's, the PDF of T1 is, of course, 0. ", "For the exponential random variable,  we have seen that it has certain memorylessness properties.  Namely, if I condition on an event  that nothing has occurred until a certain time, ", "t, and I am interested in the time from now  until the first arrival occurs, this remaining  until the first arrival is again an exponential distribution. ", "That is, looking ahead from this time,  I will still wait an exponentially distributed  amount of time until I see the first arrival.  Whatever happened in the past and how long ", "I have been waiting doesn't matter.  Starting from this time, I will still  wait an exponentially distributed amount of time.  This is essentially an expression  of a fresh start property of the Poisson process, which ", "is analogous to the fresh start properties for the Bernoulli  process.  And we will be discussing this fresh start  property a lot more.  Having figured out the distribution  of the time of the first arrival, ", "let us now study the time of the k-th arrival, a random variable  that we denote by Y sub k, similar to the case  of the Bernoulli process. ", "This random variable is a continuous one,  because arrivals happen in continuous time,  so it takes continuous values.  And therefore, it will be described by a PDF.  And this is what we want to find. ", "In order to find it, we will make use of the Poisson PMF  that we have already derived for the number of arrivals  during an interval of a fixed length. ", "One approach to finding the PDF of Yk  is the usual program, similar again  to what we did for the case of the first arrival time.  We can first find CDF, and then differentiate to find the PDF. ", "So what is the CDF?  We want to calculate the probability  that Yk is less than or equal to some number, little y. ", "Now what is this event?  The k-th arrival occurs by time y.  This means that by time y, we've had at least k arrivals. ", "We've had k arrivals, or maybe k plus 1, or maybe k plus 2.  We've had some number of arrivals, n,  in an interval of length, y. ", "And this is an event that happens with this probability.  But we need to take into account all of the possible values of n  that are at least as large as k. ", "Now we have a formula for this probability, the probability  of n arrivals in an interval of given length.  This is the Poisson PMF with appropriate changes of symbols. ", "So we can take this expression, substitute it here, and then  differentiate to do some algebra and find the answer.  Instead of carrying out this algebra, ", "however, we will proceed in a more intuitive way that  will get us there perhaps faster.  And the derivation that we would follow actually ", "parallels the one that we went through  in the case of the Bernoulli process.  The intuitive argument that we will use  will rest on the interpretation of a PDF ", "in terms of probabilities of small intervals.  So the PDF evaluated at some particular point,  y, times delta, is approximately the probability ", "that our random variable falls within a delta interval  from this number, little y, that we're considering.  So here's time 0, here's time y, and here's time y plus delta. ", "We want to find or to say something  about the probability of falling inside this small interval.  Now what does it mean for the k-th arrival ", "to fall inside this interval?  This is an event that can happen as follows.  The k-th arrival falls in this interval,  and we've had k minus 1 arrivals during the previous interval. ", "What is the probability of this event?  A basic assumption about the Poisson process  is the independence assumption.  Therefore, having k minus 1 arrivals in this interval ", "and having one arrival in this interval  are independent events.  Therefore, the probability of this scenario  is the product of the probabilities  that we've had k minus 1 arrivals in an interval ", "of length, y, times the probability  that we've had one arrival in an interval of length delta.  And that latter probability is approximately ", "equal to lambda times delta.  So I should write here an approximate equality instead  of an exact equality, to indicate  that there are other terms, order of delta squared, ", "for example, but which are much smaller compared to the delta.  However, this is not the only way  that we can get the k-th arrival in this interval.  There's an alternative scenario. ", "We might have had k minus 2 arrivals during this interval,  and then two arrivals during that little interval.  In this case, the k-th arrival again ", "occurs within that little interval.  So we need to also calculate the probability of this scenario.  The probability of that scenario is  the probability of k minus 2 arrivals in an interval ", "of length, y, times the probability of two arrivals.  But the probability of two arrivals  is something that's order of delta squared.  And order of delta squared is much smaller ", "than this term, which is linear in delta.  And so this term can be ignored as long as we're just  keeping track of the dominant terms,  those are linear in delta. ", "And then, they would be similar expressions.  For example, the scenario that we have three arrivals up  to time y, and then three more arrivals  during that little interval, which is again ", "an event of probability, order of delta  squared, that we get three arrivals there.  And all of those terms are insignificant,  and we can ignore them.  And we end up with an approximate equality ", "between this term and this expression here.  Delta shows up on both sides, so we can cancel delta. ", "And therefore, we have ended up with a formula for the PDF.  In particular, the PDF is equal to this probability times  lambda. ", "What is this probability?  We have a formula for it.  But we just need to substitute.  Put k minus 1 in the place of k, and put y in the place of tau. ", "This gives us lambda y to the power k minus 1, e  to the minus lambda y, divided by k minus 1 factorial. ", "And then we have the extra factor  of lambda, which can be put together with this lambda  to the k minus 1 here.  And we end up with this final formula for the PDF of Yk. ", "The distribution that we have here  is called an Erlang distribution.  But actually, it's not just one distribution.  We have different distributions depending  on what k we're considering. ", "The distribution of the time of the third arrival  is different from the distribution  of the 10th arrival.  So if we fix a particular k, then  we say that we have an Erlang distribution of order k. ", " For the case where k is equal to 1,  this term here disappears, k minus 1 is equal to 0. ", "And the denominator term disappears,  and we end up with lambda times e to the minus lambda y.  But this is the exponential distribution  that we had already derived with a different method earlier. ", "As you increase k, of course, you  get different distributions.  And these tend to shift towards the right.  This makes sense.  The time of the second arrival is ", "likely to take certain values.  The time of the third arrival is likely to take  values that are higher.  And the more you increase k, the more the distribution  will be shifting towards the right. ", "  This segment is probably the most critical one  for the purpose of understanding what the Poisson process really  is and how it behaves.  There will be almost no mathematical formulas. ", "But the segment will be quite dense  in terms of conceptual reasoning.  So pay a lot of attention.  In a nutshell, we will argue that the Poisson process has ", "memorylessness properties that are entirely similar to those  that we have seen for the Bernoulli process.  This should not be surprising, since the Poisson process can  be thought of as a limiting case of the Bernoulli process. ", "We will reason through these properties,  not in the style of a formal mathematical proof,  but with an intuitive argument.  But I would like to assure you that the intuitive argument can ", "be translated into a rigorous proof.  The first property is the following.  The process starts at time 0.  You come in and start watching at let's say time 7. ", "Or more generally, instead of time 7,  suppose that you come in and start  watching at some time, little t.  The important thing here is that little t is a constant. ", "It's a deterministic number.  Starting at that time, what will you see?  Well, the original process was Poisson. ", "This means that disjoint intervals  in the original process are independent.  Therefore, disjoint intervals in the process ", "that you will be seeing will also be independent.  Furthermore, during any little interval of length  delta in the process that you see ", "will still have probability lambda times  delta, approximately, of seeing and arrival.  Therefore, what you see also satisfies the properties  of a Poisson process, and is itself a Poisson process. ", "Second, the original process was Poisson.  So different intervals are independent.  So whatever happens in this interval  is independent from whatever happens in that interval. ", "But that interval corresponds to the future of the process,  and therefore, the future of the process, what you get to see,  is independent from the past history. ", "And so the conclusion is that the process that you get to see  is a Poisson process, which is independent of the history  until the time that you started watching. ", "And we say, therefore, that what you see  is a fresh starting process.  The Poisson process starts fresh at time t. ", "We have the fresh start property.  And similar to the language we use for the Bernoulli process,  the fresh start property means that you see a process that's  independent of the past and which ", "has the same statistical properties as if this was time  0, as if the process was just starting right now.  One consequence of this fresh start property ", "is the following.  You start watching at time t.  And you're interested in the time  it takes until the next arrival. ", "What are the properties of this random variable?  Well, since you have a fresh starting Poisson process  at this time, this is the time until the first arrival ", "in this fresh starting Poisson process.  And the time until the first arrival  in a process that is just starting,  we know that it has an exponential distribution. ", "So this is going to be an exponential random variable  with the same parameter, lambda.  Furthermore, because the process starts fresh,  whatever happens in the future is independent from the past. ", "And so this random variable, the remaining time,  is independent of whatever happened in the past until time  t.  ", "Now let us look at a somewhat different situation.  You start watching the process at time T1.  Time T1 is the time of the first arrival. ", "And you start watching from here on.  What is it that you're going to see?  Suppose that the first arrival happens,  let's say, at time equal to 3. ", "So we're conditioning on this event.  In that case, you start watching the process at time 3.  And you also know that the first arrival happened at time 3. ", "But this fact about the first arrival happening at time 3  belongs to the history of the process until time 3.  This is information about the past, ", "and does not affect what is going to happen after time 3.  The process after time 3 will be independent from the history  until time 3 and whatever happened until that time. ", "So starting at that particular time 3, what you see  is a Poisson process that is independent from the past.  Now, this argument is valid even if I ", "were to use here a 3.5 or 3.4 or 3.7.  No matter when this first arrival occurred,  what I see starting from this time ", "is a Poisson process which is independent from the past.  At the time of the first arrival,  the process just starts fresh. ", "As a consequence of this, and by repeating the argument that we  carried out for the remaining time until the next arrival  up here, we can repeat this argument  and argue that the time until the next arrival ", "in this fresh starting process, this  will also be an exponential random variable.  Now, this time until the next arrival ", "is the difference between the second arrival  time and the first arrival time.  And we denote it by T2.  What we just argued is that this time until the next arrival ", "is going to be an exponential random variable.  And also, it is independent from the past.  And in particular, it is independent from T1. ", "So the time until the second arrival,  starting from the first arrival, the second inter-arrival time  is a random variable that has an exponential distribution that ", "is the same distribution as that of T1,  and is independent from T1.  Now we can extend this argument and look at the kth  inter-arrival time. ", "For example, if the arrival numbered k minus 1  occurred here, and the k arrival occurs here,  this difference, here we denote it by Tk, ", "and by arguing in a similar way that the process starts  fresh at this particular time, the time until the next arrival  will also be an exponential random variable ", "with the same distribution.  And furthermore, will be independent  from the past history, and therefore,  independent from the earlier inter-arrival times. ", "And this has lots of important implications.  For example, the time until the kth arrival,  which is the sum of the first k inter-arrival times, ", "is the sum of independent, identically distributed,  exponential random variables.  In particular, this means that we can find the PDF of Yk ", "by convolving the exponential PDF  of these inter-arrival times, convolving this exponential PDF  with itself k times. ", "And this is indeed one way to find the PDF of Yk.  But fortunately for us, we were able to find it  with a much simpler argument.  And we already know what it is. ", "But this property here is also useful for finding  the mean and the variance of Yk.  The mean of the sum is the sum of the means.  And since the random variables are independent, ", "the variance of the sum is the sum of the variances.  We know what is the mean and the variance of an exponential.  And so by multiplying that by k, we  obtain the mean of the kth arrival time ", "and the variance of the kth arrival time.  And so we now know the mean and variance  of the Erlang PDF of order k.  A second implication of this property ", "is more theoretical, more conceptual.  Recall that we defined the Poisson process  in terms of an independence assumption  and an assumption on the probability of arrivals ", "during a small interval.  But we could have defined the Poisson process as follows.  Consider a sequence of independent, identically ", "distributed exponentials.  Call them Tk.  And use these to define the arrival times.  This is a way of constructing a process. ", "What we argued in this segment is  that a Poisson process under the original definition  satisfies this new definition.  One can complete the argument to show ", "that the two definitions are equivalent.  It is possible to argue that if we define an arrival  process in this manner, this arrival process will also  satisfy the basic properties of the Poisson process. ", "This argument can indeed be carried out,  but we will not go through it.  A final implication, which is a little more practical.  If you want to simulate the Poisson process, ", "how would you do it?  Given what we now know, the most natural way is the following.  We generate independent, identically distributed, ", "exponential random variables, using  for example a random number generator.  And then use these exponential random variables  to construct the values of the inter arrival times. ", "And this way, construct a complete time history   Let us now take stock and summarize  what we have done for these two processes, the Bernoulli ", "and the Poisson process, and their relation.  The Poisson process runs in continuous time,  whereas, for the Bernoulli process,  time is discrete and is divided into slots. ", "The Poisson process is defined by a single parameter, lambda,  which is the intensity or arrival rate,  and tells us the expected number of arrivals per unit time. ", "For the Bernoulli process, we have, again,  one basic parameter, which is the probability of success  at any given trial, or the probability  of an arrival during each one of the slots. ", "Based on our model, we were interested in three kinds  of quantities.  And we found the distributions of them.  The first quantity is the number of arrivals ", "during a certain time interval.  For the discrete case, the number of arrivals  has a binomial distribution, whereas for the one Poisson  case, the distribution is that of a Poisson random variable. ", "Then we looked at the time until the first arrival,  or the time between consecutive arrivals.  For the Bernoulli process, that distribution is geometric. ", "For the Poisson process, that distribution is exponential.  Note that in this instance, we're  dealing with a discrete random variable,  but, here, with a continuous random variable.  And then, as a generalization, we ", "could find the time until a kth arrival, which, in the Poisson  case, is given by an Erlang distribution.  And for the Bernoulli case, we developed ", "one particular formula.  And that formula is actually known  under the name of the Pascal distribution.  All of these results, for the Poisson case, ", "were obtained because we used an approximation argument.  That is, we had the results for the Bernoulli case.  But then we argued that the Poisson process ", "is a limiting case of the Bernoulli process  in which we take time, divide it into a large number of slots,  during each one of the slots, however, ", "we have a small probability of an arrival.  And this is done in a way so that the product of these two  numbers stays a constant.  By using a finer and finer discretization, ", "we could approach the Poisson process arbitrarily  close by a Bernoulli process.  And then we used the Bernoulli formulas  in which we took the limit as delta was going to zero. ", " In this segment, we go through an example  to get some practice with Poisson process calculations.  The example is as follows.  You go fishing and fish are caught according ", "to a Poisson process with an arrival rate-- that  is the rate at which fish are caught-- of 0.6 fish per hour.  You will fish for two hours no matter what. ", "And if during those two hours you  have caught at least one fish, then you stop.  As in this scenario, in which you have caught three fish  during the first two hours, and then you stop. ", "Otherwise, you will continue until you catch one fish.  And at that time, you will stop.  We will answer a few questions and we will write down ", "the answers to these questions in terms of the notation  that we have introduced.  And here, for reference, we have all of the formulas  that we have developed so far. ", "The first question is, what is the probability  that you get to fish for more than two hours?  Well, you get to fish for more than two hours if and only  if you didn't catch any fish during the first two hours. ", "So this is the probability of catching  zero fish in the first two hours.  And we can use this formula.  Substitute k equal to 0, tau equal to 2, ", "lambda equal to 0.6.  Plug in the numbers and obtain a numerical answer.  We will not bother [with] the numerical answers,  we will just be writing down the expressions that ", "give us the answers.  Now, in this question we could have a different approach.  You will fish for more than two hours ", "if and only if there are no arrivals during the first two  hours, which means that the first arrival  in the Poisson process of fishing happens after time 2. ", "So we're talking about the event that the first arrival, T1,  is bigger than 2.  And we're looking into the probability  of this event, which is the integral of the density ", "of the first arrival time.  And the integral is taken over the range  of values of interest-- larger than 2.  That is, from 2 to infinity. ", "We know that this density is exponential,  so we can write down this integral and evaluate it.  So notice the difference between these two approaches.  Here we think in terms of the random variables that ", "correspond to the number of arrivals  during a certain time interval.  Here we're reasoning in terms of inter-arrival times.  And more generally, for Poisson process problems, ", "an event of interest sometimes can  be expressed in terms of number of arrivals.  Or sometimes it can be expressed in terms  of arrival and inter-arrival times. ", "Or sometimes both approaches are possible.  But usually one of the two approaches  will be simpler than the other.  For example, here we already have a formula,  whereas here we would need to evaluate an integral. ", "Here is now our next question, which is a little bit more  complicated.  What is the probability that you get  to fish for more than two hours, and also you ", "get to fish for less than five hours?  This is the scenario, again, that you  fish for more than two hours, which means that no fish were ", "caught during the first two hours.  And then you continue fishing.  And by time 5 you have already caught your fish  and you have left. ", "Now, it is convenient of thinking about the Poisson  process as follows.  Think about the Poisson process of catching fish  at the rate of 0.6 per hour as going on forever. ", "So there's a fisherman who fishes forever,  except that this fisherman at either this time,  under this scenario, or at that time, under this scenario, ", "raises a flag and says, OK, this is  the time I should be stopping.  So even though the fisherman will stop fishing at this time, ", "we can imagine the Poisson process keeps going on.  With this way of thinking, the fact  that you stopped fishing before time 5 is the event ", "and that the number of fish caught,  or the number of Poisson arrivals during the interval  from 2 to 5 is at least equal to 1, larger than or equal to 1. ", "So the event of interest consists of the intersection  of two events, zero fish caught during the first two hours--  which has this probability-- and at least one ", "arrival in the Poisson process between times 2 and 5--  this is a time interval of length 3.  And having at least one arrival is ", "1 minus the probability of 0 arrivals  in a time interval of length 3.  Notice that I'm multiplying those two probabilities here. ", "Why am I doing this?  In a Poisson process, whatever happens  in disjoint time intervals are independent events.  So an event having to do with this interval-- ", "the event that no fish were caught--  and the event that has to do with this interval-- at least  one fish caught, at least one arrival during this time  interval-- these two events are independent. ", "And this is why we can multiply their probabilities.  Now, let us think of the alternative approach,  a different way of describing this event using  arrival and inter-arrival times. ", "What is this event?  This is the event that no arrival happened  until this time, but an arrival happened before time 5.  So this is the event that the first arrival ", "happens after time 2, but before time 5.  And we're looking at the probability  of this event, which we can find by integrating ", "the PDF of the first arrival time from 2 until 5.  The next question is, what is the probability  that we catch at least two fish? ", "Under this scenario, we catch one fish and we stop.  Therefore, this scenario must have materialized.  The event of catching at least two fish ", "is the scenario that from time from 0 until 2,  we caught at least two fish.  So we're talking about the probability  of catching at least two fish, which ", "is the probability of catching k fish during a time  interval of length 2, where k can be anything from 2 ", "to infinity.   So this is the probability that the number  of fish caught during these two time units  is at least equal to 2. ", "And an alternative way of writing this expression  so that we do not have to evaluate an infinite sum,  it is 1 minus the probability of catching 0 fish, ", "and minus the probability of catching 1 fish.   If we were to write this in terms of arrival  and inter-arrival times, we will catch at least two fish ", "if and only if by the time we stop-- which will be time 2--  we've had 2 arrivals, which means that the second arrival  time happened before time 2. ", "So we're looking into the probability  that the second arrival time happened before time 2, which  is the integral from 0 to 2 of the density ", "of the second arrival time.  We have a formula for this density  given by the Erlang PDF.  So we could take this expression, plug it in here, ", "evaluate the integral, and obtain the same answer  as we would have obtained here.  Clearly, in this case as well, this first approach  would be a simpler one because these probabilities are already ", "available to us.  The next question is the following.  Suppose that you already fished for three hours.  This is something that can only happen ", "under the second scenario.  So no fish have being caught until time 2.  You continue.  No fish were caught until time 3.  And given that this event has occurred, ", "what is the expected value of the future fishing time?  The expected value until a fish gets caught for the first time? ", "Well, the Poisson process starts fresh at time 3,  no matter what happened in the past,  no matter what information we're given in the past.  Now you're sitting at time 3 and looking into the future. ", "You have a fresh starting Poisson process,  as if this was the initial time.  Starting from this time, the time until the first arrival ", "is going to have an exponential distribution with parameter  lambda, and the expected value of this distribution  is equal to 1 over lambda. ", "Finally, let's look at a different type of question.  What is the expected value of the total time  that you get to fish?  Let us introduce here some notation. ", "Let us call the total fishing time capital F.  And the total fishing time consists of two pieces.  There's a time until time 2 that you ", "will be fishing no matter what.  And then there's going to be the remaining fishing  time after time 2.  ", "So now let's look at the expectation  of the remaining fishing time after time 2.  Here there are two scenarios.  In the first scenario, you stop.  In the second scenario, you continue. ", "And we will take into account these two scenarios  by using the total expectation theorem.  The first scenario happens with some probability. ", "This is the probability that you stop fishing at time 2.  And in that case, your remaining fishing time  is going to be equal to 0 because you do not ", "continue under that scenario.  But there's the other scenario that you  get to fish for more than 2 time units.  And then we multiply this term with ", "the conditional expectation of the remaining fishing time,  given that you got to fish for more than 2 times units.  ", "So what is this term?  The probability that you get to fish for more than 2 time  units, this is the probability that no fish  were caught during the first time units. ", "This is the probability of the second scenario.  And then we have this conditional expectation.  Given that you didn't catch anything ", "and, therefore, you will be continuing fishing,  what is the expected amount of time-- F minus 2--  that you will be fishing? ", "Now the Poisson process starts fresh at time 2.  So looking into the future, we're  faced with a Poisson process and we're  asking for the expected time until the first arrival. ", "And this time has an expected value equal to 1 over lambda.  Our last question is of a similar type. ", "What is the expected number of fish you're going to catch?  Once more, we will break this into two pieces.  Number of fish caught during the first two hours, ", "and number of fish caught during the remaining hours.  During the first two hours, the expected number  of fish that you catch is given by this formula. ", "It is equal to lambda tau-- and in our case lambda is 0.6  and tau is equal to 2-- plus the expected number of fish ", "that are caught afterwards.  What is this expected value?  Again, we think in terms of the total expectation theorem.  There's one scenario that has a certain probability, ", "and under that scenario you do not catch any fish.  So that doesn't give us any contribution.  Then there is this scenario, the second one,  that has this probability of occurring. ", "The probability of catching no fish here,  so that the second scenario materializes.  And if that second scenario materializes,  how many fish are you going to catch after time 2? ", "It's going to be one fish with certainty.   And this is the final answer to this question.  Notice that in answering both of these questions ", "we used the divide and conquer strategy twice.  We first divided the time horizon into two pieces  and dealt separately with each one of the pieces. ", "And then in order to deal with this second piece--  the time after time 2-- we used divide  and conquer into the two different scenarios ", "and using the total expectation theorem. "], "vid_duration": [10.69, 10.55, 10.62, 12.53, 11.25, 10.29, 10.52, 11.5, 10.124, 11.836, 10.289, 10.57, 11.901, 13.24, 10.239, 11.171, 11.98, 11.599, 12.071, 10.43, 13.119, 10.161, 11.57, 10.25, 10.97, 12.579, 10.62, 11.611, 12.28, 10.87, 13.34, 12.699, 10.931, 11.52, 12.493, 10.7, 13.92, 11.87, 13.66, 11.75, 10.649, 10.25, 10.801, 12.569, 12.77, 10.361, 11.87, 10.909, 11.931, 11.21, 11.706, 10.49, 11.59, 10.84, 10.06, 10.529, 10.651, 13.31, 12.36, 11.88, 10.38, 10.86, 10.849, 14.47, 11.331, 10.002, 11.388, 12.539, 11.23, 10.351, 12.89, 14.769, 14.29, 11.181, 12.86, 10.29, 12.52, 14.84, 10.019, 10.811, 12.854, 11.546, 14.059, 11.201, 14.529, 10.74, 12.54, 10.091, 10.459, 10.97, 12.741, 11.853, 10.31, 11.03, 10.24, 10.95, 13.6, 10.68, 12.43, 11.48, 11.16, 14.19, 11.85, 11.36, 10.62, 10.99, 13.79, 10.43, 11.604, 11.77, 11.85, 12.09, 11.76, 10.0, 13.95, 11.33, 11.21, 13.08, 11.28, 10.45, 10.83, 15.41, 10.66, 10.57, 11.023, 11.63, 11.78, 10.81, 11.23, 11.76, 11.64, 10.22, 10.91, 10.19, 12.22, 12.21, 12.51, 12.36, 11.71, 13.66, 11.73, 10.15, 11.68, 10.61, 14.15, 10.22, 12.11, 12.52, 13.46, 10.71, 10.06, 10.56, 10.58, 11.22, 12.96, 11.01, 13.96, 12.33, 15.08, 10.34, 10.14, 11.98, 11.58, 12.63, 12.04, 10.78, 12.42, 13.63, 12.73, 10.8, 11.18, 12.35, 13.25, 11.03, 12.55, 10.16, 12.89, 11.7, 11.47, 12.59, 12.31, 13.35, 10.53, 14.89, 10.77, 12.31, 10.24, 11.06, 13.71, 11.96, 10.81, 11.16, 11.13, 11.35, 12.18, 10.01, 10.59, 12.35, 12.36, 14.69, 13.79, 11.16, 10.78, 10.31, 12.27, 10.71, 11.99, 12.41, 13.36, 11.19, 13.5, 14.34, 10.73, 10.2, 12.1, 10.75, 11.6, 12.26, 11.91, 10.4, 11.02, 11.37, 12.469, 12.861, 11.25, 10.06, 12.54, 11.69, 13.66, 11.95, 10.88, 12.21, 11.092, 11.1, 10.56, 12.44, 10.83, 13.12, 10.08, 11.15, 10.17, 10.92, 10.3, 10.51, 11.72, 12.54, 11.61, 12.92, 10.85, 12.2, 10.99, 13.92, 12.2, 10.63, 10.7, 11.21, 14.94, 11.16, 13.16, 12.21, 11.89, 12.93, 10.75, 11.19, 10.72, 11.77, 13.54, 10.11, 13.86, 13.1, 14.32, 10.4, 11.17, 11.56, 11.01, 11.74, 12.82, 10.86, 11.985, 12.005, 12.66, 12.351, 11.389, 10.23, 14.09, 12.84, 11.67, 12.43, 12.01, 10.52, 11.84, 10.25, 13.16, 11.0, 11.4, 12.2, 13.03, 12.71, 12.23, 11.16, 11.38, 13.86, 10.7, 10.09, 10.47, 11.42, 11.03, 10.16, 11.8, 13.14, 13.22, 12.13, 12.22, 11.26, 11.63, 12.74, 10.97, 3.742], "stet": [[0, 10.69], [10.69, 21.240000000000002], [21.240000000000002, 31.86], [31.86, 44.39], [44.39, 55.64], [55.64, 65.93], [65.93, 76.45], [76.45, 87.95], [87.95, 98.074], [98.074, 109.91], [109.91, 120.199], [120.199, 130.769], [130.769, 142.67000000000002], [142.67000000000002, 155.91000000000003], [155.91000000000003, 166.14900000000003], [166.14900000000003, 177.32000000000002], [177.32000000000002, 189.3], [189.3, 200.899], [200.899, 212.97], [212.97, 223.4], [223.4, 236.519], [236.519, 246.68], [246.68, 258.25], [258.25, 268.5], [268.5, 279.47], [279.47, 292.04900000000004], [292.04900000000004, 302.66900000000004], [302.66900000000004, 314.28000000000003], [314.28000000000003, 326.56], [326.56, 337.43], [337.43, 350.77], [350.77, 363.469], [363.469, 374.4], [374.4, 385.91999999999996], [385.91999999999996, 398.41299999999995], [398.41299999999995, 409.11299999999994], [409.11299999999994, 423.03299999999996], [423.03299999999996, 434.90299999999996], [434.90299999999996, 448.563], [448.563, 460.313], [460.313, 470.962], [470.962, 481.212], [481.212, 492.013], [492.013, 504.582], [504.582, 517.352], [517.352, 527.713], [527.713, 539.583], [539.583, 550.492], [550.492, 562.423], [562.423, 573.633], [573.633, 585.339], [585.339, 595.8290000000001], [595.8290000000001, 607.4190000000001], [607.4190000000001, 618.2590000000001], [618.2590000000001, 628.3190000000001], [628.3190000000001, 638.8480000000001], [638.8480000000001, 649.499], [649.499, 662.809], [662.809, 675.169], [675.169, 687.049], [687.049, 697.429], [697.429, 708.289], [708.289, 719.138], [719.138, 733.6080000000001], [733.6080000000001, 744.9390000000001], [744.9390000000001, 754.941], [754.941, 766.3290000000001], [766.3290000000001, 778.868], [778.868, 790.0980000000001], [790.0980000000001, 800.4490000000001], [800.4490000000001, 813.339], [813.339, 828.1080000000001], [828.1080000000001, 842.398], [842.398, 853.5790000000001], [853.5790000000001, 866.4390000000001], [866.4390000000001, 876.729], [876.729, 889.249], [889.249, 904.089], [904.089, 914.1080000000001], [914.1080000000001, 924.9190000000001], [924.9190000000001, 937.7730000000001], [937.7730000000001, 949.3190000000002], [949.3190000000002, 963.3780000000002], [963.3780000000002, 974.5790000000002], [974.5790000000002, 989.1080000000002], [989.1080000000002, 999.8480000000002], [999.8480000000002, 1012.3880000000001], [1012.3880000000001, 1022.4790000000002], [1022.4790000000002, 1032.938], [1032.938, 1043.9080000000001], [1043.9080000000001, 1056.6490000000001], [1056.6490000000001, 1068.5020000000002], [1068.5020000000002, 1078.8120000000001], [1078.8120000000001, 1089.842], [1089.842, 1100.082], [1100.082, 1111.0320000000002], [1111.0320000000002, 1124.632], [1124.632, 1135.3120000000001], [1135.3120000000001, 1147.7420000000002], [1147.7420000000002, 1159.2220000000002], [1159.2220000000002, 1170.3820000000003], [1170.3820000000003, 1184.5720000000003], [1184.5720000000003, 1196.4220000000003], [1196.4220000000003, 1207.7820000000002], [1207.7820000000002, 1218.402], [1218.402, 1229.392], [1229.392, 1243.182], [1243.182, 1253.612], [1253.612, 1265.2160000000001], [1265.2160000000001, 1276.986], [1276.986, 1288.836], [1288.836, 1300.926], [1300.926, 1312.686], [1312.686, 1322.686], [1322.686, 1336.636], [1336.636, 1347.966], [1347.966, 1359.176], [1359.176, 1372.2559999999999], [1372.2559999999999, 1383.5359999999998], [1383.5359999999998, 1393.9859999999999], [1393.9859999999999, 1404.8159999999998], [1404.8159999999998, 1420.2259999999999], [1420.2259999999999, 1430.886], [1430.886, 1441.456], [1441.456, 1452.4789999999998], [1452.4789999999998, 1464.109], [1464.109, 1475.889], [1475.889, 1486.6989999999998], [1486.6989999999998, 1497.9289999999999], [1497.9289999999999, 1509.6889999999999], [1509.6889999999999, 1521.329], [1521.329, 1531.549], [1531.549, 1542.459], [1542.459, 1552.6490000000001], [1552.6490000000001, 1564.8690000000001], [1564.8690000000001, 1577.0790000000002], [1577.0790000000002, 1589.5890000000002], [1589.5890000000002, 1601.949], [1601.949, 1613.659], [1613.659, 1627.3190000000002], [1627.3190000000002, 1639.0490000000002], [1639.0490000000002, 1649.1990000000003], [1649.1990000000003, 1660.8790000000004], [1660.8790000000004, 1671.4890000000003], [1671.4890000000003, 1685.6390000000004], [1685.6390000000004, 1695.8590000000004], [1695.8590000000004, 1707.9690000000003], [1707.9690000000003, 1720.4890000000003], [1720.4890000000003, 1733.9490000000003], [1733.9490000000003, 1744.6590000000003], [1744.6590000000003, 1754.7190000000003], [1754.7190000000003, 1765.2790000000002], [1765.2790000000002, 1775.8590000000002], [1775.8590000000002, 1787.0790000000002], [1787.0790000000002, 1800.0390000000002], [1800.0390000000002, 1811.0490000000002], [1811.0490000000002, 1825.0090000000002], [1825.0090000000002, 1837.3390000000002], [1837.3390000000002, 1852.419], [1852.419, 1862.759], [1862.759, 1872.8990000000001], [1872.8990000000001, 1884.8790000000001], [1884.8790000000001, 1896.459], [1896.459, 1909.0890000000002], [1909.0890000000002, 1921.1290000000001], [1921.1290000000001, 1931.909], [1931.909, 1944.3290000000002], [1944.3290000000002, 1957.9590000000003], [1957.9590000000003, 1970.6890000000003], [1970.6890000000003, 1981.4890000000003], [1981.4890000000003, 1992.6690000000003], [1992.6690000000003, 2005.0190000000002], [2005.0190000000002, 2018.2690000000002], [2018.2690000000002, 2029.2990000000002], [2029.2990000000002, 2041.8490000000002], [2041.8490000000002, 2052.009], [2052.009, 2064.899], [2064.899, 2076.5989999999997], [2076.5989999999997, 2088.0689999999995], [2088.0689999999995, 2100.6589999999997], [2100.6589999999997, 2112.9689999999996], [2112.9689999999996, 2126.3189999999995], [2126.3189999999995, 2136.8489999999997], [2136.8489999999997, 2151.7389999999996], [2151.7389999999996, 2162.5089999999996], [2162.5089999999996, 2174.8189999999995], [2174.8189999999995, 2185.0589999999993], [2185.0589999999993, 2196.1189999999992], [2196.1189999999992, 2209.8289999999993], [2209.8289999999993, 2221.7889999999993], [2221.7889999999993, 2232.5989999999993], [2232.5989999999993, 2243.758999999999], [2243.758999999999, 2254.888999999999], [2254.888999999999, 2266.238999999999], [2266.238999999999, 2278.418999999999], [2278.418999999999, 2288.428999999999], [2288.428999999999, 2299.0189999999993], [2299.0189999999993, 2311.3689999999992], [2311.3689999999992, 2323.7289999999994], [2323.7289999999994, 2338.4189999999994], [2338.4189999999994, 2352.2089999999994], [2352.2089999999994, 2363.3689999999992], [2363.3689999999992, 2374.1489999999994], [2374.1489999999994, 2384.4589999999994], [2384.4589999999994, 2396.7289999999994], [2396.7289999999994, 2407.4389999999994], [2407.4389999999994, 2419.428999999999], [2419.428999999999, 2431.838999999999], [2431.838999999999, 2445.198999999999], [2445.198999999999, 2456.388999999999], [2456.388999999999, 2469.888999999999], [2469.888999999999, 2484.2289999999994], [2484.2289999999994, 2494.9589999999994], [2494.9589999999994, 2505.158999999999], [2505.158999999999, 2517.258999999999], [2517.258999999999, 2528.008999999999], [2528.008999999999, 2539.608999999999], [2539.608999999999, 2551.8689999999992], [2551.8689999999992, 2563.778999999999], [2563.778999999999, 2574.178999999999], [2574.178999999999, 2585.198999999999], [2585.198999999999, 2596.568999999999], [2596.568999999999, 2609.037999999999], [2609.037999999999, 2621.898999999999], [2621.898999999999, 2633.148999999999], [2633.148999999999, 2643.208999999999], [2643.208999999999, 2655.748999999999], [2655.748999999999, 2667.438999999999], [2667.438999999999, 2681.098999999999], [2681.098999999999, 2693.0489999999986], [2693.0489999999986, 2703.9289999999987], [2703.9289999999987, 2716.1389999999988], [2716.1389999999988, 2727.230999999999], [2727.230999999999, 2738.3309999999988], [2738.3309999999988, 2748.8909999999987], [2748.8909999999987, 2761.3309999999988], [2761.3309999999988, 2772.1609999999987], [2772.1609999999987, 2785.2809999999986], [2785.2809999999986, 2795.3609999999985], [2795.3609999999985, 2806.5109999999986], [2806.5109999999986, 2816.6809999999987], [2816.6809999999987, 2827.6009999999987], [2827.6009999999987, 2837.900999999999], [2837.900999999999, 2848.410999999999], [2848.410999999999, 2860.130999999999], [2860.130999999999, 2872.670999999999], [2872.670999999999, 2884.280999999999], [2884.280999999999, 2897.200999999999], [2897.200999999999, 2908.050999999999], [2908.050999999999, 2920.250999999999], [2920.250999999999, 2931.2409999999986], [2931.2409999999986, 2945.1609999999987], [2945.1609999999987, 2957.3609999999985], [2957.3609999999985, 2967.9909999999986], [2967.9909999999986, 2978.6909999999984], [2978.6909999999984, 2989.9009999999985], [2989.9009999999985, 3004.8409999999985], [3004.8409999999985, 3016.0009999999984], [3016.0009999999984, 3029.1609999999982], [3029.1609999999982, 3041.3709999999983], [3041.3709999999983, 3053.260999999998], [3053.260999999998, 3066.190999999998], [3066.190999999998, 3076.940999999998], [3076.940999999998, 3088.130999999998], [3088.130999999998, 3098.850999999998], [3098.850999999998, 3110.620999999998], [3110.620999999998, 3124.160999999998], [3124.160999999998, 3134.270999999998], [3134.270999999998, 3148.130999999998], [3148.130999999998, 3161.230999999998], [3161.230999999998, 3175.550999999998], [3175.550999999998, 3185.950999999998], [3185.950999999998, 3197.1209999999983], [3197.1209999999983, 3208.680999999998], [3208.680999999998, 3219.6909999999984], [3219.6909999999984, 3231.430999999998], [3231.430999999998, 3244.2509999999984], [3244.2509999999984, 3255.1109999999985], [3255.1109999999985, 3267.0959999999986], [3267.0959999999986, 3279.1009999999987], [3279.1009999999987, 3291.7609999999986], [3291.7609999999986, 3304.1119999999987], [3304.1119999999987, 3315.500999999999], [3315.500999999999, 3325.730999999999], [3325.730999999999, 3339.820999999999], [3339.820999999999, 3352.660999999999], [3352.660999999999, 3364.330999999999], [3364.330999999999, 3376.760999999999], [3376.760999999999, 3388.7709999999993], [3388.7709999999993, 3399.2909999999993], [3399.2909999999993, 3411.1309999999994], [3411.1309999999994, 3421.3809999999994], [3421.3809999999994, 3434.5409999999993], [3434.5409999999993, 3445.5409999999993], [3445.5409999999993, 3456.9409999999993], [3456.9409999999993, 3469.140999999999], [3469.140999999999, 3482.1709999999994], [3482.1709999999994, 3494.8809999999994], [3494.8809999999994, 3507.1109999999994], [3507.1109999999994, 3518.2709999999993], [3518.2709999999993, 3529.6509999999994], [3529.6509999999994, 3543.5109999999995], [3543.5109999999995, 3554.2109999999993], [3554.2109999999993, 3564.3009999999995], [3564.3009999999995, 3574.7709999999993], [3574.7709999999993, 3586.1909999999993], [3586.1909999999993, 3597.2209999999995], [3597.2209999999995, 3607.3809999999994], [3607.3809999999994, 3619.1809999999996], [3619.1809999999996, 3632.3209999999995], [3632.3209999999995, 3645.5409999999993], [3645.5409999999993, 3657.6709999999994], [3657.6709999999994, 3669.890999999999], [3669.890999999999, 3681.1509999999994], [3681.1509999999994, 3692.7809999999995], [3692.7809999999995, 3705.5209999999993], [3705.5209999999993, 3716.490999999999], [3716.490999999999, 3720.2329999999993]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [91, 398, 581, 1061, 1262, 1449, 2089, 2722, 2876, 3723]}
{"example_id": "mit002@@ocw-18_02-f07-lec33_300k", "text": ["visit MIT OpenCourseWare at ocw.mit.edu.  Let's try to discuss a bit how things relate to physics. ", "There are two main things I want to discuss.  One of them is what curl says about force fields and, ", "in particular,a nice consequence of that concerning  gravitational attraction. More about curl. ", "If we have a velocity field, then we have seen that the curl  measures the rotation affects. More precisely curl v measures ", "twice the angular velocity, or maybe I should say the  angular velocity vector because it also includes the axis of ", "rotation. I should say maybe for the  rotation part of a motion. For example, ", "just to remind you, I mean we have seen this guy a ", "couple of times, but if I give you a uniform  rotation motion about the z, axes. ", "That is a vector field in which the trajectories are going to be  circles centered in the z-axis and our vector field is just  going to be tangent to each of these circles. ", "And, if you look at it from above, then you will have this  rotation vector field that we have seen many times. ", "Typically, the velocity vector for this would be minus yi plus  yj times maybe a number that represents how fast we are ", "spinning, the angular velocity in  gradients per second. And then.  if you compute the curl of this, you will end up with two ", "omega times k. Now, the other kinds of vector  fields we have seen physically are force fields.  The question is what does the curl of a force field mean? ", "What can we say about that? The interpretation is a little  bit less obvious, but let's try to get some idea ", "of what it might be. I want to remind you that if we  have a solid in a force field, we can measure the torque ", "exerted by the force on the solid.  Maybe first I should remind you about what torque is in space.  Let's say that I have a piece of solid with a mass, ", "delta m for example, and I have a force that is  being exerted to it. Let's say that maybe my force ", "might be F times delta m. If you think,  for example, a gravitational field.  The gravitational force is actually the gravitational field ", "times the mass. I mean you can forget delta m  if you don't like it. And let's say that the position  vector, which should be aiming for the origin, ", "R is here. And now let's say that maybe  this guy is at the end of some arm or some metal thing and I  want to hold it in place. The force is going to exert a ", "torque relative to the origin that will try to measure how  much I am trying to swing this guy around the origin.  And, consequently, how much effort I have to exert ", "if I want to actually maintain its place by just holding it at  the end of the stick here. So the torque is now a vector, ", "which is just the cross-product of a position vector with a ", "force. What the torque measures again  is the rotation effects of the force.  And if you remember the principle that the derivative of ", "velocity, which is acceleration,  is force divided by mass then the derivative of angular ", "velocity should be angular acceleration which is related to  the torque per unit mass. To just remind you, ", "if I look at translation motions,  say I am just looking at the point mass so there are no  rotation effects then force divided by mass is acceleration, ", "which is the derivative of velocity.  And so what I am claiming is that for rotation effects we ", "have a similar law, which maybe you have seen in  8.01. Well, it is one of the  important things of solid mechanics, which is the torque ", "of a force divided by the moment of inertia.  I am cheating a little bit here. If you can see how I am  cheating then I am sure you know how to state it correctly. ", "And if you don't see how I am cheating then let's just ignore  the details. [LAUGHTER]  Is angular acceleration. And angular acceleration is the ", "derivative of angular velocity. If I think of curl as an ", "operation, which from a velocity field  gives the angular velocity of its rotation effects, ", "then you see that the curl of an acceleration field gives the  angular acceleration in the rotation part of the  acceleration effects. And, therefore, ", "the curl of a force field measures the torque per unit  moment of inertia. It measures how much torque its ", "force field exerts on a small test solid placed in it.  If you have a small solid somewhere, the curl will just  measure how much your solid starts spinning if you leave it ", "in this force field. In particular,  a force field with no curl is a force field that does not  generate any rotation motion. That means if you put an object ", "in there that is completely immobile and you leave it in  that force field, well, of course it might  accelerate in some direction but it won't start spinning.  While, if you put it in there spinning already in some ", "direction, it should continue to spin in the same way.  Of course, maybe there will be friction and things like that ", "which will slow it down but this force field is not responsible  for it. The cool consequence of this is ", "if a force field F derives from a potential -- That is what we  have seen about conservative forces. ", "Our main concern so far has been to say if we have a  conservative force field it means that the work of a force  is the change in the energy. And, in particular,  we cannot get energy for free out of it. ", "And the change in the potential energy is going to be the change  in kinetic energy. You have conservation of energy  principles. There is another thing that we ", "know now because if a force derives from a potential then  that means its curl is zero. That is the criterion we have ", "seen for a vector field to derive from a potential.  And if the curl is zero then it means that this force does not ", "generate any rotation effects. For example,  if you try to understand where the earth comes from, ", "well, the earth is spinning on itself as it goes around the  sun. And you might wonder where that  comes from. Is that causes by gravitational ", "attraction? And the answer is no.  Gravitational attraction in itself cannot cause the earth to  start spinning faster or slower, at least if you assume the ", "earth to be a solid, which actually is false.  I mean basically the reason why the earth is spinning is because ", "it was formed spinning. It didn't start spinning  because of gravitational effects.  And that is a rather deep purely mathematical consequence ", "of understanding gravitation in this way.  It is quite spectacular that just by abstract thinking we got  there. What is the truth?  Well, the truth is the earth, the moon and everything is ", "slightly deformable. And so there is deformation,  friction effects, tidal effects and so on.  And these actually cause rotations to get slightly  synchronized with each other. For example, ", "if you want to explain why the moon is always showing the same  face to the earth, why the rotation of a moon on  itself is synchronized with its revolution around the earth, ", "which is actually explained by friction effects over time and  the gravitational attraction of the earth and the moon.  There is something there, but if you took perfectly ", "rigid, solid bodies then gravitation would never cause ", "any rotation effects. Of course that tells us that we  do not know how to answer the question of why is the earth ", "spinning. That will be left for another  physics class. I don't have a good answer to ", "that. That was kind of 8.01-ish.  Let me now move forward to 8.02 stuff.  I want to tell you things about electric and magnetic fields. ", "And, in fact, something that is known as  Maxwell's equations. Just a quick poll. ", "How many of you have been taking 8.02 or something like  that? OK. That is not very many.  For most of you this is a preview.  If you have been taking 8.02, have you seen Maxwell's ", "equations, at least part of them?  Yeah. OK.  Then I am sure, in that case,  you know better than me what I am going to talk about because I  am not a physicist. But just in case. ", "Maxwell's equations govern how electric and magnetic fields  behave, how they are caused by electric charges and their  motions. And, in particular, ", "they explain a lot of things such as how electric devices  work, but also how electromagnetic waves propagate.  In particular, that explains light and all ", "sorts of waves. It is thanks to them,  you know, your cell phone, laptops and things like that  work. Anyway. ", "Hopefully most of you know that the electric field is a vector  field that basically tells you what kind of force will be  exerted on a charged particle that you put in it. ", "If you have a particle carrying an electric charge then this  vector field will tell you, basically there will be an  electric force which is the charge times E that will be ", "exerted on that particle. And that is what is  responsible, for example, for the flow of electrons when  you have a voltage difference. Because classically this guy is ", "a gradient of a potential. And that potential is just  electric voltage. The magnetic field is a little  bit harder to think about if you have never seen it in physics, ", "but it is what is causing, for example,  magnets to work. Well, basically it is a force  that is also expressed in terms of a vector field usually called ", "B. Some people call it H but I am  going to use B. And that force tends to cause  it, if you have a moving charged particle, to deflect its ", "trajectory and start rotating in a magnetic field.  What it does is not quite as easy as what an electric field ", "does. Just to give you formulas,  the force caused by the electric field is the charge  times the electric field. And the force caused by the ", "magnetic field, I am never sure about the sign.  Is that the correct sign? Good.  Now, the question is we need to understand how these fields ", "themselves are caused by the charged particles that are  placed in them. There are various laws in there  that explain what is going on. Let me focus today on the ", "electric field. Maxwell's equations actually  tell you about div and curl of these fields. ", "Let's look at div and curl of the electric field.  The first equation is called the Gauss-Coulomb law. ", "And it says that the divergence of the electric field is equal ", "to, so this is a just a physical  constant, and what it is equal to depends  on what units you are using. And this guy rho, ", "well, it is not the same rho as in spherical coordinates because  physicists somehow pretended they used that letter first.  It is the electric charge density. ", "It is the amount of electric charge per unit volume.  What this tells you is that divergence of E is caused by the ", "presence of electric charge. In particular,  if you have an empty region of space or a region where nothing  has electrical charge then E has divergence equal to zero. ", "Now, that looks like a very abstract strange equation.  I mean it is a partial differential equation satisfied  by the electric field E. And that is not very intuitive ", "in any way. What is actually more intuitive  is what we get if we apply the divergence theorem to this ", "equation. If I think now about any closed  surface, and I want to think about the ", "flux of the electric field out of that surface,  we haven't really thought about what the flux of a force field  does. And I don't want to get into ", "that because there is no very easy answer in general,  but I am going to explain soon how this can be useful  sometimes. Let's say that we want to find ", "the flux of the electric field out of a closed surface.  Then, by the divergence theorem,  that is equal to the triple integral of a region inside of ", "div E dV, which is by the equation one  over epsilon zero, that is this constant,  times the triple integral of rho dV. ", "But now, if I integrate the charge density over the entire  region, then what I will get is  actually the total amount of electric charge inside the ", "region. That is the electric charge in ", "D. This one tells us,  in a more concrete way, how electric charges placed in  here influence the electric field around them. ", "In particular, one application of that is if  you want to study capacitors. Capacitors are these things  that store energy by basically you have two plates,  one that contains positive charge and a negative charge. ", "Then you have a voltage between these plates.  And, basically, that can provide electrical  energy to power maybe an electric circuit. ", "That is not really a battery because it doesn't store energy  in large enough amounts. But, for example,  that is why when you switch your favorite gadget off it  doesn't actually go off immediately but somehow you see ", "things dimming progressively. There is a capacitor in there.  If you want to understand how the voltage and the charge  relate to each other, the voltage is obtained by  integrating the electric field from one plate to the other ", "plate. And the charges in the plates  are what causes the electric field between the plates.  That is how you can get the relation between voltage and ", "charge in these guys. That is an example of  application of that. Now, of course,  if you haven't seen any of this then maybe it is a little bit ", "esoteric, but that will tell you part of what you will see in  8.02. Questions? ", "I see some confused faces. Well, don't worry.  It will make sense some day. [LAUGHTER] ", "The next one I want to tell you about is Faraday's law.  In case you are confused, Maxwell's equations, ", "there are four equations in the set of Maxwell's equations and  most of them don't carry Maxwell's name.  That is a quirky feature. That one tells you about the ", "curl of the electric field. Now, depending on your  knowledge, you might start telling me that  the curl of the electric field has to be zero because it is the ", "gradient of the electric potential.  I told you this stuff about voltage.  Well, that doesn't account for the fact that sometimes you can  create voltage out of nowhere using magnetic fields. ", "And, in fact, you have a failure of  conservativity of the electric force if you have a magnetic  field. What this one says is the curl ", "of E is not zero but rather it is the derivative of the  magnetic field with respect to time.  More precisely it tells you that what you might have learned ", "about electric fields deriving from electric potential becomes  false if you have a variable magnetic field.  And just to tell you again that is a strange partial ", "differential equation relating these two vector fields.  To make sense of it one should use Stokes' theorem. ", "If we apply Stokes' theorem to compute the work done by the  electric field around a closed curve,  that means you have a wire in there and you want to find the ", "voltage along the wire. Now there is a strange thing  because classically you would say, well, if I just have a wire  with nothing in it there is no voltage on it.  Well, a small change in plans. If you actually have a varying ", "magnetic field that passes through that wire then that will  actually generate voltage in it. That is how a transformer works. ", "When you plug your laptop into the wall circuit,  you don't actually feed it directly 110 volts,  120 volts or whatever. There is a transformer in there.  What the transformer does it takes some input voltage and ", "passes that through basically a loop of wire.  Not much seems to be happening. But now you have another loops  of wire that is intertwined with it. ", "Somehow the magnetic field generated by it,  and it has to be a donating current.  The donating current varies over time in the first wire. ", "That generates a magnetic field that varies over time,  so that causes 2B by 2t and that causes curl of the electric  field. And the curl of the electric  field will generate voltage between these two guys. ", "And that is how a transformer works.  It uses Stokes' theorem. More precisely,  how do we find the voltage between these two points? ", "Well, let's close the loop and let's try to figure out the  voltage inside this loop. To find a voltage along a  closed curve places in a varying magnetic field, ", "we have to do the line integral along a closed curve of the  electric field. And you should think of this as  the voltage generated in this circuit. ", "That will be the flux for this surface bounded by the curve of ", "curl E dot dS. That is what Stokes' theorem  says. And now if you combine that  with Faraday's law you end up with the flux trough S of minus ", "dB over dt. And, of course, you could take,  if your loop doesn't move over time,  I mean there is a different story if you start somehow ", "taking your wire and somehow moving it inside the field.  But if you don't do that, if it is the field that is  moving then you just can take the dB by dt outside.  But let's not bother. Again, what this equation tells ", "you is that if the magnetic field changes over time then it  creates, just out of nowhere, and electric field.  And that electric field can be used to power up things. ", "I don't really claim that I have given you enough details to  understand how they work, but basically these equations  are the heart of understanding how things like capacitors and ", "transformers work. And they also explain a lot of  other things, but I will leave that to your  physics teachers. Just for completeness,  I will just give you the last two equations in that. ", "I am not even going to try to explain them too much.  One of them says that the divergence of the magnetic field  is zero, which somehow is fortunate ", "because otherwise you would run into trouble trying to  understand surface independence when you apply Stokes' theorem  in here. And the last one tells you how ", "the curl of the magnetic field is caused by motion of charged  particles. In fact, let's say that the ", "curl of B is given by this kind of formula, well,  J is what is called the vector of current density. ", "It measures the flow of electrically charged particles.  You get this guy when you start taking charged particles, ", "like electrons maybe, and moving them around.  And, of course, that is actually part of how  transformers work because I have told you running the AC through ", "the first loop generates a magnetic field.  Well, how does it do that? It is thanks to this equation.  If you have a current passing in the loop that causes a  magnetic field and, in turn, for the other equation ", "that causes an electric field, which in turn causes a current.  It is all somehow intertwined in a very intricate way and is ", "really remarkable how well that works in practice.  I think that is basically all I wanted to say about 8.02.  I don't want to put your physics teachers out of a job. ", "[LAUGHTER] If you haven't seen any of this  before, I understand that this is  probably not detailed enough to be really understandable,  but hopefully it will make you a bit curious about that and  prompt you to take that class someday and maybe even remember ", "how it relates to 18.02. "], "vid_duration": [10.0, 10.0, 14.0, 20.0, 15.0, 17.0, 10.0, 16.0, 12.0, 16.0, 11.0, 13.0, 11.0, 17.0, 13.0, 12.0, 10.0, 11.0, 13.0, 13.0, 11.0, 15.0, 15.0, 12.0, 11.0, 14.0, 17.0, 14.0, 14.0, 11.0, 19.0, 11.0, 11.0, 12.0, 11.0, 12.0, 10.0, 12.0, 12.0, 15.0, 15.0, 12.0, 11.0, 10.0, 21.0, 13.0, 10.0, 10.0, 10.0, 11.0, 13.0, 11.0, 11.0, 16.0, 10.0, 11.0, 11.0, 23.0, 12.0, 12.0, 12.0, 11.0, 13.0, 12.0, 12.0, 13.0, 10.0, 14.0, 14.0, 11.0, 12.0, 11.0, 13.0, 15.0, 11.0, 15.0, 10.0, 10.0, 11.0, 12.0, 14.0, 15.0, 16.0, 11.0, 11.0, 11.0, 15.0, 13.0, 11.0, 11.0, 10.0, 11.0, 14.0, 11.0, 12.0, 11.0, 12.0, 10.0, 15.0, 11.0, 15.0, 10.0, 12.0, 10.0, 14.0, 15.0, 10.0, 13.0, 14.0, 13.0, 14.0, 11.0, 10.0, 12.0, 10.0, 14.0, 12.0, 11.0, 16.0, 10.0, 17.0, 21.0, 11.0, 13.0, 12.0, 13.0, 11.0, 14.0, 11.0, 10.0, 10.0, 14.0, 15.0, 13.0, 2.03], "stet": [[0, 10.0], [10.0, 20.0], [20.0, 34.0], [34.0, 54.0], [54.0, 69.0], [69.0, 86.0], [86.0, 96.0], [96.0, 112.0], [112.0, 124.0], [124.0, 140.0], [140.0, 151.0], [151.0, 164.0], [164.0, 175.0], [175.0, 192.0], [192.0, 205.0], [205.0, 217.0], [217.0, 227.0], [227.0, 238.0], [238.0, 251.0], [251.0, 264.0], [264.0, 275.0], [275.0, 290.0], [290.0, 305.0], [305.0, 317.0], [317.0, 328.0], [328.0, 342.0], [342.0, 359.0], [359.0, 373.0], [373.0, 387.0], [387.0, 398.0], [398.0, 417.0], [417.0, 428.0], [428.0, 439.0], [439.0, 451.0], [451.0, 462.0], [462.0, 474.0], [474.0, 484.0], [484.0, 496.0], [496.0, 508.0], [508.0, 523.0], [523.0, 538.0], [538.0, 550.0], [550.0, 561.0], [561.0, 571.0], [571.0, 592.0], [592.0, 605.0], [605.0, 615.0], [615.0, 625.0], [625.0, 635.0], [635.0, 646.0], [646.0, 659.0], [659.0, 670.0], [670.0, 681.0], [681.0, 697.0], [697.0, 707.0], [707.0, 718.0], [718.0, 729.0], [729.0, 752.0], [752.0, 764.0], [764.0, 776.0], [776.0, 788.0], [788.0, 799.0], [799.0, 812.0], [812.0, 824.0], [824.0, 836.0], [836.0, 849.0], [849.0, 859.0], [859.0, 873.0], [873.0, 887.0], [887.0, 898.0], [898.0, 910.0], [910.0, 921.0], [921.0, 934.0], [934.0, 949.0], [949.0, 960.0], [960.0, 975.0], [975.0, 985.0], [985.0, 995.0], [995.0, 1006.0], [1006.0, 1018.0], [1018.0, 1032.0], [1032.0, 1047.0], [1047.0, 1063.0], [1063.0, 1074.0], [1074.0, 1085.0], [1085.0, 1096.0], [1096.0, 1111.0], [1111.0, 1124.0], [1124.0, 1135.0], [1135.0, 1146.0], [1146.0, 1156.0], [1156.0, 1167.0], [1167.0, 1181.0], [1181.0, 1192.0], [1192.0, 1204.0], [1204.0, 1215.0], [1215.0, 1227.0], [1227.0, 1237.0], [1237.0, 1252.0], [1252.0, 1263.0], [1263.0, 1278.0], [1278.0, 1288.0], [1288.0, 1300.0], [1300.0, 1310.0], [1310.0, 1324.0], [1324.0, 1339.0], [1339.0, 1349.0], [1349.0, 1362.0], [1362.0, 1376.0], [1376.0, 1389.0], [1389.0, 1403.0], [1403.0, 1414.0], [1414.0, 1424.0], [1424.0, 1436.0], [1436.0, 1446.0], [1446.0, 1460.0], [1460.0, 1472.0], [1472.0, 1483.0], [1483.0, 1499.0], [1499.0, 1509.0], [1509.0, 1526.0], [1526.0, 1547.0], [1547.0, 1558.0], [1558.0, 1571.0], [1571.0, 1583.0], [1583.0, 1596.0], [1596.0, 1607.0], [1607.0, 1621.0], [1621.0, 1632.0], [1632.0, 1642.0], [1642.0, 1652.0], [1652.0, 1666.0], [1666.0, 1681.0], [1681.0, 1694.0], [1694.0, 1696.03]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [738, 1696]}
{"example_id": "mit032@@MIT8_01F16_L03_360p", "text": [" Let's consider a two dimensional motion.  Suppose we have something like projectile motion.  And we have an object moving. ", "Let's now describe how we can describe this motion  with vectors.  So the first thing we always want  to do, and let's remind ourselves of the steps,  is we want to choose a coordinate system. ", "Now what does a coordinate system consist of?  It consists of an origin.  It consists of two axes.  In this case, we'll identify the positive direction  for each axis as plus x and plus y. ", "And at every single point in space--  so if we had any arbitrary point P here-- let's call this P1.  We have a choice of unit vectors, i-hat 1 and j-hat 1. ", "Now, what makes Cartesian coordinates  unique is that no matter what point we're at,  the unit vectors are all the same.  So we could erase all these indices ", "for that particular point and just  have an abstract set of unit vectors, i-hat and j-hat.  Now normally what we'll do is we'll just put those off  to the side. ", "So in our Cartesian coordinates, we now  want to define the position vector.  And the position vector is a vector  from the origin to where the object is. ", "So we'll write that position vector.  We'll denote it by r of t.  Because as this object moves along its trajectory  that position vector is changing.  And we'll write down r of t in terms ", "of two coordinate functions, x of t and y of t.  And so our vector-- position vector of the object r of t ", "is equal to x of t, i-hat plus y of t, j-hat.  And one of our main goals is to figure out ", "what these position functions are for the motion of objects.  So this is how we describe an object  in a Cartesian coordinate system,  undergoing two dimensional motion. ", "What we want to analyze next is what  is the velocity of that object.   Recall, when we were examining the motion an object, ", "in two dimensions, we introduced Cartesian coordinates  and a position vector.  Now let's suppose the object has moved  to a new point, along the orbit. ", "Well, we'll write another vector r of t.  And let's say this took a time delta t to the new point. ", "And what we want to define is the displacement  of that object.  So that's a vector delta r.  And recall that a vector of time of t plus delta t ", "is equal to the old vector r of t plus this displacement vector  delta r.  Now what we want to consider is a limit as delta t goes to 0. ", "And let's just look graphically at what that means.  As we move this delta, delta t-- as delta t  gets smaller and smaller and our object is getting closer ", "and closer to its position at time t,  and the position vector r of t plus delta t  is getting closer and closer to r of t delta t,  the key fact is that if we do a tangent to the orbit, ", "then the limit of delta r is approaching tangent  to the curve.  So in the limit, delta r, the direction ", "is tangent to the orbit.  So that's our first key property of delta r. ", "Now the second thing we want to express  is, if we write delta r, as a displacement  in the i-hat direction and a displacement  in the j-hat direction, now again, ", "maybe we can just clean this up a little bit,  and see what we mean by that.  So here's our delta r. ", "And we have a little delta x in this direction,  delta y in that direction.  Remember delta x or delta y can be positive or negative.  That's all right.  Now if we want to define our velocity as the limit, ", "as delta t goes to 0 of delta r over delta t,  then what we see is we have two pieces, the limit as delta t  goes to 0, of delta x over delta t i-hat, plus the limit ", "as delta t goes to 0 of delta y delta t j-hat.  And the definition of these limits, ", "we'll write that as the derivative dr, dt.  So the velocity is dr, dt.  And that's equal to dx, dt, how that coordinate function is ", "changing in time, i-hat plus dy, dt j-hat.  Now as far as notation goes, we write ", "this philosophy as an x component of the velocity  plus a y component of the velocity, where  the x component, the x, is dx, dt. ", "And the y component is dy, dt.  Now recall that the direction was tangent to the curve,  but the magnitude of the velocity,  what we call the speed, is just the sum ", "of the squares of the components, the square root.  And so now we've describe what we  refer to as the instantaneous velocity. ", " So far we've looked that a trajectory in two dimensions. ", "Let's again consider some type of motion  where we choose a positive y-axis, a positive x-axis,  an origin, e at vectors, i-hat and j-hat. ", "And I'll have some type of trajectory,  where our object is moving like that.  We know that at this particular time,  the velocity is tangent to this trajectory, at that point. ", "And now, what we'd like to do, is  try to describe-- we've described  it's two components ex and vy as a vector. ", "So if you did vector decomposition,  you would write a vector like this and a vector like that.  This is the x component. ", "That's the y component.  And now if I define this angle theta,  we know that a vector has a direction and a magnitude.  We've seen what we call the magnitude the speed. ", "So that's just the sum of these components squared,  square root.  Speed is always positive.  So we always take the positive square root.  And now what about the direction of this vector in the xy plane? ", "Well, we can see from our geometry  that the tangent theta is given by the y  component over the x component. ", "Or one could say that the angle theta, at this given time,  is the inverse function of vy over vx.  And so now we've described not only the direction of velocity, ", "but the angle that it's making with the horizontal axis.  And so we have now completely described the velocity,  instantaneous velocity, vector at time t ", "in terms of its two component functions, its speed  ", "Let's now consider two dimensional motion,  and let's try to analyze how to describe  the change in velocity.  So again, let's choose a coordinate system. ", "We have an origin plus y plus x.  And let's draw the trajectory of our object.  And now let's draw the object at two different times. ", "So for instance, if I call this the location at time t1,  and a little bit later here, this  is the location of the object at time t2. ", "We'll call our unit vectors i hat and j hat.   We know that the direction of the velocity ", "is tangent to this curve.  So if we draw v at time t1-- and over here,  notice the direction has changed v at time t2. ", "And what we'd like to do now is describe, just as before,  that our acceleration a of t is the derivative of the velocity ", "as a function of time.  What that means is the limit as delta t goes  to 0 of delta v over delta t.  Now, it's much harder to visualize the delta v ", "in this drawing.  And partly, the reason for that is these velocity vectors  are located at two different points.  And right now, the backs of these vectors ", "have different places in space.  But remember that delta v is just v, in this case,  at time t2 minus v at time t1. ", "And our principle for subtracting two vectors  at different locations in space is  to draw the vectors where we put the tails at the same location.  So here's a tail at this vector. ", "We're just going to translate that vector in space.  That is still v at time t1.  These vectors are equal.  They have the same length, and they have the same direction. ", "And so delta v is just the vector  that connects here to there.  That's what we mean by delta v.  And so you can see in this particular case ", "that it's not obvious from looking at the orbit what  the delta v is.  So what we need to do is just trust our calculus. ", "And so when we write the velocity as dx dt i hat plus dy  dy j hat, and we're now treating each direction independently. ", "We call this vx i hat plus vy j hat.  So that's our velocity vector.  Then our acceleration is just the derivative of the velocity. ", "We take each direction separately,  so we have dv x dt i hat plus dv y dt j hat. ", "Now, again, notice that velocity v of x  is already the first derivative of the position ", "of the exponent function.  So what we really have here is the second derivative  of the position function in the i hat ", "direction and the second derivative of the component  function in the y direction.  And that is what we call the instantaneous acceleration.  Now, again, this is sometimes awkward to draw, ", "but you always must remember that this x component  of the acceleration by definition  is the second derivative of the component function ", "or the first derivative of the component  function for the velocity.  And likewise, the y component of the acceleration ay ", "is the second derivative of the component  function for position.  And that's also equal, by definition,  to the first derivative of the component of the velocity ", "vector.  And that's how we describe the acceleration.  As before, we can talk about the magnitude of a vector.  And the magnitude of a we'll just write as a. ", "It's the components squared, added together, taken  square root.  And that's our magnitude. ", "And so now we've described all of our kinematic quantities  in two dimensions-- the position,  the velocity as the derivative of the position,  and the acceleration as the derivative of the velocity ", "where each direction is treated independently.   One of the most common motions we see in our everyday lives ", "is the path of an object moving thrown  and moving through space.  Now, this type of motion has a very famous name  called projectile motion.  And when we look at it, let's introduce a coordinate system. ", "i hat and j hat.  Here's our y plus y-axis and our plus x-axis.  Then, in order to understand the kinematics of this motion,  we'd like to apply Newton's second law. ", "So separately we'll draw our object.  It has gravitational force acting downward.  Remember our unit vectors in the j hat direction.  And so when we write our equations of motion, ", "f equals ma.  We have two different directions.  In the j hat direction, we have the gravitational force  downward minus mg.  And remember here that g is our positive quantity, 9.8 meters ", "per second, and we have m a y.  Newton's second law equates these two different things.  And that's-- we'll write it like that. ", "So those two quantities are equal.  And so our conclusion is that the acceleration  is equal to minus g in the y direction. ", "Now, likewise, keep in mind that we  have our horizontal direction as well.  And notice that we're now assuming that there's  no horizontal forces.  In the real world, there can be all types of air resistances. ", "But here, for the simplicity of this model,  we have no horizontal forces.  So we have 0 equals m a x.  And so we have our separate equation, a x equals 0. ", "Now, both of these equations are equations that we've already  been working with in kinematics.  Here we have a constant acceleration,  and here we have zero acceleration.  So using the results that we had earlier from integration, ", "we can write down the equations of motion  in the y and the x directions.  First, we'll write the velocity.  Vy as a function of time is equal to some initial value. ", "And because the acceleration is negative, minus gt.  You can test your integration technique to see that.  And the position as a function of time, ", "remember, is just some constant value.  This is our constant y nought.  And we have plus vy nought t minus 1/2 gt squared again ", "doing integration.  Now, the horizontal equation of motion,  the x(t), because there is no acceleration  in the horizontal direction, this ", "is a constant value given by the initial value of the component  of the velocity in the x direction  and the position x(t) is then equal to some initial position ", "plus Vx nought t.  And so those are our functions of time  for the components of the velocity  and the components of position. ", "Now, for our particular example, it's much easier.  Here we have X nought equal to 0.  Notice that our object is starting at the origin. ", "And so that tells us that x as a function of time  is just Vx nought t.  I'm dropping the parentheses t.  Remember, that's not a product. ", "That's just a function of time.  And given this fact, that tells us  that t is x divided by Vx nought,  and now I can take this value of t ", "and put it into our vertical equation  and I get V y is some initial value plus V y nought x over Vx ", "nought, substituting for t, minus 1/2 gx  squared over V x nought squared. ", "When we described projectile motion,  we had an equation describing y as a function of t,  an equation describing x as a function  of t-- the horizontal motion and the vertical motion-- ", "and here we have a separate equation,  which is describing the y as a function of x.  Notice there is no time involved in this equation.  Now, let's try to look at graphically ", "what we're seeing here.  So, for instance, when we look at a plot of the motion of y  versus x, we can see the vertical component going ", "up and down and we can see the horizontal component moving  to the right while the object is following this trajectory.  And this is a parabolic trajectory ", "of y as a function of x.  Now, if we wanted to actually plot out y as a function of t,  then here we can look at the simulation ", "where we're just looking at the y component  and you can see that that motion too is a parabola.  However, what's crucial to look at is  that it's y as a function of t and not y as a function of x. ", "Finally, we can look at the horizontal motion  and again recall that when we looked at the trajectory as y  as a function of x, you can see the horizontal motion  component.  Let's plot that separately, x as a function of t. ", "And when we make that plot, you can  see that this is just a linear equation in time  where there is some initial condition,  x nought, and so that's the plot of x as a function of t. ", "And so we see three separate representations of this motion.  y as a function of x, y as a function of t, and x ", "as a function of t. "], "vid_duration": [10.94, 12.276, 11.404, 12.95, 10.8, 11.24, 10.7, 12.37, 11.35, 10.44, 12.25, 11.584, 11.201, 10.54, 11.73, 18.25, 14.48, 16.26, 13.54, 10.35, 11.95, 10.4, 14.96, 15.21, 11.52, 10.839, 10.211, 13.88, 12.81, 10.041, 11.058, 11.691, 16.53, 11.63, 10.51, 13.07, 13.61, 11.25, 14.28, 10.9, 10.079, 10.11, 11.18, 12.415, 10.385, 14.496, 10.654, 14.5, 11.85, 12.76, 11.73, 12.46, 11.54, 10.12, 16.92, 13.49, 11.09, 13.82, 11.78, 12.24, 12.58, 11.41, 13.71, 12.595, 11.165, 12.06, 11.204, 14.33, 11.78, 14.51, 14.82, 11.27, 12.11, 12.54, 12.189, 13.331, 13.43, 10.91, 13.85, 11.829, 13.091, 10.42, 11.5, 10.439, 11.46, 11.151, 10.22, 11.98, 11.55, 10.56, 11.99, 10.65, 16.57, 13.85, 12.91, 12.859, 1.193], "stet": [[0, 10.94], [10.94, 23.216], [23.216, 34.620000000000005], [34.620000000000005, 47.57000000000001], [47.57000000000001, 58.370000000000005], [58.370000000000005, 69.61], [69.61, 80.31], [80.31, 92.68], [92.68, 104.03], [104.03, 114.47], [114.47, 126.72], [126.72, 138.304], [138.304, 149.505], [149.505, 160.045], [160.045, 171.77499999999998], [171.77499999999998, 190.02499999999998], [190.02499999999998, 204.50499999999997], [204.50499999999997, 220.76499999999996], [220.76499999999996, 234.30499999999995], [234.30499999999995, 244.65499999999994], [244.65499999999994, 256.60499999999996], [256.60499999999996, 267.00499999999994], [267.00499999999994, 281.9649999999999], [281.9649999999999, 297.1749999999999], [297.1749999999999, 308.6949999999999], [308.6949999999999, 319.5339999999999], [319.5339999999999, 329.7449999999999], [329.7449999999999, 343.6249999999999], [343.6249999999999, 356.4349999999999], [356.4349999999999, 366.4759999999999], [366.4759999999999, 377.5339999999999], [377.5339999999999, 389.22499999999985], [389.22499999999985, 405.7549999999999], [405.7549999999999, 417.3849999999999], [417.3849999999999, 427.89499999999987], [427.89499999999987, 440.96499999999986], [440.96499999999986, 454.5749999999999], [454.5749999999999, 465.8249999999999], [465.8249999999999, 480.10499999999985], [480.10499999999985, 491.0049999999998], [491.0049999999998, 501.08399999999983], [501.08399999999983, 511.19399999999985], [511.19399999999985, 522.3739999999998], [522.3739999999998, 534.7889999999998], [534.7889999999998, 545.1739999999998], [545.1739999999998, 559.6699999999997], [559.6699999999997, 570.3239999999997], [570.3239999999997, 584.8239999999997], [584.8239999999997, 596.6739999999998], [596.6739999999998, 609.4339999999997], [609.4339999999997, 621.1639999999998], [621.1639999999998, 633.6239999999998], [633.6239999999998, 645.1639999999998], [645.1639999999998, 655.2839999999998], [655.2839999999998, 672.2039999999997], [672.2039999999997, 685.6939999999997], [685.6939999999997, 696.7839999999998], [696.7839999999998, 710.6039999999998], [710.6039999999998, 722.3839999999998], [722.3839999999998, 734.6239999999998], [734.6239999999998, 747.2039999999998], [747.2039999999998, 758.6139999999998], [758.6139999999998, 772.3239999999998], [772.3239999999998, 784.9189999999999], [784.9189999999999, 796.0839999999998], [796.0839999999998, 808.1439999999998], [808.1439999999998, 819.3479999999997], [819.3479999999997, 833.6779999999998], [833.6779999999998, 845.4579999999997], [845.4579999999997, 859.9679999999997], [859.9679999999997, 874.7879999999998], [874.7879999999998, 886.0579999999998], [886.0579999999998, 898.1679999999998], [898.1679999999998, 910.7079999999997], [910.7079999999997, 922.8969999999997], [922.8969999999997, 936.2279999999997], [936.2279999999997, 949.6579999999997], [949.6579999999997, 960.5679999999996], [960.5679999999996, 974.4179999999997], [974.4179999999997, 986.2469999999996], [986.2469999999996, 999.3379999999996], [999.3379999999996, 1009.7579999999996], [1009.7579999999996, 1021.2579999999996], [1021.2579999999996, 1031.6969999999997], [1031.6969999999997, 1043.1569999999997], [1043.1569999999997, 1054.3079999999998], [1054.3079999999998, 1064.5279999999998], [1064.5279999999998, 1076.5079999999998], [1076.5079999999998, 1088.0579999999998], [1088.0579999999998, 1098.6179999999997], [1098.6179999999997, 1110.6079999999997], [1110.6079999999997, 1121.2579999999998], [1121.2579999999998, 1137.8279999999997], [1137.8279999999997, 1151.6779999999997], [1151.6779999999997, 1164.5879999999997], [1164.5879999999997, 1177.4469999999997], [1177.4469999999997, 1178.6399999999996]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [131, 497, 811, 1178]}
{"example_id": "mit032@@MIT8_01F16_L17_360p", "text": [" Today we'd like to explore the idea  of the center of mass, or the center of gravity,  of a rigid object.  For instance, take this rod. ", "And if I try to balance it on my finger  at a certain point in that rod, I'm  balancing it via the gravitational force.  And this point is often referred to as the center  of gravity of the rod. ", "Now, if we were in empty space with no gravitational field,  then center of gravity doesn't make any sense.  But this point still coincides with what  we call the center of mass of the object. ", "And now I'd like to define center of mass.  So let's consider our rigid body.  And we'll just describe it as some object--  we'll make it idealized-- and that there's ", "going to be trying to find some point in this object.  And we'll identify that point as the center of mass.  Now, let's imagine that this rigid body is made up ", "of a bunch of little pieces.  So we have m, j.  And this j piece is located from the center  of mass, a vector rcm. ", "Now how we want to define this particular point  is that when we make the sum from j  equals 1 to n over every single point in this body, ", "then that will be 0.  And this will be the definition of the center of mass, ", "that when you add up the position vector with respect  to this point weighted by the mass,  and you add up all of those vectors, you'll get 0. ", "Now, if you don't know where the center of mass is then  this is difficult to calculate.  So let's find a way where you choose an arbitrary point,  and that's write that arbitrary point, say, over here. ", "We'll write it like this-- s.  And we'll treat that as our origin.  And I'll draw a vector, rsj.   And here, I'll draw the vector Rcm. ", " And now what we have from our vector relationship  is that the vector rsj equals the vector Rcm-- ", "and that's what I want to find-- plus the vector rcmj.   And now let's add up-- multiply each of these by the mass ", "and make a sum.  So we have mj rsj equals the sum of mj. ", "Now, the vector Rcm, this vector,  no matter where we picked a point in this object,  the vector's always the same.  And that's why I pulled it out of the sum. ", "And over here, I have the sum from j  goes from 1 to n, j 1 to n, of mj rcmj.   Now, recall, this is precisely how ", "we define the center of mass point, that this is 0.  And so we can now conclude that the center of mass--  so you pick an arbitrary point, and if you want ", "to find that vector to the center of mass, what you do  is you make the sum from j goes from 1 to n of mj rsj,  and you divide that by j goes from 1 to n, mj. ", "And this is what we call the center of mass.  So conceptually, the center of mass  is the point in the object where,  if you take a vector to any of the little mass elements, ", "and you weight it by the mass element, and you add them up,  you get 0.  If you wanted to calculate the center of mass about any point,  you choose a point, s, you draw the vector from s ", "to the object.  You sum up those vectors.  We see by our vector triangle rule  that we can now calculate that center of mass vector  by this equation. ", "And now let's just rewrite this because this is the total mass.  And what we see is that the Rcm equals j goes from 1 to n, ", "mj rsj divided by the total mass.  ", "The little prince is sitting on his little planet,  and he's watching the planets go by.  And so suddenly, he's seeing three of them.  One, two, three. ", "And he wonders, hmm, what would the center of mass  of these three planets be?  So let's calculate it.  We have one planet here that's three times ", "the mass of this guy.  And then this one has half of m1.  And I've written this up there already.  And the center of mass, when we want ", "to determine its coordinate-- it is a coordinate  that depends on this coordinate system,  and this origin here-- then we need ", "to have the total mass of the system,  because it's a mass-weighted coordinate.  And so the total mass is going to be 4.5 m1.  And if we want to calculate this position ", "function of the center of mass, Rcm,  that is the mass weight here.  And then we need the sum of all of our masses ", "times our distances.  We're going to sum here over j from 1 to n.  And what that means is we need to now write out ", "the sum for our three planets.  And we need to give this a radius here,  so the r1 would be going from here to here.  r2 goes from here to there. ", "And r3 from here to here.  You need to write them out in the i hat direction  and in the j hat direction.  ", "Let's add that here.  And then sum it all up and calculate our r.  So let's write this out.  We have m1, and we're going to have 35 and 10. ", "35 i hat plus 10 j hat plus m2.  It's going to be 5 and 20. ", "5 and 20.  And then m3, we have 40 and 30.  ", "And what we can do-- oh, and of course that  has to be divided by my system mass.  And what we can do is we can concentrate first ", "on the x component, and then on the y component.  Maybe we'll just continue here.  So we're going to have-- and we can plug it in all the m's. ", "We'll do it for the x component first.  We're going to have m1, and then we have 35 i hat plus here ", "we're going to have 1/2 m2.  That is 3m1 5 plus-- and for m3, we have 0.5 m1 40. ", "that's in the i hat direction.  And we'll have to divide that over our system mass.  And then we do the same for the y component. ", "So m1, 10 plus 3. m1, 20 plus 0.5 m1 30 j hat. ", "And again, we have to divide this over our system mass.  So this boils down to-- hang on. ", "Let me redo this again.  Let me actually look at the answer first.   What do I have here?  70 and 85, OK. ", "So this boils to m1 over the system mass.  And we have 70 in the i hat plus 85 in the j hat direction. ", "So the 70 comes from this term, the 80 comes from this.  And I put it back together, and now we need to plug in this one  here.  And so we will get in the end of that Rcm equals m over 4.5 m. ", "So the m goes away, and we have a factor of 1/4.5 here.  We'll divide this through, and we're  going to have 15.5 in the i hat direction, and 18.9 ", "in the j hat direction.   All right, so let's see where this fits on our graph here.  So 15 in the i hat is somewhere here. ", "And 19 is almost 20, so it's going  to be here, so about there.  ", "So this is my Rcm, and this here is  my center of mass of the system of these three little planets. ", "Of course, we used approximate math here for all the planets.  But if we look at the real numbers,  imagine that this would be Earth,  and it has one Earth mass. ", "And if this were Saturn, it would have something  like 318 Earth masses.  And if this is Pluto, it would have 0.0025 Earth masses. ", "You will see that Saturn really holds all the weight.  And if we were to do this calculation with these numbers  here, then our Rcm would-- and keeping this coordinate system ", "in the arrangement of the planets,  then it would go right into-- if here's the center,  it would go right next to the center right over here, ", "because Saturn just weighs so, so, so much more than Pluto   Let's try to find the center of mass of a uniform object ", "like a uniform rod.  And let's assume this rod is length L,  and we want to find the center of mass.  Now, before I begin this calculation, ", "you can probably already guess that it's  going to be exactly in the middle, and we'll verify that,  but let's first define what we mean by our center of mass  for discrete particles. ", "Recall that this was a sum over all  the particles in the system.  So we'll take a label J goes from 1 to N,  and it was the mass of that jth particle times the position ", "vector that jth particle with respect to some origin,  and we're dividing that by j equals  from 1 to N of the total mass in the system. ", "Now, how do we translate this equation  for a continuous system?  And let me just again show that we had chosen an origin.  Here was our jth particle of mass mj and rj. ", "So what we want to do is draw the analogy,  and here's how it works-- that for each discrete particle,  we're going to look at that as some mass element delta mj. ", "Our vector rj will go to a vector for this mass element.  I'll just write it delta m.  And our sum from j goes from 1 to N ", "is actually going to go to an integral over the body.  So let's see how that looks.  So first, we'll do it with the total mass, ", "m-- here we're summing over j-- from 1 to N of mj. ", "That goes to the integral over the body.  Now, the delta m, when we take limits,  because that's when an integral goes, we'll write that as dm. ", "So that becomes a limit over the body.  And likewise, our sum j goes from 1  to N of mj rj goes to an integral over the body of dm ", "vector r going to that element.  So we can say in the limit that this becomes  r going to that element.  Now, that means that our continuous expression ", "for the continuous object is an integral  over the body of dm r to that element dm divided  by an integral over the body of dm. ", " So now we want to find the center  of mass of a uniform rod.  And we have the result for a continuous body, which  is that integral over the body of dmr to that mass element dm ", "divided by an interval.  Now our goal is to figure out how  to apply this result, specifically,  to real physical objects. ", "And the key, as always, is choosing a coordinate system.  So now I'll draw the object, again.  And the first thing I'll do is choose an origin.  I can pick my origin anywhere I want. ", "I can pick it in the middle.  I can put it in the middle.  I could put it at this end.  I could put it that end.  I could put it down here, but I'll choose it over here.  Because the object is linear, this ", "is a very Cartesian system.  I'm only doing a one dimensional object.  So I choose my coordinate system plus x.  That's step one. ", "Now my origin-- now here comes the crucial thing.  In this argument, dm is the infinitesimal mass element.  And I want to pick that at an arbitrary place in the object. ", "I don't want to pick it at the origin.  I don't want to pick it at the end.  Note down here this is x equals L.  So I'll arbitrarily pick an infinitesimal element. ", "I'll shade it in dm.  That represents-- this is what I'm  going to make my summation over when I do my integral.  I'm going to add up all these dm's. ", "And the point is that the dm's are different distances  from the origin.  So the vector-- and here's the next step--  is I draw a picture of my vector rdm. ", "So now I have these terms, at least, explained in my diagram.  The next step is to turn-- is to introduce an integration  variable for both of these quantities. ", "So step one was the coordinate system.   Step two, was the identification of dm. ", "And step three and I think this is  absolutely the crucial one is to introduce the integration  variable.  Now you'll see that will come in two different cases. ", "So this is the quantity, the distance from dm  to the origin that's changing.  You can see for each of these little elements, that changes.  So what I'll write [INAUDIBLE] as a vector is x prime, ", "which will be my integration variable in the i hat  direction.  So the integration variables x prime.  That's the first place that I introduced the integration  variable.  And x prime, you can see, will vary. ", " And it varies from x prime equals 0 to x prime equals L.  And that will show up in terms of the limits of my integral. ", "Now the second place that the integration variable comes in  is dm.  I want to express in terms of x prime,  which is a measure of where this object is. ", "And that's how, if we choose this length here  to be dx prime, notice in terms of the integration variable,  then I have a relationship between and dm and dx prime. ", "dm is mass in this little element.  dx prime is the length of the element.  And if the whole object is a uniform rod with a mass capital ", "M and a length L, then its just given by M over L dx prime.  And this quantity M over L is an example ", "of a mass, linear mass density, which we  have a scale challenge about.  So I have two places, where my integration  variable has been introduced. ", "And now I can write up every piece in this interval.  So let's now indicate that we're integrating  from x prime equals 0 to x prime equals ", "L. dm is M over L dx prime, and our vector is x prime i hat. ", "And downstairs, it's just M over L dx  prime from x prime equals 0 to x prime equals L. ", "And that's how I set up the integral  for the center of mass.  Both of these integrals are now not difficult to do.  Notice, it's x prime dx prime. ", "So this integral is x squared over 2.  And I get 1/2 M over L, L squared.  And downstairs, dx prime from 0 to is just L. ", "So the downstairs integral is just M over L.  And when you have M over L's cancel,  we just are left with a-- this is-- ", "I'm sorry-- this is just M not M over L, dimension incorrect.  So we get for the position of the center  of mass, the M's cancel. ", "One of the L's cancel.  And we have an i hat in this expression  so our answer is r equals L over 2 I hat, which ", "is exactly what we expected.  We expected the center of mass to be half way down the rod.  ", "I'd now like to talk about the velocity of the center of mass  for a system of particles.  So let's take a system, which I'll just outline by this.  And in that system, we have a bunch of particles, particle 1, ", "particle 2-- let's refer to this as the j-th particle  and some point xcm.  And if I want to talk about the position of the center of mass, ", "I can choose a point s.  And if I want to define that vector Rcm,  then what I have to do is draw a vector to each object Rsj. ", "And we saw that this velocity, the position  of the center of mass with respect to this origin  s is the sum and mjrsj.  ", "And that's divided by the total mass and m total.  And j goes from 1 to n, where n is the number  of particles in the system. ", "Now if I want to find the velocity of the center of mass,  then I can just differentiate this.  And I'm dropping the point s for the moment, ", "but let's just differentiate 1 to n.  And you'll see why.  And when I differentiate the position vector  of the object, that's the velocity of the object divided ", "by j goes from 1 to n, the total mass.  Now why did I drop the position?  Because if you have any two fixed  points-- so if I chose another fixed point, say, over here p, ", "then this distance R-- we'll call it vector from s  to t Rsp-- this is a constant. ", "And if I draw position vector with respect to p-- now  the point here is that this is a constant distance,  because this is a fixed-- these are fixed points. ", "Then if you were to draw your vector triangle, which  is the position of the object with respect to s--  that's this vector-- is equal to that fixed position ", "vector from s to p, plus the vector from p to j,  and I differentiate this, drs jdt. ", "Well, this derivative of a constant vector, this  is 0 plus drp jdt. ", "And so we see that the velocity j  is independent of the choice of point s. ", "You choose any other fixed point and you  get that velocities drs jdt equals  drp jpt for all fixed points p. ", "And that's why in this expression, when  we differentiate the velocity, even though we had an index s,  we dropped that.  And so our conclusion is that we can  treat that we have the velocity of the center of mass ", "of this system is equal to the sum mj vj.  j from 1 to n divided by the total mass. ", "Now what's interesting here is, why  is this an important quantity?  Let's just add that if we want to talk  about the acceleration of the center of mass, ", "I do exactly the same type of calculation.  I just differentiate.  And I get the mass of the j-th particle  times the acceleration of the j-th particle divided  by the total mass. ", "And our next step is to understand  why this is an important quantity  for a system of particles.  ", "We'd like to consider a system of particles.  Let's say we have object one.  We'll call this the j-th object, object n.  And somewhere in this system of particles is a center of mass. ", "Now, we know that the external force  is causing the momentum of the system to change,  and what we'd now like to show is ", "that we can reduce this system to  an effective single particle.  The way we'll do that is recall that the momentum of the system ", "is given by the sum of the individual momentums.  We'll call that the j-th particle where  we're summing j from 1 to n.  And that's the sum of the momentums ", "of the various particles.  Now when you differentiate the momentum  of the system with respect to time,  we're just differentiating the velocity. ", "And so that becomes the acceleration  of the j-th particle.  Now we saw when we define the center of mass  that the acceleration of the center  of mass times the total mass of the system ", "was equal to the sum of mj aj.  j goes from 1 to n.  So we see that another way to think ", "about how the momentum of the system of particles is changing  is simply the total mass times the acceleration ", "of the center of mass.  And our combination of Newton's second and third law  now becomes that only the external forces ", "cause the momentum of the system to change so that's  equal to the total mass times the acceleration of the center  of mass.  Now what does this equation really mean? ", "So let's draw our pictures again.  Here's our system.  We have particles 1, et cetera.  That's the j-th particle, n particles. ", "And in here is the center of mass.  Now I'm going to outline my system like this  and what this equation is telling  us is that we can just focus by putting all of the mass ", "and total at the center of mass.  And that center of mass is going to move  according to some trajectory. ", "And all we have to think about is  this is a point particle of total mass m, m total. ", "So what we've done is we've done a very important reduction.  We've taken a complicated system of particles  and reduced it to a single point particle ", "of total mass m located at cm.  And the dynamics of that total particle  is if there is external force acting on this system, ", "we place this external force at the center of mass.  And now we can calculate the acceleration  of the center of mass is just that external force divided ", "by the total mass.  And that's how we can reduce this complicated system  of particles to a translational motion of the center of mass. ", "Now we still cannot describe the individual interactions  in the system, but we're not trying to do that anymore.  We're not trying to trace how each particle moves. ", "We're just looking at as our system is a point particle  and talking about how that point-like object is  translating the space.  And this is a powerful tool that we use again ", "and again and again. "], "vid_duration": [11.33, 11.22, 11.47, 13.49, 10.53, 10.92, 12.54, 10.01, 11.95, 13.43, 11.2, 12.3, 12.48, 10.44, 10.17, 12.3, 12.3, 15.21, 11.52, 10.71, 11.11, 14.01, 11.346, 11.74, 11.729, 11.18, 11.361, 15.43, 12.95, 10.709, 11.5, 10.791, 15.329, 12.386, 15.145, 10.909, 15.18, 14.531, 19.15, 15.659, 19.5, 12.431, 11.28, 15.809, 16.101, 24.36, 13.16, 10.32, 12.03, 12.019, 16.49, 15.5, 12.821, 13.741, 12.73, 13.01, 11.84, 12.07, 13.81, 12.05, 12.07, 11.55, 11.13, 12.145, 14.96, 13.054, 10.917, 15.73, 10.41, 10.394, 10.356, 10.49, 12.59, 10.69, 12.779, 10.761, 10.86, 18.321, 11.989, 12.89, 13.804, 11.695, 12.651, 14.19, 10.29, 11.7, 11.93, 12.319, 10.551, 10.32, 10.96, 14.17, 15.02, 10.22, 10.38, 10.716, 11.51, 11.71, 13.5, 11.47, 11.31, 11.59, 11.48, 17.5, 10.36, 13.27, 10.86, 11.6, 10.85, 14.78, 18.55, 13.36, 11.73, 10.03, 14.04, 11.123, 11.991, 11.05, 10.71, 10.11, 12.16, 12.47, 10.5, 10.29, 10.17, 12.42, 10.77, 14.11, 11.96, 15.67, 10.38, 12.78, 12.75, 12.6, 10.14, 10.38, 1.087], "stet": [[0, 11.33], [11.33, 22.55], [22.55, 34.02], [34.02, 47.510000000000005], [47.510000000000005, 58.040000000000006], [58.040000000000006, 68.96000000000001], [68.96000000000001, 81.5], [81.5, 91.51], [91.51, 103.46000000000001], [103.46000000000001, 116.89000000000001], [116.89000000000001, 128.09], [128.09, 140.39000000000001], [140.39000000000001, 152.87], [152.87, 163.31], [163.31, 173.48], [173.48, 185.78], [185.78, 198.08], [198.08, 213.29000000000002], [213.29000000000002, 224.81000000000003], [224.81000000000003, 235.52000000000004], [235.52000000000004, 246.63000000000005], [246.63000000000005, 260.64000000000004], [260.64000000000004, 271.98600000000005], [271.98600000000005, 283.72600000000006], [283.72600000000006, 295.45500000000004], [295.45500000000004, 306.63500000000005], [306.63500000000005, 317.99600000000004], [317.99600000000004, 333.42600000000004], [333.42600000000004, 346.37600000000003], [346.37600000000003, 357.08500000000004], [357.08500000000004, 368.58500000000004], [368.58500000000004, 379.37600000000003], [379.37600000000003, 394.70500000000004], [394.70500000000004, 407.09100000000007], [407.09100000000007, 422.23600000000005], [422.23600000000005, 433.14500000000004], [433.14500000000004, 448.32500000000005], [448.32500000000005, 462.85600000000005], [462.85600000000005, 482.00600000000003], [482.00600000000003, 497.665], [497.665, 517.165], [517.165, 529.596], [529.596, 540.876], [540.876, 556.685], [556.685, 572.786], [572.786, 597.146], [597.146, 610.3059999999999], [610.3059999999999, 620.626], [620.626, 632.656], [632.656, 644.675], [644.675, 661.165], [661.165, 676.665], [676.665, 689.486], [689.486, 703.227], [703.227, 715.957], [715.957, 728.967], [728.967, 740.807], [740.807, 752.8770000000001], [752.8770000000001, 766.687], [766.687, 778.737], [778.737, 790.807], [790.807, 802.357], [802.357, 813.487], [813.487, 825.632], [825.632, 840.592], [840.592, 853.646], [853.646, 864.563], [864.563, 880.293], [880.293, 890.703], [890.703, 901.097], [901.097, 911.453], [911.453, 921.943], [921.943, 934.533], [934.533, 945.2230000000001], [945.2230000000001, 958.0020000000001], [958.0020000000001, 968.763], [968.763, 979.623], [979.623, 997.9440000000001], [997.9440000000001, 1009.9330000000001], [1009.9330000000001, 1022.8230000000001], [1022.8230000000001, 1036.6270000000002], [1036.6270000000002, 1048.3220000000001], [1048.3220000000001, 1060.9730000000002], [1060.9730000000002, 1075.1630000000002], [1075.1630000000002, 1085.4530000000002], [1085.4530000000002, 1097.1530000000002], [1097.1530000000002, 1109.0830000000003], [1109.0830000000003, 1121.4020000000003], [1121.4020000000003, 1131.9530000000002], [1131.9530000000002, 1142.2730000000001], [1142.2730000000001, 1153.2330000000002], [1153.2330000000002, 1167.4030000000002], [1167.4030000000002, 1182.4230000000002], [1182.4230000000002, 1192.6430000000003], [1192.6430000000003, 1203.0230000000004], [1203.0230000000004, 1213.7390000000003], [1213.7390000000003, 1225.2490000000003], [1225.2490000000003, 1236.9590000000003], [1236.9590000000003, 1250.4590000000003], [1250.4590000000003, 1261.9290000000003], [1261.9290000000003, 1273.2390000000003], [1273.2390000000003, 1284.8290000000002], [1284.8290000000002, 1296.3090000000002], [1296.3090000000002, 1313.8090000000002], [1313.8090000000002, 1324.169], [1324.169, 1337.439], [1337.439, 1348.299], [1348.299, 1359.899], [1359.899, 1370.7489999999998], [1370.7489999999998, 1385.5289999999998], [1385.5289999999998, 1404.0789999999997], [1404.0789999999997, 1417.4389999999996], [1417.4389999999996, 1429.1689999999996], [1429.1689999999996, 1439.1989999999996], [1439.1989999999996, 1453.2389999999996], [1453.2389999999996, 1464.3619999999996], [1464.3619999999996, 1476.3529999999996], [1476.3529999999996, 1487.4029999999996], [1487.4029999999996, 1498.1129999999996], [1498.1129999999996, 1508.2229999999995], [1508.2229999999995, 1520.3829999999996], [1520.3829999999996, 1532.8529999999996], [1532.8529999999996, 1543.3529999999996], [1543.3529999999996, 1553.6429999999996], [1553.6429999999996, 1563.8129999999996], [1563.8129999999996, 1576.2329999999997], [1576.2329999999997, 1587.0029999999997], [1587.0029999999997, 1601.1129999999996], [1601.1129999999996, 1613.0729999999996], [1613.0729999999996, 1628.7429999999997], [1628.7429999999997, 1639.1229999999998], [1639.1229999999998, 1651.9029999999998], [1651.9029999999998, 1664.6529999999998], [1664.6529999999998, 1677.2529999999997], [1677.2529999999997, 1687.3929999999998], [1687.3929999999998, 1697.773], [1697.773, 1698.86]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [267, 695, 865, 1211, 1461, 1699]}
{"example_id": "mit035@@MIT8_04S16_lec01_300k", "text": ["PROFESSOR: Very good.  So it's time to start.  So today, I want to talk about general features of quantum  mechanics.  Quantum mechanics is something that takes some time to learn, ", "and we're going to be doing some of that learning this semester.  But I want to give you a perspective of where we're  going, what are the basic features, how ", "quantum mechanics looks, what's surprising about it,  and introduce some ideas that will  be relevant throughout this semester and some ", "that will be relevant for later courses as well.  So it's an overview of quantum mechanics.  So quantum mechanics, at this moment,  is almost 100 years old. ", "Officially-- and we will hear--  this year, in 2016, we're celebrating the centenary  of general relativity. ", "And when will the centenary of quantum mechanics be?  I'm pretty sure it will be in 2025.  Because in 1925, Schrodinger and Heisenberg ", "pretty much wrote down the equations of quantum mechanics.  But quantum mechanics really begins earlier.  The routes that led to quantum mechanics began in the late ", "years of the 19th century with work of Planck,  and then at the beginning of the century,  with work of Einstein and others,m as we will see today ", "and in the next few lectures.  So the thoughts, the puzzles, the ideas  that led to quantum mechanics begin before 1925, ", "and in 1925, it suddenly happened.  So what is quantum mechanics?  Quantum mechanics is really a framework to do physics, ", "as we will understand.  So quantum physics has replaced classical physics  as the correct description of fundamental theory. ", "So classical physics may be a good approximation,  but we know that at some point, it's not quite right.  It's not only not perfectly accurate. ", "It's conceptually very different from the way things  really work.  So quantum physics has replaced classical physics. ", "And quantum physics is the principles  of quantum mechanics applied to different physical phenomena.  So you have, for example, quantum electrodynamics, ", "which is quantum mechanics applied to electromagnetism.  You have quantum chromodynamics, which  is quantum mechanics applied to the strong interaction. ", "You have quantum optics when you apply quantum mechanics  to photons.  You have quantum gravity when you  try to apply quantum mechanics to gravitation. ", "Why the laughs?  And that's what gives rise to string theory, which  is presumably a quantum theory of gravity, ", "and in fact, the quantum theory of all interactions  if it is correct.  Because it not only describes gravity,  but it describes all other forces.  So quantum mechanics is the framework, ", "and we apply it to many things.  So what are we going to cover today?  What are we going to review?  Essentially five topics-- one, the linearity ", "of quantum mechanics, two, the necessity of complex numbers, ", "three, the laws of determinism, four, ", "the unusual features of superposition, ", "and finally, what is entanglement.  ", "So that's what we aim to discuss today.  So we'll begin with number one, linearity. ", "And that's a very fundamental aspect  of quantum mechanics, something that we have  to pay a lot of attention to.  So whenever you have a theory, you ", "have some dynamical variables.  These are the variables you want to find  their values because they are connected with observation.  If you have dynamical variables, you ", "can compare the values of those variables,  or some values deduced from those variables,  to the results of an experiment.  So you have the equations of motion, so linearity. ", "We're talking linearity.  You have some equations of motion, EOM. ", "And you have dynamical variables.  If you have a theory, you have some equations, ", "and you have to solve for those dynamical variables.  And the most famous example of a theory that is linear ", "is Maxwell's theory of electromagnetism.  Maxwell's theory of electromagnetism  is a linear theory.  What does that mean?  Well, first, practically, what it means ", "is that if you have a solution--  for example, a plane wave propagating in this direction--  and you have another solution-- ", "a plane wave propagating towards you--  then you can form a third solution,  which is two plane waves propagating simultaneously. ", "And you don't have to change anything.  You can just put them together, and you get a new solution.  The two waves propagate without touching each other, ", "without affecting each other.  And together, they form a new solution.  This is extraordinarily useful in practice ", "because the air around us is filled  with electromagnetic waves.  All your cell phones send electromagnetic waves ", "up the sky to satellites and radio stations  and transmitting stations, and the millions of phone calls  go simultaneously without affecting each other. ", "A transatlantic cable can conduct millions of phone calls  at the same time, and as much data and video and internet. ", "It's all superposition.  All these millions of conversations  go simultaneously through the cable  without interfering with each other. ", "Mathematically, we have the following situation.  In Maxwell's theory, you have an electric field, ", "a magnetic field, a charge density, and a current density.   That's charge per unit area per unit of time. ", "That's the current density.  And this set of data correspond to a solution  if they satisfy Maxwell's equations, ", "which is a set of equations for the electromagnetic field,  charged densities, and current density.  So suppose this is a solution, that you verify that it ", "solves Maxwell's equation.  Then linearity implies the following. ", "You multiply this by alpha, alpha e, alpha b, alpha rho,  and alpha j. ", "And think of this as the new electric field,  the new magnetic field, the new charged density,  and the new current is also a solution.  ", "If this is a solution, linearity implies  that you can multiply those values ", "by a number, a constant number, a alpha being a real number.   And this is still a solution. ", "It also implies more.  Linearity means another thing as well.  It means that if you have two solutions, e1, b1, rho 1, j1, ", "and e2, b2, rho 2, j2--   if these are two solutions, then linearity ", "implies that the sum e1 plus e2, b1 plus b2, rho 1 plus rho 2, ", "and j1 plus j2 is also a solution.  ", "So that's the meaning, the technical meaning of linearity.  We have two solutions.  We can add them.  We have a single solution.  You can scale it by a number. ", "Now, I have not shown you the equations  and what makes them linear.  But I can explain this a little more as to ", "what does it mean to have a linear equation.  Precisely what do we mean by a linear equation?  So a linear equation.  ", "And we write it schematically.  We try to avoid details.  We try to get across the concept.  A linear equation, we write this l u equal 0 where ", "u is your unknown and l is what is called the linear operator, ", "something that acts on u.  And that thing, the equation, is of the form l and u equal 0.  Now, you might say, OK, that already ", "looks to me a little strange, because you have just one  unknown, and here we have several unknowns.  So this is not very general.  And you could have several equations. ", "Well, that won't change much.  We can have several linear operators  if you have several equations, like l1 or something, ", "l2 on something, all these ones equal to 0  as you have several equations.  So you can have several u's or several unknowns, ", "and you could say something like you have l on u, v,  w equals 0 where you have several unknowns. ", "But it's easier to just think of this first.  And once you understand this, you can think about the case  where you have many equations.  So what is a linear equation? ", "It's something in which this l--  the unknown can be anything, but l  must have important properties, as being a linear operator ", "will mean that l on a times u, where a is a number,  should be equal to alu and l on u1 plus u2 on two unknowns ", "is equal to lu 1 lu 2.  This is what we mean by the operator being linear.  ", "So if an operator is linear, you also  have l on alpha u1 plus beta u2. ", "You apply first the second property, l on the first plus  l on the second.  So this is l of alpha u1 plus l of beta u2. ", "And then using the first property,  this is alpha l of u1 plus beta l of u2.  And then you realize that if u1 and u2 are solutions-- ", "which means lu 1 equal lu 2 equals 0  if they solve the equation--  then alpha u1 plus beta u2 is a solution. ", " Because if lu1 is 0 and lu2 is 0, l of alpha u1 plus beta u2 ", "is 0, and it is a solution.  So this is how we write a linear equation. ", "Now, an example probably would help.  If I have the differential equation  du dt plus 1 over tau u equals 0, ", "I can write it as an equation of the form lu  equals 0 by taking l on u to be defined ", "to be vu vt plus 1 over tau u.  Now, it's pretty much-- ", "I haven't done much here.  I've just said, look, let's define l [? active ?] [? on ?]  u to be this.  And then certainly, this equation is just lu equals 0. ", "The question would be maybe if somebody would tell you  how do you write l alone--  well, l alone, probably we should write it ", "as d dt without anything here plus 1 over tau.  Now, that's a way you would write ", "it to try to understand yourself what's going on.  And you say, well, then when l acts as the variable u,  the first term takes the derivative,  and the second term, which is a number, just multiplies it. ", "So you could write l as this thing.  And now it is straightforward to check ", "that this is a linear operator.  l is linear.  And for that, you have to check the two properties there. ", "So for example, l on au would be ddt of au  plus 1 over tau au, which is a times du d tau ", "plus 1 over tau u, which is alu.   And you can check.  I asked you to check the other property ", "l on u1 plus u2 is equal to lu 1 plus lu 2.  PROFESSOR: So here is of something funny. ", "You might say, OK, what is simpler?  A theory that is linear or a theory that is not linear?  And the answer, of course, a linear theory is much simpler. ", "General-- Maxwell's equations are linear.  Einstein's theory of relativity is very nonlinear,  very complicated. ", "How about classical mechanics?  Is classical mechanics linear or nonlinear?   What do we think? ", " Can't hear anyone.  Linear, OK.  You may think it's linear because it's supposed ", "to be simple, but it's not.  It's actually is very nonlinear.  Newton could solve the two body problem  but he couldn't solve the three body problem. ", "Already with three bodies, you cannot superpose solutions that  you get with two bodies.  It's extraordinarily complicated,  classical mechanics. ", "Let me show you.  If you have motion in one dimension, in 1D,  you have the equation of motion, motion in one dimension, ", "and there are potential V of x, that this time independent--  a particle moving in one dimension x  with under the influence of a potential, V of x. ", "The second-- the dynamical variable is x of t.  The dynamical variable.  And the equation of motion is-- ", " so let me explain this.  This is force equal mass times acceleration. ", "This is mass, this is acceleration,  the second derivative of the position,  and V force is minus the derivative of the potential ", "evaluated at the position.  You know, derivatives of potentials--  if you think of a potential, the derivative of the potential ", "is here positive, and you know if you have a mass  here, it tends to go to the left,  so the force is on the left, so it's minus.  So V prime is the derivative of V with respect to its argument. ", " And the problem is that while this, taking derivatives, ", "is a linear operation.  If you take two derivatives of a sum of things,  you take two derivatives of the first  plus two derivatives of the second. ", "But yes, its-- this side is linear,  but this side may not be linear.  Because a potential can be arbitrary. ", "And that the reverse-- so suppose  the potential is cubic in x.  V of x goes like x cubed.  Then the derivative of V goes like x squared, ", "and x squared is not a linear function.  So this, Newton's equation, is not a linear equation.  And therefore, it's complicated to solve. ", "Very complicated to solve.  So finally, we can get to our case, quantum mechanics.  So in quantum mechanics, what do we have? ", "Quantum mechanics is linear.   First, you need an equation, and whose equation is it?  Schrodinger's equation, 1925. ", "He writes an equation for the dynamical variable,  and the dynamical variable is something  called the wave function.  ", "This wave function can depend on t--  depends on time-- and it may depend on other things as well. ", "And he describes the dynamics of the quantum system  as it evolved in time.  There is the wave function, and you have an equation  for this wave function. ", "And what is the equation for this wave function?  It's a universal equation-- i hbar  partial derivative with respect to time of psi ", "is equal to H hat of psi, where H hat is called the Hamiltonian ", "and it's a linear operator.  That's why I had to explain a little bit what  the linear operator is. ", "This is the general structure of the Schrodinger equation--  time derivative and the linear operator.  So if you wish to write the Schrodinger equation as an L ", "psi equals 0, then L psi would be defined i hbar del/del ", "t of psi minus H hat psi.   Then this is the Schrodinger equation. ", "This equation here is Schrodinger's equation.   And as you can see, it's a linear equation.  You can check it, check that L is a linear operator. ", "Therefore, it is naturally linear, you can see,  because you do it differently, because the derivative  with respect to time is a linear operation. ", "If you have the ddt of a number of times a function,  the number goes out, you differentiate the function.  ddt of the sum of two functions, you differentiate the first, ", "you differentiate.  So this is linear and H we said is linear,  so L is going to be linear and the Schrodinger equation ", "is going to be a linear equation,  and therefore, you're going to have the great advantage  that any time you find solutions, you can scale them,  you can add them, you can put them together, combine them ", "in superpositions, and find new solutions.  So in that sense, it's remarkable  that quantum mechanics is simpler ", "than classical mechanics.  And in fact, you will see throughout this semester  how the mathematics and the things that we do  are simpler in quantum mechanics, ", "or more elegant, more beautiful, more coherent,  it's simpler and very nice.  OK, i is the square root of minus 1, is the imaginary unit, ", "and that's what we're going to talk next  on the necessity of complex numbers.  hbar, yes, it's a number.  It shows up in quantum mechanics early on. ", "It it's called Planck's constant and it  began when Planck tried to fit the black value spectrum  and he found the need to put a constant in there, ", "and then later, Einstein figured out that it was very relevant,  so yes, it's a number.  For any physical system that you have, ", "you will have a wave function and you  will have a Hamiltonian, and the Hamiltonian  is for you to invent or for you to discover.  So if you have a particle moving on a line, ", "the wave function will depend on time and on x.  If you have a particle moving in three dimensions,  it will depend on x vector. ", "It may depend on other things as well  or it maybe, like, one particle has several wave functions  and that happens when you have a particle with spin. ", "So in general, always time, sometimes position,  there may be cases where it doesn't depend on position.  You think of an electron at some point in space and it's fixed-- ", "you lock it there and you want understand  the physics of that electron locked into place,  and then position is not relevant.  So what it does with its spin is relevant ", "and then you may need more than one wave function-- what  is one describing the spin up and one  describing the spin down? ", "So it was funny that Schrodinger wrote this equation  and when asked, so what is the wave function?  He said, I don't know. ", "No physical interpretation for the wave function  was obvious for the people that invented quantum mechanics.  It took a few months until Max Born said ", "it has to do with probabilities, and that's  what we're going to get next.  So our next point is the necessity of complex numbers ", " PROFESSOR: So in quantum mechanics,  you see this i appearing here, and it's a complex number-- ", "the square root of minus 1.  And that shows that somehow complex numbers  are very important.  Well it's difficult to overemphasize ", "the importance of i--  is the square root of minus 1 was invented by people in order  to solve equations.  Equations like x squared equals minus 1. ", "And it so happens that once you invent i  you need to invent more numbers, and you  can solve every polynomial equation with just i. ", "And square root of i-- well square root of i  can be written in terms of i and other numbers.  So if you have a complex number z-- ", "we sometimes write it this way, and we  say it belongs to the complex numbers,  and with a and b belonging to the real numbers. ", "And we say that the real part of z  is a, the imaginary part of z is b.  We also define the complex conjugate of z, ", "which is a minus i b and we picture the complex number z  by putting a on the x-axis b on the y-axis, ", "and we think of the complex number z here--  kind of like putting the real numbers here  and the imaginary parts here.  So you can think of this as ib or b, ", "but this is the complex number-- maybe ib would be a better way  to write it here.  So with complex numbers, there is one more useful identity. ", "You define the norm of the complex number  to be square root of a squared plus b squared  and then this results in the norm ", "squared being a squared plus b squared.  And it's actually equal to z times z star.  A very fundamental equation-- ", "z times z star--  if you multiply z times z star, you  get a squared plus b squared.  So the norm squared-- ", "the norm of this thing is a real number.   And that's pretty important.  So there is one other identity that is very useful ", "and I might well mention it here as we're  going to be working with complex numbers.  And for more practice on complex numbers,  you'll see the homework. ", "So suppose I have in the complex plane an angle theta,  and I want to figure out what is this complex number z here ", "at unit radius.  So I would know that it's real part would be cosine theta. ", " And its imaginary part would be sine theta.  It's a circle of radius 1. ", " So that must be the complex number.  z must be equal to cosine theta plus i sine theta. ", "Because the real part of it is cosine theta.  It's in that horizontal part's projection.  And the imaginary part is the vertical projection. ", "Well the thing that is very amazing  is that this is equal to e to the i theta.  And that is very non-trivial. ", "To prove it, you have to work a bit,  but it's a very famous result and we'll use it.   So that is complex numbers. ", "So complex numbers you use them in electromagnetism.  You sometimes use them in classical mechanics,  but you always use it in an auxiliary way. ", "It was not directly relevant because the electric field  is real, the position is, real the velocity is real-- ", "everything is real and the equations are real.  On the other hand, in quantum mechanics,  the equation already has an i.  So in quantum mechanics, psi is a complex number necessarily. ", "It has to be.  In fact, if it would be real, you would have a contradiction  because if psi is real, turns out ", "for all physical systems we're interested in, H on psi real  gives you a real thing.  And here, if psi is real then the relative is real, ", "and this is imaginary and you have a contradiction.  So there are no solutions that are real.  So you need complex numbers.  They're not auxiliary. ", "On the other hand, you can never measure a complex number.  You measure real numbers--  ammeter, position, weight, anything ", "that you really measure at the end of the day  is a real number.  So if the wave function was a complex number,  it was the issue of what is the physical interpretation. ", "And Max Born had the idea that you  have to calculate the real number called  the norm of this square, and this is ", "proportional to probabilities.   So that was a great discovery and had a lot ", "to do with the development of quantum mechanics.  Many people hated this.  In fact, Schrodinger himself hated it,  and his invention of the Schrodinger cat ", "was an attempt to show how ridiculous  was the idea of thinking of these things as probabilities.  But he was wrong, and Einstein was wrong in that way. ", "But when very good physicists are wrong,  they are not wrong for silly reasons,  they are wrong for good reasons, and we can learn a lot ", "from their thinking.  And this EPR are things that we will  discuss at some moment in your quantum sequence at MIT. ", "Einstein-Podolski-Rosen was an attempt  to show that quantum mechanics was wrong  and led to amazing discoveries.  It was the EPR paper itself was wrong, ", "but it brought up ideas that turned out  PROFESSOR: Determinism.  ", "And it all begins with photons.  Einstein reluctantly came up with the idea ", "that light was made of quanta--  quanta of light called photons.  Now when you think of photons, we think of a particle. ", "So everybody knew that light was a wave.  Maxwell's equations had been so successful.  Nevertheless, photoelectric effect-- ", "Planck's work-- all were leading to the idea that, in some ways,  photons were also particles.  ", "So when you think of a particle, however, there  is an important difference between a particle  in the sense of Newton, which is an object with zero size that ", "carries energy and has a precise position  and velocity at any time, and the quantum mechanical idea  of particle, which is just some indivisible amount of energy ", "or momentum that propagates.  So light was made of photons--  packets of energy. ", "And a photon is a particle-- a quantum mechanical particle.  Not in the sense that maybe it has position and velocity  determined or it's a point particle, ", "but more like a packet that is indivisible.  You cannot decompose it in further packets.  So Einstein realized that for a photon, ", "the energy was given by h nu.  Where nu is the frequency of the light  that this photon is helping build up. ", "So if you have a beam of light, you  should think it's billions of photons.  And according to the frequency of that light  that is related to the wavelength-- ", "by the equation frequency times wavelength  is velocity of light--  you typically know, for light, the wavelength,  and you know the frequency, and then  you know the energy of each of the photons. ", "The photons have very, very little energy.  We have very, very little energy,  but your eyes are very good detectors of photons.  If you're in a totally dark room, your eye, ", "probably, can take as little as five photons  if they hit your retina.  So it's a pretty good detector of photons.  Anyway, the thing that I want to explain here ", "is what happens if a beam of light hits a polarizer.  So what is a polarizer?  It's a sheet of plastic or some material. ", "It has a preferential direction.  Let me align that preferential direction with the x-axis,  and that's a polarizer. ", "And if I send light that is linearly  polarized along the x-axis, it all goes through.  If I send light linearly polarized along the y-axis, ", "nothing goes through.  It all gets absorbed.  That's what a polarizer does for a living.  In fact, if you send light in this direction, ", "the light that comes out is identical to the light  that came in.  The frequency doesn't change.  The wavelength doesn't change.  It's the same light, the same energy. ", "So far, so good.  Now let's imagine that we send in light linearly polarized  at some angle alpha. ", "So we send an electric field E alpha,  which is E0 cosine alpha x hat plus E0 sine alpha y hat. ", " Well, you've studied electromagnetism, ", "and you know that this thing, basically, will come around  and say, OK, you can go through because you're  aligning the right direction, but you  are orthogonal to my preferential direction, ", "or orthogonal I absorbed, so this disappears.  So after the polarizer, E is just E0 cosine alpha x hat. ", " That's all that is left after the polarizer.  Well here is something interesting-- ", "you know that the energy on electromagnetic field  is proportional to the magnitude of the electric field ", "square, that's what it is.  So the magnitude of this electric field--  if you can notice, it's the square root ", "of the sum of the squares will give you  E0 as the magnitude of this full electric field.  But this electric field has magnitude E0 cosine alpha. ", "So the fraction of power--  fraction of energy through is cosine alpha squared. ", " The energy is always proportional to the square.  So the square of this is E0 squared cosine squared alpha.  And for this one, the magnitude of it is E0, ", "so you divide by E0 and cosine alpha is the right thing.  This is the fraction of the energy.  If alpha is equal to 0, you get cosine of 01.  You get all the energy 1. ", "If alpha is equal to pi over 2, the light  is polarized along the y direction,  nothing goes through--  indeed, cosine of pi over 2 is 0, and nothing goes through. ", "So the fraction of energy that goes through  is cosine squared alpha.  But now, think what this means for photons. ", " What it means for photons is something  extraordinarily strange.  And so strange that it's almost unbelievable that we ", "get so easily in trouble.  Here is this light beam over here,  and it's made up of photons. ", "All identical photons, maybe billions of photons,  but all identical.  And now, think of sending this light beam over there-- ", "a billion identical photons-- you send them one by one  into the state, and see what happens. ", "You know what has to happen, because classical behavior is  about right.  This fraction of the photons must go through, ", "and 1 minus that must not go through.   You see, it cannot be there comes a photon and half of it ", "goes through, because there's no such thing as half of it.  If there would be half of it, it would  be half the energy and, therefore, different color.  And we know that after a polarizer, ", "the color doesn't change.  So here is the situation.  You're sending a billion photons and, say, one-third  has to get through. ", "But now, the photos are identical.  How can that happen in classical physics?  If you send identical photos, whatever happens to a photon ", "will happen to all, but the photon either gets absorbed  or goes through.  And if it gets absorbed, then all should get absorbed.  And if it goes through, all should go through ", "because they are all identical.  And now you have found a situation  which identical set of experiments  with identically prepared objects ", "sometimes gives you different results.  It's a debacle.  It's a total disaster.  What seems to have happened here--  you suddenly have identical photons,  and sometimes they go through, and sometimes they ", "don't go through.  And therefore, you've lost predictability.  It's so simple to show that if photons exist,  you lose predictability. ", "And that's what drove Einstein crazy.  He knew when he entered these photons  that he was getting in trouble.  He was going to get in trouble with classical physics. ", "So possible ways out--  people speculate about it--  people said, well, yes, the photos are identical,  but the polarizer has substructure. ", "If it hits in this interatomic part, it goes through,  and in that interatomic part, it doesn't go through.  People did experiments many times.  It's not true.  The polarizer is like that. ", "And then came a more outrageous proposition  by Einstein and others--  that there are hidden variables. ", "You think the photons are identical,  but a photon has a hidden variable-- a property  you don't know about. ", "If you knew that property about the photon,  you would be able to tell if it goes through  or it doesn't go through.  But you don't know it, so that's why you're  stuck with probabilities. ", "It's because the quantum theory is not complete.  There are hidden variables.  And once you put the hidden variables,  you'll discover the photon has more something inside it, ", "and they are not the same, even though they look the same.  And that's a hidden variable theory.  And it sounds so philosophical that you would think, well, ", "if you don't know about them, but they are there,  these properties, how could you ever know they are there?  And the great progress of John Bell with the Bell inequalities ", "is that he demonstrated that that would not fix the problem.  Quantum mechanics cannot be made deterministic with hidden ", "variables.  It was an unbelievable result--  the result of John Bell.  So that's something we will advance towards in this course ", "but not quite get there.  805 discusses this subject in detail.  So at the end of the day, we've lost determinism. ", "We can only predict probabilities.  So photons either gets through or not, ", "and can only predict probabilities. ", " Now we write, in classical physics, a beam like that. ", "But how do we write the wave function of a photon?  Well, this is quite interesting.  We think of states of a particle as wave functions. ", "And I will call them, sometimes, states;  I will call them, sometimes, wave functions;  and I sometimes will call them vectors.  Why vector?  Because the main thing you do with vectors ", "is adding them or multiplying them by numbers to scale them.  And that's exactly what you can do with a linear equation.  So that's why people think of states, or wave functions, ", "as vectors.  And Dirac invented a notation in which  to describe a photon polarized in the x direction,  you would simply write something like this. ", "Photon colon x and this object--  you think of it as some vector or wave function, ", "and it represents a photon in the x direction.  And we're not saying yet what kind of vector this is,  but it's some sort of vector. ", "It's not just a symbol, it represents a vector.  And that's a possible state.  This is a photon polarized along x.  And you can also have, if you wish, ", "a photon polarized along y.  And linearity means that if those photos can exist, ", "the superposition can exist.  So there can exist a state called cos alpha photon x ", "plus sine alpha photon y, in which I've superposed  one state with another-- ", "created a sum-- and this I call the photon state polarized  in the alpha direction. ", "So this is how, in quantum mechanics, you think of this--  photons-- we will elaborate that and compare with this equation.  It's kind of interesting. ", "What you lose here is this ease.  There's no ease there because it's one photon.  When you have a big electric field,  I don't know how many photons there are. ", "I would have to calculate the energy of this beam  and find the frequency that I didn't specify,  and see how many photons.  But each photon in this beam quantum mechanically ", "can be represented as this superposition.   And we'll talk more about this superposition now  because our next subject is superpositions  and how unusual they are. ", "Well the hidden variable explanation  failed because Bell was very clever,  and he noted that you could design ", "an experiment in which the hidden variables would  imply that some measurements would satisfy an inequality. ", "If the existed hidden variables and the world  was after all classical, the results of experiments  would satisfy a Bell inequality. ", "And then a few years later, the technology  was good enough that people could test the Bell  inequality with an experiment, and they figured out ", "it didn't hold.  So the hidden variables lead to Bell inequalities  that are experimentally shown not to hold. ", "And we will touch a little bit on it  when we get to untangle them.  After the polarizer, the photon is in the state photon x. ", "It's always polarized along the x direction,  so it's kind of similar that this doesn't go through.  This goes through, but at the end of the day, ", "as we will explain very soon, the cosine alpha  is not relevant here.  When it goes through, the whole photon goes through.  So there's no need for a cosine alpha.  PROFESSOR: Superposition is very unusual and very interesting. ", "Now we've said about superposition  that in classical physics, when we talk about superposition ", "we have electric fields, and you add the electric fields,  and the total electric field is the sum of electric fields,  and it's an electric field.  And there's nothing strange about it. ", "The nature of superposition in quantum mechanics  is very strange.  So nature of superposition-- ", " I will illustrate it in a couple of different ways.  One way is with a device that we will get accustomed to. ", "It it's called the Mach-Zehnder interferometer, ", "which is a device with a beam splitter in here.  You send in a beam of light-- ", "input- beam splitter and then the light--  indeed half of it gets reflected, half of it ", "gets transmitted.   Then you put the mirror here--   mirror 1, you put the mirror 2 here, ", "and this gets recombined into another beam splitter.   And then if there would be just a light going in, ", "here there would be two things going out.  There's another one coming from the bottom.  There will be two.  There will be interference.  So you put a detector D0 here and a detector ", "E1 here to detect the light.  So that's the sketch of the Mach-Zehnder interferometer-- ", "beam splitters and mirrors.  Take a beam, spit the light, go down, up, and then recombine it ", "and go into detectors.   This was invented by these two people,  independently, in the 1890s-- ", "'91 to '92 apparently.   And people did this with light-- ", "beams of light before they realized they're photons.  And what happens with a beam of light-- it's interesting-- ", "comes a beam of light.  The beam splitter sends half of the light one way half  of the light the other way.  You already know with quantum mechanics ", "that's going to be probabilistic some photons will go up maybe  some photons will go down or something more strange  can happen. ", "If you have a superposition, some photons  may go both up and down.  So that's what can happen in quantum mechanics. ", "If you send the beam, classical physics,  it divides half and half and then combines.  And there's an interference effect here.  And we will design this interferometer in such a way ", "that sometimes we can produce an interference that everything  goes to D0 or everything goes to D1  or we can produce suitable interferences that we ", "can get fractions of the power going into D1 and D2--   D0 and D1.  So we can do it in different ways, ", "but we should think of this as a single photon.  Single photos going one at a time.  You see, whatever light you put in here, experimentally, ", "the same frequency goes out here.  So what is interference?  You might think, intuitively, that interference  is one photon interfering with another one, but it can't be. ", "If two photos would interfere in a canceling, destructive  interference, you will have a bunch of energy.  It goes into nothing.  It's impossible. ", "If they would interfere constructively,  you would add the electric fields  and the amplitude would be four times as big because it's  proportional to the square. ", "But two photos are not going to go to four photons.  It cannot conserve energy.  So first of all, when you get light interference, ", "each photon is interfering with itself.   It sounds crazy, but it's the only possibility. ", "They cannot interfere with each other.  You can send the photons one at a time  and, therefore, each photon will have ", "to be in both beams at the same time.  And then, each photon as it goes along,  there will be an interference effect,  and the photon may end up here or end up there ", "in a probabilistic way.  So you have an example of superposition.   Superposition. ", "A single photon state a single photon  is equal to superposition of a photon in the upper beam ", "and a photon in the lower beam.   It's like two different states-- ", "a little different from here, you  had photons in two different polarizations  states superposed.  Here you have photons in two different beams-- ", "a single photon is in both beams at the same time.  And unless you have that, you cannot get a superposition  and an interference that is consistent with experiment. ", "So what does that mean for superpositions?  Well, it means something that we can discuss, ", "and I can say things that, at this moment,  may not make too much sense, but it  would be a good idea that you think about them a little bit. ", "We associated states with vectors.   States and vectors are the same thing.  And it so happens that when you have vectors, ", "you can write them as the sum of other vectors.  So the sum of these two vectors may be this vector.  But you can also write it as the sum of these two vectors-- ", "these two vectors add to the state.  And you can write any vector as a sum of different vectors,  and that's, actually, quite relevant.  You will be doing that during the semester-- ", "writing a state a superposition of different things.  And in that way you will understand  the physics of those states.  So for example, we can think of two states-- ", "A and B. And you see, as I said, states wave functions,  vectors--  we're all calling them the same thing.  If you have a superposition of the states A and B, ", "what can happen?  All right, we'll do it the following way.  Let's assume if you measure some property on A, ", "you always get value A. So you measure something-- position,  momentum, angular momentum, spin, energy, something-- ", "on A, it states that you always get  A. Suppose you measured the same property on B. You always ", "get B as the value.   And now suppose you have a quantum mechanical state, ", "and the state is alpha A plus beta B--  it's a superposition. ", "This is your state.  You superimpose A and B. And now you measure that property. ", "That same property you could measure here,  you measure it in your state.   The question is, what will you get? ", "You've now superimpose those states.  On the first state, you always get A; on the second state,  you always get B. What do you get on the superimposed states,  where alpha and beta are numbers-- ", " complex numbers in general?   Well the most, perhaps, immediate guess ", "is that you would get something in-between  maybe alpha A plus beta B or an average or something.  But no, that's not what happens in quantum mechanics. ", "In quantum mechanics, you always get A or you always get B.  So you can do the experiment many times, ", "and you will get A many times, and you may get B many times.  But you never get something intermediate.  So this is very different than in classical physics. ", "If a wave has some amplitudes and you  add another wave of different amplitudes,  you measure the energy you get something intermediate.  Here not!  You make the superposition and as you measure you will either ", "get the little a or the little b but  with different probabilities.  So roughly speaking, the probability to get little a ", "is proportional to the number in front of here is alpha squared,  and the probability to measure little b ", "is proportional to beta squared.  So in a quantum superposition, a single measurement  doesn't yield an average result or an intermediate result. ", "It leads one or the other.  And this should connect with this.  Think of the photon we were talking about before. ", "If you think of the photon that was at an angle  alpha in this way, you could say that the polarizer is measuring ", "the polarization of the object.  And therefore, what is the possible result  it may measure the polarizations say oh, if it's ", "in the x direction you get it right,  and what is the probability that you get  it to be in the x direction is proportional to cosine squared ", "alpha-- the coefficient here squared.  So the probability that you find the photon  after measuring in the x direction  is closer in squared alpha, and the probability ", "that you'll find that here is sine squared alpha.  And after you measure, you get this state which  is to say the following thing.  The probability to get the value A is alpha squared, ", "but if you get A, the state becomes A ", "because this whole state of the system becomes that.  Because successive measurements will keep giving you the value  A. If you get B, the state becomes ", "B. So this is what is called the postulate of measurement  and the nature of superposition.  This is perhaps the most sophisticated idea  we've discussed today, in which in a quantum superposition ", "the results are not intermediate.  So when you want to figure out what state you have,  you have to prepare many copies of your state ", "in this quantum system and do the experiment many times.  Because sometimes you'll get A, sometimes you'll  get B. After you've measured many times,  you can assess the probabilities and reconstruct the state. "], "vid_duration": [13.27, 10.95, 11.25, 14.34, 10.98, 14.58, 15.81, 12.61, 11.56, 10.51, 11.7, 11.4, 10.86, 13.59, 11.07, 13.14, 11.58, 14.43, 14.65, 15.07, 11.6, 15.58, 11.36, 12.01, 12.19, 12.51, 13.39, 10.31, 11.1, 10.05, 12.36, 11.58, 14.11, 11.32, 10.53, 10.5, 13.14, 11.76, 10.56, 11.31, 13.74, 11.948, 10.642, 10.83, 12.69, 13.95, 10.05, 12.68, 13.23, 23.65, 12.23, 17.08, 12.88, 10.58, 12.87, 16.44, 13.08, 12.02, 11.69, 11.61, 11.43, 12.39, 11.76, 11.1, 19.35, 12.76, 11.84, 13.8, 21.65, 16.935, 11.745, 13.7, 15.32, 12.21, 10.8, 11.07, 10.92, 10.79, 13.83, 11.35, 11.598, 16.772, 10.11, 11.339, 10.47, 11.32, 10.94, 13.21, 10.71, 10.47, 14.43, 13.5, 11.355, 10.975, 13.92, 10.88, 22.915, 10.285, 10.27, 11.08, 10.99, 12.29, 11.64, 13.45, 14.709, 13.011, 11.47, 12.71, 14.41, 10.59, 14.54, 11.16, 11.73, 14.92, 10.11, 10.71, 10.33, 13.94, 10.05, 10.349, 14.401, 13.05, 10.86, 11.04, 11.7, 11.969, 10.201, 13.89, 11.44, 11.37, 12.23, 13.47, 11.715, 13.03, 11.13, 13.575, 11.335, 12.91, 11.47, 14.07, 13.52, 14.1, 12.97, 12.3, 11.53, 10.4, 17.98, 12.75, 12.84, 10.38, 10.19, 12.4, 12.56, 11.04, 12.49, 13.23, 10.23, 20.07, 10.91, 11.08, 11.26, 11.03, 10.53, 10.05, 13.45, 12.629, 10.051, 10.65, 10.5, 12.43, 11.489, 10.279, 11.281, 12.08, 19.98, 15.639, 15.631, 11.79, 10.13, 15.159, 12.611, 11.48, 12.1, 12.46, 13.38, 12.299, 12.611, 14.69, 11.949, 12.411, 11.37, 16.005, 10.755, 12.65, 16.23, 12.07, 10.43, 10.22, 11.8, 16.695, 12.975, 12.21, 12.3, 14.25, 12.27, 12.77, 13.359, 11.021, 11.8, 11.369, 10.921, 11.179, 10.311, 11.399, 11.091, 12.43, 11.15, 11.4, 10.85, 12.69, 11.44, 11.93, 11.16, 13.26, 10.93, 11.76, 10.77, 10.56, 10.71, 18.579, 10.0, 11.191, 15.02, 11.97, 14.16, 11.699, 10.151, 11.25, 11.13, 10.44, 11.25, 11.37, 10.72, 11.899, 10.5, 12.601, 12.56, 13.74, 11.95, 10.83, 10.41, 10.83, 16.77, 11.4, 17.881, 10.24, 10.71, 10.46, 12.43, 15.29, 14.14, 10.02, 13.5, 11.91, 13.758, 10.722, 13.2, 17.21, 10.92, 11.24, 10.53, 12.41, 12.34, 13.17, 11.22, 11.22, 12.3, 16.52, 11.25, 10.65, 10.44, 10.16, 11.43, 13.14, 10.74, 20.03, 10.86, 10.87, 13.89, 11.43, 13.33, 11.82, 12.31, 13.38, 12.33, 22.44, 21.18, 14.87, 12.67, 14.33, 10.17, 12.18, 11.24, 11.754, 10.936, 12.67, 11.17, 12.0, 14.04, 12.12, 10.89, 14.36, 11.11, 11.0, 10.68, 10.11, 11.1, 14.95, 15.38, 17.49, 15.18, 11.07, 11.871], "stet": [[0, 13.27], [13.27, 24.22], [24.22, 35.47], [35.47, 49.81], [49.81, 60.790000000000006], [60.790000000000006, 75.37], [75.37, 91.18], [91.18, 103.79], [103.79, 115.35000000000001], [115.35000000000001, 125.86000000000001], [125.86000000000001, 137.56], [137.56, 148.96], [148.96, 159.82], [159.82, 173.41], [173.41, 184.48], [184.48, 197.62], [197.62, 209.20000000000002], [209.20000000000002, 223.63000000000002], [223.63000000000002, 238.28000000000003], [238.28000000000003, 253.35000000000002], [253.35000000000002, 264.95000000000005], [264.95000000000005, 280.53000000000003], [280.53000000000003, 291.89000000000004], [291.89000000000004, 303.90000000000003], [303.90000000000003, 316.09000000000003], [316.09000000000003, 328.6], [328.6, 341.99], [341.99, 352.3], [352.3, 363.40000000000003], [363.40000000000003, 373.45000000000005], [373.45000000000005, 385.81000000000006], [385.81000000000006, 397.39000000000004], [397.39000000000004, 411.50000000000006], [411.50000000000006, 422.82000000000005], [422.82000000000005, 433.35], [433.35, 443.85], [443.85, 456.99], [456.99, 468.75], [468.75, 479.31], [479.31, 490.62], [490.62, 504.36], [504.36, 516.308], [516.308, 526.95], [526.95, 537.7800000000001], [537.7800000000001, 550.4700000000001], [550.4700000000001, 564.4200000000002], [564.4200000000002, 574.4700000000001], [574.4700000000001, 587.1500000000001], [587.1500000000001, 600.3800000000001], [600.3800000000001, 624.0300000000001], [624.0300000000001, 636.2600000000001], [636.2600000000001, 653.3400000000001], [653.3400000000001, 666.2200000000001], [666.2200000000001, 676.8000000000002], [676.8000000000002, 689.6700000000002], [689.6700000000002, 706.1100000000002], [706.1100000000002, 719.1900000000003], [719.1900000000003, 731.2100000000003], [731.2100000000003, 742.9000000000003], [742.9000000000003, 754.5100000000003], [754.5100000000003, 765.9400000000003], [765.9400000000003, 778.3300000000003], [778.3300000000003, 790.0900000000003], [790.0900000000003, 801.1900000000003], [801.1900000000003, 820.5400000000003], [820.5400000000003, 833.3000000000003], [833.3000000000003, 845.1400000000003], [845.1400000000003, 858.9400000000003], [858.9400000000003, 880.5900000000003], [880.5900000000003, 897.5250000000002], [897.5250000000002, 909.2700000000002], [909.2700000000002, 922.9700000000003], [922.9700000000003, 938.2900000000003], [938.2900000000003, 950.5000000000003], [950.5000000000003, 961.3000000000003], [961.3000000000003, 972.3700000000003], [972.3700000000003, 983.2900000000003], [983.2900000000003, 994.0800000000003], [994.0800000000003, 1007.9100000000003], [1007.9100000000003, 1019.2600000000003], [1019.2600000000003, 1030.8580000000004], [1030.8580000000004, 1047.6300000000003], [1047.6300000000003, 1057.7400000000002], [1057.7400000000002, 1069.0790000000002], [1069.0790000000002, 1079.5490000000002], [1079.5490000000002, 1090.8690000000001], [1090.8690000000001, 1101.8090000000002], [1101.8090000000002, 1115.0190000000002], [1115.0190000000002, 1125.7290000000003], [1125.7290000000003, 1136.1990000000003], [1136.1990000000003, 1150.6290000000004], [1150.6290000000004, 1164.1290000000004], [1164.1290000000004, 1175.4840000000004], [1175.4840000000004, 1186.4590000000003], [1186.4590000000003, 1200.3790000000004], [1200.3790000000004, 1211.2590000000005], [1211.2590000000005, 1234.1740000000004], [1234.1740000000004, 1244.4590000000005], [1244.4590000000005, 1254.7290000000005], [1254.7290000000005, 1265.8090000000004], [1265.8090000000004, 1276.7990000000004], [1276.7990000000004, 1289.0890000000004], [1289.0890000000004, 1300.7290000000005], [1300.7290000000005, 1314.1790000000005], [1314.1790000000005, 1328.8880000000006], [1328.8880000000006, 1341.8990000000006], [1341.8990000000006, 1353.3690000000006], [1353.3690000000006, 1366.0790000000006], [1366.0790000000006, 1380.4890000000007], [1380.4890000000007, 1391.0790000000006], [1391.0790000000006, 1405.6190000000006], [1405.6190000000006, 1416.7790000000007], [1416.7790000000007, 1428.5090000000007], [1428.5090000000007, 1443.4290000000008], [1443.4290000000008, 1453.5390000000007], [1453.5390000000007, 1464.2490000000007], [1464.2490000000007, 1474.5790000000006], [1474.5790000000006, 1488.5190000000007], [1488.5190000000007, 1498.5690000000006], [1498.5690000000006, 1508.9180000000006], [1508.9180000000006, 1523.3190000000006], [1523.3190000000006, 1536.3690000000006], [1536.3690000000006, 1547.2290000000005], [1547.2290000000005, 1558.2690000000005], [1558.2690000000005, 1569.9690000000005], [1569.9690000000005, 1581.9380000000006], [1581.9380000000006, 1592.1390000000006], [1592.1390000000006, 1606.0290000000007], [1606.0290000000007, 1617.4690000000007], [1617.4690000000007, 1628.8390000000006], [1628.8390000000006, 1641.0690000000006], [1641.0690000000006, 1654.5390000000007], [1654.5390000000007, 1666.2540000000006], [1666.2540000000006, 1679.2840000000006], [1679.2840000000006, 1690.4140000000007], [1690.4140000000007, 1703.9890000000007], [1703.9890000000007, 1715.3240000000008], [1715.3240000000008, 1728.2340000000008], [1728.2340000000008, 1739.7040000000009], [1739.7040000000009, 1753.7740000000008], [1753.7740000000008, 1767.2940000000008], [1767.2940000000008, 1781.3940000000007], [1781.3940000000007, 1794.3640000000007], [1794.3640000000007, 1806.6640000000007], [1806.6640000000007, 1818.1940000000006], [1818.1940000000006, 1828.5940000000007], [1828.5940000000007, 1846.5740000000008], [1846.5740000000008, 1859.3240000000008], [1859.3240000000008, 1872.1640000000007], [1872.1640000000007, 1882.5440000000008], [1882.5440000000008, 1892.7340000000008], [1892.7340000000008, 1905.134000000001], [1905.134000000001, 1917.6940000000009], [1917.6940000000009, 1928.7340000000008], [1928.7340000000008, 1941.2240000000008], [1941.2240000000008, 1954.4540000000009], [1954.4540000000009, 1964.6840000000009], [1964.6840000000009, 1984.7540000000008], [1984.7540000000008, 1995.664000000001], [1995.664000000001, 2006.7440000000008], [2006.7440000000008, 2018.0040000000008], [2018.0040000000008, 2029.0340000000008], [2029.0340000000008, 2039.5640000000008], [2039.5640000000008, 2049.614000000001], [2049.614000000001, 2063.0640000000008], [2063.0640000000008, 2075.6930000000007], [2075.6930000000007, 2085.7440000000006], [2085.7440000000006, 2096.3940000000007], [2096.3940000000007, 2106.8940000000007], [2106.8940000000007, 2119.3240000000005], [2119.3240000000005, 2130.8130000000006], [2130.8130000000006, 2141.0920000000006], [2141.0920000000006, 2152.3730000000005], [2152.3730000000005, 2164.4530000000004], [2164.4530000000004, 2184.4330000000004], [2184.4330000000004, 2200.0720000000006], [2200.0720000000006, 2215.7030000000004], [2215.7030000000004, 2227.4930000000004], [2227.4930000000004, 2237.6230000000005], [2237.6230000000005, 2252.7820000000006], [2252.7820000000006, 2265.3930000000005], [2265.3930000000005, 2276.8730000000005], [2276.8730000000005, 2288.9730000000004], [2288.9730000000004, 2301.4330000000004], [2301.4330000000004, 2314.8130000000006], [2314.8130000000006, 2327.1120000000005], [2327.1120000000005, 2339.7230000000004], [2339.7230000000004, 2354.4130000000005], [2354.4130000000005, 2366.3620000000005], [2366.3620000000005, 2378.7730000000006], [2378.7730000000006, 2390.1430000000005], [2390.1430000000005, 2406.1480000000006], [2406.1480000000006, 2416.9030000000007], [2416.9030000000007, 2429.553000000001], [2429.553000000001, 2445.783000000001], [2445.783000000001, 2457.853000000001], [2457.853000000001, 2468.283000000001], [2468.283000000001, 2478.5030000000006], [2478.5030000000006, 2490.303000000001], [2490.303000000001, 2506.998000000001], [2506.998000000001, 2519.973000000001], [2519.973000000001, 2532.183000000001], [2532.183000000001, 2544.483000000001], [2544.483000000001, 2558.733000000001], [2558.733000000001, 2571.003000000001], [2571.003000000001, 2583.773000000001], [2583.773000000001, 2597.132000000001], [2597.132000000001, 2608.153000000001], [2608.153000000001, 2619.9530000000013], [2619.9530000000013, 2631.3220000000015], [2631.3220000000015, 2642.2430000000013], [2642.2430000000013, 2653.4220000000014], [2653.4220000000014, 2663.7330000000015], [2663.7330000000015, 2675.1320000000014], [2675.1320000000014, 2686.2230000000013], [2686.2230000000013, 2698.653000000001], [2698.653000000001, 2709.8030000000012], [2709.8030000000012, 2721.2030000000013], [2721.2030000000013, 2732.0530000000012], [2732.0530000000012, 2744.7430000000013], [2744.7430000000013, 2756.1830000000014], [2756.1830000000014, 2768.113000000001], [2768.113000000001, 2779.273000000001], [2779.273000000001, 2792.5330000000013], [2792.5330000000013, 2803.463000000001], [2803.463000000001, 2815.2230000000013], [2815.2230000000013, 2825.9930000000013], [2825.9930000000013, 2836.5530000000012], [2836.5530000000012, 2847.2630000000013], [2847.2630000000013, 2865.8420000000015], [2865.8420000000015, 2875.8420000000015], [2875.8420000000015, 2887.0330000000013], [2887.0330000000013, 2902.0530000000012], [2902.0530000000012, 2914.023000000001], [2914.023000000001, 2928.183000000001], [2928.183000000001, 2939.882000000001], [2939.882000000001, 2950.033000000001], [2950.033000000001, 2961.283000000001], [2961.283000000001, 2972.413000000001], [2972.413000000001, 2982.853000000001], [2982.853000000001, 2994.103000000001], [2994.103000000001, 3005.473000000001], [3005.473000000001, 3016.1930000000007], [3016.1930000000007, 3028.0920000000006], [3028.0920000000006, 3038.5920000000006], [3038.5920000000006, 3051.1930000000007], [3051.1930000000007, 3063.7530000000006], [3063.7530000000006, 3077.4930000000004], [3077.4930000000004, 3089.443], [3089.443, 3100.273], [3100.273, 3110.683], [3110.683, 3121.513], [3121.513, 3138.283], [3138.283, 3149.683], [3149.683, 3167.564], [3167.564, 3177.8039999999996], [3177.8039999999996, 3188.5139999999997], [3188.5139999999997, 3198.9739999999997], [3198.9739999999997, 3211.4039999999995], [3211.4039999999995, 3226.6939999999995], [3226.6939999999995, 3240.8339999999994], [3240.8339999999994, 3250.8539999999994], [3250.8539999999994, 3264.3539999999994], [3264.3539999999994, 3276.263999999999], [3276.263999999999, 3290.021999999999], [3290.021999999999, 3300.7439999999992], [3300.7439999999992, 3313.943999999999], [3313.943999999999, 3331.153999999999], [3331.153999999999, 3342.073999999999], [3342.073999999999, 3353.313999999999], [3353.313999999999, 3363.843999999999], [3363.843999999999, 3376.253999999999], [3376.253999999999, 3388.593999999999], [3388.593999999999, 3401.763999999999], [3401.763999999999, 3412.983999999999], [3412.983999999999, 3424.203999999999], [3424.203999999999, 3436.503999999999], [3436.503999999999, 3453.023999999999], [3453.023999999999, 3464.273999999999], [3464.273999999999, 3474.923999999999], [3474.923999999999, 3485.363999999999], [3485.363999999999, 3495.523999999999], [3495.523999999999, 3506.953999999999], [3506.953999999999, 3520.0939999999987], [3520.0939999999987, 3530.8339999999985], [3530.8339999999985, 3550.8639999999987], [3550.8639999999987, 3561.723999999999], [3561.723999999999, 3572.5939999999987], [3572.5939999999987, 3586.4839999999986], [3586.4839999999986, 3597.9139999999984], [3597.9139999999984, 3611.2439999999983], [3611.2439999999983, 3623.0639999999985], [3623.0639999999985, 3635.3739999999984], [3635.3739999999984, 3648.7539999999985], [3648.7539999999985, 3661.0839999999985], [3661.0839999999985, 3683.5239999999985], [3683.5239999999985, 3704.7039999999984], [3704.7039999999984, 3719.5739999999983], [3719.5739999999983, 3732.2439999999983], [3732.2439999999983, 3746.5739999999983], [3746.5739999999983, 3756.7439999999983], [3756.7439999999983, 3768.923999999998], [3768.923999999998, 3780.163999999998], [3780.163999999998, 3791.917999999998], [3791.917999999998, 3802.853999999998], [3802.853999999998, 3815.523999999998], [3815.523999999998, 3826.693999999998], [3826.693999999998, 3838.693999999998], [3838.693999999998, 3852.733999999998], [3852.733999999998, 3864.853999999998], [3864.853999999998, 3875.743999999998], [3875.743999999998, 3890.103999999998], [3890.103999999998, 3901.213999999998], [3901.213999999998, 3912.213999999998], [3912.213999999998, 3922.893999999998], [3922.893999999998, 3933.003999999998], [3933.003999999998, 3944.103999999998], [3944.103999999998, 3959.053999999998], [3959.053999999998, 3974.433999999998], [3974.433999999998, 3991.9239999999977], [3991.9239999999977, 4007.1039999999975], [4007.1039999999975, 4018.1739999999977], [4018.1739999999977, 4030.044999999998]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1067, 1667, 2123, 3162, 4031]}
{"example_id": "mit035@@MIT8_04S16_lec02_300k", "text": [" We spoke about superposition, and we  showed how, when you have two states that are superimposed,  the resulting state that is built up ", "doesn't have properties that are intermediate between the two  states that you're superimposing.  But rather, when you do a measurement,  you obtain the result that you would sometimes-- ", "you sometimes obtain the result that you  would have with one of the states,  and some other times with different probabilities,  the result as if you had the other state. ", "So it's a strange kind of way in which things are  combined in quantum mechanics.   So the next thing we have to say is a physical assumption ", "that is made here.  And it is that if you have a state  and you superimpose it to itself,  you haven't done anything. ", "So the superposition of a state with itself  has no physical import.  So we can say this. ", "A physical assumption superimposing a state to itself ", "does not change the physics.  ", "So if I have a state, this is physically equivalent--  I'll write physically equivalent with this symbol-- ", "to the state a plus a, which would be 2 times a.  It's physically equivalent to the state minus a. ", "It's physically equivalent to the state ia on anything.  It's not equivalent to 0a, because that  would be the zero state. ", "So it's physically equivalent as long  as you have a non-zero coefficient.  All these states are supposed to be physically equivalent. ", "And that will eventually mean that we sometimes  choose a particular one in those collection of states  that is one that is convenient to work with. ", "And that will be called a normalized state, a state that  satisfies other properties having  to do with the norm squared of the state. ", "That will come later.  But it's important that the number that  is multiplying the physical state of your system  has no relevance. ", "And you could say, well, why all of the sudden you tell us this.  Could this be shown to be necessary?  Or it's a physical assumption, so can we test it? ", "Does it make some sense?  And we can make some sense of this assumption at this level.  And we do it with states of light.  So remember, we spoke about photons hitting a polarizer. ", "And we could speak of two independent kind of photons--  photons polarized along the x-axis and a photon polarized ", "along the y-axis.   And those are two quantum mechanical states.   Now suppose I decide to superimpose ", "those states to create the most general photon state.  I would have an alpha, which is a number here,  a complex number, and a beta there. ", "And I would say, OK, here is my most general photon state.  And how many parameters does this state have?  It has two complex parameters, alpha and beta, and therefore, ", "four real parameters.  And then you think about polarization states,  how many parameters they have. ", "And as we'll review in a second, it's well known that photons--  their polarization state can be expressed  with just two real parameters. ", "So some counting is not going very well here.  But here comes the help.  If the overall coefficient here doesn't matter-- ", "if I can change it, I can multiply everything  by 1 over alpha, and therefore get that the state is just ", "the same, physically equivalent to this state,  beta over alpha photon y. ", "So all the physics is contained in this state as well.  And if all the physics is contained in that state,  I must look how many parameters it has. ", "It still looks like there's two numbers here,  but only the ratio appears.  So if you call beta over alpha, the number gamma ", "is just one complex parameter.   And therefore, thanks to this assumption, ", "you now get that the most general photon polarization  state has just one complex parameter, or just ", "equivalently, two real parameters.   And that is the correct number. ", "Indeed, if you have a polarization, a wave that  has some polarization, the most general polarization state ", "of a wave is an elliptical polarization.  You probably did study a lot about circular polarizations,  or maybe you also heard about the elliptical one ", "in which the electric field-- in a circular polarization,  the electric field at any point traces a circle.  But if you have an elliptical polarization,  the electric field traces an ellipse. ", " And that ellipse has an angle that is one parameter. ", "And for an ellipse, the other--  the size doesn't matter.  The size depends just on the magnitude  of the electric field.  It's not a parameter of the polarization of the wave. ", "Since the size doesn't matter, it's  the shape of the ellipse that matters.  And that's characterized by the eccentricity or by the ratio  a over b of the semi-major axis, so parameters, two parameters, ", "and they are a over b and theta.  So an elliptically polarized wave,  which is the most general state of polarization of a wave, ", "has two real parameters.  And now, thanks to this physical assumption, we get this right.  And this is important because that's ", "something we're going to use all the time,  that the overall factor in a wave function does not matter.   So if we have superpositions, I want ", "to emphasize one more thing about superpositions.  And for that, I'm going to use spins.  ", "So what is spin?  Spin is a property of elementary particles  that says that actually, even if they're not ", "rotating around some other particle,  they have angular momentum.  They have intrinsic angular momentum,  as if they would be made of a tiny little ball that ", "is spinning.  I say as if because nobody has ever  constructed a model of an elementary particle  where you can really make it spin and calculate ", "how it works.  Somehow, this elementary particle  has angular momentum is born.  Even if it is a point particle, it has angular momentum, ", "and it's spin.  And spin is very quantum mechanical.  And we can't quite understand it without it. ", "So what happens is that you can measure the spin of a particle.  And then if you measure it, you have  to decide, however, since angular momentum is a vector, ", "what direction you should use.  And suppose you use the z direction  to measure the spin of a particle.  You may find that the particle has either spin up ", "or the particle has spin down.  Spin.   And the spin is the direction of the angular momentum. ", "And that's a funny thing that happens with most matter  particles.  These are spin 1/2 particles.  The spin can be up or it can be down along the z direction ", "that you measure.  You measure it, and you never find it's 0 or a little bit.  It's just either up with the full magnitude  or down with the full magnitude. ", "That is a spin 1/2 particle.  And the state where it is up, we sometimes denote it  with an arrow up and call it z because it's up along z. ", "And this would be down, an arrow down along z.  ", "If those are possible quantum states,  you could build a new quantum state  by superposition which would be up along z plus down along z. ", " Now, if I wish to normalize it, I  would put the factor in front of this. ", "I will not talk about normalizations at this moment.  They're not so important.   If you are faced with this quantum state-- ", "so suppose you have an electron that is not in this state  nor in this state, but is in this state, in a quantum ", "superposition.  So you go and you decide to try to measure it.  Now, since you cannot predict what that electron is going ", "to be doing--  we cannot predict things in quantum mechanics with  certainty--  we, since we're going to do this experiment,  avail ourselves of 1,000 copies of this electron, all of them ", "in this peculiar quantum state.  So you have the 1,000 copies, and you start measuring.  And you decide to measure the spin in the z direction. ", "And now what do you get?  Well, we mentioned last time that you don't get an average,  or since this is up and this is down, you get 0.  You measure the first particle and you find it up. ", "Measure the second, up, the third, up, the fourth, down,  five, down.  And then you get a series of measurements.  At the end of the 1,000 particles, you find about 495 ", "up and 505 down, about half and half.  And if you did it with 10,000 particles,  maybe it would be closer. ", "Eventually, you'll find 50% in this state  and find 50% in this state. ", " And if you think this is strange, which you probably do, ", "well, you could be justified.  But here would come Einstein along  and would say all this stuff of this superposition ", "is not quite right.  You had this 1,000 particles.  But actually, those 1,000 particles, half of them ", "were with a spin up and half of them were with a spin down.  So here you have your 1,000 particles,  your quantum state, this.  But Einsten says, no, let's make an ensemble of 1,000 particles, ", "500 up, 500 down, and do the same experiment.  And the result is going to be the same.  So how do you know you really have this as opposed ", "to somebody has given you 1,000 particles, 500 up, 500 down?  How can you tell?  And in fact, he would say even more-- ", "whenever Einstein used the word realism  to say if I measure a spin and I find it up, ", "it's because before I measured it, the spin was up.  It's almost like learning something about an object.  If I look at this page and I find the color red, ", "it's because before I looked at it, it was red.   But then in quantum mechanics, that  doesn't seem to be the case. ", "The state is this mix.  And it was this mix before you measured.  And after you measure, it's this.  So there is no such thing as you learn ", "by doing one measurement what the state of the particle was.  So we will not resolve Einstein's paradox ", "completely here because we would have to learn more about spins,  which you will do soon enough.  But here's the catch that actually happens. ", "If, instead of having an ensemble of quantum states,  you would have an ensemble of those states that half of them  are up and half of them are down, ", "you could now decide to measure the spin of the particle  along the x direction.  You take these particles, and you measure along x. ", "And what you will calculate with quantum mechanics  later in this course--  if you measure along x, in this state,  you will find all of them to be pointing along plus, up ", "along x, all of them.  While on this Einstein ensemble of 50% up and 50% down, ", "you would find 50% up along x and 50% down along x.  So there is an experiment that can tell the difference, ", "but you have to look in another direction.  And that experiment, of course, can be done.  And it's a calculation that can be done,  and you can decide whether these quantum states exist. ", "BARTON ZWIEBACH: Let's talk now about entanglement.  ", "So we talk about entanglement when we have  two non-interacting particles.  You don't need a strong interaction between particles  to produce entanglement, the particles ", "can be totally non-interacting.  Suppose particle 1 can be in any of these states--  ", "u 1, u 2.  Let's assume just u 1 and u 2.  And particle 2 can be in states v 1 and v 2. ", " And you have these two particles flying around,  these are possible states of particle 1 ", "and possible states of particle 2.  Now you want to describe the full system, the quantum  state of the two particles.  States of the two particles. ", " Two particles.   Well, it seems reasonable that to describe ", "the state of the two particles that are not interacting,  I should tell you what particle 1 is doing  and what particle 2 is doing.  OK, so particle 1 could be doing this. ", "Could be u 1.  And particle 2 could be doing v 1.  ", "And in a sense, by telling you that,  we've said what everything is doing.  Particle 1 is doing u 1, particle 2 is doing u 2.  And mathematically, we like to make this look like a state ", "and we want to write it in a coherent way.  And we sort of multiply these two things,  but we must say sort of multiply, ", "because this strange multiplication, this,  you know, we think of them as vectors or states,  so how do you multiply states?  So you put something called the tensor ", "product, a little multiplication like this.   So you could say, don't worry, it's kind of like a product, ", "and it's the way we do it.  We don't move things across, the first state here,  the second state here, and that's a possible state.  ", "Now, I could have a different state.  Because particle 1, in fact, could be doing  something a little different. ", "Could be doing alpha 1 u 1 plus alpha 2 u 2,  and maybe particle 2 is doing beta 1 v 1 plus beta 2 v 2. ", " And this would be all right.  I'm telling you what particle 1 is doing and I'm telling you  what particle 2 is doing and the rules ", "of tensor multiplication or this kind of multiplication  to combine those states are just like a product,  except that as I said, you never move the states across. ", "So you just distribute, so you have alpha 2, beta 1,  the number goes out, u 1 v 1-- ", "that's the first factor--  plus alpha 1 beta 2 u 1 v 2 plus alpha 2 beta 1 u 2 v 1 ", "plus alpha 2 beta 2 u 2 v 2. ", "I think I got it right.  Let me know.   I just multiplied and got the numbers out. ", "The numbers can be move out across this product.  OK, so that's a state and that's a superposition of states,  so actually, I could try to write a different state now. ", "You see, we're just experimenting, but here  is another state.  u 1 v 1 plus u 2 v 2. ", " Now this is a state that actually seems different. ", "Quite different.  Because I don't seem to be able to say  that what particle 1 is doing and what  particle 2 is doing separately. ", "You see, I can say when particle 1 is doing u 1,  particle 2 is doing v 1.  And if when particle 1 is doing u 2, this is v 2. ", "But can I write this as some state  of the first particle times some state of the second particle?  ", "Well, let's see.  Maybe I can and can write it in this form.  This is the most general state that you can say, ", "particle 1 is doing this, and particle 2 is doing that.  So can they do that?  Well, I can compare these two terms with those ", "and they conclude that alpha 1 beta 1 must be 1.  ", "Alpha 2 beta 2 must be also 1.  But no cross products exist, so alpha 1 beta 2 must be 0 ", "and alpha 2 beta 1 must be 0.  And that's a problem because either alpha 1  is 0, which is inconsistent, or beta 2 ", "is 0, which is inconsistent with that,  so now this state is un-factorizable.   It's a funny state in which you cannot say that this quantum ", "state can be described by telling what the first particle  is doing and what the second particle is doing.  What the first particle is doing depends on the second  and what the second is doing depends on the first. ", "This is an entangled state.  ", "And then we can build entangled states and our very strange  states.  So with two particles with spins, ", "for example, we can build an entangled states of 2  spin 1/2 particles.  ", "And this state could look like this--  the first particle is up along z and the second particle is  down along z, plus a particle that ", "is down along z for the first particle,  but the second is up along z.  ", "And these are 2 spin 1/2 particles  and in the usual notation, these experiments in quantum  mechanics and black hole physics,  people speak of Alice and Bob. ", "Alice has one particle, Bob has the other particle.  Maybe Alice is in the moon and has her electron  and Bob is on earth and has his electron, ", "and the two electrons, one on the earth and in the moon,  are in this state.  So then we say that Alice and Bob share an entangled pair. ", "And all kinds of strange things happen.  People can do those things in the lab-- not quite one  in the earth and one in the moon,  but one photon at one place and another photon ", "entangled with it at 100 kilometers away,  that's pretty doable.  And they are in this funny state in which their properties are ", "currently that in surprising ways.  So what happens here?  Suppose Alice goes-- or let's say ", "Bob goes along and measures his spin  and he finds his spin down.  So-- oh, you look here, oh, here is down for Bob. ", "So at this moment, the whole state collapses into this.  Because up with Bob didn't get realized.  So once Bob measures and he finds down, ", "the whole state goes into this.  So if Alice-- on the moon or in another galaxy--  at that instant looks at her spin,  she will find it's up before light ", "has had time to get there.  Instantaneously.  It will go into this state.  People were sure somehow this violates special relativity. ", "It doesn't.  You somehow when you think about this carefully,  you can't quite send information,  but the collapse is instantaneous  in quantum mechanics. ", "Somehow, Bob and Alice cannot communicate information  by sharing this entangled pair, but it's an interesting thing  why it cannot happen. ", "Einstein again objected to this.  And he said, this is a fake thing.   You guys are going to share-- ", "and now, of course, they have to share many entangled pairs  to do experiments, so maybe 1,000 entangled pairs.  And Einstein would say, no, that's not what's happening. ", "What's happening is that some of your entangled pairs are this.  That is, Bob is down, Alice is up, some of them are this-- ", "and there's no such thing as this entanglement  and indeed, if you measure and you find down,  she will find up, and if you measure and you find up,  she will find down, and there's nothing too mysterious here. ", "But then came John Bell in 1964 and discovered his Bell  inequalities that demonstrated that if Alice and Bob can ", "measure in three different directions,  they will find correlations that are impossible to explain  with classical physics. ", "It took a lot of originally for Bell to discover this,  that you have to measure in three directions,  and therefore, the kind of correlations  that appear in entangled states are very subtle and pretty ", "difficult to disentangle.  So that's why entanglement is a very peculiar subject.  People think about it a lot because it's very mysterious. ", "It somehow violates classical notions,  PROFESSOR: Mach-Zehnder--   interferometers. ", " And we have a beam splitter.  ", "And the beam coming in, it splits into 2.  A mirror--   another mirror.  The beams are recombined into another beam splitter. ", "And then, 2 beams come out.  One to a detector d0--   and a detector d1.  ", "We could put here any kind of devices in between.  We could put a little piece of glass,  which is a phase shifter.  We'll discuss it later. ", "But our story is a story of a photon  coming in and somehow leaving through the interferometer.  ", "And we want to describe this photon in quantum mechanics.  And we know that the way to describe it  is through a wave function.  But this photon can live in either of 2 beams. ", "If a photon was in 1 beam, I could  have a number that tells me the probability to be in that beam.  But now, it can be in either of 2 beams. ", "Therefore, I will use two numbers.  And it seems reasonable to put them in a column vector.  Two complex numbers that give me the probability amplitudes-- ", " for this photon to be somewhere.  So you could say, oh, look here.  What is the probability that we'll find this photon over  here?  Well, it may depend on the time. ", "I mean, when the photon is gone, it's gone.  But when it's crossing here, what is the probability?  And I have 2 numbers.  What is the probability here, here, here, here? ", "And in fact, you could even have 1 photon  that is coming in through 2 different channels, as well.  So I have 2 numbers. ", "And I want, now, to do things in a normalized way.  So this will be the probability amplitude to be here.  This is the probability amplitude to be down. ", "And therefore, the probability to be in the upper one--  you do norm squared.  The probability to be in the bottom one,  you do norm squared. ", "And you get 1.  Must get 1.  So if you write 2 numbers, they better satisfy that thing.  Otherwise, you are not describing probabilities. ", " On the other hand, I may have a state that is like this.  Alpha-- oh, I'll mention other states. ", "State 1-0 is a photon in the upper beam.  ", "No probability to be in the lower beam.  And state 0-1 is a photon in the lower beam.  ", "So these are states.  And indeed--   think of superposition.  And we have that the state, alpha beta-- ", "you know how to manipulate vectors--  can be written as alpha 1-0.  Because the number goes in and becomes alpha 0. ", "Plus beta 0-1.   So the state, alpha beta, is a superposition  with coefficient alpha of the state in the upper beam ", "plus the superposition with coefficient beta  of the state in the lower beam.  We also had this little device, which ", "is called the beam shifter of face delta.  If the probability amplitude completing  is alpha to the left of it, it's alpha ", "e to the i delta to the right of it, with delta a real number.  So this is a pure phase.  And notice that alpha is equal to e to the i delta. ", "The norm of a complex number doesn't change when  you multiply it by a phase.  The norm of a complex number times a phase  is the norm of the complex number  times the norm of the phase. ", "And the norm of any phase is 1.  So actually, this doesn't absorb the photon,  doesn't generate more photons. ", "It preserves the probability of having a photon there,  but it changes the phase.   How does the beam splitter work, however? ", "This is the first thing we have to model here.  So here is the beam splitter.   And you could have a beam coming--  ", "A 1-0 beam hitting it.  So nothing coming from below.  And something coming from above.  And then, it would reflect some and transmit some. ", "And here is a 1--  is the 1 of the 1-0.  And here's an s and a t.  Which is to mean that this beam splitter takes the 1-0 photon ", "and makes it into an st photon.  Because it produces a beam with s up and t down.  ", "On the other hand, that same beam splitter-- now,  we don't know what those numbers s and t are.  That's part of designing a beam splitter.  You can ask the engineer what are s ", "and t for the beam splitter.  But we are going to figure out what are the constraints.  Because no engineer would be able to make a beam splitter ", "with arbitrary s and t.   In particular, you already see that if 1-0--  if a photon comes in, probability conservation, ", "there must still be a photon.  You need that s squared plus t squared is equal to 1  because that's a photon state.  Now, you may also have a photon coming from below ", "and giving you uv.  So this would be a 0-1 photon, giving you uv.  ", "And therefore, we would say that 0-1--   gives you uv.  And you would have u plus v norm squared is equal to 1. ", "So we need, apparently, 4 numbers  to characterize the beam splitter.  And let's see how we can do that.  ", "Well, why do we need, really, 4 numbers?  Because of linearity.  So let's explore that a little more clearly. ", "And suppose that I ask you, what happens to an alpha beta  state--   alpha beta state if it enters a beam splitter? ", "What comes out?  Well, the alpha beta state, as you know,  is alpha 1-0 plus beta 0-1. ", "And now, we can use our rules.  Well, this state, the beam splitter is a linear device.  So it will give you alpha times what it makes out of the 1-0. ", "But out of the 1-0 gives you st.   And the beta times 0-1 will give you beta uv. ", "So this is alpha s plus beta u times alpha t  plus beta v. And I can write this, actually, as alpha beta ", "times the matrix, s u t v.  And you get a very nice thing, that the effect of the beam ", "splitter on any photon state, alpha beta,  is to multiply it by this matrix, s u t v. ", "So this is the beam splitter.  The beam splitter acts on any photon state.  And out comes the matrix times the photon state.  ", "This is matrix action, something that is going  to be pretty important for us.   How do we get those numbers? ", "After all, the beam splitter is now  determined by these 4 numbers and we  don't have enough information.  So the manufacturer can tell you that maybe you've got-- ", "you bought a balanced beam splitter.  Which means that if you have a beam, half of the intensity  goes through, half of the intensity gets reflected. ", "That's a balanced beam splitter.  That simplifies things because the intensity  here, the probability, [INAUDIBLE]  must be the same as that.  So each norm squared must be equal to 1/2, ", "if you have a balanced--   beam splitter.   And you have s squared equal t squared equal u squared ", "equal v squared equal 1/2.  But that's still far from enough to determine s, t, u, and v. So ", "rather than determining, them at this moment,  might as well do a guess.  So can it be that the beam splitter matrix-- ", "Could it be that the beam splitter matrix  is 1 over square root of 2, 1 over square root of 2,  1 over the square root of 2, and 1 over square root of 2. ", "That certainly satisfies all of the properties  we've written before.   Now, why could it be wrong?  Because it could be pluses or minuses or it could be i's ", "or anything there.  But maybe this is right.  Well, if it is right, the condition that it be right ", "is that, if you take a photon state, 1 photon--  after the beam splitter, you still have 1 photon.  So conservation of probability. ", "So if you act on a normalized photon  state that satisfies this alpha squared plus beta squared  equal 1, it should still give you a normalized photon state. ", "And it should do it for any state.  And presumably, if you get any numbers that satisfy that,  some engineer will be able to build that beam splitter ", "for you because it doesn't contradict  any physical principle.  So let's try acting on this with on this state-- ", "1 over square root of 2, 1 over square root of 2.   Let's see.  This is normalized-- 1/2 plus 1/2 is 1. ", "So I multiply.  I get 1/2 plus 1/2 is 1, and 1.  Sorry, this is not normalized.  1 squared plus 1 squared is 2, not 1. ", "So this can't be a beam splitter.  No way.  ", "We try minus 1 over square root of 2.  Actually, if you try this for a few examples, it will work. ", "So how about if we tried in general.  So if I try it in general, acting on alpha beta,  I would get 1 over square root of 2 alpha plus beta and alpha ", "minus beta.  Then, I would check the normalization.  So I must do norm of this 1 squared.  So it's 1/2 alpha plus beta squared ", "plus 1/2 alpha minus beta norm squared.   Well, what is this? ", "Let me go a little slow for a second.  [INAUDIBLE] plus beta star.   Plus alpha minus beta. ", "Alpha star minus beta star.   Well, the cross terms vanish. ", "And alpha alpha star, alpha alpha star, beta beta star,  beta beta star add.  So you do get alpha squared plus beta squared. ", "And that's 1 by assumption because you  started with a photon.  So this works.  This is a good beam splitter matrix.  ", "It does the job.  So actually--   Consider this beam splitters. ", "Actually, it's not the unique solution by all means.   But we can have 2 beam splitter that differ a little bit. ", "So I'll call beam splitter 1 and beam splitter 2.  Beam splitter or 1 will have this matrix. ", "And beam splitter 2 will have the matrix were found here,  which is a 1 1 1 minus 1.  So both of them work, actually. ", "And both of them are good beam splitters.  I call this--   beam splitter 1.  ", "And this, beam splitter 2.  And we'll keep that.  And so we're ready, now, to think about our experiments  ", "PROFESSOR: And let me I assume, for example,  that I'll put the state alpha beta in.  Alpha and beta.  What do I get out? ", "So you have this state, alpha beta.  What do you get out?  Well, state comes in and is acted by beam splitter 1. ", "So you must put the beam splitter, 1 matrix.   And then it comes the mirrors. ", "And lets assume mirrors do nothing.  In fact, mirrors-- the two mirrors  would multiply by minus 1, which will have no effect.  So lets ignore mirrors. ", "And then you get to beam splitter 2  and you must multiply by the matrix of beam squared 2.  And that's the output.  ", "And that output is a two-component vector.  That gives you the amplitude up and the amplitude down.  ", "So I should put BS2 here, BS1 over here, alpha beta. ", " The numbers move away, 1 over square root of 2 and 1  over square root of 2.  Commute in matrix multiplication. ", "Then you multiply these two matrices.  You get 0, 2, minus 2, and 0, alpha beta. ", "And you put the 2 in so you get beta minus alpha.  So here is the rule.  If you have alpha and beta, you get, ", "here, beta and minus alpha here, or a beta minus  alpha photon at the end.  ", "Good.  So let's do our first kind of experiment. ", "Our first experiment is to have the beam splitters here.  ", "D0-- detector D0 and detector D1 over there.  And let's send in a photon over here only--  1 or input 0, 1. ", " Well this photon, 0, 1, splits here. ", "You act with BS1--  the matrix BS1.  You get two things.  You act with the matrix BS2, and it gives you this.  But we have the rule already.  If you have an alpha beta, out comes a beta minus alpha. ", "So it should have as 1, here, and minus 0, here, which is 0.  So you get a 1, 0. ", "So what is really happening?   What's really happening is that your photon that came in ", "divided in two, recombined, and, actually,  there was a very interesting interference here.  From the top beam came some amplitude ", "and gave some reflected and some transmitted.  From the bottom beam, there was some transmission  and some reflection. ", "The transmission from the top and reflection from the bottom  interfered, to give 0.  And this, too, the reflection from the top and transmission ", "from the bottom, were coherent and added up to 1.  And every single photon ends up in D0. ", "If you would put the beam--  well, Mach and Zehnder were working  in the late 1800s, 1890s.  And they would shine light. ", "They had no ability to manipulate photons.  But they could put those beam splitters  and they could get this interference effect,  where everything goes to D0. ", "So far, so good.  Now let me do a slightly different experiment.   I will now put the same thing, a BS1 and a beam ", "going in, mirror, mirror, BS2 here.   But now, I will put a block of concrete here on the way. ", " I'll put it like this.   So that if there is any photon that ", "wants to come in this direction, it will be absorbed.  Photon could still go like this, but nothing  would go through here. ", "And here, of course, there might be D0 and D1.   And here are the mirrors, M and M. ", "Now the bottom mirror is of no use  anymore because there is a big block of concrete  that will stop any photon from getting there. ", " And we are asked, again, what happens?  What do the detectors see? ", "And this time, we still have a 01.  Now I would be tempted to use this formula,  but this formula was right under the wrong assumption-- ", "that there was no block here.  So I cannot use that formula.  And certainly, things are going to be different.   So I have to calculate things. ", "And we're doing a quantum mechanical calculation.  Well, up to here, before it reaches here,  I can you do my usual calculation. ", "Certainly, we have BS1 acting on the state, 01,  and this is 1 over square root of 2, I think, minus 1, 1, 1, ", "1.  Yup, that B is 1, acting on 01.  And that gives me 1 over square root of 2,  1 over square root of 2. ", "So, yes, here I have one over square root of 2 amplitude.  And here I also have 1 over square root of 2 amplitude. ", " OK.   Now that's the end of this amplitude. ", "It doesn't follow.  But on the other hand, in this branch,  the mirror doesn't change the amplitude, doesn't absorb.  So you still have 1 over square root of 2 here. ", "And now you're reaching BS2.  Now what is the input for BS2?  The input is a one over square root 2 in the top beam, ", "and nothing in the lower beam because nothing is reaching BS2  from below.   This is blocked.  So yes, there was some times when something reached ", "from below, but nothing here.  So to figure out the amplitudes, here, I  must do BS2 acting on 1 over the square root of 2, 0. ", "Because 1 over square root of 2 is coming in,  but nothing is coming in from below.   And, therefore, I get 1 over the square root of 2, ", "1, 1, 1, minus 1, 1 over square root of 2, 0.  ", "This time, I get 1/2 and 1/2.   OK, we must trust the math. ", "1/2 here and 1/2 there, so 1/2 a column vector, 1/2, 1/2.  ", "OK, let me maybe tabulate this result, which  is somewhat strange, really. ", "So what is strange about it is the following.  In the first case, where the interferometer  was totally clear, nothing in the middle, everything ", "went to D2.  And nothing went into D1.  But now, you do something that should block some photons.  You block some photons in the lower path, ", "and yet, now you seem to be able to get something into D1.  There is an amplitude to get into the D1.  So by blocking a source, you're getting more somewhere. ", "It's somewhat counterintuitive.  You will see by the end of the lecture in 10 minutes,  that it's not just somewhat counterintuitive, ", "it's tremendously counterintuitive.  Let's summarize the result here--  the outcome in the blocked lower branch case and the probability ", "for those events.   So photon at the block-- ", "the photon can end in three places.  It can end on the block.  It can end on the D0.  Or it can end on D1. ", "So photon at the block--  well, the amplitude to be here is one over square root of 2.  The probability should be 1/2.  ", "Photon at D0, probability amplitude, 1/2, probability, ", "1/4--  photon at D1, probability, 1/4.   You could put another table here-- outcome ", "all open, probability.  And in this case, there's just photon at D0.  ", "That's 1.  And photon at D1 was 0.  PROFESSOR: So far so good.  So here is the kind of very entertaining thing ", "that happens when you try to do some physics with this.  And this was done by two physicists, Elitzur and Vaidman ", "in Tel Aviv, they invented or fantasized  about some sort of bombs--  things that explode.  So they're called Elitzur-Vaidman bombs. ", " And you could invent different things,  but here is what an Elitzur-Vaidman bomb is-- ", "some sort of bomb, and the way it works  is with a photon detector.   So there's a little tube in the bomb, ", "and there's a photon detector.  And you have your bomb, and you want  to detonate it-- you send the photon in, ", "you send the photon in through the tube.  And the photon, it's detected by the detector.  And the bomb explodes. ", "On the other hand, if the bomb is defective,  the photon goes in, and the detector doesn't work.  The photon goes out. ", "Just goes through.  So that's an Elitzur-Vaidman bomb.  And here is the puzzle for you-- ", "suppose you have those bombs, and unfortunately, those bombs,  after time, they decay.  And sometimes the detectors go wrong, ", "and they don't work anymore.  So you have 10 bombs, and you know,  maybe five have gone wrong.  ", "And now, you have maybe a very important mission  and you need the bomb that really works.  So what do you do? ", "Let's assume you cannot break apart the detector--  it's just too complicated.  So you have the bombs, and you want to test them.  If you send in a photon and nothing happens, ", "the bomb is not working.  But if you send in a photon, and the bomb is working--  explodes.  So you cannot use it anymore. ", "So the question that Elitzur and Vaidman pose,  is there a way to certify that the bomb is  working without exploding it? ", "Can you do that?   The answer looks absolutely impossible.  And certainly, in classical physics,  it's completely impossible. ", "You either do the measurement to see if the detector works,  and if it works, your lab goes off.  It's totally destroyed.  And if it doesn't work, well, OK, ", "it's not a good bum anyways.  So there's no way out.  But there is a way out, and it is  to insert this bomb in the mass [? center ?] interferometer. ", "So here we go.  We put the mass [? center ?] interferometer, ", "and we insert the bomb here with the detector along this place.  ", "D 0 and D 1 are still here.  ", "And now, you put this, and you send in a photon. ", "So let's see what happens if you send in a photon.  Suppose the bomb is defective--  ", "bomb is defective.   So what are the possible outcomes? ", "Outcome and probability.   Photon goes to D 0-- ", " 0.  Photon to D 1, bomb explodes. ", " Well, we said the bomb is defective.  So if the bomb is defective, we said ", "it's like a detector that doesn't work, and lets  the photons go through.  So if the bomb is defective, it's as if there no bomb here, ", "and you have the situation where all is open.  So there will be a probability of 1 to get the photon to D 0-- ", "a probability of 0 to get the photon to D 1.  And the bomb, of course, doesn't explode--  probability of 0. ", "On the other hand, suppose the bomb is good--  ", "bomb is good.   And then, what are the outcomes?  ", "And what are the probabilities?  ", "Well, you know, more or less, what's happening already.  The bomb is good means there is a detector that never  fails to detect the photon. ", "And if a photon comes in, it will capture it--  it will block it.  The bomb will explode.  So you have your mass [? center ?] interferometer, ", "and you've really done the equivalent of this--  if the bomb is really working.  You've put a block of concrete-- it's ", "going to absorb the photon.  So if the bomb is really working,  the outcome are the following-- ", " well, I'm sorry to say, your lab will explode half of the times, ", "because the photon on the block happens,  and bomb explodes with probability 1/2. ", " On the other hand, in this situation,  it is possible that the photon--  ", "photon-- at D 0, and bomb doesn't explode--  not explode. ", "And there is a probability 1/4.   And there is a probability, 1/4, that the photon is at D 1, ", "and the bomb does not explode.   But here is the catch now-- ", "yes, half of the bombs exploded, we're sorry about that.  But if the bomb doesn't work, there  is no way a photon can reach D 1, because if a bomb doesn't ", "work, all photons go to D 0.  So the fact that some photons, a quarter percent  of the time, 1/4-- ", "25% of the time--  reach D 1 implies that photon is at D 1,  and bomb did not explode. ", "But the bomb is good.  So look what has happened-- it's really strange.  The photon went-- the bomb was here, it was ready to explode. ", "The photons kept the bomb, and ended at D 1,  and you still know that the bomb works now--  even though the photon never went through the detector. ", "It never touched here, it never went inside and get detected.  Somehow it went through the other way,  but you know that the bomb is working, with a quarter percent ", "efficiency.  We will do exercises, and it's possible to raise  the efficiency to 50%.  And if you put the bomb inside a cavity, a resonant cavity ", "with photons going around, you can reach 99% efficiency.  So the probability of blowing up MIT goes down to 1%.  [LAUGHTER] ", "I don't know if we can live with that--  I don't think so.  But anyway, this is a true fact--  experiments without bombs have been done,  and it shows that in quantum mechanics, ", "you can do very surprising measurements. "], "vid_duration": [14.73, 13.17, 11.38, 14.53, 12.03, 11.07, 24.92, 10.51, 10.73, 10.97, 10.6, 12.64, 13.17, 12.02, 10.89, 14.9, 16.54, 15.55, 11.83, 11.04, 13.62, 11.45, 10.12, 10.14, 11.93, 11.5, 11.11, 11.17, 14.19, 10.14, 12.93, 12.14, 10.8, 11.815, 10.765, 12.85, 19.18, 11.83, 10.89, 12.72, 11.35, 10.88, 10.79, 12.23, 11.19, 10.81, 10.82, 14.19, 11.51, 11.67, 11.79, 14.4, 12.74, 17.14, 11.03, 11.91, 10.07, 10.08, 17.15, 12.0, 13.89, 13.888, 10.652, 15.09, 18.43, 12.14, 11.59, 15.21, 11.83, 12.14, 11.01, 13.28, 11.18, 11.54, 10.32, 11.64, 12.48, 13.06, 14.25, 11.11, 11.22, 11.72, 10.33, 11.45, 12.72, 13.63, 11.28, 11.01, 14.0, 13.02, 13.16, 15.68, 11.47, 10.4, 13.57, 10.74, 11.46, 17.01, 14.49, 12.33, 12.54, 21.71, 10.12, 10.28, 20.01, 15.83, 13.46, 12.945, 11.165, 13.38, 11.86, 10.81, 12.55, 15.47, 12.45, 15.18, 12.03, 17.11, 10.56, 15.61, 14.12, 13.26, 12.29, 12.46, 14.29, 13.26, 12.66, 10.63, 11.73, 12.36, 14.37, 13.42, 10.42, 10.77, 11.12, 13.19, 11.41, 15.17, 11.46, 10.47, 15.45, 13.12, 10.181, 12.27, 15.05, 11.52, 11.28, 10.28, 12.48, 11.25, 15.03, 11.409, 11.67, 10.991, 12.84, 11.19, 11.46, 12.81, 10.46, 17.41, 13.78, 10.65, 12.24, 10.18, 10.41, 13.88, 11.5, 10.05, 11.82, 10.776, 15.404, 12.72, 10.64, 12.54, 10.89, 12.53, 14.16, 10.02, 13.48, 12.46, 12.21, 14.52, 12.24, 12.42, 13.43, 14.81, 10.69, 10.38, 11.33, 11.27, 13.63, 10.5, 12.45, 13.66, 11.97, 11.02, 12.86, 14.03, 12.85, 10.3, 10.43, 11.12, 11.67, 13.48, 12.41, 10.44, 10.25, 13.25, 11.2, 11.33, 12.24, 10.27, 10.5, 12.66, 12.36, 10.93, 11.11, 11.04, 11.54, 14.392, 11.2, 13.23, 10.0, 11.02, 12.48, 12.05, 13.48, 10.31, 17.02, 10.92, 12.45, 11.2, 11.55, 11.11, 15.21, 16.54, 10.06, 15.63, 11.91, 10.22, 12.58, 11.55, 11.12, 13.0, 17.93, 15.61, 11.72, 10.17, 15.015, 11.085, 14.88, 12.07, 11.79, 11.76, 11.94, 10.15, 10.35, 11.53, 10.309, 11.311, 12.79, 11.85, 14.72, 10.65, 13.16, 15.74, 10.38, 13.49, 13.72, 13.31, 10.64, 23.4, 11.379, 10.031, 12.219, 12.731, 14.019, 12.721, 12.645, 12.81, 18.509, 11.031, 14.0, 12.409, 11.94, 10.391, 11.04, 12.18, 11.77, 10.79, 12.409, 12.44, 13.071, 11.36, 12.129, 15.31, 11.771, 15.72, 10.518, 10.371, 11.25, 10.5, 12.441, 12.309, 10.77, 12.971, 13.129, 12.481, 11.25, 11.74, 10.909, 12.221, 11.93, 10.119, 13.06, 12.701, 11.975, 12.994, 10.721, 11.16, 10.94, 14.73, 11.25, 11.13, 14.29, 12.45, 11.849, 11.321, 11.0, 12.189, 1.923], "stet": [[0, 14.73], [14.73, 27.9], [27.9, 39.28], [39.28, 53.81], [53.81, 65.84], [65.84, 76.91], [76.91, 101.83], [101.83, 112.34], [112.34, 123.07000000000001], [123.07000000000001, 134.04000000000002], [134.04000000000002, 144.64000000000001], [144.64000000000001, 157.28000000000003], [157.28000000000003, 170.45000000000002], [170.45000000000002, 182.47000000000003], [182.47000000000003, 193.36], [193.36, 208.26000000000002], [208.26000000000002, 224.8], [224.8, 240.35000000000002], [240.35000000000002, 252.18000000000004], [252.18000000000004, 263.22], [263.22, 276.84000000000003], [276.84000000000003, 288.29], [288.29, 298.41], [298.41, 308.55], [308.55, 320.48], [320.48, 331.98], [331.98, 343.09000000000003], [343.09000000000003, 354.26000000000005], [354.26000000000005, 368.45000000000005], [368.45000000000005, 378.59000000000003], [378.59000000000003, 391.52000000000004], [391.52000000000004, 403.66], [403.66, 414.46000000000004], [414.46000000000004, 426.27500000000003], [426.27500000000003, 437.04], [437.04, 449.89000000000004], [449.89000000000004, 469.07000000000005], [469.07000000000005, 480.90000000000003], [480.90000000000003, 491.79], [491.79, 504.51000000000005], [504.51000000000005, 515.86], [515.86, 526.74], [526.74, 537.53], [537.53, 549.76], [549.76, 560.95], [560.95, 571.76], [571.76, 582.58], [582.58, 596.7700000000001], [596.7700000000001, 608.2800000000001], [608.2800000000001, 619.95], [619.95, 631.74], [631.74, 646.14], [646.14, 658.88], [658.88, 676.02], [676.02, 687.05], [687.05, 698.9599999999999], [698.9599999999999, 709.03], [709.03, 719.11], [719.11, 736.26], [736.26, 748.26], [748.26, 762.15], [762.15, 776.038], [776.038, 786.69], [786.69, 801.7800000000001], [801.7800000000001, 820.21], [820.21, 832.35], [832.35, 843.94], [843.94, 859.1500000000001], [859.1500000000001, 870.9800000000001], [870.9800000000001, 883.1200000000001], [883.1200000000001, 894.1300000000001], [894.1300000000001, 907.4100000000001], [907.4100000000001, 918.59], [918.59, 930.13], [930.13, 940.45], [940.45, 952.09], [952.09, 964.57], [964.57, 977.63], [977.63, 991.88], [991.88, 1002.99], [1002.99, 1014.21], [1014.21, 1025.93], [1025.93, 1036.26], [1036.26, 1047.71], [1047.71, 1060.43], [1060.43, 1074.0600000000002], [1074.0600000000002, 1085.3400000000001], [1085.3400000000001, 1096.3500000000001], [1096.3500000000001, 1110.3500000000001], [1110.3500000000001, 1123.3700000000001], [1123.3700000000001, 1136.5300000000002], [1136.5300000000002, 1152.2100000000003], [1152.2100000000003, 1163.6800000000003], [1163.6800000000003, 1174.0800000000004], [1174.0800000000004, 1187.6500000000003], [1187.6500000000003, 1198.3900000000003], [1198.3900000000003, 1209.8500000000004], [1209.8500000000004, 1226.8600000000004], [1226.8600000000004, 1241.3500000000004], [1241.3500000000004, 1253.6800000000003], [1253.6800000000003, 1266.2200000000003], [1266.2200000000003, 1287.9300000000003], [1287.9300000000003, 1298.0500000000002], [1298.0500000000002, 1308.3300000000002], [1308.3300000000002, 1328.3400000000001], [1328.3400000000001, 1344.17], [1344.17, 1357.63], [1357.63, 1370.575], [1370.575, 1381.74], [1381.74, 1395.1200000000001], [1395.1200000000001, 1406.98], [1406.98, 1417.79], [1417.79, 1430.34], [1430.34, 1445.81], [1445.81, 1458.26], [1458.26, 1473.44], [1473.44, 1485.47], [1485.47, 1502.58], [1502.58, 1513.1399999999999], [1513.1399999999999, 1528.7499999999998], [1528.7499999999998, 1542.8699999999997], [1542.8699999999997, 1556.1299999999997], [1556.1299999999997, 1568.4199999999996], [1568.4199999999996, 1580.8799999999997], [1580.8799999999997, 1595.1699999999996], [1595.1699999999996, 1608.4299999999996], [1608.4299999999996, 1621.0899999999997], [1621.0899999999997, 1631.7199999999998], [1631.7199999999998, 1643.4499999999998], [1643.4499999999998, 1655.8099999999997], [1655.8099999999997, 1670.1799999999996], [1670.1799999999996, 1683.5999999999997], [1683.5999999999997, 1694.0199999999998], [1694.0199999999998, 1704.7899999999997], [1704.7899999999997, 1715.9099999999996], [1715.9099999999996, 1729.0999999999997], [1729.0999999999997, 1740.5099999999998], [1740.5099999999998, 1755.6799999999998], [1755.6799999999998, 1767.1399999999999], [1767.1399999999999, 1777.61], [1777.61, 1793.06], [1793.06, 1806.1799999999998], [1806.1799999999998, 1816.3609999999999], [1816.3609999999999, 1828.6309999999999], [1828.6309999999999, 1843.6809999999998], [1843.6809999999998, 1855.2009999999998], [1855.2009999999998, 1866.4809999999998], [1866.4809999999998, 1876.7609999999997], [1876.7609999999997, 1889.2409999999998], [1889.2409999999998, 1900.4909999999998], [1900.4909999999998, 1915.5209999999997], [1915.5209999999997, 1926.9299999999998], [1926.9299999999998, 1938.6], [1938.6, 1949.591], [1949.591, 1962.4309999999998], [1962.4309999999998, 1973.6209999999999], [1973.6209999999999, 1985.081], [1985.081, 1997.8909999999998], [1997.8909999999998, 2008.3509999999999], [2008.3509999999999, 2025.761], [2025.761, 2039.541], [2039.541, 2050.191], [2050.191, 2062.4309999999996], [2062.4309999999996, 2072.6109999999994], [2072.6109999999994, 2083.0209999999993], [2083.0209999999993, 2096.9009999999994], [2096.9009999999994, 2108.4009999999994], [2108.4009999999994, 2118.4509999999996], [2118.4509999999996, 2130.2709999999997], [2130.2709999999997, 2141.0469999999996], [2141.0469999999996, 2156.4509999999996], [2156.4509999999996, 2169.1709999999994], [2169.1709999999994, 2179.8109999999992], [2179.8109999999992, 2192.350999999999], [2192.350999999999, 2203.240999999999], [2203.240999999999, 2215.7709999999993], [2215.7709999999993, 2229.930999999999], [2229.930999999999, 2239.950999999999], [2239.950999999999, 2253.430999999999], [2253.430999999999, 2265.890999999999], [2265.890999999999, 2278.100999999999], [2278.100999999999, 2292.620999999999], [2292.620999999999, 2304.860999999999], [2304.860999999999, 2317.280999999999], [2317.280999999999, 2330.710999999999], [2330.710999999999, 2345.520999999999], [2345.520999999999, 2356.210999999999], [2356.210999999999, 2366.590999999999], [2366.590999999999, 2377.920999999999], [2377.920999999999, 2389.190999999999], [2389.190999999999, 2402.820999999999], [2402.820999999999, 2413.320999999999], [2413.320999999999, 2425.770999999999], [2425.770999999999, 2439.4309999999987], [2439.4309999999987, 2451.4009999999985], [2451.4009999999985, 2462.4209999999985], [2462.4209999999985, 2475.2809999999986], [2475.2809999999986, 2489.310999999999], [2489.310999999999, 2502.1609999999987], [2502.1609999999987, 2512.460999999999], [2512.460999999999, 2522.8909999999987], [2522.8909999999987, 2534.0109999999986], [2534.0109999999986, 2545.6809999999987], [2545.6809999999987, 2559.1609999999987], [2559.1609999999987, 2571.5709999999985], [2571.5709999999985, 2582.0109999999986], [2582.0109999999986, 2592.2609999999986], [2592.2609999999986, 2605.5109999999986], [2605.5109999999986, 2616.7109999999984], [2616.7109999999984, 2628.0409999999983], [2628.0409999999983, 2640.280999999998], [2640.280999999998, 2650.550999999998], [2650.550999999998, 2661.050999999998], [2661.050999999998, 2673.710999999998], [2673.710999999998, 2686.070999999998], [2686.070999999998, 2697.000999999998], [2697.000999999998, 2708.110999999998], [2708.110999999998, 2719.150999999998], [2719.150999999998, 2730.690999999998], [2730.690999999998, 2745.082999999998], [2745.082999999998, 2756.2829999999976], [2756.2829999999976, 2769.5129999999976], [2769.5129999999976, 2779.5129999999976], [2779.5129999999976, 2790.5329999999976], [2790.5329999999976, 2803.0129999999976], [2803.0129999999976, 2815.062999999998], [2815.062999999998, 2828.542999999998], [2828.542999999998, 2838.852999999998], [2838.852999999998, 2855.872999999998], [2855.872999999998, 2866.792999999998], [2866.792999999998, 2879.2429999999977], [2879.2429999999977, 2890.4429999999975], [2890.4429999999975, 2901.9929999999977], [2901.9929999999977, 2913.102999999998], [2913.102999999998, 2928.312999999998], [2928.312999999998, 2944.852999999998], [2944.852999999998, 2954.9129999999977], [2954.9129999999977, 2970.542999999998], [2970.542999999998, 2982.4529999999977], [2982.4529999999977, 2992.6729999999975], [2992.6729999999975, 3005.2529999999974], [3005.2529999999974, 3016.8029999999976], [3016.8029999999976, 3027.9229999999975], [3027.9229999999975, 3040.9229999999975], [3040.9229999999975, 3058.8529999999973], [3058.8529999999973, 3074.4629999999975], [3074.4629999999975, 3086.1829999999973], [3086.1829999999973, 3096.3529999999973], [3096.3529999999973, 3111.367999999997], [3111.367999999997, 3122.4529999999972], [3122.4529999999972, 3137.3329999999974], [3137.3329999999974, 3149.4029999999975], [3149.4029999999975, 3161.1929999999975], [3161.1929999999975, 3172.9529999999977], [3172.9529999999977, 3184.8929999999978], [3184.8929999999978, 3195.042999999998], [3195.042999999998, 3205.3929999999978], [3205.3929999999978, 3216.922999999998], [3216.922999999998, 3227.231999999998], [3227.231999999998, 3238.5429999999983], [3238.5429999999983, 3251.3329999999983], [3251.3329999999983, 3263.182999999998], [3263.182999999998, 3277.902999999998], [3277.902999999998, 3288.552999999998], [3288.552999999998, 3301.712999999998], [3301.712999999998, 3317.4529999999977], [3317.4529999999977, 3327.832999999998], [3327.832999999998, 3341.3229999999976], [3341.3229999999976, 3355.0429999999974], [3355.0429999999974, 3368.3529999999973], [3368.3529999999973, 3378.992999999997], [3378.992999999997, 3402.3929999999973], [3402.3929999999973, 3413.771999999997], [3413.771999999997, 3423.802999999997], [3423.802999999997, 3436.021999999997], [3436.021999999997, 3448.7529999999974], [3448.7529999999974, 3462.771999999997], [3462.771999999997, 3475.492999999997], [3475.492999999997, 3488.137999999997], [3488.137999999997, 3500.947999999997], [3500.947999999997, 3519.456999999997], [3519.456999999997, 3530.487999999997], [3530.487999999997, 3544.487999999997], [3544.487999999997, 3556.896999999997], [3556.896999999997, 3568.8369999999973], [3568.8369999999973, 3579.2279999999973], [3579.2279999999973, 3590.2679999999973], [3590.2679999999973, 3602.447999999997], [3602.447999999997, 3614.217999999997], [3614.217999999997, 3625.007999999997], [3625.007999999997, 3637.416999999997], [3637.416999999997, 3649.8569999999972], [3649.8569999999972, 3662.927999999997], [3662.927999999997, 3674.2879999999973], [3674.2879999999973, 3686.416999999997], [3686.416999999997, 3701.726999999997], [3701.726999999997, 3713.4979999999973], [3713.4979999999973, 3729.217999999997], [3729.217999999997, 3739.735999999997], [3739.735999999997, 3750.1069999999972], [3750.1069999999972, 3761.3569999999972], [3761.3569999999972, 3771.8569999999972], [3771.8569999999972, 3784.297999999997], [3784.297999999997, 3796.6069999999972], [3796.6069999999972, 3807.376999999997], [3807.376999999997, 3820.3479999999972], [3820.3479999999972, 3833.476999999997], [3833.476999999997, 3845.9579999999974], [3845.9579999999974, 3857.2079999999974], [3857.2079999999974, 3868.947999999997], [3868.947999999997, 3879.8569999999972], [3879.8569999999972, 3892.0779999999972], [3892.0779999999972, 3904.007999999997], [3904.007999999997, 3914.126999999997], [3914.126999999997, 3927.186999999997], [3927.186999999997, 3939.887999999997], [3939.887999999997, 3951.862999999997], [3951.862999999997, 3964.8569999999972], [3964.8569999999972, 3975.5779999999972], [3975.5779999999972, 3986.737999999997], [3986.737999999997, 3997.677999999997], [3997.677999999997, 4012.407999999997], [4012.407999999997, 4023.657999999997], [4023.657999999997, 4034.7879999999973], [4034.7879999999973, 4049.0779999999972], [4049.0779999999972, 4061.527999999997], [4061.527999999997, 4073.376999999997], [4073.376999999997, 4084.697999999997], [4084.697999999997, 4095.697999999997], [4095.697999999997, 4107.886999999997], [4107.886999999997, 4109.809999999997]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1028, 1813, 2743, 3485, 4112]}
{"example_id": "mit035@@MIT8_04S16_lec10_300k", "text": ["PROFESSOR: This definition in which  the uncertainty of the permission operator  Q in the state psi.  It's always important to have a state associated ", "with measuring the uncertainty.  Because the uncertainty will be different in different states.  So the state should always be there.  Sometimes we write it, sometimes we ", "get a little tired of writing it and we don't write it.  But it's always implicit.  So here it is.  From the analogous discussion of random variables, ", "we were led to this definition, in which we  would have the expectation value of the square  of the operator minus the square of the expectation value.  This was always-- well, this is always a positive quantity. ", "Because, as claim 1 goes, it can be rewritten as the expectation  value of the square of the difference between the operator ", "and its expectation value.  This may seem a little strange.  You're subtracting from an operator a number,  but we know that numbers can be thought as operators as well. ", "Operator of minus a number acting on a state  is well defined.  The operator acts on the state, the number multiplies a state.  So this is well defined. ", "And claim 1 is proven by direct computation.  You certainly indeed prove.  You can expand what is inside the expectation value, ", "so it's Q hat squared.  And then the double product of this Q hat and this number. ", "Now, the number and Q hat commute,  so it is really the double product.  If you have A plus B times A plus B, you have AB plus BA, ", "but if they commute it's 2AB, so this  is minus 2 Q hat Q. Like that. ", "And then, the last term is the number squared,  so it's plus Q squared.  And sometimes I don't put the hats as well. ", "And all this is the expectation value  of the sum of all these things.  The expectation value of a sum of things  is the expectation value of the first ", "plus the expectation value of the second,  plus the expectation value of the next.  So we can go ahead and do this, and this is therefore  expectation value of Q squared minus the expectation ", "value of this whole thing.   But now the expectation value of a number times an operator,  the number can go out. ", "And this is a number, and this is a number.  So it's minus 2 expectation value of Q, number went out.  And then you're left with expectation value of another Q. ", "And the expectation value of a number  is just the number, because then you're  left within the world of psi star psi, which is equal to 1. ", "So here is plus Q hat squared.  And these two terms, the second and the third, ", "are the same really.  They are both equal to expectation value of Q squared.  They cancel a little bit, and they give you this. ", "So indeed, this is equal to expectation value  of Q squared minus expectation value of Q squared. ", "So claim 1 is true.  And claim 1 shows in particular that this number, delta Q  squared, in the expectation value of a square of something, ", "is positive.  We'll see more clearly in a second  when we have claim number 2.  And claim number 2 is easily proven. ", "That's another expression for uncertainty.  For claim number 2, we will start with the expectation ", "value of Q minus Q squared, like this, which is the integral dx ", "psi star of x and t, Q minus expectation value of Q, Q ", "minus expectation value of Q, on psi.  ", "The expectation value of this thing squared  is psi star, the operator, and this.  And now, think of this as an operator acting on all of that. ", "This is a Hermitian operator.  ", "Because Q hat is Hermitian, and expectation value of Q is real. ", "So actually this real number multiplying something  can be moved from the wave function  to the starred wave function without any cost. ", "So even though you might not think of a real number  as a Hermitian operator, it is.  And therefore this whole thing is Hermitian. ", "So it can be written as dx.  And now you have this whole operator, Q minus Q  hat, acting on psi of x and t. ", "And conjugate.  Remember, the operator, the Hermitian operator,  moves to act on psi, and the whole thing [INAUDIBLE]. ", "And then we have here the other term left over.  ", "But now, you see that you have whatever that state is  and the state complex conjugated.  ", "So that is equal to this integral.  This is the integral dx of the norm squared of Q hat minus Q ", "hat psi of x and t squared, which means that thing, that's  its complex conjugate. ", "So this completes our verification  that these claims are true, and allow us  to do the last step on this analysis, which ", "is to show that if you have an eigenstate of Q,  if a state psi is an eigenstate of Q, there is no uncertainty. ", "This goes along with our measurement postulate that  says an eigenstate of Q, you measure Q ", "and you get the eigenvalue of Q and there's no uncertainty.  In particular, we'll do it here I think.  If psi is an eigenstate of Q, so you'll ", "have Q psi equal lambda psi, where lambda is the eigenvalue. ", "Now, this is a nice thing.  It's stating that the state psi is an eigenstate of Q ", "and this is the eigenvalue, but there is a little bit more  than can be said.  And it is.  It should not surprise you that the eigenvalue ", "happens to be the expectation value of Q on the state psi.  Why?  Because you can take this equation and integrate dx times ", "psi star.  If you bring that in into both sides of the equation  then you have Q psi equals integral dx psi star psi, ", "and the lambda goes up.  Since my assumption whenever you do expectation values,  your states are normalized, this is just lambda. ", "And by definition, this is the expectation value of Q.  So lambda happens to be equal to the expectation value of Q, ", "so sometimes we can say that this equation really  implies that Q hat psi is equal to expectation value of Q psi ", "times psi.  ", "It looks a little strange in this form.  Very few people write it in this form,  but it's important to recognize that the eigenvalue is  nothing else but the expectation value ", "of the operator of that state.  But if you recognize that, you realize  that the state satisfies precisely Q hat minus Q on psi ", "is equal to 0.  Therefore, if Q hat minus Q on psi is equal to 0,  delta Q is equal to 0. ", " By claim 2.  ", "Q hat minus Q expectation value kills the state,  and therefore this is 0.  ", "OK then.  The other way is also true.  If delta Q is equal to 0, by claim 2, this integral is 0. ", "And since it's the sum of squares  that are always positive, this state must be 0 by claim 2. ", " And you get that Q minus Q hat psi is equal to 0. ", "And this means that psi is an eigenstate of Q. ", "So the other way around it also works.  So the final conclusion is delta Q  is equal to 0 is completely equivalent of-- ", "I'll put in the psi.  Psi is an eigenstate of Q. ", "So this is the main conclusion.  ", "Also, we learned some computational tricks.  Remember you have to compute an expectation  value of a number, uncertainty, you ", "have these various formulas you can use.  You could use the first definition.  Sometimes it may be the simplest.  In particular, if the expectation value of Q ", "is simple, it's the easiest way.  So for example, you can have a Gaussian wave function,  and people ask you, what is delta of x of the Gaussian wave ", "function?   Well, on this Gaussian wave function,  you could say that delta x squared  is the expectation value of x squared minus the expectation ", "value of x squared.   What is the expectation value of x?  Well, it would seem reasonable that the expectation value of x ", "is 0.  It's a Gaussian centered at the origin.  And it's true.  For a Gaussian it would be 0, the expectation value of x.  So this term is 0. ", "You can also see 0 because of the integral.  You're integrating x against psi squared.  Psi squared is even, x is odd with respect ", "to x going to minus x.  So that integral is going to be 0.  So in this case, the uncertainty is just ", "the calculation of the expectation value of x squared,  and that's easily done.  It's a Gaussian integral.  The other good thing about this is that ", "even though we have not proven the uncertainty  principle in all generality.  We've only [? multivated ?] it.  It's precise with this definition. ", "So when you have the delta x, delta p  is greater than or equal to h bar over 2,  these things are computed with those definitions. ", "And then it's precise.  It's a mathematically rigorous result.  It's not just hand waving.  The hand waving is good. ", "PROFESSOR: We start with the stationary states.  ", "In fact, stationary states are going  to keep us quite busy for probably a couple of weeks.  Because it's a place where you get the intuition about solving ", "Schrodinger's equation.  So the stationary states are simple and useful solutions ", "of the Schrodinger equation, very nice and simple.  So what are they by definition?  Well, we begin with a definition. ", "And the intuition of a stationary state will follow.  See the word stationary is not the same as static. ", "Stationary is something that maybe it's kind of moving,  but things don't change.  Static is something that's just not moving. ", "Stationary states have time dependence.  It is very simple, as we will see.  So, your definition of a stationary state ", "has a factorized space and time dependencies. ", " So this psi of x and t is a stationary state. ", "If you can write it as a product of a function of time  times a function of position. ", " And now, I will try to be careful about this.  Wave functions that have position and time ", "will have this bar at the bottom.  Wave functions that don't have x will not have it.  If I slip on that, please let me know. ", "So this is a stationary state, but a stationary state  has factorized space and time dependencies  and solves the Schrodinger equation-- the solution ", "of Schrodinger's equation.  So what we need to understand is what this factorized dependence  tell us for the Schrodinger equation. ", "So this stationary state has time dependence.  But the thing that makes them stationary ", "is that if you look at some observable,  a Hermitian operator, and you say,  OK, the state has time dependence,  so maybe my observable will have time dependence. ", "No.  The observables don't have time dependence.  That is the nice thing about stationary states.  So, what we call time independent observables which ", "are all observables that are familiar [INAUDIBLE]--  Hamiltonian, the momentum, the precision,  the angular momentum.  Time independent observables have no time dependence. ", " And it kind of looks simple when you write it like that.  Time independent means don't have time dependence. ", "But you've seen that d dt of the expectation  value of x is equal to p over m, or the sum of p ", "over m, the velocity.  And here it is-- a time independent observable  that does have time dependence.  So the observable is time independent, ", "but expectation value have no time dependence  in their expectation values.  ", "The time dependence comes from the state--  the state, the psi of x and t have time dependence,  and sometimes it just doesn't drop out. ", "But for stationary states, it will drop, as you will see.  So, time independent observables have no time dependence ", "in their expectation values.  OK.  So enough of saying things.  And let's just get to them.  So we look at the Schrodinger equation, ", "i h-bar d dt of psi of x and t is  equal to h-bar psi of x and t. ", "And just to remind, this minus h squared over 2m d second d x  squared plus V of x. ", "And I will consider states that have just that at this moment.  ", "Otherwise, it's not so easy to get time-dependent--  to get stationary states.  If you have a potential that has time dependence, ", "we kind of do the nice thing that we're going to do.  So we're going to look only at time independent potentials.  So, V of x, like this, times psi of x and t. ", "OK.  So what we do next is to simply substitute  the value of the wave function into the differential equation  and see what we get. ", "So on the left hand side, we will  get i h-bar The psi of x goes out but you have d dt, Now ", "a normal derivative of g of t.   And now, this factor, H of psi acts on these two things. ", "Imagine the function of time times  the function of x sitting here.  Well, the function of time can be moved out.  So the function of time can be moved across the Hamiltonian ", "operator.  It doesn't do anything to it.  So we'll have g of t times H-hat of the psi of x. ", "This is H-hat.   And because we had no time dependence ", "in the potential, our assumption,  this whole thing is a function of x.  ", "All right.  Next step.  Divide this whole equation by the total wave function.  Divide by psi. ", " Well, if you divide by psi, you cancel the middle psi here,  and you get the 1 over g.  So you get i h-bar 1 over g dg dt is equal-- ", "on the right side, you cancel the g and you get a 1  over psi of x H-hat psi of x. ", " And now you look at this equation.  And this equation is saying something very strange. ", "The left hand side is a function of time only.  The right hand side is a function of space only. ", "How can a function of time be equal to a function of space?  The only way this can be is if both are not ", "a function of what they were supposed to be.  They're just numbers.  Any function of time cannot be equal to a function of space,  in generality. ", "It just doesn't make sense.  So each side must be equal to a constant,  and it's the same constant.  So each side, this is all equal to a constant. ", " And we'll call the constant E. And this E has units of energy. ", " E equal to be a real constant with units of energy. ", " You can see the units because the Hamiltonian ", "has units of energy.  And whatever psi units it has--  whatever every unit psi has, they cancel.  Here, whatever units g has, they cancel. ", "And h-bar over time is units of energy,  like in energies equal h-bar omega.   So it has units of energy. ", "The only thing that you may be could say, why real.  Quantum mechanics loves complex numbers.  So why don't we put the complex E? ", "We'll see what trouble we get if you choose  something that is complex.  So here we go.  It's a real quantity to be-- let's  do it real for the time being. ", "And let's solve the first equation.  The left hand side, i h-bar dg dt is now equal to gE, or E, ", "where E is a number and g is a function of time  from where g of p is equal to constant E ", "to the minus iEt over h-bar.  Let's just check it works correctly. ", "It's a first order differential equation.  Just one function of integration.  If you guess the answer, must be the answer.  And that's the time dependence of a stationary state. ", " It's exponential minus iEt over h-bar. ", "What about the other equation?  The other equation has become H psi of x equals E psi of x. ", "Or, we should write at least once, minus h squared over 2m--  did I make a mistake?  No, I didn't-- d second dx squared-- ", "I got this normal derivatives here  because this is just a function of x--  plus V of x psi is equal to E psi of x. ", "This is the same equation that I'm boxing twice,  because it's written in those two ways.  And both ways are very important. ", "And this is part of solving for stationary state.  You've solved for g of t.  The time dependence was easy to solve for, ", "but the x dependence is complicated, in general.  There, you have to do some work.  You have to solve a differential equation.  It's not that easy. ", "So many people-- most people--  call this the time independent Schrodinger equation.  ", "So that's the time independent Schrodinger equation,  where H psi equal E psi.  And as you can imagine, solving this differential equation can ", "be challenging, or sometimes very interesting  because it may be that, as far as the first equation  is concerned, of what we did here,  we don't know what this number E is. ", "But it may be that the only reasonable solutions  that this equation has are for some values of E.  The analogy with matrices should tell you ", "that's probably what's going to happen.  Because you remember eigenstates and eigenvalues of matrices  are peculiar numbers.  If you have a matrix, they're peculiar eigenvalues. ", "So this equation is an eigenfunction equation.  And it's possible that it has the solution  for some particular values of the energy. ", "Let me write the whole solution then.  If you've solved these two things,  the whole solution psi of x and t ", "is now a constant times psi of x times  e to the minus iEt over h-bar, where this psi of x ", "solves this equation.  So this is the stationary state.  ", "How about normalizing the stationary state?  Can we do that?  Well, if we try to normalize it--  psi star of x and t and psi of x and t dx, ", "and you set this equal to 1.  This should be the case, because this  should be interesting solutions of the Schrodinger equation.  We expect that we could do particles with them. ", "And we can start wave packets or peculiar states with them.  And let's see what we get here.  ", "Maybe I should know.  I'm really [INAUDIBLE].  I'm going to erase that constant C here. ", "Since we want to normalize this, we  will think of this as a normalization of psi.  When we try to normalize psi, we'll ", "be normalizing middle psi, as you will see here.  There's no need to put that constant there.  So what do we get here?  We get integral dx psi star of x and t, ", "so you have psi of x star.  And now you could say it's E to the iEt over h-bar. ", "That's the complex conjugate.  Now, on the other hand, suppose--  I'll do this this way.  [INAUDIBLE] of this other term is ", "psi of x into the minus iEt over h-bar.  ", "And now the good thing about this, you  see this integral should be normalized to 1 to make sense.  And it's a great thing that the time dependence drops out. ", "And it would not have dropped out if the energy had not  been real.  If the energy was not real, I would  have had to put here E start. ", "And here I would have had E star minus E  and some function of time.  And how can a function of time be equal to 1?  Would be a problem. ", "We would not be able to normalize this wave function.  So E must be real because otherwise we  don't cancel this time dependence, which happily, ", "when it cancels, it just tells you  that the integral dx of psi star of x psi of x  must be 1, which is a very nice thing. ", "So in a stationary state, the normalization condition  for a full time dependent stationary state  is that the spacial part is normalized. ", "PROFESSOR: How about the expectation value  of the Hamiltonian in a stationary state?  You would imagine, somehow it has ", "to do with energy ion states and energy.  So let's see what happens.  The expectation value of the Hamiltonian  on this stationary state. ", "That would be integral dx stationary state  Hamiltonian stationary state. ", " And we're going to see this statement that we made  a few minutes ago become clear.  Well what do we get here? dx psi star ", "of x e to the i Et over h bar H e to the minus i  Et over h bar psi of x. ", "And H hat couldn't care less about the time dependence,  that exponential is irrelevant to H hat. ", "That exponential of time can be moved across and cancelled with  this one.   And therefore you get that this is ", "equal to dx psi star of x H hat psi of x, which is a nice thing ", "to notice.  The expectation value of H on the full stationary state  is equal to the expectation value of H ", "on the spatial part of the stationary state.  That's neat.  I think it should be noted.  So it's equal to the H of little psi of x. ", "But this one, we can evaluate, because if we  are in a stationary state, H hat psi of x is E times psi of x. ", "So we get an E integral the x psi  star of psi, which we already show  that integral is equal to one, so we get the energy. ", " So two interesting things.  The expectation value of this quantity ", "of H in the stationary state is the same  as it's quotation value of H in the spatial part,  and it's manually equal to the energy.  ", "By the way, you know, these states are energy eigenstates,  these psi of x's, so you would expect zero uncertainty ", "because they are energy eigenstates.  So the zero uncertainty of the energy operator in an energy  eigenstate.  There's zero uncertainty even in the whole stationary state. ", "If you have an H squared here, it would give you an E squared,  and the expectation value of H is equal to E, ", "so the expectation value of H squared minus the expectation  value of H squared would be zero.  Each one would be equal to E squared. ", "Nothing would happen, no uncertainties whatsoever.  So let me say once more, in general, being ", "so important here is the comment that the expectation  value of any time independent operator, so comments 1, ", "the expectation value of any time-independent operator ", "Q in a stationary state is time-independent. ", " So how does that go?  It's the same thing.  Q hat on the psi of x and t is general, ", "now it's integral dx capital Psi of x and t Q hat psi of x and t ", "equals integral dx-- you have to start breaking the things now.  Little psi star of x E to the i et over H bar. ", "And I'll put the whole thing here.  Q hat Psi of x E to the minus i et over H.  So it's the same thing. ", "Q doesn't care about time So this factor just moves across  and cancels this factor. ", "The time dependence completely disappears.  And in this case, we just get-- this  is equal to integral dx psi star Q psi, which is the expectation ", "value of Q on little psi of x, which is clearly  time-independent, because the state has no time anymore ", "and the operator has no time.  So everybody loves their time and we're in good shape. ", "The second problem is kind of a peculiarity,  but it's important to emphasize superposition.  It's always true, but the superposition ", "of two stationary states is or is not a stationary state?  STUDENT: No.  PROFESSOR: No, good.  It's not a stationary state in general ", "because it's not factorizing.  You have two stationary states with different energies,  each one has its own exponential, ", "and therefore, the whole state is not factorized  between space and time.  One time-dependence has one space-dependence plus another  time-dependence and another space-dependence, ", "you cannot factor it.  So it's not just a plain fact.  So the superposition of two stationary states ", "of different energy is not stationary. ", " And it's more than just saying, OK, it's not stationary. ", "What it means is that if you take the expectation  value of a time-independent operator,  it may have time-dependence, because you are not anymore ", "guaranteed by the stationary state  that the expectation value has no time-dependence.  That's how, eventually, these things have time-dependence, ", "because these things are not [INAUDIBLE]  on stationary states.  On stationary states, these things  would have no time-dependence. ", "And that's important, because it would  be very boring, quantum mechanics,  if expectation values of operators  were always time-independent. ", "So what's happening?  Whatever you measure never changes, nothing moves,  nothing changes.  And the way it's solved is because you  do have those stationary states that will give you ", "lots of solutions.  And then we combine them.  And as we combine them, we can get time-dependence  PROFESSOR: Would solving this equation for some potential, ", "and since h is Hermitian, we found the results  that we mentioned last time.  That is the eigenfunctions of h are ", "going to form an orthonormal set of functions  that span the space.  You can expand anything on there. ", "This is what we proved for a general condition operator  to some degree.  So the eigenfunctions form an orthonormal set ", "that spans the space.  So you're going to define that psi 1 with an E1 ", "and psi 2 with an E2, and then this continues.  And this is called the spectrum of the theory ", "because energy eigenstates are considered the gold standard.  If you want to find solving a theory  means finding the energy eigenstates. ", "Because if you find the energy eigenstates, you can solve,  you can write any wave function of superposition  of energetic states and then just let them evolve. ", "And the energetic states involve easily  because they are just stationary states.  So the spectrum of the theory is the collection ", "of numbers that are the allowed energies and of course,  the associated eigenfunctions.  So the energies may be many, maybe discrete, maybe it ", "has a little bit of continuous partners,  all kind of varieties.  But your task is to find those for any problem. ", "So the equation that we're trying to solve  is now re-written.  We're going to try to solve it.  ", "So let's look at it.   It's a second order differential equation ", "with a potential in general.  So we had an example there.  It's there.  It's boxed.  So we'll write it slightly different, ", "remove the potential to the right-hand side  and get rid of the constants here.  So d x squared is equal to 2m over h squared. ", "", "So this is the equation we have to solve.   So whenever you have a problem, you ", "may encounter a potential, v of x.  And the question is how bad this potential can be.  Well, the potential may be nice and simple, or it may be nice ", "but then has some jumps.  It may have infinite jumps, like a potential is  a complete barrier, or it may have delta functions. ", " all these are v of x equal possibles.  ", "All of them.  Many things can happen with a potential.  In fact, the potential can be as strange  as you're one, depending on what problems you want to solve. ", "So it's your choice.  Now, we're going to accept, in fact, all of those potentials ", "for our analysis.  May be nice and smooth.  There may have discontinuities.  It may have infinite discontinuities,  and worse things like delta function. ", "But worse things than that we will ignore,  and there are worse things than that. ", "Maybe a potential discontinues at every point, or maybe  a potential has delta functions and derivatives  of delta functions. ", "Or potentials that blow up and do all kinds of things.  And I'm not saying you should never consider that.  I'm saying that we don't know of any very useful case where ", "you get anything interesting with that.  But a conceivable a particular time a singular potential one  day could be used.  So we'll look at these potentials ", "and try to understand how to set up boundary conditions. ", "And we're going to worry about basically psi  and how does it behave.  And my first claim is that psi of x has to be continuous. ", " So psi of x cannot jump. ", "The wave function move along but cannot jump.  And the reason is a differential equation.  Look, if psi of x was not continuous, ", "if psi of x was like this, and just  had a discontinuity, psi of x equal to x, ", "psi prime of x would contain a delta function  and this is continuity.  The derivative is infinite. ", "And psi double prime of x, the second derivative,  would have a derivative of a delta function which is worse  because a delta function, we think of it ", "as a spike that is becoming thinner and higher,  but the derivative of the delta function first goes to infinity  and then goes to minus infinity and then comes back up. ", "It's much worse in many ways.  And look, if you have this differential equation  and psi is not continuous, well, the right-hand side ", "is not continuous.   Or if you have a delta function, then  something not continuous, but left-hand side, ", "we've had a derivative of a delta function that is nowhere  on the right-hand side.  On the right-hand side, the worst that could exist  is a delta function in v of x. ", "But the derivative of a delta function doesn't exist.  So you cannot afford to have a psi that is discontinuous.  Psi has to be continuous. ", "There's other ways to argue this.  You might put them in your notes,  but I'll leave it like that.  ", "Now how about the next case?  I will say the following happens too.  Sine prime of x is continuous unless v of x ", "has a delta function.   You see, potentials of delta functions are nice, ", "they are interesting.  We will consider that.  Delta functions potentials can be attractive  potentials, repulsive potentials of [INAUDIBLE].  So I claim now that psi prime of x has to also be continuous. ", "Why are we worrying about psi and psi  prime is because you need two conditions whenever you're  going to solve this differential equation at an interface, ", "you will need to know psi is continuous  and psi prime is continuous because  of second-order differential equations.  So suppose psi prime is continuous. ", "Then there is no problem.  If psi prime is continuous, the worse that can happen  is that the second derivative is discontinuous. ", "And the second derivative is discontinuous  could happen with a potential of this discontinuous,  so one problem if psi prime is continuous. ", "But psi prime can fail to be continuous if the potential has  a delta function.  And let's see that.  If psi prime is discontinuous, then ", "psi double prime is proportional to a delta function.   If psi prime is discontinuous, double prime ", "is proportional to a delta function.  But here psi just takes some value--  there's nothing strange about it--  in order to have delta function, which is psi double prime. ", "To be equal to the right-hand side, v of x  must have a delta function.   And v will have a delta function. ", "So it will be a somewhat similar potential,  but we're going to look at them in about a week from now. ", "But this will be our guidance to solve problems.  The continuity of the wave function  and the continuity of the derivative of the wave ", "function.  And for this slightly more complicated problems  in which the potential has a delta function, ", "then you will have a discontinuity in psi prime,  and it will be calculable, and it's manageable,  and it's all very nice.  Now, we do it a little complicated, ", "and everything is mixed up, but you will  BARTON ZWIEBACH: --that has served, also,  our first example of solving the Schrodinger equation. ", "Last time, I showed you a particle in a circle.  And we wrote the wave function.  And we said, OK, let's see what is the momentum of it.  But now, let's solve, completely, this problem. ", "So we have the particle in the circle.  Which means particle moving here.  And this is the coordinate x.  And x goes from 0 to L. And we think of this point ", "and that point, identify.  We actually write this as, x is the same as x plus L.  This is a strange way of saying things, ", "but it's actually very practical.  Here is 2L, 3L.  We say that any point is the same as the point at which you ", "add L. So the circle is the whole, infinite line  with this identification, because every point here, ", "for example, is the same as this point.  And this point is the same as that point.  So at the end of everything, it's  equivalent to this piece, where L is equivalent to 0. ", "It's almost like if I was walking here in this room,  I begin here.  I go there.  And when I reach those control panels, ", "somehow, it looks like a door.  And I walk in.  And there's another classroom there with lots of people  sitting.  And it continues, and goes on forever. ", "And then I would conclude that I live in a circle,  because I have just begun here and returned  to the same point that is there.  And it just continues.  So here it is. ", "You are all sitting here.  But you are all sitting there.  And you are all sitting there, and just live on a circle.  So this implies that in order to solve wave functions ", "in a circle, we'll have to put that psi of x plus L  is equal to psi of x, which are the same points. ", "And we'll have 0 potential.  V of x equals 0.  It will make life simple.  So the Hamiltonian is just minus h squared ", "over 2m d second dx squared.  ", "We want to find the energy eigenstate.  So we want to find minus h squared over 2m  d second psi dx squared is equal to E psi. ", "We want to find those solutions.   Now it's simple, or relatively simple ", "to show that all the energies that you can find  are either zero or positive. ", "It's impossible to find solutions of this equation  with a negative energies. ", "And we do it as follows.  We multiply by dx and psi star and integrate from 0 to L. ", "So we do that on this equation.  And what will we get?  Minus h squared over 2m integral psi star ", "of x d dx of d dx psi of x is equal to E times ", "the integral psi star psi x dx.  And we will assume, of course, that you have things ", "that are well normalized.  So if this is well normalized, this is 1. ", "So this is the energy is equal to this quantity.   And look at this quantity.  This is minus h squared over 2m. ", "I could integrate by parts.  If I do this quickly, I would say, just  integrate by parts over here.  And if we integrate by parts, d dx of psi of x, ", "we will get a minus sign.  We'll cancel this minus sign, and will be over.  But let's do it a little bit more slowly.  You can put dx, this is equal to d dx of psi star ", "d psi dx minus d psi star dx d psi dx. ", "I will do it like this, with a nice big bracket.  Look what I wrote.  I rewrote the psi star d second of psi ", "as d dx of this quantity, which gives me  this term when the derivative acts on the second factor.  But then I used an extra term, where the derivative ", "acts on the first factor that is not present in the above line.  Therefore, it must be subtracted out.  So this bracket has replaced this thing. ", " Now d dx of something, if you integrate over x from 0 ", "to L, the derivative of something,  this will be minus h bar squared over 2m psi star d psi ", "dx integrated at L and at 0.  And then minus cancels.  So you get plus h squared over 2m integral from 0 ", "to L dx d psi dx squared equal E. ", "And therefore, this quantity is 0.  The point L is the same point as the point 0. ", "This is not the point at infinity.  I cannot say that the wave function goes to 0 at L,  or goes to 0, because you're going to infinity. ", "No, they have a better argument in this case.  Whatever it is, the wave function,  the derivative, everything, is periodic with L. ", "So whatever values it has at L equal 0 it has--  at x equals 0, it has at x equals L. So this is 0. ", "And this equation shows that E is the integral  of a positive quantity.  So it's showing that E is greater than 0, as claimed. ", " So E is greater than 0.  So let's just try a couple of solutions, and solve. ", "We'll comment on them more in time.  But let's get the solutions, because,  after all, that's what we're supposed to do.  The differential equation is d second psi dx ", "squared is equal to minus 2mE over h squared psi.  And here comes the thing.  We always like to define quantities, numbers. ", "If this is a number, and E is positive,  this I can call minus k squared psi.  Where k is a real number. ", " Because k real, the square is positive.  And we've shown that the energy is positive. ", "And in fact, this is nice notation.  Because if you were setting k squared equal to 2mE  over h squared, you're saying that E ", "is equal to h squared k squared over 2m.  So, in fact, the momentum is equal to hk.  Which is very nice notation. ", "So this number, k, actually has the meaning  that we usually associate, that hk is the momentum.  And now you just have to solve this. d second psi dx squared ", "is equal to minus k squared psi.  Well, those are solved by sines or cosines of kx. ", "So you could choose sine of kx, cosine of kx, e to the ikx.  ", "And this is, kind of better, or easier,  because you don't have to deal with two  types of different functions.  And when you take k and minus k, you have to use this, too. ", "So let's try this.  And these are your solutions, indeed.  psi is equal to e to the ikx.  ", "So we leave for next time to analyze  the [INAUDIBLE] details.  What values of k are necessary for periodicity  and how we normalize this wave function. "], "vid_duration": [13.15, 10.43, 13.07, 16.17, 14.144, 14.842, 11.727, 13.537, 10.2, 11.325, 10.893, 13.747, 10.647, 15.814, 11.034, 17.418, 10.782, 12.95, 10.332, 10.081, 14.887, 14.458, 14.712, 10.948, 11.378, 13.184, 16.643, 14.147, 11.9, 11.28, 12.54, 13.325, 12.229, 10.024, 12.912, 10.612, 11.958, 13.84, 13.92, 11.08, 23.704, 11.816, 12.76, 11.93, 12.83, 16.674, 14.006, 13.14, 14.36, 12.72, 10.49, 18.245, 11.739, 11.776, 10.84, 15.91, 10.672, 12.984, 10.834, 13.23, 16.79, 10.72, 11.31, 13.67, 12.891, 12.449, 11.39, 11.27, 11.47, 10.25, 12.09, 11.17, 13.468, 10.662, 10.63, 12.15, 13.82, 10.531, 12.069, 11.08, 20.055, 12.3, 10.425, 11.74, 10.74, 15.41, 11.747, 10.653, 11.67, 11.02, 19.309, 17.214, 12.018, 13.751, 14.978, 14.262, 11.218, 10.874, 11.662, 12.066, 12.742, 11.206, 13.76, 17.38, 10.56, 10.794, 17.166, 12.758, 13.672, 13.99, 12.45, 14.34, 20.41, 16.382, 11.169, 10.359, 10.53, 10.553, 10.627, 13.29, 13.342, 11.035, 12.27, 10.993, 11.42, 11.68, 13.12, 10.94, 11.74, 13.0, 10.24, 13.89, 13.17, 12.625, 10.205, 12.75, 10.49, 24.202, 10.668, 12.85, 12.4, 13.44, 11.908, 10.502, 15.21, 15.22, 18.26, 13.264, 11.318, 10.723, 10.432, 12.922, 11.483, 12.563, 10.495, 17.13, 11.87, 10.88, 12.32, 18.28, 10.32, 10.37, 12.24, 12.37, 14.525, 15.889, 10.426, 10.735, 10.343, 10.152, 15.3, 10.534, 12.066, 12.0, 12.44, 15.7, 14.37, 12.4, 10.735, 12.225, 22.449, 12.696, 13.035, 12.6, 10.469, 11.137, 14.124, 12.574, 14.798, 12.028, 10.45, 11.73, 12.81, 11.688, 11.794, 19.244, 10.478, 11.386, 13.43, 12.11, 10.844, 10.725, 11.681, 20.18, 15.37, 10.74, 24.392, 11.028, 19.03, 12.844, 11.35, 11.865, 13.081, 10.06, 12.859, 12.425, 12.646, 36.27, 37.57, 11.65, 17.89, 18.39, 11.9, 11.67, 11.09, 11.93, 10.01, 12.12, 14.36, 11.792, 13.478, 15.606, 10.389, 16.53, 10.375, 11.33, 11.95, 14.14, 14.59, 10.51, 13.73, 13.34, 12.54, 18.09, 12.44, 16.48, 10.8, 15.02, 10.95, 13.444, 20.116, 14.49, 14.17, 17.819, 11.551, 10.52, 10.38, 11.005, 15.885, 13.239, 16.98, 11.73, 10.584, 12.394, 12.923, 10.04, 10.86, 10.57, 13.47, 14.908, 13.512, 11.02, 15.25, 12.335, 10.375, 12.7, 17.61, 11.57, 13.011, 13.013, 10.886, 13.68, 14.309, 19.743, 17.645, 11.483, 12.75, 12.378, 12.572, 10.37, 13.601, 11.929, 11.545, 10.085, 14.22, 12.03, 12.35, 12.805, 14.98, 14.965, 12.653, 11.037, 13.73, 11.01, 13.94, 11.389, 10.261, 14.009, 11.901, 9.7], "stet": [[0, 13.15], [13.15, 23.58], [23.58, 36.65], [36.65, 52.82], [52.82, 66.964], [66.964, 81.806], [81.806, 93.533], [93.533, 107.07000000000001], [107.07000000000001, 117.27000000000001], [117.27000000000001, 128.595], [128.595, 139.488], [139.488, 153.235], [153.235, 163.882], [163.882, 179.696], [179.696, 190.73], [190.73, 208.148], [208.148, 218.93], [218.93, 231.88], [231.88, 242.212], [242.212, 252.29299999999998], [252.29299999999998, 267.17999999999995], [267.17999999999995, 281.638], [281.638, 296.34999999999997], [296.34999999999997, 307.29799999999994], [307.29799999999994, 318.67599999999993], [318.67599999999993, 331.85999999999996], [331.85999999999996, 348.50299999999993], [348.50299999999993, 362.6499999999999], [362.6499999999999, 374.5499999999999], [374.5499999999999, 385.82999999999987], [385.82999999999987, 398.3699999999999], [398.3699999999999, 411.6949999999999], [411.6949999999999, 423.92399999999986], [423.92399999999986, 433.94799999999987], [433.94799999999987, 446.85999999999984], [446.85999999999984, 457.47199999999987], [457.47199999999987, 469.4299999999999], [469.4299999999999, 483.26999999999987], [483.26999999999987, 497.1899999999999], [497.1899999999999, 508.26999999999987], [508.26999999999987, 531.9739999999998], [531.9739999999998, 543.7899999999998], [543.7899999999998, 556.5499999999998], [556.5499999999998, 568.4799999999998], [568.4799999999998, 581.3099999999998], [581.3099999999998, 597.9839999999998], [597.9839999999998, 611.9899999999998], [611.9899999999998, 625.1299999999998], [625.1299999999998, 639.4899999999998], [639.4899999999998, 652.2099999999998], [652.2099999999998, 662.6999999999998], [662.6999999999998, 680.9449999999998], [680.9449999999998, 692.6839999999999], [692.6839999999999, 704.4599999999998], [704.4599999999998, 715.2999999999998], [715.2999999999998, 731.2099999999998], [731.2099999999998, 741.8819999999998], [741.8819999999998, 754.8659999999999], [754.8659999999999, 765.6999999999998], [765.6999999999998, 778.9299999999998], [778.9299999999998, 795.7199999999998], [795.7199999999998, 806.4399999999998], [806.4399999999998, 817.7499999999998], [817.7499999999998, 831.4199999999997], [831.4199999999997, 844.3109999999997], [844.3109999999997, 856.7599999999996], [856.7599999999996, 868.1499999999996], [868.1499999999996, 879.4199999999996], [879.4199999999996, 890.8899999999996], [890.8899999999996, 901.1399999999996], [901.1399999999996, 913.2299999999997], [913.2299999999997, 924.3999999999996], [924.3999999999996, 937.8679999999996], [937.8679999999996, 948.5299999999996], [948.5299999999996, 959.1599999999996], [959.1599999999996, 971.3099999999996], [971.3099999999996, 985.1299999999997], [985.1299999999997, 995.6609999999996], [995.6609999999996, 1007.7299999999996], [1007.7299999999996, 1018.8099999999996], [1018.8099999999996, 1038.8649999999996], [1038.8649999999996, 1051.1649999999995], [1051.1649999999995, 1061.5899999999995], [1061.5899999999995, 1073.3299999999995], [1073.3299999999995, 1084.0699999999995], [1084.0699999999995, 1099.4799999999996], [1099.4799999999996, 1111.2269999999996], [1111.2269999999996, 1121.8799999999997], [1121.8799999999997, 1133.5499999999997], [1133.5499999999997, 1144.5699999999997], [1144.5699999999997, 1163.8789999999997], [1163.8789999999997, 1181.0929999999996], [1181.0929999999996, 1193.1109999999996], [1193.1109999999996, 1206.8619999999996], [1206.8619999999996, 1221.8399999999997], [1221.8399999999997, 1236.1019999999996], [1236.1019999999996, 1247.3199999999997], [1247.3199999999997, 1258.1939999999997], [1258.1939999999997, 1269.8559999999998], [1269.8559999999998, 1281.9219999999998], [1281.9219999999998, 1294.6639999999998], [1294.6639999999998, 1305.8699999999997], [1305.8699999999997, 1319.6299999999997], [1319.6299999999997, 1337.0099999999998], [1337.0099999999998, 1347.5699999999997], [1347.5699999999997, 1358.3639999999998], [1358.3639999999998, 1375.5299999999997], [1375.5299999999997, 1388.2879999999998], [1388.2879999999998, 1401.9599999999998], [1401.9599999999998, 1415.9499999999998], [1415.9499999999998, 1428.3999999999999], [1428.3999999999999, 1442.7399999999998], [1442.7399999999998, 1463.1499999999999], [1463.1499999999999, 1479.532], [1479.532, 1490.701], [1490.701, 1501.06], [1501.06, 1511.59], [1511.59, 1522.143], [1522.143, 1532.77], [1532.77, 1546.06], [1546.06, 1559.402], [1559.402, 1570.4370000000001], [1570.4370000000001, 1582.707], [1582.707, 1593.7], [1593.7, 1605.1200000000001], [1605.1200000000001, 1616.8000000000002], [1616.8000000000002, 1629.92], [1629.92, 1640.8600000000001], [1640.8600000000001, 1652.6000000000001], [1652.6000000000001, 1665.6000000000001], [1665.6000000000001, 1675.8400000000001], [1675.8400000000001, 1689.7300000000002], [1689.7300000000002, 1702.9000000000003], [1702.9000000000003, 1715.5250000000003], [1715.5250000000003, 1725.7300000000002], [1725.7300000000002, 1738.4800000000002], [1738.4800000000002, 1748.9700000000003], [1748.9700000000003, 1773.1720000000003], [1773.1720000000003, 1783.8400000000001], [1783.8400000000001, 1796.69], [1796.69, 1809.0900000000001], [1809.0900000000001, 1822.5300000000002], [1822.5300000000002, 1834.438], [1834.438, 1844.94], [1844.94, 1860.15], [1860.15, 1875.3700000000001], [1875.3700000000001, 1893.63], [1893.63, 1906.894], [1906.894, 1918.212], [1918.212, 1928.935], [1928.935, 1939.367], [1939.367, 1952.289], [1952.289, 1963.772], [1963.772, 1976.335], [1976.335, 1986.83], [1986.83, 2003.96], [2003.96, 2015.83], [2015.83, 2026.71], [2026.71, 2039.03], [2039.03, 2057.31], [2057.31, 2067.63], [2067.63, 2078.0], [2078.0, 2090.24], [2090.24, 2102.6099999999997], [2102.6099999999997, 2117.1349999999998], [2117.1349999999998, 2133.024], [2133.024, 2143.45], [2143.45, 2154.185], [2154.185, 2164.528], [2164.528, 2174.68], [2174.68, 2189.98], [2189.98, 2200.514], [2200.514, 2212.58], [2212.58, 2224.58], [2224.58, 2237.02], [2237.02, 2252.72], [2252.72, 2267.0899999999997], [2267.0899999999997, 2279.49], [2279.49, 2290.225], [2290.225, 2302.45], [2302.45, 2324.899], [2324.899, 2337.595], [2337.595, 2350.6299999999997], [2350.6299999999997, 2363.2299999999996], [2363.2299999999996, 2373.6989999999996], [2373.6989999999996, 2384.836], [2384.836, 2398.9599999999996], [2398.9599999999996, 2411.5339999999997], [2411.5339999999997, 2426.3319999999994], [2426.3319999999994, 2438.359999999999], [2438.359999999999, 2448.809999999999], [2448.809999999999, 2460.539999999999], [2460.539999999999, 2473.349999999999], [2473.349999999999, 2485.037999999999], [2485.037999999999, 2496.831999999999], [2496.831999999999, 2516.075999999999], [2516.075999999999, 2526.553999999999], [2526.553999999999, 2537.939999999999], [2537.939999999999, 2551.369999999999], [2551.369999999999, 2563.479999999999], [2563.479999999999, 2574.323999999999], [2574.323999999999, 2585.048999999999], [2585.048999999999, 2596.729999999999], [2596.729999999999, 2616.909999999999], [2616.909999999999, 2632.279999999999], [2632.279999999999, 2643.0199999999986], [2643.0199999999986, 2667.4119999999984], [2667.4119999999984, 2678.4399999999982], [2678.4399999999982, 2697.4699999999984], [2697.4699999999984, 2710.3139999999985], [2710.3139999999985, 2721.6639999999984], [2721.6639999999984, 2733.528999999998], [2733.528999999998, 2746.6099999999983], [2746.6099999999983, 2756.6699999999983], [2756.6699999999983, 2769.528999999998], [2769.528999999998, 2781.9539999999984], [2781.9539999999984, 2794.5999999999985], [2794.5999999999985, 2830.8699999999985], [2830.8699999999985, 2868.4399999999987], [2868.4399999999987, 2880.089999999999], [2880.089999999999, 2897.9799999999987], [2897.9799999999987, 2916.3699999999985], [2916.3699999999985, 2928.2699999999986], [2928.2699999999986, 2939.9399999999987], [2939.9399999999987, 2951.029999999999], [2951.029999999999, 2962.9599999999987], [2962.9599999999987, 2972.969999999999], [2972.969999999999, 2985.089999999999], [2985.089999999999, 2999.449999999999], [2999.449999999999, 3011.241999999999], [3011.241999999999, 3024.719999999999], [3024.719999999999, 3040.325999999999], [3040.325999999999, 3050.7149999999992], [3050.7149999999992, 3067.2449999999994], [3067.2449999999994, 3077.6199999999994], [3077.6199999999994, 3088.9499999999994], [3088.9499999999994, 3100.899999999999], [3100.899999999999, 3115.039999999999], [3115.039999999999, 3129.629999999999], [3129.629999999999, 3140.1399999999994], [3140.1399999999994, 3153.8699999999994], [3153.8699999999994, 3167.2099999999996], [3167.2099999999996, 3179.7499999999995], [3179.7499999999995, 3197.8399999999997], [3197.8399999999997, 3210.2799999999997], [3210.2799999999997, 3226.7599999999998], [3226.7599999999998, 3237.56], [3237.56, 3252.58], [3252.58, 3263.5299999999997], [3263.5299999999997, 3276.9739999999997], [3276.9739999999997, 3297.0899999999997], [3297.0899999999997, 3311.5799999999995], [3311.5799999999995, 3325.7499999999995], [3325.7499999999995, 3343.5689999999995], [3343.5689999999995, 3355.1199999999994], [3355.1199999999994, 3365.6399999999994], [3365.6399999999994, 3376.0199999999995], [3376.0199999999995, 3387.0249999999996], [3387.0249999999996, 3402.91], [3402.91, 3416.149], [3416.149, 3433.129], [3433.129, 3444.859], [3444.859, 3455.4429999999998], [3455.4429999999998, 3467.8369999999995], [3467.8369999999995, 3480.7599999999993], [3480.7599999999993, 3490.7999999999993], [3490.7999999999993, 3501.6599999999994], [3501.6599999999994, 3512.2299999999996], [3512.2299999999996, 3525.6999999999994], [3525.6999999999994, 3540.6079999999993], [3540.6079999999993, 3554.1199999999994], [3554.1199999999994, 3565.1399999999994], [3565.1399999999994, 3580.3899999999994], [3580.3899999999994, 3592.7249999999995], [3592.7249999999995, 3603.0999999999995], [3603.0999999999995, 3615.7999999999993], [3615.7999999999993, 3633.4099999999994], [3633.4099999999994, 3644.9799999999996], [3644.9799999999996, 3657.9909999999995], [3657.9909999999995, 3671.0039999999995], [3671.0039999999995, 3681.8899999999994], [3681.8899999999994, 3695.5699999999993], [3695.5699999999993, 3709.8789999999995], [3709.8789999999995, 3729.6219999999994], [3729.6219999999994, 3747.2669999999994], [3747.2669999999994, 3758.7499999999995], [3758.7499999999995, 3771.4999999999995], [3771.4999999999995, 3783.8779999999997], [3783.8779999999997, 3796.45], [3796.45, 3806.8199999999997], [3806.8199999999997, 3820.421], [3820.421, 3832.35], [3832.35, 3843.895], [3843.895, 3853.98], [3853.98, 3868.2], [3868.2, 3880.23], [3880.23, 3892.58], [3892.58, 3905.3849999999998], [3905.3849999999998, 3920.365], [3920.365, 3935.33], [3935.33, 3947.9829999999997], [3947.9829999999997, 3959.0199999999995], [3959.0199999999995, 3972.7499999999995], [3972.7499999999995, 3983.7599999999998], [3983.7599999999998, 3997.7], [3997.7, 4009.089], [4009.089, 4019.35], [4019.35, 4033.359], [4033.359, 4045.2599999999998], [4045.2599999999998, 4054.9599999999996]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [950, 2069, 2607, 3394, 4056]}
{"example_id": "mit057@@MIT9_00SCF11_lec24_300k", "text": ["PROFESSOR: So we began just a few months ago with this goal  of trying to understand the scientific study of human  nature, how our mind operates, why we behave the way we do. ", "From the brain basis, how we see and hear the world, how we  think, how we feel, our predispositions to act in  certain ways, how we develop from infancy to adolescence to ", "adulthood, through the middle ages and into  old age, we all hope.  The remarkably odd things about human social  interactions, which are just amazing I think. ", "And the challenges that so many people face, with a  degree of vulnerability in these very kinds of abilities  and behaviors.  And so it's hard to know what to conclude on. ", "So I thought I would touch on two things.  One, sort of fun to think about, hard to know how to  think about scientifically.  And one, it probably matters to us all the time. ", "So let me talk about this.  So when we think about why we do things, how our brain is  organized, mind is organized, we know that we've evolved  over a long period of time, from other species. ", "And that many things in us reflect this evolutionary  history, cast into a modern, unimaginable world from the  viewpoint of biology.  But here we are, sort of creatures from the past living ", "in an incredibly accelerated, changing environment.  And so evolutionary psychology, people say, let's  try to identify why we have certain patterns of thoughts  and feelings, given the evolutionary history of our ", "minds and brains.  And I'll say a word about that.  It's tough in many ways though to have, as much as you  believe that's true, it's got to be true, it's very tough to  approach scientifically. ", "Because often, it comes down to people telling fun,  interesting, clever stories.  Very hard to test.  So we know it's a big part of who we are, in a deep sense  where we came from. ", "Very hard to test experimentally.  But I'll show you a couple examples where people have  probed this a bit.  And then another question is in the last decade, some  people have said, well so much of psychology seems to focus ", "on the negative, the harm we're willing to do, the  stereotypes we're willing to hold.  How about positive psychology?  How about thinking about what can we learn from psychology  to lead a better, happier, more meaningful life. ", "As I'm going to tell you about the core results about  research about happiness.  And some of them I think will surprise you.  Some of them, you'll tuck in the back of your mind maybe,  as you think about what will make you happy. ", "I mean we all want to be happy in a deep sense.  We don't know what's on the other side of this life.  But we know this is the one we have in our hands. ", "And so what can psychology suggest that might make you  think what's a path to happiness?  So we talked about throughout this course about the fragile  power of the human brain. ", "It endows us with an unbelievable capacity for  thought, sight, behavior, vulnerabilities at every  stage, from neurological injuries to  neuropsychiatric disorders. ", "And again, we know this all has grown through this Paul  MacLean triune brain idea, that within us are kind of a  version of reptilian brains, within us are simple mammalian ", "brains, and then finally the primate and  human expanded neocortex.  And so within us, it's almost as if we represent in a  certain sense, our species history, literally in your ", "brain, literally right now, in some complex way of  interactions.  With parts of the brain that have evolved modestly and  parts that evolved spectacularly in humans.  ", "And the usual story, you're used to this in evolution, is  that our brains and minds evolved in nature.  And natural selection was the dominating part of the story.  Survival of the fittest for passing genes into the next ", "generation, that sort of all stories boil down to that.  And I'm going to tell you two specific examples.  One that surprised me and then one that's just sort of fun I ", "think in a silly way.  So the first one is attitudes towards race and sex.  And this can came up.  And then the second one is different attitudes in men and  women, who might have in terms of sex and procreation. ", "So let me focus on this for a moment.  In the last election, you may remember that there was a  long, grueling race across the primaries between Hillary ", "Clinton and Barack Obama.  And in many ways, this is a huge surprise in the United  States, because with such a history of racism and sexism,  the idea that the two leading candidates are a woman and an ", "African American, was just kind of an amazing thing.   As much as we had distance to go, that we  have come that far.  That these were the two candidates on the Democratic ", "side, who are competing state to state across the country,  one of whom would become the Democratic  nominee and the President.  And I got call from a reporter from the Boston Globe.  And he said, he was writing a story saying, which is the ", "worst problem these candidates faced, sexism or racism?  And many of us, and I'm no exception, our egos get turned  up when somebody from the press calls. ", "Because our name will be in the newspaper.  And we can show it to our friends and family.  And then they know we have a real job and somebody thinks  we know something.  You laugh. ", "And the graduate students, like their parents never  understand anything, except when their  name gets in the newspaper.  You know how that is, right?  So I thought, well, I'm going to say something really clever  and all the neuroscience and all the psychology I know, ", "either from my own research or for teaching this course.  I'll have something.  And I just had nothing to say.  I mean we can agree that racism is bad  and sexism is bad.  And it's kind of excellent that candidates are beating  those glass ceilings in the national leadership. ", "We know from research on things like the IAT test, that  you heard about, that both remain a problem.  Negative stereotypes of certain kinds remain in our  society to this day, across society. ", "So I was like, which is worst, terrible thing A or  terrible thing B?  And I had nothing to say.  And then a newspaper article came out and said, oh, ", "according to evolutionary psychologists, and I was not  included, because I nothing to say.  This was very sad.  They said well, really Hillary Clinton faces the harder path. ", "Because in their mind, sexism is built into our species.  Because the whole idea of how we procreate, how men and  women relate in species and investments, that's deep in  us, all through evolution. ", "Whereas racism is culturally specific and malleable.  There's countries where one group is picked on.  There's countries where another group is picked on.  There's changes in societies. ", "That's a changeable thing.  This is a tougher thing to change, was their  interpretation.  I thought well, that sounds good.  And it might even be true.  It's like a lot of evolutionary psychology, a  good possibility, a better answer by infinitely far than ", "I could give.  But who knows?  And then this one study came out, that's kind of curious.  So this is a study of children with Williams syndrome, a rare ", "disorder, but very studied in both human genetics and human  psychology.  And partly, it's interesting.  These are the unusual facial features of  these kinds of children.  They're born this way. ", "And it's caused by deletion of 26 genes from the long arm of  chromosome 7.  It's one of the most purely defined and specific genetic  developmental disorders in humans. ", "So it's really drawn the interest of geneticists.  Because it's a disorder that's really very linked to a very  specific part of the human genome always. ", "Distinctive, what they call elfin facial features,  developmentally delayed language skills.  And maybe the most curious and charming element is unusually ", "cheerful demeanor and ease with strangers.  These are the children who will walk up to strangers and  talk your ear off and not be afraid of anybody or anything.  To an extent that's charming, can get you in trouble with ", "the world being the way it is.  It's sometimes contrasted with autism.  Because individual with autism find social interactions  sometimes laborious, difficult, mysterious. ", "These individuals find it delightful, nonstop.  You get tired sometimes of talking to such children,  because they're ready to go infinitely in terms of social  interaction.  And there's been some study that they have atypical ", "amygdala function and lack of fear response there.  So that's the background about Williams syndrome.  And then somebody did a IAT study.  This was in France.  But its been replicated since. ", "That shows that for these children with Williams  syndrome, they still have a gender IAT effect.  That is for example, they're willing to consider women less  likely to be good at science and math, ", "which we know is silly.  But that's the stereotype.  But they showed no racial IAT effect.  And they had control participants who showed both.  So now, there's still interpretation. ", "But all of sudden, it's as if this is deeper in the brain.  And maybe this is learned.  And these children aren't learning this one.  But they can't stop this one. ", "So a suggestion that there is something true about this  evolutionary psychology thing.  And that maybe the hardest thing for us to change deep  down, because of the fundamental sexual relations ", "in procreation.  That's a hard thing for us to work our head around, without  being thoughtful and careful about it.  So here's an experiment that was used to demonstrate. ", "So what's the usual story?  The usual story in evolution is people on average, not  everybody of course, wants to have kids.  Because that's how they pass their genes down.  And who has a lot of investment per kid, in however ", "way you look it?  Women.  For women it's, just the first part is nine months.  And then the immediate support.  For men, how long is the minimal contribution? ", "15 seconds.  OK, well 15 minutes.  It varies.  But you know.   So there's a theory that if the thing you cared about was  just getting us your genes down ", "there as much as possible.  Was it Wilt Chamberlain, the former basketball player, who  said he had slept with 1,000 women.  That he would be like the champion example in men.  And with women, it's you can't do a 1,000 nine-month cycles. ", "So that for men, if that was the only thing in  life, and it's not.  But here's the experiment they did.  We couldn't have an IRB approve this.  But this was done at a university.  And they said, we're going to show you an ", "experiment like this.  And this is meant to be kind of silly.  But this is how evolutionary  psychology, things are expressed.  And it's kind of funny, I think.  We'll see.  So what they would do is they pick take an attractive man ", "and an attractive woman.  They were the confederates.  And they would approach a student leaving the library, a  random student.  And here's the responder, who is a woman.  Imagine yourself as women now, for those of you who are ", "woman, leaving a library, kind of late at night, not too  threatening.  But somebody walks up to you and says, I've noticed you in  the library a few times.  You seem very nice. ", "Do you think there's any chance we could get together  for a date sometime?  What percentage of women said yes?  In this study, 50%. ", "Do you think that's high?  Let's pretend it was a better approach  than what I just said.  I tried to make it low key and nice, a ", "low key, nice approach.   For other women, the same male confederate walks up and says,  I've noticed you in library.  You seem very nice. ", "What do you about going back to my apartment and having  some coffee?   We'll take turns then.  Women, what do you think is the number?  We start with 50. ", "What?  20.   I noticed you in the library.  You seem very nice.  I think there's something compatible between us. ", "What do you think about going back to my apartment and  having sex right now?   See finally, the course gets super practical.  ", "I'm not saying it.  This is just one study.  Now, we reverse the roles.  Men, you get ready, all right?  An attractive woman walks up to you and says, I noticed in  the library.  You seem very friendly.  We seem to be compatible. ", "Would you be willing to have a date with me some time?  AUDIENCE: 100%.   PROFESSOR: Would you be willing, the woman says to the ", "man, to go back to my apartment with me right now?  ", "All right, you know where this going.  An attractive woman walks up to the man.  And she says, would you go back to my apartment to have  sex with me this very minute?  ", "The guys got things to do.  You now, he can't--  Yeah?  AUDIENCE: [INAUDIBLE]?  PROFESSOR: What is the citation for this?  Let me get that.  I heard it in a talk. ", "And I saw the numbers.  The numbers are correct.  I have to say when this was presented, there was some  murmuring, because maybe it wasn't quite IRB-approved.  I heard it from a good source.  I'll get that for you. ", "It's in your notes.   So evolutionary psychology, whatever, it's kind of fun.  But it's hard to know where it gets you. ", "But it's definitely fun to talk about.  So happiness research.  So for a long time, from ancient philosophy to the  founding of the US and everything, people said, the ", "objective of life, as we choose it, Aristotle, for  itself, and never for any other reason.  And one of the most amazing phrases in the Declaration of  independence, \"We hold these truths to be self-evident,  that all men are created equal, that they are endowed ", "by their Creator with certain unalienable Rights, that among  these are life and liberty.\" Well, that we would think  would be obvious things, now.  But this amazing thing, \"and the pursuit of Happiness.\"  As important as life itself and liberty itself, the ", "pursuit of happiness.  And I think we know that in our own lives, as we relate to  other people, as we pursue careers, as we do things,  where we put our limited lifetime resources, time and ", "effort, we all want to end up in a deep way to be happy and  make the choices to get there.  So we can think on average, you could think in your head  what makes you happy, what makes you want unhappy? ", "And a standard list might be, people  definitely want to be healthy.  Nobody minds being wealthy.  We'll talk about that.  It never hurts to get a new car, a new TV, ", "or new stuff, right?  What makes you unhappy?  Physical injury, emotional injury.  I mean that would be kind of standard.  Now, how do you measure happiness? ", "And this is the part where you get us into the funniness of  psychology.  So you have with you a questionnaire, which is one of  the most widely used measures of happiness.  So I'll just give you a moment to look at it. ", "You could fill it out for yourself.  We're not going to collect it.  And you may even want to or whatever.  But just to get a feeling of this.  And you could say--  oh, sorry.  Anybody else who didn't get it, that we  could help you with? ", " A few hands over here.  Oh, thank you.   Again, let me say whoever did this amazing display is maybe ", "super happy.  So you're ahead of me.  Thank you.   So it's measured in life value.  You ask the person like basically, how happy are you? ", "And we have a tendency to be suspicious of just asking  people straight on.  Because if we ask them straight on, would you say  this line is as big as this line, if three  other people said that?  You'd say, no, not me. ", "If you say, would you zap somebody until you think  they're dead in another room?  You'd say no, not me.  So we're very suspicious about what people say they will do ", "and what they really do.  But for happiness research, it's hard to beat that.  Here's another one.  You can circle the happiness that represents you.  Because what's the better question, what's the more ", "objective measure to decide that somebody's happy, a brain  image, a blood test?  We don't have a better thing than the person's own  statement about their sense of happiness. ", "All the way back to a Roman philosopher, \"The happy man is  not he who seems thus to others, but who seems thus to  himself.\" We don't know of a better way to ask you if ", "you're happy, than to ask if you're happy.  So it's not the most satisfying kind of objective,  scientific measure.  But maybe it's the life we lead anywhere.  We decide if we're happy or not, in some sense. ", "So if you ask people on average how happy they are,  2/3 of the people will put themselves here, almost  everybody above average.  A few people report that they're consistently unhappy. ", " And I'm going to come back to this, but the thing that  struck happiness researchers, surprisingly modest  influences, and I'm going to touch this up a little bit ", "with a research study, of social status, income, gender,  or ethnicity.  A number of things that you could have thought would touch  that, surprisingly don't touch it, or in very limited ways. ", "But I'll tell you a little bit about those limited ways.  So on a seven-point scale, the average is 4 or a 5.  College students, 4.9.  Older people, happier. ", "We've talk about that before.  Ironically, even though older people probably face more  challenges in various ways and limited life spans, they seem  happier by self-report.  ", "One argument that income has little relationship is this  kind of a graph, that looks at the average income in the US  from 1930 to 1991.  So here's this increase, that's not going up anymore. ", "But it was in the last century.  And self-reported happiness.  And you can see that at some point, it goes up, but then it  flattens out. ", "So the general thought analysis, I'll show you a  little bit more detail, is, not much money or in current  situations, poverty, does strike down ", "people's sense of happiness.  But once you get above some threshold, and of course, what  that threshold is varies in so many ways depending on who you  are and what you expect, but once you get above some  threshold, that's not the biggest part ", "of the story anymore.  And that's pretty much a general finding.  They've done all kinds of surveys about  happiness across countries.  It's a really interesting thing about happiness ", "research, it's more powerful than you can imagine in  grabbing hold of the minds of many people in public policy.  Derek Bok, the former president of Harvard, has  written a book suggesting that happiness research ought to be ", "the basis of public policies by the government.  That if know what makes people happy, short of giving  everybody $1 million every year, why wouldn't you tweak ", "every policy, even if people don't think it will make them  happy, but you know from research it will?  And then here's a world map, where they surveyed people all  over the place. ", "The darker the color, the more people  reported themselves happy.  Now, this is very tricky.  Because now you're in full scale, there's things like ", "poverty, but there's also things like cultural emphases.  In the US, we talk a lot about happiness.  That concept is less prevalent in many other cultures,  relatively speaking.  So it's hard to know how much is the culture, how much is ", "the actual per capita income relevant.  But people are pursuing these things.  And they are finding roughly--  the most recent one, that again in countries where ", "there's a lot of poverty, it's less than in countries where  you start to have higher incomes.  So poverty is still associated with less happiness. ", "And you can guess that is reasonable.  And then more studies like this,  again about that direction.  So early on, people said that income has ", "nothing to do with happiness.  And that seems not quite right, especially at the lower  end of poverty.  Now, Dan Kahneman, the Nobel Laureate, a psychologist at  Princeton, has spent the last few years talking about what ", "he calls the focusing illusion.  And let me tell you what that is.  It's basically this, when thinking about one topic, it  could be income, could be graduate school admissions.  Like whatever the topic is, fairness, whatever the topic ", "is, when you're thinking about that one topic, people tend to  attribute more importance to that topic than it really has.  They think it accounts for more of what goes in the world  when they're focused on it.  And you see this all the time in political discussions. ", "Like it's all the deficit.  If we just fix the deficit, everything works.  It's all raising taxes.  If we just do this.  People fixate on one thing.  And then that's the answer to the whole problem.  That all the time, never mind political debates where things ", "might be staged, but even in one's own  personal life, that happens.  Let me give you an example of how they  showed that to be true.  They have people rate their happiness, just like you have.  And then they ask them, and these were, how many dates for ", "the single people, how many dates in the last month?  And they get no correlation between self-rated happiness  and how many dates you've had in the last month.  Now they were reverse for some people,  the order of questions. ", "How many dates have you had in the last month and now rate  your happiness.  And they get a positive correlation.  The more dates you had, the happier your report yourself.  Well, for people who are dating, on average, that's a ", "measure, like getting out there and meeting people.  It's an average of succeeding in some path  you want to be on.  So when you just thought about this, you said, whoa, if I had  no dates this past month, I must be pretty miserable. ", "I'm pretty unhappy.  I'm thinking about that.  And all the other elements of your life that contribute to  happiness, because you just focused on that.  You just focused on that because the question was  asked, recede disproportionately, compared ", "to the actual importance.  If you go the other way around, how happy you are, and  you ask this, there's no correlation, because you're  not thinking about this one thing and weighting your  overall happiness by this one question or dimension. ", "Does that make sense?  So the order is the whole story.  That people, when they think about a topic and then think  of how happy or meaningful it is, they overvalue that topic, ", "because they just focused in their  minds on this one dimension.  So getting back to this issue of income and how that goes  with happiness, here's what they did, the same thing ", "again, by asking a specific question and then asking your  general impression, the same idea.  So they said, how bad was your mood the previous day?  So there's a specific question about mood. ", "Now, how much time do you think people with various  income levels are in a bad mood?  And they picked for example, people making less than  $20,000 or people making more than $100,000. ", "These people who just answered this question said, gee--  AUDIENCE: [INAUDIBLE].   PROFESSOR: I don't see anything.  That's right.  ", "Thank you very much.  ", "The cool thing is now that they're making  videos of these lectures.  We have so many applicants to be your peers in  the years to come.  It's going to be unbelievable.  So you guys are great. ", "So they said it was about 32% more bad mood, if you were  making less or more.  If you asked people making how much, it's only a 12%  difference.  It matters, but only a third as much. ", "Because you just got them thinking about  being in a bad mood.  So now they over attribute income for daily happiness.  And here's a kind of interesting thing. ", "And it's a trade-off.  And it gets us to what is it in your life  that makes you happy.  So people making over $100,000 spend about 20% more time on-- ", " I've got this reversed.   So people making over $100,000 spend more time-- ", "I'll fix the slide up.  Sorry.  Spend more time on doing things that they report as  being kind of stressful, work, pressure shopping for the  family, pressured childcare situations, what they call ", "obligatory tasks.  And people who make less money, spend considerably more  time doing things that everybody considers fun when  they're doing it, socializing, or watching TV that you like. ", "So you can see it's kind of weird.  It's a little bit of where you put your time and what counts  for you to feel happy about something.  ", "Everybody's in pretty much agreement, like you've heard  about almost everything, twin studies suggest, the set point  of happiness, where you rate yourself as always  super-happy, moderately happy, or somewhat grumpy, seems to ", "be about between 15% and 80% heritable.  It's as if a piece of us is born to be super-happy, medium  happy, or chronically grumpy. ", "There's not a better or worse way to be, right?  So that people will call this a set point.  So of course things happen on a day-to-day basis, on a  moment-to-moment basis, that push you up or down in  happiness, of course. ", "You'll get good news, you get bad new, you have fearful  things, joyful things coming up.  But the idea is that people tend to get back pretty fast  to the set point, their level, whatever that is, of chronic, ", "constant happiness.  And this is kind of an amazing finding.  So let's take a look at that and add one more point.  So here's extroverts by personality measures and ", "introverts.  And extroverts report themselves as being happier.  That's a set point example, a personality thing that seems  to go over time.  But they share the bumpiness of the week. ", "Here's how happy they are on Monday, Tuesday, Wednesday  whoa, weekend approaching, and the misery of Sunday, when the  weekend is over.  So you can see in both things, of course they're responding ", "to the work week cycle of heavy work, anticipation of  the weekend, the weekend itself, and anticipation of  the work day.  Both groups do.  But the set points seem to be a little bit different, the ", "chronic, constant level.  Now, there's been a bunch of ideas about a question about  whether people can be too happy. ", "Can a person be too happy?  And here's what they find.  That if they had take people who say, I'm super, super,  super happy, and you ask them what's going on their life ", "that makes some super, super happy?  Those people often report that it's close relations to other  people and often, good deeds or volunteer work, is the  thing that's making them super, super happy. ", "A little less happy on average, but still pretty  happy, are people who have higher incomes, higher  education, and more political participation. ", "So look at these two things.  And you could say in your own life, but all these things  will matter.  But which is the model of success for you in your heart,  the human relations and doing good or the sort of income, ", "education, active in your world thing?  And it's not one is better than other.  It's not you have to choose one or the other.  But it seems like people will tend to focus more  on one or the other.  All these things are matter. ", "But, where you put your heart.  It's easier.  Or you end up doing this, if you're on the  most extensive happy.  So maybe if you want somebody to do a certain thing for you, ", "you don't want them to be so happy. they have to a little  bit grumbling about stuff.  If you think the world is perfect, you're not going to  fight for political change.   So what makes us happy? ", "And it turns out in interesting ways, it's more  complicated than you think.  And so it's worth thinking about, because your first  intuitions might not pan out.  So here's an example. ", "But I want to tell you this, I'll remind you of this again.  And then switch to every day one.  So one part of happiness is that when we reconstruct what  made us happy, what made us happy growing up as a child; ", "what made as happy as an adolescent in high school;  what made us happy last year, last month, last week, that's  all out of memory.  That's not the current moment of joy or frustration. ", "That's your sense of what was it all about.  Where was I in terms of happiness?  And so Kahneman again did this work looking at pain ratings  during a dental procedure. ", "And he said, what determines your memory for  how painful it was?  And the two values were the peak of the pain and the  ending intensity. ", "So that if you added a little extra pain at the end, people  actually rated the whole session in  memory as less painful.  You add some mild pain at the end, rate it as painful, but ", "because it was mild, because the last number that goes in  their algorithm in their mind is the strength at the end,  and the other number seems to be the peak, he could predict  pretty well how you would rate the painfulness ", "of the entire session.  So this shows you that in many ways, our minds construct our  definitions of happiness.  They're not simply our sensory experience.  ", "And here is a thing you could think about for a moment.  Many of have had jobs or something.  You haven't had, most of you, a long work period on a  consistent basis, most of you I'm guessing. ", "But think about are you happier at work or vacation?  So if you ask most people are you happier at work or  vacation, most people will say vacation. ", "That's why I work 50 or 51 weeks of the year to have that  awesome vacation.   If they do a study where you carry a beeper on you and they ", "beep you every once in a while, unexpectedly, and say,  OK, one to seven, how happy are you?  And some days you're at the office and some days you're on  your vacation, what happens?  You report yourself happier at work, on average. ", "So that's amazing.  Why do we have vacations at all?  Not to be miserable.  I mean could you imagine an ad that said come to our hotel,  you'll be less miserable than another ", "hotel on your vacation.  That wouldn't work.  What do think is going on here?   This is the finding.  What's going on here in the interpretation is, when we ", "think ahead about a vacation or when we reconstruct in our  mind, there's some things about it that make  us like it a lot.  When we're on the vacation, and you may know this, and I ", "think part of it is the anticipation of vacation  sometimes, what happens?  The hotel wasn't so good.  You got that food poisoning that ruined the whole trip.  Your brother or sister were really a nuisance. ", "Your parents were a drag.  Your parents can't understand why you were so sulky.  It's was like you didn't have the space to separate out and  get yourself all sorted out. ", "I had that too as a kid.  I mean sometimes whatever little conflicts you had at  home seem to get exaggerated when you're jammed in  together, for long periods in cars or  rooms or tents or whatever. ", "And then you go that home and in a couple weeks you go man,  that was an awesome vacation.  I'll never forget it.  It means so much to me.  And it's not that you're faking it.  You really feel that.  Otherwise, you wouldn't get ready for the next vacation, ", "the next year.  So what this suggests is, in ourselves, really there's at  least two ways, or two minds, thinking about happiness.  One is a moment to moment happiness. ", "That's real.  And one is a sort of big picture,  what is my life about.  And I feel like my life about is going to interesting places  with people I care about. ", "That's a vacation.   It's not that people are hypocritical.  It's that in them there's these different dimensions of  happiness that are tapped by different moments of thought. ", " Happiness researchers, their most controversial topic,  because they can explain almost everything in the story  I just told you, is children. ", "So you talk to parents.  And over 33% will say the single biggest thing that's  the joy in their life is having children or ", "grandchildren.  That's a very common thing.  You could say you're surprised it's not more.  But still, it's a lot.  It's the single biggest thing.  And I think people really mostly believe that  when they say that. ", "If you have people keep a day-to-day diary, the  moment-to-moment source of happiness, and they rate one  to seven, everything they just did, so it's kind of fresh in ", "their memory, childcare is rated just over housework,  below sex, socializing with friends, watching TV, praying, ", "eating, and cooking.  Because again, it's this weirdness of like, oh, he's  not doing his homework or we're afraid she's doing  something or little kids are just running around, not doing ", "what you ask them to do.  And it's so frustrating because you can't get them.  So happiness researchers don't understand why people have  children at all.  They can't explain it.  There's a lot of effort going on to come  up with some formula. ", "And again, it's not that people will tell you oh, we  can't believe we had kids.  How stupid was that?  They say and they feel, it is a phenomenal source of  happiness for them. ", "It's just when you ask them, how about five minutes ago?  They go, no.  Why did he talk that way?  Why doesn't he or she listen to me?  Why don't they clean the room ever?  They're 25 years old. ", "They could make their bed.  Or whatever.  So it's really interesting, these two different dimensions  of happiness.  So this idea that within us there's multiple selves, the ", "moment to moment self, that's real.  The big picture, what is my life about?  That's real.  They're not always perfectly aligned.  ", "In the US, the moment to moment happiness, in a recent  study, increases until about $75,000.  Of course, it's an average.  Depending on what you need to buy, that number will move.  But then it tops out on average. ", "But the big picture, emotional well-being, but overall  satisfaction keeps going up with income.  Now, you have to be very careful on these.  These are all correlations. ", "Everything I've told you just about is a correlation.  So when you say overall satisfaction, sort of big  picture sense of life goes up with income, is  it really the income?  What else could it be? ", " Is it literally the size of your paycheck?  Does it have to be that? ", "Yeah?  AUDIENCE: Do you think it might be what kind of job  you're doing?  PROFESSOR: It might be the kind of job  you're doing, on average.  And we know there's phenomenally important jobs  that are underpaid in this country.  We know that. ", "But there's a lot of jobs that are kind of fun to have, that  are decently paid.  Doctors, lawyers, scientists, a lot of people find those  jobs to be pretty fulfilling and pretty decently paid. ", "And there's other ones as well.  All kinds of jobs are decently paid, that can be fulfilling.  So it's not necessarily that it's just about literally  three more dollars and you're three more dollars happy. ", "So these correlations are very tricky.  But again, the sense that moment to moment tops out at  somewhere here, well above poverty.  But then, big picture keeps going up somewhere. ", "So think for a moment if you can, just for a moment think  about yourselves five or 10 years from now.  And when you think, if you can, just for one moment  specifically imagine in your mind what you might be doing ", "five or 10 years from now.  And put your hand up if you thought of  something pretty positive.  A hope.  Put your hand up now if you thought of ", "something kind of negative.  Some of you, oh boy.   Most people, our roots claim, they think about positive ", "things in the future, other than fumbling or failing.  So how good are people at predicting what  will make them happy?  How good are people at predicting  will make them happy?  What people call affective forecasting. ", "So I'll give you two examples.  One that's closer to my life and one  might apply to everybody.  Actually, I'll tell you a word about this.  This is a funny story. ", "If I don't get tenure, I will be sad.  If I get tenure, I will be happy.  So you know what tenure basically is.  You're given a position, a faculty position, for a  lifetime, unless you do something really horrible.  So you can't be fired no matter what you do almost. ", "You get a lot of freedom from that.  So on the other hand, what happens if you don't get  tenure somewhere?  Do you know what happens?  It's not so pleasant, I could tell you.  It's not the end of the world at all. ", "But let me just tell you what know going in.  What you know going in is your colleagues are going to meet,  they're going vote.  They're going to say no.  Which kind of hurts because you've been  there five or six years. ", "And then you have to leave town.  OK, you don't have to leave town.  There could be another university nearby.  But usually because we're so super specialized in our  fields, you have to leave town and go somewhere else.  And you have to tell your parents, I didn't get tenure. ", "And you have to tell your friends, I didn't get tenure.  And all your friends who you know from work, will go, oh,  I'm sorry you didn't get tenure.  For a year, everybody you meet with goes, I'm sorry you  didn't get tenure.  So you just don't want that. ", "Well, it's a moment I mean.  None of us want it.  So everybody says, I'd rather get tenure than not.  Would you rather win the lottery, than not?  Sure ", "Happiness researchers love these things.  So it turns out for a couple of years after you don't get  tenure, and all the negativity, and leaving town,  and getting another job, and by the way, some people have  not gotten tenure and become amazing superstars, so the ", "tenure process is often incorrect in its evaluation.  But two years later, no difference in  happiness at all.  It doesn't really matter in the long run.  Winning the lottery, a year or two later, ", "no difference either.  There's a whole research field that runs out the minute  somebody wins a big lottery.  And I had a bit of experience on this, [INAUDIBLE]  somebody working in my brother's house won the single ", "largest lottery, at that time, prize ever, for an individual  lottery winner in the United States.  It's been exceeded since.  It was something like $187 million.  And she was definitely pretty happy. ", " And she's been I have to say remarkably wise since then, in  how she's used the money. ", "And been a very stable person, kind of.  But there's equal number of stories of people who get into  huge trouble.   Actually, the most amazing story, it's sort of silly to ", "share, but I have a relatively short lecture.  This was in the news.  Because you know with the lottery they say, whoever wins  this will win the single largest--  there's a huge number of tickets sold. ", "And some guy, a taxi driver at the airport, because all the  news outlets wanted to cover this.  And they were trying.  Who won?  Who won?  Who won?  They knew that there was a winner.  They didn't know who it was. ", "And a taxi driver at the airport supposedly said, I won  the lottery.  I won the lottery.  Now, we knew he didn't, because we knew this person  had won it.  But all the news channels were running after this person, ", "because other cabdrivers thought he said that.  And then apparently, all the people he owed money were  hunting him down.  And he had to hire a lawyer to sort of fight off people. ", "And so he was really miserable.  And it was really sad, weird thing to be the lottery winner  who didn't get the lottery, but everybody thought you did.  And there's other stories in towns, these are amazing  stories if you follow it, where they know somebody won ", "the lottery in the town.  But the person doesn't have to come forward.  And then you get all this weird stuff, because other  people start to guess who really has a ton of money  amongst them.  And they have wrong guesses.  And they go and say like, my mother needs medical surgery. ", "Won't you help me?  And the person doesn't have the money or maybe that one  does, but most don't.  There's only one.  And so the whole town gets into huge fights and misery  because they are assuming that somebody could do amazing ", "things for everybody, but they're just being mean  in not doing it.  And 90% of their guesses of who that is are wrong.  More than you want to know about lotteries.  But I can tell you that on average, a year or two later,  no difference.  So it's amazing. ", "You would think that would make my life,  if I won the lottery.  And probably it does in terms of plasma TVs.  But in terms of self-rated happiness, no difference.  And here's a more amazing thing in certain way, although ", "if you talk to patients, not as amazing.  If you have a unexpected accident leading to  quadriplegia or paraplegia, so you really can't get around, ", "return to typical ratings of happiness in three months.  So we're incredibly unable to predict, because we would have  all kinds of ideas about how long these would brutalize our ", "sense of happiness.  And we're wrong, wrong, wrong.  We don't know how to predict what will make us happy.  ", "And some people call this hedonic  adaptation or a set point.  That you go back to your set point over  an incredible range.  You do respond.  But you go back to it over an incredible  range of life outcomes. ", "So there's a small experiment compared to these things, but  a controlled experiment.  Dan Gilbert at Harvard, who's done amazing work in this  area, he had Harvard students in a photography class choose  their two favorite pictures from the entire class. ", "And they were told they have to give one to their teacher  and they can keep one.  And there were two conditions.  In one condition, once they gave that picture to their  teacher, that was it.  In the other condition, they could change the ", "picture in a few days.  Now, you know in all this course, every time you think  A, go opposite B, right?  But if you weren't an amazingly sophisticated ", "psychologist at this point, if you were just a person on the  street, which do you think would sound better, having no  choice or having the possibility of exchanging the  picture, if you want to, in a couple of days?  It's a choice. ", "We like choice, right?  No.  The people who are happier are the people who say once hand  me the picture, that's to me.  These people are standing around going, I don't know.  I don't know.  Where am I going to be happier, this  picture or that picture? ", "I don't know.  I don't know.  I can't tell.  Also once it's an irrevocable choice, what amazing human  thing comes into play that helps us feel  good about our lives?  Cognitive dissonance. ", "Did I pick the right picture?  That teachers is a sucker.  I thought they were the two best.  But the one that teacher took, oh, that was pretty bad.  I can't believe how lucky I am that irrevocably I ended up ", "with this picture.  The person who has days to do this, they can't let cognitive  dissonance come in and fix up their choice.  ", "The paradox of choice, why choices can be painful.  So again, we like choice.  I like choice.  There's an experiment.  People say, you go into a typical big grocery store, 285 ", "cookie choices, 13 sports drinks, 75 ice teas, 200  channels and more, on cable.   So they did an experiment in Palo Alto, Stanford's group, ", "in a gourmet food store.  They had exotic, high-quality jams.  And you could taste some jams.  And then get a coupon for $1 off if you buy the jam.  So a typical kind of thing you might see  sometimes in grocery stores. ", "And they would have you taste either six jams or up to 24.  Now, most people didn't do 24 jams.  Because you wouldn't want to have that many, even single ", "tastes of a jam.  But you'll try a few, at a table like this.  So first of all, here's the two tables.  Six jams or 24.  More shoppers came to the table of 24.  Well, you see 24 jams out there. ", "It's kind of impressive.  Like there's got be something I like there.  What's going on?  So more people are drawn to the big choice department.  Now when they get there, they only have about five jams.  These people have about six. ", "So it's about the same number of jams that you taste.  Big display, lots of choice.  Limited choice.  What happens in your actual behavior?  Well, at the six-jam table, 30% of the people ", "purchased the jam.  If there's a 24-jam table, only 3% made the purchases.  So what do you think happened?  We don't know for sure.  This is the actual behavior.  Exactly the opposite, more choices among jams led to less ", "purchases of jams.  What's your guess as to what happened?  Yeah?  AUDIENCE: They people who liked [INAUDIBLE] with 24  jams, were in a jam.  PROFESSOR: Were what?  AUDIENCE: They're in a jam.  PROFESSOR: They're in a jam.  That's pretty good.  They were in a jam. ", "Yes.  And because what?  Because I tried five or six, it's all I could try.  But there's another 20 out there.  And they could be awesome beyond belief.  And I'm not going to commit. ", "Because there could be some awesome jam around the corner.  And I've only tried five or six.  So they're overwhelmed.  Instead of happily getting a jam, they're  jammed up as you said.  Ah, ah.  And they go, um, who can begin to figure out what's the right ", "jam for me.  It's just a way too big.  So all those choices make them less likely to make a  purchase than this.  Exactly the opposite of what might intuitively-- too many  choices are burdensome.  ", "Calling plans.  I don't know if you've ever tried to compare calling plans  across phone services.  You sit down for a few moments and you just give up.  Maybe you don't. ", "Health insurance things, retirement plans.  You just get all these complicated menus.  And a lot of people just give up.  And they just go like, what's the cheapest?  What do most people do?  Because it's just too hard to figure out. ", "So when they do surveys of asking people what people  think will make them happy, these are  the most common answers.  If I get into a relationship or a marriage that I like. ", "If I have more flexibility at work.  Getting a baby, if that's what you want.  Losing weight, cure of a chronic disease, making more  money, having more time, advancing in beauty.  OK, this is the list.  ", "It's not surprising list, right?  What would make you more happy?  And again, we know that happiness set  points are about 50%.  10% estimated the circumstances, like poverty. ", "Things that you can't help in your life.  Just can't help.  But happiness researchers are trying to make the case that  about 40% of our happiness depends on what  we choose to do. ", "So that's a big piece.  It's a big piece.  We can't help some things, in our genes or in our global  environment.  But it's almost half.  And these are estimates. ", "Maybe it's more.  But this is the current estimate.  And research, over and over again, shows that it's wrong  to think that happiness is found.  Like you get there. ", "And here I am, happy.  That it's changing in your circumstances.  I move in a city.  I get a promotion.  I meet another person.  That's the happiness.  And that you either have it or you don't. ", "I'm just a person who's not happy.  All these things, the objective evidence is against.  And here's what researchers find goes with, in experiments ", "and in correlations.  Here's their list, from an objective evidence as they can  get, in this kind of work.  Time nurturing relations with family and friends comes out  as the number one thing that plays out. ", "Expressing gratitude and helping others.  Whole experiments were if you just did something nice,  people feel awesome.  I heard a Berkeley psychologist say, just try to ", "feel unhappy after you just expressed  gratitude or helped somebody.  And you can't even do it.  I don't know if that's quite true.  But experiments have shown that when you have people ", "express gratitude or do something to help others,  their happiness ratings will zoom right up.  Practicing optimism about the future, savoring life in the  present, physical exercise, commitment to lifelong goals ", "and ambitions.  A sense that you have a path that make sense to you, as  opposed to sort of bumping around from opportunity and  opportunity.  And something about, having an approach to coping or ", "resilience when bad things happen.  I'm sure in some of your lives, heartbreaking, bad  things have happened.  Most of us get some of them.  Many of us get every day things that we struggle with. ", "And the path by which we deal with adversity, huge influence  on self-reported happiness.  So again, so this is my final slide. ", "And I hope that this course, you guys have made me happy  throughout this course.  I've have incredibly pleasurable lunches and  dinners and brunches with students from the course. ", "This is just stunning for me.  And it's really moving.  And I'm just very grateful to have had the chance to  introduce you to these ideas.  Have a OK exam period. ", "You have to get through that.  Bounce back and cope.  And have a great summer.  Thanks very much. "], "vid_duration": [10.93, 10.939, 12.271, 10.34, 11.69, 11.6, 12.83, 14.005, 10.465, 11.05, 10.84, 12.7, 11.24, 10.56, 10.89, 10.54, 10.13, 11.26, 13.93, 11.189, 11.671, 12.53, 11.81, 12.34, 11.39, 12.27, 10.71, 10.08, 12.31, 14.2, 10.99, 10.59, 10.08, 12.21, 10.99, 12.94, 10.81, 11.31, 10.34, 11.82, 10.78, 12.589, 10.721, 10.799, 11.471, 10.84, 11.35, 11.66, 11.77, 10.04, 12.49, 12.94, 11.5, 14.49, 10.38, 11.046, 10.964, 10.64, 12.895, 11.295, 10.04, 11.14, 10.38, 13.73, 11.29, 10.5, 12.25, 13.51, 10.17, 11.4, 10.48, 11.41, 10.14, 12.46, 11.87, 10.5, 10.89, 11.07, 11.99, 10.77, 11.13, 11.26, 11.36, 10.11, 12.26, 10.07, 10.22, 11.92, 11.993, 10.617, 13.31, 10.36, 12.14, 12.46, 10.1, 12.82, 11.91, 11.93, 11.34, 10.32, 10.24, 10.01, 12.0, 11.74, 10.21, 14.46, 11.18, 12.37, 11.67, 13.01, 11.92, 10.71, 13.12, 12.57, 11.24, 11.95, 11.18, 12.33, 11.37, 12.23, 12.33, 21.84, 11.13, 11.15, 10.09, 10.02, 11.29, 11.75, 11.3, 10.24, 10.58, 12.86, 11.28, 11.78, 11.22, 12.21, 11.35, 13.04, 11.59, 10.0, 12.05, 10.56, 14.12, 10.45, 11.8, 11.19, 10.7, 10.21, 10.88, 11.86, 10.92, 12.58, 11.06, 11.39, 11.14, 10.44, 11.38, 16.31, 11.3, 12.16, 10.49, 11.36, 11.73, 10.28, 11.94, 11.56, 10.99, 10.27, 11.62, 12.82, 10.78, 10.267, 10.728, 12.855, 11.21, 10.41, 10.489, 11.191, 10.059, 11.81, 10.431, 10.39, 10.89, 10.32, 10.27, 11.27, 12.05, 12.18, 11.38, 10.79, 10.87, 10.26, 14.3, 11.22, 11.11, 11.46, 10.21, 12.06, 13.81, 11.9, 13.31, 11.54, 12.03, 10.57, 10.4, 11.28, 10.52, 11.61, 12.54, 12.14, 10.8, 10.76, 12.84, 10.34, 11.7, 10.64, 10.67, 12.5, 13.14, 10.28, 10.34, 10.2, 11.3, 11.24, 10.156, 11.164, 10.68, 11.65, 10.35, 11.135, 10.695, 11.34, 14.84, 10.63, 10.46, 11.84, 13.49, 10.68, 12.51, 11.76, 12.96, 14.07, 10.19, 10.62, 10.44, 10.22, 10.81, 12.44, 10.07, 10.63, 11.68, 12.06, 13.0, 11.96, 12.71, 11.03, 10.9], "stet": [[0, 10.93], [10.93, 21.869], [21.869, 34.14], [34.14, 44.480000000000004], [44.480000000000004, 56.17], [56.17, 67.77], [67.77, 80.6], [80.6, 94.60499999999999], [94.60499999999999, 105.07], [105.07, 116.11999999999999], [116.11999999999999, 126.96], [126.96, 139.66], [139.66, 150.9], [150.9, 161.46], [161.46, 172.35000000000002], [172.35000000000002, 182.89000000000001], [182.89000000000001, 193.02], [193.02, 204.28], [204.28, 218.21], [218.21, 229.399], [229.399, 241.07], [241.07, 253.6], [253.6, 265.40999999999997], [265.40999999999997, 277.74999999999994], [277.74999999999994, 289.13999999999993], [289.13999999999993, 301.4099999999999], [301.4099999999999, 312.1199999999999], [312.1199999999999, 322.1999999999999], [322.1999999999999, 334.5099999999999], [334.5099999999999, 348.70999999999987], [348.70999999999987, 359.6999999999999], [359.6999999999999, 370.28999999999985], [370.28999999999985, 380.36999999999983], [380.36999999999983, 392.5799999999998], [392.5799999999998, 403.5699999999998], [403.5699999999998, 416.5099999999998], [416.5099999999998, 427.3199999999998], [427.3199999999998, 438.6299999999998], [438.6299999999998, 448.9699999999998], [448.9699999999998, 460.7899999999998], [460.7899999999998, 471.56999999999977], [471.56999999999977, 484.15899999999976], [484.15899999999976, 494.87999999999977], [494.87999999999977, 505.67899999999975], [505.67899999999975, 517.1499999999997], [517.1499999999997, 527.9899999999998], [527.9899999999998, 539.3399999999998], [539.3399999999998, 550.9999999999998], [550.9999999999998, 562.7699999999998], [562.7699999999998, 572.8099999999997], [572.8099999999997, 585.2999999999997], [585.2999999999997, 598.2399999999998], [598.2399999999998, 609.7399999999998], [609.7399999999998, 624.2299999999998], [624.2299999999998, 634.6099999999998], [634.6099999999998, 645.6559999999998], [645.6559999999998, 656.6199999999999], [656.6199999999999, 667.2599999999999], [667.2599999999999, 680.1549999999999], [680.1549999999999, 691.4499999999998], [691.4499999999998, 701.4899999999998], [701.4899999999998, 712.6299999999998], [712.6299999999998, 723.0099999999998], [723.0099999999998, 736.7399999999998], [736.7399999999998, 748.0299999999997], [748.0299999999997, 758.5299999999997], [758.5299999999997, 770.7799999999997], [770.7799999999997, 784.2899999999997], [784.2899999999997, 794.4599999999997], [794.4599999999997, 805.8599999999997], [805.8599999999997, 816.3399999999997], [816.3399999999997, 827.7499999999997], [827.7499999999997, 837.8899999999996], [837.8899999999996, 850.3499999999997], [850.3499999999997, 862.2199999999997], [862.2199999999997, 872.7199999999997], [872.7199999999997, 883.6099999999997], [883.6099999999997, 894.6799999999997], [894.6799999999997, 906.6699999999997], [906.6699999999997, 917.4399999999997], [917.4399999999997, 928.5699999999997], [928.5699999999997, 939.8299999999997], [939.8299999999997, 951.1899999999997], [951.1899999999997, 961.2999999999997], [961.2999999999997, 973.5599999999997], [973.5599999999997, 983.6299999999998], [983.6299999999998, 993.8499999999998], [993.8499999999998, 1005.7699999999998], [1005.7699999999998, 1017.7629999999998], [1017.7629999999998, 1028.3799999999999], [1028.3799999999999, 1041.6899999999998], [1041.6899999999998, 1052.0499999999997], [1052.0499999999997, 1064.1899999999998], [1064.1899999999998, 1076.6499999999999], [1076.6499999999999, 1086.7499999999998], [1086.7499999999998, 1099.5699999999997], [1099.5699999999997, 1111.4799999999998], [1111.4799999999998, 1123.4099999999999], [1123.4099999999999, 1134.7499999999998], [1134.7499999999998, 1145.0699999999997], [1145.0699999999997, 1155.3099999999997], [1155.3099999999997, 1165.3199999999997], [1165.3199999999997, 1177.3199999999997], [1177.3199999999997, 1189.0599999999997], [1189.0599999999997, 1199.2699999999998], [1199.2699999999998, 1213.7299999999998], [1213.7299999999998, 1224.9099999999999], [1224.9099999999999, 1237.2799999999997], [1237.2799999999997, 1248.9499999999998], [1248.9499999999998, 1261.9599999999998], [1261.9599999999998, 1273.8799999999999], [1273.8799999999999, 1284.59], [1284.59, 1297.7099999999998], [1297.7099999999998, 1310.2799999999997], [1310.2799999999997, 1321.5199999999998], [1321.5199999999998, 1333.4699999999998], [1333.4699999999998, 1344.6499999999999], [1344.6499999999999, 1356.9799999999998], [1356.9799999999998, 1368.3499999999997], [1368.3499999999997, 1380.5799999999997], [1380.5799999999997, 1392.9099999999996], [1392.9099999999996, 1414.7499999999995], [1414.7499999999995, 1425.8799999999997], [1425.8799999999997, 1437.0299999999997], [1437.0299999999997, 1447.1199999999997], [1447.1199999999997, 1457.1399999999996], [1457.1399999999996, 1468.4299999999996], [1468.4299999999996, 1480.1799999999996], [1480.1799999999996, 1491.4799999999996], [1491.4799999999996, 1501.7199999999996], [1501.7199999999996, 1512.2999999999995], [1512.2999999999995, 1525.1599999999994], [1525.1599999999994, 1536.4399999999994], [1536.4399999999994, 1548.2199999999993], [1548.2199999999993, 1559.4399999999994], [1559.4399999999994, 1571.6499999999994], [1571.6499999999994, 1582.9999999999993], [1582.9999999999993, 1596.0399999999993], [1596.0399999999993, 1607.6299999999992], [1607.6299999999992, 1617.6299999999992], [1617.6299999999992, 1629.6799999999992], [1629.6799999999992, 1640.239999999999], [1640.239999999999, 1654.359999999999], [1654.359999999999, 1664.809999999999], [1664.809999999999, 1676.609999999999], [1676.609999999999, 1687.799999999999], [1687.799999999999, 1698.499999999999], [1698.499999999999, 1708.7099999999991], [1708.7099999999991, 1719.5899999999992], [1719.5899999999992, 1731.4499999999991], [1731.4499999999991, 1742.3699999999992], [1742.3699999999992, 1754.9499999999991], [1754.9499999999991, 1766.009999999999], [1766.009999999999, 1777.3999999999992], [1777.3999999999992, 1788.5399999999993], [1788.5399999999993, 1798.9799999999993], [1798.9799999999993, 1810.3599999999994], [1810.3599999999994, 1826.6699999999994], [1826.6699999999994, 1837.9699999999993], [1837.9699999999993, 1850.1299999999994], [1850.1299999999994, 1860.6199999999994], [1860.6199999999994, 1871.9799999999993], [1871.9799999999993, 1883.7099999999994], [1883.7099999999994, 1893.9899999999993], [1893.9899999999993, 1905.9299999999994], [1905.9299999999994, 1917.4899999999993], [1917.4899999999993, 1928.4799999999993], [1928.4799999999993, 1938.7499999999993], [1938.7499999999993, 1950.3699999999992], [1950.3699999999992, 1963.1899999999991], [1963.1899999999991, 1973.9699999999991], [1973.9699999999991, 1984.2369999999992], [1984.2369999999992, 1994.9649999999992], [1994.9649999999992, 2007.8199999999993], [2007.8199999999993, 2019.0299999999993], [2019.0299999999993, 2029.4399999999994], [2029.4399999999994, 2039.9289999999994], [2039.9289999999994, 2051.1199999999994], [2051.1199999999994, 2061.1789999999996], [2061.1789999999996, 2072.9889999999996], [2072.9889999999996, 2083.4199999999996], [2083.4199999999996, 2093.8099999999995], [2093.8099999999995, 2104.6999999999994], [2104.6999999999994, 2115.0199999999995], [2115.0199999999995, 2125.2899999999995], [2125.2899999999995, 2136.5599999999995], [2136.5599999999995, 2148.6099999999997], [2148.6099999999997, 2160.7899999999995], [2160.7899999999995, 2172.1699999999996], [2172.1699999999996, 2182.9599999999996], [2182.9599999999996, 2193.8299999999995], [2193.8299999999995, 2204.0899999999997], [2204.0899999999997, 2218.39], [2218.39, 2229.6099999999997], [2229.6099999999997, 2240.72], [2240.72, 2252.18], [2252.18, 2262.39], [2262.39, 2274.45], [2274.45, 2288.2599999999998], [2288.2599999999998, 2300.16], [2300.16, 2313.47], [2313.47, 2325.0099999999998], [2325.0099999999998, 2337.04], [2337.04, 2347.61], [2347.61, 2358.01], [2358.01, 2369.2900000000004], [2369.2900000000004, 2379.8100000000004], [2379.8100000000004, 2391.4200000000005], [2391.4200000000005, 2403.9600000000005], [2403.9600000000005, 2416.1000000000004], [2416.1000000000004, 2426.9000000000005], [2426.9000000000005, 2437.6600000000008], [2437.6600000000008, 2450.500000000001], [2450.500000000001, 2460.840000000001], [2460.840000000001, 2472.540000000001], [2472.540000000001, 2483.1800000000007], [2483.1800000000007, 2493.850000000001], [2493.850000000001, 2506.350000000001], [2506.350000000001, 2519.4900000000007], [2519.4900000000007, 2529.770000000001], [2529.770000000001, 2540.110000000001], [2540.110000000001, 2550.310000000001], [2550.310000000001, 2561.610000000001], [2561.610000000001, 2572.850000000001], [2572.850000000001, 2583.0060000000008], [2583.0060000000008, 2594.170000000001], [2594.170000000001, 2604.850000000001], [2604.850000000001, 2616.500000000001], [2616.500000000001, 2626.850000000001], [2626.850000000001, 2637.985000000001], [2637.985000000001, 2648.680000000001], [2648.680000000001, 2660.0200000000013], [2660.0200000000013, 2674.8600000000015], [2674.8600000000015, 2685.4900000000016], [2685.4900000000016, 2695.9500000000016], [2695.9500000000016, 2707.790000000002], [2707.790000000002, 2721.2800000000016], [2721.2800000000016, 2731.9600000000014], [2731.9600000000014, 2744.4700000000016], [2744.4700000000016, 2756.230000000002], [2756.230000000002, 2769.190000000002], [2769.190000000002, 2783.260000000002], [2783.260000000002, 2793.450000000002], [2793.450000000002, 2804.070000000002], [2804.070000000002, 2814.510000000002], [2814.510000000002, 2824.730000000002], [2824.730000000002, 2835.540000000002], [2835.540000000002, 2847.980000000002], [2847.980000000002, 2858.050000000002], [2858.050000000002, 2868.680000000002], [2868.680000000002, 2880.360000000002], [2880.360000000002, 2892.420000000002], [2892.420000000002, 2905.420000000002], [2905.420000000002, 2917.380000000002], [2917.380000000002, 2930.090000000002], [2930.090000000002, 2941.120000000002], [2941.120000000002, 2952.0200000000023]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [817, 1685, 2952]}
{"example_id": "mit057@@MIT9_00SCF11_lec13_300k", "text": ["PROFESSOR: In a way, I would say most of this course up  until today, or maybe the memory lecture, was about how  brilliant the human mind and brain is.  How the visual system is so brilliant nobody can make a ", "machine that sees so well.  We didn't talk too much about physical action.  But how we move in the world, how we act upon the world,  there's no robot that can compete with you.  Language is far beyond computers to be nearly as ", "sophisticated as you are, as a five-year-old is.  So in all those domains, we mostly think about in terms of  psychology or brain function, how is it that we're endowed ", "with such amazing capacities?  When it comes to thinking, one of the highest forms of human  activity, thinking, hard problem solving, edges of  creativity, that kinds of thing, it's something we have ", "a huge respect for, something we wish for, something that we  know is a very, very valuable tool.  But psychologists have emphasized the  traps we can fall in.  I mean in a way what's easy for us is what the brain ", "empowers in us.  It's easy for us to recognize objects or faces  or move in the world.  When we feel something is hard, like thinking hard, for  problem sets or global warming or other things that are hard ", "to think about, then we know that we're sort of leaving the  apparatus that's easy for us and we're entering into a  hazardous, difficult form of our mental lives. ", "So, I'm going to show you a video for a moment.  Because the other fun thing is, and maybe this is true of  all of us in different ways, all the time, we often don't ", "recognize, we often don't recognize when we're thinking  not as well as we might.  So this is a trap.  So I'm going to show you, the original punking TV show, this ", "was called Candid Camera.  It's pretty old.  So this is a clip from there.  And here's a couple people asked to do a school problem,  7/8 divided by 3/4 and how many square  feet in a square yard? ", "And what's kind of funny about it in my mind is, not only  that the people are wrong, but how wrong they are and how  much they don't realize sometimes how wrong they are.  ", "I mean what's impressive about this is that not only are the  people wrong, but they don't say like, I forget.  They just start to give answers, throwing out numbers. ", "And so how different are all of us in that?  So some of these again are on the internet.  And this is an MIT audience, which is about the hardest  audience to pull this off.  And at Stanford, I could pull this off much better. ", "So some of these won't go as easily as they might for other  typical audiences.  Here we go.  Two train stations are a hundred miles apart.  At 2:00 PM one Saturday afternoon, the two trains  start toward each other, one from each station. ", "One travels at 60 miles an hour, the other  at 40 miles an hour.  Just as the trains pulls out of their stations, a bird  springs into the air in front of the first train, and flies  ahead to the front of the second.  When the bird reaches the second, it turns back, without  losing any speed, and flies directly ", "toward the first step.  Doesn't this remind you of all the high school physics  problems you had earlier?  Where's the frictionless pulley?  The bird continues to fly back and forth between the trains  at 80 miles an hour.  How many miles will the bird have flown ", "before the trains meet?  It's a little bit of a trick.  Because the answer is told to you directly, pretty much.  So 100 miles apart. ", "How long will it take for the trains to reach each other, if  one is 60 miles an hour and one is 40 miles an hour?  AUDIENCE: Hour.  PROFESSOR: Hour.  So how many miles an hour does the bird fly? ", "AUDIENCE: 80.  Easier than you think.   So those are the kinds of ones I just showed that people kind  of get themselves into their thinking cap. ", "And it's a trick.  Here we go.  I need somebody who is willing to, at their chair,  just call out words.  ", "Thank you very much.  Here we go.  In English, many words are pronounced somewhat  differently depending on the way they are spelled.  But here we go.  Can you give me a synonym for people or family, a word that ", "people would often say for that?  I'll give you one.  Folk.  Now, I know this is a history quiz.  But I'll help you.  I wouldn't know the answer to this, necessarily. ", "Can you give me the name of an American president at the time  of the Mexican War?  And I'll give you a hint.  It rhymes with folk.  AUDIENCE: Polk.  PROFESSOR: Polk.  Everybody can help.  Everybody help.  One, two, three.  Can you give me the name of the word that means egg white? ", "AUDIENCE: Yolk.  PROFESSOR: Aha.  No.  Is the yolk, the egg white?   I know.  It's a pretty hilarious course.  Thank you. ", "So this is an example of what people  call functional fixedness.  Your mind is going a certain way.  And you're on a certain pace.  And all of a sudden when you need to put the mental break ", "on, your habit of thought takes you a slightly wrong  direction, on a very superficial test.  Thank you very much.  Here's an experiment. ", "In 10 minutes, only about 39% of people solve this.  You go into a room like this.  The strings are too far apart.  You have stuff around here.  And your job to tie the strings together. ", "What do you do?   AUDIENCE: Stand on the chair?  PROFESSOR: Standing on the chair is an interesting one.  Let's pretend it doesn't work. ", "It wouldn't.  It would get you up, but they'd be far apart still.  It could.  Let's pretend it doesn't.  You'd have to be there, to be convinced.  You know what I mean.  It mean depends on the angle.  ", "AUDIENCE: [INAUDIBLE].  PROFESSOR: Sorry?  AUDIENCE: Tie it to the end.  PROFESSOR: Ah.  So you're one of the 39%.  So the idea is, if you tie for example, the pliers onto the ", "thing and get it swinging, you could catch it, right?  So why don't people come up with that answer very easily?  PROFESSOR: Because what are pliers for? ", "Pliering.  They're not for swinging ropes.  So again, the word they use is functional fixedness.  You know what a plier is for.  It doesn't seem like a good candidate to do this job. ", "Here's another one.  You walk into a room and there's a door that's closed  behind you.  And you see these things on a table.  And you're asked, could you support this  candle on the door?  About 23% of people get this, in 1945. ", "What do you do?  This is just like all the spy movies.  Yes?  AUDIENCE: [INAUDIBLE].   PROFESSOR: Sorry? ", "AUDIENCE: Put the tacks through the width of the door.  PROFESSOR: Yeah, through the width of door  would be pretty good.  It's not really supporting the candle, but it  could get the job done.  That's not a bad thought.  These are all good thoughts.  If it were me, I wouldn't be close. ", "So that's better than I do.  Yeah?  AUDIENCE: Take out the tacks and then tack the base.  PROFESSOR: Have you see this before?  No.  Excellent.  As I tell you, MIT's audience is not an easy audience. ", "The idea is that you dump the tacks, and then stick the tack  into the back of the empty box.  Nice platform for a candle.  Why don't most people think about that? ", "Because what's the job of the box?  To hold the tacks.  My job is to figure out this problem.  You hang on to the tacks. ", "And in fact if they do the same experiment, but just put  the tacks next to the box, a lot of people  get it right away.  Because now that box, it's yearning to support something.  It no longer has a job. ", "It's an unemployed box that you can stick onto the door  and support this.  Your mind just gets stuck with thinking the box is a holder.  It's not a platform.  ", "This is the original-- and you've seen this so  many times by now.  This is one of the original, thinking outside of the box  things, where you're supposed to connect the dots with four  straight lines without lifting a pencil.  ", "Some of you know this.  Some of you are figuring out on the spot.  But I'll just show you.  So there's an answer.  The other ones are similar.  Why do so many people get stuck in this ", "and not get it done?  Because they don't like this part.  And they don't like this part, because it's  drawing outside the box.  They're always looking for the connections within the box. ", "And it seems cheating in some sense to draw outside the box.  There's an intuition, like with the box with the tacks,  that you're supposed to stay in there.  So if they get no information in this study, practically ", "nobody solved it, in a given time.  If they get a hint, you can draw outside the  square, that helps.  But then, outside the square puts again, the first line.  They're still only half the time getting it. ", "Because you've got to go outside a second time.  So it gets a lot of information to get comfortable  with finding a way to do this that's completely within the  rules, but not the way you intuitively feel might be the ", "right way to do it.  So those are all examples of functional fixedness, where  you have a certain belief about what's going on and it's  hard to overcome that to solve a problem in a novel way. ", "Another thing that people think about as the way to  overcome some of these problems of thinking about  problems is different representations that let you  take a different look at a problem to be solved. ", "So picture a large piece of paper, a  hundredth of an inch thick.  Now, in your imagination, fold it once.  You have two layers.  Continue to fold it on itself 50 times.  It's true that's it's impossible to fold it in  place, such a piece of paper, 50 times. ", "But for the sake of the problem, imagining that you  can, about how thick would the 50-times-folded paper be?  And everybody's first intuition is, well, how thick  can a piece of paper be?  Of course, this is a hypothetical problem, not an ", "actual paper problem.  But if you do the math, it's big.   So here's another one.  ", "One morning, exactly at sunrise, a Buddhist monk began  to climb a tall mountain.  A narrow path no more than a foot or two wide, spiraled  around the mountain to a glittering  temple at the summit.  The monk ascended at various rates of speed, stopping many ", "times along the way to rest and eat dried fruit he  carried with him.  He reached the temple shortly before sunset.  After several days of fasting and meditation, he began his  journey back along the same path, starting it at sunrise  and again walking at variable speeds, with many ", "pauses along the way.  His average speed descending was, of course, greater than  his average climbing speed.  Show that there's a spot along the path that the monk will  occupy on both trips at precisely the  same time of day. ", "So that sounds moderately hard.  But if you draw the picture, so we  went and get an equation.  Now, we have a pictorial representation.  You can see there has to be some moment of the ascending ", "and descending path that cross in time.  You don't know what it's going to be.  But there has to be some moment in time.  And maybe that's obvious.  But for a lot of people it seems stunningly complicated  that you could even demonstrate that ", "in any way at all.  Here's one you could think about.  Suppose you are a doctor faced with a patient who has a  malignant tumor in his stomach.  It's impossible to operate on the tumor, but unless the ", "tumor is destroyed the patient will die.  There's a kind of ray that can be used to destroy the tumor.  If the rays reach the tumor all at once, with sufficiently  high intensity, the tumor will be destroyed.  Unfortunately, at this high intensity the healthy tissue ", "that the rays pass through, will also be destroyed.  At lower intensity, the rays are harmless to healthy  tissue, but they don't affect the tumor either.  What type of procedure might be used to destroy the tumor ", "with the rays, and at the same time avoid destroying the  healthy tissue?  Now, if you know the answer to this, don't jump right up.  Give other people a few moments to puzzle.  ", "About 10% of people solve this in a small unit of time,  before the Internet.   And so, what's the answer though, for those of you? ", "Yeah, I see some hands, I think.  Go ahead.  Did you want to say?  AUDIENCE: [INAUDIBLE].  PROFESSOR: No.  Exactly at the spot, sir.  AUDIENCE: [INAUDIBLE].  PROFESSOR: Yeah.  Have several weak ones aimed to converge at the tumor. ", "I saw your hands.  So the idea is to have several different rays, each of which  are weak enough not to destroy the tissue.  But when they converge spatially at the tumor, they  would sum enough to destroy the tumor. ", "That's the problem-solving answer to this.  So knowing that, here's another kind of a problem.  A dictator ruled a small country from a fortress.  The fortress was situated in the middle of the country and ", "many roads radiated outward from it,  like spokes in a wheel.  A great general vowed to capture the fortress and free  the country of the dictator.  The general knew that if the entire army could attack the  fortress at once, it could be captured. ", "But a spy reported that the dictator had planted mines on  each of the roads.  The mines were set so that small bodies of men could pass  over them safely, since dictator needed to be able to  move troops and workers about. ", "However, any large force would detonate the mines.  Not only would this blow up the road, but the dictator  would destroy many villages in retaliation.  A full-scale, direct attack on the fortress seemed  impossible. ", "Does this problem remind you of the other problem, I mean  back-to-back, like this?  He divided his army up into small groups.  Now, they're small enough per path into the castle.  And they converge on the castle, like the X-rays ", "converged on the tumor.  So this is reasoning by analogy.  We have problem solving approach.  Divide your resources spatially.  Have them meet at the same time, and converge in a way  that's effective.  So what you might call the deep structure of the problem ", "is the same, with the surface story being different.  One is tumors and treatments.  But there's a strict analogy.  Capturing the castle is like destroying the tumor.  The fortress is like the tumor that you want to get to. ", "The army is like the rays and the  general is like the doctor.  So if it is back-to-back like this, where I just said,  here's a problem.  And here's a problem just like that. ", "Everybody says, well, send the troops on the different paths  and have them converge at the same time.  If you don't say that though, if you don't tell people this  is the same, use the same rule. ", "If you don't tell people that, only about a third come up  with it spontaneously.  If you just make a little bit of an effort not to make it  completely obvious that it's the same problem.  You just wait a little bit. ", " So the surface differences, the war story versus the  medical story, will mostly throw people from recognizing ", "the analogies.  People recognize surface analogies all the time.  If we have war in the Middle East now, from the US  perspective there's analogies to Vietnam, a war and a war. ", "But other kinds of analogies across situations, people have  a hard time mapping, if the surfaces look different.  And here's an example where they gave people two problems  of a certain kind. ", "And they said as part of the experiment, and here's a  classroom demonstration.  If it's immediate, they sort of get it.  But if they wait just a little bit, and they move from one  room to another room, they don't apply the rule at all. ", "So it's very tricky.  We would like to think well, gee, we know all kinds of  things about the world, that we can bring in a mental  toolkit to solve problems, all kinds of ideas.  But if the problem doesn't look the same as the prior ", "problem, people have a hard time spontaneously saying,  there's an answer I know, and I can apply it to the  situation, unless it's really, really obvious.  People don't transfer deep solutions very easily across ", "what looks like different situations.   Something different.  The instructors in a flight school adopted a policy of  consistent, positive reinforcement, recommended by  psychologists. ", "And we know we're very suspicious about  psychologists, right?  But you have to imagine the instructor went to some  classroom and somebody said, positive reinforcement  is the way to go. ", "They verbally reinforced each successful execution of a  flight maneuver.  After some experience with this training approach, the  instructors claimed that contrary to psychological  doctrine, high praise for good execution of complex maneuvers ", "typically result in a decrement of performance on  the next try.  Are they correct?  So you understand, you have to have in your mind all the  military movies where there's a really  tough sergeant training. ", "The other one that yells at you to make you succeed.  But for half the movie, you don't know if the sergeant  will break you or make you into a better woman or a  better man.  So he's barking orders.  And some psychologist says, well, you should really think ", "about saying nice things to these people, because that's  encouraging.  Errgh.  Somebody does a flight maneuver and does  a really good job.  And he goes, that's awesome.  And then the person goes up and does worse.  And he goes aargh, you're all terrible. ", "So what's happening?  Yeah.  ", "AUDIENCE: It must-- the person typically does really well.  Doing really well one time isn't indicative of really  well the next time.  PROFESSOR: It's even worse than that, right.  So all of us have in us a range of performance. ", "We know that.  If you do sports, if you do research, if you do anything,  some days we're at our average.  Some days, we're not so good.  Some days, we go wow, that was pretty good. ", "We all have a range of performance that's possible,  our average performance, our best days, our worst days.  So you just went up and you did an  awesome flight maneuver. ", "Is that your average one or is that a peak example?   It's a peak example.  Statistically, what's the likelihood of your next one ", "going to be, better or worse?  Worse.   You can't always be at your best, because you'd sort of go  into infinite excellence. ", "You have a range of performance.   In the NBA, what's a really good score?  30 points is really good.  That's the average though, of the best players. ", "They don't go out and go, I got 30 tonight.  And tomorrow, I'll get 32.  And by the end of the season, I have like 180  points every game.  Even if you're on the Miami Heat, you have  to do a good job. ", "So do you understand?  So here's another example.  Parents of very famous, successful kids, are they  mostly super-famous and super-successful? ", "Or do we mostly read about them and go whoa, that's a  tough deal, what happened there?  What's your impression?   Let's ask this question-- ", "and if you are facing these burdens.  If your parent wins a Nobel Prize, what's the odds that  you win a Nobel Prize.  Small.  And they go oh, the underachieving kid. ", "All the pressure from the parent to do really well, with  a Nobel Laureate as your parent.  Well, maybe.  Maybe your parent is berating from kindergarten on saying,  if you don't eat your peas and carrots, you won't win a Nobel ", "Prize, like I. That's a possibility.  We can't rule it out.  But if somebody in your family wins a Nobel Prize, what's the  odds that other people in your family will win that.  PROFESSOR: Yeah.  So we call that regression to the mean. ", "If you have an outstanding example, a person who wins a  Nobel Prize, everybody around them is not likely to win.  If you have an outstanding day at what you do, like a really ", "good day, the next day is likely to be worse, just  statistically.  So what's happening with this flight instructor?  This is a very powerful and important idea, that  intuitively often, what's happening with the flight ", "instructor?  Of course if the guy does awesome, he's going to do  worse the next time, every single time, practically,  statistically.  So we can think about this, regression to the mean. ", "Here's a standard  distribution, bell-shaped curve.  Here's the mean of whatever you do, how well you shoot  baskets, how well you study for a test, how well you wrote  a paper, how well you helped a friend who needed consoling. ", "You pick your thing.  Some days you do a medium job.  You're average.  Some days you really impress yourself with how you did.  And some days, you're pretty shocked at what a miserable ", "day you had.  Does that makes sense?  So if you had an awesome outing, by average, the next  outing is going to be less good, regression to the mean.  ", "So one place that this has been done over and over and  over again, and somebody help me out here.  This could happen in any sport.  But especially in basketball, people talk about a hot hand. ", "So some of you are sports enthusiasts.  Probably some of you are not.  So a sports enthusiast, will you please help me describe  what a hot hand is in basketball? ", "Help the rest of the class.  Oh, thanks.  AUDIENCE: You think you're on a hot streak just because you  made a couple baskets in row.  But they do the statistics and then it ends up being that  they're just overconfident in their shots, since they are ", "shooting more shots in the end.  PROFESSOR: So people have a saying --  If you watch a basketball game, it's incredibly how  often the announcer will say, oh, player x, he  or she is on a tear. ", "They're so hot.  Pass that ball to that person.  They're so hot.  They shoot a three-pointer.  And they come down and they shoot a three-pointer.  And they say, why are you passing the  ball to that person?  They're so hot.  And some players are known as streaky players, who go out ", "and have just awesome nights.  You hear this in the sports all the time.  I can't tell you, the end of a close March Madness game,  they're always saying, pass it to this guy.  Because this guy is on a streak in this game. ", " So they can do the statistics.  How would you do the statistic to know  whether streaks actually--  streaks exist.  Sometimes you do two baskets in a row or five. ", "Or you miss five in a row.  There are runs, like heads and tails.  But the question we're asking is, if you made a shot, does  that an increase in any short run, the probability that  you'll make the next shot? ", "That would be the streak.  That would be the hot shooter.  So you can go do statistics.  And they did it.  Psychologists have done it on many teams, in many leagues.  They did every single shot of a Cornell basketball team, the  entire season. ", "But they've done it on many other teams.  There is no such thing as a hot streak.  There is no such thing as a hot streak.  Of course, you have small runs, where people have a lot  of good shots.  Another day, they'll have a lot of bad shots. ", "But the probability of making any one shot is no higher or  lower, given the probability that you made the prior shot.  They're completely independent.  And nobody can find statistical support for any  kind of streaks in sports, except of course you have huge ", "distributions.  So sometimes a person will have an  exceptionally good or bad night.   So this is kind of like that.  And you will get this.  Suppose that you have a normal penny with a head and a tail. ", "You toss it six times.  Which is these outcomes is most likely?   All the same.  You're absolutely right.  But why do people tend not to like a), mostly, who haven't ", "studied probability much?  They don't like a).  Why don't they like a)?   Most people, most of the time, as a random thing?  Yeah? ", "AUDIENCE: It doesn't look random.  PROFESSOR: It doesn't look random, man.  A) can't be random, right?  But we know that we have short runs of anything.  And each of these are independent outcomes.  That's exactly what you got.  ", "We did this example before.  But there are 30 people in the group.  You get the month and date of each person's birthday.  What is the approximate probability that two people  have the exact same birthday?  And most people will say, oh, I haven't met that many people ", "on my birthday.  Not that high.  But it's actually 70%.  Because it's any two in the group.  It's not you.  It's any two in the group.  And that increases it to 70%. ", "Here's one we haven't done.  Imagine a college in which the average height of men is 175  centimeters.  You randomly measure the height of three men.  Which of these two outcomes is more likely?  And I'll let you think about this for a moment. ", "John at 178, Mike at 170, and Bob at 176; or John at 177,  Mike at 177, and Bob at 177?  Which is more likely, or can't tell?  AUDIENCE: [INAUDIBLE]. ", " PROFESSOR: I heard a B. Is it obvious? ", "Let me tell you.  It's the same concept we've been talking about, about  distributions and means.  So here's the average, which you are given as 175.  So these guys are closer to the average. ", "Height is distributed in a normalized way.  So here's the three people, who are red dots, the equal  heights, 177, and 177, and 177.  Here are the heights of the blue. ", "There's more people in this part of the distribution.  So it's actually more likely to get this than this, about  40% more likely.  Because you're sampling from closer to the mean.  And there are more people near the mean. ", "Does that make sense?  But people don't like that.  Overwhelmingly, if you ask people, they like the top  answer, because it just doesn't feel right to get  three people of equal height, in a random way. ", "And you could say, what do you mean it doesn't feel right?  We can do the math or we can show you the picture.  And we can all agree, I think, that that's correct.  What do you mean it doesn't feel right? ", "And that's what people mean by the difference between  algorithms and heuristics.  This is work from Kahneman and Tversky, that won a Noble  Prize for Danny Kahneman.  Tversky passed away.  Which is that humans could figure out many things ", "algorithmically.  You can do the probability.  But as an intuition, for many, many, many people, even  educated people who know a lot about probability.  There's an intuition that we have about things, heuristics, ", "a feeling we have about things.  Like the odds of this are almost nil.  And we go by that feeling, instead of by being the  rational analyst that we might be. ", "Here's one.  You'll get this one, I think.  A nearby town is served by two hospitals.  About 45 babies are born each day in the larger, about 15 in  the smaller.  Approximately half of the babies are boys.  However, the exact percentage varies day to ", "day, of boys and girls.  Some days, it's higher than 50%.  Some days, lower.  For a period of a year, both the larger and the smaller  hospital recorded the number of days in which more than 60%  of the babies were boys. ", "So a disproportionate number were boys.  Which hospital do you think recorded more such days?  ", "The answer is about the same.  The most common answer is about the same.  But because of the law of small numbers, you're going to ", "get more weird samples in the smaller hospital.   Because it'll be a less of a distribution.  You'll get more weird stuff.  Here's one. ", "It's a little dated, in terms of the language used.  But they would give people an example of this.  Linda is a 31-year-old, single,  outspoken, very bright.  She majored in philosophy as a student.  She was deeply concerned with the issue of discrimination ", "and social justice and also participated in antinuclear  demonstrations.  And then rank the options in terms of their likelihood.  In describing Linda, I'll give a ranking of 1 to the most  likely option and a ranking of 8 to the least likely option. ", "So people go through this.  I mean you're sort of just making up stuff.  Having said this, I think people go around all the time  having impressions of people in their head, what are they  really like, what are they really about. ", "But they do this kind of thing.  And here's the interesting element to the result.  People on average, are more likely to endorse the  statement, Linda is a bank teller and active in the ", "feminist movement, than Linda is a bank teller.  Now, why logically is that a bad idea, as you're guessing  about Linda and what you might do? ", "Why is it logically a bad idea to pick h, more than f?  AUDIENCE: [INAUDIBLE].  PROFESSOR: Right.  Yeah.  Yeah.  Just logically, heuristically, algorithmically, right, sorry, ", "it's more likely you'd be correct saying  she's a bank teller.  She's a bank teller and shes--  But why do you think more people pick this one?   Because of your intuition. ", "So people think, well this is a person who  might be like this?  So they go for the bigger description.  And not just unsuspecting undergraduates, but also  first-year grad students in stats courses, and also  doctoral students in decision science programs ", "and business school.  It's not, with more training you can avert these errors.  But everybody has it in them pretty easily to be seduced by  intuitive heuristics of reasoning, rather than ", "algorithmic analyses.  Availability is kind of fun.  So this is a slow one.   This example is a little work, for an example. ", "Some experts studied the frequency of appearance of  various letters in the English language.  They studied a typical passage in English and recorded the  relative frequency with which various letters of the  alphabet appeared in the first and the third  positions of words.  For example, in the word \"language,\" appears \"L\" ", "appears in the first position and \"N\" appears in the third.  In this study, words with less than three  letters were not examined.  Consider the letter \"K.\" Do you think that the K is more  likely to appear in the first position  or the third position? ", "Now estimate the ratio for the number of times it appears in  the first versus the third.  So it could be even, 1:1; it could be more often in the  third position, like 1:2; or it could twice as often in the ", "first position.  Any feelings?   Just for fun, who thinks K appears more often in the  first word than the third? ", "Just for fun.  Help me out here.  Hands up.  If you have to pick one or the other.  You have to pick one or the other.  How many people like in the third position?  Anyway, so here's what happens mostly. ", "Not your estimate, but the estimate of  students in larger samples.  2:1, they like K in the first position.  It's really 1:2 in the dictionary.  Why do you think on average, people tend to go for K in the ", "first position?  So now we need somebody who's willing to say something, give  some answers out there.  Yeah?  AUDIENCE: Because it's easier to think of words that start  with K than it is-- ", "PROFESSOR: Yes.  So help me out.  Let's do this for one second.  Somebody call out a K word, any word?  AUDIENCE: Knight.  PROFESSOR: Knight.  Another word?  AUDIENCE: Kind.  PROFESSOR: Kind.  Another word? ", "AUDIENCE: Kangaroo.  PROFESSOR: Kangaroo.  Excellent.  OK, very good.  OK, quick, a K in the third position?  AUDIENCE: [INAUDIBLE].  PROFESSOR: Oh, you guys are--   I should have done it differently. ", "So now we're talking about the heuristic of availability,  that we sort of think that how common something is and then  in some ways, how important something is, by the ease with ", "which it comes to mind.  It's easier really to think of words beginning with K, then  having K in the third position.  Here's a question.  How much more likely are you, and I don't know the answer to ", "this, but you can figure it out, to drown in the bathtub  than to die from a terrorist attack in the United States?  Obviously since 9/11, terrorism has been a a huge  issue in our county, a huge issue.  But in the US, what do you think? ", "Much more likely for people to die drowning in a bathtub than  terrorist attacks, including 9/11, for the 2000s.  So why is it, why is it that you have constant discussion ", "about terrorism?  Why is it that you take off your shoes and can't take much  of your toothpaste on the airplane?  And yet nobody is talking to you, saying, please exercise ", "caution when you go into the bathroom.  And please have those things, those sticky things that make  it less likely to slip.  Do you get much of that?  Do you go to the airport and they say, those shoes look a  little slippery, in case you go into a shower. ", "So think about this, which is the real danger, just in a  practical way, and why do people worry so much, and not  for bad reasons, about terrorism?  What's the difference between them? ", "And you can think of more than one.  Yeah?  AUDIENCE: You hear about terrorism on the news, but you  don't hear about anyone drowning in the bathtub.  PROFESSOR: That's huge.  Availability is huge.  The news is a very powerful way in which we think that's ", "what the world is full of, terrorism in the US.  We hear about terror groups that are found, terror cells  that are found.  We'll hear about homicides a little bit, in the local news. ", "But you just never hear about, unless it unfortunately  happens to somebody you know personally, somebody slipping  and dying in the bathtub.  And it does happen.  But you don't hear about it much.  It's not available to you.  Yeah?  AUDIENCE: We're most scared of things that are foreign to us ", "even if they are less dangerous.  Like we'd be more likely to drink a clear fluid that was  more dangerous than something that looks scary.  PROFESSOR: Part of it is, what you're saying, there's a sense  of foreignness to the terrorism that we don't ", "understand.  Maybe there's a sense of passivity.  We feel like we could do something about the bathroom.  We can't do something about an airplane being  driven into a building.  These things are complicated.  But it's fascinating what people think is scary versus ", "what by any rational analysis, is dangerous.   Here's another kind of way that people easily struggle  with numbers and thinking about what's ", "dangerous and not.  So imagine you're a physician and you're presented with this  information.  And let's hypothesize that it's true.  Somebody comes in with dizziness.  And they say, I'm worried about a brain tumor.  They go to your neurologist. ", "And the neurologist says well, here we have some statistics  over the last two years, whether somebody turned out to  have a brain tumor or not, present or absent; and whether  they were dizzy or not, present or absent.  So you can make a 2 x 2 cell, about they had a tumor and ", "they reported dizziness; they reported dizziness, but it  turns out they had the tumor; and so on.  So here's the question for you.  Is being dizzy something to worry about in ", "terms of having a tumor?  Should you be worried if you're dizzy, that you might  have a brain tumor, by these numbers?  So what do you think most people think? ", "You have to make a quick answer.  You're one of those doctors on House, who's going to get  berated in a moment.  And you go, whoa, 160, bad. ", "That's what a lot of people feel.  And by the way, there's a lot of concern in medicine about  how doctors convey risk to patients, as patients pick  what kind of treatment they want. ", "Because it's exactly what we're talking about now.  It's the exact way that you convey to a patient, the risk  they're facing or their family member is facing among  different treatment options. ", "So is dizziness associated with a brain tumor?  And the answer is no, because if you do the probabilities,  so the probability of a tumor is 4:1.  So here's whether you have the tumor, brain tumor. ", "And it's one out of four, and it's one out of four.  The odds are identical.  But you're impressed by this absolute, big number.  Intuitively, almost everybody is, almost all the time. ", "Here's another one that's a bit more subtle.  It comes up all the time in medical testing.  It's come up in things like discussions about how often we  should test for, if you're a male, for prostate cancer when  you get older; if you're a female, for breast cancer. ", "So these kinds of things come up all the time in decisions  about should you get the tests or not, and so on.  So imagine now, a hypothetical syndrome, is a serious  condition that affects one person in 1,000.  Imagine also that the test to diagnose the disease always ", "indicates correctly that a person who has it,  actually has it.  So if you actually have the disorder and you get a yes,  you will always be identified.  So that's a good test in that way. ", "Finally, suppose the test occasionally misidentifies a  healthy individual as having that disorder.  So that's a false positive.  The test is a false positive at a rate of 5%.  Meaning the test wrongly indicates that the virus is ", "present in 5% of cases where the person does  not have the virus.  So if you have it, it's always correct.  But 5% of healthy people will be misidentified on the  initial test. ", "Choose a person at random, administer the test, and the  person tests positive for that syndrome.  What is the probability the person really has that? ", "This is the kind of medical testing topic that goes on all  the time, all the time.   What do you think most people are going to say? ", " AUDIENCE: 95%.  PROFESSOR: Yeah, 95% exactly.  Because he said well, 5% of the time it's wrong.  But that ignores the base rate of this order. ", "Because if there's 1/1000, then if the other 999 are  tested, then you have about 0.5 times 999.  That means for every 51 who are tested, only one has it. ", "So the answer is only about 2%.  Because the odds, the prior odds, that you have  it are so, so low.  So that comes into the likelihood that it's an  accurate test and the false positive rate. ", "So again, people's intuition when they hear, their  intuition is there's a 95% probability that the person  has the disorder.  It's really only about 2%, given the low known base rate. ", "And if all this is whizzing by you a bit, I know I'm going  through it pretty fast.  But you can think in two ways.  You can also think you're a patient being told this.  You're not going to get an hour long lecture on  probabilities either. ", "So how this is communicated to physicians, for example in the  medical area and families, is a really big challenge.  So we talked about two heuristics, that people liked  things to look random, that we tend to go for what we often ", "hear about and imagine that's how frequent or dangerous  something is, in a very broad, intuitive way.  Anchoring and adjustment, here's a fun one.  So here's the experiment they did.  They went to people, like in courtyards around things that ", "are around Stanford, actually mostly.  And they had them do the following.  They gave them either this problem or this problem.  And here's what happened. ", "If they got this problem, and they quickly had to guess the  answer, they came up with this many.  This was their average estimate and this was the  average estimate.  So the first thing we can agree upon, regardless of the  fact that everybody is completely underestimating the ", "actual answer--  that's almost not the point--  regardless of that, look at this estimate.  This rapid estimate is four times greater than that.  Why is that happening? ", "You're only getting one or the other.  But why is that happening?  This is the heuristic of anchoring, how people come to  quick decisions.  ", "If we go, 8, that's a pretty big number.  8, we're talking some big numbers here, right now.  They don't even get that they're going to get to here.  They start with 1 and 2. ", "They go, we're talking about a pretty small thing.  But I can't quite calculate it out, because it's too hard to  calculate it out for most of us.  This is going to be pretty small by the time-- so they  are already thinking small. ", "They are already thinking big.  So now you know why, when you go negotiate for your salary  somewhere in the future, if you have any negotiating  power, start with a big number. ", " And the person who is negotiating with you knows  that too, and in fact is often more practiced than you are.  So here's a practical clue.  Start with a big number.  Because that's the number where people's minds are. ", "And I'll show you several more examples of how  ridiculous this is.  But when there's no true, exact number that you can  quickly come up with, what's the fair salary for you to  get, the first year out of MIT in a job or something? ", "First number out there, has a lot of power.  So here they made it ridiculous.  This anchoring, that my mind start somewhere and I kind of  stay in that neighborhood. ", "I don't recalibrate myself.  So they took a wheel of fortune, a spinning wheel of  fortune, with the numbers 1 to 100.  It's clearly random.  Can't make it more obviously random than that. ", "It stops somewhere.  And they say, we want you to estimate the number of African  nations in the UN?  And most people don't really know.  And there's some vague sense that it's more than a couple.  But who knows how big it is exactly. ", "So the number stops somewhere.  And here's the kind of thing that happens.  First you say, is it more or less than the number it  randomly stopped at?  Let's pretend it stopped at 65. ", "Then average estimate was 45 African nations.  Let's say it randomly stopped at 10.  Then the average estimate was 25 nations. ", "What's happening?  Anchoring.  You say well, it's more than 10.  But 10, I'm going to go way up from 10.  Because that's way too low.  And I'll split-- ", "going beyond 25 seems hazardous.  You start at 65.  You go, whoa, that's way too many.  But you're anchored.  And then you use don't go down that much.  So that first number, when you don't really know what the ", "right answer is, has an incredible power over how far  you range from that, for your best estimate.  Same idea.  Is the Mississippi River longer or  shorter than 500 miles? ", "So they're giving you the anchor.  How long is it actually do you think?  Or another person is asked, is it longer or shorter than  5,000 miles?  There's the anchor.  How long is it, do you think?  And here's the estimates. ", "They're both underestimating.  But they're moving towards that number that was  completely randomly thrown in.  But it's not random to the human mind.  We don't know what the right number is, but we're going to  start in the neighborhood that we first have any number ", "presented to us.  Framing.  Framing is arguably, together with availability, maybe the  one that's the most interesting in terms of how  powerful it is and how often people use it to convince you ", "that their political position, their corporate position,  their anything, is the way to go.  And once you know framing, you're empowered a bit to  think about that, because you hear arguments made to you ", "about what to believe in or what to support.  So here comes the framing.  Imagining the United States is preparing for the outbreak of  an unusual South American disease, which is expected to  kill 600 people.  Two alternative programs to combat the ", "disease have been proposed.  Assume that the exact scientific estimate of the  consequences of the programs were as follows.  If Program A is adopted, 200 people will be saved.  If Program B is adopted, there's a one-third ", "probability the 600 people will be saved and a two-thirds  probability that no people will be saved.  Which program do you favor?  So B is pretty complicated.  But A is pretty simple, 200 people might be ", "saved, will be saved.  So here's the exact same scenario by lives and deaths,  given to a second group of research participants. ", "If Program A is adopted, 400 people will die.  Do you see that if A is adopted, 200 people are saved,  equals 400 people will die.  It's the same thing. ", "There's 600.  You're really saying the same outcome.  But that numerical identity is treated by humans as  incredibly different information on which to base ", "your decision.  And here's what happens.  If people are given this scenario, which is explained  in terms of lives saved, 200 lives saved out of 600, 3/4 of  the time they pick it.  If people are given this scenario, 3/4 of the time they ", "don't pick it.  It's the exact same choice.  But to be human, is to gravitate towards something  where you save lives and avoid something ", "where you lose lives.  Even though numerically, it's the exact same outcome.  But people radically switch which one they think is the  correct one, by the framing of it.  By simply the way it's described in ", "this most simple sense.  So does that makes sense?  I mean it's very powerful.  When people present to you stuff, how do they present it?  Lives saved, lives lost; jobs made, jobs lost; whatever you ", "want, money made, money lost.  We don't treat them as two bits of  information that are equal.  We should.  That's the algorithm, out of 600 people, ", "200 people make it.  But that's not how we psychologically interpret it.  We go tremendously by, we're drawn--  any answer that uses the word \"saves\", is a positive thing.  And we're averse from any answer that talks about bad ", "things, how many people will die.  Even though they're identical in the  consequence of life and death.  Is that clear?  Very powerful.  Here's another version of it now, moving to money. ", "And it gives you another feeling of this.  So you could think about the top one.  Would you rather have a sure gain of $75.  Somebody said, I'll give you $75 right now.  Or you can have a lottery where you have a 75% chance of ", "winning $100, so that's even more, or a 25% chance of  winning nothing at all.   Another group of people get this question.  We're going to take from you $75. ", "It's a rough experiment to sign up for.  Or you're going to be in a lottery with a 75% chance of  losing $100, which is even a worse loss, and 25% chance of ", "losing nothing at all.  So these are meant to be kind of symmetric stories.  But one is expressed all in terms of gain and one all in  terms of losses.  And when people are thinking about gains, ", "they're risk averse.  I'm not going to give up what's in my hands.  So 84% of the time, they take that.  Even though this is sort of formally similar because it's ", "a loss, now when it's losses, people are risk taking.  Humans are very asymmetric.  If things are expressed in gains, we're risk averse.  Let's do the safe thing.  I'm going to hang on to what's already in my grasp. ", "If it's in terms of loss, it's like, let's bet the house,  let's do any crazy, wild thing.  Because losses are so bad that I'll take any  chance to avoid a loss. ", "Even though rationally, the choices should be about the  same, if we were machines making choices.  Very big difference.  I mean when I first heard about these  things, I was stunned. ", "Because it's huge.  Everything that we vote for, everything that we support,  every decision we make about careers, and policies that we  are for or against, are always being expressed to us in a ", "framework like this.  Things that we can gain or lose in our own lives, in the  world, in societies.  And you spin around so easily by how they're framed.  Although now you know something. ", "And you can think about them.   Here's just two odds and ends things, that I thought were  kind of fun.  Other things that people find kind of challenging to think ", "their way through, just because of the way our minds  are constructed.  So here's a problem.  Jack is looking at Anne, but Anne is looking at George.  Jack is married, but George is not. ", "Here's your problem to think about.  Is a married person looking at an unmarried person, yes, no,  or cannot be determined?  ", "The only reason I know the answers to these is because I  have the answers to these.  The first time I see these, I'm like, oh no.  So just for fun. ", "You can go by intuition and maybe you worked it out or you  looked ahead.  How many people who haven't looked ahead, say yes?  OK, there's some hands, 10.  How many say no? ", "Nobody.  How many say, cannot be determined?  The answer is, that's good.  Most answer, 80% say cannot be determined.  But the answer is this. ", "Think about this.  The answer is yes.  And here's why.  We don't know Anne's marital status.  The other two are given.  So we have to figure out Anne's situation.  Let's say she's married.  Then she's looking at unmarried George. ", "Let's say she's not married.  Then Jack is looking at unmarried Anne.  Is that OK?  This is what people in logic, call fully disjunctive  reasoning, where if you work your way through the  possibilities, you see it has to work out. ", "But that's not our intuitions.  I mean you're a very smart group.  So if it's hard for you, imagine the rest of the world ", "is not as suspicious about how to figure their problems out.  So it's just fantastically interesting how the human mind  is brilliant at some things.  And for other things, it could solve, it could solve, ", "intuitively, it's not often going to happen.  We go by these shortcuts where either we don't get the answer  at all or we come up with a completely wrong one, because  of availability or framing.  Here's a quick one. ", "You'll get this fast.  It's fun.  A ball and a bat cost $1.10 in total.  The bat cost a dollar more than the ball.  How much did the ball cost?  All right, you guys are now, you're very suspicious. ", "You're thinking it through.  Most people love $0.10.  But you can tell that's not going to work?  Because then the bat would have to cost $1.10 and the  total would be $1.20. ", "But a lot you were pulled to, most of us to, having a $1.10,  because we don't quite think it through.  There's $1.00.  There's $0.10.  And we do these shortcuts, these heuristics, instead of ", "logically working our way through.  One more example of this kind of thing.  Because now we're going to add one more  element just for this.  Imagine that the US Department of Transportation has found  that a particular German car is eight times more likely ", "than a typical family car to kill occupants of another car  in a crash.  The federal government is considering restricting sale  and use of this German car.  Do you think sales of the German car should be banned in  the US or do you think the German car should be banned ", "from being driven on the US streets?  So here's one, given in this study to US participants.  Or to do exactly the same thing, but it's  not a German car.  It's a Ford Explorer. ", " So American participants, if it's a German car, 73%, get  that car off the road.  If it's a Ford Explorer, sorry. ", "If a German car, off the streets, you get 73%, If it's  the American car, and Germany is making the decision, only  40% of the people think that Germany should do that.  Now, that's not purely logic. ", "What is that?  That's bias, right?  That's like, yeah, on my streets, we don't want these  threatening machines from overseas.  Germany, we've got to keep that economy going. ", "Those Ford workers are really doing a good job.  So of course most decisions aren't hyperrational in the  way we've been talking about, unknown people.  Of course they involve things in the world that we already ", "have feelings about.  So you add that in and you can see that making a truly  logical judgment is shockingly hard, if anything is a little  complicated.  So let me turn for the last little bit to what we think of ", "as some of the core parts of the brain for higher level  thought, the struggle we have between the best we have in  our mind and the traps we can fall into.  And when we talk about that, we tend to focus on sort of ", "three areas of the frontal lobe.  So let me just remind you of this.  So here's the frontal lobes.  And you could think of the frontal lobe I think as the  business end of the brain. ", "Here comes visual information coming in, auditory  information coming in, touch coming in.  Somewhere back here, would be taste.  So that's getting stuck in and figuring out what's out there. ", "So the front half is the business end of the brain,  acting upon the world.  Moving your hands, moving your body, making decisions about  what you do.  Motor cortex, premotor cortex, a guy's motor cortex. ", "This so-called lateral prefrontal cortex, that's  higher levels of thought.  And this bottom part of ventromedial or orbitofrontal  cortex, that we talked about with Phineas Gage.  So Oliver Sacks, in Chapter 13, talks about one example of ", "a woman who has a large tumor in this ventromedial area.  So sometimes I think there's a Roman philosopher who said  that life is composed of desires and decisions, desires ", "and decisions.  So this part of the brain is involved in desires and this  part in decisions.  And I'll show that, roughly speaking.  So here's a woman who is a former research chemist.  And she has a rapid personality change, becoming ", "facetious, impulsive, superficial.  And she a cerebral tumor in this  ventromedial part of the brain.  When I see her, she's full of quips and cracks,  often clever and funny. ", "Yes, father, she says to me on one occasion; yes, sister, on  another; yes, doctor, on a third.  What am I?  And then she make some jokes.  So she's constantly joking.  And she says, everything means nothing. ", "Nothing at all, she says with a bright smile and a tone of  one who makes a joke, wins an argument, or wins at poker.  So she just finds that sort of there are facts of the world,  but they just don't feel like they mean anything. ", "Because a tumor is influencing a part of the brain that we  understand to organize the relationship between thoughts  and feelings, between thoughts and feelings.  And that's a huge way about how we go about the world, ", "what we think, what we feel.  We've put it into a formula of some sense.  And that's how we act upon the world, whether we help  somebody, or don't help somebody, like somebody, or  don't like somebody.  All those sorts of things.  So when we think about behavior, we normally think of ", "the challenge of getting it going.  You get in your car and you turn on and you accelerate  from 0 to 60.  But a really interesting thing about the human brain is that  we have lots of habits, things we acquire about how to deal ", "with the world.  So just as big a problem for our brains is stopping the  course of action that's no longer relevant.  So the frontal cortex both has the job of initiating things, ", "but also stopping things.  And you can see it in a couple of ways, I'll show you.  So here's an example of a patient with a  frontal lobe injury.  They're drawn this scratchily, by a physician. ", "And here's their exact copy.  Do you see they can't stop?  Here's again the model,  scratched out by the physician.  Look at the patient.  The patient can't stop.  So the problem's not starting. ", "The problem is stopping the mental operation once it's  going and repeating.  And it's hard to put on the mental breaks.  Here's an example of a behavioral test of that kind. ", "And I remember this, when I was testing patients in E17  and E18 here, I did this a fair bit.  It's called the Wisconsin Card Sorting Test.  And what happens is, you put on four cards like these. ", "These are the key cards.  It's very mysterious when you give the test.  You just put them down.  And you have a pile of cards over here.  And you tell the person, your job is to pick a card from  this pile and put it below one of these cards. ", "And I'll tell you if you're right or wrong.  And then use that information to know where to  put the next card.  So imagine you are doing this experiment, and if you're  color blind, there's an extra issue. ", "I'll just warn you.  But you get this first card.  Where would you put it below?  Where could you put it below?  AUDIENCE: [INAUDIBLE].  PROFESSOR: OK.  That has an equal number.  That's one possibility. ", "What's another possibility, as the rule by which you might  sort the card?  AUDIENCE: Color.  PROFESSOR: Color.  Yeah, that's green.  That goes with that.  What's another possibility that you can see?  Shape.  You can say that's a plus sign, that's a plus sign.  They all seem reasonable. ", "So people usually pick one of those three.  And if they happen to pick the one that I as a tester know  from my instruction sheet, it's my job to reinforce.  Let's pretend it starts with color. ", "If they do this, I go wrong.  I go, hmm.  And they pick another card and they try something else.  They pick another card and they try something else.  And after three or four cards, people pretty ", "much get the color.  And then you go get another card out.  You go right, right, right, right right, wrong.  And when I did this, I was approximately your age. ", "And most of the patients I tested were older.  And they go like, sonny, look back on your score sheet  because it's correct.  And I go no ma'am, no sir.  I'm sorry about that.  But it's wrong.  Because what you do is after 10 consecutive correct ", "responses, you switch the rule from color to shape.  After 10 correct shape, you switch to number.  And then you do that again.  So you switch the rule after 10. ", "So it's a test of mental flexibility, in a fairly  simple way.  Does that make sense?  They have to figure out what the answer is.  Then they're zooming along.  And you go, no stop.  And you have to come up with the next answer. ", "So here's what happens for patients with frontal lobe  lesions, they make a huge amount of what's called  perseverative errors.  So this is now the intellectual analog of the too ", "many squiggles.  Once they get that first rule, they can't stop that rule.  So they go color, color, color, color, color.  They get about 10. ", "So you switch.  And they just keep doing it.  You go no, wrong, wrong, wrong, wrong, wrong.  But they can't stop the rule that worked in the first  place, without the prefrontal cortex being intact. ", "So our mental flexibility seems to depend tremendously  on prefrontal cortex.  And you can do the same kind of thing in imaging, just to  make sure it's not just a patient thing.  And again, when you have to do this very same kind of task, ", "typical people activate prefrontal cortex to do the  mental manipulation of the simple problem solving task.  So we talked about perserveration and its hard to  stop and mental flexibility. ", "With ventromedial lesions, you get some weird things.  You get what they call utilization behaviors.  So again, we're having this idea what's the good thing  about having very powerful habits?  ", "Is it very good to have very powerful habits, and we use a  different word for this, when you read?  Yeah.  Because that's how you're a fast reader.  You know how to read words really fast.  Is it good to have very powerful habits when you walk? ", "Yeah.  You don't want to go like, OK, I'm moving the leg now.  Everybody get ready.  We're moving the other leg.  Because you could never get out of the room very  efficiently.  So for many, many things, having very powerful habits  are very strong. ", "But for other things, they're not as good and you have to  put the brakes on.  So Lhermitte described patients with ventromedial  lesions who came in, saw in his office.  This was not a set-up experiment. ", "He didn't expect this.  There was a hammer, a nail, and a picture.  And the patient just goes over, up.  And you could imagine, if you go into the doctor's office  and you see a hammer, a nail, and a picture, would you go  over and put up the picture? ", "No.  I mean you know that's what you do with that stuff.  You know that's what's going on.  But you go, that's not my place to do it, even though  it's attempted to do it.  The patient could not help himself but go do that,  literally go do that. ", "The most dramatic example was, the patient walks in and sees  a hypodermic needle, pulls down his pants, and injects  himself in the derriere.  So again, he knew that was going to happen. ", "He knew that's the habit.  But you wouldn't go into a doctor's office and start  using their stuff and perform on yourself.  You understand.  The habits are completely running the show.  And any kind of frontal cortical control of those ", "habits has been eliminated in these patients.  And here's a couple more things that  are along that line.  So I need a volunteer, in your seats, to try something with  me for a minute. ", " It's not bad.  I think I've traumatized you in these examples.  OK, thank you.  If you had to answer this question, and there's no  correct answer.  But let's just talk about how you might do it. ", "How long is a man's spine, on average?  AUDIENCE: About two feet?  PROFESSOR: And how did you kind of come to that?  And that might be right or not.  AUDIENCE: My back is roughly two feet long.  My spine is-- ", "PROFESSOR: Yeah.  It's got to be less seven feet.  Because that's like the tallest basketball players.  On average, it's got to be more than a couple feet.  Something in that range.  OK, you just guessed which it was.  Or how fast does a horse in a race gallop? ", "Or what's the largest object normally found in the house?  What do you think that might be?  AUDIENCE: Fridge?  PROFESSOR: Help me out here.  AUDIENCE: A refrigerator.  PROFESSOR: A refrigerator is a good one.  Anybody else?  AUDIENCE: [INAUDIBLE]. ", "PROFESSOR: All those are good.  Is toaster a good answer?  No.  One more person.  Who's going to help me out here?  One more example.  ", "Come on.  One more example.  It's easy.  OK, thank you, Rich.  How many camels are there in the Netherlands?  Now, nobody knows.  But tell me a thought process roughly, so you would come up  with an estimate.  AUDIENCE: 100. ", "PROFESSOR: Yeah.  Because are you going to figure there's a lot in the  Netherlands?  No.  Because there's no desert, right?  Where might you find a few?  AUDIENCE: [INAUDIBLE] ", "PROFESSOR: On a ranch.  I haven't been to Amsterdam for a while, so perhaps  there's a few loping around in the canals.  And some zoo, some kids' petting thing, who knows? ", "So, yeah, 100 sounds good to me.  But frontal patients will give really bad answers,  thousands or zero.  Or 12 feet for a spinal cord.  Or just something that you go like, where  did you come up that? ", "You can do the Price Is Right game with them.  They'll come up with more ridiculous answers.  Here's just a graph.  These are bad answers for how expensive something is, just  unreasonable answers within these sort  of open-ended questions. ", "Or you can do more formal problems.  The kind of problem where you're given  a puzzle like this.  And your job is to move these into a target state.  And so to get over to here, you've got to move the blue ", "guy over here and whatever, in a different number of moves.  That's planning ahead and problem solving.  Patients with frontal lobe lesions make many mistakes on  these kinds of tasks. ", "So the last thing I want to talk is a little bit about  Phineas Gage kind of lesions.  And we'll get in a moment to a comment about serial killers.  So Phineas Gage had this huge injury. ", "We talked about him already in the  ventromedial prefrontal cortex.  There's some other patients who have orbitofrontal  lesions, who have been studied.  And let me tell you a little bit about  what's known about them. ", "And I can tell you this is the part of the brain that's been  most implicated in psychopaths, some of whom turn  out to be these serial killers.  One measure they've used in these experiments is galvanic ", "skin response.  That's the kind of stuff they use in  polygraphs, lie detectors.  They put them on your skin and what they measure is responses  that are related to sweat glands.  So it's a measure of emotional reactivity, basically. ", "Here's a really interesting thing.  If we measure your galvanic skin response and we show you  faces of people you know, family members, friends, and  so on, versus people you don't know, you get a galvanic skin ", "response for the people you know, because  they matter to you.  It's an emotional response, versus faces you don't know.  You even get that kind of strikingly in several studies  in patients with prosopagnosia. ", "So we talked about those patients who can't recognize  people by their faces.  But something in them still recognizes who's  familiar and who's not.  Even if they can't tell you, that's my mother or that's my ", "father or that's my brother, their galvanic skin response  is a pretty good response.  Patients with orbitofrontal lesions  are exactly the opposite.  When they're shown pictures of family members and friends, ", "they have no more of a response in the sweat glands,  in the autonomic nervous system, than they do for  absolute strangers.  And you might intuitively imagine that it's pretty easy ", "to lie and deceive your friends and family, if they  don't mean to you anything more  than an absolute stranger.   No galvanic response to emotional ", "versus neutral pictures.  And so these patients seem to have this disconnection  between thought and emotion.  They know who the person is.  But they don't have an emotional response of any kind  to that person. ", "And here's one clever experiment that shows some of  the consequence of that.  So this is work from Damasio and his colleagues.  So they took a couple of these patients.  There's not that many of them.  And they put them into an experiment where you could ", "pick from two decks.  One deck has a low immediate reward, but  positive long-term rewards.  It's a little bit like studying a lot, and hoping it  all pays off.  And another one is high immediate rewards, but higher ", "long-term losses.  Like not studying has some unpleasant consequences.  So two decks of cards.  And you don't know this, but you just quickly discover that  Pile A, you get the occasional $50, but you often lose $100. ", "But Pile B, you get the thrill of the $100 loss, but you  often lose $1,000.  So they're kind of pitting against each other, the thrill  of the $100 win, versus the certain doom of the quick ", "thrill pile.  You get the quick thrill, but it will doom you.  So what do typical people do?  After a little while, they figure out well, Pile B is  pretty fun when I get the $100. ", "But it beats me up a lot in the long term, so they go for  Pile A.  Orbitofrontal patients don't.  They go for that one-time thrill, over any long-term  consequences. ", "As interesting as that, if you measure the galvanic skin  response, for control people, typical people, when they go  for the risky pile, their heart is pounding, their hands ", "are sweating.  And they go, I'm going to walk on the wild side.  Back to the save file, mostly.  No galvanic skin response for the patients with  orbitofrontal lesions.  Yeah?  AUDIENCE: Do people get the lesions ", "after reaching adulthood?  PROFESSOR: So this is interesting.  I'm going to come to this in a moment.  Actually literally, absolutely right now.  Same pattern for people who have these injuries at 15 ", "months or three months, as happens in adulthood.  Now, we don't know if that's everybody.  But these are patients who came forth with problems.  So this is a little bit like, we don't know if there are a  lot of people with damage there, who are not doing this. ", "But these two patients who they studied, had that.  And they got in lots of trouble in  school, all the time.  They did all the things you might imagine a  three-year-old, and for the rest of us, like ", "Phineas Gage would do.  So that raises the question about whether the kinds of  people who behave in this most disturbing, psychopathic,  serial killer fashion have either an injury or something ", "like that, that makes them predisposed to being very  inhumane in the way they think about people.   And just in case you, as careful MIT scientists, worry ", "about well, maybe they're not having a GSR that works at  all, what does that mean?  If these patients who had the damage early in childhood just  get a loud tone, a big boat horn, like ooh, there's a ", "galvanic skin response that looks pretty good.  So it's not their autonomic system won't respond to  emotionally provocative things, like a big sound.  It just doesn't respond to emotionally provocative things ", "like risk and people you should care about.   And I'll just end in this one minute.  So this is an area where a guy, Kent Khiel, at the ", "University of New Mexico.  You can go look this up.  It's an amazing story.  He's very interested in these brain differences in  psychopaths in prison.  Many are in prison because they're scary people. ", "So you can't get them out to do research very easily.  So he has a truck with an MR scanner.  And he drives from penitentiary to penitentiary  and does brain scanning with these people.  And is getting on average, some differences ", "in this brain region.  So I have a question for you, just for one minute.  Do you think that should be introduced in a court case for  a serial killer?  ", "If he gets up there and shows you brain pictures, should a  jury hear about that or should they not hear about that, for  somebody who's done an awful murder or an ", "awful string murders?  AUDIENCE: I'd say no.  PROFESSOR: Sorry.  You say no.  Because what?  AUDIENCE: I think that the risk is too great that you  will have innocent people be shown. ", "And the science is not fully resolved yet in that respect.  There are also a lot of salient factors and  environmental factors that have been constrained by  genetics, and say, oh, if you have this huge issue, this ", "condition of the brain, you're automatically [INAUDIBLE].  PROFESSOR: OK.  Let me tell one sentence.  Yeah, go ahead.  AUDIENCE: You know the correlation in one direction-- ", "PROFESSOR: We don't know.  These are good points.  Let me just say, so here's where we stand now, because  this will be your lives in the future, in a lot  of different ways.  Where we stand now is, for the first time ever, brain imaging ", "evidence was introduced in the court case about a year ago of  a serial killer.  They were only allowed to do it--  court cases like this go through two phases.  You see these in TV shows or movies. ", "There's the initial trial.  And if the person is found guilty, there's a second phase  where they decide what the appropriate penalty is.  The judge said they could only be reported in the penalty ", "phase, when people were thinking about what's the  right punishment for a person, not before the conviction.  And they said they couldn't show any color pictures of  brain stuff, because that would  over-influence the jurors. ", "And so you could only talk about this stuff.  Because if you showed a brain picture, sort of like you  said, it would look so scientific that they were  afraid it overwhelm the jurors' judgment.  So this is all coming up, about what the brain maybe do ", "in your lifetimes.  Thanks. "], "vid_duration": [12.52, 12.739, 11.021, 12.84, 11.39, 12.33, 11.14, 10.45, 10.16, 11.25, 16.41, 11.49, 13.69, 11.47, 11.28, 10.03, 10.24, 10.77, 10.53, 12.37, 10.149, 11.731, 11.62, 10.62, 10.04, 10.05, 10.34, 10.16, 11.78, 10.24, 12.54, 14.0, 14.39, 10.095, 10.215, 10.97, 11.46, 10.3, 10.75, 11.3, 16.57, 11.7, 10.21, 11.1, 11.83, 10.13, 11.26, 11.18, 11.42, 10.1, 13.79, 10.53, 10.94, 10.39, 10.99, 10.015, 10.315, 13.01, 10.51, 12.51, 12.81, 11.17, 10.05, 11.35, 10.57, 10.68, 11.25, 11.07, 12.43, 12.54, 10.14, 10.58, 10.85, 10.26, 11.12, 13.17, 14.23, 12.05, 10.54, 10.55, 10.02, 13.18, 11.16, 10.8, 12.05, 11.48, 10.57, 11.44, 10.22, 10.369, 11.371, 10.26, 11.49, 12.49, 10.95, 10.9, 10.29, 11.5, 11.55, 10.96, 11.37, 10.48, 11.59, 11.52, 10.48, 11.14, 11.242, 11.718, 13.24, 10.97, 12.03, 11.26, 10.2, 11.21, 11.62, 11.39, 17.69, 10.0, 11.71, 10.8, 10.59, 10.46, 10.884, 14.086, 12.49, 11.15, 11.67, 11.61, 11.23, 11.71, 11.22, 14.2, 10.81, 10.25, 12.51, 10.643, 10.127, 10.035, 10.495, 10.27, 10.06, 10.8, 10.71, 10.07, 11.06, 12.31, 11.52, 10.38, 10.64, 12.36, 11.86, 10.565, 10.495, 10.62, 10.62, 12.35, 10.3, 10.07, 13.1, 11.78, 10.68, 13.16, 11.39, 12.57, 10.93, 11.642, 10.448, 13.03, 10.45, 10.8, 13.62, 11.44, 10.26, 13.6, 10.12, 10.51, 12.43, 11.76, 13.62, 12.7, 10.87, 11.04, 10.799, 10.161, 10.57, 10.64, 10.74, 12.13, 12.69, 10.33, 14.12, 12.076, 10.304, 11.84, 12.19, 11.74, 10.89, 10.29, 11.5, 11.28, 10.81, 10.04, 10.31, 10.05, 10.0, 10.0, 10.08, 11.62, 10.74, 10.83, 12.8, 12.475, 10.845, 10.77, 10.36, 10.51, 13.4, 10.08, 12.69, 13.19, 12.09, 10.96, 11.09, 10.69, 13.17, 10.23, 10.9, 11.85, 10.52, 14.32, 10.73, 12.63, 10.16, 10.83, 11.23, 11.02, 10.82, 11.46, 15.71, 10.53, 11.86, 11.44, 10.35, 11.99, 11.48, 11.23, 10.12, 10.81, 11.92, 10.7, 11.46, 11.44, 10.64, 12.29, 10.17, 10.33, 11.07, 12.57, 13.28, 10.56, 11.54, 11.35, 14.16, 12.87, 11.7, 10.19, 13.01, 11.98, 11.14, 16.54, 11.34, 11.49, 10.57, 10.91, 10.86, 11.47, 12.76, 10.35, 10.4, 10.93, 11.0, 10.43, 10.78, 11.07, 10.35, 11.76, 11.39, 10.19, 12.21, 11.14, 11.91, 12.4, 13.726, 10.714, 10.46, 11.33, 10.11, 10.0, 11.27, 10.79, 11.31, 12.18, 11.57, 10.43, 13.87, 10.89, 10.56, 11.52, 11.12, 10.51, 11.97, 11.74, 11.65, 10.93, 10.31, 14.07, 10.3, 11.12, 12.18, 11.8, 10.39, 10.42, 10.82, 11.7, 11.33, 14.63, 15.38, 10.18, 10.04, 13.32, 10.33, 11.31, 11.18, 10.8, 12.88, 11.47, 12.77, 10.2, 13.67, 10.63, 11.37, 14.19, 10.576, 10.171, 11.928, 10.015, 12.05, 10.94, 10.0, 11.99, 13.18, 3.32], "stet": [[0, 12.52], [12.52, 25.259], [25.259, 36.28], [36.28, 49.120000000000005], [49.120000000000005, 60.510000000000005], [60.510000000000005, 72.84], [72.84, 83.98], [83.98, 94.43], [94.43, 104.59], [104.59, 115.84], [115.84, 132.25], [132.25, 143.74], [143.74, 157.43], [157.43, 168.9], [168.9, 180.18], [180.18, 190.21], [190.21, 200.45000000000002], [200.45000000000002, 211.22000000000003], [211.22000000000003, 221.75000000000003], [221.75000000000003, 234.12000000000003], [234.12000000000003, 244.26900000000003], [244.26900000000003, 256.00000000000006], [256.00000000000006, 267.62000000000006], [267.62000000000006, 278.24000000000007], [278.24000000000007, 288.2800000000001], [288.2800000000001, 298.3300000000001], [298.3300000000001, 308.6700000000001], [308.6700000000001, 318.8300000000001], [318.8300000000001, 330.61000000000007], [330.61000000000007, 340.8500000000001], [340.8500000000001, 353.3900000000001], [353.3900000000001, 367.3900000000001], [367.3900000000001, 381.7800000000001], [381.7800000000001, 391.8750000000001], [391.8750000000001, 402.0900000000001], [402.0900000000001, 413.0600000000001], [413.0600000000001, 424.5200000000001], [424.5200000000001, 434.8200000000001], [434.8200000000001, 445.5700000000001], [445.5700000000001, 456.8700000000001], [456.8700000000001, 473.4400000000001], [473.4400000000001, 485.1400000000001], [485.1400000000001, 495.3500000000001], [495.3500000000001, 506.4500000000001], [506.4500000000001, 518.2800000000001], [518.2800000000001, 528.4100000000001], [528.4100000000001, 539.6700000000001], [539.6700000000001, 550.85], [550.85, 562.27], [562.27, 572.37], [572.37, 586.16], [586.16, 596.6899999999999], [596.6899999999999, 607.63], [607.63, 618.02], [618.02, 629.01], [629.01, 639.025], [639.025, 649.34], [649.34, 662.35], [662.35, 672.86], [672.86, 685.37], [685.37, 698.18], [698.18, 709.3499999999999], [709.3499999999999, 719.3999999999999], [719.3999999999999, 730.7499999999999], [730.7499999999999, 741.3199999999999], [741.3199999999999, 751.9999999999999], [751.9999999999999, 763.2499999999999], [763.2499999999999, 774.3199999999999], [774.3199999999999, 786.7499999999999], [786.7499999999999, 799.2899999999998], [799.2899999999998, 809.4299999999998], [809.4299999999998, 820.0099999999999], [820.0099999999999, 830.8599999999999], [830.8599999999999, 841.1199999999999], [841.1199999999999, 852.2399999999999], [852.2399999999999, 865.4099999999999], [865.4099999999999, 879.6399999999999], [879.6399999999999, 891.6899999999998], [891.6899999999998, 902.2299999999998], [902.2299999999998, 912.7799999999997], [912.7799999999997, 922.7999999999997], [922.7999999999997, 935.9799999999997], [935.9799999999997, 947.1399999999996], [947.1399999999996, 957.9399999999996], [957.9399999999996, 969.9899999999996], [969.9899999999996, 981.4699999999996], [981.4699999999996, 992.0399999999996], [992.0399999999996, 1003.4799999999997], [1003.4799999999997, 1013.6999999999997], [1013.6999999999997, 1024.0689999999997], [1024.0689999999997, 1035.4399999999998], [1035.4399999999998, 1045.6999999999998], [1045.6999999999998, 1057.1899999999998], [1057.1899999999998, 1069.6799999999998], [1069.6799999999998, 1080.6299999999999], [1080.6299999999999, 1091.53], [1091.53, 1101.82], [1101.82, 1113.32], [1113.32, 1124.87], [1124.87, 1135.83], [1135.83, 1147.1999999999998], [1147.1999999999998, 1157.6799999999998], [1157.6799999999998, 1169.2699999999998], [1169.2699999999998, 1180.7899999999997], [1180.7899999999997, 1191.2699999999998], [1191.2699999999998, 1202.4099999999999], [1202.4099999999999, 1213.6519999999998], [1213.6519999999998, 1225.37], [1225.37, 1238.61], [1238.61, 1249.58], [1249.58, 1261.61], [1261.61, 1272.87], [1272.87, 1283.07], [1283.07, 1294.28], [1294.28, 1305.8999999999999], [1305.8999999999999, 1317.29], [1317.29, 1334.98], [1334.98, 1344.98], [1344.98, 1356.69], [1356.69, 1367.49], [1367.49, 1378.08], [1378.08, 1388.54], [1388.54, 1399.424], [1399.424, 1413.51], [1413.51, 1426.0], [1426.0, 1437.15], [1437.15, 1448.8200000000002], [1448.8200000000002, 1460.43], [1460.43, 1471.66], [1471.66, 1483.3700000000001], [1483.3700000000001, 1494.5900000000001], [1494.5900000000001, 1508.7900000000002], [1508.7900000000002, 1519.6000000000001], [1519.6000000000001, 1529.8500000000001], [1529.8500000000001, 1542.3600000000001], [1542.3600000000001, 1553.0030000000002], [1553.0030000000002, 1563.13], [1563.13, 1573.1650000000002], [1573.1650000000002, 1583.66], [1583.66, 1593.93], [1593.93, 1603.99], [1603.99, 1614.79], [1614.79, 1625.5], [1625.5, 1635.57], [1635.57, 1646.6299999999999], [1646.6299999999999, 1658.9399999999998], [1658.9399999999998, 1670.4599999999998], [1670.4599999999998, 1680.84], [1680.84, 1691.48], [1691.48, 1703.84], [1703.84, 1715.6999999999998], [1715.6999999999998, 1726.2649999999999], [1726.2649999999999, 1736.7599999999998], [1736.7599999999998, 1747.3799999999997], [1747.3799999999997, 1757.9999999999995], [1757.9999999999995, 1770.3499999999995], [1770.3499999999995, 1780.6499999999994], [1780.6499999999994, 1790.7199999999993], [1790.7199999999993, 1803.8199999999993], [1803.8199999999993, 1815.5999999999992], [1815.5999999999992, 1826.2799999999993], [1826.2799999999993, 1839.4399999999994], [1839.4399999999994, 1850.8299999999995], [1850.8299999999995, 1863.3999999999994], [1863.3999999999994, 1874.3299999999995], [1874.3299999999995, 1885.9719999999995], [1885.9719999999995, 1896.4199999999996], [1896.4199999999996, 1909.4499999999996], [1909.4499999999996, 1919.8999999999996], [1919.8999999999996, 1930.6999999999996], [1930.6999999999996, 1944.3199999999995], [1944.3199999999995, 1955.7599999999995], [1955.7599999999995, 1966.0199999999995], [1966.0199999999995, 1979.6199999999994], [1979.6199999999994, 1989.7399999999993], [1989.7399999999993, 2000.2499999999993], [2000.2499999999993, 2012.6799999999994], [2012.6799999999994, 2024.4399999999994], [2024.4399999999994, 2038.0599999999993], [2038.0599999999993, 2050.7599999999993], [2050.7599999999993, 2061.629999999999], [2061.629999999999, 2072.669999999999], [2072.669999999999, 2083.468999999999], [2083.468999999999, 2093.629999999999], [2093.629999999999, 2104.1999999999994], [2104.1999999999994, 2114.8399999999992], [2114.8399999999992, 2125.579999999999], [2125.579999999999, 2137.709999999999], [2137.709999999999, 2150.399999999999], [2150.399999999999, 2160.729999999999], [2160.729999999999, 2174.849999999999], [2174.849999999999, 2186.925999999999], [2186.925999999999, 2197.229999999999], [2197.229999999999, 2209.0699999999993], [2209.0699999999993, 2221.2599999999993], [2221.2599999999993, 2232.999999999999], [2232.999999999999, 2243.889999999999], [2243.889999999999, 2254.179999999999], [2254.179999999999, 2265.679999999999], [2265.679999999999, 2276.959999999999], [2276.959999999999, 2287.769999999999], [2287.769999999999, 2297.809999999999], [2297.809999999999, 2308.119999999999], [2308.119999999999, 2318.169999999999], [2318.169999999999, 2328.169999999999], [2328.169999999999, 2338.169999999999], [2338.169999999999, 2348.249999999999], [2348.249999999999, 2359.869999999999], [2359.869999999999, 2370.6099999999988], [2370.6099999999988, 2381.4399999999987], [2381.4399999999987, 2394.239999999999], [2394.239999999999, 2406.714999999999], [2406.714999999999, 2417.5599999999986], [2417.5599999999986, 2428.3299999999986], [2428.3299999999986, 2438.6899999999987], [2438.6899999999987, 2449.199999999999], [2449.199999999999, 2462.599999999999], [2462.599999999999, 2472.679999999999], [2472.679999999999, 2485.369999999999], [2485.369999999999, 2498.559999999999], [2498.559999999999, 2510.649999999999], [2510.649999999999, 2521.609999999999], [2521.609999999999, 2532.6999999999994], [2532.6999999999994, 2543.3899999999994], [2543.3899999999994, 2556.5599999999995], [2556.5599999999995, 2566.7899999999995], [2566.7899999999995, 2577.6899999999996], [2577.6899999999996, 2589.5399999999995], [2589.5399999999995, 2600.0599999999995], [2600.0599999999995, 2614.3799999999997], [2614.3799999999997, 2625.1099999999997], [2625.1099999999997, 2637.74], [2637.74, 2647.8999999999996], [2647.8999999999996, 2658.7299999999996], [2658.7299999999996, 2669.9599999999996], [2669.9599999999996, 2680.9799999999996], [2680.9799999999996, 2691.7999999999997], [2691.7999999999997, 2703.2599999999998], [2703.2599999999998, 2718.97], [2718.97, 2729.5], [2729.5, 2741.36], [2741.36, 2752.8], [2752.8, 2763.15], [2763.15, 2775.14], [2775.14, 2786.62], [2786.62, 2797.85], [2797.85, 2807.97], [2807.97, 2818.7799999999997], [2818.7799999999997, 2830.7], [2830.7, 2841.3999999999996], [2841.3999999999996, 2852.8599999999997], [2852.8599999999997, 2864.2999999999997], [2864.2999999999997, 2874.9399999999996], [2874.9399999999996, 2887.2299999999996], [2887.2299999999996, 2897.3999999999996], [2897.3999999999996, 2907.7299999999996], [2907.7299999999996, 2918.7999999999997], [2918.7999999999997, 2931.37], [2931.37, 2944.65], [2944.65, 2955.21], [2955.21, 2966.75], [2966.75, 2978.1], [2978.1, 2992.2599999999998], [2992.2599999999998, 3005.1299999999997], [3005.1299999999997, 3016.8299999999995], [3016.8299999999995, 3027.0199999999995], [3027.0199999999995, 3040.0299999999997], [3040.0299999999997, 3052.0099999999998], [3052.0099999999998, 3063.1499999999996], [3063.1499999999996, 3079.6899999999996], [3079.6899999999996, 3091.0299999999997], [3091.0299999999997, 3102.5199999999995], [3102.5199999999995, 3113.0899999999997], [3113.0899999999997, 3123.9999999999995], [3123.9999999999995, 3134.8599999999997], [3134.8599999999997, 3146.3299999999995], [3146.3299999999995, 3159.0899999999997], [3159.0899999999997, 3169.4399999999996], [3169.4399999999996, 3179.8399999999997], [3179.8399999999997, 3190.7699999999995], [3190.7699999999995, 3201.7699999999995], [3201.7699999999995, 3212.1999999999994], [3212.1999999999994, 3222.9799999999996], [3222.9799999999996, 3234.0499999999997], [3234.0499999999997, 3244.3999999999996], [3244.3999999999996, 3256.16], [3256.16, 3267.5499999999997], [3267.5499999999997, 3277.74], [3277.74, 3289.95], [3289.95, 3301.0899999999997], [3301.0899999999997, 3312.9999999999995], [3312.9999999999995, 3325.3999999999996], [3325.3999999999996, 3339.1259999999997], [3339.1259999999997, 3349.8399999999997], [3349.8399999999997, 3360.2999999999997], [3360.2999999999997, 3371.6299999999997], [3371.6299999999997, 3381.74], [3381.74, 3391.74], [3391.74, 3403.0099999999998], [3403.0099999999998, 3413.7999999999997], [3413.7999999999997, 3425.1099999999997], [3425.1099999999997, 3437.2899999999995], [3437.2899999999995, 3448.8599999999997], [3448.8599999999997, 3459.2899999999995], [3459.2899999999995, 3473.1599999999994], [3473.1599999999994, 3484.0499999999993], [3484.0499999999993, 3494.609999999999], [3494.609999999999, 3506.129999999999], [3506.129999999999, 3517.249999999999], [3517.249999999999, 3527.7599999999993], [3527.7599999999993, 3539.729999999999], [3539.729999999999, 3551.469999999999], [3551.469999999999, 3563.119999999999], [3563.119999999999, 3574.049999999999], [3574.049999999999, 3584.3599999999988], [3584.3599999999988, 3598.429999999999], [3598.429999999999, 3608.729999999999], [3608.729999999999, 3619.849999999999], [3619.849999999999, 3632.029999999999], [3632.029999999999, 3643.829999999999], [3643.829999999999, 3654.219999999999], [3654.219999999999, 3664.639999999999], [3664.639999999999, 3675.459999999999], [3675.459999999999, 3687.159999999999], [3687.159999999999, 3698.489999999999], [3698.489999999999, 3713.119999999999], [3713.119999999999, 3728.499999999999], [3728.499999999999, 3738.679999999999], [3738.679999999999, 3748.719999999999], [3748.719999999999, 3762.039999999999], [3762.039999999999, 3772.369999999999], [3772.369999999999, 3783.679999999999], [3783.679999999999, 3794.8599999999988], [3794.8599999999988, 3805.659999999999], [3805.659999999999, 3818.539999999999], [3818.539999999999, 3830.009999999999], [3830.009999999999, 3842.779999999999], [3842.779999999999, 3852.9799999999987], [3852.9799999999987, 3866.6499999999987], [3866.6499999999987, 3877.279999999999], [3877.279999999999, 3888.6499999999987], [3888.6499999999987, 3902.839999999999], [3902.839999999999, 3913.415999999999], [3913.415999999999, 3923.5869999999986], [3923.5869999999986, 3935.5149999999985], [3935.5149999999985, 3945.5299999999984], [3945.5299999999984, 3957.5799999999986], [3957.5799999999986, 3968.5199999999986], [3968.5199999999986, 3978.5199999999986], [3978.5199999999986, 3990.5099999999984], [3990.5099999999984, 4003.6899999999982], [4003.6899999999982, 4007.0099999999984]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [910, 2180, 2927, 4007]}
{"example_id": "mit057@@MIT9_00SCF11_lec12_300k", "text": ["PROFESSOR: OK, good afternoon.  So in the last couple of weeks, we've gone through some  of the major human capacities that you have and I have and ", "most people have most of them, right?  Which are the ability to see the world around us, to attend  to what's important, to learn lessons from life, to remember ", "things, why we sometimes forget things.  And today, we're going to talk about another huge dimension  of human experience, of the human mind, of the human  brain, language.  The ability to talk to one another. ", "I can talk, you can listen, and vice versa.  To read, to communicate, in the ways that are so  remarkable.  Our life is flooded with language, right?  That we hear, that we read, and so on. ", "So when psychologists try to divide up language and the  study of both components, they talk about comprehension,  understanding what somebody says to you when you're an  infant, or now, as an adult, or reading text, or producing ", "speech, which you can do with your mouth by speaking, or you  learn to write.  So you can both comprehend and produce language, both  visually and orally.  And the thing that has greatly enamored linguists to figure ", "out is how language that we speak is endlessly generative.  I'm not sure you can actually calculate out how many  sentences we could possibly produce, but just for fun,  people have done stuff.  And they said it would take 100 trillion years to memorize ", "all the sentences we can produce.  I'm not sure that's exactly the right  number, but it's a lot.  Because we can say a lot of different sentences and  understand what a person is saying.  It's an incredibly generative system for communication, one ", "person to another.  So when people in psychology think about different aspects  of language, levels of language, they often divide it  into something like this. ", "Phonology is the sounds of language that we hear, that we  acquire as infants, that we use to speak to one another.  Syntax, grammar.  And by this, this isn't school grammar, not get ", "the sentence right.  It's just the understanding of the organization of words, and  how that changes the meaning of the sentence.  Syntax.  Semantics, what do the words mean?  What do the groups of words mean? ", "Pragmatics.  And we'll talk about each of these a little bit.  Sometimes a person is sarcastic.  So they go, that was an awesome lecture yesterday in ", "psychology.  Somebody could say that, in a hundred trillion years.  And you go, yeah, yeah.  Right?  So that's the pragmatics versus semantics.  Then, of course, it's not just sentences. ", "We have whole discussions.  And another aspect of language we'll just touch on a little  bit today is emotional comprehension and production.  The tone somebody speaks in, the tone you produce, are also ", "informative.  So there's many aspects of language.  We'll start with the most basic, or phonology.  So phonemes are the words that people use to describe the  building blocks of speech sounds.  So boy versus toy are different by one phoneme. ", "Phonemes are the building blocks of  the sounds of language.  Humans use about 100 phonemes across languages, but any  given language only uses a subset. ", "And this has really interesting consequences.  Of course, a language could only exist in the world if you  could understand those phonemes.  Phonemes that are ununderstandable aren't going  to be a part of anybody's language. ", "But different languages, for historical reasons, have ended  up using different subsets of phonemes.  And we'll come back to that.  When we're babies, for about the first six months of our  lives, we're universal learners. ", "We know all the phonemes and respond to all of them.  As we become native language speakers and listeners, we  become only good at the ones that are used in our language,  and our ability to even recognize the ones that are ", "not in our language disappears.  You can get it back some, but the older that you are, you  never get it back fully.  So we're universal learners at birth, but we become enslaved  to the language that we are native speakers of and listen ", "to within months of birth.   English has about 45.  So it's more than the number of letters we have.  Some people get confused a little bit ", "that letters are phonemes.  They're not.  So hot and cold, the oh sound in hot and the oh sound in  cold are different sounds, same letters. ", "So there's many more phonemes.  Even in English, when they say there's about 45, depending on  dialects, you could have a couple more, a couple less.  So again, we're born to use all of them.  Then we use them or lose them. ", "It's something, we don't entirely lose it, but we're  never as good if we try to learn a distinction once we  become older than that.  Humans understand speech at an incredible rate. ", "The typical fast talking is about 180 words a minute, 14  phonemes a second in a continuous speech stream.  But people can go up to 250 words.  We're incredibly fast language processors, incredibly fast ", "language processors.  So how do we roughly conceptualize, in the most  simple way, what we have to do to get to a word that we hear,  to get to its meaning. ", "Well, acoustic information comes through the ear.  Those are wave forms, physical things, arriving at our ears.  We in some way figure out how those correspond to phonemes, ", "and then map that in some way to words that have  meanings in the world.   And the reason why machines understanding what you say is ", "shockingly hard to do a good job on is for  the following reason.  There's a huge difference between a word by the time  your mind understands what it is and the nature of the ", "signal that arrived at your year.  So we talked a lot about that in terms of  the retina in vision.  Right?  You have this very impoverished stuff that  arrives in your retina, and then the whole rest of your ", "brain, millions and millions of neurons and synapses,  reconstruct what's out there from a very impoverished  retinal input.  And the same thing happens in audition. ", "What gets to your ear is incredibly impoverished, and  the rest of your brain has to brilliantly reconstruct what  it heard and assign its meaning.  And so part of the challenge of your mind and brain to do ", "that is this.  This is a representation of something like the physical  signal that arrives at your ear.  And you could say, well, here's one word.  Here's another word.  What's the problem?  But this is all the signal that arrives at your ear for ", "the word captain.  So here's the C, all this stuff for the A, a period of  long silence that sets up the P. Turns out-- ", "I'll convince you of this in a moment--  that our speech is full within words of silent breaks that  are incredibly informative and alter our perception of what's  physically going on. ", "Then the little T. This long stuff for the AI.  This long stuff for the N.  So the physical signal to your ear barely resembles what  seems like a single unit, captain. ", "And where's that pause?  A person doesn't say, \"cap,\" or doesn't say \"ca,\" one, two,  three, \"ptain.\" Right?  I mean, but the pause is happening, and it's incredibly ", "informative, as I'll show you.  So that's the incredible thing.  Your auditory system, your language system, has to  reconstruct sound into phonemes, into words.  It's not obvious in the physical signal of the ear. ", "It's not even that the physical signal at the ear  gives you much information at the outset about whether  you're hearing one word or two words or three words.  So here's \"what,\" and \"do you mean\" as one big blend. ", "Where is \"do\"?  Where is \"you\"?  Where is \"you mean\"?  And why does \"what\" look so separate, and these three  words, \"what do you mean,\" get all garbled together.  And you have to unpack them by your brain and mind. ", " Here's another example.  John said that the dog snapped at them.  The dog snapped.  Here's what's coming, roughly, to your ear, ", "taken from spoken speech.  And here, again, notice that the boundaries that you can  see here, the gaps of silence, occur not very related to the  boundaries between the words that your mind ultimately ", "understands.  So here's the word \"the,\" \"dog\".  Here's S for \"snapped\".  Here's a good pause.  But that's a pause between the P sound and the T sound. ", "That looks like a good word boundary.  To a machine, that's a very good word boundary.  It's not a word boundary for you.  You know snapped is one word.  And here comes \"at.\" \"At\" is kind of blended into the T. So ", "there's this physical signal doesn't even give you breaks  where words separate from one another.  It's kind of a continuous mix of breaks and silences. ", "So here's to convince you that a silence carries incredible  information in it.  Let's see, make sure I have the volume.  OK, so I'm going to play you this. ", "This is a physical signal to your ear of the word \"say.\"  RECORDING: Say.  PROFESSOR: OK.  Yeah? ", "I always worry because Tyler's an expert in this, and I'm  always like, please, Tyler, don't  embarrass me when I'm wrong.  You don't have this pressure out there, but the teaching  assistants are all experts in something or another.  And then they know more often than I do on that topic, and ", "we hit their topic in the course.  I'm looking over there nervously.  So here's \"say.\" Now, they're going to take this thing and  just separate this, just in the way you do a physical ", "signal on a computer, just separate in time.  They're just going to add a little bit of time.  And what do you hear?  RECORDING: Stay.  PROFESSOR: The T sound that makes is simply adding silence ", "here to produce that.  Now, that's what you hear all the time.  It's not a random choice.  But isn't that amazing?  That silence is as ultimately informative for your mind as  actual language sounds themselves. ", "All this is happening on the order of thousandths of a  second, in bits of information.   That's bad enough.  Here's another amazingly tough thing.  So people like to compare consonants that have a lot of ", "similarities with some interesting differences.  Ba and da.  This is really comparing B versus D. It's throwing on the  A just to have a vowel sound.  So here, again, is a representation of what's  coming to your ear. ", "Notice that all the difference between the B and the D, these  two consonants, all the physical differences occurring  in 40,000ths of a second.  40,000ths of a second is all the physical difference that ", "you get as you hear these two things.   RECORDING: Ba.  Da.  PROFESSOR: 40,000ths of a second, and yet you could hear ", "the word bad, and you're not going bad, dab.  Come on, that was thousandths of a second, right?  And not only that, there'd be another word and another word  in a sentence.  That's why people use the word speech stream, and we like to ", "think of it as a speech torrent.  Phonemes, phonemes, phonemes, breaks, all garbled together  in your mind as you back and constantly, instantly, and  brilliantly figure out what you've heard. ", "So let me give you another example because part of the  challenge of this are phonemes occur in the context of words  and sentences.  So make sure I have good volume on this. ", "OK, so let's do this first one.  RECORDING: [INAUDIBLE].  PROFESSOR: What was that?  AUDIENCE: [INAUDIBLE].  PROFESSOR: What?  AUDIENCE: [INAUDIBLE].  PROFESSOR: OK.  Here's the same thing, and a person is going to say this ", "now all by itself.  RECORDING: Little.  PROFESSOR: You got that, right?  OK.  RECORDING: Mary saw the three little pigs in the corridor.  PROFESSOR: OK, but here's the amazing thing. ", "The first sound you heard, and I'll replay it, they took the  word little, and they cut it out from the last  sentence you heard.  When little is said all by itself, what comes to your ear ", "is literally the first thing you heard.  Not this, because when you say a word in isolation, little,  people say it differently.  But we almost never talk like that. ", "We almost always have a sentence.  And it turns out the way we say things, and therefore, the  way you hear things, is hugely influenced by what comes  before it and what comes after it. ", "Never mind things like the speed at which different  people talk, the accent they talk, or the loudness of the  background conversation.  But just simply the fact that you're going to  say little by itself. ", "How does that work?  It's amazing, right?  Listen again.  If you heard little all by itself, and it's exactly the  same physical signal.  ", "Maybe it's not so--  RECORDING: [INAUDIBLE].  PROFESSOR: OK?  Let me try that again.  RECORDING: [INAUDIBLE].  PROFESSOR: That's exactly the same physical signal, exactly  the same physical signal, as-- ", "RECORDING: Mary saw the three little pigs in the corridor.  PROFESSOR: What you hear easily as  little is exactly that.  Words in isolation--  and there's a great demonstration.  If you hear a word cut out, the reason why it sounds like ", "nothing is your mind is already preparing how to  interpret that, given what you heard just before it, and also  a little bit what you hear just after it.  Your mind is constantly fixing up things because it knows ", "what's going on, what's going into it, what's coming out.  It's not because it just simply hears the word itself.  If we lived in a world where people just say one word every  half an hour, we could do this.  In a world where we're talking to each other in sentences all ", "the time, we have to do this.   Here's another example of our brilliant auditory system for  hearing these kinds of things.  So again, these are representations of how this ", "physical signal arrives at your ear.  Here's the word bet, bee, boat, and bird.  They all start with the same B sound.  That's easy, right?  But look what came to your ear. ", "Look at this signal, this signal, this signal.  Look at this one.  How different does this look?  It's different because what follows bird influences how  this is said, but you can see that you can translate both of ", "these into the B sound pretty easily.  Now, look at these words.  These all start with D. Look at how bet and debt look  almost identical.  We said it's only 40 milliseconds difference,  40,000ths of a second difference that physically ", "moved through your ear.  But you can tell the word bet versus debt.  Look at the word D, how different it looks  from word to word.  So your mind is constantly figuring  out what you're hearing. ", "The problem of invariance, and it's constantly coming to you  in incredibly variable ways.   So one of the tools we have, and an amazing human capacity, ", "is what's called categorical perception.  So we have all this huge range of physical sounds that can  come to our ear.  And kind of brilliantly, and you don't  even think about it--  I mean, none of you go around bragging about your ", "categorical perception abilities, right?  Like when you go to spring break, right?  And maybe some of you will go home, or you'll see friends,  and you won't go, I have categorical perception.  I try to be modest about it. ", "But it's an amazing human talent, and essential because  what it does is this.  We hear this huge range of sounds, depending on accents,  what comes before, what comes after. ", "And we have to decide that's a B. And what you're going to do  is take this huge range of things, and just go, boom.  It's a B or a D, and that's all there is to it.  So here's the way they do it. ", "So categorical perception.  Sounds can vary continuously.  We showed you some of this continuity.  In this experiment, on purpose, they're going to vary  sounds in a very continuous, physical way. ", "But in our heads, for ba and da here, in our heads, all the  stuff that's over here, even though they're very different  one from the other at a physical, specific level, ", "we'll say, ba.  I'm done with it.  We're going to put it in one category for interpretation.  And you're going to have a pretty sharp boundary here.  And then everything over here, all these physical signals,  you're going to call pa. ", "And so you're not going to spend a lot of time going,  that was a one third ba, 2/3 pa, probability.  You couldn't do that, right?  Because you couldn't get through a  word, nevermind a sentence.  You're going to instantly group huge numbers of things ", "that are different from one another into two categories  that need to be separated.  So here's a kind of experiment they do.  I'll just give you the feeling of it.  Here's what they're varying, constant units. ", "Constant units, every stimulus here is different.  But every time you hear ba, and they're constantly going  to vary something by its physical property, you always  call it a B. And then something happens, in about 20 ", "milliseconds of information, and boom, you always call it a  P. So change, change, change, change, change, in the  physical signal, you call it one category. ", "A little bit more change, boom.  It's the other category.  And you keep changing, but for you, it's always a perfectly  good P, even though every one of those are different.  So it's an amazing fundamental capacity to take a huge, and, ", "for all practical purposes, an infinite variety of inputs and  say it's a B or a P if that's the world I'm working in.  Syntax.  That's another way in which we understand things, the way ", "that words are organized and the order.  So we could say, \"The model embraced the designer and the  photographer.\" Imagine somebody saying to this.  But then they complete the sentence, \"The model embraced  the designer and the photographer laughed.\" ", "So people who study syntax really are interested in what  happens in your mind as you hear, \"The model embraced the  designer and the photographer,\" and some big  group hug is going on, right?  And then all of a sudden, you get this word laughed, and you ", "have to rearrange the elements in your mind.  That's what syntax is letting you do, to say, oh, the  meaning is really quite different.  There's only one hug going on, and one person laughing at  them, right?  But the meaning over time as somebody talks to you set up, ", "you're thinking this, boom.  Because you understand syntax, you understand what happens.  Semantics are kind of more straightforward than how we  usually think about them. ", "They're the meaning of words or sentences, morphemes.  And we can understand semantics even when the  sentence is nonsense. \"Colorless green ideas sleep  furiously\" is a famous example. ", "We can understand semantics even in bad grammatical  sentences, right?  \"Fastly eat dinner, ballgame start soon.\" Your fifth grade  teacher would be up in arms to hear that, but you understand. ", "Eat now.  Go see the ball game.  So we get through a lot of stuff to get semantics.  And we can see interactions.  I stole this example from Ted Gibson because it took me 20  minutes to figure out what the sentence means. ", "You're probably faster than I am.   Are you OK?  I'm like the old man.  Where's the missing words? ", "The old man the boats.  So this is how you have to parse up the sentence.  It's not always obvious.  People who study language love these things, where people are  all confused.  Most of our lives, we don't go through that much confusion. ", "But there's some fun ones, sort of like the visual  illusions, to point out how meaning and syntax can  interact as you figure out things.  Here's another example.  Jay Leno talked about sex with Lindsey Lohan. ", "OK, now wait a minute.  Did I miss that excellent episode of Jay Leno, or was  she on the show, and talking about-- she was saying I'd  rather not talk about my recent conviction. ", "I'd rather talk about something less controversial.  So semantic.  All these things are constantly  interacting in your mind.  It's kind of amazing when you think about that, right?  We said phonology's amazing. ", "Semantics, syntax, boom.  They're all happening in you.  And none of you are sitting there,  going, just do phonology.  Please don't ask me to do semantics.  We just had midterms, right?  Brilliant. ", "So one of the ways that people try to convince themselves  that these things are separable and gives a little  bit more insight is Evoked Response Potentials.  Those are these things that you can measure on infants or  adults that measure electrical activity in milliseconds and ", "the speed of language processing, surface electrodes  that give you an index of a few hundred thousand neurons.  And this is an example you saw before, actually, earlier in ", "the course, the so-called N400.  So N means whether the wave is going up or  down, negative or positive.  400 means that it occurs about 400 milliseconds, about half a ", "second, after the relevant event.  So here is this, let's see, it was his first day at work.  That's the baseline.  He spread the warm bread with socks. ", "Oh my gosh, socks.  Semantically bad.  And here comes the N400.  And the control condition is you throw up this unexpected  word, shoes, that's weird, but not semantically, and you get ", "quite a different response.  So here's an N400 that seems to simply be about semantic  expectation or congruence.  How about if you mess up syntax? ", "The spoiled child throw the toys on the box.  Then you get a response at about 600 milliseconds to  syntactic incongruity. ", "So people, this is just more evidence that in the brain,  meaning or semantics and syntax or something about word  order are processed somewhat differently in time and place. ", "Pragmatics is kind of fun.  It's practical understanding.  The old joke, do you know what time it is?  And the person says, yes.  They're messing with your sense of pragmatics.   Two negatives make a positive. ", "Saying, yeah, yeah.  I've heard that one before, earlier in the lecture.  Now, here's something kind of interesting, again, which is  remarkable.  And if you didn't do the experiment, you couldn't know  that our mind is like this. ", "Because you wouldn't do things like this because it sounds  too ridiculous, but your mind does it all the time.  So we're going to think about the word \"bugs.\" And I have to  set you up a little bit with paradigms you've heard before, ", "but just remind you of these things.  So one kind of task that psychologists like to use to  think about how people process words is a  lexical decision task. ", "All you're deciding is whether a word is a real word or a  nonsense word.  So doctor is real.  Poctor is not.  Spy is a real word.  This spelling is not a real word. ", "So real word, not a real word.  We also talked about one other idea early in the course, that  if, prior to processing a word like doctor, you get an  unrelated word or a related word, you process doctor ", "faster if you had a related word before it.  Semantic priming.  The ideas about nurse overlap a lot with  the ideas about doctor.  And seeing this word before makes you  process this word faster. ", "So you need those two things in mind.  What was the person doing?  Is it a real word or not?  And you're going to mess with what's in their mind before  that, related or unrelated.  And here's the experiment. ", "So you would hear, over headphones, something like  this, as an example.  \"Rumor has it that for years the government building had  been plagued with problems.\" Now,  here's a critical sentence.  \"The man was not surprised when he found several spiders, ", "roaches, and other bugs in the corner of his room.\"  So there's two senses of the word, at least two meanings of  the word bug, right?  The insect you don't want in your soup, or the microphone ", "that somebody slipped into your room to listen to  what's going on.  Two different meanings for the word bug.  This is obviously about the insect.  So the person is hearing this over headphones, and on a ", "computer monitor in front of them, after they hear the word  bugs here, they see, for a lexical decision, the word  \"ant,\" which is related to this meaning, or \"spy,\" which ", "is related to the other meaning that's not relevant  for here, or \"sew,\" which is the control condition.  We'll ignore that because it's just a control condition.  I'll ignore that for now.  So you're making a lexical decision now on the related ", "meaning or the unrelated meaning.  And here's what they find.  If it's the related meaning, and you only have about a half  second from when that came on to when you had to do this ", "task, so you saw the word bug and here comes  this, you're faster.  But if you get the unrelated meaning within a half a second  of processing the word, you're also faster. ", "What this means is, your mind has done exactly what you  would think it wouldn't do.  Your mind has looked up in your brain, and in your  knowledge of vocabulary, every meaning of the word. ", "Even though the sentence is clearly setting you up for the  word, the insect meaning, every meaning of your word is  turned on and available to you.  Your mind does the opposite of what you might think. ", "You might think, well, I know--  let's look at the sentence.  I know, once I get spiders, roaches, and bugs.  By here, you know you're in the insect world, not in the  world of spies, right? ", "But your mind, even then, looks up every possible word.  Because it's cheaper for the mind to look up every word  than to start to decide what the appropriate word is. ", "And then, if you wait another second and a half, you're only  fast for the selected meaning.  And now you're slowed down for the one  that's not context relevant. ", "So your mind looks up everything all the time.  Every meaning of every word you know.  Every time that word pops up, it seems like your mind looks  up every meaning, and then the rest of your mind selects out ", "the one that's relevant and shuts down the  ones that are not.  But you wouldn't think that.  You would think, maybe I'll just get the one I need.  I'm not going to get everything.  It's like, I'm not going to put all my clothes on, walk  outside, and take off everything that's not relevant ", "for the weather, right?  It seems like a really inefficient way to get  dressed, right?  But that's not the way your mind is.  Your mind is cheaper and more efficient to look up every ", "meaning every time, and then pick the right one.  It's more efficient, and that's how people do it.  So people use this word exhaustive lexical access.  I look up every meaning of a word, and then I'll pick out ", "the correct one.   Another interesting aspect that could be brought into ", "pragmatics, and we'll talk a little bit more about this  later in the course, but emotional intonation.  And it turns out where it's almost all language processes  are left dominance as we talked about many  times in the course. ", "One stream of processing language, both visual and  auditory, is right hemisphere dependent.  And that's emotional intonation.  And that brings us to our reading for ", "today, from Oliver Sacks.  And I have to say, I think Oliver Sacks is a phenomenal  author, but there's always been this sense of some of  these stories are just a bit too true to be-- just a bit ", "cute, or whatever it is.  And so for years, I taught from this story, and I  believed it's likely true.  But I thought, well, it's just a little cute.  And then came an experiment that showed it's not only ", "cute, but it's exactly correct.  So for this, you appreciate this a bit more if you know a  couple things about Ronald Reagan, who was ", "president in the 1980s.  So what do you guys know about Ronald Reagan?  What party?  AUDIENCE: Republican.  PROFESSOR: There you go.  Was he considered a good communicator? ", "AUDIENCE: Yes.  PROFESSOR: Yes.  He was considered-- you know, you can have all kinds of  views on Ronald Reagan's things.  The public said, he's an awesome communicator.  In fact, Barack Obama said he would like to communicate like  Ronald Reagan. ", "Whether that's to get Republican votes or not,  that's your judgment.  But he was considered an excellent communicator.  Was he considered, by and large, to be an extremely ", "analytic thinker?  He might have been.  I don't know him.  But not so much.  Now, part of this is the prejudice or not, but he was  from California, and he was an actor before he became ", "president, or the governor president.  He also had some degree of--  well, he ultimately got Alzheimer's disease.  It's a question about later in his administration, whether he  was already working his way towards that. ", "So anyway, complicated things.  So he was a master communicator, but not  necessarily the Barack Obama, Bill Clinton, Jimmy Carter  version of an analytic power, is the general perception. ", "You never know whether these are right or  wrong for the person.  But in the story, listening to the president's speech, are  patients with aphasia that Oliver Sacks described, and  he's getting laughter as they're watching his speech. ", "And what happens is, some of the people with a left  hemisphere lesion-- so you have a language problem.  We'll see a video of that pretty shortly.  They're laughing because they think that the way he's ", "talking and his facial  expressions, they find hilarious.  Now, why do they find it hilarious?  They have damage to the parts of the brain that help them  understand the content of his message on the left  hemisphere. ", "And here's what Sacks thinks is going on.  \"The feelings I have, which all of us who work closely  with aphasics have, is that you cannot lie to an aphasic. ", "He cannot grasp your words, and so be deceived by them.  But what he grasps, he grasps with infallible precision,  namely, the expression that goes with the words, that  total spontaneous, involuntary expressiveness which can never ", "be simulated or faked, or words alone can hide all  sometimes too easily.\"  So when you give a very public speech, especially under tough  circumstances, that presidents sometimes have to do, we ", "sometimes think there's a tension between exactly what  they're saying and exactly what they're thinking.  And what they feel they need to say, and exactly what they  know is behind the scenes.  And so the idea is that these aphasics, they were saying ", "this guy obviously doesn't mean what he's saying.  Look at his face.  Look at his tone.  I don't know what he's saying, but it's hilarious, how he's  masking his face and speaking in a funny tone to tell ", "something he truly doesn't believe.  That's their interpretation.  And yet, he has an opposite patient, a patient with a  right hemisphere lesion.  We said that's the side of the hemisphere that seems  important for facial expressions and emotional ", "intonation.  And she complains about the logic of the case he's making,  as if having--  normally, when we talk to somebody, it's both.  Left hemisphere's getting the content,  analyzing the content. ", "Right hemisphere, something about the intonation.  True or not true?  Are their eyes like this, and they can't even face us as  they tell us something they know is false.  But these patients, maybe because they have one channel ", "of information knocked out because of injury, they become  hypersensitive to the other one.  So I thought, well, that sounds fantastically  interesting, but is that really true? ", "So here in Boston, they did a study with a large number of  patients that says they had superior identification of  people who are lying to you--  they had made video clips and audio clips of people who are ", "lying to you--  if they had a left hemisphere lesion.  So this is a paper.  So here's the two examples.  So they have an example.  Let's pick this one. ", "Where both, you see just a facial  expression of a person talking.  The voice is turned down.  Your job is to decide whether a person is lying or not.  And some videos they're lying. ", "Some videos they're not.  So how would you do?  I don't know how you would do, but I can tell you how a group  of Harvard undergraduates did.  50% is chance, and here's how they did. ", "That was one of their control groups.  And, in fact, for studies like this, they brought in many,  many kinds of people to ask whether anybody is better.  Everybody's pretty much terrible at directly telling ", "whether a lie is going on.  Now, these are video clips of people you don't know in  circumstances you don't know.  That could matter.  But everybody's terrible at that.  Policemen are terrible.  FBI agents are terrible. ", "The only group that seems to be above chance, and not much  above it, are Secret Service agents.  So if you're friend with a Secret Service agent, and you  want to deceive them, keep in mind that they seem to be ", "above chance.  They're not awesome, but they're above chance.  But look who's doing better than everybody, patients with  the left hemisphere lesions.  And the interpretation is, all the content  of the lie is gone. ", "All they see is your expression, or your expression  and intonation.  And because that's all they have to go on, they can tell  more when you have the discomfort of lying than a ", "person who's partly persuaded by hearing the message you're  sending as you talk.  So I thought this was an overly cute example, but it  turns out to be exactly replicable in a full study. ", "Any questions about that?   OK.  So let's talk a little bit about the  brain basis of language.  We've talked a little bit about-- ", "we know that if you have damage here, you have Broca's  aphasia on the left hemisphere,  trouble producing language.  Damage here, Wernicke's aphasia, trouble  comprehending language. ", " To a first approximation, and there's a lot of research that  has made this much more complicated, but a first  approximation, the lesions are in frontal ", "cortex or temporal cortex.  The speech in these patients are what's called non-fluent  or telegraphic.  They get single words out but have a hard time with anything  like a sentence.  It can be very frustrating for these patients. ", "Wernicke's patients seem much happier.  You'll see a film in a moment.  Their speech is fluent, but it's  amazingly empty of content.  These patients have trouble producing speech, but their ", "comprehension is decent.  These patients produce speech pretty well, but their  comprehension.  So they're mirror opposites.  And let's see, what do I want? ", "Yes.  So in this field, a frequently, incredibly  frequently used picture to study aphasia is  this specific picture.  It's called the cookie theft picture. ", "Why it's become widely used, I'm not exactly sure.  But once it's widely used, then often everybody uses it.  So they'll put a picture like this in front of an  individual, and they'll ask them to describe ", "what's going on.  It's to elicit production.  And you would say something like, there's two kids.  The kid's on a stool.  Uh oh, is he going to fall over?  Because they're falling off the cookie jar, and the ", "mother's sort of not paying attention.  Her mind must be somewhere else because she's letting the  water splish splash here, right?  You would say something like that.  So let's see what patients with aphasia say, and other ", "examples of their difficulty with language.  ", "Yeah?  AUDIENCE: [INAUDIBLE].  PROFESSOR: Their writing tends to go pretty much with their  spoken language.  That's a really good question about-- so the question is, ", "what would their writing be like?  It very much parallels their spoken language.  Yeah?  AUDIENCE: [INAUDIBLE].  PROFESSOR: Sorry? ", "AUDIENCE: [INAUDIBLE]  sign language?  PROFESSOR: OK, so very good question.  Could not fluent aphasics learn sign language to bypass,  in a sense, their problem, right?  So I'm about to answer that in a moment, ", "right on the next slide.  Not directly that, but the implication of that.  Because the important thing is-- so let me show you this  thing, and let me come back.  The question is, could you train an aphasic to use sign  language to get around his or her language problem, if it's ", "a speech problem?  So people have studied sign language as a language for  many reasons, but a huge one is this. ", "Because I'm going to interpret your question the way I need  to, and then you can tell me if I did it right from your  perspective.  Which is, in what sense does language equal speech? ", "Could you communicate linguistically like, but just  switch to your hands, if for some reason-- and the answer  is, that at the level of the problem of these patients,  they could not do it. ", "Because these kinds of patients, the problem isn't  really speech.  There are people who have problems with the motor  apparatus to move their mouth.  That does exist. ", "Their problem is in language processes that produce your  speech intent, or language processes that extract meaning  from sounds.  And those language processes that produce what you want to ", "say, that comprehend what you hear or read, those are the  same ones that are utilized, as far as we understand,  whether you're producing language in the typical, vocal  way, or in the less typical, but ", "well-studied, way of sign language.  Does that make sense?  OK.  So you can't get around it because  it's a language problem.  So both by brain imaging evidence, for example, here ", "are patients who use sign language turning on Broca's  area and Wernicke's area on tasks that are about  comprehension and production.  It's the same areas, whether it's using your hands for sign ", "language or using your mouth to talk or your ear to hear.  Further, there have been really fun studies where they  took deaf infants and have shown-- and it's not easy to ", "show, but I think most people are convinced that they babble  with their hands.  The same way babies make little sounds to get  themselves going.  We'll talk more about infants in a moment.  Infants who grow up in an environment where they only ", "learn sign language babble with their hands because  speech, language is not about your mouth talking.  It's about ideas that you can communicate by your production ", "or comprehension, by your hand or by your mouth.  So language is separable from speech, because even without  speech, you communicate in very much the same way, in  terms of sign language, by many studies. ", "Yeah?  AUDIENCE: So does that mean that people that [INAUDIBLE]  imagined words or language?  PROFESSOR: Say that again, sorry?  AUDIENCE: Does that mean that they also couldn't imagine ", "words or language?  PROFESSOR: Who couldn't?  AUDIENCE: People with Broca's area aphasia.   PROFESSOR: I don't think so.  We talked about this before, that-- ", "I may not be understanding your question exactly, but--  in many ways, imagining something is the same part of  the brain that does it.  When we imagine a face, we turn on the parts of  our brain that sees. ", "I think when you imagine, if you--  I do this sometimes.  I say, here's what I'm going to say to that  person, in my head.  And I practice that little speech.  That's this part of the brain pretty much running. ", "There's just a last little step of moving your mouth, but  from the discussion we're having now, that's kind of a  superficial thing of moving your mouth.  That's not speech planning, speech thinking, speech ", "intentions.  Those are our core process for production, for comprehension,  and I think imagined stuff is exactly the same way.  Is that OK?  Yeah.  Yeah? ", "AUDIENCE: So if they can't really imagine language, then  how do they-- what is their thinking like?  [INAUDIBLE]?  ", "PROFESSOR: Yeah, that's a good-- so the question is, if  they have these troubles with core language ideas,  abilities, what's their thinking like?  I could just tell you, it's a classic debate for humans, how ", "deeply language equals thought.  But language [INAUDIBLE] in a sense of speech.  It's just one of those things that people debate a lot  because it depends what you mean by these things in many  different ways. ", "But if language means something like comprehending  ideas in the world, it's hard to get around that for  thinking [INAUDIBLE].  It means planning actions in the world that change the  world around you, and communicating that, it's hard ", "to not have that capacity for thinking in that way, right?  So it's at this level, not whether you use your hands or  your mouth, it's very hard to separate out what you might  call thought and what you might call language. ", "But keep in mind that these patients that we see, it's not  like they lost all of language at all.  So even the Broca's aphasic has trouble producing  language, he's producing some, and he  comprehends it pretty well. ", "So it's not like these patients have lost all of  their language circuitry, and therefore don't have thought  available, right?  They have a lot of language left in their head, and a lot  of thought left in their mind.  Is that OK? ", "So one interesting thing that people have wondered, and  where brain imaging gives us evidence that we couldn't have  imagined 15 years ago, is this.  So if you have damage, let's say, here's a patient with  damage to the left frontal area. ", "And they get better because they've had a stroke here or  an injury here.  They get better.  A question that people have wondered is, do they get  better by sort of somehow recovering ability in a part  of their brain that got injured? ", "Or do they get better because they use an entirely different  pathway in their brain?  Now, until brain imaging, you couldn't begin  to touch that question.  But now we have some evidence, and I'll make it just--  and so here's an example of a patient who has damage here. ", "They have him do a task that in healthy people turns on  exactly that place.  And when he does it, he can do it OK.  And where does he do it? ", "In his right hemisphere.  So this patient seems to switch which hemisphere he  uses for language.  It takes time and training to recover that.  But it seems like he's found an alternate pathway to ", "produce a language somehow.  Turns out that the more people have studied these things, the  more complicated it gets.  Maybe just diversity of people, diversity of injuries, ", "or whatever.  So it doesn't always work this way.  But often, it seems like when people have better recovery  from a large injury to the speaking left hemisphere, they  find a way, somehow, through practice and training, to get ", "the right hemisphere to take over some of those  responsibilities.   Language acquisition.  So one of the most amazing things about infants is they  go from zero to speech in just a couple of years, and go ", "through an unbelievable training and program of  development.  So what happens?  In two or three months, they perceive all the phonemes.  They notice this change in phonemes.  By six months, they start to ignore distinctions among ", "sounds that are not used in their language.  In other words, other language sounds.  They start to babble, in some way getting their  speech ready to go.  By eight months, they start to identify single words in a ", "speech stream.  In a year, their babbling becomes  more adult-like sounding.  But a little bit after that, they get up to about 50 words  in understanding.  So comprehension always goes ahead of production. ", "Children understand words before they can speak them.  But they're lagging.  Here comes a speech, telegraphic speech, short  sentences at two years.  And then, finally, pretty complete speech, in  many ways, by nine. ", "So it's a long, long process, learning 10,000 words  estimated by the age of six.  That's a spectacular learning curve.  When they do experiments on infants where they measure ", "things like preference or learning by sucking rates on a  nipple because they can't talk, they try to figure out,  what is the infant hearing.  Within two hours of birth, they suck with more enthusiasm  to their mother's voice over another voice. ", "These are infants, this is their first  visit to their mother.  You have to sign up to do this experiment.  Now, they might have heard their mother's voice in a  certain way in the womb, right? ", "But they already have picked up, by three-day-old, they  prefer language to many other sounds, like music.  We come to love music, but that's not the urgent business  of the infant.  By four days old, they start to notice the differences ", "between languages.  This is amazing.  Their rate of learning is fantastic.  And by two months, they can tell the ba-ga distinction,  subtle distinctions, 40 milliseconds information. ", "And then they develop a continuingly strong preference  for the sounds of their native language.  Now, some years ago, people debated endlessly this left  hemisphere specialization for language. ", "This is fantastically essential  and striking in humans.  Does that grow over time, or is it in your mind  and brain at birth?  And the evidence is pretty compelling for many sources, ", "but here is maybe the most.  Here's fMRI on two-day-old infants.  You might ask, how do they instruct the infants to lie  still in the scanner and participate in the experiment? ", "And the answer is, at two days old, infants mostly just lay  there and don't do much.   They don't do much.  And there's a lot going on in their mind, but they don't ", "have much physical apparatus to do much.  So you could swaddle them very warmly, and just lay--  you put them on a cradle into the fMRI scanner.  Their parents have signed up for them. ", "And you could play them sounds while they just lay there and  do nothing.  They can't push buttons.  They can't do stuff.  But you can see what's happening inside their brain.  And at two days old, here's the left hemisphere response  to language compared to the right. ", "So it's there instantly, we believe.  It's been there, actually in the womb as the child's been  developing.  This left hemisphere, genetically set up dominance ", "for language in almost everybody.   fMRI, just for those of you who--  again, we can start doing it at about age five, but from ", "about three months to age five, it's incredibly hard to  do children in a scanner.  But the first couple days, it's not so hard.  Now, a really interesting line of research has ", "talked about motherese.  Have you heard this term?  So how do grown-ups, even college  students, talk to babies?  Do you talk to babies just like you talk  to everybody else?  No. ", " Cute baby.  Baby, baby.  And everybody looks like an idiot, right?   And you could just think, OK, that's just people being ", "idiots around babies.  But it turns out there's been beautiful, beautiful studies  to show that, while you spontaneously do this-- and  you and I don't take motherese or fatherese courses-- ", "but what we do spontaneously is that way of elongating  sounds, the intonations we give, are incredibly perfect  to help the baby learn language. ", "We're exactly doing what they can understand.  And that, again, must be virtually in  our genes, I think.  We hear it around, so it's not zero.  But the short pauses, careful enunciation, exaggerated ", "intonation, that's--  you could do experiments where you take language and you get  rid of those, and the babies are like-- they don't know  what's going on.  They're not interested.  You put them back in, boom.  Those are perfect for the baby. ", "It's amazing, not only how babies are ready to go, but  how adults who talk with them are ready to go.  I mean, it's just amazing.  None of us will ever be as good a teacher in a classroom ", "as all of you will be with a baby anytime  you talk with them.  It's just amazing.  So there's beautiful experiments that show that  every time you tinker with the way the mother spontaneously, ", "or parents spontaneously, talk to indants, you make it worse,  less interesting, and less informative for the infant.   So now let's talk about a more formal experiment. ", "These are the classic experiment that nailed home  this message, that at birth we're universal understanders  of all sounds in the world.  And as the years go along, we became only good at the sounds ", "that are relevant, that are part of our own language.  A famous example in the US is a difficulty for Japanese  native speakers for the R-L distinction.  But every language has some distinctions it doesn't make, ", "and they're really hard when you get older.  So here's the idea.  In English, we make a distinction between ba and da,  and by 10 to 12 months, an infant can make that  distinction. ", "And certainly, adults can.  That's categorical perception that we talked about, that  kind of division between ba and da.  But there's sounds that occur in other language. ", "So we're shown here.  And you're going to hear--  some of you may know Hindi sounds, and it'll be a  different experience for you.  Every year, when I first hear this clip I'm about to show ", "you, I think something's wrong.  Because they say, the infant's going to tell the difference  between da and da.  And I go, well, how are they going to do that?  I can't do that.  That's because they really are different sounds you're ", "hearing, but in English, they're not different sounds.  And so it all sounds the same to me.  I'm no longer a universal learner.  I haven't been since quite a while. ", "So here we go.   I'm stunned, always, by the brilliance of infant  researchers like this, who somehow, pretty convincingly ", "in most cases, really tell you what the infant knows or pays  attention to or thinks in pretty compelling ways, even  though they can't tell you themselves.  So one thing that's come up in the US-- ", "I mean, the whole world is becoming ever more bilingual  and trilingual.  There used to be some concerns, less now, and I'll  tell you, you don't have to worry about it.  Whether it's bad to learn two languages at once ", "when you're a kid.  And some parents worry about this, right?  You're going to be all messed up because you're going to  blend them all up and not do well in school.  And so there's been quite a bit of research, actually,  tracking and asking whether there's any downside. ", "I mean, there's huge upsides to knowing  two or three languages.  Are there any downsides in terms of language development?  And the objective evidence is pretty compelling that for ", "babbling, for first words, for pairs of words at a time,  [INAUDIBLE] at two months, that there's really no cost.  So they followed, in Canada, for example, children who grew ", "up learning English and French, English and ASL,  French or English only.  Everybody does the same, pretty much.  There's no cost, compared to the huge gain. ", "Sometimes some kids will get a little mixed up.  They'll actually mix up languages because they'll just  mix them up when they're pretty young.  But there's no developmental delay of milestones or  negative consequences. ", "There's only the benefit of having two or three languages  that you could speak.  So the evidence is overwhelming, empirically,  that there's no cost for learning more than one  language at a time when you're an infant. ", "One thing, there is a cost, a little bit, if you're a boy.  So unknown why this happened.  I don't think there's any deep science about it.  But everybody has observed that, for example, number of ", "new words understood during the first two years of life,  that girls, on average, outperform boys in language  acquisition early on.  And then things get closer, pretty much.  But the rate of learning on girls on average ", "is faster than boys.  Nobody, I think, understands the specific basis of that.  So when people talk about critical periods in language  acquisition, and what are fragile or resilient aspects ", "of language.  Which aspects of learning language that seem very  dependent on the age you are, and which are independent.  So phonology, including the production of language sounds,  seems very fragile. ", "Easy when you're young, harder when you're older.  Grammar is also age-sensitive, making subtle grammatical  distinctions.  Learning about meaning or vocabulary, you're perfectly  fine when you're an adult. ", "That doesn't seem to show something  like a sensitive period.  And here's one famous study that established  some of these things.  They looked at what age people arrive to different countries,  from different countries to the US and ", "started learning English.  These are people that didn't know English before.  They're all adults now, and they had them do quickly  grammatical judgments.  And what they found is, if you came to the US when you-- ", "if you were born in the US, or you came to the age three to  seven, you were very good at doing this.  But the later you came here, 8 to 10 years of age, 11 to 15,  17 to 39, your ability to make these fast, subtle grammatical ", "judgments just went down.  Even though you've been here, in many cases, for many years.  You're very smart.  Accents are like that, right?  People come to the US at a certain point in their  development.  They're very skilled in English, have a big ", "vocabulary, but the accent never disappears.  That's another thing in terms of language production that  has its fragile developmental early period.  So the last thing I'll do, and then show you a movie for ", "about eight minutes.  We get this occasional horrible experiments.  It's not even an experiment of nature.  It's just an experiment of horrible human behavior. ", "And the most famous one in language development, which  had a huge impact on the field at the  time, is a child, Genie.  I'll show you.  You'll see her in a movie clip in a moment.  They discovered her locked in a room, in a house, from age ", "20 months, approximately, until they  discovered her at 13.  She almost spoke to no one.  So the people taking care of her locked her in a closet,  basically, and did not talk with her, or she had no ", "language interactions until she was  discovered and rescued.  And then they performed research for years saying  could she learn things, what could she not learn.  She got single words, for example, but she never got ", "particularly good at grammar.  [INAUDIBLE]  syntax.  So a brutal way to test the idea that what's acquirable  later in life.  And what, if you don't learn it early in life, is ", "impossible to acquire fully?  So I'll end with this.  We'll do this for five minutes or seven minutes.   I'll stop there.  It's summarized in your book. ", "Everybody knows about it because it's this study you  couldn't do ethically in a million years.  You would never do, which is if you deprive a child of the  critical period of language exposure.  And she never got lots of aspects of language going. ", "She got OK on a minimal vocabulary,  grew in other ways.  But many of the things that, from a language perspective,  she never got because she missed that critical period.  So that's a bit of a sad story, obviously, but have a ", "good spring break and a refreshing spring break.  And I'll see you in 10 days. "], "vid_duration": [10.06, 12.18, 11.66, 13.01, 13.99, 13.82, 12.15, 12.1, 10.22, 11.05, 10.82, 11.67, 10.97, 10.28, 12.03, 11.53, 10.49, 10.8, 11.7, 12.489, 10.741, 10.78, 10.75, 10.37, 13.87, 10.42, 10.7, 11.65, 11.06, 10.31, 10.19, 12.57, 12.98, 11.96, 11.26, 11.56, 10.44, 14.13, 12.76, 13.15, 10.33, 11.69, 10.118, 12.282, 11.14, 11.34, 11.1, 12.02, 10.29, 12.41, 11.67, 12.38, 11.38, 11.39, 12.32, 10.96, 12.56, 10.75, 12.9, 10.76, 12.03, 10.59, 11.83, 10.79, 10.134, 10.496, 11.57, 12.47, 11.95, 11.3, 11.4, 13.23, 11.8, 11.07, 12.43, 10.62, 11.43, 10.44, 11.25, 10.13, 10.27, 11.09, 11.98, 10.31, 13.84, 10.43, 13.97, 11.308, 11.451, 12.061, 12.96, 11.1, 10.14, 11.86, 11.98, 10.65, 11.5, 10.01, 10.15, 10.61, 12.48, 12.34, 12.37, 10.92, 10.35, 11.35, 11.21, 11.16, 12.2, 11.33, 10.65, 11.12, 10.28, 11.4, 12.25, 10.31, 11.47, 12.28, 11.31, 10.34, 12.66, 11.35, 10.74, 13.28, 11.48, 10.57, 10.66, 13.41, 10.74, 10.55, 10.31, 10.99, 10.72, 10.25, 10.22, 12.48, 10.3, 10.63, 10.67, 11.49, 10.17, 10.4, 14.35, 11.06, 11.76, 12.01, 14.28, 10.71, 10.21, 13.26, 13.04, 13.11, 10.73, 12.12, 10.44, 10.56, 11.65, 11.47, 11.31, 10.91, 11.13, 12.85, 10.91, 10.59, 11.3, 10.3, 10.83, 10.51, 10.18, 11.33, 10.63, 10.19, 10.39, 11.21, 11.33, 10.89, 10.32, 11.25, 10.91, 10.82, 11.89, 12.679, 10.171, 10.66, 11.35, 10.02, 12.36, 11.79, 10.5, 10.0, 10.41, 11.07, 11.39, 12.05, 10.813, 11.437, 10.0, 12.02, 10.43, 10.923, 10.367, 13.2, 11.7, 12.83, 13.12, 10.11, 12.33, 12.54, 11.18, 14.28, 10.2, 12.12, 10.19, 12.22, 14.12, 11.91, 11.01, 13.26, 10.96, 10.85, 11.61, 14.0, 11.58, 11.57, 10.45, 11.28, 10.03, 10.48, 10.38, 11.25, 10.25, 10.19, 10.07, 10.12, 11.0, 11.16, 10.33, 13.32, 11.29, 12.29, 10.71, 10.71, 11.14, 12.86, 10.0, 10.87, 10.23, 10.77, 10.09, 11.46, 11.23, 11.89, 12.07, 10.27, 10.12, 11.29, 10.75, 12.09, 10.53, 10.18, 12.43, 10.56, 10.65, 11.12, 12.6, 14.41, 11.31, 10.23, 11.31, 12.68, 12.032, 11.198, 10.3, 11.65, 12.24, 11.78, 5.01], "stet": [[0, 10.06], [10.06, 22.240000000000002], [22.240000000000002, 33.900000000000006], [33.900000000000006, 46.910000000000004], [46.910000000000004, 60.900000000000006], [60.900000000000006, 74.72], [74.72, 86.87], [86.87, 98.97], [98.97, 109.19], [109.19, 120.24], [120.24, 131.06], [131.06, 142.73], [142.73, 153.7], [153.7, 163.98], [163.98, 176.01], [176.01, 187.54], [187.54, 198.03], [198.03, 208.83], [208.83, 220.53], [220.53, 233.019], [233.019, 243.76], [243.76, 254.54], [254.54, 265.28999999999996], [265.28999999999996, 275.65999999999997], [275.65999999999997, 289.53], [289.53, 299.95], [299.95, 310.65], [310.65, 322.29999999999995], [322.29999999999995, 333.35999999999996], [333.35999999999996, 343.66999999999996], [343.66999999999996, 353.85999999999996], [353.85999999999996, 366.42999999999995], [366.42999999999995, 379.40999999999997], [379.40999999999997, 391.36999999999995], [391.36999999999995, 402.62999999999994], [402.62999999999994, 414.18999999999994], [414.18999999999994, 424.62999999999994], [424.62999999999994, 438.75999999999993], [438.75999999999993, 451.5199999999999], [451.5199999999999, 464.6699999999999], [464.6699999999999, 474.9999999999999], [474.9999999999999, 486.6899999999999], [486.6899999999999, 496.8079999999999], [496.8079999999999, 509.08999999999986], [509.08999999999986, 520.2299999999999], [520.2299999999999, 531.5699999999999], [531.5699999999999, 542.67], [542.67, 554.6899999999999], [554.6899999999999, 564.9799999999999], [564.9799999999999, 577.3899999999999], [577.3899999999999, 589.0599999999998], [589.0599999999998, 601.4399999999998], [601.4399999999998, 612.8199999999998], [612.8199999999998, 624.2099999999998], [624.2099999999998, 636.5299999999999], [636.5299999999999, 647.4899999999999], [647.4899999999999, 660.0499999999998], [660.0499999999998, 670.7999999999998], [670.7999999999998, 683.6999999999998], [683.6999999999998, 694.4599999999998], [694.4599999999998, 706.4899999999998], [706.4899999999998, 717.0799999999998], [717.0799999999998, 728.9099999999999], [728.9099999999999, 739.6999999999998], [739.6999999999998, 749.8339999999998], [749.8339999999998, 760.3299999999998], [760.3299999999998, 771.8999999999999], [771.8999999999999, 784.3699999999999], [784.3699999999999, 796.3199999999999], [796.3199999999999, 807.6199999999999], [807.6199999999999, 819.0199999999999], [819.0199999999999, 832.2499999999999], [832.2499999999999, 844.0499999999998], [844.0499999999998, 855.1199999999999], [855.1199999999999, 867.5499999999998], [867.5499999999998, 878.1699999999998], [878.1699999999998, 889.5999999999998], [889.5999999999998, 900.0399999999998], [900.0399999999998, 911.2899999999998], [911.2899999999998, 921.4199999999998], [921.4199999999998, 931.6899999999998], [931.6899999999998, 942.7799999999999], [942.7799999999999, 954.7599999999999], [954.7599999999999, 965.0699999999998], [965.0699999999998, 978.9099999999999], [978.9099999999999, 989.3399999999998], [989.3399999999998, 1003.3099999999998], [1003.3099999999998, 1014.6179999999998], [1014.6179999999998, 1026.0689999999997], [1026.0689999999997, 1038.1299999999997], [1038.1299999999997, 1051.0899999999997], [1051.0899999999997, 1062.1899999999996], [1062.1899999999996, 1072.3299999999997], [1072.3299999999997, 1084.1899999999996], [1084.1899999999996, 1096.1699999999996], [1096.1699999999996, 1106.8199999999997], [1106.8199999999997, 1118.3199999999997], [1118.3199999999997, 1128.3299999999997], [1128.3299999999997, 1138.4799999999998], [1138.4799999999998, 1149.0899999999997], [1149.0899999999997, 1161.5699999999997], [1161.5699999999997, 1173.9099999999996], [1173.9099999999996, 1186.2799999999995], [1186.2799999999995, 1197.1999999999996], [1197.1999999999996, 1207.5499999999995], [1207.5499999999995, 1218.8999999999994], [1218.8999999999994, 1230.1099999999994], [1230.1099999999994, 1241.2699999999995], [1241.2699999999995, 1253.4699999999996], [1253.4699999999996, 1264.7999999999995], [1264.7999999999995, 1275.4499999999996], [1275.4499999999996, 1286.5699999999995], [1286.5699999999995, 1296.8499999999995], [1296.8499999999995, 1308.2499999999995], [1308.2499999999995, 1320.4999999999995], [1320.4999999999995, 1330.8099999999995], [1330.8099999999995, 1342.2799999999995], [1342.2799999999995, 1354.5599999999995], [1354.5599999999995, 1365.8699999999994], [1365.8699999999994, 1376.2099999999994], [1376.2099999999994, 1388.8699999999994], [1388.8699999999994, 1400.2199999999993], [1400.2199999999993, 1410.9599999999994], [1410.9599999999994, 1424.2399999999993], [1424.2399999999993, 1435.7199999999993], [1435.7199999999993, 1446.2899999999993], [1446.2899999999993, 1456.9499999999994], [1456.9499999999994, 1470.3599999999994], [1470.3599999999994, 1481.0999999999995], [1481.0999999999995, 1491.6499999999994], [1491.6499999999994, 1501.9599999999994], [1501.9599999999994, 1512.9499999999994], [1512.9499999999994, 1523.6699999999994], [1523.6699999999994, 1533.9199999999994], [1533.9199999999994, 1544.1399999999994], [1544.1399999999994, 1556.6199999999994], [1556.6199999999994, 1566.9199999999994], [1566.9199999999994, 1577.5499999999995], [1577.5499999999995, 1588.2199999999996], [1588.2199999999996, 1599.7099999999996], [1599.7099999999996, 1609.8799999999997], [1609.8799999999997, 1620.2799999999997], [1620.2799999999997, 1634.6299999999997], [1634.6299999999997, 1645.6899999999996], [1645.6899999999996, 1657.4499999999996], [1657.4499999999996, 1669.4599999999996], [1669.4599999999996, 1683.7399999999996], [1683.7399999999996, 1694.4499999999996], [1694.4499999999996, 1704.6599999999996], [1704.6599999999996, 1717.9199999999996], [1717.9199999999996, 1730.9599999999996], [1730.9599999999996, 1744.0699999999995], [1744.0699999999995, 1754.7999999999995], [1754.7999999999995, 1766.9199999999994], [1766.9199999999994, 1777.3599999999994], [1777.3599999999994, 1787.9199999999994], [1787.9199999999994, 1799.5699999999995], [1799.5699999999995, 1811.0399999999995], [1811.0399999999995, 1822.3499999999995], [1822.3499999999995, 1833.2599999999995], [1833.2599999999995, 1844.3899999999996], [1844.3899999999996, 1857.2399999999996], [1857.2399999999996, 1868.1499999999996], [1868.1499999999996, 1878.7399999999996], [1878.7399999999996, 1890.0399999999995], [1890.0399999999995, 1900.3399999999995], [1900.3399999999995, 1911.1699999999994], [1911.1699999999994, 1921.6799999999994], [1921.6799999999994, 1931.8599999999994], [1931.8599999999994, 1943.1899999999994], [1943.1899999999994, 1953.8199999999995], [1953.8199999999995, 1964.0099999999995], [1964.0099999999995, 1974.3999999999996], [1974.3999999999996, 1985.6099999999997], [1985.6099999999997, 1996.9399999999996], [1996.9399999999996, 2007.8299999999997], [2007.8299999999997, 2018.1499999999996], [2018.1499999999996, 2029.3999999999996], [2029.3999999999996, 2040.3099999999997], [2040.3099999999997, 2051.1299999999997], [2051.1299999999997, 2063.0199999999995], [2063.0199999999995, 2075.6989999999996], [2075.6989999999996, 2085.8699999999994], [2085.8699999999994, 2096.5299999999993], [2096.5299999999993, 2107.879999999999], [2107.879999999999, 2117.899999999999], [2117.899999999999, 2130.2599999999993], [2130.2599999999993, 2142.0499999999993], [2142.0499999999993, 2152.5499999999993], [2152.5499999999993, 2162.5499999999993], [2162.5499999999993, 2172.959999999999], [2172.959999999999, 2184.0299999999993], [2184.0299999999993, 2195.419999999999], [2195.419999999999, 2207.4699999999993], [2207.4699999999993, 2218.2829999999994], [2218.2829999999994, 2229.7199999999993], [2229.7199999999993, 2239.7199999999993], [2239.7199999999993, 2251.7399999999993], [2251.7399999999993, 2262.169999999999], [2262.169999999999, 2273.092999999999], [2273.092999999999, 2283.459999999999], [2283.459999999999, 2296.659999999999], [2296.659999999999, 2308.3599999999988], [2308.3599999999988, 2321.1899999999987], [2321.1899999999987, 2334.3099999999986], [2334.3099999999986, 2344.4199999999987], [2344.4199999999987, 2356.7499999999986], [2356.7499999999986, 2369.2899999999986], [2369.2899999999986, 2380.4699999999984], [2380.4699999999984, 2394.7499999999986], [2394.7499999999986, 2404.9499999999985], [2404.9499999999985, 2417.0699999999983], [2417.0699999999983, 2427.2599999999984], [2427.2599999999984, 2439.479999999998], [2439.479999999998, 2453.599999999998], [2453.599999999998, 2465.509999999998], [2465.509999999998, 2476.519999999998], [2476.519999999998, 2489.7799999999984], [2489.7799999999984, 2500.7399999999984], [2500.7399999999984, 2511.5899999999983], [2511.5899999999983, 2523.1999999999985], [2523.1999999999985, 2537.1999999999985], [2537.1999999999985, 2548.7799999999984], [2548.7799999999984, 2560.3499999999985], [2560.3499999999985, 2570.7999999999984], [2570.7999999999984, 2582.0799999999986], [2582.0799999999986, 2592.1099999999988], [2592.1099999999988, 2602.589999999999], [2602.589999999999, 2612.969999999999], [2612.969999999999, 2624.219999999999], [2624.219999999999, 2634.469999999999], [2634.469999999999, 2644.659999999999], [2644.659999999999, 2654.729999999999], [2654.729999999999, 2664.849999999999], [2664.849999999999, 2675.849999999999], [2675.849999999999, 2687.009999999999], [2687.009999999999, 2697.339999999999], [2697.339999999999, 2710.659999999999], [2710.659999999999, 2721.949999999999], [2721.949999999999, 2734.239999999999], [2734.239999999999, 2744.949999999999], [2744.949999999999, 2755.659999999999], [2755.659999999999, 2766.799999999999], [2766.799999999999, 2779.659999999999], [2779.659999999999, 2789.659999999999], [2789.659999999999, 2800.529999999999], [2800.529999999999, 2810.759999999999], [2810.759999999999, 2821.529999999999], [2821.529999999999, 2831.619999999999], [2831.619999999999, 2843.079999999999], [2843.079999999999, 2854.309999999999], [2854.309999999999, 2866.199999999999], [2866.199999999999, 2878.269999999999], [2878.269999999999, 2888.539999999999], [2888.539999999999, 2898.659999999999], [2898.659999999999, 2909.949999999999], [2909.949999999999, 2920.699999999999], [2920.699999999999, 2932.789999999999], [2932.789999999999, 2943.3199999999993], [2943.3199999999993, 2953.499999999999], [2953.499999999999, 2965.929999999999], [2965.929999999999, 2976.489999999999], [2976.489999999999, 2987.139999999999], [2987.139999999999, 2998.259999999999], [2998.259999999999, 3010.8599999999988], [3010.8599999999988, 3025.2699999999986], [3025.2699999999986, 3036.5799999999986], [3036.5799999999986, 3046.8099999999986], [3046.8099999999986, 3058.1199999999985], [3058.1199999999985, 3070.7999999999984], [3070.7999999999984, 3082.8319999999985], [3082.8319999999985, 3094.0299999999984], [3094.0299999999984, 3104.3299999999986], [3104.3299999999986, 3115.9799999999987], [3115.9799999999987, 3128.2199999999984], [3128.2199999999984, 3139.9999999999986], [3139.9999999999986, 3145.009999999999]], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], "topic_end_seconds": [1009, 1527, 2443, 3145]}
